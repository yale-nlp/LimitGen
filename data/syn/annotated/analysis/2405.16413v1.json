{
    "title": "Augmented Risk Prediction for the Onset of Alzheimer\u2019s Disease from Electronic Health Records with Large Language Models",
    "abstract": "Alzheimer\u2019s disease (AD) is the fifth-leading cause of death among Americans aged 65 and older. Screening and early detection of AD and related dementias (ADRD) are critical for timely intervention and for identifying clinical trial participants. The widespread adoption of electronic health records (EHRs) offers an important resource for developing ADRD screening tools such as machine learning based predictive models.\nRecent advancements in large language models (LLMs) demonstrate their unprecedented capability of encoding knowledge and performing reasoning, which offers them strong potential for enhancing risk prediction.\nThis paper proposes a novel pipeline that augments risk prediction by leveraging the few-shot inference power of LLMs to make predictions on cases where traditional supervised learning methods (SLs) may not excel.\nSpecifically, we develop a collaborative pipeline that combines SLs and LLMs via a confidence-driven decision-making mechanism, leveraging the strengths of SLs in clear-cut cases and LLMs in more complex scenarios.\nWe evaluate this pipeline using a real-world EHR data warehouse from Oregon Health & Science University (OHSU) Hospital, encompassing EHRs from over 2.5 million patients and more than 20 million patient encounters.\nOur results show that our proposed approach effectively combines the power of SLs and LLMs, offering significant improvements in predictive performance.\nThis advancement holds promise for revolutionizing ADRD screening and early detection practices, with potential implications for better strategies of patient management and thus improving healthcare.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Alzheimer\u2019s disease (AD) and Alzheimer\u2019s disease related dementias (ADRD) are neurodegenerative disorders primarily affecting memory and cognitive functions. They gradually erode overall function abilities, eventually leading to death [39  ###reference_b39###]. The development of AD/ADRD treatment has been slow due to the complex disease pathology and clinical manifestations. The decline of memory and cognitive functions is associated with pathological progression and structural changes of the brain [28  ###reference_b28###], which can be identified from neuroimage or biomarkers from cerebro-spinal fluid. However, those procedures are expensive and invasive, which are unlikely to be ordered for asymptomatic patients. For real world patients, typically only the electronic health records (EHRs) collected from their routined care are available[6  ###reference_b6###, 18  ###reference_b18###]. These data include information like demographics, lab tests, diagnoses, medications, and procedures, and they provide a potential opportunity for risk prediction of AD/ADRD [34  ###reference_b34###].\nRisk prediction from EHRs is commonly formulated as a supervised learning problem [56  ###reference_b56###] and one can model with existing supervised learning (SLs) tools, such as logistic regression (LR) [68  ###reference_b68###], XGBoost (XGB) [44  ###reference_b44###], and multi-layer perceptron (MLP) [54  ###reference_b54###]. However, SL approaches face significant challenges in predicting risk from EHRs, due to the complexity of medical problems and the noisy nature of the data [75  ###reference_b75###]. Moreover, EHRs do not contain all critical information that is needed for risk prediction for particular conditions. For example, diagnosis of MCI requires a comprehensive evaluation of cognitive functions, such as memory, executive function, and language. In early stages, when symptoms are subtle and not extensively documented in the EHRs, risk prediction using traditional machine-learning approaches can be difficult. Though some information in EHRs may be weakly related to the risk, SL models may or may not be able to pick them up.\nRecent advancements in pre-trained large language models (LLMs) [61  ###reference_b61###, 62  ###reference_b62###, 1  ###reference_b1###, 8  ###reference_b8###, 58  ###reference_b58###] have demonstrated their capability to provide robust reasoning power, particularly with rich contextual information and domain knowledge. Intuitively, LLM can leverage its reasoning capability and flexible in-context learning (ICL) strategies to better derive valuable insights from EHRs. However, there are still several technical challenges to achieve this goal. The first one is how to perform effective reasoning with an EHR database. While fine-tuning external knowledge into the LLMs has been a major approach in many domains, it is not trivial to fine-tune knowledge from EHR to LLMs. EHR includes clinical information for individual patients and evolves over time, whereas LLMs are typically learned and tuned using static information. The second challenge is the representation of medical records for reasoning. LLMs are probability models trained to understand and reason with natural language, and it is not clear how structured EHRs, such as vital, diagnosis codes, and prescriptions, are best represented in LLMs for effective reasoning. The third challenge is rooted in the inherent data quality issues in EHR data, which could be noisy as they were originally designed for billing purposes. The presence of such events is likely to compromise and greatly mislead the reasoning of LLMs.\nContributions.  Here, we summarize the contributions as follows:\nWe identified the strengths and weaknesses of SLs and LLMs in risk predictions from EHR.\nFrom the SLs\u2019 perspective, they provide accurate predictions for confident samples, which are typically aligned well with training data distribution. However, when the samples are not common or the features are sparse, SLs are usually not confident about the predictions and generate poorer predictions than LLMs, showing the value of reasoning from LLMs in EHR analysis.\nBased on our findings, we propose a collaborative approach that combines SLs and LLMs through a confidence-driven selection process for enhanced ADRD risk prediction. This method dynamically selects between SL and LLM predictions based on confidence levels, effectively leveraging the strengths of SLs for high-confidence cases and LLMs for low-confidence instances. Furthermore, we incorporate a meticulously designed ICL demonstration denoising strategy to save the ICL performance of LLMs, which in turn boosts the overall efficiency of the pipeline.\nWe validate our approach using a real-world dataset from the OHSU health system, highlighting the effectiveness of our method and its superiority over traditional SLs and LLMs in predicting ADRD. Additionally, we conduct experiments with different sizes of LLMs and models fine-tuned on various medical datasets. Our findings suggest that neither a larger model size nor fine-tuning on medical data consistently improves risk prediction performance. Further investigation is required to check these dynamics in practice."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "OHSU Data and ADRD Risk Prediction",
            "text": "In this section, we describe the real-world dataset that is the primary focus of this paper. It involves a classification task, i.e., determining whether a patient has (or will have) an ADRD. We will provide a detailed description of the dataset.\nDataset overview. \nWe utilize extensive EHR data from OHSU Hospital, which is mined by the Oregon Clinical and Translational Research Institute (OCTRI) [72  ###reference_b72###]. This dataset contains longitudinal EHRs for  (approx.  million) individuals (i.e., ). Here,  represents the feature vector of the  patient and  is the corresponding ADRD label, respectively.  is characterized by  features (i.e., ), where  denotes the value of the  feature. These  features are categorized into five primary types: vital signs, laboratory test results, International Classification of Diseases (ICD) codes, RxNorm medication codes, and Current Procedural Terminology (CPT) codes. Detail information for each category is described in Table 1  ###reference_###. This rich information is further processed as features that support the development of risk predictive models for identifying ADRD, along with analysis of different ADRD patient group definitions and prediction windows [75  ###reference_b75###]. We split  into training  and testing  datasets after obtaining  by following the procedures described in this section."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Task Description",
            "text": "Following existing risk prediction models [3  ###reference_b3###], we formulate the risk prediction as classification tasks that distinguish between \u201ccase\u201d and \u201ccontrol\u201d labels, which correspond to \u201cpositive\u201d and \u201cnegative\u201d outcomes, respectively, in the context of ADRD. The definition of ADRD cases (labeled as \u201cpositive\u201d) is established through a combined methodology involving the use of ICD-Ninth and -Tenth Revision (ICD-9/ICD-10) diagnosis codes along with the administration of specific anti-dementia medications, namely donepezil, galantamine, memantine, and rivastigmine. This classification approach is consistent with existing computable phenotypes documented in the literature, such as those found in references [34  ###reference_b34###, 66  ###reference_b66###], with the exception of aducanumab, which was excluded due to its recent FDA approval in 2021 and the temporal constraints of our dataset. Table 2  ###reference_### presents the two rule-based computable phenotypes (CPs) employed in this research. These CP algorithms were meticulously designed to accurately identify and categorize the various forms of ADRD, acknowledging the heterogeneity inherent in these conditions. Controls are defined as those without ADRD-related diagnoses or other conditions potentially associated with or causative of dementia (e.g., mild cognitive impairment, Parkinson\u2019s disease, and so on.), and who had not been prescribed dementia-related medications.\n###figure_1###"
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Constructing Control Set",
            "text": "Three steps are involved in constructing the control set based on the cases of each computable phenotype. The first step filters out samples whose birth date and encounter are far from those of cases (see red lines in Figure 1  ###reference_###). After that, we select samples with higher similarity scores to the cases. Finally, we split the previously obtained dataset into three different prediction window cases for each CP (see blue lines in Figure 1  ###reference_###).\nSelect similar birth date and encounter statistics. \nIn the first step, we select patients with similar birth dates and encounter statistics. More precisely, we choose patients from the entire control set (i.e., not cases) who were born within one year before or after the case, and who have a history of visiting the hospital within six months following the case diagnosis date (which will be called \u201cindex date\u201d). As described in red lines of Figure 1  ###reference_###, the birth date of the control lies within one year and also includes encounters within six months of the related case.\nSimilar sample mining based on the propensity score. \nAs the second step, we select 10 controls for each case by utilizing propensity scores, thereby constructing a data category ratio that simulates real-world scenarios. We adhere to the following steps to select the controls based on the propensity score: (1) The comorbidity score is measured using ICD codes [34  ###reference_b34###]. (2) Subsequently, the propensity score is computed using LR [4  ###reference_b4###]. (3) We then construct a distance matrix between the propensity scores of case and controls. (4) Finally, we find the optimal matching using the Hungarian algorithm over the distance matrix generated in the third step. Note that after this sample mining process, we have control and cases with statistics of Prediction Window 0 (PW0) in Table 3  ###reference_###. Other cases (PW1, PW3) are described in the next paragraph, explaining how we subsample the PW0 case.\nTimeline of case and control. \nTo conduct risk prediction of ADRD, we define the prediction window. We identify the first ADRD-related diagnosis or medication prescription date for cases, i.e., positive, termed the \u201cindex date.\u201d The corresponding controls, i.e., negatives, which are selected from the second step, regard the encounter dates within six months after the \u201cindex date\u201d of the case as the \u201cindex date\u201d for them. The timeline prior to the index date is divided into a prediction window (in {0, 1, 3} years before the index date) and an observation period (from the first database encounter to the start of the prediction window, see yellow lines in Figure 1  ###reference_###). Predictive analyses utilized data solely from the observation period to explore the feasibility of ADRD prediction at various lead times, with a minimum one-year observation period required for inclusion."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "Additional Processing",
            "text": "Outlier handling. \nSince real-world datasets usually contain missing values or human-error-induced incorrect values, we employ the -sigma rule [48  ###reference_b48###] as a systematic method for outlier detection. By applying this criterion, we can identify extreme values that might lead to misleading predictions. We then set these outliers directly to NaN, in preparation for imputation. Given the inevitable presence of missing values in the dataset, especially within laboratory results and vital signs, we suggest imputing them using the median value of each feature from the training data. This method is robust to outliers and preserves the central tendency of the data distribution, making it appropriate for medical scenarios.\nDecoding features to reduce sparsity. \nTo address the challenge of processing sparsely encoded values such as ICD codes in our dataset, we implement a decoding strategy that enhances accessibility following previous work [34  ###reference_b34###]. Specifically, the 18,922 unique ICD-9/10 codes are converted into 1,712 Phenotype codes, such as transforming J18.9 (Pneumonia, unspecified organism) into 480 (Pneumonia). Similarly, we simplify  RxNorm medication codes to  ingredient codes and  CPT codes to  Clinical Classification Software codes, significantly reducing data sparsity. It is important to note that the preprocessed dataset is in table format. For each patient group, defined by their computable phenotype and prediction window, we exclude any laboratory tests with more than 50% missing data and applied one-hot encoding to binary features. We then create a feature vector for each patient, which consists of continuous laboratory tests and vital signs data, combined with one-hot encoded vectors for PheCodes, RxNorm ingredient codes, and CCS codes. Despite the above efforts, the resulting feature vectors are still relatively sparse."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Preliminary and Motivation",
            "text": "In this section, we present the motivation behind our proposed method, highlighting the intuitive pros and cons of SLs and LLMs in the analysis of EHRs. We then offer empirical evidence to validate our insights and illustrate the potential of augmenting risk prediction with LLMs using in-context learning (ICL). Before describing our motivation, we briefly summarize how ICL works.\nBased on the insights above, we describe our proposed algorithm for predicting ADRD risk, which fuses the advantages of LLMs and SLs. Our approach is tailored such that LLMs target hard samples, utilizing their advanced reasoning capabilities, while SLs efficiently predict easy samples by capitalizing on patterns learned during training. We present the proposed method below, with a brief illustration provided in Figure 2  ###reference_###.\nWe categorize related research of this work into the following categories: (1) the use of machine learning for handling ADRD, (2) large language models, (3) In-context learning, and (4) large language models for clinical tasks.\nIn this paper, we address the challenge of early ADRD prediction using cost-effective EHR databases. We introduce a novel collaborative approach that combines the predictive power of conventional supervised learning techniques, such as LR, XGB, and MLP, with the advanced reasoning capabilities of LLMs. By integrating a confidence-driven selection process, our method dynamically chooses between the robust, data-driven predictions from SLs and the nuanced, context-aware interpretations by LLMs. This is based on their confidence levels, harnessing the strengths of SLs in clear-cut cases and LLMs in more complex scenarios. The extensive validation of our method with a real-world dataset from OHSU hospital demonstrates the superiority of ADRD risk prediction. Furthermore, our findings reveal that neither scaling up the model size nor specific fine-tuning on medical datasets consistently enhances performance, indicating the need for further investigation into these aspects in practice.\nThis material is based in part upon work supported by the National Science Foundation under Grant\nIIS-2212174, IIS-1749940, IIS-1750326, Office of Naval Research N00014-24-1-2168, National Institute of General Medical Sciences R01GM134307, R01GM145700, and\nNational Institute on Aging (NIA) RF1AG072449, R01AG080624, R01AG076448, RF1AG084178, R01AG076234, R01AG080991."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Preliminary of ICL",
            "text": "Suppose that we have the training dataset  where input text is  and its corresponding output text is . For any test query 333In this study,  refers to tabular data or text generated from tabular data. This simplification facilitates the processing of the same data  by both SLs and LLMs., we get LLM\u2019s response  using the following ICL paradigm:\nand  is the selected samples for  from the training dataset and  denotes the concatenation operation. To construct the , there are several approaches, such as a term-frequency-based approach or utilizing neural networks to select the informatively relevant samples. Here, ICL is a way of achieving better inference using LLMs by feeding relevant examples to the model so that these examples serve as hints for understanding the context. From these relevant examples provided, LLMs are expected to make better reasoning in answering the question. It is one of the most cost-efficient methods for adapting to the target task since we can make LLMs adapt to our context without fine-tuning."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Pros and Cons of SLs and LLMs using ICL",
            "text": "To create a synergistic combination of SLs and LLMs, we describe the pros and cons of each SL and ICL hereinafter.\nPros and cons of SLs. \nThe traditional SLs, such as LR, XGB, and MLP, are notable primarily for their strong learning capability to extract common patterns from data. For example, MLP trains the model parameters to extract meaningful features among various input features by iteratively feeding and backpropagating the training dataset multiple times. As illustrated in \nTable 4  ###reference_###, SLs perform better than LLMs on easy (confident) samples\u2014those samples that closely align with the common patterns recognized during training. These samples are explicitly marked by their high levels of predictive confidence. Note that merging the knowledge of SLs (Average SLs) yields better F1 scores than when a single SL is used, demonstrating greater robustness.\nHowever, there are several challenges with SLs. One significant limitation is their difficulty in handling hard (unconfident) samples\u2014those with sparse or uncommon features compared to the training data. SLs tend to generate predictions with low confidence for these challenging cases. As illustrated in \nTable 5  ###reference_###, the inference quality on hard samples is notably poorer compared to that of LLMs. This issue arises because SLs struggle to extract valuable clues from samples that diverge significantly from common patterns.\nPros and cons of LLMs using ICL. \nOn the other hand, LLMs exhibit distinct characteristics over SLs. The main strength of LLMs is their strong pre-trained reasoning capability, which is extensively studied in the research field of ICL. Their reasoning power enables them to effectively manage hard (unconfident) samples, particularly when provided with appropriate ICL examples that supplement the hard samples with specific domain knowledge for better prediction. This superiority is evident in \nTable 5  ###reference_###, where LLMs using ICL demonstrate better performance in addressing hard samples compared to SLs.\nHowever, despite this easy adaptation to each test sample, there are various drawbacks to using LLMs with ICL. As described in \nTable 4  ###reference_###, it is difficult to capture the common patterns for prediction compared to using SLs, thus we get worse performance on easy (confident) samples. This is because ICL only uses a very small number of samples as context from the training dataset. Therefore, it is generally inappropriate to apply LLMs directly to infer each sample in our task, and it is better to use them in a smart manner.\nIntegrating SLs and LLMs for ADRD Risk Prediction. \nConsidering the advantages and disadvantages of SLs and LLMs, we are motivated to integrate the strengths of these two methodologies while mitigating their weaknesses for risk prediction. Our insights consist of two key characteristics: (1) When SL generates a confident prediction on a sample, we will use the SL prediction. These samples are typically not hard samples and have rich features, and therefore LLM is unlikely to generate good performance over SL here. (2) When SL generates a low-confident prediction, this suggests a hard sample and usually has low feature quality, and we will use LLMs w/ICL to augment the prediction. We expect that the LLMs can use their reasoning power to make improved predictions on these samples. Based on our intuition, we describe our method in section 4  ###reference_###.\n###figure_2### Natural Language Summarization of EHRs. \nThe EHR structured data is tabular (e.g.,  [75  ###reference_b75###]) but not natural language that is easily understandable by LLMs. For LLMs to consume the information in the structured data, we propose first summarizing the tabular data into natural language using LLMs\u2019 summarization capability. Specifically, for a given tabular representation of a patient, the goal is to summarize the information into a comprehensive representation in natural language. LLM is capable of such transformation, and yet there is a trade-off between the details to be included in the summary that is best for downstream in-context learning and risk prediction: While looking for an informative summary, LLM may suffer from hallucination for too excessive elaboration on the summary. We describe the LLM-based summarization of EHRs in Appendix A  ###reference_###.\nReliable subset sampling. \nThe next question is how to build  for each test sample. Existing studies (e.g., [7  ###reference_b7###, 36  ###reference_b36###]) suggest that the choice of ICL examples will significantly impact performance. Furthermore, the quality of ICL examples is also a key factor that affects ICL performance [64  ###reference_b64###, 35  ###reference_b35###]. In our framework, we first construct a reliable candidate set for quality ICL examples using SL signals, as we believe the predictability of an ICL example is directly related to the quality of the example. We set the criteria for reliable candidates as \u201cHigh Average Prediction Confidence,\u201d which means we select the samples from the training set whose average prediction probability, across all SLs, is above a predefined threshold, i.e.,\nwhere  is the set of SL methods, i.e., {LR, XGB, MLP} in our case,  is the -th sample in the training set,  is the corresponding ground-truth label, and  represents the predicted probability444See supplement for details on obtaining the predicted probability for training samples. by model . The threshold  serves as a level of confidence that determines whether a sample\u2019s prediction is reliable. The defined set  contains samples exceeding  in average prediction confidence, deemed robust and quality candidates from the training set for building .\nRetrieving score of EHRs for ICL. \nTo construct  for each test sample using reliable candidate set  , we measure the similarity between test sample  and candidate sample , where , based on two types of similarity scores. As the features in vital signs and lab tests have continuous values while the others are categorical features, we divide them into two cases and measure the similarity using Euclidean distance for continuous features, and Hamming distance for categorical features, respectively. Then, we measure the total similarity score  as follows:\nwhere  and  represent the Euclidean and Hamming distances between  and  using continuous and binary values, respectively. Moreover,  denotes the balancing hyperparameter between these two distance metrics. We select the top- similar samples for each  and assign the order of constructing  in an ascending manner, i.e.,  and  have the lowest and highest similarity scores among the top- samples, respectively, so that the model encounters the most relevant samples right before inference [74  ###reference_b74###].\nWe note that many approaches for patient similarity retrieval, such as [76  ###reference_b76###, 25  ###reference_b25###, 63  ###reference_b63###], have been developed in the past decade, and they can be naturally adopted in our proposed framework.\nA comparison of existing patient similarity approaches under our framework is important and will be conducted in future work.\nConfidence-driven selection. \nA crucial step in our approach involves routing a risk prediction case to either SLs or LLMs. We employ an average confidence score from SL methods as the primary selection criteria, which is defined as follows:\nwhere  is the test sample,  refers to any possible label in the current task, and  represents the prediction probability from the model A trained on the entire training set. According to the confidence score , we regard the sample as confidently predicted by SLs when the sample has greater than  confidence, i.e., .\nOtherwise, we regard it as an unconfident sample.\nSLs for confident samples. \nFor the samples which has higher confidence when we use SLs combination, it has to be answered by using SLs prediction itself based on our motivation and its empirical verification. Therefore, we get the answer  of the test sample  by using the following way:\nwhere . Note that  is the hyperparameter balancing the usages of SLs and LLMs. An increase in  will result in more use of LLMs, while a decrease in  will enhance the reliance on SLs.\nICL for unconfident samples. \nOn the other side, when the test samples cannot be confidently predicted by SLs, i.e., , we use ICL to predict them by leveraging the relevant information:\nwhere  is the concatenated input, and  represents the in-context examples obtained from the reliable candidate set . The information from  is often more useful than the main pattern from the full training set, as discussed in section 3  ###reference_###, which guides LLM to answer more accurately in low-confidence part.\nBased on the above components, we summarize our pipeline to the risk prediction in Algorithm 1  ###reference_###. The proposed algorithm is composed of two phases: preparation and inference. In the preparation phase, we first train the SLs using the entire training dataset  and get the prediction probability  of the test sample , then compute average confidence score using the signals from all SLs. In the inference phase, we first decide whether the test sample  is confidently answered by SLs or not. If it is confident, we directly use the prediction from SLs. Otherwise, we use the prediction from LLM via ICL. Finally, our system outputs the predicted answer .\nData Splitting. \nTo address potential biases and ensure consistency across various computable phenotypes (CP) and prediction windows (PW) intervals, we adopted a uniform random sampling approach, selecting 5500 samples for each CP_PW group, and maintaining the case-control ratio to be 1:10. This method guarantees that the size of the data remains constant across all groups, thereby ensuring that differences do not compromise the comparability of experimental outcomes. Then, we randomly select 80%, 20% of total samples to be training and testing sets respectively.\nSL Methods. \nIn our study, we compare our pipeline with three SLs commonly used for medical form data i.e., LR [26  ###reference_b26###], XGB [10  ###reference_b10###] and MLP [22  ###reference_b22###], which are also components in our proposed pipeline. These models serve as baselines for medical tabular data classification due to their scalability, and ability to handle complex relationships in features. We also introduce the Avg. SLs approach, which ensembles the above approaches and makes robust predictions as compared to a single model. To address the class imbalance problem in training SL models (see details in Table 3  ###reference_###), we integrated the Synthetic Minority Over-sampling Technique (SMOTE) [9  ###reference_b9###], ensuring a balanced class distribution for training. We use 5-fold cross-validation to obtain the optimal hyperparameters of each model, the grid search spaces are detailed in the supplement.\nLLM Configuration. \nIn our pipeline, we utilized LLaMA2 as the backbone language model, an open-source LLM developed by Meta and accessed through Hugging Face555https://huggingface.co/meta-llama  ###reference_huggingface.co/meta-llama###. Our approach involves employing two distinct versions of the LLaMA2, specifically the 7B model and 70B model, to cater to different aspects of our task. The 7B model is designated for generating patient summaries, whereas the more powerful 70B model is tasked with the complex process of final reasoning. Given the medical field requires more reliable outputs, we use the \u201cGreedy\u201d strategy for each output. Specifically, by setting \u201cnum_beams=1\u201d (i.e., the number of hypotheses to keep track of) and \u201cdo_sample=false,\u201d we prevent LLaMA2 from generating outputs other than the most probable one. This approach reduces diversity but enhances the reliability of the results, ensuring reproducibility. For ICL, we use  demonstrations unless noted otherwise. The parameter , set at , weights categorical features (like diagnosis and medication) more heavily than continuous features (such as vital signs) in our demonstration retrieval process.\nTo evaluate the performance of our pipeline, we conducted experiments on the processed OHSU dataset and compared the testing performance with those obtained by using SLs and LLM independently. We focus on the OHSU data for six different combinations of computable phenotypes (CP1, CP2) and prediction windows (PW0, PW1, PW3), see Table 2  ###reference_### for definitions. The confidence threshold  in our pipeline is set to 0.6, i.e., if the prediction probability produced by Avg. SLs is greater than 0.6, then we use the predicted label of Avg. SLs. Otherwise, we will take the prediction of ICL, which uses demonstrations from the reliable set .\nWe repeat the experiment 5 times and report the mean with standard deviation in precision, recall, and F1 score, by Table 6  ###reference_###. We mainly focus on the F1 score, which is the most important metric in classification tasks with label imbalance problems. From Table 6  ###reference_###, we can see our pipeline shows superiority in F1 score among almost all cases, which shows the effectiveness of our proposed pipeline, combining the strength of traditional SLs and LLMs in risk prediction. Our pipeline is capable of managing imbalanced data to ensure robust and accurate predictions. For the baselines, XGB, however, shows consistently good performance in terms of precision, while low performance in recall, suggesting that it tends to predict more negatives. LR\u2019s lower precision and higher recall indicate a tendency to answer positives, leading to many misdiagnoses. Avg. SLs achieves a balance among different SL models. LLaMA2 70B model performs the worst in all cases, which shows that it is difficult to capture the common pattern by relying on just ICL.\nNote that the overall poor performance, with F1 scores below 0.4, may be attributed to inherent challenges in the ADRD risk prediction task. In the OHSU dataset, crucial factors like demographics and clinical notes, which could significantly enhance predictive accuracy, are not available. From the perspective of different CPs, the models\u2019 performance for CP2 is better than for CP1 in most cases. This is probably because the patients grouped by CP2 have many ADRD-related characteristics that lead them to be diagnosed with multiple ADRDs.\nTo better understand the proposed pipeline, we conduct some ablation studies: (1) assessing the influence of LLM-based summarization, (2) investigating the consequences of randomly selecting demonstrations in ICL, (3) exploring the different denoising strategies in ICL, (4) hyperparameter sensitivity, i.e., studying on different confidence thresholds in the proposed pipeline, (5) the impact of different types of LLMs, i.e., analyzing the impact of model size and medical data fine-tuning on predicting performance.\nEffect of LLM-based Summarization. \nIn our study, to make predictions based on the LLM, we have to reformulate the tabular data into text. We proposed to use LLM for patient data summarization, and the summarized text will, to some extent, reflect the characteristics of the LLM\u2019s pre-trained knowledge, as the model\u2019s behavior and output are based on the data distributions and patterns it learned during the training phase. So, we expect that the generated text will be LLM-friendly, which would be useful for subsequent tasks. To confirm the effect of such LLM-generated text, we conduct experiments to compare the use of concatenated sentence only (w/o Summary) and LLM-based summarization in our case (w/ Summary) on CP1_PW0 and CP2_PW0 datasets. Here, we set the number  of ICL examples to be 6 because the length of the concatenated sentence is too long and will exceed the input token limit of LLaMA2 if . The experiment result in Table 7  ###reference_### shows that the pipeline w/ Summary has better performance, as the f1 score is much higher, which indicates the effectiveness of LLM-based summarization.\nSee supplement for examples of concatenated sentences and LLM-generated summaries.\nSimilarity-based Demonstration Retrieval in ICL. \nIn our study, we select the in-context examples based on the similarity between the test sample and the reliable candidate sample. The context samples, which are similar to the test sample, are expected to help LLM learn more about the background to make decisions. To evaluate the effect of such a similarity-based retrieval strategy, we conduct experiments on CP1_PW0 and CP2_PW0 datasets using two types of ICL sample selection strategy: random selection (w/o Sim-Selection) and similarity-based sample selection (w/ Sim-Selection). Both strategies selected samples from the reliable candidate set .  Table 8  ###reference_### shows that employing a similarity-based sample selection strategy enhances performance across all metrics, suggesting that providing contextually similar examples yields more accurate responses. In contrast, random selection tends to produce a higher proportion of negative answers, reflecting the inherent label imbalance where a predominance of negative ICL examples results in more negative predictions.\nStudy on Different Denoising Strategies in ICL. \nIn our pipeline, we build the reliable candidate set  for ICL by using signals from conventional SLs, specifically, LR, XGB, and MLP. We hypothesize that those samples that exhibit high prediction confidence across all SLs are high-quality samples, otherwise, they are considered as noise samples. Such a denoising process is expected to boost ICL performance. We test our hypothesis using the CP1_PW0 and CP2_PW0 datasets, comparing four strategies for constructing ICL candidate sets. We avoid confidence-driven predictions in our pipeline to better observe performance differences among ICL strategies. The full training set refers to using the complete training set as the candidate. The all-correct subset comprises samples that all SLs successfully predict. The any-correct subset includes any samples that at least one SL successfully predicts. The high confidence subset, which is the strategy employed in this paper, considers the average confidence levels of predictions across different SLs. According to the results in Table 9  ###reference_###, all three denoising strategies significantly enhanced the performance of ICL, with the High Confidence Subset achieving the best results.\n###figure_3### ###figure_4### ###figure_5### ###figure_6### ###figure_7### ###figure_8### Analysis of Different Confidence Thresholds. \nOur pipeline integrates SLs and LLMs for risk prediction through a confidence-driven mechanism. If the prediction probability of Avg. SLs falls below the confidence threshold , the prediction will be generated by the LLM. To investigate the performance at different confidence thresholds, we conduct experiments on CP{1,2}_PW{0,1,3} data using six thresholds {0.5, 0.6, 0.7, 0.8, 0.9, 1.0}. According to the results in Figure 3  ###reference_###, we can see that the performance is better with a concave form through confidence threshold, i.e., SLs an LLMs balance is necessary. This is consistent with our discussion in section 3  ###reference_###. In other words, LLMs do not outperform SLs on all samples, but confident samples still rely on SLs that capture common patterns via training on extensive data, and unconfident samples are better handled by using LLMs.\n###figure_9### The Impact of Model Size and Medical Data Fine-tuning. \nIn our approach, we employed the LLaMA2 70B model for inference. To understand the effect of different model sizes on performance, we conducted a series of comparative experiments with various sizes of LLMs. In addition to the pre-trained LLaMA2 models, we also compared models that were fine-tuned on diverse medical datasets to assess their efficacy on our ADRD prediction task. See the supplement for details about the medical data fine-tuned models used in our experiment. The results in Figure 4  ###reference_### indicate that medical data fine-tuning does not necessarily enhance performance for the target task. The effectiveness depends on the similarity between the domain of the data used for fine-tuning and the target data domain. For example, the Asclepius-7b model, which performed the best, utilized a fine-tuning dataset containing a large number of QA pairs related to ADRD. This dataset closely aligns with our target task, which likely contributed to the model\u2019s superior performance. Furthermore, our findings challenge the common wisdom from scaling laws that larger models are inherently better; we observed that smaller models can achieve superior performance under certain conditions. This highlights the need for a nuanced understanding of the interaction between model size and domain-specific fine-tuning within the context of task-specific applications.\nTo detect ADRD, [34  ###reference_b34###] employed logistic regression and a gradient boost algorithm using a real-world dataset obtained from the OneFlorida+ Research Consortium. In [47  ###reference_b47###], the use of logistic regression, support vector machines, and random forest methods was explored. The authors of [45  ###reference_b45###] utilized the LASSO algorithm, and [46  ###reference_b46###] proposed an algorithm named ZCoR, which assesses the future risk of AD. Differing from the aforementioned studies, which primarily focused on ADRD, the following papers targeted AD more directly [32  ###reference_b32###]. The authors of [40  ###reference_b40###] employed MRI images to detect AD. In [2  ###reference_b2###], the authors utilized EEG signals to detect AD using support vector machines. Several studies have attempted to classify AD using a range of methods, including random forest and linear models [31  ###reference_b31###]. K-nearest neighbors (KNN) classifier [5  ###reference_b5###], support vector machine (SVM) [16  ###reference_b16###], multi-layer perceptron (MLP) [41  ###reference_b41###], Cuckoo Search [14  ###reference_b14###], and traditional machine learning techniques [51  ###reference_b51###, 27  ###reference_b27###].\nLanguage models with billions of parameters are commonly referred to as LLMs. The emergence of LLMs began with BERT [13  ###reference_b13###], marking the start of the LLM era. GPT-3 [8  ###reference_b8###] has demonstrated a significant impact on real-world applications due to its versatility. Following GPT-3, GPT-4 [1  ###reference_b1###] has been developed with improved performance, surpassing human capabilities in some tasks. Very recently, Gemini [58  ###reference_b58###] was announced; however, most models still feature gray-box or black-box architectures, which do not allow access to their model parameters. They only allow to access at most their output probability. To tackle this, Meta release LLaMAv1/v2 [61  ###reference_b61###, 62  ###reference_b62###] which are publicly accessible models for research objectives with various model parameter cases, such as 7B, 13B, and 70B.\nIn-Context Learning is a promising method to make the model answer based on few-shot samples, which dramatically reduces the fine-tuning cost to the target task [15  ###reference_b15###]. The conventional ICL sample selection method randomly selects samples and demonstrates performance improvement [7  ###reference_b7###]. To further enhance performance, several works have attempted to select relevant samples using BM25 [50  ###reference_b50###], and language model-oriented embeddings [49  ###reference_b49###, 30  ###reference_b30###].\nLLMs possess strong capability in performing various tasks, including those in the medical field [23  ###reference_b23###]. In particular, many studies have attempted to develop new LLMs specifically for medical tasks. For example, Med-PaLM [55  ###reference_b55###] represents a medical domain-specific variant of the PaLM model. Similarly, based on Alpaca [57  ###reference_b57###], MedAlpaca [21  ###reference_b21###] was proposed, and fine-tuend LLaMA [61  ###reference_b61###, 62  ###reference_b62###] for medical domain, PMC-LLaMA [67  ###reference_b67###] was suggested. Chat-bot oriented model [70  ###reference_b70###] and Huatuo-GPT [71  ###reference_b71###] were trained using the dataset obtained from the real-world doctors and ChatGPT [1  ###reference_b1###]. Yang et al. [69  ###reference_b69###] trained and release the GatorTron model. Different from proposing a new medical-specific models, several works have aimed to directly use the pre-trained LLMs in a zero-shot manner. For example in [42  ###reference_b42###, 38  ###reference_b38###] used GPT models for the medical field. Nori et al. [43  ###reference_b43###] proposed a way of leveraging pre-trained LLMs for the medical field by leveraging some techniques including in-context learning, and chain-of-thought.\n-Supplementary Material-\n\nAugmented Risk Prediction for the Onset of Alzheimer\u2019s Disease from Electronic Health Records with Large Language Models\nInitially, we transform the tabular data of  sample (red table in Figure S1  ###reference_###) into concatenated sentences  (yellow box in Figure S1  ###reference_###) using following template:\nFormat template\nThe patient\u2019s {}: , {}: , . Diagnoses: [ICD]. Medications: [RxNorm]. Orders: [CPT].\n \nOutput: \n\nHere, {} is used to denote the description of features. For example, if  is the feature value of Age, then {} would correspond to the term \u201cage.\u201d The operator [] denotes the concatenation of descriptions of active features within categories such as Diagnoses, Medications, and Orders. For example, consider a patient identified as AAA who has  and \u2014indicating the presence of the respective conditions\u2014for features  and , corresponding to Essential hypertension and Diabetes Type 2. In this case, the concatenated feature description [ICD] would be \u201cEssential hypertension, Type 2 diabetes,\u201d representing the active health conditions of the patient as specified by their respective feature indicators.\nAfter obtaining the concatenated sentences from the raw tabular data using a format template, we summarized them using the LLM, i.e.,\nwhere the guideline prompt  is defined as follows:\nLLM\u2019s prompt\nYou are an expert medical professional. Please summarize the patient\u2019s medical record in one paragraph. \nRecord:  \nSummary:  \n \nOutput: \n\nIn this prompt, the input  represents the concatenated sentence for  patient as mentioned in section A.1  ###reference_###, the ouput  is the patient\u2019s summary given by the LLM. In the blue box of Figure S1  ###reference_###, we present an example of the summarized sentence, which is more concise and free from the excessive numbers that LLMs typically struggle with [20  ###reference_b20###]. In our use of the LLaMA2 7B model for EHR summarization, we observed that the \u201crepetition_penalty\u201d parameter significantly affects the quality of the summaries produced. When set too low (), the summaries tend to omit explanations of certain medical terms. Conversely, when set too high (), the summaries occasionally generate fictitious content, or what could be described as hallucinations. We recommend using a \u201crepetition_penalty\u201d setting of either  or .\nWe employ a unified framework for training different SLs, including LR, XGB, and MLP, which are served as baseline classifiers in our experiment. These models are selected for their scalability and their ability to manage different type of feature relationships (from linear to non-linear) in medical tabular data. Each model is tuned using a 5-fold cross-validation approach, facilitated by the StratifiedKFold from scikit-learn, configured with n_splits=5, shuffle=True, and random_state=42. This step ensures that the optimal hyperparameters obtained through cross-validation reflect the overall preferences of the dataset.\nWe conduct hyperparameter tuning using GridSearchCV for LR and MLP, and RandomizedSearchCV for XGB, aiming to optimize the F1 score. The specific hyperparameter grids for each model are as follows:\nLogistic Regression (LR).\nXGBoost (XGB).\nMulti-layer Perceptron (MLP)."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Confidence-Driven Prediction",
            "text": "Confidence-driven selection. \nA crucial step in our approach involves routing a risk prediction case to either SLs or LLMs. We employ an average confidence score from SL methods as the primary selection criteria, which is defined as follows:\nwhere  is the test sample,  refers to any possible label in the current task, and  represents the prediction probability from the model A trained on the entire training set. According to the confidence score , we regard the sample as confidently predicted by SLs when the sample has greater than  confidence, i.e., .\nOtherwise, we regard it as an unconfident sample.\nSLs for confident samples. \nFor the samples which has higher confidence when we use SLs combination, it has to be answered by using SLs prediction itself based on our motivation and its empirical verification. Therefore, we get the answer  of the test sample  by using the following way:\nwhere . Note that  is the hyperparameter balancing the usages of SLs and LLMs. An increase in  will result in more use of LLMs, while a decrease in  will enhance the reliance on SLs.\nICL for unconfident samples. \nOn the other side, when the test samples cannot be confidently predicted by SLs, i.e., , we use ICL to predict them by leveraging the relevant information:\nwhere  is the concatenated input, and  represents the in-context examples obtained from the reliable candidate set . The information from  is often more useful than the main pattern from the full training set, as discussed in section 3  ###reference_###  ###reference_###, which guides LLM to answer more accurately in low-confidence part."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Risk Prediction combining SLs and LLMs",
            "text": "Based on the above components, we summarize our pipeline to the risk prediction in Algorithm 1  ###reference_###  ###reference_###. The proposed algorithm is composed of two phases: preparation and inference. In the preparation phase, we first train the SLs using the entire training dataset  and get the prediction probability  of the test sample , then compute average confidence score using the signals from all SLs. In the inference phase, we first decide whether the test sample  is confidently answered by SLs or not. If it is confident, we directly use the prediction from SLs. Otherwise, we use the prediction from LLM via ICL. Finally, our system outputs the predicted answer ."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "Experimental Setting",
            "text": "Data Splitting. \nTo address potential biases and ensure consistency across various computable phenotypes (CP) and prediction windows (PW) intervals, we adopted a uniform random sampling approach, selecting 5500 samples for each CP_PW group, and maintaining the case-control ratio to be 1:10. This method guarantees that the size of the data remains constant across all groups, thereby ensuring that differences do not compromise the comparability of experimental outcomes. Then, we randomly select 80%, 20% of total samples to be training and testing sets respectively.\nSL Methods. \nIn our study, we compare our pipeline with three SLs commonly used for medical form data i.e., LR [26  ###reference_b26###  ###reference_b26###], XGB [10  ###reference_b10###  ###reference_b10###] and MLP [22  ###reference_b22###  ###reference_b22###], which are also components in our proposed pipeline. These models serve as baselines for medical tabular data classification due to their scalability, and ability to handle complex relationships in features. We also introduce the Avg. SLs approach, which ensembles the above approaches and makes robust predictions as compared to a single model. To address the class imbalance problem in training SL models (see details in Table 3  ###reference_###  ###reference_###), we integrated the Synthetic Minority Over-sampling Technique (SMOTE) [9  ###reference_b9###  ###reference_b9###], ensuring a balanced class distribution for training. We use 5-fold cross-validation to obtain the optimal hyperparameters of each model, the grid search spaces are detailed in the supplement.\nLLM Configuration. \nIn our pipeline, we utilized LLaMA2 as the backbone language model, an open-source LLM developed by Meta and accessed through Hugging Face555https://huggingface.co/meta-llama  ###reference_huggingface.co/meta-llama###  ###reference_huggingface.co/meta-llama###. Our approach involves employing two distinct versions of the LLaMA2, specifically the 7B model and 70B model, to cater to different aspects of our task. The 7B model is designated for generating patient summaries, whereas the more powerful 70B model is tasked with the complex process of final reasoning. Given the medical field requires more reliable outputs, we use the \u201cGreedy\u201d strategy for each output. Specifically, by setting \u201cnum_beams=1\u201d (i.e., the number of hypotheses to keep track of) and \u201cdo_sample=false,\u201d we prevent LLaMA2 from generating outputs other than the most probable one. This approach reduces diversity but enhances the reliability of the results, ensuring reproducibility. For ICL, we use  demonstrations unless noted otherwise. The parameter , set at , weights categorical features (like diagnosis and medication) more heavily than continuous features (such as vital signs) in our demonstration retrieval process."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "Main Result",
            "text": "To evaluate the performance of our pipeline, we conducted experiments on the processed OHSU dataset and compared the testing performance with those obtained by using SLs and LLM independently. We focus on the OHSU data for six different combinations of computable phenotypes (CP1, CP2) and prediction windows (PW0, PW1, PW3), see Table 2  ###reference_###  ###reference_### for definitions. The confidence threshold  in our pipeline is set to 0.6, i.e., if the prediction probability produced by Avg. SLs is greater than 0.6, then we use the predicted label of Avg. SLs. Otherwise, we will take the prediction of ICL, which uses demonstrations from the reliable set .\nWe repeat the experiment 5 times and report the mean with standard deviation in precision, recall, and F1 score, by Table 6  ###reference_###  ###reference_###. We mainly focus on the F1 score, which is the most important metric in classification tasks with label imbalance problems. From Table 6  ###reference_###  ###reference_###, we can see our pipeline shows superiority in F1 score among almost all cases, which shows the effectiveness of our proposed pipeline, combining the strength of traditional SLs and LLMs in risk prediction. Our pipeline is capable of managing imbalanced data to ensure robust and accurate predictions. For the baselines, XGB, however, shows consistently good performance in terms of precision, while low performance in recall, suggesting that it tends to predict more negatives. LR\u2019s lower precision and higher recall indicate a tendency to answer positives, leading to many misdiagnoses. Avg. SLs achieves a balance among different SL models. LLaMA2 70B model performs the worst in all cases, which shows that it is difficult to capture the common pattern by relying on just ICL.\nNote that the overall poor performance, with F1 scores below 0.4, may be attributed to inherent challenges in the ADRD risk prediction task. In the OHSU dataset, crucial factors like demographics and clinical notes, which could significantly enhance predictive accuracy, are not available. From the perspective of different CPs, the models\u2019 performance for CP2 is better than for CP1 in most cases. This is probably because the patients grouped by CP2 have many ADRD-related characteristics that lead them to be diagnosed with multiple ADRDs."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "Empirical Analysis",
            "text": "To better understand the proposed pipeline, we conduct some ablation studies: (1) assessing the influence of LLM-based summarization, (2) investigating the consequences of randomly selecting demonstrations in ICL, (3) exploring the different denoising strategies in ICL, (4) hyperparameter sensitivity, i.e., studying on different confidence thresholds in the proposed pipeline, (5) the impact of different types of LLMs, i.e., analyzing the impact of model size and medical data fine-tuning on predicting performance.\nEffect of LLM-based Summarization. \nIn our study, to make predictions based on the LLM, we have to reformulate the tabular data into text. We proposed to use LLM for patient data summarization, and the summarized text will, to some extent, reflect the characteristics of the LLM\u2019s pre-trained knowledge, as the model\u2019s behavior and output are based on the data distributions and patterns it learned during the training phase. So, we expect that the generated text will be LLM-friendly, which would be useful for subsequent tasks. To confirm the effect of such LLM-generated text, we conduct experiments to compare the use of concatenated sentence only (w/o Summary) and LLM-based summarization in our case (w/ Summary) on CP1_PW0 and CP2_PW0 datasets. Here, we set the number  of ICL examples to be 6 because the length of the concatenated sentence is too long and will exceed the input token limit of LLaMA2 if . The experiment result in Table 7  ###reference_###  ###reference_### shows that the pipeline w/ Summary has better performance, as the f1 score is much higher, which indicates the effectiveness of LLM-based summarization.\nSee supplement for examples of concatenated sentences and LLM-generated summaries.\nSimilarity-based Demonstration Retrieval in ICL. \nIn our study, we select the in-context examples based on the similarity between the test sample and the reliable candidate sample. The context samples, which are similar to the test sample, are expected to help LLM learn more about the background to make decisions. To evaluate the effect of such a similarity-based retrieval strategy, we conduct experiments on CP1_PW0 and CP2_PW0 datasets using two types of ICL sample selection strategy: random selection (w/o Sim-Selection) and similarity-based sample selection (w/ Sim-Selection). Both strategies selected samples from the reliable candidate set .  Table 8  ###reference_###  ###reference_### shows that employing a similarity-based sample selection strategy enhances performance across all metrics, suggesting that providing contextually similar examples yields more accurate responses. In contrast, random selection tends to produce a higher proportion of negative answers, reflecting the inherent label imbalance where a predominance of negative ICL examples results in more negative predictions.\nStudy on Different Denoising Strategies in ICL. \nIn our pipeline, we build the reliable candidate set  for ICL by using signals from conventional SLs, specifically, LR, XGB, and MLP. We hypothesize that those samples that exhibit high prediction confidence across all SLs are high-quality samples, otherwise, they are considered as noise samples. Such a denoising process is expected to boost ICL performance. We test our hypothesis using the CP1_PW0 and CP2_PW0 datasets, comparing four strategies for constructing ICL candidate sets. We avoid confidence-driven predictions in our pipeline to better observe performance differences among ICL strategies. The full training set refers to using the complete training set as the candidate. The all-correct subset comprises samples that all SLs successfully predict. The any-correct subset includes any samples that at least one SL successfully predicts. The high confidence subset, which is the strategy employed in this paper, considers the average confidence levels of predictions across different SLs. According to the results in Table 9  ###reference_###  ###reference_###, all three denoising strategies significantly enhanced the performance of ICL, with the High Confidence Subset achieving the best results.\n###figure_10### ###figure_11### ###figure_12### ###figure_13### ###figure_14### ###figure_15### Analysis of Different Confidence Thresholds. \nOur pipeline integrates SLs and LLMs for risk prediction through a confidence-driven mechanism. If the prediction probability of Avg. SLs falls below the confidence threshold , the prediction will be generated by the LLM. To investigate the performance at different confidence thresholds, we conduct experiments on CP{1,2}_PW{0,1,3} data using six thresholds {0.5, 0.6, 0.7, 0.8, 0.9, 1.0}. According to the results in Figure 3  ###reference_###  ###reference_###, we can see that the performance is better with a concave form through confidence threshold, i.e., SLs an LLMs balance is necessary. This is consistent with our discussion in section 3  ###reference_###  ###reference_###. In other words, LLMs do not outperform SLs on all samples, but confident samples still rely on SLs that capture common patterns via training on extensive data, and unconfident samples are better handled by using LLMs.\n###figure_16### The Impact of Model Size and Medical Data Fine-tuning. \nIn our approach, we employed the LLaMA2 70B model for inference. To understand the effect of different model sizes on performance, we conducted a series of comparative experiments with various sizes of LLMs. In addition to the pre-trained LLaMA2 models, we also compared models that were fine-tuned on diverse medical datasets to assess their efficacy on our ADRD prediction task. See the supplement for details about the medical data fine-tuned models used in our experiment. The results in Figure 4  ###reference_###  ###reference_### indicate that medical data fine-tuning does not necessarily enhance performance for the target task. The effectiveness depends on the similarity between the domain of the data used for fine-tuning and the target data domain. For example, the Asclepius-7b model, which performed the best, utilized a fine-tuning dataset containing a large number of QA pairs related to ADRD. This dataset closely aligns with our target task, which likely contributed to the model\u2019s superior performance. Furthermore, our findings challenge the common wisdom from scaling laws that larger models are inherently better; we observed that smaller models can achieve superior performance under certain conditions. This highlights the need for a nuanced understanding of the interaction between model size and domain-specific fine-tuning within the context of task-specific applications."
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "ML with ADRD",
            "text": "To detect ADRD, [34  ###reference_b34###  ###reference_b34###] employed logistic regression and a gradient boost algorithm using a real-world dataset obtained from the OneFlorida+ Research Consortium. In [47  ###reference_b47###  ###reference_b47###], the use of logistic regression, support vector machines, and random forest methods was explored. The authors of [45  ###reference_b45###  ###reference_b45###] utilized the LASSO algorithm, and [46  ###reference_b46###  ###reference_b46###] proposed an algorithm named ZCoR, which assesses the future risk of AD. Differing from the aforementioned studies, which primarily focused on ADRD, the following papers targeted AD more directly [32  ###reference_b32###  ###reference_b32###]. The authors of [40  ###reference_b40###  ###reference_b40###] employed MRI images to detect AD. In [2  ###reference_b2###  ###reference_b2###], the authors utilized EEG signals to detect AD using support vector machines. Several studies have attempted to classify AD using a range of methods, including random forest and linear models [31  ###reference_b31###  ###reference_b31###]. K-nearest neighbors (KNN) classifier [5  ###reference_b5###  ###reference_b5###], support vector machine (SVM) [16  ###reference_b16###  ###reference_b16###], multi-layer perceptron (MLP) [41  ###reference_b41###  ###reference_b41###], Cuckoo Search [14  ###reference_b14###  ###reference_b14###], and traditional machine learning techniques [51  ###reference_b51###  ###reference_b51###, 27  ###reference_b27###  ###reference_b27###]."
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "Large Language Models",
            "text": "Language models with billions of parameters are commonly referred to as LLMs. The emergence of LLMs began with BERT [13  ###reference_b13###  ###reference_b13###], marking the start of the LLM era. GPT-3 [8  ###reference_b8###  ###reference_b8###] has demonstrated a significant impact on real-world applications due to its versatility. Following GPT-3, GPT-4 [1  ###reference_b1###  ###reference_b1###] has been developed with improved performance, surpassing human capabilities in some tasks. Very recently, Gemini [58  ###reference_b58###  ###reference_b58###] was announced; however, most models still feature gray-box or black-box architectures, which do not allow access to their model parameters. They only allow to access at most their output probability. To tackle this, Meta release LLaMAv1/v2 [61  ###reference_b61###  ###reference_b61###, 62  ###reference_b62###  ###reference_b62###] which are publicly accessible models for research objectives with various model parameter cases, such as 7B, 13B, and 70B."
        },
        {
            "section_id": "6.3",
            "parent_section_id": "6",
            "section_name": "In-Context Learning",
            "text": "In-Context Learning is a promising method to make the model answer based on few-shot samples, which dramatically reduces the fine-tuning cost to the target task [15  ###reference_b15###  ###reference_b15###]. The conventional ICL sample selection method randomly selects samples and demonstrates performance improvement [7  ###reference_b7###  ###reference_b7###]. To further enhance performance, several works have attempted to select relevant samples using BM25 [50  ###reference_b50###  ###reference_b50###], and language model-oriented embeddings [49  ###reference_b49###  ###reference_b49###, 30  ###reference_b30###  ###reference_b30###]."
        },
        {
            "section_id": "6.4",
            "parent_section_id": "6",
            "section_name": "LLMs for Clinical Domain",
            "text": "LLMs possess strong capability in performing various tasks, including those in the medical field [23  ###reference_b23###  ###reference_b23###]. In particular, many studies have attempted to develop new LLMs specifically for medical tasks. For example, Med-PaLM [55  ###reference_b55###  ###reference_b55###] represents a medical domain-specific variant of the PaLM model. Similarly, based on Alpaca [57  ###reference_b57###  ###reference_b57###], MedAlpaca [21  ###reference_b21###  ###reference_b21###] was proposed, and fine-tuend LLaMA [61  ###reference_b61###  ###reference_b61###, 62  ###reference_b62###  ###reference_b62###] for medical domain, PMC-LLaMA [67  ###reference_b67###  ###reference_b67###] was suggested. Chat-bot oriented model [70  ###reference_b70###  ###reference_b70###] and Huatuo-GPT [71  ###reference_b71###  ###reference_b71###] were trained using the dataset obtained from the real-world doctors and ChatGPT [1  ###reference_b1###  ###reference_b1###]. Yang et al. [69  ###reference_b69###  ###reference_b69###] trained and release the GatorTron model. Different from proposing a new medical-specific models, several works have aimed to directly use the pre-trained LLMs in a zero-shot manner. For example in [42  ###reference_b42###  ###reference_b42###, 38  ###reference_b38###  ###reference_b38###] used GPT models for the medical field. Nori et al. [43  ###reference_b43###  ###reference_b43###] proposed a way of leveraging pre-trained LLMs for the medical field by leveraging some techniques including in-context learning, and chain-of-thought."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Model Training and Validation",
            "text": "We employ a unified framework for training different SLs, including LR, XGB, and MLP, which are served as baseline classifiers in our experiment. These models are selected for their scalability and their ability to manage different type of feature relationships (from linear to non-linear) in medical tabular data. Each model is tuned using a 5-fold cross-validation approach, facilitated by the StratifiedKFold from scikit-learn, configured with n_splits=5, shuffle=True, and random_state=42. This step ensures that the optimal hyperparameters obtained through cross-validation reflect the overall preferences of the dataset."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Hyperparameter Tuning",
            "text": "We conduct hyperparameter tuning using GridSearchCV for LR and MLP, and RandomizedSearchCV for XGB, aiming to optimize the F1 score. The specific hyperparameter grids for each model are as follows:\nLogistic Regression (LR).\nXGBoost (XGB).\nMulti-layer Perceptron (MLP)."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Method",
            "text": "Based on the insights above, we describe our proposed algorithm for predicting ADRD risk, which fuses the advantages of LLMs and SLs. Our approach is tailored such that LLMs target hard samples, utilizing their advanced reasoning capabilities, while SLs efficiently predict easy samples by capitalizing on patterns learned during training. We present the proposed method below, with a brief illustration provided in Figure 2  ###reference_###  ###reference_###."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Confidence-Driven Prediction",
            "text": "Confidence-driven selection. \nA crucial step in our approach involves routing a risk prediction case to either SLs or LLMs. We employ an average confidence score from SL methods as the primary selection criteria, which is defined as follows:\nwhere  is the test sample,  refers to any possible label in the current task, and  represents the prediction probability from the model A trained on the entire training set. According to the confidence score , we regard the sample as confidently predicted by SLs when the sample has greater than  confidence, i.e., .\nOtherwise, we regard it as an unconfident sample.\nSLs for confident samples. \nFor the samples which has higher confidence when we use SLs combination, it has to be answered by using SLs prediction itself based on our motivation and its empirical verification. Therefore, we get the answer  of the test sample  by using the following way:\nwhere . Note that  is the hyperparameter balancing the usages of SLs and LLMs. An increase in  will result in more use of LLMs, while a decrease in  will enhance the reliance on SLs.\nICL for unconfident samples. \nOn the other side, when the test samples cannot be confidently predicted by SLs, i.e., , we use ICL to predict them by leveraging the relevant information:\nwhere  is the concatenated input, and  represents the in-context examples obtained from the reliable candidate set . The information from  is often more useful than the main pattern from the full training set, as discussed in section 3  ###reference_###  ###reference_###  ###reference_###, which guides LLM to answer more accurately in low-confidence part."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Risk Prediction combining SLs and LLMs",
            "text": "Based on the above components, we summarize our pipeline to the risk prediction in Algorithm 1  ###reference_###  ###reference_###  ###reference_###. The proposed algorithm is composed of two phases: preparation and inference. In the preparation phase, we first train the SLs using the entire training dataset  and get the prediction probability  of the test sample , then compute average confidence score using the signals from all SLs. In the inference phase, we first decide whether the test sample  is confidently answered by SLs or not. If it is confident, we directly use the prediction from SLs. Otherwise, we use the prediction from LLM via ICL. Finally, our system outputs the predicted answer ."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Experiment",
            "text": ""
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "Experimental Setting",
            "text": "Data Splitting. \nTo address potential biases and ensure consistency across various computable phenotypes (CP) and prediction windows (PW) intervals, we adopted a uniform random sampling approach, selecting 5500 samples for each CP_PW group, and maintaining the case-control ratio to be 1:10. This method guarantees that the size of the data remains constant across all groups, thereby ensuring that differences do not compromise the comparability of experimental outcomes. Then, we randomly select 80%, 20% of total samples to be training and testing sets respectively.\nSL Methods. \nIn our study, we compare our pipeline with three SLs commonly used for medical form data i.e., LR [26  ###reference_b26###  ###reference_b26###  ###reference_b26###], XGB [10  ###reference_b10###  ###reference_b10###  ###reference_b10###] and MLP [22  ###reference_b22###  ###reference_b22###  ###reference_b22###], which are also components in our proposed pipeline. These models serve as baselines for medical tabular data classification due to their scalability, and ability to handle complex relationships in features. We also introduce the Avg. SLs approach, which ensembles the above approaches and makes robust predictions as compared to a single model. To address the class imbalance problem in training SL models (see details in Table 3  ###reference_###  ###reference_###  ###reference_###), we integrated the Synthetic Minority Over-sampling Technique (SMOTE) [9  ###reference_b9###  ###reference_b9###  ###reference_b9###], ensuring a balanced class distribution for training. We use 5-fold cross-validation to obtain the optimal hyperparameters of each model, the grid search spaces are detailed in the supplement.\nLLM Configuration. \nIn our pipeline, we utilized LLaMA2 as the backbone language model, an open-source LLM developed by Meta and accessed through Hugging Face555https://huggingface.co/meta-llama  ###reference_huggingface.co/meta-llama###  ###reference_huggingface.co/meta-llama###  ###reference_huggingface.co/meta-llama###. Our approach involves employing two distinct versions of the LLaMA2, specifically the 7B model and 70B model, to cater to different aspects of our task. The 7B model is designated for generating patient summaries, whereas the more powerful 70B model is tasked with the complex process of final reasoning. Given the medical field requires more reliable outputs, we use the \u201cGreedy\u201d strategy for each output. Specifically, by setting \u201cnum_beams=1\u201d (i.e., the number of hypotheses to keep track of) and \u201cdo_sample=false,\u201d we prevent LLaMA2 from generating outputs other than the most probable one. This approach reduces diversity but enhances the reliability of the results, ensuring reproducibility. For ICL, we use  demonstrations unless noted otherwise. The parameter , set at , weights categorical features (like diagnosis and medication) more heavily than continuous features (such as vital signs) in our demonstration retrieval process."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "Main Result",
            "text": "To evaluate the performance of our pipeline, we conducted experiments on the processed OHSU dataset and compared the testing performance with those obtained by using SLs and LLM independently. We focus on the OHSU data for six different combinations of computable phenotypes (CP1, CP2) and prediction windows (PW0, PW1, PW3), see Table 2  ###reference_###  ###reference_###  ###reference_### for definitions. The confidence threshold  in our pipeline is set to 0.6, i.e., if the prediction probability produced by Avg. SLs is greater than 0.6, then we use the predicted label of Avg. SLs. Otherwise, we will take the prediction of ICL, which uses demonstrations from the reliable set .\nWe repeat the experiment 5 times and report the mean with standard deviation in precision, recall, and F1 score, by Table 6  ###reference_###  ###reference_###  ###reference_###. We mainly focus on the F1 score, which is the most important metric in classification tasks with label imbalance problems. From Table 6  ###reference_###  ###reference_###  ###reference_###, we can see our pipeline shows superiority in F1 score among almost all cases, which shows the effectiveness of our proposed pipeline, combining the strength of traditional SLs and LLMs in risk prediction. Our pipeline is capable of managing imbalanced data to ensure robust and accurate predictions. For the baselines, XGB, however, shows consistently good performance in terms of precision, while low performance in recall, suggesting that it tends to predict more negatives. LR\u2019s lower precision and higher recall indicate a tendency to answer positives, leading to many misdiagnoses. Avg. SLs achieves a balance among different SL models. LLaMA2 70B model performs the worst in all cases, which shows that it is difficult to capture the common pattern by relying on just ICL.\nNote that the overall poor performance, with F1 scores below 0.4, may be attributed to inherent challenges in the ADRD risk prediction task. In the OHSU dataset, crucial factors like demographics and clinical notes, which could significantly enhance predictive accuracy, are not available. From the perspective of different CPs, the models\u2019 performance for CP2 is better than for CP1 in most cases. This is probably because the patients grouped by CP2 have many ADRD-related characteristics that lead them to be diagnosed with multiple ADRDs."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "Empirical Analysis",
            "text": "To better understand the proposed pipeline, we conduct some ablation studies: (1) assessing the influence of LLM-based summarization, (2) investigating the consequences of randomly selecting demonstrations in ICL, (3) exploring the different denoising strategies in ICL, (4) hyperparameter sensitivity, i.e., studying on different confidence thresholds in the proposed pipeline, (5) the impact of different types of LLMs, i.e., analyzing the impact of model size and medical data fine-tuning on predicting performance.\nEffect of LLM-based Summarization. \nIn our study, to make predictions based on the LLM, we have to reformulate the tabular data into text. We proposed to use LLM for patient data summarization, and the summarized text will, to some extent, reflect the characteristics of the LLM\u2019s pre-trained knowledge, as the model\u2019s behavior and output are based on the data distributions and patterns it learned during the training phase. So, we expect that the generated text will be LLM-friendly, which would be useful for subsequent tasks. To confirm the effect of such LLM-generated text, we conduct experiments to compare the use of concatenated sentence only (w/o Summary) and LLM-based summarization in our case (w/ Summary) on CP1_PW0 and CP2_PW0 datasets. Here, we set the number  of ICL examples to be 6 because the length of the concatenated sentence is too long and will exceed the input token limit of LLaMA2 if . The experiment result in Table 7  ###reference_###  ###reference_###  ###reference_### shows that the pipeline w/ Summary has better performance, as the f1 score is much higher, which indicates the effectiveness of LLM-based summarization.\nSee supplement for examples of concatenated sentences and LLM-generated summaries.\nSimilarity-based Demonstration Retrieval in ICL. \nIn our study, we select the in-context examples based on the similarity between the test sample and the reliable candidate sample. The context samples, which are similar to the test sample, are expected to help LLM learn more about the background to make decisions. To evaluate the effect of such a similarity-based retrieval strategy, we conduct experiments on CP1_PW0 and CP2_PW0 datasets using two types of ICL sample selection strategy: random selection (w/o Sim-Selection) and similarity-based sample selection (w/ Sim-Selection). Both strategies selected samples from the reliable candidate set .  Table 8  ###reference_###  ###reference_###  ###reference_### shows that employing a similarity-based sample selection strategy enhances performance across all metrics, suggesting that providing contextually similar examples yields more accurate responses. In contrast, random selection tends to produce a higher proportion of negative answers, reflecting the inherent label imbalance where a predominance of negative ICL examples results in more negative predictions.\nStudy on Different Denoising Strategies in ICL. \nIn our pipeline, we build the reliable candidate set  for ICL by using signals from conventional SLs, specifically, LR, XGB, and MLP. We hypothesize that those samples that exhibit high prediction confidence across all SLs are high-quality samples, otherwise, they are considered as noise samples. Such a denoising process is expected to boost ICL performance. We test our hypothesis using the CP1_PW0 and CP2_PW0 datasets, comparing four strategies for constructing ICL candidate sets. We avoid confidence-driven predictions in our pipeline to better observe performance differences among ICL strategies. The full training set refers to using the complete training set as the candidate. The all-correct subset comprises samples that all SLs successfully predict. The any-correct subset includes any samples that at least one SL successfully predicts. The high confidence subset, which is the strategy employed in this paper, considers the average confidence levels of predictions across different SLs. According to the results in Table 9  ###reference_###  ###reference_###  ###reference_###, all three denoising strategies significantly enhanced the performance of ICL, with the High Confidence Subset achieving the best results.\n###figure_17### ###figure_18### ###figure_19### ###figure_20### ###figure_21### ###figure_22### Analysis of Different Confidence Thresholds. \nOur pipeline integrates SLs and LLMs for risk prediction through a confidence-driven mechanism. If the prediction probability of Avg. SLs falls below the confidence threshold , the prediction will be generated by the LLM. To investigate the performance at different confidence thresholds, we conduct experiments on CP{1,2}_PW{0,1,3} data using six thresholds {0.5, 0.6, 0.7, 0.8, 0.9, 1.0}. According to the results in Figure 3  ###reference_###  ###reference_###  ###reference_###, we can see that the performance is better with a concave form through confidence threshold, i.e., SLs an LLMs balance is necessary. This is consistent with our discussion in section 3  ###reference_###  ###reference_###  ###reference_###. In other words, LLMs do not outperform SLs on all samples, but confident samples still rely on SLs that capture common patterns via training on extensive data, and unconfident samples are better handled by using LLMs.\n###figure_23### The Impact of Model Size and Medical Data Fine-tuning. \nIn our approach, we employed the LLaMA2 70B model for inference. To understand the effect of different model sizes on performance, we conducted a series of comparative experiments with various sizes of LLMs. In addition to the pre-trained LLaMA2 models, we also compared models that were fine-tuned on diverse medical datasets to assess their efficacy on our ADRD prediction task. See the supplement for details about the medical data fine-tuned models used in our experiment. The results in Figure 4  ###reference_###  ###reference_###  ###reference_### indicate that medical data fine-tuning does not necessarily enhance performance for the target task. The effectiveness depends on the similarity between the domain of the data used for fine-tuning and the target data domain. For example, the Asclepius-7b model, which performed the best, utilized a fine-tuning dataset containing a large number of QA pairs related to ADRD. This dataset closely aligns with our target task, which likely contributed to the model\u2019s superior performance. Furthermore, our findings challenge the common wisdom from scaling laws that larger models are inherently better; we observed that smaller models can achieve superior performance under certain conditions. This highlights the need for a nuanced understanding of the interaction between model size and domain-specific fine-tuning within the context of task-specific applications."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": "We categorize related research of this work into the following categories: (1) the use of machine learning for handling ADRD, (2) large language models, (3) In-context learning, and (4) large language models for clinical tasks."
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "ML with ADRD",
            "text": "To detect ADRD, [34  ###reference_b34###  ###reference_b34###  ###reference_b34###] employed logistic regression and a gradient boost algorithm using a real-world dataset obtained from the OneFlorida+ Research Consortium. In [47  ###reference_b47###  ###reference_b47###  ###reference_b47###], the use of logistic regression, support vector machines, and random forest methods was explored. The authors of [45  ###reference_b45###  ###reference_b45###  ###reference_b45###] utilized the LASSO algorithm, and [46  ###reference_b46###  ###reference_b46###  ###reference_b46###] proposed an algorithm named ZCoR, which assesses the future risk of AD. Differing from the aforementioned studies, which primarily focused on ADRD, the following papers targeted AD more directly [32  ###reference_b32###  ###reference_b32###  ###reference_b32###]. The authors of [40  ###reference_b40###  ###reference_b40###  ###reference_b40###] employed MRI images to detect AD. In [2  ###reference_b2###  ###reference_b2###  ###reference_b2###], the authors utilized EEG signals to detect AD using support vector machines. Several studies have attempted to classify AD using a range of methods, including random forest and linear models [31  ###reference_b31###  ###reference_b31###  ###reference_b31###]. K-nearest neighbors (KNN) classifier [5  ###reference_b5###  ###reference_b5###  ###reference_b5###], support vector machine (SVM) [16  ###reference_b16###  ###reference_b16###  ###reference_b16###], multi-layer perceptron (MLP) [41  ###reference_b41###  ###reference_b41###  ###reference_b41###], Cuckoo Search [14  ###reference_b14###  ###reference_b14###  ###reference_b14###], and traditional machine learning techniques [51  ###reference_b51###  ###reference_b51###  ###reference_b51###, 27  ###reference_b27###  ###reference_b27###  ###reference_b27###]."
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "Large Language Models",
            "text": "Language models with billions of parameters are commonly referred to as LLMs. The emergence of LLMs began with BERT [13  ###reference_b13###  ###reference_b13###  ###reference_b13###], marking the start of the LLM era. GPT-3 [8  ###reference_b8###  ###reference_b8###  ###reference_b8###] has demonstrated a significant impact on real-world applications due to its versatility. Following GPT-3, GPT-4 [1  ###reference_b1###  ###reference_b1###  ###reference_b1###] has been developed with improved performance, surpassing human capabilities in some tasks. Very recently, Gemini [58  ###reference_b58###  ###reference_b58###  ###reference_b58###] was announced; however, most models still feature gray-box or black-box architectures, which do not allow access to their model parameters. They only allow to access at most their output probability. To tackle this, Meta release LLaMAv1/v2 [61  ###reference_b61###  ###reference_b61###  ###reference_b61###, 62  ###reference_b62###  ###reference_b62###  ###reference_b62###] which are publicly accessible models for research objectives with various model parameter cases, such as 7B, 13B, and 70B."
        },
        {
            "section_id": "6.3",
            "parent_section_id": "6",
            "section_name": "In-Context Learning",
            "text": "In-Context Learning is a promising method to make the model answer based on few-shot samples, which dramatically reduces the fine-tuning cost to the target task [15  ###reference_b15###  ###reference_b15###  ###reference_b15###]. The conventional ICL sample selection method randomly selects samples and demonstrates performance improvement [7  ###reference_b7###  ###reference_b7###  ###reference_b7###]. To further enhance performance, several works have attempted to select relevant samples using BM25 [50  ###reference_b50###  ###reference_b50###  ###reference_b50###], and language model-oriented embeddings [49  ###reference_b49###  ###reference_b49###  ###reference_b49###, 30  ###reference_b30###  ###reference_b30###  ###reference_b30###]."
        },
        {
            "section_id": "6.4",
            "parent_section_id": "6",
            "section_name": "LLMs for Clinical Domain",
            "text": "LLMs possess strong capability in performing various tasks, including those in the medical field [23  ###reference_b23###  ###reference_b23###  ###reference_b23###]. In particular, many studies have attempted to develop new LLMs specifically for medical tasks. For example, Med-PaLM [55  ###reference_b55###  ###reference_b55###  ###reference_b55###] represents a medical domain-specific variant of the PaLM model. Similarly, based on Alpaca [57  ###reference_b57###  ###reference_b57###  ###reference_b57###], MedAlpaca [21  ###reference_b21###  ###reference_b21###  ###reference_b21###] was proposed, and fine-tuend LLaMA [61  ###reference_b61###  ###reference_b61###  ###reference_b61###, 62  ###reference_b62###  ###reference_b62###  ###reference_b62###] for medical domain, PMC-LLaMA [67  ###reference_b67###  ###reference_b67###  ###reference_b67###] was suggested. Chat-bot oriented model [70  ###reference_b70###  ###reference_b70###  ###reference_b70###] and Huatuo-GPT [71  ###reference_b71###  ###reference_b71###  ###reference_b71###] were trained using the dataset obtained from the real-world doctors and ChatGPT [1  ###reference_b1###  ###reference_b1###  ###reference_b1###]. Yang et al. [69  ###reference_b69###  ###reference_b69###  ###reference_b69###] trained and release the GatorTron model. Different from proposing a new medical-specific models, several works have aimed to directly use the pre-trained LLMs in a zero-shot manner. For example in [42  ###reference_b42###  ###reference_b42###  ###reference_b42###, 38  ###reference_b38###  ###reference_b38###  ###reference_b38###] used GPT models for the medical field. Nori et al. [43  ###reference_b43###  ###reference_b43###  ###reference_b43###] proposed a way of leveraging pre-trained LLMs for the medical field by leveraging some techniques including in-context learning, and chain-of-thought."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we address the challenge of early ADRD prediction using cost-effective EHR databases. We introduce a novel collaborative approach that combines the predictive power of conventional supervised learning techniques, such as LR, XGB, and MLP, with the advanced reasoning capabilities of LLMs. By integrating a confidence-driven selection process, our method dynamically chooses between the robust, data-driven predictions from SLs and the nuanced, context-aware interpretations by LLMs. This is based on their confidence levels, harnessing the strengths of SLs in clear-cut cases and LLMs in more complex scenarios. The extensive validation of our method with a real-world dataset from OHSU hospital demonstrates the superiority of ADRD risk prediction. Furthermore, our findings reveal that neither scaling up the model size nor specific fine-tuning on medical datasets consistently enhances performance, indicating the need for further investigation into these aspects in practice."
        }
    ],
    "url": "http://arxiv.org/html/2405.16413v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "3"
        ],
        "methodology_sections": [
            "4",
            "4.1",
            "4.2",
            "4.3"
        ],
        "main_experiment_and_results_sections": [
            "5.1",
            "5.2",
            "5.3"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "5.3"
        ]
    },
    "research_context": {
        "paper_id": "2405.16413v1",
        "paper_title": "Augmented Risk Prediction for the Onset of Alzheimer\u2019s Disease from Electronic Health Records with Large Language Models",
        "research_background": "### Motivation\nAlzheimer\u2019s disease (AD) and related dementias (ADRD) are severe neurodegenerative disorders that substantially impair memory and cognitive functions, eventually leading to death. Given the complexities of AD/ADRD pathology and clinical presentation, current treatment development has been slow. Early identification and risk prediction are vital but challenging, especially since standard diagnostic procedures involving neuroimages or cerebro-spinal fluid biomarkers are costly and invasive. Thus, there is a significant need to leverage more accessible datasets, such as electronic health records (EHRs), for risk prediction. However, traditional supervised learning (SL) approaches face hurdles due to the noisy nature and incomplete information inherent in EHRs. Recently, large language models (LLMs) have shown promise due to their robust reasoning and contextual learning capabilities, presenting an opportunity for improved risk prediction methods.\n\n### Research Problem\nThe primary research problem is to develop an effective approach for risk prediction of AD/ADRD using EHR data. Traditional SL models struggle due to the noisy and incomplete nature of EHR data, especially in the early stages of the disease where symptoms are subtle. While LLMs offer powerful reasoning and contextual learning capacity, integrating them with EHR data poses significant technical challenges. These include:\n1. Adapting LLMs for dynamic and evolving data such as EHRs.\n2. Representing structured medical records in a format that LLMs can effectively process.\n3. Managing inherent data quality issues within EHRs to avoid misleading conclusions.\n\n### Relevant Prior Work\n- **Traditional SL Models**: Existing methods like logistic regression, XGBoost, and multi-layer perceptron have been used for EHR-based risk prediction, but they often falter when dealing with the noisy, sparse, and sometimes incomplete nature of EHR data.\n  \n- **LLMs and Pre-trained Models**: Advancements in pre-trained large language models have shown their capability to perform robust reasoning, especially with rich contextual information and domain knowledge. However, their application to dynamic and noisy data like EHRs has not been extensively studied.\n\n### Contributions\nThis paper makes the following contributions:\n1. **Evaluation of SL and LLM Approaches**: It identifies the strengths and weaknesses of traditional supervised learning models and large language models for risk prediction from EHR data.\n   \n2. **Collaborative Prediction Model**: Proposes a new approach that combines SL models and LLMs using a confidence-driven selection process, dynamically switching between SL and LLM predictions based on confidence levels to utilize their respective strengths.\n\n3. **ICL Demonstration Denoising Strategy**: Introduces an in-context learning (ICL) demonstration denoising strategy to improve the performance of LLMs, enhancing the overall efficacy of the prediction pipeline.\n\n4. **Empirical Validation**: Validates the proposed approach using a real-world dataset from the OHSU health system, showing its superiority over standalone traditional SL models and LLMs. The study also explores the impact of LLM size and model fine-tuning on prediction performance, indicating that larger models or fine-tuning do not always result in improved outcomes, thus suggesting areas for further research.",
        "methodology": "**Methodology:**\n\n1. **Natural Language Summarization of EHRs**:\n   - **Objective**: Convert structured electronic health record (EHR) data (typically tabular) into natural language that large language models (LLMs) can understand and process.\n   - **Process**:\n     - Summarize the tabular data into a comprehensive natural language representation.\n     - Balance the trade-off between including enough detail to be informative for downstream tasks and avoiding excessive elaboration that could introduce hallucinations.\n     - Details on the summarization process are provided in Appendix A.\n\n2. **Reliable Subset Sampling**:\n   - **Objective**: Select a reliable subset of training examples to use as in-context learning (ICL) examples to enhance prediction accuracy.\n   - **Criteria for Reliable Candidates**:\n     - Selected based on the \"High Average Prediction Confidence,\" which involves predicting samples with high average probability across multiple supervised learning (SL) methods (logistic regression (LR), extreme gradient boosting (XGB), and multi-layer perceptron (MLP)).\n     - Define a threshold \\( \\delta \\) for the average prediction confidence, ensuring that only samples exceeding this threshold are considered reliable.\n\n3. **Retrieving Score of EHRs for ICL**:\n   - **Objective**: Construct a reliable set \\( \\mathcal{S}_q \\) for each test sample \\( q \\) using the reliable candidate set \\( \\mathcal{S} \\).\n   - **Similarity Measurement**:\n     - Employ Euclidean distance for continuous features (e.g., vital signs, lab tests).\n     - Use Hamming distance for categorical features.\n     - Calculate the total similarity score \\( s_{ij} \\) integrating both distance metrics with a balancing hyperparameter \\( \\lambda \\).\n     - Select the top- \\( k \\) samples with the highest similarity scores to construct \\( \\mathcal{S}_q \\).\n     - Order \\( \\mathcal{S}_q \\) in an ascending manner of similarity to prioritize the most relevant samples right before inference.\n\n4. **Future Work Recognized**:\n   - While this framework can adopt many patient similarity retrieval approaches, a comparative analysis of existing methods under this framework is planned for future work.\n\nBy summarizing structured EHR data into natural language for use by LLMs, selecting high-confidence prediction samples for reliable context, and employing a combination of distance metrics for similarity calculation, the proposed method aims to enhance the accuracy and reliability of Alzheimer's disease onset prediction from EHRs.",
        "main_experiment_and_results": "### Main Experiment Setup and Results: \n\n**Data Splitting:**\n- **Sampling Approach:** To address potential biases and ensure consistency, a uniform random sampling approach was employed. This involved selecting 5500 samples for each computable phenotype (CP) and prediction window (PW) interval, with a 1:10 case-control ratio.\n- **Consistency:** The sample size was kept constant across all groups to ensure comparability of experimental outcomes.\n- **Training and Testing Sets:** Out of the total samples, 80% were allocated for training and the remaining 20% for testing.\n\n**SL Methods:**\n- **Compared Models:** The study compared the proposed pipeline with three traditional supervised learning (SL) methods commonly used for medical form data: Logistic Regression (LR), eXtreme Gradient Boosting (XGB), and Multi-Layer Perceptron (MLP). \n- **Ensemble Approach:** An ensemble method named Avg. SLs was also introduced, which combined the aforementioned models to make robust predictions.\n- **Class Imbalance:** The Synthetic Minority Over-sampling Technique (SMOTE) was integrated to balance the class distribution in the training data.\n- **Model Optimization:** A 5-fold cross-validation was conducted to identify the optimal hyperparameters for each model.\n\n**LLM Configuration:**\n- **LLaMA2 Models:** The LLaMA2 language model served as the backbone, with different versions designated for specific tasks:\n  - **7B Model:** Utilized for generating patient summaries.\n  - **70B Model:** Leveraged for final reasoning processes.\n- **Output Strategy:** The \"Greedy\" strategy was used to enhance reliability and reproducibility. This involved setting \"num_beams=1\" and \"do_sample=false\" to ensure the generation of the most probable output.\n- **Demonstration Retrieval:** A demonstration retrieval process was employed with demonstrations unless noted otherwise. Categorical features (such as diagnosis and medication) were weighted more heavily than continuous features (like vital signs).\n\n**Evaluation Metrics:**\n- **Metrics:** The main evaluation metrics were not explicitly provided in the provided text. \n\n**Main Experimental Results:**\nThe main experimental results were not explicitly detailed in the provided text and therefore cannot be described based solely on the given information.\n\n**Additional Information:** \nThe experimental setup integrates both traditional supervised learning techniques and large language models to create a hybrid predictive framework for the onset of Alzheimer\u2019s Disease. The study emphasizes balancing data, ensuring model robustness through ensemble approaches, and maintaining high output reliability."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "Assessing the influence of LLM-based summarization on predictive performance.",
            "experiment_process": "To make predictions based on the LLM, tabular data is reformulated into text using LLM for patient data summarization. Experiments compared the use of concatenated sentences only (w/o Summary) and LLM-based summarization (w/ Summary) on CP1_PW0 and CP2_PW0 datasets, with the number of ICL examples set to 6 due to input token limits of LLaMA2.",
            "result_discussion": "The experiment results show that the pipeline w/ Summary has better performance, with a significantly higher f1 score, indicating the effectiveness of LLM-based summarization.",
            "ablation_id": "2405.16413v1.No1"
        },
        {
            "research_objective": "Investigating the consequences of randomly selecting demonstrations in ICL.",
            "experiment_process": "In-context examples were selected based on similarity between the test sample and the reliable candidate sample. Comparisons were made between random selection (w/o Sim-Selection) and similarity-based sample selection (w/ Sim-Selection) using CP1_PW0 and CP2_PW0 datasets.",
            "result_discussion": "The similarity-based sample selection strategy enhanced performance across all metrics, suggesting contextually similar examples yield more accurate responses. Random selection produced a higher proportion of negative answers, likely due to label imbalance.",
            "ablation_id": "2405.16413v1.No2"
        },
        {
            "research_objective": "Exploring different denoising strategies in ICL.",
            "experiment_process": "The reliable candidate set for ICL was built using signals from SLs (LR, XGB, and MLP). Four strategies for constructing ICL candidate sets were compared using CP1_PW0 and CP2_PW0 datasets: full training set, all-correct subset, any-correct subset, and high confidence subset.",
            "result_discussion": "All three denoising strategies significantly enhanced ICL performance, with the High Confidence Subset achieving the best results, confirming the effectiveness of the denoising process.",
            "ablation_id": "2405.16413v1.No3"
        },
        {
            "research_objective": "Studying the effect of different confidence thresholds in the proposed pipeline.",
            "experiment_process": "Performance was investigated at different confidence thresholds (0.5, 0.6, 0.7, 0.8, 0.9, 1.0) using CP{1,2}_PW{0,1,3} data. Predictions were made by the LLM if the prediction probability of Avg. SLs fell below the confidence threshold.",
            "result_discussion": "The performance showed a concave form with various confidence thresholds, indicating that balancing SLs and LLMs is necessary. Confident samples still rely on SLs while unconfident samples are better handled by LLMs.",
            "ablation_id": "2405.16413v1.No4"
        },
        {
            "research_objective": "Analyzing the impact of model size and medical data fine-tuning on predictive performance.",
            "experiment_process": "A series of comparative experiments were conducted with various sizes of LLMs, along with pre-trained LLaMA2 models and models fine-tuned on diverse medical datasets to assess efficacy on ADRD prediction.",
            "result_discussion": "Medical data fine-tuning did not necessarily enhance performance. Effectiveness depended on the similarity between the fine-tuning data domain and the target task. Smaller models can achieve superior performance under certain conditions, highlighting the nuanced interaction between model size and domain-specific fine-tuning.",
            "ablation_id": "2405.16413v1.No5"
        }
    ]
}