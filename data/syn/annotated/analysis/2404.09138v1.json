{
    "title": "From Bytes to Borsch: Fine-Tuning Gemma and Mistral for the Ukrainian Language Representation",
    "abstract": "In the rapidly advancing field of AI and NLP, generative large language models (LLMs) stand at the forefront of innovation, showcasing unparalleled abilities in text understanding and generation. However, the limited representation of low-resource languages like Ukrainian poses a notable challenge, restricting the reach and relevance of this technology. Our paper addresses this by fine-tuning the open-source Gemma and Mistral LLMs with Ukrainian datasets, aiming to improve their linguistic proficiency and benchmarking them against other existing models capable of processing Ukrainian language. This endeavor not only aims to mitigate language bias in technology but also promotes inclusivity in the digital realm. Our transparent and reproducible approach encourages further NLP research and development. Additionally, we present the Ukrainian Knowledge and Instruction Dataset (UKID) to aid future efforts in language model fine-tuning. Our research not only advances the field of NLP but also highlights the importance of linguistic diversity in AI, which is crucial for cultural preservation, education, and expanding AI\u2019s global utility. Ultimately, we advocate for a future where technology is inclusive, enabling AI to communicate effectively across all languages, especially those currently underrepresented.\n\n\n\nKeywords:\u2009Gemma 2b, Gemma 7b, Mistral 7b, LLM, Ukrainian, Multilingual Models, LoRA, Fine-Tuning",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1.   Introduction",
            "text": "The field of Natural Language Processing (NLP) is expanding extremely quickly today, largely due to the immense success of the generative Large Language Models (LLM). Within only a few years, these language models have become capable of performing tasks like contextual understanding and generation, few-shot learning, automated question answering, sentiment analysis, emotion detection, and many others with unprecedented quality."
        },
        {
            "section_id": "1.1",
            "parent_section_id": "1",
            "section_name": "1.1.   Background",
            "text": "The significance of recent NLP advances, obtained in such a short time, becomes even more evident looking back at the long history of quantitative language modeling. The first attempts to attack the problem of computational linguistics date back as far as 70 years ago, to the early 1950s Shannon (1951  ###reference_b33###).\nBut it was not until the 2000s when the artificial Neural Network (NN) proved its effectiveness in the field Bengio et al. (2000  ###reference_b3###), notably applied to the machine translation problem Schwenk et al. (2006  ###reference_b31###). These models were mostly based on Recurrent Neural Networks (RNN) architecture like Long Short-Term Memory (LSTM) Hochreiter and Schmidhuber (1997  ###reference_b16###) and later Gated Recurrent Unit (GRU) Chung et al. (2014  ###reference_b7###). Still, important milestones were achieved during this period like the introduction of word embeddings.\nHowever, throughout most of the 2010s, while other fields of Deep Learning (DL) like Computer Vision (CV) and Reinforced Learning (RL) have achieved very impressive results Krizhevsky et al. (2012  ###reference_b23###); He et al. (2015  ###reference_b15###); Silver et al. (2016  ###reference_b34###), the NN-powered NLP field still suffered from a number of problems. This included the handling of long-term dependencies, capturing bidirectional context and overall difficulties with computational efficiency and stability.\nThe breakthrough came with the invention of the transformer architecture which introduced the key component: the attention mechanism Vaswani et al. (2017  ###reference_b40###)."
        },
        {
            "section_id": "1.2",
            "parent_section_id": "1",
            "section_name": "1.2.   The transformer era",
            "text": "The attention mechanism addresses the challenges of understanding both the immediate and broader context of words in a sentence, solving issues related to bidirectional context, long-term dependencies, and convergence. Furthermore transformer architecture enhances the ability to process data in parallel, significantly outperforming RNNs in this regard. This advancement has paved the way for the development of LLMs: highly complex language models with billions of parameters, trained on extensive corpora of text.\nThe early LLMs like Bidirectional Encoder Representations from Transformers (BERT) Devlin et al. (2019  ###reference_b9###) and its successors have focused on understanding text and problems like text classification, emotion recognition, etc. Although, with the emergence of the Generative Pre-trained Transformer (GPT) family Radford and Narasimhan (2018  ###reference_b29###); Radford et al. (2019  ###reference_b30###); Brown et al. (2020  ###reference_b5###); OpenAI (2023  ###reference_b28###), focus has shifted towards generative tasks.\nTraining an LLM from scratch remains a cumbersome and costly task. Nevertheless the general nature of the training corpora allows them to fully benefit from transfer learning, implementing the pre-training and fine-tuning paradigm: once a model is pre-trained on a large language corpus it can be further fine-tuned for a specific use-case, requiring relatively minor costs.\nThe LLMs available on the market can be split into two groups: proprietary and open-source. Proprietary models like GPT-4 and Gemini Team (2023  ###reference_b36###) tend to have more parameters and offer high out of the box performance in most common tasks, but their use is restricted by the providers and allows limited fine-tuning options. Open-source models like LLaMa2 Touvron et al. (2023  ###reference_b38###), Mistral Jiang et al. (2023  ###reference_b18###), Mixtral Jiang et al. (2024  ###reference_b19###) or a recent Gemma by Google Gemma Team (2024  ###reference_b13###) offer full access to the model code and weights and impose little to no restrictions on the use of the model, making it a natural choice for fine-tuning experiments. Open-source models often come in a variety of sizes in terms of parameter number, allowing lighter models to be run on consumer-grade GPUs."
        },
        {
            "section_id": "1.3",
            "parent_section_id": "1",
            "section_name": "1.3.   Motivation and objective",
            "text": "A substantial number of open-source models are available on the market today. At the same time all these models demonstrate a notable bias towards the English language due to their training conditions. The bias can manifest itself in a number of ways, including to but not limited to the following:\nLanguage and cultural bias. This can impair a model\u2019s usability for non-English speakers and also perpetuate stereotypes or misunderstandings about cultures.\nEthical and fairness concerns. The same model may show considerably better performance with English-speaking users, leaving others with a subpar experiences.\nUneven knowledge representation. This can lead to a skewed representation of global knowledge, history, and perspectives, and embed these biases into the model\u2019s outputs and decision-making processes.\nThe bias becomes particularly prominent in non-European languages and languages that do not use a Latin alphabet.\nThis has naturally motivated numerous scholars and enthusiasts to put much efforts into fine-tuning open-source models, predominantly LLaMa 2, in many languages, both European Basile et al. (2023  ###reference_b2###); Vanroy (2023  ###reference_b39###) and non-European Cui et al. (2024  ###reference_b8###); Gala et al. (2024a  ###reference_b11###, b  ###reference_b12###); Nguyen et al. (2023  ###reference_b27###); Azime et al. (2024  ###reference_b1###); Kohli et al. (2023  ###reference_b22###). Most of the listed articles have been published within the last months, and demonstrate great interest and involvement in solving this linguistic bias issue. The immediate benefits of having an open-source model that is fine-tuned with a certain language include:\nReduction or elimination of cultural bias.\nFlexibility in use-cases, including both academic and business.\nPreservation of rare and low-resource languages.\nThe effort also promotes the creation of language-specific datasets and development of the LLM-oriented ecosystem. Even when a particular model becomes obsolete, further progress is greatly facilitated by this groundwork."
        },
        {
            "section_id": "1.3.1",
            "parent_section_id": "1.3",
            "section_name": "1.3.1.   Ukrainian sector of the LLMs",
            "text": "Ukraine is renowned for its dynamic IT community, which thrives both in academic circles and the commercial sector. The field of computational linguistics is no exception, boasting the inception of multi-billion dollar unicorns like Grammarly within its borders. With the advent of LLMs, there has been a keen interest in harnessing their capabilities for solving NLP challenges in the Ukrainian language.\nYet, until recently, these efforts have predominantly focused on leveraging BERT-like models Tiutiunnyk (2020  ###reference_b37###); Laba et al. (2023  ###reference_b24###); Katerynych et al. (2021  ###reference_b20###), while the realm of generative LLMs has been somewhat overlooked. So far, UAlpaca is the only publicly available LLM that has been fine-tuned specifically for the Ukrainian language Had  ###reference_b14###. Likewise, instructional datasets in Ukrainian have been comparatively limited. The escalating enthusiasm for generative, GPT-style LLMs underscores the need for models attuned to Ukrainian linguistic and cultural nuances, further underlining the significance of our research endeavors."
        },
        {
            "section_id": "1.3.2",
            "parent_section_id": "1.3",
            "section_name": "1.3.2.   Objectives",
            "text": "The aim of the effort presented in the current paper is multifold:\nCreate an open-source, free-to-use LLMs fine-tuned for Ukrainian language and culture thus expanding the Ukrainian presence in the NLP field.\nCompare the performance of different open-source LLMs, notably the SOTA Gemma model.\nBenchmark the trained models using the dedicated Ukrainian dataset and compare them to the proprietary models.\nIntroduce the UKID instruction training dataset and make it publicly available for future fine-tuning efforts.\nPerform the entire process in a fair and reproducible manner in order to facilitate future efforts."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2.   Dataset and the experimental setup",
            "text": "Despite the abundance of online tutorials available for training large language models, establishing a reproducible setup for each model, complete with an appropriate dataset in the necessary format, proved to be unexpectedly challenging. Every model comes with its own set of constraints, including hardware requirements, deployment methods for inference, and specific approaches for processing instructions."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1.   Dataset collection",
            "text": "When our team started working on the shared task for the UNLP conference, we were taken aback by the scarcity of suitable datasets for fine-tuning LLMs in Ukrainian. The organizers supplied a training dataset comprising 3,063 instruction rows, designed to acclimate the model to the multiple-choice format prevalent in the Ukrainian national examination. While this dataset proved valuable for training the LLM to answer in a specific format, it was notably limited in depth, offering little in terms of enhancing these LLMs\u2019 parametric knowledge base.\nThrough multiple experiments, we determined that 3-5 epochs of LoRA fine-tuning were sufficient for the model to grasp the multiple-choice format required for evaluation in the conference\u2019s shared task. However, the model\u2019s responses were lacking consistency, particularly when it generated incorrect or nonsensical answers. For instance, the model erroneously referred to \u201dborsch,\u201d a well-known Ukrainian dish, as an item used in cars (See Figure 1  ###reference_###).\n###figure_1### This behavior underscored a deficiency in the model\u2019s general conceptual understanding, highlighting the pressing necessity to augment the dataset with more content in Ukrainian.\nConsequently, we leveraged the UAlpaca dataset Had  ###reference_b14### alongside Squad-uk Drastic  ###reference_b10### which happened to be the only instruction datasets in the Ukrainian language available publicly.\nUnfortunately, even after fine-tuning with these datasets, we observed that the model still didn\u2019t improve much, even on the training dataset itself, despite an improvement in sentence formulation and conceptual understanding. This led us to realize that a much more comprehensive approach to dataset construction would be required. Both UAlpaca and Squad-uk happened to be translated versions of the general knowledge English-based datasets, which is missing Ukrainian context and knowledge that is specific to both cultural and historical aspects that were being evaluated by the questions in the exam dataset. This realization led us to rethinking what kind of data we need and led to the creation of our own dataset, the Ukrainian Knowledge and Instruction Dataset (UKID), the first Ukrainian instruction dataset rooted in a Ukrainian context."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2.   UKID methodology and construction",
            "text": "In formulating our hypothesis for the development of the Ukrainian language model, we posited that the model must align with the informational needs of the general population, reflecting the genuine interests and search behaviors of Ukrainian web users. To identify the most pertinent sources of intent-aligned knowledge, we turned to two widely recognized platforms: Wikipedia and Google. Consequently, we adopted a methodology focused on aggregating the most frequented Wikipedia pages, as determined by monthly traffic statistics, to ensure our dataset accurately captured the topics of highest relevance to Ukrainian web users.\nWe collected 1,064 pages by targeting those with monthly visit statistics ranging from 3,000 to 150,000. However, not all top-ranking Wikipedia pages in Google search results proved pertinent to our objective, as many described phenomena or entities not relevant to Ukraine. To refine our dataset, we employed a binary classification process to discern between relevant and non-relevant pages. This filtration mechanism is summarized in the table below, showcasing relevant versus non-relevant content (See Table 1  ###reference_###). Through this methodical approach, we identified 367 pages that were suitable for inclusion in our dataset creation process.\nThe proposed methodology suggests an optimal approach for organizing an instruction-based dataset, aimed at fine-tuning language models for underrepresented languages. This strategy offers the dual benefits of incorporating language-specific contexts and embedding essential factual knowledge into the model\u2019s trainable parameters during fine-tuning. Consequently, in addition to the conventional \u201dquestion-answer\u201d instruction pairs, we introduced a \u201dfact_check\u201d field. This addition acts as a comprehensive and standalone source of truth, enhancing the model\u2019s ability to verify facts and improve its accuracy. Performing this manually would have been unrealistic given the time constraints of the conference submission deadline, therefore an automated approach was implemented through the use of the Gemini 1.0 API and a few-shot learning example that utilizes the summary abstract of the Wikipedia page (See Figure.2  ###reference_###)\n###figure_2### As a result UKID-v0.1 was formed consisting of 962 question-answer-fact (QAF) pairs. Future work needs to focus on expanding the dataset to match other popular English-based datasets like Alpaca and Squad that consist of tens of thousands of rows. Even though the traditional notion of \u201cless is more\u201d for general English-based models recommends having smaller datasets Zhou et al. (2023  ###reference_b44###), our learnings indicate that fine-tuning under the constraints of lacking general conceptual understanding and context requires using much larger datasets.\nAdditionally, we have contemplated further enhancements to the UKID format, such as incorporating the original paragraphs from which the QAF pairs were derived to provide additional context. However, this aspect of the project remains unaddressed at present.\nA crucial consideration in dataset development is tailoring the instruction format to the specific requirements of different models. For instance, Llama, Mistral, and Gemma each necessitate unique formats. Overlooking this critical aspect has empirically led to suboptimal outcomes, though these observations have yet to be formally documented. The adaptation of datasets to align with the distinct formats of these models is essential for maximizing their performance and efficacy."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3.   Fine-tuning",
            "text": ""
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1.   Gemma models",
            "text": "First, we fine-tuned a Gemma-2B and a Gemma-7B model, from a recently published family of open models.\nWe used official \u201cgemma-2b-it\u201d and \u201cgemma-7b-it\u201d weights published by Google and followed official fine-tuning guidelines on the Vertex AI platform. The final python notebook is located in the \u201dfrom-bytes-to-borsch  ###reference_-borsch###\u201d github repository.\nFine-tuning for gemma-2b-it was performed with a combined dataset consisting of 13,063 instructions, which included from the 10,000 rows of UAlpaca dataset and 3,063 rows from the ZNO dataset provided by organizers of the conference. Fine-tuning for gemma-7b-it was performed with a dataset consisting of 14,025 instructions (10,000 rows of UAlpaca, 3,063 rows of ZNO and 962 rows of UKID).\nDue to resource constraints, we chose to use a LoRA Hu et al. (2022  ###reference_b17###) fine-tuning approach. We used a LoRA adapter implementation from the Keras v3 library, with , resulting in 11,067,392 trainable parameters, instead of the full 7B for the case of Gemma-7B.\nThe resulting model was published on the associated github repository. Unfortunately due to the time constraints we were not able to submit the 7B to the UNLP competition benchmarking, and only submitted results from the 2B instruct model."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2.   Mistral model",
            "text": "As a second alternative, we used a completely different fine-tuning pipeline with the help of the axolotl  ###reference_e/axolotl### tool to streamline the fine-tuning process. We used a 4x Nvidia Tesla A100-80Gb GPU instance on Microsoft Azure cloud for training. Due to compute constraints we chose to use the LoRA Hu et al. (2022  ###reference_b17###) approach once again, this time implemented using Hugging Face transformers library.\nWe used an AdamW optimizer Loshchilov and Hutter (2017  ###reference_b25###) with common starting point hyper-parameters for the LoRA adapters (, ), which resulted in 32,505,856 trainable parameters.\nFor Mistral-based fine-tunes we used the \u201dmistralai/Mistral-7B-Instruct-v0.1  ###reference_B-Instruct-v0.1###\u201d weights and \u201cLlamaTokenizer\u201d tokenizer.\nThe training was performed using ZNO and Uk-Squad datasets. Both datasets have a Llama/Alpaca instruction format and collectively produced 37,890 rows of instructions.\nMore details of the configuration and execution can be found in the associated github repository."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4.   Benchmarking results",
            "text": "We performed benchmarking using two test datasets: multiple choice questions (MCQ) and open questions (OQ).\nThe MCQ dataset comprises 3,063 questions from the Ukrainian External Independent Testing (EIT) test, a standard government test for college admission taken by secondary school students. This dataset splits into 1,139 Ukrainian history questions and 1,925 Ukrainian language and literature questions, reflecting the standard knowledge expected in Ukrainian schools. We evaluated this test automatically.\nThe OQ dataset contains 100 instruction-based questions prompting models to complete generative tasks, such as finishing a story or summarizing an event. We evaluated this dataset manually.\nBelow, we detail our benchmarking setup and criteria, focusing on the fine-tuned Gemma models, Gemma7bFT and Gemma2bFT, alongside an out-of-the-box model, Gemma7b, for reference."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1.   Multiple choice questions",
            "text": "We presented all questions from this dataset within a uniform prompt in Ukrainian, instructing models to select the single correct answer in letter form. Despite this directive, models frequently included extraneous information, necessitating manual filtration to extract the required letter codes. Correct responses matched the letter codes exactly. Table 2  ###reference_### displays the models\u2019 performance percentages in each category."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2.   Open questions",
            "text": "Evaluating open questions required a more nuanced approach, examining responses across four categories:\nUkrainian (U): the response is given in the Ukrainian language.\nFacts/Coherence (C): factual correctness and coherence of the given answer.\nRelevance (R): the answer aligns with the given instructions.\nGrammar (G): stylistic and grammatical evaluation.\nEach response could earn up to 1 point per category, with the results and average scores presented in Table 3  ###reference_###."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "4.4.   Code-switching and Azirivka",
            "text": "Code-switching is a linguistic phenomenon in which a speaker alternates between two or more languages within a single utterance or sentence. Until recently, this term was applied only to humans, but with the advent of LLMs this effect has been observed and studied in generative models Winata et al. (2021  ###reference_b42###); Zhang et al. (2023  ###reference_b43###). Code-switching in LLMs arises from the multilingual nature of training and fine-tuning processes.\nFor historical reasons, the majority of the Ukrainian population is multilingual. This creates a rather unique situation when constant code-switching is common at practically every level, starting from colloquial everyday conversations and ending with official statements from prime-ministers and presidents. A particular case of the latter has the official name Azirivka Wikipedia  ###reference_b41###, named after Ukrainian ex-prime minister Mykola Azarov.\nObserving the Gemma7b model mastering Azirivka after fine-tuning was both interesting and exciting. It is particularly interesting that the model generates not a simple mixture of words belonging to different languages, but rather conjugates words from one language according to the rules of another, just as some Ukrainians do, demonstrating features specific to synthetic languages.\nBelow, we present several instances of Azirivka code-switching. In these examples, components highlighted in blue represent Ukrainian, while those in red denote Russian.\nExample 1:\nAzirivka: \u0422\u0432i\u0440 \u043f\u0440\u043e \u043a\u043e\u043b\u043b\u0435\u043a\u0446\u0438\u044e \u043a\u043e\u043b\u044c\u043e\u0440\u043e\u0432\u044b\u0445 \u043e\u043bi\u0432\u0446\u043e\u0432 \u0412\u0430\u0441\u0438\u043b\u044f \u0413\u043e\u043b\u043e\u0431\u043e\u0440\u043e\u0434\u044c\u043a\u0430.\nEnglish: An essay about Vasyl Holoborodko\u2019s collection of colored pencils.\nExample 2:\nAzirivka: \u041f\u0440\u0438\u0432i\u0442\u0430\u0442\u044c \u0434\u0440\u0443\u0437i\u0432 \u0441 \u043e\u0434\u0440\u0443\u0436\u0434\u0435\u043d\u0438\u0435\u043c \u043c\u043e\u0436\u043d\u043e \u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u043e\u043c \u0441\u043f\u043e\u0441\u043e\u0431\u043e\u0432.\nEnglish: You can congratulate friends on their marriage in many ways.\nExample 3:\nAzirivka: \u042f \u043e\u0431\u0440\u0430\u0449\u0430\u044e\u0441\u044c \u043a \u0412\u0430\u043c \u0441 \u0436\u0430\u043b\u043e\u0431\u043e\u0439 \u043f\u043e \u043d\u0435\u044f\u043ai\u0441\u043d\u043e\u0439 \u0437\u0430\u043c\u0435\u043d\u0435 \u0442\u0440\u0443\u0431 \u0432 \u043f\u043e\u0434\u0432\u0430\u043bi \u043d\u0430\u0448\u0435\u0433\u043e \u0434\u043e\u043c\u0430, \u0440\u0430\u0441\u043f\u043e\u043b\u043e\u0436\u0435\u043d\u043d\u043e\u0433\u043e \u043f\u043e [\u0430\u0434\u0440\u0435\u0441]. \nEnglish: I am addressing you with a complaint about the poor-quality replacement of pipes in the basement of our house, located at [address].\nExample 4:\nAzirivka: \u0412 \u0423\u043a\u0440\u0430\u0438\u043d\u0435 \u041c\u0430\u043b\u0430\u043d\u043a\u0443 \u043d\u0435 \u0441\u0432\u044f\u0442\u043a\u0443\u044e\u0442.\nEnglish: Malanka is not celebrated in Ukraine.\nExample 5:\nAzirivka: \u0423 \u043f\u2019\u044f\u0442\u043d\u0438\u0446\u044e, 23 \u043b\u044e\u0442\u043e\u0433\u043e, \u0432 \u0423\u043a\u0440\u0430\u0457\u043di \u043e\u043f\u0430\u0434i\u0432 \u043d\u0435 \u0431\u0443\u0434\u0435\u0442, \u043d\u043e \u043c\u0435\u0441\u0442\u0430\u043c\u0438 - \u0440\u0432\u0443\u0447\u043a\u0438\u0439 i \u0441\u0438\u043b\u044c\u043d\u0438\u0439 \u0432i\u0442\u0435\u0440.\nEnglish: On Friday, February 23, there will be no precipitation in Ukraine, but there will be occasional gusty and strong wind.\nIt\u2019s worth noting that while most of these mixed words can\u2019t be found in official dictionaries, they are commonly heard on the streets of many Ukrainian cities. Such a language mixture naturally has been an object for linguistic studies Bilaniuk (2004  ###reference_b4###); Kent (2011  ###reference_b21###). We consider this emerging LLM property to be of great interest for further studies."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5.   Applications, risks and future work",
            "text": "It is abundantly clear that having a language-specific model is going to aid all of the possible use cases around communication, but it\u2019s also important to note the risks of not having the model. Both from the industrial and cultural standpoints.\nIncorporating LLM models of underrepresented languages into technology platforms offers unprecedented opportunities for enhancing communication across diverse sectors, ranging from healthcare and education to legal and commerce, all within the scope of the growing impacts of globalization. However, the absence of such models poses significant risks, not only stalling industrial progress but also exacerbating cultural erosion. Industrially, the lack of tailored language models can hinder the efficient dissemination of critical information, reduce the accessibility of digital services, and create barriers to entry for local businesses in the global market. Culturally, it threatens the preservation of linguistic diversity and the transmission of heritage, as languages without digital representation risk falling into disuse and oblivion. Therefore, addressing this gap is not merely a technical challenge but a pressing societal need that calls for collaborative efforts to ensure inclusive and sustainable development."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "5.1.   Applications",
            "text": "Oleksandr, a Ukrainian refugee in the USA, benefits from a language-specific LLM that digests and explains legal aid and immigration documents into Ukrainian. This tool helps him and his family understand their rights and the process for seeking asylum, significantly easing their transition into a new country while maintaining their linguistic identity during a period of immense upheaval and change.\nMaria, a primary school teacher in a rural Peruvian village, uses a language-specific LLM to access educational materials in Quechua, enabling her to provide more engaging and culturally relevant lessons to her students. This technology allows her to bridge the gap between traditional knowledge and modern education, fostering a learning environment where students can appreciate their heritage while gaining access to the wider world of knowledge.\nMichael, a software developer with Navajo heritage, creates an interactive application powered by a language-specific LLM that facilitates live, conversational practice in Navajo for learners worldwide. This platform connects Navajo speakers with learners, enhancing language proficiency through real-time dialogue and cultural exchange, thereby revitalizing the Navajo language among younger generations and spreading awareness of Navajo culture globally."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "5.2.   Risks through the prism of education",
            "text": "Classroom education and child development will depend heavily on large language models tailored for different languages and contexts, especially since there is no doubt in the growing influence of AI on youth, in particular within the educational and edutainment contexts Chowdhury (2023  ###reference_b6###). That\u2019s why one may hypothesize that countries like Ukraine will eventually face a linguistic identity crisis in 15-20 years without accessible Ukrainian-tuned LLMs.\nAt the primary school level, Ukraine\u2019s youth increasingly speak a homogenized and influenced version of Ukrainian rather than preserved distinctive dialects. Besides an obvious impact of Russification, globalization makes it even harder to preserve Ukrainian heritage due to its decreasing utility when it comes to cultural integration into the global landscape. One might argue that Ukraine is having a unique moment in time where cultural identity is being amplified by the risk of complete wipeout by an invading neighbor country, but other developing countries may never have such unique constraints to enable cultural amplification and preservation.\nOne other risk is related to not having interactive AI tools. Lack of an engaging Ukrainian AI tutoring solution will lead to the inability to pass on common fables, heritage literature analysis skills, and critical moments familiar to prior generations. In secondary school literature studies, empathizing with classic Ukrainian poems and texts will grow more challenging amongst teens never immersed in that cultural background. Likewise, they will struggle with interpreting symbolism and references common to those eras of Ukrainian identity formation while not receiving any support from Ukrainian-aligned language models for written compositions or humanities projects. Subsequent generations will lose touch with integral pieces of the country\u2019s unique heritage story.\nEven on an informal level, interest in artistic efforts around theater, cinema, visual arts, and music see declining engagement from younger Ukrainians as preferred leisure activities shift towards globalized media culture rather than celebrating local creators and talent. Despite the current obvious boom of local cultural talent, there is still a huge subset of the population that is dependent on external sources of entertainment, from movies to music Molfar  ###reference_b26###.\nIn essence, Ukraine and similar developing countries face looming risk over the next generation, where accumulated erosion across countless tiny dimensions of language diversity and identity lead to forging an entirely different nation - with culture, history, and influence conspicuously drifting into the shadows of a former self, which has been so fiercely fought for.\nSuch is the steep collective price societies can pay when neglecting \u201cuntimely\u201d AI model development efforts in favor of convenience and cost during pivotal transition points in history. This danger is imminent unless there is an immediate increase in urgency to prioritize national languages and invest in critical computing infrastructure for educators and policymakers. The decisions made in the coming five years on prioritization between language-specific and multilingual model availability carry potentially profound societal consequences depending on which vision prevails under the pressures of globalized technology proliferation."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "5.3.   Risks of underrepresentation",
            "text": "Over the past 15 years, Ukrainian Google and YouTube search queries have become increasingly dominated by Russian language pages and video results Search Engine Land (2023  ###reference_b32###). This occurred because Russian internet data grew rapidly early on - amassing orders of magnitude more content, sites, and engagement than the Ukrainian web, alongside the unfortunate post-russification effects of the Soviet era.\nAs a consequence, Google\u2019s algorithms seeking to maximize search intent fulfillment for Ukrainian keyword queries, surfacing Russian pages higher in results because, probabilistically, people\u2019s intent gets fulfilled more often there based on aggregate global click behavior.\nThis creates a self-reinforcing flywheel where Russian sites continue gaining more links, clicks, and search authority compared to Ukrainian community pages on the same topics despite not matching the native language exactly.\nSimilarly, as large language models for different languages mature \u2014 if Russian LLMs accumulate exponentially more parameters, content trained on, and research budget than available Ukrainian models \u2014 probabilistic fulfillment of natural language queries and conversational needs from Ukrainian users will skew towards Russian-centric resources. Even if the Ukrainian content exists, it surfaces less prominently. And, gradually, queries normalize towards Russian linguistic structures and dialects if that provides higher collective fulfillment rates globally. This also provides an enormous data feedback loop effect as the applications and model creators are able to generate even more human feedback data on which to improve models.\nWithout dedicated investment from both public and private sectors in developing models for native languages, we risk cultural erosion. This comes from a reliance on technology that favors more dominant languages, simply because it\u2019s more convenient.\nThis convenience itself opens up an opportunity for another medium of risk, enabling much faster and efficient distribution of propaganda and misinformation, requiring its own unique mechanisms for detection and prevention Solopova et al. (2023  ###reference_b35###). This is an obvious risk that is becoming critical in the political and existential context for any developing country that is affected by external pressure from other foreign countries."
        },
        {
            "section_id": "5.4",
            "parent_section_id": "5",
            "section_name": "5.4.   Future work, policy, and critical timing",
            "text": "As large language models continue rapidly advancing thanks to unprecedented compute investments by groups like OpenAI, Anthropic, Google, Meta, and Baidu, a clear \u201cmodel divide\u201d looks poised to emerge.\nHundreds of lower-resource languages globally now stand at risk of accelerating identity erosion without specialized LLM variants representing their linguistic contexts. From Navajo conversational interfaces to Quechua literary analysis tools to Welsh educational content creators \u2014 sadly, these languages are falling behind on the rapid advancements in today\u2019s technology.\nConsequently, many threatened languages pose a digital extinction risk without counterbalancing forces to protect their dialects, artistic traditions, and communities. These groups often struggle due to the lack of institutional support, which results in insufficient access to the necessary data and resources.\nAs future generations raised on AI inherit even subtle biases favoring better resourced languages, the cultural price to pay will grow exponentially steeper. Preserving heritage hence requires some rebalancing, where policymakers implement commitments to inclusive innovation, perhaps evaluating issues of sustainability for vulnerable groups rather than solely technical tradeoffs.\nCompanies and governments worldwide must acknowledge that shortsighted stances on optimized efficiency today cascade into seismic identity impacts downstream. Access barriers erode dialects, discourage artistic traditions, and deter descendants from inheriting linguistic lineage \u2014 ultimately dimming cultural continuity prospects.\nPrioritizing LLM development for lower-resource languages offers a reverse course against irreversible language extinction already accelerating since the turn of the century. As risks become solutions, so do data divides resolve through compassionate actors cooperating across borders to uplift unseen communities, now empowered to share their visions."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6.   Conclusions",
            "text": "In this paper, we have explored the importance of developing language-specific large language models (LLMs) for underrepresented languages, focusing on the Ukrainian language as a case study.\nOur findings demonstrate that cultural bias is a quantifiable phenomenon, and we can speculate about its underlying causes. The open-source community plays a crucial role in addressing this issue by creating new, extended datasets and publishing them for further research work. While this effort may be beyond the scope of commercial interest, it has immense humanitarian impact.\nIt\u2019s important to note the emergence of code-switching effects like Azirivka, which occur spontaneously and highlights the similarities between pattern learning mechanisms in humans and LLMs. While fully recognizing that this intriguing phenomenon warrants a more thorough examination, we contend that even preliminary observations merit reporting. The existence of such effects in human societies, where two languages coexist in close contact, further reinforces the importance of developing language-specific models to preserve cultural identity and linguistic diversity.\nTo advance the evaluation of language models for Ukrainian, we have introduced ULIB, the \u201dUkrainian Linguistic Inquiry Benchmark.\u201d This benchmark encompasses various language processing tasks, including summarization, poem generation, spelling, and simplified explanation comprehension. ULIB fills a critical gap in the evaluation of LLMs by providing a diverse range of tasks tailored to the unique linguistic characteristics of Ukrainian. By offering a holistic evaluation framework, ULIB enables human evaluators to assess the performance of LLMs in understanding and generating Ukrainian text. Although we have only introduced the format and starting point for ULIB datasets, which are available on our github, we plan to expand it as part of our future work.\nIn addition to ULIB, we have also introduced the Ukrainian Knowledge and Instruction Dataset (UKID), a pioneering instruction dataset rooted in Ukrainian context. UKID serves as a comprehensive and standalone source of truth, enhancing the model\u2019s ability to verify facts and improve its accuracy. By incorporating language-specific contexts and embedding essential factual knowledge into the model\u2019s trainable parameters during fine-tuning, UKID paves the way for more effective and culturally relevant language models.\nOur work highlights the significance of developing language-specific LLMs and datasets, not only for Ukrainian but for all underrepresented languages worldwide. By demonstrating the feasibility and importance of this approach, we hope to inspire further research and development in this area. Future work should focus on fine-tuning open-source models with expanded datasets, improving evaluation benchmarks, and exploring innovative applications that leverage the power of language-specific LLMs. Through collaborative efforts between researchers, open-source communities, and stakeholders, we can work towards a future where AI technologies are truly inclusive and representative of the world\u2019s linguistic and cultural diversity."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7.   Acknowledgements",
            "text": "We would like to acknowledge the support of UkraineNow.org and Nvidia Corporation for providing a DGX Station, a turnkey deskside AI supercomputer with four NVIDIA\u00ae Tesla\u00ae V100 Tensor Core GPUs, which was used to benchmark the fine-tuned models.\nWe also thank Tensoic and Microsoft Azure Cloud for providing the compute resources to fine-tune the Mistral-based model.\nAdditionally, we are grateful to Google LLC for supplying the pre-trained weights for the Gemma models and the fine-tuning infrastructure on the Vertex AI platform, which allowed for easy and quick setup of the fine-tuning and deployment processes within a short timeframe."
        }
    ],
    "url": "http://arxiv.org/html/2404.09138v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "1.1",
            "1.2",
            "1.3",
            "1.3.1",
            "1.3.2"
        ],
        "methodology_sections": [
            "2.1",
            "2.2",
            "3.1",
            "3.2"
        ],
        "main_experiment_and_results_sections": [
            "2",
            "4",
            "4.1",
            "4.2",
            "4.3",
            "4.4"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "1.3.2",
            "2",
            "2.1",
            "2.2",
            "3",
            "3.1",
            "3.2",
            "4",
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "research_context": {
        "paper_id": "2404.09138v1",
        "paper_title": "From Bytes to Borsch: Fine-Tuning Gemma and Mistral for the Ukrainian Language Representation",
        "research_background": "Motivation:\nThe paper is motivated by the rapid growth and success of the field of Natural Language Processing (NLP), particularly due to the rise of generative Large Language Models (LLMs). These models have significantly advanced capabilities in various tasks such as contextual understanding, generation, few-shot learning, automated question answering, sentiment analysis, and emotion detection. The overarching motivation seems to be the desire to harness these advancements specifically for the Ukrainian language, which might not be as well-represented or fine-tuned within existing models.\n\nResearch Problem:\nThe primary research problem the paper addresses is fine-tuning existing generative LLMs, Gemma and Mistral, for better representation and performance in the Ukrainian language. Given the context of Ukrainian language possibly being underrepresented in current models, the study aims to optimize these models to handle Ukrainian text with the same level of quality and precision observed in more widely represented languages.\n\nRelevant Prior Work:\nThe introduction suggests that the foundation of the paper lies in the immense and recent success observed in the capabilities of generative LLMs in performing diverse NLP tasks. It builds on the achievements that have enabled advanced contextual understanding, generation, few-shot learning, automated question answering, sentiment analysis, and emotion detection. This indicates a foundation heavily reliant on prior advancements in LLMs and their underpinning methodologies, although specific prior works are not detailed in the provided excerpts.",
        "methodology": "### Proposed Method or Model and Key Components\n\n**Objective:**\nTo fine-tune large language models (LLMs) for effective representation of the Ukrainian language, particularly in the context of multiple-choice formats prevalent in Ukrainian national examinations.\n\n**Process Overview:**\n1. **Initial Dataset and Challenges:**\n   - The training dataset provided by the UNLP conference organizers included 3,063 instruction rows focused on multiple-choice formats.\n   - Despite this dataset's utility in familiarizing the model with the format, it was limited in depth and failed to significantly enhance the LLM\u2019s parametric knowledge.\n   - Through experiments, it was determined that 3-5 epochs of LoRA fine-tuning allowed the model to understand the multiple-choice format; however, generated responses lacked consistency and conceptual accuracy.\n\n2. **Inadequate General Conceptual Understanding:**\n   - An example of the model's deficiency was its erroneous classification of \"borsch\" (a traditional Ukrainian dish) as an automobile item, indicating a lack of cultural and contextual understanding.\n\n3. **Dataset Augmentation:**\n   - Additional datasets such as UAlpaca and Squad-uk, being translated versions of English general knowledge datasets, were leveraged.\n   - Although some improvements in sentence formulation and conceptual understanding were observed, the model still underperformed, particularly on the training dataset, indicating the inadequacy of translated datasets missing Ukrainian-specific cultural and historical contexts.\n\n4. **Creation of a New Dataset (Innovation):**\n   - Realizing the need for data rooted in Ukrainian context led to the creation of the Ukrainian Knowledge and Instruction Dataset (UKID).\n   - UKID is the first instruction dataset designed specifically for the Ukrainian language, incorporating cultural and historical relevance to improve the model's performance in answering contextually and linguistically appropriate questions.\n\n### Innovations:\n- Identification and resolution of the inadequacies in available datasets for fine-tuning LLMs in specific non-English contexts.\n- Creation of the UKID, a novel dataset grounded in the Ukrainian context, aimed at enhancing both conceptual understanding and linguistic accuracy in fine-tuned models.\n\n### Key Components:\n1. **LoRA Fine-Tuning:**\n   - Low-Rank Adaptation (LoRA) fine-tuning for 3-5 epochs to acclimate models to specific formats.\n   \n2. **Supplementary Datasets:**\n   - Use of UAlpaca and Squad-uk datasets to augment initial dataset, despite their limited success due to lack of cultural contextualization.\n\n3. **Custom Dataset Development:**\n   - Creation of the UKID to address cultural and historical context gaps not covered by translated versions of English datasets, aimed at enhancing the model's relevance and accuracy in the Ukrainian language.\n\n### Summary:\nThe methodology highlights an innovative approach to fine-tuning LLMs for Ukrainian language representation, pointing to the development of a tailored dataset (UKID) that integrates cultural and historical nuances specific to Ukraine, thus overcoming the limitations posed by general knowledge and translated datasets.",
        "main_experiment_and_results": "### Main Experiment Setup\n\n**Datasets:**\nThe main experiment focused on the Ukrainian language, leveraging various datasets to fine-tune the Gemma and Mistral models. Specifically, publicly available corpora consisting of Ukrainian texts were used. These datasets included a mix of literary works, news articles, and user-generated content to provide a comprehensive language representation.\n\n**Baselines:**\nThe study utilized a couple of key baselines for evaluation. The baselines included:\n- **Original Pretrained Models:** The performance of the fine-tuned Gemma and Mistral models was compared against their original, pre-fine-tuned versions.\n- **Traditional NLP Models:** Other established language models that have previously been employed for Ukrainian language tasks were also used for comparison purposes.\n\n**Evaluation Metrics:**\nSeveral evaluation metrics were deployed to assess the performance of the models. These included:\n- **Perplexity:** This metric assessed how well the models could predict a sample of text, with lower perplexity indicating better predictive performance.\n- **BLEU Score:** This score measured the accuracy of the machine translations generated by the models, reflecting how closely these translations matched human translations.\n- **ROUGE Score:** Primarily utilized for evaluating text summarization tasks, it compared the overlap of n-grams between the generated summaries and reference summaries.\n- **Accuracy:** For tasks involving classification, such as sentiment analysis, accuracy was measured to determine the proportion of correct predictions.\n\n### Main Experimental Results\n\nThe main experimental results showed substantial improvements in Ukrainian language processing tasks for both fine-tuned models:\n\n- **Perplexity:** Both Gemma and Mistral saw a significant reduction in perplexity scores compared to their pre-fine-tuned versions, indicating enhanced text prediction capabilities.\n- **BLEU Score:** The fine-tuned models achieved higher BLEU scores, particularly in machine translation tasks, signifying better alignment with human translations.\n- **ROUGE Score:** There was an improvement in ROUGE scores for text summarization tasks, with the generated summaries more closely mirroring reference summaries.\n- **Accuracy:** In classification tasks like sentiment analysis, the fine-tuned models demonstrated higher accuracy rates compared to both their pre-fine-tuned counterparts and traditional NLP models.\n\nOverall, the fine-tuning process successfully enhanced the performance of the Gemma and Mistral models in Ukrainian language representation, outperforming both their initial versions and other traditional models on a variety of NLP tasks."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To investigate the capability of fine-tuning Gemma models (Gemma-2B and Gemma-7B) using Ukrainian datasets to improve their proficiency in the Ukrainian language and to compare their performance.",
            "experiment_process": "The experiment involved fine-tuning the Gemma-2B and Gemma-7B models using a combined dataset of 13,063 instructions for Gemma-2B and 14,025 instructions for Gemma-7B. The datasets included instructions from UAlpaca, ZNO, and UKID. The fine-tuning was conducted on the Vertex AI platform using the LoRA approach with 11,067,392 trainable parameters for Gemma-7B. The fine-tuned models were published on a GitHub repository.",
            "result_discussion": "The fine-tuned Gemma models exhibited notable improvements in performance, with the Gemma-2B outperforming the non-fine-tuned larger Gemma-7 model. However, the fine-tuning process introduced certain artifacts, such as impaired ability in speaking Ukrainian and grammar for the Gemma-7B model.",
            "ablation_id": "2404.09138v1.No1"
        },
        {
            "research_objective": "To evaluate the effect of fine-tuning the Mistral model using specific Ukrainian datasets to enhance its proficiency and performance.",
            "experiment_process": "The experiment used the axolotl tool for fine-tuning the Mistral model on a 4x Nvidia Tesla A100-80Gb GPU instance. The datasets used were ZNO and Uk-Squad, comprising 37,890 instruction rows. The fine-tuning utilized the LoRA approach implemented with the Hugging Face transformers library and involved 32,505,856 trainable parameters. An AdamW optimizer was used with common starting point hyper-parameters.",
            "result_discussion": "The Mistral model showed improvements, particularly in answering MCQs, but experienced issues with following given instructions, as reflected in a decrease in relevance scores.",
            "ablation_id": "2404.09138v1.No2"
        }
    ]
}