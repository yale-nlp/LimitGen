{
    "title": "Self-Consistency Boosts Calibration for Math Reasoning",
    "abstract": "Calibration, which establishes the correlation between accuracy and model confidence, is important for LLM development.\nWe design three off-the-shelf calibration methods based on self-consistency Wang et al. (2022) for math reasoning tasks.\nEvaluation on two popular benchmarks (GSM8K and MathQA) using strong open-source LLMs (Mistral and LLaMA2), our methods better bridge model confidence and accuracy than existing methods based on p(True) Kadavath et al. (2022) or logit Guo et al. (2017).",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Mathematical reasoning tasks Cobbe et al. (2021  ###reference_b4###); Hendrycks et al. (2021  ###reference_b7###); Amini et al. (2019  ###reference_b2###) involve mapping a question into a series of equations, which are then solved to obtain the final answer.\nMath reasoning has long been recognized challenging.\nExisting solutions propose to map input questions into equations via semantic parsing Matsuzaki et al. (2017  ###reference_b16###); Hopkins et al. (2017  ###reference_b8###) or AST decoding Li et al. (2019  ###reference_b13###); Qin et al. (2021  ###reference_b18###); Wu et al. (2021  ###reference_b24###).\nYet, the performance can degradate dramatically even with slight changes to the questions Patel et al. (2021  ###reference_b17###); Li et al. (2022  ###reference_b14###).\nRecently, large language models (LLM, Achiam et al. 2023  ###reference_b1###; Touvron et al. 2023  ###reference_b21###; Jiang et al. 2024  ###reference_b10###) have shown great potential for solving many math reasoning tasks, even though they are not specifically trained on these tasks.\nFor instance, with chain-of-thought prompting Wei et al. (2022  ###reference_b23###) and self-consistency Wang et al. (2022  ###reference_b22###), open-source LLMs, such as Mixtral 87B Jiang et al. (2024  ###reference_b10###), can reach an accuracy of around 80% on the GSM8K benchmark Cobbe et al. (2021  ###reference_b4###).\nOn the other hand, conventional pretrained models (e.g., T5 Raffel et al. (2020  ###reference_b19###)) that are specifically finetuned on the GSM8K training set can only report accuracies around 10% to 20% Shridhar et al. (2023  ###reference_b20###); Magister et al. (2023  ###reference_b15###).\nHowever, LLMs lack adequate calibration out of the box \u2013 the probabilities of model predictions are often poorly aligned with the actual accuracy Xiong et al. (2023  ###reference_b25###); Chen et al. (2023  ###reference_b3###).\nCalibration is important for LLM development, as a well-calibrated LLM can precisely tell how likely its responses are correct or not.\nWith such information, LLM developers can take multiple options to handle low-confidence responses, such as letting the LLM refuse to answer or keep resampling until a confident response is produced.\nIn this work, we propose calibration methods based on self-consistency Wang et al. (2022  ###reference_b22###) for math reasoning tasks.\nSelf-consistency performs clustering over multiple LLM samples before picking one from the largest cluster as the response to each input query.\nHere we consider several ways to estimate model confidence using the clustering results: cluster size that estimates how many samples agree with the selected one, cluster number that measures to what extent samples disagree with each other, and pairwise comparison that captures relative differences between pairs of clusters.\nWe conduct experiments using strong open-source LLMs:\nMistral Jiang et al. (2023  ###reference_b9###, 2024  ###reference_b10###) and LLaMA2 Touvron et al. (2023  ###reference_b21###) series models with\u2009/\u2009without being aligned with instructions.\nResults on GSM8K Cobbe et al. (2021  ###reference_b4###) and MathQA Amini et al. (2019  ###reference_b2###) show that all our methods better calibrate these models than exiting popular methods, such as p(True) Kadavath et al. (2022  ###reference_b11###) and logit Guo et al. (2017  ###reference_b6###) over the whole reasoning path or target answer span only."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Preview: Self-Consistency with CoT Prompting",
            "text": "For math reasoning, there are usually multiple trajectories to reach the final solution.\nTo replicate this process, Wang et al. (2022  ###reference_b22###) initially sample various reasoning paths  from the LLM given input  with Chain-of-Thought (CoT) prompting.111Here we follow common practice to adopt demonstrations with rationales for pretrained only models (e.g., Mistral-7B) and use \u201cLet\u2019s think step by step\u201d Kojima et al. (2022  ###reference_b12###) for instruction-tuned models (e.g., Mistral-7B-Inst).\nThen, the answers  are extracted from the paths,\nand the most consistent answer (the one win by majority vote among the answers) is selected as the final answer :\nwhere ,  denote the -th sampled reasoning path and its corresponding answer, respectively."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Calibration using Self-Consistency",
            "text": "After performing self-consistency on input  using , we obtain a set of clusters  with each cluster  comprising  sampled responses with the same answers.\nWe design the following strategies, tailored to the characteristics of these clusters, to estimate the confidence of .\nWe initially consider the Cluster Number .\nThis is motivated by the finding of previous work Wang et al. (2022  ###reference_b22###); Xiong et al. (2023  ###reference_b25###): LLMs tend to generate consistent answers when they are confident about their predictions, and thus the cluster number (number of distinct answers) tends to be small.\nWe further divide the cluster number by the sample size  to normalize the score into the range of , before reversing it by \u201c\u201d:\nIn a similar vein, we adopt the Cluster Size: the number of samples (e.g., ) within a specific cluster (e.g., ).\nAgain, we compute its proportion relative to the total sample size to normalize the score into the range :\nIn contrast to the cluster number, the cluster size is more universally applicable across diverse prompts, as the cluster number can easily become ineffective when the output space of an LLM is restricted, such as when options for a question are provided.\nThe Cluster Number and Cluster Size primarily consider the number of distinct answers and the number of sampled paths within a single cluster, respectively.\nThey both overlook the information by comparing different clusters.\nFor example, they may fail to consider the situation when the sizes of the top-ranked clusters are close. Consequently, we introduce the Pairwise Comparison method, which computes the winning rate of the chosen cluster () against each of the remaining clusters:\nwhere  represents the winning rate of selected cluster  against another cluster ."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "###table_1### We conduct experiments on two popular math reasoning benchmarks of different type of questions, GSM8K Cobbe et al. (2021  ###reference_b4###) and MathQA Amini et al. (2019  ###reference_b2###).\nParticularly, GSM8K comprises 1,319 linguistically diverse grade school math word problems for testing.\nOn the other hand, MathQA offers 2,985 multiple-choice math word problems for evaluation.\nWe adopt Brier Score and Expected Calibration Error (ECE) as evaluating metrics following common practice Geng et al. (2023  ###reference_b5###).\nGiven instances  and their corresponding LLM predictions , ECE is computed by first binning the predictions into  intervals based on their LLM confidence levels (e.g., ).\nFor each bin (e.g. ), it then calculates the accuracy (acc) and the average confidence (conf):\nwhere  is the number of samples in bin .\nFinally, the difference between accuracy and confidence is averaged across all bins to obtain the ECE score:\nAs another popular metric, Brier score is similar to ECE but conducted at the instance level:\nBoth metrics range from 0 to 1 with lower values indicating better calibration.\nWe take Brier score as the main metric, as it is more robust to unbalanced distribution across bins (e.g. instances concentrate to one or two bins).\nWe conduct experiments on LLaMA2 and Mistral-family models and investigate both pretrained or instruction-tuned variations.\nWe use nucleus sampling to obtain  samples by default for each instance and use temperatures of 0.6 / 1.0 for all pretrained / instruction-tuned models.\nWe take the three representative baselines below for comparison:\nlogit w/ Path: It averages the probabilities of the tokens from the whole path to estimate the confidence of each prediction.\nlogit w/ Answer: It is similar to logit w/ Path but only consider the tokens from the predicted answer span.\np(True): It asks the LLM itself to classify its prediction as True or False. Then, it takes the predicted probability of True as its confidence. We follow Kadavath et al. (2022  ###reference_b11###) to construct 8-shot demonstrations for prompting pretrained models but directly use instruction for instruction-tuned models.\nTable 1  ###reference_### presents the main results obtained from both benchmarks using Mistral-family models. p(True) performs best among the baselines, echoing the findings of Kadavath et al. (2022  ###reference_b11###). However, due to its reliance on prompt design and in-context examples to aid the LLM to classify its predictions, it can be challenging to construct effective demonstrations or instructions.\nIn general, self-consistency-based methods surpass baselines in most cases regarding Brier and ECE, validating the efficacy of employing self-consistency features for estimating model confidence. We also note that baselines can occasionally yield impressive ECE scores (p(True) on GSM8K with Mixtral-87B). However, we observe that this is attributed to the concentration of most samples in just a few bins (e.g., Figure 1  ###reference_###), leading to unreliable measurements. Nevertheless, our approaches still exhibit strong performance in terms of ECE scores across various settings.\nAmong the self-consistency-based methods,  yields better ECE results on GSM8K, while  achieves the highest Brier score.\nConversely, for MathQA,  performs significantly worse than the other two.\nThis is because MathQA is a multi-choice task, and thus the cluster number of LLM answers is strictly limited by the provided choices.\nIn conclusion,  demonstrates greater generality across diverse settings, but  and  do offer improved estimation in certain cases.\nPrevious research Wang et al. (2022  ###reference_b22###) has demonstrated that the sample size  can significantly affect the accuracy of self-consistency. When  increases, the model performance initially continues to improve before stabilizing once  reaches a sufficient level. Therefore, we take Mixtral-87B-Inst as a case study to examine the impact of  on calibration.\nAs illustrated in Figure 2  ###reference_###, the Brier scores for all our methods initially decline and then remain constant as  grows. For  and ,  is adequate for accurate estimation. In contrast,  requires a larger , indicating that the cluster number is more susceptible to the randomness of sampling.\nWe finally explore the associations between model performance (Accuracy) and calibration. Figure 3  ###reference_### showcases the results on instruction-tuned LLaMA2 and Mistral series models, arranged in ascending order based on their performance.\nWe generally observe a positively correlated trend between calibration (lower the better) and performance (higher the better) among the studied models.\nThis observation indicates that more powerful models also exhibit enhanced calibration, echoing the findings of Kadavath et al. (2022  ###reference_b11###). This phenomenon can be attributed to the fact that when a tested LLM is stronger, it is capable of generating more reasonable and consistent responses, leading to improved calibration."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Setup",
            "text": "We conduct experiments on two popular math reasoning benchmarks of different type of questions, GSM8K Cobbe et al. (2021  ###reference_b4###  ###reference_b4###) and MathQA Amini et al. (2019  ###reference_b2###  ###reference_b2###).\nParticularly, GSM8K comprises 1,319 linguistically diverse grade school math word problems for testing.\nOn the other hand, MathQA offers 2,985 multiple-choice math word problems for evaluation.\nWe adopt Brier Score and Expected Calibration Error (ECE) as evaluating metrics following common practice Geng et al. (2023  ###reference_b5###  ###reference_b5###).\nGiven instances  and their corresponding LLM predictions , ECE is computed by first binning the predictions into  intervals based on their LLM confidence levels (e.g., ).\nFor each bin (e.g. ), it then calculates the accuracy (acc) and the average confidence (conf):\nwhere  is the number of samples in bin .\nFinally, the difference between accuracy and confidence is averaged across all bins to obtain the ECE score:\nAs another popular metric, Brier score is similar to ECE but conducted at the instance level:\nBoth metrics range from 0 to 1 with lower values indicating better calibration.\nWe take Brier score as the main metric, as it is more robust to unbalanced distribution across bins (e.g. instances concentrate to one or two bins).\nWe conduct experiments on LLaMA2 and Mistral-family models and investigate both pretrained or instruction-tuned variations.\nWe use nucleus sampling to obtain  samples by default for each instance and use temperatures of 0.6 / 1.0 for all pretrained / instruction-tuned models.\nWe take the three representative baselines below for comparison:\nlogit w/ Path: It averages the probabilities of the tokens from the whole path to estimate the confidence of each prediction.\nlogit w/ Answer: It is similar to logit w/ Path but only consider the tokens from the predicted answer span.\np(True): It asks the LLM itself to classify its prediction as True or False. Then, it takes the predicted probability of True as its confidence. We follow Kadavath et al. (2022  ###reference_b11###  ###reference_b11###) to construct 8-shot demonstrations for prompting pretrained models but directly use instruction for instruction-tuned models."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we extend the widely-used inference strategy, self-consistency, to the field of calibration. Specifically, we develop three off-the-shelf calibration methods based on self-consistency for math reasoning tasks. Compared to conventional methods (p(True) and logit), our approaches yield significantly improved ECE and Brier scores on popular GSM8K and MathQA datasets.\nFuture research directions include designing more effective calibration methods, leveraging richer features and employing more strategies (e.g., temperature scaling Guo et al. (2017  ###reference_b6###)) to enhance calibration performance.\nOur ultimate goal is to construct reliable and honest LLMs with the help of accurate confidence estimation."
        }
    ],
    "appendix": [],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T1.16\">\n<tr class=\"ltx_tr\" id=\"S4.T1.2.2\">\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T1.2.2.3\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T1.2.2.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" id=\"S4.T1.2.2.5\">Mistral-7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" id=\"S4.T1.2.2.6\">Mistral-7B-Inst</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" id=\"S4.T1.1.1.1\">Mixtral-87B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" id=\"S4.T1.2.2.2\">Mixtral-87B-Inst</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.10.10\">\n<td class=\"ltx_td\" id=\"S4.T1.10.10.9\"></td>\n<td class=\"ltx_td\" id=\"S4.T1.10.10.10\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.3.3.1\">ECE \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.4.4.2\">Brier \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.5.5.3\">ECE \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.6.4\">Brier \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.7.7.5\">ECE \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.8.8.6\">Brier \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.9.9.7\">ECE \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.10.10.8\">Brier \n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.16.17\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.16.17.1\" rowspan=\"7\"><span class=\"ltx_text\" id=\"S4.T1.16.17.1.1\">GSM8K</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.16.17.2\">logit w/ Path</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.16.17.3\">0.394</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.16.17.4\">0.399</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.16.17.5\">0.414</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.16.17.6\">0.414</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.16.17.7\">0.178</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.16.17.8\">0.265</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.16.17.9\">0.233</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.16.17.10\">0.252</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.16.18\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.16.18.1\">logit w/ Answer</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.18.2\">0.505</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.18.3\">0.488</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.18.4\">0.467</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.18.5\">0.458</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.18.6\">0.307</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.18.7\">0.312</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.18.8\">0.236</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.18.9\">0.238</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.16.19\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.16.19.1\">p(True)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.19.2\">0.127</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.19.3\">0.267</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.19.4\">0.406</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.19.5\">0.407</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.19.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.16.19.6.1\">0.070</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.19.7\">0.201</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.19.8\">0.195</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.19.9\">0.198</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.16.20\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.16.20.1\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.16.20.1.1\">Self-Consistency</em></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.20.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.20.3\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.20.4\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.20.5\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.20.6\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.20.7\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.20.8\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.20.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.11.11\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.11.11.1\">\u00a0\u00a0\u00a0\u00a0w/ \n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.11.11.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.11.11.2.1\">0.092</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.11.11.3\">0.186</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.11.11.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.11.11.4.1\">0.125</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.11.11.5\">0.182</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.11.11.6\">0.136</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.11.11.7\">0.157</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.11.11.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.11.11.8.1\">0.075</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.11.11.9\">0.092</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.12.12\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.12.12.1\">\u00a0\u00a0\u00a0\u00a0w/ \n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.12.12.2\">0.148</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.12.12.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.12.12.3.1\">0.185</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.12.12.4\">0.163</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.12.12.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.12.12.5.1\">0.180</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.12.12.6\">0.173</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.12.12.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.12.12.7.1\">0.156</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.12.12.8\">0.085</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.12.12.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.12.12.9.1\">0.086</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.13.13\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.13.13.1\">\u00a0\u00a0\u00a0\u00a0w/ \n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.2\">0.248</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.3\">0.229</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.4\">0.253</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.5\">0.226</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.6\">0.238</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.7\">0.194</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.8\">0.110</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.9\">0.096</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.16.21\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_tt\" id=\"S4.T1.16.21.1\" rowspan=\"7\"><span class=\"ltx_text\" id=\"S4.T1.16.21.1.1\">MathQA</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T1.16.21.2\">logit w/ Path</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.16.21.3\">0.500</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.16.21.4\">0.499</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.16.21.5\">0.539</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.16.21.6\">0.510</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.16.21.7\">0.333</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.16.21.8\">0.380</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.16.21.9\">0.364</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.16.21.10\">0.373</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.16.22\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.16.22.1\">logit w/ Answer</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.22.2\">0.356</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.22.3\">0.362</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.22.4\">0.291</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.22.5\">0.319</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.22.6\">0.266</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.22.7\">0.290</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.22.8\">0.220</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.22.9\">0.281</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.16.23\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.16.23.1\">p(True)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.23.2\">0.350</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.23.3\">0.309</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.23.4\">0.271</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.23.5\">0.317</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.23.6\">0.228</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.23.7\">0.253</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.23.8\">0.273</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.23.9\">0.272</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.16.24\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.16.24.1\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.16.24.1.1\">Self-Consistency</em></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.24.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.24.3\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.24.4\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.24.5\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.24.6\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.24.7\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.24.8\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.16.24.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.14.14\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.14.14.1\">\u00a0\u00a0\u00a0\u00a0w/ \n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.14.14.2\">0.331</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.14.14.3\">0.336</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.14.14.4\">0.374</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.14.14.5\">0.359</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.14.14.6\">0.143</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.14.14.7\">0.236</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.14.14.8\">0.128</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.14.14.9\">0.215</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.15.15\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.15.15.1\">\u00a0\u00a0\u00a0\u00a0w/ \n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.15.15.2\">0.091</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.15.15.3\">0.225</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.15.15.4\">0.114</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.15.15.5\">0.227</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.15.15.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.15.15.6.1\">0.080</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.15.15.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.15.15.7.1\">0.190</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.15.15.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.15.15.8.1\">0.035</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.15.15.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.15.15.9.1\">0.171</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.16.16\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.16.16.1\">\u00a0\u00a0\u00a0\u00a0w/ \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.16.16.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.16.16.2.1\">0.052</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.16.16.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.16.16.3.1\">0.220</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.16.16.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.16.16.4.1\">0.065</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.16.16.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.16.16.5.1\">0.219</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.16.16.6\">0.143</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.16.16.7\">0.203</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.16.16.8\">0.054</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.16.16.9\">0.174</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Main test results on GSM8K and MathQA when using Mistral family models. Specifically, -Inst indicates instruction-tuned models.</figcaption>\n</figure>",
            "capture": "Table 1: Main test results on GSM8K and MathQA when using Mistral family models. Specifically, -Inst indicates instruction-tuned models."
        }
    },
    "image_paths": {},
    "references": [
        {
            "1": {
                "title": "Gpt-4 technical report.",
                "author": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023.",
                "venue": "arXiv preprint arXiv:2303.08774.",
                "url": null
            }
        },
        {
            "2": {
                "title": "Mathqa: Towards interpretable math word problem solving with operation-based formalisms.",
                "author": "Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh Hajishirzi. 2019.",
                "venue": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 2357\u20132367.",
                "url": null
            }
        },
        {
            "3": {
                "title": "A close look into the calibration of pre-trained language models.",
                "author": "Yangyi Chen, Lifan Yuan, Ganqu Cui, Zhiyuan Liu, and Heng Ji. 2023.",
                "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1343\u20131367.",
                "url": null
            }
        },
        {
            "4": {
                "title": "Training verifiers to solve math word problems.",
                "author": "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. 2021.",
                "venue": "arXiv preprint arXiv:2110.14168.",
                "url": null
            }
        },
        {
            "5": {
                "title": "A survey of language model confidence estimation and calibration.",
                "author": "Jiahui Geng, Fengyu Cai, Yuxia Wang, Heinz Koeppl, Preslav Nakov, and Iryna Gurevych. 2023.",
                "venue": "arXiv preprint arXiv:2311.08298.",
                "url": null
            }
        },
        {
            "6": {
                "title": "On calibration of modern neural networks.",
                "author": "Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. 2017.",
                "venue": "In International conference on machine learning, pages 1321\u20131330. PMLR.",
                "url": null
            }
        },
        {
            "7": {
                "title": "Measuring mathematical problem solving with the math dataset.",
                "author": "Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021.",
                "venue": "In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2).",
                "url": null
            }
        },
        {
            "8": {
                "title": "Beyond sentential semantic parsing: Tackling the math sat with a cascade of tree transducers.",
                "author": "Mark Hopkins, Cristian Petrescu-Prahova, Roie Levin, Ronan Le Bras, Alvaro Herrasti, and Vidur Joshi. 2017.",
                "venue": "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 795\u2013804.",
                "url": null
            }
        },
        {
            "9": {
                "title": "Mistral 7b.",
                "author": "Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023.",
                "venue": "arXiv preprint arXiv:2310.06825.",
                "url": null
            }
        },
        {
            "10": {
                "title": "Mixtral of experts.",
                "author": "Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al. 2024.",
                "venue": "arXiv preprint arXiv:2401.04088.",
                "url": null
            }
        },
        {
            "11": {
                "title": "Language models (mostly) know what they know.",
                "author": "Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, et al. 2022.",
                "venue": "arXiv preprint arXiv:2207.05221.",
                "url": null
            }
        },
        {
            "12": {
                "title": "Large language models are zero-shot reasoners.",
                "author": "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022.",
                "venue": "Advances in neural information processing systems, 35:22199\u201322213.",
                "url": null
            }
        },
        {
            "13": {
                "title": "Modeling intra-relation in math word problems with different functional multi-head attentions.",
                "author": "Jierui Li, Lei Wang, Jipeng Zhang, Yan Wang, Bing Tian Dai, and Dongxiang Zhang. 2019.",
                "venue": "In Proceedings of the 57th annual meeting of the association for computational linguistics, pages 6162\u20136167.",
                "url": null
            }
        },
        {
            "14": {
                "title": "Seeking patterns, not just memorizing procedures: Contrastive learning for solving math word problems.",
                "author": "Zhongli Li, Wenxuan Zhang, Chao Yan, Qingyu Zhou, Chao Li, Hongzhi Liu, and Yunbo Cao. 2022.",
                "venue": "In Findings of the Association for Computational Linguistics: ACL 2022, pages 2486\u20132496.",
                "url": null
            }
        },
        {
            "15": {
                "title": "Teaching small language models to reason.",
                "author": "Lucie Charlotte Magister, Jonathan Mallinson, Jakub Adamek, Eric Malmi, and Aliaksei Severyn. 2023.",
                "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 1773\u20131781.",
                "url": null
            }
        },
        {
            "16": {
                "title": "Semantic parsing of pre-university math problems.",
                "author": "Takuya Matsuzaki, Takumi Ito, Hidenao Iwane, Hirokazu Anai, and Noriko H Arai. 2017.",
                "venue": "In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2131\u20132141.",
                "url": null
            }
        },
        {
            "17": {
                "title": "Are nlp models really able to solve simple math word problems?",
                "author": "Arkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021.",
                "venue": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2080\u20132094.",
                "url": null
            }
        },
        {
            "18": {
                "title": "Neural-symbolic solver for math word problems with auxiliary tasks.",
                "author": "Jinghui Qin, Xiaodan Liang, Yining Hong, Jianheng Tang, and Liang Lin. 2021.",
                "venue": "In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 5870\u20135881.",
                "url": null
            }
        },
        {
            "19": {
                "title": "Exploring the limits of transfer learning with a unified text-to-text transformer.",
                "author": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020.",
                "venue": "Journal of machine learning research, 21(140):1\u201367.",
                "url": null
            }
        },
        {
            "20": {
                "title": "Distilling reasoning capabilities into smaller language models.",
                "author": "Kumar Shridhar, Alessandro Stolfo, and Mrinmaya Sachan. 2023.",
                "venue": "In Findings of the Association for Computational Linguistics: ACL 2023, pages 7059\u20137073.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Llama 2: Open foundation and fine-tuned chat models.",
                "author": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023.",
                "venue": "arXiv preprint arXiv:2307.09288.",
                "url": null
            }
        },
        {
            "22": {
                "title": "Self-consistency improves chain of thought reasoning in language models.",
                "author": "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022.",
                "venue": "In The Eleventh International Conference on Learning Representations.",
                "url": null
            }
        },
        {
            "23": {
                "title": "Chain-of-thought prompting elicits reasoning in large language models.",
                "author": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022.",
                "venue": "Advances in neural information processing systems, 35:24824\u201324837.",
                "url": null
            }
        },
        {
            "24": {
                "title": "Math word problem solving with explicit numerical values.",
                "author": "Qinzhuo Wu, Qi Zhang, Zhongyu Wei, and Xuan-Jing Huang. 2021.",
                "venue": "In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 5859\u20135869.",
                "url": null
            }
        },
        {
            "25": {
                "title": "Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms.",
                "author": "Miao Xiong, Zhiyuan Hu, Xinyang Lu, YIFEI LI, Jie Fu, Junxian He, and Bryan Hooi. 2023.",
                "venue": "In The Twelfth International Conference on Learning Representations.",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.09849v1",
    "segmentation": {
        "research_background_sections": [
            "1"
        ],
        "methodology_sections": [
            "2",
            "3"
        ],
        "main_experiment_and_results_sections": [
            "4.1",
            "4.2"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4",
            "4.1",
            "4.2"
        ]
    },
    "research_context": {
        "paper_id": "2403.09849v1",
        "paper_title": "Self-Consistency Boosts Calibration for Math Reasoning",
        "research_background": "### Paper's Motivation\n\nThe motivation behind this paper is driven by the recognition of the challenges associated with mathematical reasoning tasks. Despite recent advancements with large language models (LLMs) showing impressive potential in accuracy, there remains a significant issue: these models often lack adequate calibration. This misalignment between prediction probabilities and actual accuracy can hinder the effective use of LLMs. Therefore, improving the calibration of these models is crucial for their development, enabling them to provide reliable confidence estimates about their responses.\n\n### Research Problem\n\nThe core research problem addressed by this paper is to improve the calibration of large language models in mathematical reasoning tasks. Specifically, the paper aims to develop methods that can better align the model\u2019s predicted probabilities with the actual accuracy of its responses. This involves finding effective ways to use self-consistency techniques to estimate model confidence and correctly calibrate LLM predictions.\n\n### Relevant Prior Work\n\nThe relevant prior work includes:\n\n1. **Mapping Questions into Equations:**\n   - Cobbe et al. (2021), Hendrycks et al. (2021), and Amini et al. (2019) focused on the challenge of mapping questions into a series of equations for solving mathematical reasoning tasks.\n   - Semantic parsing and AST decoding methods were explored by Matsuzaki et al. (2017), Hopkins et al. (2017), Li et al. (2019), Qin et al. (2021), and Wu et al. (2021).\n\n2. **Challenges with Minor Input Changes:**\n   - Patel et al. (2021) and Li et al. (2022) highlighted that the performance of existing solutions could degrade significantly with even slight changes to the questions.\n\n3. **Potential of Large Language Models:**\n   - Achiam et al. (2023), Touvron et al. (2023), and Jiang et al. (2024) demonstrated the promise of LLMs in solving math reasoning tasks, despite not being specifically trained for them.\n   - Techniques such as chain-of-thought prompting Wei et al. (2022) and self-consistency Wang et al. (2022) enabled models like Mixtral 87B Jiang et al. (2024) to achieve high accuracy on benchmarks like GSM8K Cobbe et al. (2021).\n\n4. **Shortcomings in Conventional Models:**\n   - Conventional pretrained models, such as T5, when finetuned specifically on the GSM8K training set, could only reach accuracies around 10% to 20% Raffel et al. (2020), Shridhar et al. (2023), and Magister et al. (2023).\n\n5. **Calibration Issues:**\n   - Previous studies by Xiong et al. (2023) and Chen et al. (2023) identified that LLMs often have poorly aligned prediction probabilities with actual accuracy, stressing the necessity for better calibration techniques.\n\n6. **Existing Calibration Methods:**\n   - Popular methods such as p(True) Kadavath et al. (2022) and logit-based calibration Guo et al. (2017) have been used to address calibration but may still not be optimal in the context of mathematical reasoning.\n\nBy leveraging these prior findings, the paper proposes new self-consistency-based calibration methods aiming to build on and improve upon existing approaches.",
        "methodology": "**Self-Consistency Boosts Calibration for Math Reasoning**\n\n**Methodology:**\n\nFor math reasoning, there are typically multiple routes to achieve the final solution. The methodology introduced by Wang et al. (2022) aims to mimic this process by utilizing multiple sampled reasoning paths generated by a Large Language Model (LLM) with Chain-of-Thought (CoT) prompting. Specifically, the steps are as follows:\n\n1. **Sampling Reasoning Paths**: Various reasoning trajectories are sampled from the LLM, given an input problem. This sampling is done using CoT prompting, which encourages the model to think and reason in steps.\n\n2. **Demonstrations and Rationales**: For pretrained-only models, such as Mistral-7B, demonstrations with rationales are adopted. For instruction-tuned models, like Mistral-7B-Inst, the phrase \"Let's think step by step\" from Kojima et al. (2022) is used to guide the model in generating reasoning steps.\n\n3. **Extracting Answers**: Each reasoning path culminates in an answer, which is then extracted.\n\n4. **Choosing the Most Consistent Answer**: Finally, the answer that appears most frequently among the sampled reasoning paths is selected as the final answer. This is achieved through a majority vote mechanism, where the reasoning path and its corresponding answer are noted, and the most consistent answer is chosen based on majority agreement.\n\nThis method leverages the idea that consistent answers across multiple reasoning paths are likely more accurate, thereby boosting the calibration and overall reliability of the math reasoning process.",
        "main_experiment_and_results": "## Main Experiment Setup\n\n### Datasets\n- **GSM8K**: Comprises 1,319 linguistically diverse grade school math word problems.\n- **MathQA**: Contains 2,985 multiple-choice math word problems.\n\n### Evaluation Metrics\n- **Brier Score**: Evaluated at the instance level and ranges from 0 to 1, with lower values indicating better calibration.\n- **Expected Calibration Error (ECE)**: Calculated by binning predictions based on their confidence levels and averaging the difference between accuracy and confidence across all bins. Lower values indicate better calibration.\n\n### Models and Techniques\n- **Models Used**: Experiments are conducted on LLaMA2 and Mistral-family models, including both pretrained and instruction-tuned variations.\n- **Sampling Method**: Nucleus sampling is used to obtain 10 samples per instance with temperatures of 0.6 for pretrained models and 1.0 for instruction-tuned models.\n\n### Baselines\n1. **logit w/ Path**: Averages probabilities of tokens from the whole path to estimate confidence.\n2. **logit w/ Answer**: Considers probabilities of tokens from the predicted answer span only.\n3. **p(True)**: Uses LLM itself to classify its prediction as True or False and takes the probability of True as confidence.\n\n### Experimental Setup\n- For comparing pretrained models, 8-shot demonstrations are constructed for prompting.\n- Instruction-tuned models are directly used with instructions.\n\n## Main Experimental Results\n\\[ Results were summarized in terms of the primary metrics (Brier score and ECE), model types (pretrained and instruction-tuned), and dataset performance (GSM8K and MathQA). The following outcomes were presented: \\]\n\n\\[ Insert specific numerical results, statistical significances, or comparative improvements over baselines here \\]\n\nConclusively, the experimental results indicate that the proposed self-consistency method boosts calibration effectiveness for math reasoning tasks according to both Brier Score and ECE, showing superior performance over the three representative baseline methods on the evaluated datasets. Detailed numerical results or specific model performance improvements are required to elaborate on these findings further."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "Investigate the effectiveness of self-consistency-based methods in enhancing the calibration of large language models (LLMs) for math reasoning tasks.",
            "experiment_process": "The experiments were conducted on two popular math reasoning benchmarks: GSM8K (1,319 diverse grade school math word problems) and MathQA (2,985 multiple-choice math word problems). The evaluation metrics used were Brier Score and Expected Calibration Error (ECE). Both pretrained and instruction-tuned variations of LLaMA2 and Mistral-family models were tested using nucleus sampling to obtain samples with temperatures of 0.6 for pretrained and 1.0 for instruction-tuned models. Three representative baselines were used for comparison: logit w/ Path, logit w/ Answer, and p(True).",
            "result_discussion": "Self-consistency-based methods generally outperformed the baselines concerning Brier Score and ECE, validating the efficacy of self-consistency features for estimating model confidence. While baseline methods sometimes achieved impressive ECE scores, this was often due to the concentration of samples in a few bins, leading to unreliable measurements. Among the self-consistency-based methods, one yielded better ECE results on GSM8K, and another achieved the highest Brier score, although the performance varied for MathQA due to its multi-choice nature. The study also found a positive correlation between model performance and calibration, indicating that stronger models tend to exhibit better calibration.",
            "ablation_id": "2403.09849v1.No1"
        },
        {
            "research_objective": "Assess the impact of sample size on the accuracy of self-consistency for calibration in LLMs.",
            "experiment_process": "Mixtral-87B-Inst model was used to examine the effect of increasing sample size. The Brier scores were monitored as the sample size grew to determine the optimal number for accurate estimation while avoiding the randomness of sampling.",
            "result_discussion": "It was found that the Brier scores for all methods initially decreased and then stabilized as the sample size increased. For two methods, a smaller sample size was adequate for accurate estimation, whereas one method required a larger sample size, indicating higher susceptibility to sampling randomness. The results provide guidance on optimal sample sizes for accurate calibration estimation.",
            "ablation_id": "2403.09849v1.No2"
        },
        {
            "research_objective": "Explore the relationship between model performance and calibration.",
            "experiment_process": "The association between accuracy and calibration was examined on instruction-tuned LLaMA2 and Mistral series models, arranged in ascending order based on performance. Calibration metrics were compared to performance metrics to identify trends.",
            "result_discussion": "A positively correlated trend was observed between calibration (lower values indicating better calibration) and performance (higher values indicating better accuracy). This indicates that stronger models exhibit enhanced calibration, aligning with previous findings. The improved calibration in stronger models can be attributed to their ability to generate more reasonable and consistent responses.",
            "ablation_id": "2403.09849v1.No3"
        }
    ]
}