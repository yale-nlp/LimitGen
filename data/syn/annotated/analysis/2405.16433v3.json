{
    "title": "CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling",
    "abstract": "Using large language models (LLMs) to assist psychological counseling is a significant but challenging task at present. Attempts have been made on improving empathetic conversations or acting as effective assistants in the treatment with LLMs. However, the existing datasets lack consulting knowledge, resulting in LLMs lacking professional consulting competence. Moreover, how to automatically evaluate multi-turn dialogues within the counseling process remains an understudied area. To bridge the gap, we propose CPsyCoun, a report-based multi-turn dialogue reconstruction and evaluation framework for Chinese psychological counseling. To fully exploit psychological counseling reports, a two-phase approach is devised to construct high-quality dialogues while a comprehensive evaluation benchmark is developed for the effective automatic evaluation of multi-turn psychological consultations. Competitive experimental results demonstrate the effectiveness of our proposed framework in psychological counseling. We open-source the datasets and model for future research. 111https://github.com/CAS-SIAT-XinHai/CPsyCoun",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "\"No health without mental health\" is becoming more than a slogan, with approximately 14% of the global disease burden attributed to neuropsychiatric disorders Prince et al. (2007  ###reference_b16###). Despite the affordability and effectiveness of many mental health treatments, a significant gap persists between those in need and those able to access care Freeman (2022  ###reference_b7###). The World Health Organization (WHO) continually advocates for increased investment to augment understanding and dispel the stigma associated with mental health disorders. Yet, the challenge of ensuring quality, affordable care for mental health conditions remains formidable. Consequently, the identification of novel treatments and enhancement of existing therapies for all mental diseases are key objectives in the research domain.\nThe Natural Language Processing (NLP) community is actively contributing to the advancement of AI-assisted psychological counseling and treatment. Various research topics have been proposed to conduct mental disease counseling Orr et al. (2022  ###reference_b14###); Toleubay et al. (2023  ###reference_b23###), improve emotional support ability Buechel et al. (2018  ###reference_b3###); Rashkin et al. (2019  ###reference_b19###); Liu et al. (2021  ###reference_b12###); Cheng et al. (2023  ###reference_b6###), and provide online psychological consultation Sun et al. (2021  ###reference_b21###).\n###figure_1### The advent of large language models (LLMs) such as ChatGPT 222https://chat.openai.com/  ###reference_chat.openai.com/### and LLaMA Touvron et al. (2023  ###reference_b24###), has spurred more research efforts on generating not just empathetic conversations, but also serving as therapeutic aids and effective assistants in treatment. For instance, Psy-LLM Lai et al. (2023  ###reference_b9###) is a psychological consultation model that leverages the LLM PanGu and is trained with Q&A from professional psychologists and large-scale Chinese psychological articles from public databases. This model demonstrates proficiency in psychological knowledge and counseling services. Parallel to this, other LLM-based psychological models such as MeChat Qiu et al. (2023  ###reference_b18###), SoulChat Chen et al. (2023b  ###reference_b5###) and MindChat Yan and Xue (2023  ###reference_b27###) are also available online. Recent trends in adopting LLMs for psychological counseling focus on generating more interpretable mental health analyses Yang et al. (2023  ###reference_b28###) and simulating psychiatrist-patient interactions Chen et al. (2023a  ###reference_b4###). This shift in focus from generating responses to diagnosing mental health issues as an expert signifies a trend change in research. The quest for interpretability in mental health analysis serves a dual purpose. First, it provides a detailed rationale behind each response, making it more amenable for human evaluation and debugging. Second, the simulation approach not only addresses data privacy concerns but also challenges the traditional symptom collection method via questionnaires. Providing a range of professional skills, this approach enables more effective completion of consultation tasks.\nDespite these advancements, there remains a dearth of authentic counseling datasets from psychological counseling sessions, which include symptom descriptions of the consultant and treatment methodologies employed by the counselor. Such data could offset issues arising from doctor-patient simulations being template-based and lacking control. For example, psychiatrists have observed that chatbots do not typically resemble patients Chen et al. (2023a  ###reference_b4###). However, it\u2019s noteworthy that these diagnoses are generally sensitive, warranting careful attention to potential privacy issues.\nIn addition to the form of psychological counseling conversations, there is a wealth of psychological counseling data in the real world, which is hidden in professional psychological counseling reports. However, due to its structured nature, it is unsuitable for model training.\nIn this paper, we propose a new framework CPsyCoun for Chinese Psychological Counseling, which consists a dialogue reconstruction method based on psychological counseling reports and a benchmark for multi-turn consultation dialogue evaluation.\nSpecifically, we first collect anonymized psychological counseling reports from publicly accessible websites and further propose a privacy shadowing method to postprocess these reports into a dataset CPsyCounR.\nCPsyCounR includes nine types of psychological consultation and seven classic schools of psychological counseling.\nThrough our proposed Memo2Demo dialogue reconstruction method, we construct another dataset CPsyCounD, which contains 3,134 high-quality multi-turn consultation dialogues.\nFurther, we propose a psychological counseling benchmark for automatic evaluation on multi-turn dialogues and fine-tune an open-sourced LLM on CPsyCounD, named CPsyCounX.\nExperimental results from both intrinsic and extrinsic evaluations consistently verify the superiority of the proposed method.\nFigure 1  ###reference_### illustrates the general framework of our proposed CPsyCoun.\nOur contributions are the following:\nTo the best of our knowledge, our work is the first to generate psychological consultation dialogues based on psychological counseling reports, which effectively expands the source of psychological consultation dialogue data. For efficient dialogue reconstruction, we specifically introduce a two-phase method named Memo2Demo.\nWe propose a benchmark for automatic evaluation of multi-turn dialogues in psychological counseling, which includes comprehensive evaluation metrics, datasets and methods.\nWith the help of Memo2Demo, we construct CPsyCounD, a dataset contains 3,134 high-quality multi-turn consultation dialogues. The model CPsyCounX fine-tuned on this dataset outperforms other models in the benchmark, validating the effectiveness of our proposed framework in psychological counseling."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Dialogue Generation and Reconstruction using LLMs",
            "text": "Dialogue generation and reconstruction using LLMs have been proven to be effective in data augmentation and conversation denoising.\nFor example, SAFARI Wang et al. (2023a  ###reference_b25###) harnesses the planning and understanding capabilities of LLMs to generate persona-consistent and knowledge-enhanced responses.\nIn the medical domain, DISC-MedLLM Bao et al. (2023  ###reference_b2###) undertakes real-world dialogue reconstruction for consultation records sourced from medical forums. This process addresses issues of informal language usage and unregulated expressive styles.\nIn the realm of psychology, numerous studies concentrate on augmenting emotional support capability by enhancing empathy.Qian et al. (2023  ###reference_b17###) amplifies empathetic responses by enriching the dialogue context with a commonsense knowledge graph, thereby stimulating the relevant knowledge encoded by LLMs.\nIn this work, we propose a two-phase method for efficient dialogue reconstruction."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Evaluation of Generated Dialogues using LLMs",
            "text": "The search for better automatic evaluation metrics in natural language generation (NLG) has been a hot topic for the natural language processing (NLP) community.\nCompared to conventional lexicon-based metrics like BLEU Papineni et al. (2002  ###reference_b15###) and Rouge Lin (2004  ###reference_b10###), these new metrics capture deeper semantic meaning and usually have better alignment with human judgments.\nThere have been a series of transformer-based evaluation metrics available in the community, such as BERTScore Zhang et al. (2020  ###reference_b31###), BARTScore Yuan et al. (2021  ###reference_b29###) and GPTScore Fu et al. (2023  ###reference_b8###).\nIn specific domains, there are also derivatives of such metrics tailored for the domain.\nFor example, CodeBERTScore Zhou et al. (2023  ###reference_b32###) is proposed to achieve a higher correlation with human preference and with functional correctness.\nCBERTScore Shor et al. (2023  ###reference_b20###) can penalize clinically-relevant mistakes more than others.\nThe same trend continues with LLMs. Wang et al. (2023b  ###reference_b26###) shows that ChatGPT achieves state-of-the-art or competitive correlation with human judgments in most cases.\nA new framework constructed over GPT-4 called G-Eval Liu et al. (2023b  ###reference_b13###) makes use of LLMs with chain-of-thoughts (CoT) and a form-filling paradigm to assess the quality of NLG outputs, outperforming all previous methods by a large margin.\nIn this work, we design a psychological counseling benchmark for automatic evaluation."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "CPsyCoun",
            "text": "###figure_2### ###figure_3### Considering the differences in data sources of our collection, we need to reformat these collected reports according to a uniform standard.\nTo build a comprehensive and helpful dataset, we combine the case format of China\u2019s National Class 2 Psychological Counselor Examination and other psychological counseling literature to regularize collected reports, where the following 6 components are included: Title, Type, Method, Case Brief, Consultation Process and Experience Thoughts.\nNote that the consultation process is written from a third-person perspective and does not contain specific dialog.\nFor a detailed description of components and examples of psychological counseling report, please refer to Appendix A  ###reference_###.\nAccording to statistics, there are about 230 types of psychological counseling cases and more than 250 counseling methods used in psychological counseling.\nConsidering that the classification of the original types is too detailed, we further summarized the case types into 9 representative topics based on common scenarios of psychological counseling.\nThe distribution of counseling topics is shown in Figure 2a  ###reference_sf1###.\nBased on relevant information from the American Psychological Association (APA) and the International Academy of Psychotherapy (IACP), we have categorized the professional counselor\u2019s methods utilized in psychological counseling reports into 7 classic schools of psychological counseling. The distribution of methods is shown in Figure 2b  ###reference_sf2###.\nDirect role-play prompting is utilized as our baseline method for generating multiple rounds of dialogue from a single round, which has been successfully used in previous work on dialogue generation Qiu et al. (2023  ###reference_b18###); Chen et al. (2023b  ###reference_b5###).\nHowever, we believe that there are still aspects for improvement when applying direct role-play prompting to multi-round dialogue generation in the field of psychological counseling:\n(1) Comprehensiveness: Despite presenting high-quality counseling reports to the language model, it may fail to focus on the significant descriptions of the client\u2019s situation within the report, leading to subsequent dialogues that lack completeness.\n(2) Professionalism: Role-playing prompted dialogues merely reference psychological methods in generated dialogues. We hope that language models could integrate these methods into the problem-solving process, thereby obtaining reconstructed dialogue with professionalism.\n(3) Authenticity: Dialogue constructed by the baseline method lacks the emotional interaction between the client and the psychological counselor present in real scenarios, leaving a deficit in terms of authenticity.\nWe present the detailed prompt of role-play method in Figure 6  ###reference_### in the appendix.\nTo address the aforementioned issues of the baseline method, we propose a two-phase framework named Memo2Demo to generate high-quality psychological consultation dialogue from counseling reports. Mirroring real-life scenarios, we incorporate two key roles into this framework: a psychological supervisor together with a psychological counselor. The psychological supervisor guides the psychological counselor on counseling techniques while ensuring the privacy of the clients during the counseling process. Meanwhile, the psychological counselor engages in direct dialogue with the clients to conduct specific psychological counseling. Figure 3  ###reference_### illustrates the general framework of our proposed method Memo2Demo, where a psychological counseling report is first converted into a counseling note by the psychological supervisor, then the psychological counselor generates the multi-turn consultation dialogue based on both the report and the note. We present detailed prompts used for Memo2Demo in Figure 7  ###reference_### and 8  ###reference_### in the appendix.\nIn psychological counseling, the evaluation metrics remain diverse and not universally standardized. For instance, SoulChat Chen et al. (2023b  ###reference_b5###) proposes evaluation metrics: Content, Empathy, Helpfulness and Safety. Some of these metrics hinge on expert evaluations and lack specific scoring criteria, favoring manual rather than objective and automatic evaluations.\nSimilarly, ChatCounselor Liu et al. (2023a  ###reference_b11###) introduces the Counseling Bench, encompassing seven different perspectives. While these metrics are designed to cater to the model\u2019s specific dialogue strategies, they lack the ability to evaluate the overall dialogue effect. They are more adapted to single-round dialogue evaluations and are not suitable for multi-turn dialogues.\nRecognizing the aforementioned limitations in evaluating consultation dialogues, and in order to analyze the counseling case used for dialogue generation, we propose new evaluation metrics for multi-turn consultation dialogues in psychological counseling. These metrics encompass four different perspectives: Comprehensiveness, Professionalism, Authenticity, and Safety, which are used for automatic evaluation in the rest of this paper. For each perspective, we give its description and corresponding score criterion in Appendix C  ###reference_###.\nWe propose a turn-based dialogue evaluation approach to effectively evaluate multi-turn consultation dialogues.\nDenote a -turn dialogue as a set of paired elements , where each  represents a query from the client, and each corresponding  represents the counselor\u2019s reply. We first split it into  single-turn dialogue, then prompt the model with query together with its dialogue history in each single-turn dialogue, resulting in the corresponding single-turn response:\nwhere  signifies the dialogue history before -th turn, and  denotes the inference process of LLMs.\nTo automatically obtain reliable evaluation results,\nWe employ GPT-4 Achiam et al. (2023  ###reference_b1###) to assess these responses, utilizing the evaluation metrics we previously proposed. Concretely, we ask the model to assign an evaluation score  for a single-turn response . Then we average them to yield the total evaluation score of the current -turn dialogue:\nFor detailed prompts of single-turn response generation, please refer to Figure 11  ###reference_### in the appendix.\nSMILECHAT Qiu et al. (2023  ###reference_b18###), a richly diverse and realistic multi-turn dialogue dataset, comprises 56k multi-turn counseling dialogues, averaging 6.36 rounds per dialogue. Given its wide range of dialogue types, we choose it as our base dataset. However, the open-source data of this dataset is not classified by topic type.\nTo address this limitation and conduct a more comprehensive and explainable evaluation of models\u2019 capabilities, we construct a general multi-turn dialogue evaluation dataset with clear topic classification - CPsyCounE. Leveraging the nine common counseling topics we introduce in CPsyCounR, we manually select the five most representative dialogues from SMILECHAT for each topic, resulting in a comprehensive evaluation dataset of 45 cases."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Data Collection",
            "text": "We conduct a survey of publicly available psychological counseling cases online and collect data from well-known Chinese psychological communities.\nThe online communities used in this work are:\n(1) Yidianling 333https://www.ydl.com, a top-tier mental health platform in China, serves approximately 39 million users, backed by a robust network of over 6,000 professional counselors.\n(2) Psy525 444https://www.psy525.cn, another prominent mental health platform in China, caters to over 1 million users and is supported by nearly 30,000 professional counselors.\nAs the data are anonymized by the websites, there\u2019s a low privacy risk.\nTo enhance the security of the collected data, we further conduct an analysis of privacy and security issues about the data.\nThe procedures adopted during data collecting to ensure no sensitive or privacy-related content in the dataset include rule-based cleaning, manual rewriting, and human proofreading.\nAfter cleaning procedures, relevant private information has been completely removed, and we ensure that relevant private information is protected.\nIn total, we collected 4,700 psychological counseling reports in different formats, with a variety of types and counseling methods. These reports will not be released to the public unless a Privacy Data Protection Agreement is signed upon reasonable request."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Data Processing",
            "text": "To construct a high-quality dataset, we carefully selected 3,134 psychological counseling reports.\nThey contain complete methods and types, clear case briefs, detailed consultation processes and experience thoughts. In the selection process, we found that some of the collected reports contained several counseling cases in one report.\nWe did not select this type of report due to multiple cases in one report where the background information of the client and the consultation processes are incomplete.\nTherefore, among the selected 3,134 psychological counseling reports, each report corresponds to only one case. This high-quality report dataset is named CPsyCounR.\n###figure_4### Considering the differences in data sources of our collection, we need to reformat these collected reports according to a uniform standard.\nTo build a comprehensive and helpful dataset, we combine the case format of China\u2019s National Class 2 Psychological Counselor Examination and other psychological counseling literature to regularize collected reports, where the following 6 components are included: Title, Type, Method, Case Brief, Consultation Process and Experience Thoughts.\nNote that the consultation process is written from a third-person perspective and does not contain specific dialog.\nFor a detailed description of components and examples of psychological counseling report, please refer to Appendix A  ###reference_###  ###reference_###.\nAccording to statistics, there are about 230 types of psychological counseling cases and more than 250 counseling methods used in psychological counseling.\nConsidering that the classification of the original types is too detailed, we further summarized the case types into 9 representative topics based on common scenarios of psychological counseling.\nThe distribution of counseling topics is shown in Figure 2a  ###reference_sf1###  ###reference_sf1###.\nBased on relevant information from the American Psychological Association (APA) and the International Academy of Psychotherapy (IACP), we have categorized the professional counselor\u2019s methods utilized in psychological counseling reports into 7 classic schools of psychological counseling. The distribution of methods is shown in Figure 2b  ###reference_sf2###  ###reference_sf2###."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Dialogue Generation Method for Psychological Counseling",
            "text": "Direct role-play prompting is utilized as our baseline method for generating multiple rounds of dialogue from a single round, which has been successfully used in previous work on dialogue generation Qiu et al. (2023  ###reference_b18###  ###reference_b18###); Chen et al. (2023b  ###reference_b5###  ###reference_b5###).\nHowever, we believe that there are still aspects for improvement when applying direct role-play prompting to multi-round dialogue generation in the field of psychological counseling:\n(1) Comprehensiveness: Despite presenting high-quality counseling reports to the language model, it may fail to focus on the significant descriptions of the client\u2019s situation within the report, leading to subsequent dialogues that lack completeness.\n(2) Professionalism: Role-playing prompted dialogues merely reference psychological methods in generated dialogues. We hope that language models could integrate these methods into the problem-solving process, thereby obtaining reconstructed dialogue with professionalism.\n(3) Authenticity: Dialogue constructed by the baseline method lacks the emotional interaction between the client and the psychological counselor present in real scenarios, leaving a deficit in terms of authenticity.\nWe present the detailed prompt of role-play method in Figure 6  ###reference_###  ###reference_### in the appendix.\nTo address the aforementioned issues of the baseline method, we propose a two-phase framework named Memo2Demo to generate high-quality psychological consultation dialogue from counseling reports. Mirroring real-life scenarios, we incorporate two key roles into this framework: a psychological supervisor together with a psychological counselor. The psychological supervisor guides the psychological counselor on counseling techniques while ensuring the privacy of the clients during the counseling process. Meanwhile, the psychological counselor engages in direct dialogue with the clients to conduct specific psychological counseling. Figure 3  ###reference_###  ###reference_### illustrates the general framework of our proposed method Memo2Demo, where a psychological counseling report is first converted into a counseling note by the psychological supervisor, then the psychological counselor generates the multi-turn consultation dialogue based on both the report and the note. We present detailed prompts used for Memo2Demo in Figure 7  ###reference_###  ###reference_### and 8  ###reference_###  ###reference_### in the appendix."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Automatic Evaluation of LLM-based Psychological Counseling",
            "text": "In the field of psychological counseling, assessing the quality of multi-turn consultation dialogues has always been a challenging task. Despite having successfully generated high-quality counseling dialogues from case reports using Memo2Demo, we still need to verify the impact of these dialogues on subsequent tasks. To this end, we elect to utilize CPsyCounD for supervised fine-tuning on publicly accessible LLMs. This allows us to assess the changes in the psychological counseling competency before and after the use of data.\nNonetheless, the multi-turn consultation dialogue that characterizes the psychological counseling process is complex to evaluate without the input of human experts. To address this, we first introduce evaluation metrics tailored for multi-turn consultation dialogue. Then a turn-based dialogue evaluation method is proposed for automatic evaluation of the psychological counseling process.\nMoreover, we acknowledge the current shortfall of a comprehensive, general multi-turn dialogue evaluation dataset within the psychological counseling community. Such a dataset is vital for assessing LLM-based psychological counseling. To bridge this gap, we present CPsyCounE, a general multi-turn dialogue evaluation dataset.\nIn psychological counseling, the evaluation metrics remain diverse and not universally standardized. For instance, SoulChat Chen et al. (2023b  ###reference_b5###  ###reference_b5###) proposes evaluation metrics: Content, Empathy, Helpfulness and Safety. Some of these metrics hinge on expert evaluations and lack specific scoring criteria, favoring manual rather than objective and automatic evaluations.\nSimilarly, ChatCounselor Liu et al. (2023a  ###reference_b11###  ###reference_b11###) introduces the Counseling Bench, encompassing seven different perspectives. While these metrics are designed to cater to the model\u2019s specific dialogue strategies, they lack the ability to evaluate the overall dialogue effect. They are more adapted to single-round dialogue evaluations and are not suitable for multi-turn dialogues.\nRecognizing the aforementioned limitations in evaluating consultation dialogues, and in order to analyze the counseling case used for dialogue generation, we propose new evaluation metrics for multi-turn consultation dialogues in psychological counseling. These metrics encompass four different perspectives: Comprehensiveness, Professionalism, Authenticity, and Safety, which are used for automatic evaluation in the rest of this paper. For each perspective, we give its description and corresponding score criterion in Appendix C  ###reference_###  ###reference_###.\nWe propose a turn-based dialogue evaluation approach to effectively evaluate multi-turn consultation dialogues.\nDenote a -turn dialogue as a set of paired elements , where each  represents a query from the client, and each corresponding  represents the counselor\u2019s reply. We first split it into  single-turn dialogue, then prompt the model with query together with its dialogue history in each single-turn dialogue, resulting in the corresponding single-turn response:\nwhere  signifies the dialogue history before -th turn, and  denotes the inference process of LLMs.\nTo automatically obtain reliable evaluation results,\nWe employ GPT-4 Achiam et al. (2023  ###reference_b1###  ###reference_b1###) to assess these responses, utilizing the evaluation metrics we previously proposed. Concretely, we ask the model to assign an evaluation score  for a single-turn response . Then we average them to yield the total evaluation score of the current -turn dialogue:\nFor detailed prompts of single-turn response generation, please refer to Figure 11  ###reference_###  ###reference_### in the appendix.\nSMILECHAT Qiu et al. (2023  ###reference_b18###  ###reference_b18###), a richly diverse and realistic multi-turn dialogue dataset, comprises 56k multi-turn counseling dialogues, averaging 6.36 rounds per dialogue. Given its wide range of dialogue types, we choose it as our base dataset. However, the open-source data of this dataset is not classified by topic type.\nTo address this limitation and conduct a more comprehensive and explainable evaluation of models\u2019 capabilities, we construct a general multi-turn dialogue evaluation dataset with clear topic classification - CPsyCounE. Leveraging the nine common counseling topics we introduce in CPsyCounR, we manually select the five most representative dialogues from SMILECHAT for each topic, resulting in a comprehensive evaluation dataset of 45 cases."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "To delve deeper into whether the proposed dataset can effectively enhance the psychological counseling capabilities of LLMs, we further fine-tune InternLM2-7B-Chat Team (2023  ###reference_b22###) on CPsyCounD and derive a chat model CPsyCounX tailored specifically for psychological counseling.\nCPsyCounX is fine-tuning for 9 epochs with the batch size set to 448, and the learning rate set to . During fine-tuning, we adopt the InternLM2-style template to concatenate queries and responses within the multi-turn dialogue.\n###figure_5### ###figure_6### ###figure_7### The turn-based dialogue evaluation method is adopted on CPsyCounE for the following extrinsic evaluation. We include InternLM2-7B-Chat Team (2023  ###reference_b22###), SoulChat Chen et al. (2023b  ###reference_b5###), ChatGPT and GLM-4 Zeng et al. (2023  ###reference_b30###) as major baseline models.\nThe evaluation standard refers to the evaluation metrics in Table 4  ###reference_### in the appendix. To accommodate multi-turn dialogues, we adjust the authenticity criterion accordingly.\nFor detailed evaluation prompts, please refer to Figure 10  ###reference_### in the appendix.\nWe present the overall results of extrinsic evaluation on CPsyCoun in Table 3  ###reference_###, where CPsyCounX surpasses other models in terms of Professionalism and Authenticity, falling behind GLM-4 only slightly in terms of Comprehensiveness.\nFigure 4  ###reference_### further shows detailed scores of CPsyCounX and other baselines, where CPsyCounX significantly outperforms nearly all other baselines on Professionalism, demonstrating the efficacy of proposed method Memo2Demo. While judging by the topic distribution, CPsyCounX leads in all metrics in the topic \"Mental Disease\", demonstrating its high usability in the field of psychological counseling.\nFor full results, please refer to Appendix E  ###reference_###.\nUpon evaluation, we find that GLM-4 scores the highest in Comprehensiveness, largely because its single-turn dialogues encompass vast information. A manual investigation reveals that GLM-4 prioritizes summarizing previous dialogues in each turn, accounting for its high scores in Comprehensiveness. However, our evaluation shows that excessive content tends to compromise Authenticity scores.\nIn psychological counseling, Authenticity and Comprehensiveness need a balanced consideration. In our experiments, we prioritize natural and authentic dialogues that contain key information. Consequently, while CPsyCounX scores lower than GLM-4 in Comprehensiveness, it surpasses GLM-4 in Authenticity.\nThese results highlight that fine-tuning on CPsyCounD enables the model to naturally acquire professional psychological counseling techniques used in counseling dialogues. Moreover, the model can learn the conversational style of psychological counselors in real-life psychological counseling scenarios, ensuring the dialogue\u2019s authenticity."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "CPsyCounD",
            "text": "To validate the effectiveness of our proposed dialogue reconstruction approach, we adopt direct role-play prompting and Memo2Demo to generate dialogues from CPsyCounR respectively.\nWe denote the set of dialogues generated by Memo2Demo as CPsyCounD, which has a total of 3,134 multi-turn consultation dialogues, covering nine topics and seven classic schools of psychological counseling. For statistical information, please refer to Table 1  ###reference_###."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Extrinsic Evaluation of CPsyCoun",
            "text": "To delve deeper into whether the proposed dataset can effectively enhance the psychological counseling capabilities of LLMs, we further fine-tune InternLM2-7B-Chat Team (2023  ###reference_b22###  ###reference_b22###) on CPsyCounD and derive a chat model CPsyCounX tailored specifically for psychological counseling.\nCPsyCounX is fine-tuning for 9 epochs with the batch size set to 448, and the learning rate set to . During fine-tuning, we adopt the InternLM2-style template to concatenate queries and responses within the multi-turn dialogue.\n###figure_8### ###figure_9### ###figure_10### The turn-based dialogue evaluation method is adopted on CPsyCounE for the following extrinsic evaluation. We include InternLM2-7B-Chat Team (2023  ###reference_b22###  ###reference_b22###), SoulChat Chen et al. (2023b  ###reference_b5###  ###reference_b5###), ChatGPT and GLM-4 Zeng et al. (2023  ###reference_b30###  ###reference_b30###) as major baseline models.\nThe evaluation standard refers to the evaluation metrics in Table 4  ###reference_###  ###reference_### in the appendix. To accommodate multi-turn dialogues, we adjust the authenticity criterion accordingly.\nFor detailed evaluation prompts, please refer to Figure 10  ###reference_###  ###reference_### in the appendix.\nWe present the overall results of extrinsic evaluation on CPsyCoun in Table 3  ###reference_###  ###reference_###, where CPsyCounX surpasses other models in terms of Professionalism and Authenticity, falling behind GLM-4 only slightly in terms of Comprehensiveness.\nFigure 4  ###reference_###  ###reference_### further shows detailed scores of CPsyCounX and other baselines, where CPsyCounX significantly outperforms nearly all other baselines on Professionalism, demonstrating the efficacy of proposed method Memo2Demo. While judging by the topic distribution, CPsyCounX leads in all metrics in the topic \"Mental Disease\", demonstrating its high usability in the field of psychological counseling.\nFor full results, please refer to Appendix E  ###reference_###  ###reference_###.\nUpon evaluation, we find that GLM-4 scores the highest in Comprehensiveness, largely because its single-turn dialogues encompass vast information. A manual investigation reveals that GLM-4 prioritizes summarizing previous dialogues in each turn, accounting for its high scores in Comprehensiveness. However, our evaluation shows that excessive content tends to compromise Authenticity scores.\nIn psychological counseling, Authenticity and Comprehensiveness need a balanced consideration. In our experiments, we prioritize natural and authentic dialogues that contain key information. Consequently, while CPsyCounX scores lower than GLM-4 in Comprehensiveness, it surpasses GLM-4 in Authenticity.\nThese results highlight that fine-tuning on CPsyCounD enables the model to naturally acquire professional psychological counseling techniques used in counseling dialogues. Moreover, the model can learn the conversational style of psychological counselors in real-life psychological counseling scenarios, ensuring the dialogue\u2019s authenticity."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we introduce CPsyCoun, an innovative framework for report-based multi-turn dialogue reconstruction and evaluation in Chinese psychological counseling. Our research encompasses data collection, effective data construction methods, and domain evaluation benchmarks.\nTo harness the full potential of psychological counseling reports, we design a two-phase approach to construct high-quality consultation dialogues. Concurrently, we propose a comprehensive evaluation benchmark for multi-turn consultation dialogue, inclusive of metrics, datasets and methods.\nExperimental results validate the effectiveness of our proposed framework, demonstrating its superiority in building a comprehensive, professional, and authentic psychological counseling assistant.\nAll datasets and model weights developed in this paper are publicly available.\nFor future work, a more refined balance between authenticity and professional knowledge in dialogue generation needs to be achieved. We aspire this work will furnish fresh perspectives and references for the development of LLMs in the field of psychological counseling."
        }
    ],
    "url": "http://arxiv.org/html/2405.16433v3",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.1",
            "2.2"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3",
            "3.4"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "3",
            "3.3",
            "3.4",
            "4",
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "research_context": {
        "paper_id": "2405.16433v3",
        "paper_title": "CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling",
        "research_background": "The introduction and related work sections of the paper delineate the motivation, research problem, and pertinent prior work in the context of developing AI-assisted psychological counseling frameworks.\n\n### Motivation:\n- The global disease burden attributed to neuropsychiatric disorders emphasizes the urgent need for accessible and quality mental health care.\n- Mental health treatments, although effective and affordable, are not reaching a large portion of the population in need.\n- There is a pressing necessity to explore novel treatment methods and enhance existing therapies for mental health conditions.\n- The Natural Language Processing (NLP) community's growing interest in AI-assisted psychological counseling and treatment, especially with the advent of large language models (LLMs), necessitates a structured effort in this domain.\n\n### Research Problem:\n- Despite progress, there is a significant lack of authentic counseling datasets derived from real psychological counseling sessions.\n- Existing data often doesn't encompass the detailed symptom descriptions or treatment methods necessary for effective counseling simulation.\n- Traditional methods for data generation are template-based and lack the ability to control and simulate realistic patient interactions accurately.\n- Psychological counseling dialogues found in professional reports are typically structured in ways unsuitable for model training.\n- Protecting patient privacy while generating high-quality data is another critical issue.\n\n### Relevant Prior Work:\n- Studies have focused on conducting mental disease counseling (Orr et al., 2022; Toleubay et al., 2023) and improving emotional support abilities (Buechel et al., 2018; Rashkin et al., 2019; Liu et al., 2021; Cheng et al., 2023).\n- Several models and projects like Psy-LLM (Lai et al., 2023), MeChat (Qiu et al., 2023), SoulChat (Chen et al., 2023b), and MindChat (Yan and Xue, 2023) have been developed using LLMs for psychological consultation.\n- Recent research trends emphasize generating interpretable mental health analyses (Yang et al., 2023) and simulating psychiatrist-patient interactions (Chen et al., 2023a), reflecting a shift toward providing detailed rationale behind each response and addressing privacy concerns.\n\n### Contribution:\n- Introduction of **CPsyCoun**, a novel framework incorporating a dialogue reconstruction method and multi-turn consultation dialogue evaluation benchmark specifically designed for Chinese Psychological Counseling.\n- Development of **CPsyCounR**, a dataset created by collecting and anonymizing psychological counseling reports, followed by a privacy shadowing method.\n- Introduction of the **Memo2Demo** method for dialogue reconstruction, resulting in **CPsyCounD**, a dataset containing 3,134 high-quality multi-turn consultation dialogues.\n- Establishment of an automatic evaluation benchmark for psychological counseling dialogues, involving comprehensive evaluations and metrics.\n- Fine-tuning of an open-sourced LLM on CPsyCounD to create **CPsyCounX**, which outperforms other models in various benchmarks, showcasing the practicality of the proposed framework.\n\nThis paper thus aims to fill the gap in authentic dialogue data for psychological counseling and provide robust tools for evaluation and model development in the sphere of AI-driven mental health support.",
        "methodology": "### Methodology\n\n#### Data Preparation\nThe aim was to standardize and regularize collected psychological counseling reports, integrating them according to the case format used in China\u2019s National Class 2 Psychological Counselor Examination and other widely recognized counseling literature. Each report was reformatted to include six fixed components:\n1. **Title**\n2. **Type**\n3. **Method**\n4. **Case Brief**\n5. **Consultation Process**\n6. **Experience Thoughts**\n\nThe consultation process was written from a third-person perspective, excluding specific dialogues to maintain uniformity.\n\n#### Classification\nTo streamline the variety, original psychological counseling cases, which comprised 230 unique types and 250 methods, were consolidated into 9 representative topics and 7 classical schools respectively, based on guidelines from the American Psychological Association (APA) and the International Academy of Psychotherapy (IACP).\n\n#### Baseline Method: Direct Role-Play Prompting\nWhile direct role-play prompting has proven effective in dialogue generation, it manifested specific shortcomings in comprehensiveness, professionalism, and authenticity:\n1. **Comprehensiveness**: It often failed to capture essential client details, leading to incomplete dialogues.\n2. **Professionalism**: Generated dialogues lacked full integration of psychological methods into the problem-solving process.\n3. **Authenticity**: The role-playing dialogues missed the emotional nuances typical in real counselor-client interactions.\n\n#### Proposed Method: Memo2Demo\nTo overcome these issues, the **Memo2Demo** framework was introduced:\n1. **Phase One: Psychological Supervisor's Note**\n   - A supervisor reviews the consultation report and creates a note that outlines counseling techniques without breaching client privacy.\n2. **Phase Two: Counselor-Client Dialogues**\n   - The counselor, utilizing the supervisor's note and the report, engages in direct multi-turn dialogues with the client.\n\nThis dual-role approach mirrors real-world counseling scenarios, ensuring dialogues are thorough, professional, and emotionally authentic.\n\n#### Evaluation Metrics\nCurrent evaluation metrics for psychological dialogues were deemed insufficient for multi-turn scenarios. Thus, new metrics were proposed covering four crucial dimensions:\n1. **Comprehensiveness**\n2. **Professionalism**\n3. **Authenticity**\n4. **Safety**\n\nA turn-based evaluation approach was defined to effectively assess multi-turn dialogues. This involved segmenting multi-turn dialogues into single-turn dialogues and prompting GPT-4 to evaluate each segment using the proposed metrics.\n\n#### Evaluation Dataset\nTo enable a comprehensive analysis, the SMILECHAT dataset with 56k multi-turn dialogues served as the base. However, due to its unclassified nature by topic, a specific evaluation dataset, **CPsyCounE**, was constructed. This dataset included 45 multi-turn counseling dialogues, distributed across nine common counseling topics, curated from representative SMILECHAT dialogues.\n\nIn conclusion, the **CPsyCoun** framework provides a structured approach for reconstructing and evaluating psychological counseling dialogues, aiming to enhance their comprehensiveness, professionalism, and authenticity while maintaining safety.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n#### Experiment Setup:\n\nTo assess the efficacy of the proposed dataset CPsyCounD in improving the psychological counseling capabilities of Large Language Models (LLMs), the experiment involves fine-tuning the InternLM2-7B-Chat model to create CPsyCounX, a chat model specifically tailored for psychological counseling.\n\n**Fine-tuning Configuration:**\n- Model: InternLM2-7B-Chat\n- Dataset: CPsyCounD\n- Epochs: 9\n- Batch Size: 448\n- Learning Rate: (value missing)\n- Template: InternLM2-style template to concatenate queries and responses within multi-turn dialogues.\n\n**Evaluation:**\nThe model's performance is evaluated on CPsyCounE using a turn-based dialogue evaluation method. The main baseline models included for comparison are:\n- InternLM2-7B-Chat\n- SoulChat\n- ChatGPT\n- GLM-4\n\n**Evaluation Metrics:**\nThe evaluation metrics include:\n- Professionalism\n- Authenticity\n- Comprehensiveness\n\n**Adjustment for Multi-turn Dialogues:**\nThe authenticity criterion is adjusted to cater to the multi-turn dialogue nature of the evaluation.\n\n#### Main Experimental Results:\n- **Overall Performance:** CPsyCounX surpasses other baseline models in terms of Professionalism and Authenticity, and falls just slightly behind GLM-4 in terms of Comprehensiveness, as shown in Table 3 (reference missing).\n- **Topic Distribution:** In the \"Mental Disease\" topic, CPsyCounX leads in all metrics, demonstrating its high usability in psychological counseling scenarios.\n- **Manual Investigation Findings:** GLM-4, while achieving the highest Comprehensiveness scores, tends to compromise on Authenticity by summarizing previous dialogues excessively. This leads to a trade-off where excessive content can diminish the perceived authenticity of the dialogue.\n- **Importance of Balance:** The results emphasize the need for a balanced consideration between Authenticity and Comprehensiveness in psychological counseling. CPsyCounX prioritizes natural and authentic dialogues containing essential information, thereby surpassing GLM-4 in Authenticity despite slightly lower Comprehensiveness scores.\n\nOverall, the experiment highlights that fine-tuning on CPsyCounD enables the model to acquire professional psychological counseling techniques and mimic the conversational style characteristic of real-life psychological counseling, ensuring authentic dialogues."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To validate the effectiveness of the proposed dialogue reconstruction approach and to establish the Memo2Demo framework's efficacy over direct role-play prompting for generating high-quality psychological consultation dialogues.",
            "experiment_process": "We adopted direct role-play prompting and Memo2Demo to generate dialogues from CPsyCounR, resulting in a set of 3,134 multi-turn consultation dialogues covering nine topics and seven classic schools of psychological counseling. The evaluation was done on a subset of 140 cases from these classic schools using GPT-4 to compare both methods. Evaluation metrics included Comprehensiveness, Professionalism, Authenticity, and Safety, with prompts for evaluation detailed in Figure 9 in the appendix.",
            "result_discussion": "Memo2Demo method outperforms direct role-play prompting significantly in Comprehensiveness, Professionalism, and Authenticity across all schools. The method demonstrated an enhancement of 53% in Comprehensiveness and Professionalism and a 30% improvement in Authenticity. Both methods scored full marks in Safety, showing effective privacy protection. Memo2Demo significantly improves the quality of reconstructed consultation dialogues.",
            "ablation_id": "2405.16433v3.No1"
        },
        {
            "research_objective": "To investigate the extent to which the proposed CPsyCoun dataset can enhance the psychological counseling capabilities of large language models (LLMs) following fine-tuning.",
            "experiment_process": "We fine-tuned InternLM2-7B-Chat on CPsyCounD for 9 epochs with a batch size of 448 and a learning rate set. Then, we conducted extrinsic evaluations using CPsyCounE on InternLM2-7B-Chat, SoulChat, ChatGPT, and GLM-4, using turn-based dialogue evaluation. Evaluation metrics included Comprehensiveness, Professionalism, Authenticity, and Safety, detailed in Table 4 in the appendix.",
            "result_discussion": "CPsyCounX, the model fine-tuned on CPsyCounD, surpassed other models like GLM-4 in Professionalism and Authenticity, while slightly falling behind in Comprehensiveness. GLM-4's method of summarizing previous dialogues increased its Comprehensiveness but decreased its Authenticity. The results highlight that fine-tuning on CPsyCounD enables models to adopt professional techniques and conversational styles used in real-life scenarios, boosting the model's overall authenticity.",
            "ablation_id": "2405.16433v3.No2"
        }
    ]
}