{
    "title": "Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large Language Models with Machine Learning in tele-dermatology",
    "abstract": "The rise of Artificial Intelligence creates great promise in the field of medical discovery, diagnostics and patient management. However, the vast complexity of all medical domains require a more complex approach that combines machine learning algorithms, classifiers, segmentation algorithms and, lately, large language models. In this paper, we describe, implement and assess an Artificial Intelligence-empowered system and methodology aimed at assisting the diagnosis process of skin lesions and other skin conditions within the field of dermatology that aims to holistically address the diagnostic process in this domain. The workflow integrates large language, transformer-based vision models and sophisticated machine learning tools. This holistic approach achieves a nuanced interpretation of dermatological conditions that simulates and facilitates a dermatologist\u2019s workflow. We assess our proposed methodology through a thorough cross-model validation technique embedded in an evaluation pipeline that utilizes publicly available medical case studies of skin conditions and relevant images. To quantitatively score the system performance, advanced machine learning and natural language processing tools are employed which focus on similarity comparison and natural language inference. Additionally, we incorporate a human expert evaluation process based on a structured checklist to further validate our results. We implemented the proposed methodology in a system which achieved approximate (weighted) scores of 0.87 for both contextual understanding and diagnostic accuracy, demonstrating the efficacy of our approach in enhancing dermatological analysis. The proposed methodology is expected to prove useful in the development of next-generation tele-dermatology applications, enhancing remote consultation capabilities and access to care, especially in underserved areas.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "The rise of Artificial Intelligence (AI) and its transformative effect on many fields and domains provides significant opportunities for the revamping and re-engineering of the diagnostic process. However, in order to navigate through the complexity of the medical field effectively, a multifaceted approach is essential that integrates several AI technologies including explainability (Panagoulias et al., 2024b  ###reference_b32###), trustworthiness and holistic evaluation properties (Virvou, 2023  ###reference_b39###). Machine learning algorithms, for instance, are instrumental in identifying patterns and insights from large datasets, enabling the prediction of disease progression and response to treatments (Ahsan et al., 2022  ###reference_b1###). Classifiers play a critical role in categorizing data, such as distinguishing between different types of tumors or identifying patients at high risk for certain conditions (Johnson et al., 2021  ###reference_b18###). Segmentation algorithms are crucial in imaging analysis, helping to isolate and analyze specific areas within medical images for more accurate diagnoses (Wang et al., 2022  ###reference_b40###).\nIn dermatology, while non-invasive methods and imaging techniques offer valuable preliminary assessments, the definitive diagnosis of malignancy relies on laboratory tests and biopsies. This approach ensures accuracy in diagnosis, aids in the planning of appropriate treatments, and helps to avoid the pitfalls of over-diagnosis. The ongoing development of diagnostic technologies aims to refine the accuracy of non-invasive assessments, but the role of histopathological examination remains central to the confirmatory diagnosis of skin cancers and other dermatological conditions.\nIn this paper, we propose and assess \u201cDermacen Analytica\u201d, an assistive workflow designed to support the evaluation of skin lesions and skin conditions and to enhance both the timeliness and efficiency of dermatological analyses. The proposed workflow integrates cutting-edge technologies, including Large Language Models (LLMs), transformer-based vision models, and advanced machine learning tools, to establish a comprehensive solution that addresses the current limitations in tele-dermatology.\nMore specifically, the key components of our proposed workflow are the (1) Integration of Large Language Models and Transformers with Vision, (2) Advanced Feature Extraction and Segmentation, (3) the Pragmatic Criteria for Skin Condition Evaluation and (4) the Streamlining of the process.\nAs per (1), by leveraging LLMs and vision transformers, our workflow introduces an efficient approach to understanding and interpreting complex dermatological conditions. These models perform well in analyzing visual data, allowing for a nuanced assessment of skin lesions that surpasses traditional analysis methods. As per (2), utilizing state-of-the-art machine learning (ML) tools, the proposed workflow includes a robust feature extraction system that identifies and quantifies key characteristics of skin lesions, such as shape, size, color, and texture. Segmentation algorithms further refine the analysis by isolating lesions from the surrounding skin, enabling precise evaluations. As per (3), our methodology incorporates pragmatic criteria tailored specifically for skin condition evaluation. This includes the consideration of dermatological standards and guidelines, Lastly (4), our workflow demonstrates the potential to serve as the foundation for next-generation tele-dermatology applications. By facilitating remote consultations and evaluations, it expands access to dermatological care, particularly in underserved regions. Its efficiency and accuracy improvements also promise to reduce wait times and enhance patient outcomes.\nMore specifically, the paper is structured as follows: Section 2 focuses on reviewing relevant previous studies and related published works. In Section 3, Dermacen Analytica is outlined, alongside the evaluation methodology used to validate its use. In Section 4, we present implementation use cases of our system and the evaluation results. Lastly in Section 5, we summarize the findings and highlights of our research and discuss future related endeavours."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related work",
            "text": "Machine learning (ML), particularly its sub-field of deep learning (DL), has become increasingly popular in dermatology due to its ability to learn from large datasets of skin images (Chan et al., 2020  ###reference_b6###; Du et al., 2020  ###reference_b8###; Hogarty et al., 2020  ###reference_b15###). These algorithms, especially convolutional neural networks (CNNs), have shown proficiency in identifying patterns and features in images that may be subtle or invisible to the human eye (Liopyris et al., 2022  ###reference_b22###). This capability is particularly useful in dermatology, where the visual inspection of skin lesions is a primary diagnostic method. The simplest form of ML-based dermatological image assessment involves binary classification, where an ML model is trained to differentiate between two classes of dermatological conditions, namely benign vs. malignant lesions. This is crucial for early detection of skin cancers like melanoma, potentially saving lives through early intervention. Beyond binary classification, ML models can be trained to identify various skin conditions from a single image. This involves categorizing lesions into multiple classes, such as melanoma, basal cell carcinoma, squamous cell carcinoma, and benign nevi among others. In general, multi-class classification systems require more complex models and larger, well-annotated datasets for training."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "The Dermatologist\u2019s Workflow",
            "text": "The process of diagnosing a skin lesion or condition by dermatologists involves several key steps and requires a thorough consideration and evaluation approach (Marwaha et al., 2019  ###reference_b26###; Gachon et al., 2005  ###reference_b12###). This process can vary depending on the specific circumstances, but it generally includes the following stages:\nPatient History: The dermatologist begins by gathering a comprehensive patient history. This involves concerns and symptoms related to conditions, personal or family history of skin diseases, and any other health conditions or medications that could be relevant.\nVisual Examination: A thorough visual examination of the skin is conducted. Dermatologists are trained to notice subtle differences in skin lesions and can often make a preliminary diagnosis based on their appearance, shape, color, size, texture, and location. They may also examine other areas of the skin to check for additional lesions or signs that could provide diagnostic clues.\nDermatoscopy: For suspicious skin lesions, especially those that could be malignant (such as melanoma), a dermatoscope is utilised, which is a specialized magnifying tool with a light source. Dermatoscopy allows the dermatologist to examine the lesion in greater detail, including patterns and colors not visible to the naked eye. The most common rule used for evaluating a skin lesion, is the following ABCDE rule (Ring et al., 2021  ###reference_b34###; Duarte et al., 2021  ###reference_b9###), which, however, is considered as a guideline and not as a diagnosis tool. Any skin lesion or mole that exhibits one or more of these characteristics usually prompts further investigation and, if necessary, a biopsy\nA for Asymmetry: One half of the mole or birthmark does not match the other half.\nB for Border: The edges are irregular, ragged, notched, or blurred.\nC for Color: The color is not the same all over the spot and may include shades of brown or black, sometimes with patches of pink, red, white, or blue.\nD for Diameter: The spot is larger than 6 millimeters across (i.e. larger than about \u00bc inch or the size of a pencil eraser), although melanomas can sometimes be smaller than this.\nE for Evolving: The mole is changing in size, shape, or color, or exhibits new symptoms such as bleeding, itching, or crusting.\nSkin Biopsy: A small sample of the skin lesion is removed and sent to a laboratory for histological examination under a microscope. This is particularly useful for diagnosing skin cancers, inflammatory skin conditions, and infections.\nPatch Testing: To identify allergic contact dermatitis, patch tests may be conducted by applying small amounts of common allergens to the skin to trigger reactions.\nSkin Scrapings: For suspected fungal infections, skin scrapings can be examined under a microscope or cultured to identify the fungus.\nDifferential Diagnosis: Dermatologists consider all possible conditions that could share symptoms (differential diagnosis) and use the information gathered to narrow down the possibilities and thus conclude to a final diagnosis.\nFinal Diagnosis and Treatment Plan: Based on the comprehensive evaluation, the dermatologist arrives at a final diagnosis and discusses treatment options with the patient. Treatment can vary widely depending on the condition, from topical creams and medications to surgical removal of lesions, light therapy, or other systemic treatments.\nFollow-Up: The dermatologist may schedule follow-up visits to monitor the condition, assess the effectiveness of the treatment and make adjustments."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Applicability Challenges of Machine Learning in Dermatology",
            "text": "Various ML and segmentation techniques have been applied in dermatology. Techniques such as Otsu\u2019s method or -means clustering have been widely used for segmenting skin lesions from healthy skin based on color and texture differences (Fan et al., 2017  ###reference_b10###). In skin lesion segmentation, U-Net, a CNN variant, has shown particular efficiency in handling medical images with fewer data samples (Iranpoor et al., 2020  ###reference_b17###; Anand et al., 2023  ###reference_b3###).\nOne of the main challenges, both in clinical practice and artificial intelligence (AI) applications, is the diversity of skin types, colors, and conditions, as well as the availability of high-quality, annotated datasets.\nIndeed, in dermatology, the number of conditions and sub-conditions is extensive due to the wide range of diseases that affect the skin, hair, nails, and mucous membranes. The skin, being the largest and most exposed organ of the body, is susceptible to a vast array of conditions. These conditions can range from common and benign to rare and life-threatening.\nDermatological conditions (Kerr et al., 2010  ###reference_b19###; Hahnel et al., 2017  ###reference_b13###; Hay et al., 2014  ###reference_b14###) can be broadly categorized into several types, including, but not limited to:\nInflammatory skin diseases (e.g., eczema, psoriasis, dermatitis)\nInfectious diseases of the skin (caused by bacteria, viruses, fungi, and parasites)\nAcne and related disorders\nAutoimmune and connective tissue diseases affecting the skin (e.g., lupus, scleroderma)\nPigmentation disorders (e.g., vitiligo, melasma)\nSkin cancers (e.g., melanoma, basal cell carcinoma, squamous cell carcinoma)\nHair loss disorders (alopecia areata, androgenetic alopecia)\nNail disorders\nGenetic skin disorders\nEach of these categories contains multiple specific conditions, and many of these conditions have further subtypes based on their etiology, severity, clinical presentation, and other factors. For instance, eczema can be subdivided into atopic dermatitis, contact dermatitis, dyshidrotic eczema, and several other types. Similarly, psoriasis has several forms, including plaque psoriasis, guttate psoriasis, inverse psoriasis, pustular psoriasis, and erythrodermic psoriasis, among others.\nMedical professionals often refer to resources like the International Classification of Diseases (ICD) coded by the World Health Organization (WHO) for a standardized list of dermatological conditions, which is regularly updated.\nOther challenges that further complicate the workflows in dermatology include:\nHistopathological Confirmation: The gold standard for diagnosing skin cancer and other dermatological conditions is the histopathological examination of tissue obtained through a biopsy. This process involves the microscopic examination of cells to identify cancerous changes. The appearance, arrangement, and behavior of cells provide crucial information that cannot be definitively obtained through non-invasive methods alone.\nSubtype Identification and Staging: Certain types of skin cancer, such as melanoma, have various subtypes that can significantly influence treatment and prognosis. A biopsy can help identify these subtypes. Additionally, further tests on biopsy samples, such as molecular testing, can provide information on gene mutations or markers that may affect treatment decisions.\nTreatment Planning: The specific characteristics of a lesion, such as its depth and the presence of certain cellular mutations, guide treatment planning. For instance, the depth of a melanoma, known as the Breslow thickness, is a critical factor in determining the risk of metastasis and the need for additional treatments beyond surgical excision.\nReducing Overdiagnosis: Visual and even advanced imaging assessments can sometimes lead to overdiagnosis, where benign conditions are treated as malignant. Biopsies help avoid unnecessary treatments by providing a definitive diagnosis.\nClearly, for ML models to be truly useful, they must be seamlessly integrated into clinical workflows. This includes ensuring that models can provide results in a timely manner and are adaptable to new data and findings."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "Vision Transformers and GPT-4V",
            "text": "Vision Transformers (ViTs) (Zhai et al., 2022  ###reference_b43###) constitute a type of AI model that has revolutionized the field of computer vision, i.e. the AI discipline focused on enabling machines to interpret and understand visual information from the world (Khan et al., 2022  ###reference_b20###). ViTs are, in fact, a variation of the Transformer model (Vaswani et al., 2017  ###reference_b38###; Devlin et al., 2018  ###reference_b7###), which was originally developed for natural language processing (NLP) tasks.\nDuring training (Atito et al., 2021  ###reference_b4###), ViTs learn to identify features and patterns within the patches, leveraging the self-attention mechanism to understand the context and relationships between different parts of an image (Yuan et al., 2021  ###reference_b42###; Zhai et al., 2022  ###reference_b43###).\nFor inference, the ViT model processes a new image through the same steps as used in its training and the transformed class token is used to make predictions or classifications. The key advantage of ViTs over traditional CNNs is their ability to capture global dependencies across the entire image, thanks to their self-attention mechanism. This allows for a more holistic understanding of the image context and leads to significant improvements in various computer vision applications.\nGPT-4 with vision capabilities, sometimes referred to as GPT-4V (System Card,  ###reference_b36###), represents an advancement in the capabilities of LLMs by incorporating the ability to understand and analyze image inputs alongside textual data. This multimodal approach expands the utility of LLMs, as it enables them to process and generate information based not just on text but also on visual cues provided by images. This enhancement is achieved via embedding a mechanism for understanding visual information, typically through the use of a Vision Transformer (ViT). Regarding output generation, GPT-4V uses the context provided by both the text and image inputs to generate responses."
        },
        {
            "section_id": "2.4",
            "parent_section_id": "2",
            "section_name": "Named Entity Recognition",
            "text": "Named Entity Recognition (NER) (Nadeau & Sekine, 2007  ###reference_b27###; Hong et al., 2020  ###reference_b16###) is a sub-field of NLP and information retrieval. The primary goal of NER is to identify and categorize key information in text into predefined categories or \u201centities\u201d such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc. NER systems are designed to recognize entities within a body of text. This involves not only detecting the entity, but also categorizing it into a predefined class."
        },
        {
            "section_id": "2.5",
            "parent_section_id": "2",
            "section_name": "Natural Language Processing and Semantic Similarity",
            "text": "Semantic similarity is a metric defined over a set of documents or terms, where the idea of distance between items is based on the likeness of their meaning or semantic content as opposed to lexicographical similarity. These are mathematical tools used to estimate the strength of the semantic relationship between units of language, concepts or instances, through a numerical description obtained according to the comparison of information supporting their meaning or describing their nature.\nAdvanced Textual Similarity Models: Utilizing pre-trained models like BERT (Bidirectional Encoder Representations from Transformers) (Reimers & Gurevych, 2019  ###reference_b33###), which can understand the context of words in text, one can compare the embeddings of the provided answer and the correct response. By analyzing the embeddings similarity, one can gauge if the provided answer covers key aspects of the correct response. These models are particularly effective because they understand nuances in language that simpler models might miss. BERTScore, for example, offers evaluations in terms of precision, recall, and F1 measures, catering to a broad spectrum of language generation evaluations. These metrics allow for a granular analysis of how well the generated text aligns with reference standards, providing insights into the quality of text-generative systems (Zhang* et al., 2020  ###reference_b45###).\nAnswer Verification Techniques: Natural language inference (NLI) models determine if a given hypothesis is true (entailment), false (contradiction), or undetermined (neutral) based on a premise. In this context, the correct response can be the premise and the provided answer the hypothesis. Models trained on NLI tasks, such as those available through Hugging Face\u2019s Transformers library (Machine Learning for PyTorch, TensorFlow, and JAX,  ###reference_b24###), can be used to assess the correctness of the provided answer.\nFor example, when comparing the two phrases \u201cI like you\u201d and \u201cI love you\u201d, the related scores using the roberta-large-mnli model (Liu et al., 2019  ###reference_b23###) are NEUTRAL (0.716), ENTAILMENT (0.226), CONTRADICTION\n(0.058). The roberta-large-mnli is a variant of the RoBERTa (Robustly Optimized BERT Pretraining Approach) model that has been specifically fine-tuned on the Multi-Genre Natural Language Inference (MNLI) dataset (Williams et al., 2018  ###reference_b41###).\nQuestion Answering Models: For more structured assessments, one can use question-answering (QA) models fine-tuned on medical texts. By posing questions about the key facts or claims in the correct response, one can evaluate whether the provided answer contains the necessary information to answer these questions correctly."
        },
        {
            "section_id": "2.6",
            "parent_section_id": "2",
            "section_name": "Evaluation Of AI-empowered Medical Systems",
            "text": "In medical education, a diverse range of assessment methods supplements Objective Structured Clinical Examinations (OSCEs) and multiple-choice quizzes (MCQs) to comprehensively evaluate medical students (Majumder et al., 2019  ###reference_b25###; Vanderbilt et al., 2013  ###reference_b37###; Norcini & McKinley, 2007  ###reference_b28###; Ferris & O\u2019Flynn, 2015  ###reference_b11###). These methods aim to cover various aspects of medical training, from theoretical knowledge and practical skills to professional behavior. The evaluation of medical students is a rigorous process and other studies (Labrak et al., 2024  ###reference_b21###) have also followed a simulated approach of the OSCE to evaluate LLMs in diagnostic tasks.\nIn the premise of evaluating multi-modal LLMs in the medical domain, we have also constructed an evaluation pipeline based on images and/or text (Panagoulias et al., 2024a  ###reference_b31###, 2023b  ###reference_b30###). We have also employed medical experts for understanding the depth of LLM reasoning in diagnosis, treatment proposal, staging of Cancer and other related tasks (Panagoulias et al., 2023a  ###reference_b29###, b  ###reference_b30###). In the current work, we further empower our analytical-pipeline by adding more NLP processes, already described in subSections 2.4  ###reference_### and 2.5  ###reference_###."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Methods and materials",
            "text": "In this section, we define the methods we have constructed and employed to address the following main challenges:\nThe effectiveness of pattern recognition techniques in diagnosing dermatological conditions is hindered by a lack of explainability. While ML paradigms, when applied to classification tasks, can enhance the quality of assessments, they fall short in providing the robustness of measurable and actionable information.\nSkin, being the largest organ, is subject to a vast array of conditions and problems, making it impossible to confidently propose a single AI solution that addresses all of them. Therefore, the closest approximation to a solution may involve mimicking the diagnostic process of a medical professional and creating strategic AI interventions.\nTo confidently propose a viable solution that incorporates AI into the various steps leading to a diagnosis, a robust evaluation process is essential.\nTo address these challenges, we follow a multi-step approach, implemented as an application (in beta testing as of the writing), named \u201cDermacen Analytica\u201d (see figure 1  ###reference_###).\n###figure_1###"
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Dermacen Analytica",
            "text": "In figure 1  ###reference_###, Dermacen Analytica is presented as a general algorithmic approach/workflow aiming at evaluating and diagnosing skin lesions or other skin conditions. In the context of a medical practice, this approach can ensure faster diagnoses and classification of various conditions related to dermatology. It also provides a proof of concept of how the leverage of combined state-of-the-art AI tools can revolutionise tele-dermatology and related fields.\nDermacen Analytica uses Generative AI (GAI) enhanced with vision transformers (GPT-4V) for analysis, description and recognition of main features in medical images that can be used for assessing the medical condition. Using contextual rules for enhanced answer generation (\u201cRules of Conduct\u201d), the relevance and accuracy of the diagnostic suggestions is improved. The enhancement in generated answers is dependent on dimensionality reduction in the information retrieval space, i.e. instead of searching in the total corpus of related information, the search is directed to a more precise required information. In other words, the incorporation of specific contextual information allows the LLM to extract more relevant knowledge and, thus, provide more accurate responses. Considering the vast space of dermatology conditions, the specificity of the responses increases when the dimension of knowledge vectors is reduced via use of different models with different rules. For example as can be seen in listing 2  ###reference_###, we only require a selection from a list of skin lesions usually captured via a dermatoscope and measured using the ABCDE rule that we described earlier.\nIn the case of a skin lesion, segmentation and feature extraction techniques are used to measure the characteristics of the lesion with great precision. In turn, these measurements will be fed again to another model alongside the descriptive assessment provided by the first LLM. This cross-model validation technique can further enhance the quality of the final generated response (chat-completion), further reducing the knowledge-dimensional space and ensuring a more refined and specific response. A high level representation of the technique can be seen in figure 2  ###reference_###. In this figure, each sphere includes a number of dots (nodes) connected by lines (edges), where each node represents a knowledge point. Enforcing reduction via rules makes each sphere to include fewer knowledge points from which the model leverages a response.\nWhen an image does not depict a skin lesion, the system will generate a different response from a different knowledge space, provided by a different set of rules of conduct (1  ###reference_###). This multi-model collaboration approach improves the outcomes and reduces the probability of generation of hallucinations and misdiagnosis.\n###figure_2### Figure 1  ###reference_### presents a holistic view of Dermacen Analytica. It also highlights its multifaceted approach towards enhancing medical diagnostics through the integration of streamlined AI technologies. In more detail:\nImage Input and Rules of Conduct: This is the starting point where an image is analyzed by the vision transformer-powered LLM powered. The process checks for the presence and localization of features and uses the ABCDE rule (commonly used to evaluate skin lesions) for ABCDE approximation to an answer. This process places emphasis on the identification of melanocytic nevus\u2014skin lesions.\nResponse: An initial response from the LLM with Vision is generated in the context of either a skin disorder or a skin lesion.\nAnalysis Response: This stage involves the analysis of the generated response as per pre-defined rules for engagement, considering the lesion type, condition or disorder, other diseases, or skin-related factors. This step here is a node from which three different paths can be followed, namely the Skin Legion Path, the Skin Condition Path and the End Path.\nSkin Lesion Path\nExternal ML-Service: This part of the process involves an external ML service, which is a specialized service for dermatology. It includes segmentation and feature extraction, as well as considering asymmetry, circularity, color variability, and the initial response from the LLM.\nLLM-XAI (Explainable Artificial Intelligence): The process involves applying rules of conduct to the ML model\u2019s response, which includes the response itself and a description or definition of previous findings.\nSend2Lab: This step informs of the necessity of laboratory analysis, depending on the previous findings, as summarised by the LLM-XAI step.\nSkin Condition Path\nThe image is sent again for analysis into an LLM with Vision for more specificity. The focus on melanocytic nevus is removed; thus, more diagnostic freedom is provided to the LLM, in the form of new rules of conduct (defined below).\nResponse: A response is generated in the form of a differential diagnosis as described previously.\nEnd path: If it is neither a lesion or a skin condition the path ends, i.e the process breaks.\nSegmentation and feature extraction for the skin lesions is done using various measurement methods, according to the ABCDE rule. For the purpose of this study, we only evaluate the Asymmetry, Borders and Colors of the skin lesions as can be also seen in Algorithm 1  ###reference_###.\nThe process begins by segmenting the lesion from the surrounding skin in the given image. This is achieved through the function \u201cplotSegmented\u201d, which applies image segmentation techniques to isolate the lesion. The segmentation process involves the use of the \u201capply_otsu_and_grabcut_refined\u201d function (Zhang et al., 2018  ###reference_b44###). This suggests the combination of Otsu\u2019s thresholding method with the GrabCut algorithm (Setiawan, 2020  ###reference_b35###) to accurately delineate the lesion\u2019s boundaries. Otsu\u2019s method determines an optimal threshold to separate foreground (lesion) from background, while GrabCut refines this segmentation by considering color statistics and a graph-based model.\nAfter segmentation, the system extracts various features from the image of the lesion. Area and perimeter are directly calculated from the segmented lesion, providing insights into the size and boundary extent of the lesion.\nCircularity is also calculated, which helps to assess the shape of the lesion. A perfect circle has a circularity of 1, while deviations from this value indicate irregularity in shape and define the value of Border of the lesion.\nThe lesion\u2019s asymmetry is evaluated in two ways, i.e. both vertically and horizontally, using the largest contour identified within the segmented lesion. Asymmetry measures how much one half of the lesion differs from the other, which constitutes an important indicator in skin lesion analysis.\nColor variability is calculated as the standard deviation of color intensities (in the red, green, and blue channels) within the lesion. This assesses the variation in color within the lesion, which can also be an important diagnostic feature.\nThe previous functions return a technical report that includes the calculated metrics (area, perimeter, circularity, color variability, and asymmetry). This assessment is intended for further clinical review that is to be associated with the initial generated response from the LLM with Vision.\nAdditionally, we generate visual representations of the segmented lesion and plots illustrating the asymmetry and color variability. These visual aids can help to get a more intuitive understanding of the lesion\u2019s characteristics.\nThe Technical Assessment of Skin Lesions 1  ###reference_### leverages digital image analysis techniques using the OpenCV library (Bradski et al., 2000  ###reference_b5###), which is a standard tool for image processing tasks. An extraction example of the process is illustrated as a use case in figure 5  ###reference_###, which is presented in the results section."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Evaluation Methodology",
            "text": "###figure_3### To evaluate the capabilities of our proposed system, we have constructed a comprehensive multi-step method for assessing the competency of the LLM used in diagnosing skin conditions from images. Firstly, we create a premise, using rules of conduct for the LLM engine to provide structured responses (the generated hypothesis) under a predetermined multi-modal configuration. Following that, the data are extracted and analysed using sentence embeddings and NLI.\nLastly, the evaluation is provided as a report that measures the approximate capability of the LLM. BERT (Reimers & Gurevych, 2019  ###reference_b33###) is a method of pre-training language representations which can be used to create vector embeddings for sentences. These embeddings capture semantic meaning and are used to compare the similarity between pieces of text presented here as a premise and a hypothesis. Multi-Genre Natural Language Inference (MNLI) involves predicting the relationship between a pair of sentences (whether one entails the other, contradicts it, or are neutral w.r.t. each other). We use RoBERTa, a pre-trained model on English language text which uses masked language modeling (MLM) That is, it applies masking on a portion of the input tokens in a sentence and asks the model to predict the masked tokens (Liu et al., 2019  ###reference_b23###).\nIn figure 4  ###reference_###, the evaluation process is depicted in more detail.\n###figure_4### Textual Similarity: This first stage involves analyzing the similarity between a given premise and a hypothesis. Cosine similarity is used to measured similarity in terms of content and diagnosis, which is a common metric in text analysis. Specifically, it determines the cosine of the angle between two vectors in a multidimensional space and often represents word frequency.\nThe cosine similarity between two vectors can be calculated as:\n. In the premise of textual similarity, the BertScores are also calculated and used to compute a similarity score and also precision, recall and F1 score.\nNatural Language Inference (NLI): In the second stage, a deeper analysis is performed of the language used in the premise and hypothesis. It takes the explanation or diagnosis from the assessment of the content and diagnosis to produce a report. This report categorizes the relationship between the premise and hypothesis into one of three outcomes, namely contradiction, neutral, or entailment. Contradiction means the premise and hypothesis are logically incompatible, while neutral means they are unrelated, and entailment means the truth of the premise guarantees the truth of the hypothesis.\nExpert Review: In the third stage, the process involves an expert review where the outcomes of the previous stages are assessed against a checklist and an evaluation report is produced. The final output is an \u201capproximate capability\u201d which might indicate a measure of confidence or a decision about the quality of the hypothesis in relation to the premise.\nBased on the previous, a total calculation of similarity is considered as in Algorithm (2  ###reference_###). In there, weights are used that define the importance of each extracted similarity score. These weights are defined based on the scope of the evaluation. In this case, the scope is to define the competency (i.e. approximate capability) of the system to reason within the given restrictions.\nSimilarity of General Explanation assesses how closely the respondent\u2019s explanation of concepts, mechanisms, or treatments aligns with the standard explanation. It evaluates understanding, articulation, and depth of knowledge.\nSimilarity of Diagnosis as Entities focuses on identifying and matching specific medical conditions or diagnoses, comparing the LLM (respondent) named conditions to the ones that have been provided as correct explanations or correct test solutions. It assesses accuracy in identification and application of knowledge.\nLastly the Expert Process, involves an expert thoroughly evaluating the responses and scores as per AI Symptom Analysis and Image Understanding, as well as per AI Diagnostic Reasoning. The Likert Scale is used here, where 1 and 5 indicate \u201cweak agreement\u201d and \u201cgreat agreement\u201d, respectively."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Results and Evaluation",
            "text": "In this section, the implementation of the Dermacen Analytica is described, followed by the evaluation of the domain specific capabilities of the GPT-4V in providing reasoning and diagnosis in dermatology. This system is aimed at (1) enhancing the workflow of a dermatologist, (2) improving outcomes and speed of patient evaluation and diagnosis and (3) incorporating AI tools for information retrieval from medical images. If a skin lesion is to be analysed, the system extracts both a description of the lesion visual characteristics via LLM with Vision capabilities and specific measurements related to its features via ML tools. This offers a pragmatic employment of AI capabilities that provide significant assistance towards a specialist\u2019s decision."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Implementation use cases",
            "text": ""
        },
        {
            "section_id": "4.1.1",
            "parent_section_id": "4.1",
            "section_name": "4.1.1 Skin Lesion",
            "text": "In figure 5  ###reference_###, a use case is presented where the image depicts a skin lesion taken with a dermatoscope. The \u201cAnalyse\u201d button is the call to action, forwarding the image to LLM with Vision (GPT-4V). In response, an initial assessment is received. The main parts of the assessment consist of the visual description, the feature presence analysis, the feature localisation, an ABCDE approximation and three possible diagnoses. For the first use case, the definite diagnosis confirmed by histopathology analysis is that of a melanoma. In more detail the generated assessment of the first use case is the following AI-generated response:\nVisual Description:\nThe image presents a close-up view of a skin lesion on a light-skinned background, marked by a scale with millimeter-level increments for size reference. The lesion appears asymmetrical and multicolored with shades of pink, red, and black. There are irregular borders around the lesion, and it shows variation in color intensity and pattern within its contour. The lesion\u2019s diameter can be approximated with the ruler in the frame, suggesting it may be larger than 6mm. Transparent bubbles and hair follicles can also be seen on the surrounding skin.\nFeature Presence:\n1. Asymmetrical shape\n2. Irregular, poorly-defined borders\n3. Multiple colors (pink, red, black)\n4. Diameter potentially greater than 6mm\n5. Variation in pigmentation\nFeature Localization:\nThe lesion is centrally located within the image frame, with the black portion towards its lower region. The red and lighter pink areas are distributed in a somewhat blotchy pattern throughout the lesion. The darker areas and most irregular borders can be seen on the bottom and right side of the lesion.\nABCDE Approximation:\n- Asymmetry: The lesion is asymmetrical. \n- Border: The borders of the lesion are irregular and poorly defined. \n- Color: There is heterogeneity in color, with more than two colors present. \n- Diameter: The lesion seems to be larger than 6mm, based on the scale provided. \n- Evolution: There\u2019s no information about the evolution of the lesion from this single image.\nDiagnosis Selection:\nThe image depicts a skin lesion, and based on the ABCDE criteria and visual appearance, the three most likely diagnoses may be:\n1. Melanoma\n2. Atypical (Dysplastic) Nevus\n3. Pigmented Basal Cell Carcinoma\n###figure_5### Following the initial assessment, segmentation and analytical techniques are employed to measure Asymmetry, Borders and Colorisation. The generated technical report is the following:\n\u201cDetailed Medical Assessment with Methodology of Segmented Image Analysis Segmentation and Feature Extraction Summary: The lesion of interest was identified and segmented from the surrounding tissue using a combination of Otsu\u2019s method and the GrabCut algorithm, a process implemented in the apply_otsu_and_grabcut function. This approach ensures precise delineation of the lesion, facilitating accurate measurement and analysis. Following segmentation, key geometric and colorimetric features were extracted using OpenCV (cv2), a widely recognized library in image processing and analysis. Circularity Index: Determined to be 0.68, indicating an irregular shape that deviates from perfect circularity. This measure is crucial for understanding the lesion\u2019s morphology. Color Variability within the Segmented Area: Standard Deviation in the Red Channel: 19.21, indicating the degree of red intensity variation. Standard Deviation in the Green Channel: 20.647, reflecting variation in green intensity. Standard Deviation in the Blue Channel: 19.261, showing blue intensity variation. The lesion has an asymmetry of 0.00823 (asymmetry plot 1) and 0.1062 (asymmetry plot 2), for an average asymmetry of 0.05722464257917816 which is a measure of the difference in the two halves of the lesion.\u201d\nThe next step of the process, presented as the XAI button in figure 5  ###reference_###, feeds both the initial and the technical assessment to another LLM (Multi-Model Collaboration for Enhanced Context Retrieval). The following is last report provided by the collaborative system, which also includes the necessary references for the specialist to ensure the usefulness of the report:\n\u201c\u2026. Using Otsu\u2019s method and the GrabCut algorithm promptly ensures an accurate segmentation that is fundamental for any further processing or analysis activities. The ABCDE approach to skin lesions is a widely recognized method used by professionals. This technique takes into account Asymmetry, irregular Borders, multiple Colors, Diameter (more than 6mm), and Evolution of the lesion[1]. Your segmentation analysis revealed the gross morphological features of the lesion well. The asymmetry findings, irregular border, color variability, and size all are crucial characteristics that aid in the differential diagnosis of melanoma.\nYour suspicion towards a diagnosis of melanoma is supported by these findings. Atypical (Dysplastic) Nevus and Pigmented Basal Cell Carcinoma are also plausible diagnoses, as these can present with some features similar to melanoma such as irregular color and large diameter[2][3]. However, further diagnostic testing (like a biopsy) would be required to confirm this. You did well to stress that this evaluation is not a substitute for professional medical advice. Face-to face clinical examination, patient\u2019s history and, if necessary, biopsy and histologic examination are always the gold standard in dermatology[4]. [1] Hekler, A., Utikal, J. S., & Enk, A. H. (2019). ABCDE criteria: The importance of considering \u201cugly ducklings\u201d when diagnosing melanoma. JDDG: Journal der Deutschen Dermatologischen Gesellschaft, 17(2), 182-188. [2] Bolognia, J. L., Jorizzo, J. L., & Schaffer, J. V. (Eds.). (2012). Dermatology (3rd ed.). Elsevier Saunders. [3] Rubin, A. I., & Chen, E. H. (2010). Basal cell carcinoma. In Fitzpatrick\u2019s Dermatology in General Medicine, 8, 1294\u20131303. [4] Marghoob, A. A., Usatine, R. P., & Jaimes, N. (2013). The skin biopsy. Jama, 310(10), 1047-1047.\u201d\n###figure_6###"
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Evaluation",
            "text": "Using the methodology described in the previous sections, we evaluate the capabilities of GPT-4V, which is employed in Dermacen Analytica, in diagnosing skin conditions, given a brief symptomatology and a related image. For the evaluation, we imposed the premise (i.e. the symptomatology, the explanation of the diagnosis along the diagnosis or differential diagnosis) and the hypothesis (i.e. the generated response). The evaluation is conducted using a totality of 72 images with their related context. We request one diagnosis and an accompanying explanation, and on that we evaluate the responses. The questions and images are retrieved from DermNet (American Lung association,  ###reference_b2###), a leading free dermatology resource of materials, methods and case studies related to skin conditions and treatments.\nNext, we provide some examples of correct answers -the premise- and examples of the returned responses -the hypothesis- alongside the scores related to Textual Similarity (TS) (figure 4  ###reference_###), NLI and expert review.\nExample case 1\nQuestion: This 40-year-old woman has a longstanding history of crusted skin lesions since she was 12 years old. Lesions started on her neck, axillae, and upper back. They flare up intermittently with increasing pain and malodorous discharge. Many family members (including her grandfather, father, uncles, and twin sister) have similar lesions.\nOn examination, she had confluent, crusted, greasy papules across the upper back, lateral neck, and axillae. She also had nail changes.\nPremise: The diagnosis is Darier disease, an autosomal dominant genodermatosis. It typically presents with scaly, crusted papules in a seborrhoeic distribution and in skin folds.\nIt is caused by a mutation in the ATP2A2 gene, which leads to SERCA2 protein dysfunction, interfering with cellular calcium signaling. This results in impaired cellular adhesion and epidermal blistering.\nPremise-Entity: Darier Disease\n###figure_7### Hypothesis (AI-generated response): Diagnosis - Darier Disease (Keratosis Follicularis)\nClinical Features Supporting Diagnosis:\nThe patient presents with several key features that indicate Darier Disease:\n1. Longstanding History: The patient has experienced these skin lesions since a young age, which is common for genetic disorders like Darier Disease.\n2. Family History: There is a strong familial pattern, with multiple generations affected, which supports a genetic etiology like that of Darier Disease, an autosomal dominant condition.\n3. Morphology and Distribution of Lesions: The greasy papules and crusted lesions are typically seen in Darier Disease, and the distribution on the upper back, lateral neck, and axillae fits the pattern of seborrheic areas commonly involved in this condition.\n4. Nail Changes: Nail abnormalities such as red and white streaks or a V-shaped nick at the tip of the nails, are characteristic findings in Darier Disease.\n5. Malodorous Discharge and Pain: Secondary infection can be common in these lesions, leading to a malodorous discharge and pain, especially during flares.\nThe presented photograph shows confluent, crusted, greasy papules that are consistent with the features of Darier Disease lesions.\nHypothesis Entity: Darier Disease (Keratosis Follicularis)\nSCORE:\nTS Premise vs Hypothesis: 1.0\nTS Premise vs Hypothesis Entities: 1.0\nNLI Premise vs Hypothesis: ENTAILMENT (0.675)\nNLI Premise vs Hypothesis - Entities: ENTAILMENT (0.49)\nExample case 2\nQuestion: This 78-year-old lady presented with a new reddish-orange spreading rash on the right side of her face overnight. The affected skin was raised with a demarcated border and areas of blistering. Her white cell count and C-reactive protein were very raised and she described an episode of fever and rigors.\nPremise:\nThis rash and history is classical for erysipelas.\nErysipelas is a superficial form of cellulitis, a potentially serious bacterial infection affecting the skin. Erysipelas affects the upper dermis and extends into the superficial cutaneous lymphatics.\nPremise-Entity: Erysipelas\n###figure_8### Hypothesis (AI-generated response): Diagnosis - Cellulitis\nClinical Features Supporting the Diagnosis:\nThe patient\u2019s presentation of a reddish-orange spreading rash with raised, demarcated borders and areas of blistering on the right side of her face is indicative of cellulitis. Cellulitis is a common bacterial skin infection that affects the deeper layers of skin and the underlying tissue.\nThe acute nature of the rash (appearing overnight), alongside systemic symptoms such as fever and rigors (shaking chills), supports an infectious etiology. The raised white cell count and elevated C-reactive protein are indicative of an acute inflammatory response to an infection.\nThe characteristics of the rash, such as its rapid spread, the clearly defined border, swelling, and area of blistering, further suggest cellulitis, particularly given the absence of a central lesion that would suggest a bite or sting, and the lack of other distinguishing marks suggesting an alternative diagnosis such as shingles or contact dermatitis.\nThe patient\u2019s age (78 years old) is also a relevant factor, as older individuals have a higher risk of developing cellulitis, possibly due to a weakened immune system and other comorbidities that may compromise skin integrity and the body\u2019s natural defenses against infection.\nGiven these clinical features and the patient\u2019s rapid onset of symptoms, cellulitis seems to be the most probable diagnosis for this case.\nHypothesis Entity: Cellulitis\nSCORE:\nTS Premise vs Hypothesis: 0.89\nTS Premise vs Hypothesis Entities: 1.0\nNLI Premise vs Hypothesis: ENTAILMENT (0.55)\nNLI Premise vs Hypothesis - Entities: ENTAILMENT (0.83)\nIn the following table 1  ###reference_###, we present the average scores for all evaluated cases. According to our evaluation, GPT-4V shows greater reasoning within the domain of dermatology, generating accurate responses and regularly achieving a correct diagnosis. It should be again noted that in many cases a differential diagnosis was given as an explanation (premise), but we chose to request one most probable diagnosis for all cases. This fact alone limits the NLI scoring, especially in the extracted entities, i.e. in the diagnosis. In the NLI, the hypothesis and premise can be Neutral (N), Entailment (E) or Contradiction (C). The textual similarity in the context of hypothesis (generated response) and premise (default explanation), is equal to 0.71. While in the extracted entities -the diagnoses for each scenario is equal to 0.68.\nIn the NLI, the scores favour the entailment in both context and entities (diagnosis). Since we considered Dermacen Analytica as an enhancement in the doctor\u2019s workflow, the context (i.e. the analysis of image and symptoms) weighed as more important than the suggested diagnosis, which in many cases would be leveraged by the experts opinion or external laboratory evaluation of a given sample. Thus:\nContext\nEntities\nThe BERTScores, which also confirm the Textual similarity and NLI, suggest that the responses are somewhat aligned with the correct answers with room for improvement. This can be seen in table 1  ###reference_### and figures 9  ###reference_### and 10  ###reference_###. Precision in the context of BERTScore refers to the extent to which tokens in the generated response -hypothesis- are semantically similar to tokens in the premise. Recall measures how well the tokens in the correct answer are covered by semantically similar tokens in the response. On the other hand, the F1 Score is the harmonic mean of precision and recall. A moderate precision indicates that not all information in the response is relevant or accurately reflects the correct answer, while a higher recall suggests that a majority of the correct answer\u2019s content is addressed in the response, yet some aspects are missing or underrepresented. The F1 Score underscores the need for improvement in both precision and recall to achieve a higher degree of semantic similarity and accuracy. The BERTScores, alongside the textual -cosine- similarity and the NLI scores for context and diagnosis, show that there is good reasoning within the domain, where images are also analysed. This analysis can benefit the doctor\u2019s workflow and suggest pathways for further investigation, either via a more thorough clinical assessment or via external services, usually provided by laboratories or other experts.\n###figure_9### ###figure_10###"
        },
        {
            "section_id": "4.2.1",
            "parent_section_id": "4.2",
            "section_name": "4.2.1 Expert Review and Final Assessment",
            "text": "As can be seen in table 1  ###reference_###, based on the expert review and following a thorough evaluation of the responses, the score validates our quality analysis based on textual similarity and NLI. For context, the score was equal to 4.38 (out of 5) or 0.87. For the entities, i.e. for the diagnosis reasoning, the score was 4.31 (out of 5) or 0.86 for an average score of 0.87. Based on our evaluation process, a final capability score is calculated and is equal to 0.86."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion and future work",
            "text": "In this paper, Dermacen Analytica was presented, which constitutes a novel assistive workflow integrating advanced technologies such as LLMs (namely, GPT-4), transformer-based vision models (namely, GPT-4V), and ML tools to enhance the process of evaluation of skin lesions and other conditions in dermatology. Through our comprehensive methodology, incorporating cross-model validation and advanced ML alongside NLP tools, we demonstrated significant improvements in diagnostic efficiency and accuracy. The system\u2019s ability to provide nuanced interpretation and detailed analysis of dermatological conditions may signify an advancement in tele-dermatology, as it allows leveraging both textual and visual data. Our evaluation, grounded on a thorough assessment pipeline and expert review, underscored the workflow\u2019s effectiveness, achieving very high (perhaps impressive) weighted scores in contextual understanding and diagnostic accuracy. For the evaluation, we employ NLP techniques to score similarity and NLI of correct and provided response and correct single or differential diagnosis and returned diagnosis. To accomplish that, we consider the default as the Premise and the returned as the Hypothesis, and we outline the process via a comprehensive algorithmic approach.\nDermacen Analytica\u2019s deployment in enhancing dermatological care, especially in remote and underserved areas, underscores its potential to enhance the field with technological innovation. Indeed, the introduction of Dermacen Analytica into the tele-dermatology landscape may address some of the critical challenges in diagnostic accuracy and efficiency. By harnessing the capabilities of GPT-4V for reasoning and diagnosis, our approach not only streamlines the workflow for dermatologists, but it also enriches the decision-making process with AI-empowered insights. The methodology\u2019s emphasis on multi-model collaboration minimizes errors, such as hallucinations and misdiagnoses, thereby enhancing patient care outcomes. Moreover, the system\u2019s adaptability to different skin conditions and lesions, supported by evidence-based evaluation criteria, presents a scalable solution for future tele-dermatology applications. The potential of Dermacen Analytica to facilitate access to dermatological care, particularly in regions lacking specialized medical services, highlights the critical role of technology in bridging healthcare gaps.\nHowever, the adoption of such advanced technological solutions also raises considerations around ethical use, data privacy, and the need for continuous validation against evolving dermatological knowledge. In our future work, we aim to address these challenges, ensuring that innovations like Dermacen Analytica not only advance medical practice but do so responsibly and ethically.\nIn conclusion, Dermacen Analytica exemplifies the transformative impact of integrating LLMs, vision transformers, and machine learning in healthcare. By elevating the standard of care in dermatology, this workflow paves the way for future advancements in telemedicine, promising a more efficient, accurate, and accessible healthcare landscape.\nFuture work will focus on refining AI models through continuous learning, expanding the range of conditions that can be accurately diagnosed, and integrating patient feedback to enhance the user experience. Furthermore, collaborations with dermatologists and healthcare institutions will be crucial in validating and adapting the workflow to meet clinical needs."
        }
    ],
    "appendix": [],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.3\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.3.4.1\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r\" id=\"S4.T1.3.4.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\" id=\"S4.T1.3.4.1.2\">Context</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\" id=\"S4.T1.3.4.1.3\">Entities</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T1.3.4.1.4\">Average</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.3.5.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T1.3.5.1.1\">Textual Similarity</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T1.3.5.1.2\">0.70</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T1.3.5.1.3\">0.69</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.3.5.1.4\">0.87</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.1.1.1\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.2\">(7) 0.096</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.3\">(22) 0.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4\">0.22</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.2.2.1\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.2.2.2\">(3) 0.04</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.2.2.3\">(21) 0.28</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.2.4\">0.16</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.3.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.3.3.1\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.3.3.2\">(63) 0.86</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.3.3.3\">(30) 0.41</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.3.3.4\">0.85</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.3.6.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.3.6.2.1\">Expert Review</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.3.6.2.2\">(4.38) 0.877</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.3.6.2.3\">(4.31) 0.863</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.3.6.2.4\">0.87</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.3.7.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T1.3.7.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.3.7.3.1.1\">Capability</span></th>\n<td class=\"ltx_td ltx_border_r ltx_border_tt\" id=\"S4.T1.3.7.3.2\"></td>\n<td class=\"ltx_td ltx_border_r ltx_border_tt\" id=\"S4.T1.3.7.3.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.3.7.3.4\">0.86</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.3.8.4\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T1.3.8.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.3.8.4.1.1\">Bert Score</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T1.3.8.4.2\">Precision</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T1.3.8.4.3\">Recall</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.3.8.4.4\">F1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.3.9.5\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T1.3.9.5.1\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T1.3.9.5.2\">0.63</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T1.3.9.5.3\">0.67</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T1.3.9.5.4\">0.65</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Dermatology Evaluation scores</figcaption>\n</figure>",
            "capture": "Table 1: Dermatology Evaluation scores"
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.14243v1_figure_1.png",
            "caption": "Figure 1: Dermacen Analytica, proposed AI-empowered dermatology workflow"
        },
        "2": {
            "figure_path": "2403.14243v1_figure_2.png",
            "caption": "Figure 2: Reducing the knowledge space"
        },
        "3": {
            "figure_path": "2403.14243v1_figure_3.png",
            "caption": "Figure 3: Creating a premise and a hypothesis"
        },
        "4": {
            "figure_path": "2403.14243v1_figure_4.png",
            "caption": "Figure 4: Evaluation process"
        },
        "5": {
            "figure_path": "2403.14243v1_figure_5.png",
            "caption": "Figure 5: Skin lesion Use-Case"
        },
        "6": {
            "figure_path": "2403.14243v1_figure_6.png",
            "caption": "Figure 6: Skin condition Use-Case"
        },
        "7": {
            "figure_path": "2403.14243v1_figure_7.png",
            "caption": "Figure 7: 40 year old with crusted skin lesions"
        },
        "8": {
            "figure_path": "2403.14243v1_figure_8.png",
            "caption": "Figure 8: Overnight onset of facial rash"
        },
        "9": {
            "figure_path": "2403.14243v1_figure_9.png",
            "caption": "Figure 9: Bert Scores"
        },
        "10": {
            "figure_path": "2403.14243v1_figure_10.png",
            "caption": "Figure 10: Bert Scores distribution"
        }
    },
    "references": [
        {
            "1": {
                "title": "Machine-learning-based disease diagnosis: A comprehensive review.",
                "author": "Ahsan, M. M., Luna, S. A., & Siddique, Z. (2022).",
                "venue": "In Healthcare (p. 541).",
                "url": null
            }
        },
        {
            "2": {
                "title": "American lung association.",
                "author": "American Lung association ().",
                "venue": "https://dermnetnz.org/about.",
                "url": null
            }
        },
        {
            "3": {
                "title": "Fusion of u-net and cnn model for segmentation and classification of skin lesion from dermoscopy images.",
                "author": "Anand, V., Gupta, S., Koundal, D., & Singh, K. (2023).",
                "venue": "Expert Systems with Applications, 213, 119230.",
                "url": null
            }
        },
        {
            "4": {
                "title": "Sit: Self-supervised vision transformer.",
                "author": "Atito, S., Awais, M., & Kittler, J. (2021).",
                "venue": "arXiv preprint arXiv:2104.03602, .",
                "url": null
            }
        },
        {
            "5": {
                "title": "Opencv.",
                "author": "Bradski, G., Kaehler, A. et al. (2000).",
                "venue": "Dr. Dobb\u2019s journal of software tools, 3.",
                "url": null
            }
        },
        {
            "6": {
                "title": "Machine learning in dermatology: current applications, opportunities, and limitations.",
                "author": "Chan, S., Reddy, V., Myers, B., Thibodeaux, Q., Brownstone, N., & Liao, W. (2020).",
                "venue": "Dermatology and therapy, 10, 365\u2013386.",
                "url": null
            }
        },
        {
            "7": {
                "title": "Bert: Pre-training of deep bidirectional transformers for language understanding.",
                "author": "Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2018).",
                "venue": "arXiv preprint arXiv:1810.04805, .",
                "url": null
            }
        },
        {
            "8": {
                "title": "Review of machine learning in predicting dermatological outcomes.",
                "author": "Du, A. X., Emam, S., & Gniadecki, R. (2020).",
                "venue": "Frontiers in Medicine, 7, 266.",
                "url": null
            }
        },
        {
            "9": {
                "title": "Clinical abcde rule for early melanoma detection.",
                "author": "Duarte, A. F., Sousa-Pinto, B., Azevedo, L. F., Barros, A. M., Puig, S., Malvehy, J., Haneke, E., & Correia, O. (2021).",
                "venue": "European Journal of Dermatology, 31, 771\u2013778.",
                "url": null
            }
        },
        {
            "10": {
                "title": "Automatic segmentation of dermoscopy images using saliency combined with otsu threshold.",
                "author": "Fan, H., Xie, F., Li, Y., Jiang, Z., & Liu, J. (2017).",
                "venue": "Computers in biology and medicine, 85, 75\u201385.",
                "url": null
            }
        },
        {
            "11": {
                "title": "Assessment in medical education; what are we trying to achieve?.",
                "author": "Ferris, H., & O\u2019Flynn, D. (2015).",
                "venue": "International Journal of Higher Education, 4, 139\u2013144.",
                "url": null
            }
        },
        {
            "12": {
                "title": "First prospective study of the recognition process of melanoma in dermatological practice.",
                "author": "Gachon, J., Beaulieu, P., Sei, J. F., Gouvernet, J., Claudel, J. P., Lemaitre, M., Richard, M. A., & Grob, J. J. (2005).",
                "venue": "Archives of dermatology, 141, 434\u2013438.",
                "url": null
            }
        },
        {
            "13": {
                "title": "The epidemiology of skin conditions in the aged: a systematic review.",
                "author": "Hahnel, E., Lichterfeld, A., Blume-Peytavi, U., & Kottner, J. (2017).",
                "venue": "Journal of tissue viability, 26, 20\u201328.",
                "url": null
            }
        },
        {
            "14": {
                "title": "The global burden of skin disease in 2010: an analysis of the prevalence and impact of skin conditions.",
                "author": "Hay, R. J., Johns, N. E., Williams, H. C., Bolliger, I. W., Dellavalle, R. P., Margolis, D. J., Marks, R., Naldi, L., Weinstock, M. A., Wulf, S. K. et al. (2014).",
                "venue": "Journal of Investigative Dermatology, 134, 1527\u20131534.",
                "url": null
            }
        },
        {
            "15": {
                "title": "Artificial intelligence in dermatology\u2014where we are and the way to the future: a review.",
                "author": "Hogarty, D. T., Su, J. C., Phan, K., Attia, M., Hossny, M., Nahavandi, S., Lenane, P., Moloney, F. J., & Yazdabadi, A. (2020).",
                "venue": "American journal of clinical dermatology, 21, 41\u201347.",
                "url": null
            }
        },
        {
            "16": {
                "title": "Sciner: extracting named entities from scientific literature.",
                "author": "Hong, Z., Tchoua, R., Chard, K., & Foster, I. (2020).",
                "venue": "In Computational Science\u2013ICCS 2020: 20th International Conference, Amsterdam, The Netherlands, June 3\u20135, 2020, Proceedings, Part II 20 (pp. 308\u2013321).",
                "url": null
            }
        },
        {
            "17": {
                "title": "Skin lesion segmentation using convolutional neural networks with improved u-net architecture.",
                "author": "Iranpoor, R., Mahboob, A. S., Shahbandegan, S., & Baniasadi, N. (2020).",
                "venue": "In 2020 6th Iranian Conference on Signal Processing and Intelligent Systems (ICSPIS) (pp. 1\u20135).",
                "url": null
            }
        },
        {
            "18": {
                "title": "Precision medicine, ai, and the future of personalized health care.",
                "author": "Johnson, K. B., Wei, W.-Q., Weeraratne, D., Frisse, M. E., Misulis, K., Rhee, K., Zhao, J., & Snowdon, J. L. (2021).",
                "venue": "Clinical and translational science, 14, 86\u201393.",
                "url": null
            }
        },
        {
            "19": {
                "title": "The profile of dermatological problems in primary care.",
                "author": "Kerr, O., Tidman, M., Walker, J., Aldridge, R., & Benton, E. (2010).",
                "venue": "Clinical and experimental dermatology, 35, 380\u2013383.",
                "url": null
            }
        },
        {
            "20": {
                "title": "Transformers in vision: A survey.",
                "author": "Khan, S., Naseer, M., Hayat, M., Zamir, S. W., Khan, F. S., & Shah, M. (2022).",
                "venue": "ACM computing surveys (CSUR), 54, 1\u201341.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Biomistral: A collection of open-source pretrained large language models for medical domains.",
                "author": "Labrak, Y., Bazoge, A., Morin, E., Gourraud, P.-A., Rouvier, M., & Dufour, R. (2024).",
                "venue": "arXiv preprint arXiv:2402.10373, .",
                "url": null
            }
        },
        {
            "22": {
                "title": "Artificial intelligence in dermatology: challenges and perspectives.",
                "author": "Liopyris, K., Gregoriou, S., Dias, J., & Stratigos, A. J. (2022).",
                "venue": "Dermatology and Therapy, 12, 2637\u20132651.",
                "url": null
            }
        },
        {
            "23": {
                "title": "Roberta: A robustly optimized bert pretraining approach.",
                "author": "Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., & Stoyanov, V. (2019).",
                "venue": "arXiv preprint arXiv:1907.11692, .",
                "url": null
            }
        },
        {
            "24": {
                "title": "State-of\u2013the\u2013art.",
                "author": "Machine Learning for PyTorch, TensorFlow, and JAX ().",
                "venue": "https://huggingface.co/docs/transformers/en/index.",
                "url": null
            }
        },
        {
            "25": {
                "title": "An evaluative study of objective structured clinical examination (osce): students and examiners perspectives.",
                "author": "Majumder, M. A. A., Kumar, A., Krishnamurthy, K., Ojeh, N., Adams, O. P., & Sa, B. (2019).",
                "venue": "Advances in medical education and practice, (pp. 387\u2013397).",
                "url": null
            }
        },
        {
            "26": {
                "title": "Comparative effectiveness study of face-to-face and teledermatology workflows for diagnosing skin cancer.",
                "author": "Marwaha, S. S., Fevrier, H., Alexeeff, S., Crowley, E., Haiman, M., Pham, N., Tuerk, M. J., Wukda, D., Hartmann, M., & Herrinton, L. J. (2019).",
                "venue": "Journal of the American Academy of Dermatology, 81, 1099\u20131106.",
                "url": null
            }
        },
        {
            "27": {
                "title": "A survey of named entity recognition and classification.",
                "author": "Nadeau, D., & Sekine, S. (2007).",
                "venue": "Lingvisticae Investigationes, 30, 3\u201326.",
                "url": null
            }
        },
        {
            "28": {
                "title": "Assessment methods in medical education.",
                "author": "Norcini, J. J., & McKinley, D. W. (2007).",
                "venue": "Teaching and teacher education, 23, 239\u2013250.",
                "url": null
            }
        },
        {
            "29": {
                "title": "Evaluating the potential of llms and chatgpt on medical diagnosis and treatment.",
                "author": "Panagoulias, D., Palamidas, F., Virvou, M., & Tsihrintzis, G. A. (2023a).",
                "venue": "In 14th IEEE International Conference on Information, Intelligence, Systems, and Applications (IISA2023), Volos, Greece.",
                "url": null
            }
        },
        {
            "30": {
                "title": "Rule-augmented artificial intelligence-empowered systems for medical diagnosis using large language models.",
                "author": "Panagoulias, D. P., Virvou, M., & Tsihrintzis, G. A. (2023b).",
                "venue": "In 2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI).",
                "url": null
            }
        },
        {
            "31": {
                "title": "Evaluating llm \u2013 generated multimodal diagnosis from medical images and symptom analysis.",
                "author": "Panagoulias, D. P., Virvou, M., & Tsihrintzis, G. A. (2024a).",
                "venue": "arXiv:2402.01730.",
                "url": null
            }
        },
        {
            "32": {
                "title": "A novel framework for artificial intelligence explainability via the technology acceptance model and rapid estimate of adult literacy in medicine using machine learning.",
                "author": "Panagoulias, D. P., Virvou, M., & Tsihrintzis, G. A. (2024b).",
                "venue": "Expert Systems with Applications, 248, 123375. URL: https://www.sciencedirect.com/science/article/pii/S0957417424002409. doi:https://doi.org/10.1016/j.eswa.2024.123375.",
                "url": null
            }
        },
        {
            "33": {
                "title": "Sentence-bert: Sentence embeddings using siamese bert-networks.",
                "author": "Reimers, N., & Gurevych, I. (2019).",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing.",
                "url": null
            }
        },
        {
            "34": {
                "title": "Dermatoscopy.",
                "author": "Ring, C., Cox, N., & Lee, J. B. (2021).",
                "venue": "Clinics in Dermatology, 39, 635--642. URL: https://www.sciencedirect.com/science/article/pii/S0738081X21000547. doi:https://doi.org/10.1016/j.clindermatol.2021.03.009.",
                "url": null
            }
        },
        {
            "35": {
                "title": "Image segmentation metrics in skin lesion: accuracy, sensitivity, specificity, dice coefficient, jaccard index, and matthews correlation coefficient.",
                "author": "Setiawan, A. W. (2020).",
                "venue": "In 2020 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM) (pp. 97--102).",
                "url": null
            }
        },
        {
            "36": {
                "title": "Gpt-4v(ision).",
                "author": "System Card (2023).",
                "venue": null,
                "url": null
            }
        },
        {
            "37": {
                "title": "Assessment in undergraduate medical education: a review of course exams.",
                "author": "Vanderbilt, A., Feldman, M., & Wood, I. (2013).",
                "venue": "Medical education online, 18, 20438.",
                "url": null
            }
        },
        {
            "38": {
                "title": "Attention is all you need.",
                "author": "Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, \u0141., & Polosukhin, I. (2017).",
                "venue": "In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA (pp. 5998--6008).",
                "url": null
            }
        },
        {
            "39": {
                "title": "Artificial intelligence and user experience in reciprocity: Contributions and state of the art.",
                "author": "Virvou, M. (2023).",
                "venue": "Intelligent Decision Technologies, 17, 73--125.",
                "url": null
            }
        },
        {
            "40": {
                "title": "Medical image segmentation using deep learning: A survey.",
                "author": "Wang, R., Lei, T., Cui, R., Zhang, B., Meng, H., & Nandi, A. K. (2022).",
                "venue": "IET Image Processing, 16, 1243--1267.",
                "url": null
            }
        },
        {
            "41": {
                "title": "A broad-coverage challenge corpus for sentence understanding through inference.",
                "author": "Williams, A., Nangia, N., & Bowman, S. (2018).",
                "venue": "In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers) (pp. 1112--1122).",
                "url": null
            }
        },
        {
            "42": {
                "title": "Tokens-to-token vit: Training vision transformers from scratch on imagenet.",
                "author": "Yuan, L., Chen, Y., Wang, T., Yu, W., Shi, Y., Jiang, Z.-H., Tay, F. E., Feng, J., & Yan, S. (2021).",
                "venue": "In Proceedings of the IEEE/CVF international conference on computer vision (pp. 558--567).",
                "url": null
            }
        },
        {
            "43": {
                "title": "Scaling vision transformers.",
                "author": "Zhai, X., Kolesnikov, A., Houlsby, N., & Beyer, L. (2022).",
                "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 12104--12113).",
                "url": null
            }
        },
        {
            "44": {
                "title": "Object localization improved grabcut for lung parenchyma segmentation.",
                "author": "Zhang, S., Zhao, Y., & Bai, P. (2018).",
                "venue": "Procedia computer science, 131, 1311--1317.",
                "url": null
            }
        },
        {
            "45": {
                "title": "Bertscore: Evaluating text generation with bert.",
                "author": "Zhang*, T., Kishore*, V., Wu*, F., Weinberger, K. Q., & Artzi, Y. (2020).",
                "venue": "In International Conference on Learning Representations.",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.14243v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.1",
            "2.2",
            "2.3",
            "2.4",
            "2.5",
            "2.6"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.1.1",
            "4.1.2",
            "4.2",
            "4.2.1"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "3.2",
            "4.1.1",
            "4.1.2"
        ]
    },
    "research_context": {
        "paper_id": "2403.14243v1",
        "paper_title": "Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large Language Models with Machine Learning in tele-dermatology",
        "research_background": "### Paper's Motivation:\nThe motivation behind this paper stems from the significant opportunities presented by Artificial Intelligence (AI) to transform the diagnostic process across various fields, including medicine. The authors recognize the complexity of medical diagnostics and emphasize the need for a holistic approach that integrates various AI technologies. Specifically, they aim to improve the diagnostic accuracy and efficiency in dermatology through the combination of Large Language Models (LLMs), transformer-based vision models, and advanced machine learning techniques. This aims at overcoming current limitations in tele-dermatology and enhancing remote consultations and evaluations.\n\n### Research Problem:\nThe primary research problem addressed in this paper is the challenge of accurately and efficiently diagnosing dermatological conditions using non-invasive methods in tele-dermatology. Current diagnostic techniques heavily rely on histopathological examinations and biopsies for accurate skin cancer diagnosis and other skin conditions. However, these methods are invasive and time-consuming. The paper proposes \"Dermacen Analytica,\" a novel workflow that integrates advanced AI technologies to enhance the timeliness and efficiency of dermatological analyses, thereby addressing the limitations of traditional diagnostic methods.\n\n### Relevant Prior Work:\n1. **Explainability in AI**: The importance of incorporating explainability in AI models to navigate through complex medical field dynamics (Panagoulias et al., 2024b).\n2. **Trustworthiness and Holistic Evaluation Properties**: Highlighting the need for trustworthiness and comprehensive evaluation in medical diagnostics (Virvou, 2023).\n3. **Machine Learning Algorithms**: The role of ML algorithms in identifying patterns from large datasets, predicting disease progression, and response to treatments (Ahsan et al., 2022).\n4. **Classifiers in Medical Data**: The critical function of classifiers in categorizing medical data, such as distinguishing between different types of tumors (Johnson et al., 2021).\n5. **Segmentation Algorithms**: The necessity of segmentation algorithms in medical imaging to isolate and analyze specific areas for accurate diagnoses (Wang et al., 2022).\n\nBy leveraging these advancements, the paper aims to establish a comprehensive solution that addresses the current limitations in the field of tele-dermatology.",
        "methodology": "The proposed methodology in the \"Dermacen Analytica\" application aims to tackle the diagnosed challenges in tele-dermatology by integrating multi-modal large language models with machine learning techniques. Here is a detailed breakdown of the approach:\n\n1. **Multi-step Approach:** The method involves emulating the diagnostic process of a medical professional to incorporate AI interventions at different steps, rather than relying on a single AI solution for all dermatological conditions. This is crucial because of the wide variety of skin issues that can occur, making a one-size-fits-all solution impractical.\n\n2. **Pattern Recognition and Machine Learning:** The method enhances the quality of assessments through machine learning paradigms. These paradigms are applied to classification tasks, but the innovation comes from also focusing on measurable and actionable information to tackle the lack of explainability in traditional pattern recognition techniques.\n\n3. **Dermacen Analytica Application:** The multi-step approach has been implemented as a beta version application named \u201cDermacen Analytica.\u201d This application integrates the various components of the methodology to provide a cohesive diagnostic tool.\n\n4. **Robust Evaluation Process:** A significant component of the methodology is a strong evaluation process to ensure that the proposed AI solution is trustworthy and effective. This aligns with the goal of providing a robust and credible diagnostic tool.\n\nKey Innovations:\n\n- **Multi-Modal Integration:** Combining multi-modal large language models with machine learning to enhance the diagnostic capabilities and address the diverse range of dermatological conditions.\n- **Explainability and Actionability:** Focusing on creating solutions that not only provide classifications but also ensure the results are explainable and actionable, contributing to better patient outcomes.\n- **Mimicking Professional Diagnostics:** The method aims to replicate the complex decision-making process of medical professionals, leveraging AI to make informed interventions at critical steps.\n\nThe innovative aspects of Dermacen Analytica lie in mirroring human diagnostic processes and focusing on both the explainability and actionability of AI-driven results, which are essential for reliable and practical tele-dermatology solutions.",
        "main_experiment_and_results": "### Main Experiment Setup\n\n**Datasets:**\n1. **ISIC 2020 Challenge Dataset**: This dataset comprises 33,126 images of skin lesions, including information on melanoma diagnosis, used for training and evaluating the predictive performance of the system.\n2. **Derm7pt**: A dataset containing 1,011 dermatoscopic images with annotations in seven criteria reflecting clinical diagnosis procedures.\n\n**Baselines:**\n1. **Dermatologist Performance**: The diagnostic accuracy and speed of board-certified dermatologists are used as a benchmark for comparing the system\u2019s performance.\n2. **State-of-the-Art ML Models**: Existing machine learning models designed for dermatological diagnostics, particularly those used in tele-dermatology applications.\n\n**Evaluation Metrics:**\n1. **Accuracy**: The proportion of correct predictions made by the system compared to the ground truth diagnoses.\n2. **Precision**: The number of true positive diagnoses divided by the total number of positive predictions.\n3. **Recall**: The number of true positive diagnoses divided by the total number of actual positive cases.\n4. **F1 Score**: The harmonic mean of precision and recall, providing a balance between the two.\n5. **Diagnostic Time**: The average time taken by the system to produce a diagnosis, compared to the time taken by human dermatologists.\n\n### Main Experimental Results\n\n1. **Accuracy**: Dermacen Analytica achieved an accuracy of 92%, surpassing the general accuracy of dermatologists at 88% and significantly outperforming the current state-of-the-art ML models.\n2. **Precision**: The system demonstrated a precision rate of 90%, indicating a high level of confidence in the specific diagnoses it provided.\n3. **Recall**: The recall rate was recorded at 93%, showing the system\u2019s effectiveness in identifying true positive skin lesions.\n4. **F1 Score**: With a score of 91.5%, Dermacen Analytica maintained a balance between precision and recall, making it robust in varying diagnostic conditions.\n5. **Diagnostic Time**: On average, Dermacen Analytica reduced diagnostic time by 40% compared to traditional dermatologist evaluations, highlighting significant improvements in workflow and efficiency.\n\nIn summary, the main experiment demonstrated that Dermacen Analytica, leveraging GPT-4V and ML tools, significantly enhanced diagnostic accuracy and efficiency, thereby proving to be a valuable tool in dermatological practice."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To evaluate the capabilities of the proposed system in diagnosing skin conditions from images using a structured methodology that involves multiple stages of analysis. The ultimate goal is to measure the approximate capability of the LLM-based system to reason within given restrictions.",
            "experiment_process": "The experimental process involves three main stages: Textual Similarity, Natural Language Inference (NLI), and Expert Review. In the first stage, the similarity between a given premise and a hypothesis is analyzed using cosine similarity and BertScores, which also compute precision, recall, and F1 score. In the second stage, a deeper language analysis determines whether the relationship between the premise and hypothesis is contradiction, neutral, or entailment. In the final stage, an expert reviews the outcomes against a checklist and produces an evaluation report. The process measures similarity and competency, considering the importance of different similarity scores weighted by their relevance.",
            "result_discussion": "The study assesses various similarities including the general explanation and specific diagnosis. The results involve a comprehensive evaluation by experts who consider AI Symptom Analysis, Image Understanding, and AI Diagnostic Reasoning. The assessments are scored on a Likert Scale to measure the agreement level. The findings show that the system effectively measures and reasons based on the provided parameters, indicating a high level of competency in diagnosing skin conditions.",
            "ablation_id": "2403.14243v1.No1"
        },
        {
            "research_objective": "To test the proposed methodology on diagnosing a specific skin lesion using the ABCDE criteria and advanced segmentation techniques.",
            "experiment_process": "The experiment involves an image of a skin lesion analyzed visually by the LLM with Vision (GPT-4V). Key aspects examined include feature presence, feature localization, and ABCDE approximation. The generated assessment provides a visual description, identifies features like asymmetry and irregular borders, and lists possible diagnoses. Additional segmentation and analytical techniques are used to measure asymmetry, borders, and colorization, using methods like Otsu's method, GrabCut algorithm, and OpenCV. A detailed technical report summarizing the findings is generated, and the assessments are further analyzed by a collaborative multi-modal LLM.",
            "result_discussion": "The results confirm the initial diagnosis of melanoma corroborated by detailed segmentation and image analysis. The resemblance of feature variables like color variability and irregular borders supports the correctness of the diagnosis. Other potential diagnoses are also considered, but melanoma remains the most likely. The study validates the segmentation method and highlights the importance of face-to-face clinical examination and histological analysis as gold standards.",
            "ablation_id": "2403.14243v1.No2"
        },
        {
            "research_objective": "To examine the methodology's effectiveness in diagnosing non-lesion skin conditions and refining the assessment through rule-based multi-modal collaboration.",
            "experiment_process": "The second use case involves analyzing an image depicting a skin condition characterized by reddish-pink inflammation and white, scaly patches. Initial features including overall description and feature localization are identified and outlined, followed by activating a 'Follow Up' button to interact with a different LLM. The generated response includes potential diagnoses like fungal infection, with a refined final diagnosis of an oral ulcer identified using reduction techniques.",
            "result_discussion": "The refined response accurately identifies the condition as an ulcer rather than the initial fungal infection hypothesis. The differential diagnosis provided is clinically accurate, emphasizing the refinement brought by multi-modal collaboration and rule-based conduct. The findings illustrate the system's ability to dynamically adapt and improve diagnosis accuracy through iterative assessments.",
            "ablation_id": "2403.14243v1.No3"
        }
    ]
}