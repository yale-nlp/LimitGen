{
    "title": "Leveraging Prototypical Representations for Mitigating Social Bias without Demographic Information",
    "abstract": "Mitigating social biases typically requires identifying the social groups associated with each data sample. In this paper, we present DaFair, a novel approach to address social bias in language models. Unlike traditional methods that rely on explicit demographic labels, our approach does not require any such information. Instead, we leverage predefined prototypical demographic texts and incorporate a regularization term during the fine-tuning process to mitigate bias in the model\u2019s representations. Our empirical results across two tasks and two models demonstrate the effectiveness of our method compared to previous approaches that do not rely on labeled data. Moreover, with limited demographic-annotated data, our approach outperforms common debiasing approaches.111Our code is available at https://github.com/technion-cs-nlp/DAFair",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction and Background",
            "text": "The presence of social bias in training data presents a significant challenge in the development of language models for real-world applications. While these models possess remarkable capabilities, biases within the data can lead to unfair outcomes. Mitigating these biases is crucial, but it becomes particularly challenging when acquiring or accessing sensitive attribute labels is costly or unfeasible.\nStudies showed that language models have the ability to capture demographic information about the writer, including race or gender, within their representations Caliskan et al. (2017  ###reference_b3###); Zhao et al. (2018  ###reference_b21###). However, this capability can introduce unintended biases, leading to discriminatory outputs De-Arteaga et al. (2019  ###reference_b4###).\n###figure_1### Common approaches for social bias mitigation require explicit annotation of biases for each sample in the data Beutel et al. (2017  ###reference_b1###); Zhang et al. (2018  ###reference_b20###). Recent concept removal methods Ravfogel et al. (2020  ###reference_b15###, 2022a  ###reference_b16###, 2022b  ###reference_b17###); Iskander et al. (2023  ###reference_b9###) have shown promise in addressing social bias by removing sensitive attributes. These approaches rely on training classifiers for predicting the sensitive attribute, and training such classifiers typically requires a significant amount of annotated data.\nA promising line of research has emerged that aims to mitigate bias without relying on explicit information about the biases present in the data. For instance,\nJust Train Twice (JTT) Liu et al. (2021  ###reference_b11###) employs a two-step training process. In the second step, a second model is trained on up-weighed training examples that were misclassified by the first model. Another method is\nBLIND Orgad and Belinkov (2023  ###reference_b14###), which\nintroduces a success detector and down-weighs examples for which the detector accurately predicts the outcome.\nIn this paper, we propose DaFair: Demographics-Agnostic Fairness, a novel approach for mitigating social bias during the fine-tuning process of language models, without relying on demographic information. Our approach aims to ensure equal similarity between the representation of a text and prototypical representations of different demographic groups. For instance, when classifying a biographical text of a person into their profession, our method aims to make the representation of the text equally similar to the representations of both males and females. More concretely, DaFair first defines prototypical texts, such as \u201cThis is a biography about a male\u201d and \u201cThis is a biography about a female\u201d. It then adds a regularization term that makes the representation of a training example equally similar to the representations of each of the prototypical texts (Figure 1  ###reference_###).\nFurthermore, we extend our approach to scenarios where limited demographic-annotated data is available. In such cases, we obtain the prototypical representation by averaging the sample representations corresponding to each social attribute.\nWe evaluate the effectiveness of DaFair and its extension on two tasks: occupation prediction and sentiment analysis of twitter posts. In these tasks, we investigate the performance of our approach under the settings of limited demographic labels or no labels at all, reflecting real-world scenarios where labeled data is challenging to obtain. The experimental results with two base models demonstrate that our approach outperforms previous approaches that do not rely on demographic information, as well as common approaches with limited data."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Methodology",
            "text": "Assume a dataset  of input texts , main task labels , and sensitive attributes  that correspond to discrete demographic attributes, such as race. This sensitive attribute can either be unobserved during training or available in a small subset of the data. Our aim is to learn a model  that does not rely on the sensitive attribute  in its prediction.\nIn the absence of labeled data, we leverage semantic similarity and define pairs of texts that capture the models\u2019 understanding of text describing different social attribute groups. For example, to represent gender in an occupation prediction task we can use the encoder\u2019s representations of \u201cThis biography is about a man\u201d and \u201cThis biography is about a woman\u201d. To generate these pre-defined representations, we employ a generative model. We provided ChatGPT OpenAI (2022  ###reference_b12###) with a description of the approach, DaFair, along with a description of each dataset and task, and instructed the model to produce 10 pairs of prototypical texts for each task. The prototypical texts (Tables 7  ###reference_### and 8  ###reference_###) and the full prompt (Figure 4  ###reference_###) are provided in the appendix.\nWhen a limited number of labels are available, we leverage the representations generated by the text encoder to derive data-driven representations for each labeled group. Specifically, we calculate the mean representation of each labeled group using the available labeled samples. We call this method Semi-DaFair.\nWe will assume a binary case for simplicity and denote the pair of representations as .222Our approach can be extended to handle multiple social attribute groups, denoted as ."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Demographic-Agnostic Fairness Approach",
            "text": "Our method, depicted in Fig. 1  ###reference_###, involves several key steps to mitigate social bias. First, we establish multiple representations for each group of sensitive attributes (Section 2.1.1  ###reference_.SSS1###). During fine-tuning, we measure\nsimilarity between the representation of an example and each attribute representation. These similarities are then transformed into a probability distribution. Subsequently, we use the Kullback-Leibler (KL) divergence loss Kullback and Leibler (1951  ###reference_b10###) to compare the predicted probability distribution with a uniform distribution (Section 2.1.3  ###reference_.SSS3###). This loss term encourages the model to mitigate bias by penalizing deviations from a uniform distribution, promoting fair and unbiased predictions.\nIn the absence of labeled data, we leverage semantic similarity and define pairs of texts that capture the models\u2019 understanding of text describing different social attribute groups. For example, to represent gender in an occupation prediction task we can use the encoder\u2019s representations of \u201cThis biography is about a man\u201d and \u201cThis biography is about a woman\u201d. To generate these pre-defined representations, we employ a generative model. We provided ChatGPT OpenAI (2022  ###reference_b12###  ###reference_b12###) with a description of the approach, DaFair, along with a description of each dataset and task, and instructed the model to produce 10 pairs of prototypical texts for each task. The prototypical texts (Tables 7  ###reference_###  ###reference_### and 8  ###reference_###  ###reference_###) and the full prompt (Figure 4  ###reference_###  ###reference_###) are provided in the appendix.\nWhen a limited number of labels are available, we leverage the representations generated by the text encoder to derive data-driven representations for each labeled group. Specifically, we calculate the mean representation of each labeled group using the available labeled samples. We call this method Semi-DaFair.\nWe will assume a binary case for simplicity and denote the pair of representations as .222Our approach can be extended to handle multiple social attribute groups, denoted as ."
        },
        {
            "section_id": "2.1.1",
            "parent_section_id": "2.1",
            "section_name": "2.1.1 Social Attribute Representations",
            "text": "We employ two approaches to define representations for social attribute groups, depending on the availability of labels: no labels, or few labels.\nIn the absence of labeled data, we leverage semantic similarity and define pairs of texts that capture the models\u2019 understanding of text describing different social attribute groups. For example, to represent gender in an occupation prediction task we can use the encoder\u2019s representations of \u201cThis biography is about a man\u201d and \u201cThis biography is about a woman\u201d. To generate these pre-defined representations, we employ a generative model. We provided ChatGPT OpenAI (2022  ###reference_b12###  ###reference_b12###  ###reference_b12###) with a description of the approach, DaFair, along with a description of each dataset and task, and instructed the model to produce 10 pairs of prototypical texts for each task. The prototypical texts (Tables 7  ###reference_###  ###reference_###  ###reference_### and 8  ###reference_###  ###reference_###  ###reference_###) and the full prompt (Figure 4  ###reference_###  ###reference_###  ###reference_###) are provided in the appendix.\nWhen a limited number of labels are available, we leverage the representations generated by the text encoder to derive data-driven representations for each labeled group. Specifically, we calculate the mean representation of each labeled group using the available labeled samples. We call this method Semi-DaFair.\nWe will assume a binary case for simplicity and denote the pair of representations as .222Our approach can be extended to handle multiple social attribute groups, denoted as ."
        },
        {
            "section_id": "2.1.2",
            "parent_section_id": "2.1",
            "section_name": "2.1.2 Ensemble of Representations",
            "text": "Inspired by Stacey et al. (2020  ###reference_b18###), we adopt an ensemble approach by leveraging multiple pairs of representations instead of using a single pair. We denote the ensemble of representations as , where  represents the number of pairs.\nIn the case of pre-defined representations, we use multiple pre-defined pairs that capture different perspectives. For data-driven representations, we divide the labeled data into K partitions and calculate the mean representation for each partition, resulting in K pairs of representations.\nBy incorporating an ensemble of representations, we aim to capture a diverse range of information and perspectives related to biases."
        },
        {
            "section_id": "2.1.3",
            "parent_section_id": "2.1",
            "section_name": "2.1.3 Calculating KL Loss",
            "text": "During fine-tuning, we calculate the similarity between the representation of example  and each pair of attribute representations using dot product:\nThen we apply the softmax function  to obtain the similarity distribution:\nTo calculate the overall KL loss, we compute KL divergence between each of the similarity distributions  and a uniform distribution :\nFinally, we compute the total loss:\nwhere  is the usual cross-entropy loss.\nThe hyper-parameter  adjusts the balance between task performance and fairness, providing flexibility to prioritize either aspect."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Experimental Setup",
            "text": "We use the Bias in Bios Dataset De-Arteaga et al. (2019  ###reference_b4###).\nThe task involves predicting the occupation of individuals based on their biographical information. The dataset consists of 394K biographies of 28 professions, with gender annotations.\nWe follow the setup of Elazar and Goldberg (2018  ###reference_b6###), who leveraged a Twitter dataset originally gathered by Blodgett et al. (2016  ###reference_b2###). Elazar and Goldberg (2018  ###reference_b6###) used emojis in the tweets to derive sentiment labels for the classification task. Tweets are labeled with sociolects\u2014African American English (AAE) or Standard American English (SAE)\u2014based on the author\u2019s geo-location, serving as a proxy for their racial identity. We work with a subset of 100K samples, consistent with Orgad and Belinkov (2023  ###reference_b14###).\nWe evaluate the model\u2019s accuracy (Acc) on the downstream task to ensure that it has not been significantly affected.\nTo evaluate extrinsic bias, we align with previous work De-Arteaga et al. (2019  ###reference_b4###); Ravfogel et al. (2020  ###reference_b15###) and use the True Positive Rate Gap (TPR-GAP) as the main fairness metric to assess performance disparities across different protected attribute groups. Following the guidelines in Orgad and Belinkov (2022  ###reference_b13###) for a comprehensive evaluation, we also incorporate statistical fairness metrics: Independence, Separation and Sufficiency. The metrics details and calculation procedures are provided in Appendix B  ###reference_###.\nMethod\nOriginal\nJTT\nBLIND\nIn this setting, we explore scenarios where demographic labels are not available. We evaluate the performance of demographic-agnostic methods: JTT, BLIND and DAFAIR.\nAdditionally, we investigate a scenario where we have limited access to demographic labels. In this setting, we apply information removal methods along with Semi-DaFairwhile varying the size of the available demographic-labeled data to analyze their effectiveness.\nWe run each method using 5 random seeds and report the mean and standard deviation of the test results. More details on training setup and evaluation procedures are described in Appendix A  ###reference_###.\nTo perform  tuning without the need for a validation set with demographic annotations, we adopt Orgad and Belinkov (2023  ###reference_b14###)\u2019s strategy that prioritizes selecting the most radical parameter, while ensuring that the downstream task accuracy remains above 0.97 of the original accuracy. More details are described in Appendix A  ###reference_###."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Tasks",
            "text": "We conduct experiments on two classification tasks: occupation prediction and sentiment analysis, focusing on social bias related to gender and race.\nWe use the Bias in Bios Dataset De-Arteaga et al. (2019  ###reference_b4###  ###reference_b4###).\nThe task involves predicting the occupation of individuals based on their biographical information. The dataset consists of 394K biographies of 28 professions, with gender annotations.\nWe follow the setup of Elazar and Goldberg (2018  ###reference_b6###  ###reference_b6###), who leveraged a Twitter dataset originally gathered by Blodgett et al. (2016  ###reference_b2###  ###reference_b2###). Elazar and Goldberg (2018  ###reference_b6###  ###reference_b6###) used emojis in the tweets to derive sentiment labels for the classification task. Tweets are labeled with sociolects\u2014African American English (AAE) or Standard American English (SAE)\u2014based on the author\u2019s geo-location, serving as a proxy for their racial identity. We work with a subset of 100K samples, consistent with Orgad and Belinkov (2023  ###reference_b14###  ###reference_b14###)."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Models",
            "text": "We use two pre-trained text encoders: BERT Devlin et al. (2019  ###reference_b5###) and DeBERTa-V3 He et al. (2022  ###reference_b8###). By considering two diverse tasks and different models, we can evaluate the effectiveness of our approach in mitigating social bias in various contexts and with different model architectures."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Metrics",
            "text": "We evaluate the model\u2019s accuracy (Acc) on the downstream task to ensure that it has not been significantly affected.\nTo evaluate extrinsic bias, we align with previous work De-Arteaga et al. (2019  ###reference_b4###  ###reference_b4###); Ravfogel et al. (2020  ###reference_b15###  ###reference_b15###) and use the True Positive Rate Gap (TPR-GAP) as the main fairness metric to assess performance disparities across different protected attribute groups. Following the guidelines in Orgad and Belinkov (2022  ###reference_b13###  ###reference_b13###) for a comprehensive evaluation, we also incorporate statistical fairness metrics: Independence, Separation and Sufficiency. The metrics details and calculation procedures are provided in Appendix B  ###reference_###  ###reference_###.\nMethod\nOriginal\nJTT\nBLIND"
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Compared Methods",
            "text": "We compare our approach with several methods for bias mitigation and with a baseline (Original) without any debiasing procedure.\nWe compare with two existing methods that do not rely on demographic information:\nJTT Liu et al. (2021  ###reference_b11###), which trains in a second phase on up-weighed hard examples.\nBLIND Orgad and Belinkov (2023  ###reference_b14###), which uses a success detector to down-weigh biased examples.\nWhen only limited demographic labeled samples are available, we evaluate three methods:\nINLP Ravfogel et al. (2020  ###reference_b15###) removes linear information from the neural\nrepresentation by iteratively training a linear\nclassifier to predict the demographic attribute from the representation,\nthen projecting the representations\nto the null-space of the linear classifier.\nRLACE Ravfogel et al. (2022b  ###reference_b17###) is similar to INLP with the goal of linear information removal from the neural representations. However, it uses a different approach of a linear minimax game.\nIGBP Iskander et al. (2023  ###reference_b9###) overcome the drawbacks of INLP and RLACE which only remove linearly encoded information, and removes non-linear information from representations by gradient-based projections."
        },
        {
            "section_id": "3.5",
            "parent_section_id": "3",
            "section_name": "Settings",
            "text": "In this setting, we explore scenarios where demographic labels are not available. We evaluate the performance of demographic-agnostic methods: JTT, BLIND and DAFAIR.\nAdditionally, we investigate a scenario where we have limited access to demographic labels. In this setting, we apply information removal methods along with Semi-DaFairwhile varying the size of the available demographic-labeled data to analyze their effectiveness.\nWe run each method using 5 random seeds and report the mean and standard deviation of the test results. More details on training setup and evaluation procedures are described in Appendix A  ###reference_###  ###reference_###."
        },
        {
            "section_id": "3.6",
            "parent_section_id": "3",
            "section_name": "DaFair Hyperparameters",
            "text": "Under the setting of no demographic labels, there is no validation set to optimize the selection of prototypical texts or the number of pairs. To avoid dependency on the choice of prototypical representations, we first generate  pairs, and within each iteration, we randomly sample  pairs. For all experiments, we set  ,  to capture diverse associations of the training samples with demographic attributes, without relying on an extensive set of pairs. In Section 4.3  ###reference_###, we analyze the impact of  on the model\u2019s performance and assess its implications on fairness and bias mitigation.\nTo perform  tuning without the need for a validation set with demographic annotations, we adopt Orgad and Belinkov (2023  ###reference_b14###  ###reference_b14###)\u2019s strategy that prioritizes selecting the most radical parameter, while ensuring that the downstream task accuracy remains above 0.97 of the original accuracy. More details are described in Appendix A  ###reference_###  ###reference_###."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Results and Analysis",
            "text": ""
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Effect of Number of Prototypical Texts",
            "text": "To investigate the effect of the number of prototypical text pairs (K) on model performance, we conducted experiments with varying K values of (1, 2, 4, 8). The results presented in Table 2 reveal that all K values contribute to the reduction of the TPR-GAP without affecting accuracy. While larger values of K result in more substantial reductions, the incremental improvements become less significant. These findings suggest that a small K may be sufficient for DaFair."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "We introduced DaFair, a novel approach for mitigating social bias in language models without explicit demographic information. Our method leverages semantic similarity to manipulate the model\u2019s text representations during finetuning to promote fairness. Experimental results on two tasks and under different settings demonstrated the effectiveness of DaFair in reducing bias and improving fairness while maintaining competitive downstream task performance, even with limited or no labeled demographic data. With its focus on social bias, DaFair offers a flexible framework adaptable to address other forms of bias through the modification of prototypical texts.\nIn conclusion, our approach offers a practical and flexible solution for bias mitigation in real-world applications, contributing to the development of fairer language models."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Setup",
            "text": ""
        },
        {
            "section_id": "Appendix 2",
            "parent_section_id": null,
            "section_name": "Appendix B Fairness Metrics",
            "text": ""
        },
        {
            "section_id": "Appendix 3",
            "parent_section_id": null,
            "section_name": "Appendix C Full Results",
            "text": "Tables 3  ###reference_### and 4  ###reference_### present comprehensive results for the occupation prediction and sentiment analysis tasks, respectively, employing BERT as the text encoder. Each method\u2019s performance is evaluated across multiple metrics, including Accuracy, TPR-GAP, Independence, Separation, and Sufficiency (Section B  ###reference_###). Here we also see that our proposed method reduces Independence, Separation, and Sufficiency values, in both tasks."
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T1.20\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T1.20.21.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S3.T1.20.21.1.1\" style=\"width:71.1pt;padding:2pt 10.0pt;\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" id=\"S3.T1.20.21.1.2\" style=\"padding:2pt 10.0pt;\">Occupation Prediction</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" id=\"S3.T1.20.21.1.3\" style=\"padding:2pt 10.0pt;\">Sentiment Analysis</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.4\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row\" id=\"S3.T1.4.4.5\" style=\"width:71.1pt;padding:2pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S3.T1.4.4.5.1\">Method</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.1.1\" style=\"padding:2pt 10.0pt;\">Accuracy \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.2.2.2\" style=\"padding:2pt 10.0pt;\">TPR-GAP \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.3.3.3\" style=\"padding:2pt 10.0pt;\">Accuracy \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.4.4.4\" style=\"padding:2pt 10.0pt;\">TPR-GAP \n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.8.8\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.8.8.5\" style=\"width:71.1pt;padding:2pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S3.T1.8.8.5.1\">Original</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.5.5.1\" style=\"padding:2pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.6.6.2\" style=\"padding:2pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.7.7.3\" style=\"padding:2pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.8.8.4\" style=\"padding:2pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.12.12\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.12.12.5\" style=\"width:71.1pt;padding:2pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S3.T1.12.12.5.1\">JTT</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.9.9.1\" style=\"padding:2pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.10.10.2\" style=\"padding:2pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.11.11.3\" style=\"padding:2pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.12.12.4\" style=\"padding:2pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.16.16\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row\" id=\"S3.T1.16.16.5\" style=\"width:71.1pt;padding:2pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S3.T1.16.16.5.1\">BLIND</p>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.13.13.1\" style=\"padding:2pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.14.14.2\" style=\"padding:2pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.15.15.3\" style=\"padding:2pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.16.16.4\" style=\"padding:2pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.20.20\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T1.20.20.5\" style=\"width:71.1pt;padding:2pt 10.0pt;\"><span class=\"ltx_text ltx_font_smallcaps ltx_align_top\" id=\"S3.T1.20.20.5.1\">DaFair</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.17.17.1\" style=\"padding:2pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.18.18.2\" style=\"padding:2pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.19.19.3\" style=\"padding:2pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.20.20.4\" style=\"padding:2pt 10.0pt;\"></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Evaluation results for occupation prediction and sentiment analysis tasks with BERT as the text encoder.</figcaption>\n</figure>",
            "capture": "Table 1: Evaluation results for occupation prediction and sentiment analysis tasks with BERT as the text encoder."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T2\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.24\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.24.25.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T2.24.25.1.1\" style=\"padding:1pt 8.0pt;\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T2.24.25.1.2\" style=\"padding:1pt 8.0pt;\">Occupation Prediction</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T2.24.25.1.3\" style=\"padding:1pt 8.0pt;\">Sentiment Analysis</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" id=\"S4.T2.4.4.5\" style=\"padding:1pt 8.0pt;\">K</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.1.1.1\" style=\"padding:1pt 8.0pt;\">Accuracy \n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.2.2.2\" style=\"padding:1pt 8.0pt;\">TPR-GAP \n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.3.3\" style=\"padding:1pt 8.0pt;\">Accuracy \n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.4.4.4\" style=\"padding:1pt 8.0pt;\">TPR-GAP \n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.8.8.5\" style=\"padding:1pt 8.0pt;\">Original</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.5.5.1\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.2\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.7.7.3\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.8.8.4\" style=\"padding:1pt 8.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.12.12.5\" style=\"padding:1pt 8.0pt;\">1</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.9.9.1\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.10.10.2\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.11.11.3\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.12.12.4\" style=\"padding:1pt 8.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.16.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.16.16.5\" style=\"padding:1pt 8.0pt;\">2</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.13.13.1\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.14.14.2\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.15.15.3\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.16.16.4\" style=\"padding:1pt 8.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.20.20\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.20.20.5\" style=\"padding:1pt 8.0pt;\">4</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.17.17.1\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.18.18.2\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.19.19.3\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.20.20.4\" style=\"padding:1pt 8.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.24.24\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T2.24.24.5\" style=\"padding:1pt 8.0pt;\">8</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.21.21.1\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.22.22.2\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.23.23.3\" style=\"padding:1pt 8.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.24.24.4\" style=\"padding:1pt 8.0pt;\"></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Effect of varying K on accuracy and TPR-GAP for occupation prediction and sentiment analysis tasks.</figcaption>\n</figure>",
            "capture": "Table 2: Effect of varying K on accuracy and TPR-GAP for occupation prediction and sentiment analysis tasks."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T3\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A3.T3.25\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A3.T3.25.26.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"A3.T3.25.26.1.1\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"5\" id=\"A3.T3.25.26.1.2\" style=\"padding:1.5pt 10.0pt;\">Occupation Prediction</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T3.5.5\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row\" id=\"A3.T3.5.5.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T3.5.5.6.1\">Method</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.1.1.1\" style=\"padding:1.5pt 10.0pt;\">Accuracy \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.2.2.2\" style=\"padding:1.5pt 10.0pt;\">TPR-GAP \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.3.3.3\" style=\"padding:1.5pt 10.0pt;\">Indep \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.4.4.4\" style=\"padding:1.5pt 10.0pt;\">Sep \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.5.5.5\" style=\"padding:1.5pt 10.0pt;\">Suff \n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T3.10.10\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t\" id=\"A3.T3.10.10.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T3.10.10.6.1\">Original</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.6.6.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.7.7.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.8.8.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.9.9.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.10.10.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T3.15.15\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t\" id=\"A3.T3.15.15.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T3.15.15.6.1\">JTT</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.11.11.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.12.12.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.13.13.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.14.14.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T3.15.15.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T3.20.20\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row\" id=\"A3.T3.20.20.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T3.20.20.6.1\">BLIND</p>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T3.16.16.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T3.17.17.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T3.18.18.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T3.19.19.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T3.20.20.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T3.25.25\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_bb\" id=\"A3.T3.25.25.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\"><span class=\"ltx_text ltx_font_smallcaps ltx_align_top\" id=\"A3.T3.25.25.6.1\">DaFair</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T3.21.21.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T3.22.22.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T3.23.23.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T3.24.24.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T3.25.25.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Full results for the occupation prediction task with BERT as the text encoder.</figcaption>\n</figure>",
            "capture": "Table 3: Full results for the occupation prediction task with BERT as the text encoder."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T4\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A3.T4.25\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A3.T4.25.26.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"A3.T4.25.26.1.1\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"5\" id=\"A3.T4.25.26.1.2\" style=\"padding:1.5pt 10.0pt;\">Sentiment Analysis</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T4.5.5\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row\" id=\"A3.T4.5.5.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T4.5.5.6.1\">Method</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.1.1.1\" style=\"padding:1.5pt 10.0pt;\">Accuracy \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.2.2.2\" style=\"padding:1.5pt 10.0pt;\">TPR-GAP \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.3.3.3\" style=\"padding:1.5pt 10.0pt;\">Indep \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.4.4.4\" style=\"padding:1.5pt 10.0pt;\">Sep \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.5.5.5\" style=\"padding:1.5pt 10.0pt;\">Suff \n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T4.10.10\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t\" id=\"A3.T4.10.10.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T4.10.10.6.1\">Original</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.6.6.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.7.7.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.8.8.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.9.9.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.10.10.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T4.15.15\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t\" id=\"A3.T4.15.15.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T4.15.15.6.1\">JTT</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.11.11.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.12.12.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.13.13.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.14.14.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.15.15.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T4.20.20\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row\" id=\"A3.T4.20.20.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T4.20.20.6.1\">BLIND</p>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T4.16.16.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T4.17.17.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T4.18.18.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T4.19.19.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T4.20.20.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T4.25.25\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_bb\" id=\"A3.T4.25.25.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\"><span class=\"ltx_text ltx_font_smallcaps ltx_align_top\" id=\"A3.T4.25.25.6.1\">DaFair</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T4.21.21.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T4.22.22.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T4.23.23.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T4.24.24.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T4.25.25.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Full results for the sentiment analysis task with BERT as the text encoder.</figcaption>\n</figure>",
            "capture": "Table 4: Full results for the sentiment analysis task with BERT as the text encoder."
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T5\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A3.T5.25\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A3.T5.25.26.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"A3.T5.25.26.1.1\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"5\" id=\"A3.T5.25.26.1.2\" style=\"padding:1.5pt 10.0pt;\">Occupation Prediction</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T5.5.5\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row\" id=\"A3.T5.5.5.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T5.5.5.6.1\">Method</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.1.1.1\" style=\"padding:1.5pt 10.0pt;\">Accuracy \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.2.2.2\" style=\"padding:1.5pt 10.0pt;\">TPR-GAP \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.3.3.3\" style=\"padding:1.5pt 10.0pt;\">Indep \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.4.4.4\" style=\"padding:1.5pt 10.0pt;\">Sep \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.5.5.5\" style=\"padding:1.5pt 10.0pt;\">Suff \n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T5.10.10\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t\" id=\"A3.T5.10.10.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T5.10.10.6.1\">Original</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.6.6.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.7.7.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.8.8.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.9.9.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.10.10.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T5.15.15\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t\" id=\"A3.T5.15.15.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T5.15.15.6.1\">JTT</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.11.11.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.12.12.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.13.13.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.14.14.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.15.15.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T5.20.20\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row\" id=\"A3.T5.20.20.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T5.20.20.6.1\">BLIND</p>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.16.16.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.17.17.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.18.18.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.19.19.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.20.20.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T5.25.25\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_bb\" id=\"A3.T5.25.25.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\"><span class=\"ltx_text ltx_font_smallcaps ltx_align_top\" id=\"A3.T5.25.25.6.1\">DaFair</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T5.21.21.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T5.22.22.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T5.23.23.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T5.24.24.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T5.25.25.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>Full results for the occupation prediction task with DeBERTa as the text encoder.</figcaption>\n</figure>",
            "capture": "Table 5: Full results for the occupation prediction task with DeBERTa as the text encoder."
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T6\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A3.T6.25\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A3.T6.25.26.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"A3.T6.25.26.1.1\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"5\" id=\"A3.T6.25.26.1.2\" style=\"padding:1.5pt 10.0pt;\">Sentiment Analysis</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.5.5\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row\" id=\"A3.T6.5.5.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T6.5.5.6.1\">Method</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.1.1.1\" style=\"padding:1.5pt 10.0pt;\">Accuracy \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.2.2.2\" style=\"padding:1.5pt 10.0pt;\">TPR-GAP \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.3.3.3\" style=\"padding:1.5pt 10.0pt;\">Indep \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.4.4.4\" style=\"padding:1.5pt 10.0pt;\">Sep \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.5.5.5\" style=\"padding:1.5pt 10.0pt;\">Suff \n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.10.10\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t\" id=\"A3.T6.10.10.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T6.10.10.6.1\">Original</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.6.6.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.7.7.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.8.8.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.9.9.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.10.10.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.15.15\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t\" id=\"A3.T6.15.15.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T6.15.15.6.1\">JTT</p>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.11.11.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.12.12.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.13.13.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.14.14.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.15.15.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.20.20\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row\" id=\"A3.T6.20.20.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T6.20.20.6.1\">BLIND</p>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.16.16.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.17.17.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.18.18.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.19.19.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.20.20.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.25.25\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_bb\" id=\"A3.T6.25.25.6\" style=\"width:71.1pt;padding:1.5pt 10.0pt;\"><span class=\"ltx_text ltx_font_smallcaps ltx_align_top\" id=\"A3.T6.25.25.6.1\">DaFair</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T6.21.21.1\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T6.22.22.2\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T6.23.23.3\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T6.24.24.4\" style=\"padding:1.5pt 10.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T6.25.25.5\" style=\"padding:1.5pt 10.0pt;\"></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 6: </span>Full results for the sentiment analysis task with DeBERTa as the text encoder.</figcaption>\n</figure>",
            "capture": "Table 6: Full results for the sentiment analysis task with DeBERTa as the text encoder."
        },
        "7": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T7\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A3.T7.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A3.T7.1.1.1\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T7.1.1.1.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"A3.T7.1.1.1.1.1\">Male Prototypical Texts</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"A3.T7.1.1.1.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"A3.T7.1.1.1.2.1\">Female Prototypical Texts</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A3.T7.1.2.1\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T7.1.2.1.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.2.1.1.1\">This is a biography about a male.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T7.1.2.1.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.2.1.2.1\">This is a biography about a female.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T7.1.3.2\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T7.1.3.2.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.3.2.1.1\">A man who excelled in his field.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T7.1.3.2.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.3.2.2.1\">A woman who excelled in her field.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T7.1.4.3\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T7.1.4.3.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.4.3.1.1\">He is known for his achievements in various industries.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T7.1.4.3.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.4.3.2.1\">She is known for her achievements in various industries.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T7.1.5.4\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T7.1.5.4.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.5.4.1.1\">A prominent male figure in history.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T7.1.5.4.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.5.4.2.1\">A prominent female figure in history.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T7.1.6.5\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T7.1.6.5.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.6.5.1.1\">His career and accomplishments are well-regarded.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T7.1.6.5.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.6.5.2.1\">Her career and accomplishments are well-regarded.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T7.1.7.6\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T7.1.7.6.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.7.6.1.1\">This biography focuses on the life of a distinguished man.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T7.1.7.6.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.7.6.2.1\">This biography focuses on the life of a distinguished woman.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T7.1.8.7\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T7.1.8.7.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.8.7.1.1\">An influential male individual.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T7.1.8.7.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.8.7.2.1\">An influential female individual.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T7.1.9.8\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T7.1.9.8.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.9.8.1.1\">He made significant contributions to his profession.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T7.1.9.8.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.9.8.2.1\">She made significant contributions to her profession.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T7.1.10.9\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T7.1.10.9.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.10.9.1.1\">This is a story about a man who shaped his industry.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T7.1.10.9.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.10.9.2.1\">This is a story about a woman who shaped her industry.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T7.1.11.10\">\n<td class=\"ltx_td ltx_align_justify ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T7.1.11.10.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.11.10.1.1\">His impact on his field is noteworthy.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_b ltx_border_r ltx_border_t\" id=\"A3.T7.1.11.10.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T7.1.11.10.2.1\">Her impact on her field is noteworthy.</p>\n</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 7: </span>Pre-defined Representations for Male and Female Biographical Texts</figcaption>\n</figure>",
            "capture": "Table 7: Pre-defined Representations for Male and Female Biographical Texts"
        },
        "8": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T8\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A3.T8.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A3.T8.1.1.1\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T8.1.1.1.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"A3.T8.1.1.1.1.1\">AAE Prototypical Texts</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"A3.T8.1.1.1.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"A3.T8.1.1.1.2.1\">SAE Prototypical Texts</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A3.T8.1.2.1\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T8.1.2.1.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.2.1.1.1\">This tweet reflects a [sentiment] from a white writer.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T8.1.2.1.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.2.1.2.1\">This tweet reflects a [sentiment] sentiment from a black writer.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T8.1.3.2\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T8.1.3.2.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.3.2.1.1\">A tweet expressing a [sentiment] moment by a white individual.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T8.1.3.2.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.3.2.2.1\">A tweet expressing a [sentiment] moment by a black individual.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T8.1.4.3\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T8.1.4.3.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.4.3.1.1\">A [sentiment] viewpoint shared by a writer using Standart American English.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T8.1.4.3.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.4.3.2.1\">A [sentiment] viewpoint shared by a writer using African American English.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T8.1.5.4\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T8.1.5.4.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.5.4.1.1\">This post, written in standard English, conveys [sentiment] from a white perspective.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T8.1.5.4.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.5.4.2.1\">This post, written in AAE, conveys [sentiment] from a black perspective.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T8.1.6.5\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T8.1.6.5.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.6.5.1.1\">A message filled with [sentiment] from a white communicator.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T8.1.6.5.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.6.5.2.1\">A message filled with [sentiment] from a black communicator.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T8.1.7.6\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T8.1.7.6.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.7.6.1.1\">A white person shares their [sentiment] thoughts in this tweet.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T8.1.7.6.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.7.6.2.1\">A black person shares their [sentiment] thoughts in this tweet.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T8.1.8.7\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T8.1.8.7.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.8.7.1.1\">This is an example of a tweet with [sentiment] in white sociolect.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T8.1.8.7.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.8.7.2.1\">This is an example of a tweet with [sentiment] sentiment in AAE.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T8.1.9.8\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T8.1.9.8.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.9.8.1.1\">A tweet written by a white speaker that conveys [sentiment].</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T8.1.9.8.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.9.8.2.1\">A tweet written by a black speaker that conveys [sentiment].</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T8.1.10.9\">\n<td class=\"ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T8.1.10.9.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.10.9.1.1\">This post by a white individual radiates [sentiment] and [sentiment].</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"A3.T8.1.10.9.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.10.9.2.1\">This post by a black individual radiates [sentiment] and [sentiment].</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T8.1.11.10\">\n<td class=\"ltx_td ltx_align_justify ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"A3.T8.1.11.10.1\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.11.10.1.1\">A [sentiment] perspective presented by a writer using white sociolect.</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_b ltx_border_r ltx_border_t\" id=\"A3.T8.1.11.10.2\" style=\"width:195.1pt;padding:1.5pt 10.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A3.T8.1.11.10.2.1\">A [sentiment] perspective presented by a writer using African American English.</p>\n</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 8: </span>Pre-defined Representations for AAE and SAE Tweet Texts</figcaption>\n</figure>",
            "capture": "Table 8: Pre-defined Representations for AAE and SAE Tweet Texts"
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.09516v3_figure_1.png",
            "caption": "Figure 1: Our debiasing method consists of defining task-specific representations for each social attribute, measuring similarity in the representation space for each example, and utilizing the KL loss to encourage uniform probabilities across social groups."
        },
        "2": {
            "figure_path": "2403.09516v3_figure_2.png",
            "caption": "(a) Occupation Prediction"
        },
        "3": {
            "figure_path": "2403.09516v3_figure_3.png",
            "caption": "(b) Sentiment Analysis"
        },
        "4": {
            "figure_path": "2403.09516v3_figure_4.png",
            "caption": "(a) Occupation Prediction"
        },
        "5": {
            "figure_path": "2403.09516v3_figure_5.png",
            "caption": "(b) Sentiment Analysis"
        },
        "6": {
            "figure_path": "2403.09516v3_figure_6.png",
            "caption": "Figure 4: The prompt for generating prototypical text pairs."
        }
    },
    "references": [
        {
            "1": {
                "title": "Data decisions and theoretical implications when adversarially learning fair representations.",
                "author": "Alex Beutel, Jilin Chen, Zhe Zhao, and Ed H. Chi. 2017.",
                "venue": "CoRR, abs/1707.00075.",
                "url": "http://arxiv.org/abs/1707.00075"
            }
        },
        {
            "2": {
                "title": "Demographic dialectal variation in social media: A case study of African-American English.",
                "author": "Su Lin Blodgett, Lisa Green, and Brendan O\u2019Connor. 2016.",
                "venue": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1119\u20131130, Austin, Texas. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/D16-1120"
            }
        },
        {
            "3": {
                "title": "Semantics derived automatically from language corpora contain human-like biases.",
                "author": "Aylin Caliskan, Joanna J Bryson, and Arvind Narayanan. 2017.",
                "venue": "Science, 356(6334):183\u2013186.",
                "url": null
            }
        },
        {
            "4": {
                "title": "Bias in bios: A case study of semantic representation bias in a high-stakes setting.",
                "author": "Maria De-Arteaga, Alexey Romanov, Hanna Wallach, Jennifer Chayes, Christian Borgs, Alexandra Chouldechova, Sahin Geyik, Krishnaram Kenthapadi, and Adam Tauman Kalai. 2019.",
                "venue": "In Proceedings of the Conference on Fairness, Accountability, and Transparency, FAT* \u201919, page 120\u2013128, New York, NY, USA. Association for Computing Machinery.",
                "url": "https://doi.org/10.1145/3287560.3287572"
            }
        },
        {
            "5": {
                "title": "BERT: pre-training of deep bidirectional transformers for language understanding.",
                "author": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.",
                "venue": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 4171\u20134186. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/n19-1423"
            }
        },
        {
            "6": {
                "title": "Adversarial removal of demographic attributes from text data.",
                "author": "Yanai Elazar and Yoav Goldberg. 2018.",
                "venue": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 11\u201321, Brussels, Belgium. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/D18-1002"
            }
        },
        {
            "7": {
                "title": "Domain-adversarial training of neural networks.",
                "author": "Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, Mario Marchand, and Victor Lempitsky. 2016.",
                "venue": "The journal of machine learning research, 17(1):2096\u20132030.",
                "url": null
            }
        },
        {
            "8": {
                "title": "Debertav3: Improving deberta using electra-style pre-training with gradient-disentangled embedding sharing.",
                "author": "Pengcheng He, Jianfeng Gao, and Weizhu Chen. 2022.",
                "venue": "In The Eleventh International Conference on Learning Representations.",
                "url": null
            }
        },
        {
            "9": {
                "title": "Shielded representations: Protecting sensitive attributes through iterative gradient-based projection.",
                "author": "Shadi Iskander, Kira Radinsky, and Yonatan Belinkov. 2023.",
                "venue": "In Findings of the Association for Computational Linguistics: ACL 2023, pages 5961\u20135977, Toronto, Canada. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2023.findings-acl.369"
            }
        },
        {
            "10": {
                "title": "On information and sufficiency.",
                "author": "Solomon Kullback and Richard A Leibler. 1951.",
                "venue": "The annals of mathematical statistics, 22(1):79\u201386.",
                "url": null
            }
        },
        {
            "11": {
                "title": "Just train twice: Improving group robustness without training group information.",
                "author": "Evan Z Liu, Behzad Haghgoo, Annie S Chen, Aditi Raghunathan, Pang Wei Koh, Shiori Sagawa, Percy Liang, and Chelsea Finn. 2021.",
                "venue": "In International Conference on Machine Learning, pages 6781\u20136792. PMLR.",
                "url": null
            }
        },
        {
            "12": {
                "title": "OpenAI. OpenAI: Introducing ChatGPT, 2022. URL https://openai.com/blog/chatgpt.",
                "author": "OpenAI. 2022.",
                "venue": null,
                "url": null
            }
        },
        {
            "13": {
                "title": "Choose your lenses: Flaws in gender bias evaluation.",
                "author": "Hadas Orgad and Yonatan Belinkov. 2022.",
                "venue": "In Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing (GeBNLP), pages 151\u2013167.",
                "url": null
            }
        },
        {
            "14": {
                "title": "Debiasing NLP models without demographic information.",
                "author": "Hadas Orgad and Yonatan Belinkov. 2023.",
                "venue": "In Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics, ACL 2023, July 9-14, 2023. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "15": {
                "title": "Null it out: Guarding protected attributes by iterative nullspace projection.",
                "author": "Shauli Ravfogel, Yanai Elazar, Hila Gonen, Michael Twiton, and Yoav Goldberg. 2020.",
                "venue": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020, pages 7237\u20137256. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2020.acl-main.647"
            }
        },
        {
            "16": {
                "title": "Linear adversarial concept erasure.",
                "author": "Shauli Ravfogel, Michael Twiton, Yoav Goldberg, and Ryan Cotterell. 2022a.",
                "venue": "In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 18400\u201318421. PMLR.",
                "url": "https://proceedings.mlr.press/v162/ravfogel22a.html"
            }
        },
        {
            "17": {
                "title": "Adversarial concept erasure in kernel space.",
                "author": "Shauli Ravfogel, Francisco Vargas, Yoav Goldberg, and Ryan Cotterell. 2022b.",
                "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 6034\u20136055, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2022.emnlp-main.405"
            }
        },
        {
            "18": {
                "title": "Avoiding the Hypothesis-Only Bias in Natural Language Inference via Ensemble Adversarial Training.",
                "author": "Joe Stacey, Pasquale Minervini, Haim Dubossarsky, Sebastian Riedel, and Tim Rockt\u00e4schel. 2020.",
                "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8281\u20138291, Online. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2020.emnlp-main.665"
            }
        },
        {
            "19": {
                "title": "Transformers: State-of-the-art natural language processing.",
                "author": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020.",
                "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38\u201345, Online. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2020.emnlp-demos.6"
            }
        },
        {
            "20": {
                "title": "Mitigating unwanted biases with adversarial learning.",
                "author": "Brian Hu Zhang, Blake Lemoine, and Margaret Mitchell. 2018.",
                "venue": "In Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society, pages 335\u2013340.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Gender bias in coreference resolution: Evaluation and debiasing methods.",
                "author": "Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018.",
                "venue": "In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT, New Orleans, Louisiana, USA, June 1-6, 2018, Volume 2 (Short Papers), pages 15\u201320. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/n18-2003"
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.09516v3",
    "segmentation": {
        "research_background_sections": [
            "1"
        ],
        "methodology_sections": [
            "2",
            "2.1",
            "2.1.1",
            "2.1.2",
            "2.1.3"
        ],
        "main_experiment_and_results_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3",
            "3.4",
            "3.5",
            "3.6",
            "4",
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4",
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "research_context": {
        "paper_id": "2403.09516v3",
        "paper_title": "Leveraging Prototypical Representations for Mitigating Social Bias without Demographic Information",
        "research_background": "### Paper's Motivation\nThe primary motivation behind this paper is to address the challenge of social bias in language models, which arises from biased training data. This issue is crucial to handle because biases can lead to unfair and discriminatory outcomes in real-world applications of these models. The problem is exacerbated when demographic information is either unavailable or too costly to collect, making traditional methods for bias mitigation\u2014which typically depend on explicit demographic annotations\u2014impractical.\n\n### Research Problem\nThe paper tackles the problem of mitigating social bias in language models without relying on explicit demographic information. Traditional approaches for bias mitigation often require extensive annotated data, including sensitive attribute labels, which may not always be available. The goal is to find alternative methodologies that can achieve fairness in model training by leveraging other kinds of information.\n\n### Relevant Prior Work\n1. **Ability of Language Models to Capture Demographic Information**:\n   - Caliskan et al. (2017) and Zhao et al. (2018) showed that language models can infer demographic information such as race or gender from text data. However, these inferred attributes can introduce unintended biases.\n\n2. **Issues with Biased Outputs**:\n   - De-Arteaga et al. (2019) demonstrated that the ability to infer demographic data leads to discriminatory outcomes.\n\n3. **Traditional Bias Mitigation Methods**:\n   - Methods like those by Beutel et al. (2017) and Zhang et al. (2018) require explicit bias annotations in the training data, which can be labor-intensive.\n   \n4. **Concept Removal Approaches**:\n   - Ravfogel et al. (2020, 2022) and Iskander et al. (2023) developed methods for bias mitigation by removing sensitive attributes, but these also depend on classifiers trained on annotated data.\n\n5. **Bias Mitigation Without Explicit Bias Annotations**:\n   - Liu et al. (2021) proposed Just Train Twice (JTT), a two-step training process focusing on misclassified examples.\n   - Orgad and Belinkov (2023) introduced BLIND, which uses a success detector to down-weigh correctly predicted examples to reduce bias.\n\n### Proposed Contribution\nThe paper introduces DaFair (Demographics-Agnostic Fairness), a new method designed to mitigate social bias during the fine-tuning of language models while not requiring demographic information. DaFair incorporates the following innovations:\n- Utilizes prototypical representations to ensure equal similarity between texts and prototypes of different demographic groups.\n- Extends this method to scenarios with limited demographic-annotated data by averaging sample representations for each social attribute.\n- Validates the approach via experiments on tasks like occupation prediction and sentiment analysis of Twitter posts, demonstrating superior performance over existing approaches.\n\nIn summary, the paper addresses a critical issue in bias mitigation, providing a novel approach that lessens dependency on demographic data and showcasing its effectiveness in realistic scenarios.",
        "methodology": "The methodology section describes a model designed to mitigate social bias without using explicit demographic information. Below is a detailed breakdown of the proposed method, highlighting its key components and innovations:\n\n1. **Context and Objective**:\n   - The dataset comprises input texts (\\(X\\)), main task labels (\\(Y\\)), and sensitive attributes (\\(A\\)) that indicate discrete demographic features (e.g., race).\n   - The main goal is to develop a model (\\(f\\)) that can make predictions without relying on the sensitive attribute (\\(A\\)), which may be unobserved or partially available.\n\n2. **Semantic Similarity for Text Representation**:\n   - In the absence of demographic labels, the approach uses semantic similarity to understand how texts describe different social groups.\n   - For instance, in an occupation prediction task, \"This biography is about a man\" and \"This biography is about a woman\" serve as representations for gender groups.\n\n3. **Utilizing a Generative Model**:\n   - Employ a generative model (ChatGPT by OpenAI, 2022) to produce prototypical texts.\n   - ChatGPT is given descriptions of the approach (DaFair), the dataset, and the tasks.\n   - The model generates 10 pairs of prototypical texts for each task, which serve as benchmark representations for social attribute groups.\n\n4. **Data-Driven Representations**:\n   - When limited labels are available, the model uses the text encoder's representations to create group-specific averages.\n   - Specifically, it calculates the mean representation of each labeled group from the labeled samples, referred to as the Semi-DaFair method.\n\n5. **Extension to Multiple Social Attribute Groups**:\n   - While the explanation assumes a binary case for simplicity (\\(A = \\{a_1, a_2\\}\\)), the approach can be expanded to multiple social attribute groups.\n\n**In summary**, the proposed method innovatively uses semantic text similarity and generative models to derive representations that replace sensitive demographic labels. By generating and leveraging prototypical texts via ChatGPT, and calculating mean representations for partially labeled data, it seeks to predict tasks while minimizing social bias.",
        "main_experiment_and_results": "### Main Experiment Setup and Results:\n\nThe main experiment utilizes the **Bias in Bios Dataset** (De-Arteaga et al., 2019). This dataset is comprised of 394,000 biographies spanning 28 professions, annotated with gender information. The classification task is to predict the occupation based on biographical text. Furthermore, the experiment incorporates the setup from Elazar and Goldberg (2018), leveraging a **Twitter dataset** gathered by Blodgett et al. (2016). This Twitter dataset includes 100,000 tweets labeled with sociolects\u2014African American English (AAE) or Standard American English (SAE)\u2014determined by geo-location and serving as a proxy for racial identity.\n\n### Evaluation Metrics:\n\n1. **Accuracy (Acc)**: To evaluate the model's predictive performance on the downstream task.\n2. **True Positive Rate Gap (TPR-GAP)**: The main fairness metric used to assess performance disparities between different protected attribute groups.\n3. **Statistical Fairness Metrics**:\n   - **Independence**\n   - **Separation**\n   - **Sufficiency**\n\nThe detailed procedures for calculating these metrics are available in Appendix B.\n\n### Baselines:\n\nThe study evaluates the performance of the following demographic-agnostic methods:\n- **Original**\n- **JTT (Just Train Twice)**\n- **BLIND**\n\nAdditionally, it investigates the effectiveness of **DAFAIR** and **Semi-DaFair** in scenarios with limited access to demographic labels.\n\n### Experiment Results:\n\nAll methods are run with five random seeds, and the mean and standard deviation of the test results are reported. The model hyperparameters are tuned using a strategy that selects the most radical parameter while ensuring that the downstream task accuracy remains at least 0.97 of the original accuracy. The method ensures tuning does not heavily rely on a validation set with demographic annotations.\n\nDetails regarding the training setup, evaluation procedures, and hyperparameter tuning strategies are described extensively in Appendices A and B."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To evaluate the effectiveness of the DaFair method in mitigating social bias without demographic labels, in comparison to other debiasing methods.",
            "experiment_process": "The experiments were conducted on two tasks: occupation prediction and Twitter sentiment analysis, using BERT and DeBERTA-V3 as encoders. The performance of DaFair was compared against baseline models (BLIND and JTT) in terms of accuracy and TPR-GAP. Evaluation with other statistical fairness metrics was also conducted, with detailed results in Appendix C.",
            "result_discussion": "DaFair showed slightly lower accuracy compared to the finetuned model but significantly reduced the TPR-GAP, outperforming BLIND and JTT. The effectiveness of DaFair in reducing social bias measures is attributed to the regularization term used in DaFair, which lowers the association of text representation with specific social groups.",
            "ablation_id": "2403.09516v3.No1"
        },
        {
            "research_objective": "To assess the impact of limited demographic labels on the performance of DaFair and Semi-DaFair in comparison to other debiasing methods.",
            "experiment_process": "TPR-GAP was evaluated for both tasks under different levels of labeled data for social attributes. The performance of DaFair and Semi-DaFair was compared to other debiasing methods while varying the number of labeled examples (from none to an abundance, e.g., up to 1000 labels in sentiment and 100K in occupation prediction).",
            "result_discussion": "Without any labels, DaFair outperformed other methods even when they had limited labels. DaFair further improved with some labeled data (Semi-DaFair), surpassing prior methods with limited labeled data. However, with an abundance of labeled data, other methods performed better. Limited labeled examples appeared sufficient for Semi-DaFair to mitigate associations with specific social groups.",
            "ablation_id": "2403.09516v3.No2"
        },
        {
            "research_objective": "To investigate the effect of the number of prototypical text pairs (K) on the performance of DaFair in mitigating social bias.",
            "experiment_process": "Experiments were conducted with varying values of K (1, 2, 4, 8) to observe their effect on TPR-GAP and accuracy. Table 2 presents the results of these experiments.",
            "result_discussion": "All K values contributed to reducing TPR-GAP without affecting accuracy. Larger K values resulted in more substantial reductions, but incremental improvements became less significant for higher K values. These findings suggest that a small K may be sufficient for DaFair.",
            "ablation_id": "2403.09516v3.No3"
        }
    ]
}