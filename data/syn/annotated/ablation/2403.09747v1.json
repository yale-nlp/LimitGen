{
    "title": "Re-Search for The Truth: Multi-round Retrieval-augmented Large Language Models are Strong Fake News Detectors",
    "abstract": "The proliferation of fake news has had far-reaching implications on politics, the economy, and society at large. While Fake news detection methods have been employed to mitigate this issue, they primarily depend on two essential elements: the quality and relevance of the evidence, and the effectiveness of the verdict prediction mechanism. Traditional methods, which often source information from static repositories like Wikipedia, are limited by outdated or incomplete data, particularly for emerging or rare claims. Large Language Models (LLMs), known for their remarkable reasoning and generative capabilities, introduce a new frontier for fake news detection. However, like traditional methods, LLM-based solutions also grapple with the limitations of stale and long-tail knowledge. Additionally, retrieval-enhanced LLMs frequently struggle with issues such as low-quality evidence retrieval and context length constraints. To address these challenges, we introduce a novel, retrieval-augmented LLMs framework\u2014the first of its kind to automatically and strategically extract key evidence from web sources for claim verification. Employing a multi-round retrieval strategy, our framework ensures the acquisition of sufficient, relevant evidence, thereby enhancing performance. Comprehensive experiments across three real-world datasets validate the framework\u2019s superiority over existing methods. Importantly, our model not only delivers accurate verdicts but also offers human-readable explanations to improve result interpretability.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "The escalation of fake news poses a severe threat, dwarfing extensive efforts to mitigate its impact on political, economic, and social landscapes West and Bergstrom (2020  ###reference_b35###). Fake news detection approaches to combat this issue generally fall into three categories: content-based Zhou and Zafarani (2021  ###reference_b46###); Capuano et al. (2023  ###reference_b3###), evidence-based Kotonya and Toni (2020  ###reference_b15###); Min et al. (2022  ###reference_b19###), and social context-based methods Collins et al. (2021  ###reference_b6###); Grover et al. (2022  ###reference_b7###).\nHowever, existing methods Zhou and Zafarani (2020  ###reference_b45###); Zhang and Ghorbani (2020  ###reference_b44###) are typically tailored to specific datasets, thereby inherently constraining their scalability, transferability, and robustness.\nIn light of these constraints, there arises an imperative for the development of a more versatile model that can efficiently detect fake news in a zero-shot or few-shot learning manner.\n###figure_1### Large Language Models (LLMs) have shown remarkable capabilities across various applications Wei et al. (2022a  ###reference_b33###). Current methodologies utilizing Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) often depend on specific databases such as Wikipedia or employ a simple one-step retrieval process Izacard et al. (2023  ###reference_b12###); Guu et al. (2020a  ###reference_b8###). However, in the context of real-world fake news detection, there are significant systemic challenges that necessitate more sophisticated solutions. These challenges encompass the growing issue of AI-generated disinformation, the limitations inherent in depending on a limited number of data sources, the obstacles of ensuring real-time updates in a constantly changing news environment, and the long-tail effect where rare or niche false information may remain undetected Chen and Shu (2023  ###reference_b4###). In response to these obstacles, we propose an innovative multi-round LLM-based RAG framework.\nWe introduce STEEL (STrategic rEtrieval Enhanced with Large Language Model), a comprehensive, automated framework for fake news detection that combines ease-of-use and interpretability. Our framework leverages the reasoning and uncertainty estimation capabilities of LLMs, offering more robust evidence retrieval. It also sidesteps the limitations of relying on a solitary predefined corpus by sourcing evidence directly from the expansive Internet. As illustrated in Figure 1  ###reference_###, STEEL employs an adaptive multi-round retrieval process, using a Large Language Model to generate targeted queries for missing information when initial evidence is insufficient. In addition, it can sharpen the focus of subsequent retrievals and save crucial evidence already obtained for the next judgment.\nIn this work, we make the following contributions.\nWe propose a novel framework, STEEL, for automatic fake news detection through strategic Internet-based evidence retrieval. To the best of our knowledge, this is the first framework that leverages LLMs for fake news detection via strategic evidence retrieval from the Internet.\nWe provide an open-source implementation that is designed for out-of-the-box use, eliminating the need for complicated data processing or model training.\nExtensive experiments on three real-world datasets demonstrate that STEEL outperforms state-of-the-art methods in both prediction and interpretability."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "RAG LLMs",
            "text": "The retrieval-augmented language model assists text generation by retrieving relevant documents from a vast external knowledge base Nakano et al. (2021  ###reference_b20###).\nThis combats long-tail, outdated knowledge, and hallucination issues Kandpal et al. (2023  ###reference_b14###). Recent work has shown that retrieving additional information can improve performance on a variety of downstream tasks Yao et al. (2023b  ###reference_b41###), including open-domain Q&A, fact-checking, fact completion, long-form Q&A, Wikipedia article generation, and fake news detection Yu et al. (2023  ###reference_b43###); Guu et al. (2020b  ###reference_b9###); Asai et al. (2023  ###reference_b1###); Wu et al. (2023  ###reference_b36###); Wang and Shu (2023  ###reference_b28###).\nSTEEL differs notably from other retrieval methods in the RAG+LLM framework, like FLARE Jiang et al. (2023  ###reference_b13###), Replug Shi et al. (2023  ###reference_b26###), ProgramFC Pan et al. (2023  ###reference_b22###), and SKR Wang et al. (2023b  ###reference_b30###). While FLARE, ProgramFC, and SKR focus mainly on text blocks, Replug on documents, STEEL retrieves both documents and text blocks. Unlike methods relying on Wikis, STEEL uses the Internet as its source. It shares context-based retrieval timing with other methods but introduces active search features, including LLM feedback utilization and answer verification, enhancing its flexibility and depth in retrieval tasks within the RAG+LLM framework."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Natural Language Inference LLMs",
            "text": "Natural Language Inference (NLI) is used to predict the logical connection between the claim and the provided evidence.\nRecent studies have made strides in enhancing LLMs\u2019 reasoning. Chain of Thought Wei et al. (2022b  ###reference_b34###) achieved significant improvements with simple prompt modifications. ReAct Yao et al. (2023b  ###reference_b41###) integrates reasoning and acting capabilities in LLMs for better performance in tasks requiring complex reasoning. Tree of Thoughts Yao et al. (2023a  ###reference_b40###) enables deliberate decision-making in LLMs by exploring reasoning paths and facilitating self-evaluation. In contrast, our work focuses on evidence-retrieval strategies for news verification.\nCurrently, main application paradigms can be divided into: Prompting Ram et al. (2023  ###reference_b25###), Fine-tuning Borgeaud et al. (2022  ###reference_b2###), and Reinforcement learning Liu et al. (2023  ###reference_b17###). Existing industrial solutions like NEW BINGBING 111https://www.bing.com/new  ###reference_www.bing.com/new### and Perplexity.ai 222https://www.perplexity.ai/  ###reference_www.perplexity.ai/### integrate LLMs with search engines for performance but aren\u2019t optimized for fake news detection. In this task, evidence quality is crucial due to LLM input length limits. STEEL addresses this by using LLM feedback and multi-round evidence retrieval."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Methods",
            "text": "In this section, we present our model, STEEL. The input of this method consists of a claim . Initially, a set of relevant evidence  are retrieved from the Internet. Subsequently, LLMs evaluate the sufficiency of the gathered evidence. If the evidence is deemed adequate, the results will be output promptly. Otherwise, the search for additional evidence continues. To construct an affordable, ready-to-use framework, we leverage the APIs (Application Interfaces) of leading AI (Artificial Intelligence) companies. Specifically, we utilize BING Search for web evidence retrieval and OPENAI\u2019s GPT-3.5-turbo  OpenAI (2022  ###reference_b21###) for verification. The output is the prediction of this claim , along with explanatory text . Here,  refers to the LLMs responsible for generating the output.  is a binary classification, where  indicates the assessment of the news claims as true or false.\nAs shown in Figure 2  ###reference_###, our model mainly comprises two key components: a retrieval module and a reasoning module. These two modules are integrated within the overarching framework of the re-search mechanism.\n###figure_2###"
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Retrieval Module",
            "text": "Unlike prior studies that separate web retrieval and semantic retrieval, we integrate both stages. A claim  is first processed by a web retrieval API to obtain document links  containing pertinent evidence. Typically, 10 links are retrieved; however, due to constraints imposed by the context length of Large Language Models (LLMs), not all links are utilized.\nFor source credibility, we implement a basic filtering mechanism. Based on previous research Papadogiannakis et al. (2023  ###reference_b23###), we use a list of  known fake news websites as a filter, discarding any matches during web search.\nThe documents retrieved online are initially organized based on the relevance algorithm of the search engine, with the document deemed most relevant positioned at the top of the list. Our analytical process adheres to the sequence of this sorted list, beginning with the first document. Specifically, our approach involves assessing whether the length of the top-ranked document exceeds our predefined limit determined by the LLM\u2019s context length. If it does, we employ semantic retrieval techniques to extract highly similar fragments from the document. Conversely, if the length is within acceptable limits, we utilize the entire document and then sequentially examine the second-ranked document, continuing this process until we reach the maximum allowable context length. By this, we strive to gather a comprehensive array of relevant evidence while maintaining the integrity of the information retrieved."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Reasoning Module",
            "text": "The relevant pieces of evidence  retrieved from the web are then aggregated into prompts and fed into the LLMs for inference. LLMs can make decisions based on given\nevidence, including deciding if they need to re-search, case can be seem at Figure A1  ###reference_###.\nEssentially, the prompt instructs LLM to assess the claim based on the retrieved evidence and output responses, which are classified into three categories - true, false, and NEI (Not Enough Information). Explanations of the responses are provided based on the sufficiency of the retrieved evidence. For \"NEI\", \"Established evidence\" and \"Updated queries\" will be output for further evidence collection. \"Established evidence\" is the compression of this evidence for the next judgment. \"Updated queries\" are the queries for subsequent web page retrieval, with the purpose of incrementally obtaining evidence. Prompts utilized here can be seen in listing 7  ###reference_###.\nTo mitigate consistency issues, we incorporate a confidence level for each answer, along with aggregated new and established evidence for subsequent assessment.\nThe third is aggregated evidence of  obtained after retrieval and \"Established evidence\" in the previous cycle.\nTo address inconsistent answers Ye and Durrett (2022  ###reference_b42###) and hallucinations problem, some previous work Xiong et al. (2023  ###reference_b38###); Wang et al. (2023a  ###reference_b29###) exploits the self-consistence and self-judgment approaches, enabling the LLMs to produce confidence scores within the range of . Nonetheless, it has been observed that contemporary LLMs often exhibit a tendency toward overconfidence Wang et al. (2023d  ###reference_b32###); Xiong et al. (2023  ###reference_b38###). To counteract this phenomenon, we introduce an over-confidence coefficient within the range of . The final confidence score is adjusted by multiplying it with this coefficient.\nWhen the final Confidence falls below , the model is instructed to proceed to the next iteration.\nIn equation 2  ###reference_###,  denotes the final confidence score,  represents the initial confidence score provided by the LLMs, and  represents the over-confidence coefficient."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Re-Search Mechanism",
            "text": "As illustrated in Figure 3  ###reference_###, the re-search is triggered under certain conditions. This feature ensures a more robust and exhaustive gathering of evidence, enhancing the method\u2019s reliability and performance.\n###figure_3### Upon meeting a re-search condition, the model kicks off a systematic process. First, it consolidates the evidence gathered from the initial search, appending it to an \"established evidence\" pool for future reference. Next, the model formulates a set of \"updated queries\" aimed at obtaining additional relevant evidence. This iterative approach ensures a gradual accumulation of evidence, thereby enhancing the model\u2019s ability to discern the veracity of news.\nRegarding the rationale behind our choice of re-search over alternative methods that appear to enhance retrieval quality, such as query-dependent techniques or search engineering, a detailed explanation will be provided in section 4.3  ###reference_###.\nConsequently, when LLMs determine that the current evidence set is inadequate for a reliable judgment on the claim at hand, it signals this by outputting \"NEI\". This output serves as a trigger for the model to advance to a subsequent iterative search. The mechanics behind this intermediate step are further detailed in Equation 3  ###reference_###.\nwhere  and NEI stands for Not Enough Information."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "In this section, we conduct experiments to evaluate the efficacy of our STEEL model in multiple angles. We focus on three main aspects: the efficiency of evidence retrieval in identifying fake news, the role of the re-search mechanism in bolstering detection accuracy, and the influence of varying retrieval steps and prompts on the model\u2019s performance.\nTo evaluate the performance of STEEL, we conduct extensive experiments on three real-world datasets, comprising two English datasets (LIAR333LIAR:https://www.cs.ucsb.edu/ william/data/liar_dataset.zip  ###reference_/liar_dataset.zip### and PolitiFact444PolitiFact: https://www.politifact.com/  ###reference_www.politifact.com/###) and one Chinese dataset (CHEF555CHEF: https://github.com/THU-BPM/CHEF  ###reference_github.com/THU-BPM/CHEF###).\nThe news in LIAR and PolitiFact are categorized into two distinct classes: real and fake news. The datasets were preprocessed to maintain their original meaning while fitting the task at hand, with key statistics outlined in Table 1  ###reference_###.\n###table_1### We compare our STEEL with  baselines, which can be divided into two groups:\nThe first group (G1) is classical and recent advanced evidence-based methods. G1 contains seven baselines: DeClarE (EMNLP\u201918) Popat et al. (2018  ###reference_b24###), HAN (ACL\u201919) Ma et al. (2019  ###reference_b18###), EHIAN (IJCAI\u201920) Wu et al. (2020  ###reference_b37###), MAC (ACL\u201921) Vo and Lee (2021  ###reference_b27###), GET (WWW\u201922) Xu et al. (2022  ###reference_b39###), MUSER (KDD\u201923) Liao et al. (2023  ###reference_b16###) and ReRead\n(SIGIR\u201923) Hu et al. (2023  ###reference_b11###).\nThe second group (G2) encompasses methods based on LLMs, either with or without a retrieval component. This group includes four methods: GPT-3.5-turbo OpenAI (2022  ###reference_b21###), Vicuna-7B Chiang et al. (2023  ###reference_b5###), WEBGLM (KDD\u201923) Liu et al. (2023  ###reference_b17###)and ProgramFC (ACL\u201923) Pan et al. (2023  ###reference_b22###).\nFor a detailed description of the baseline models, please refer to the Appendix A.2  ###reference_###.\nSince our model does\nnot require a training set, we utilize all the data as\na test set. This approach is also applied to all the\ndatasets we use. In our method, the hyperparameter  is set to . For the LLMs, we set the temperature at , top-p at , and limit prompt tokens to . Hyperparameters for the baseline methods are aligned with those detailed in the respective papers and key hyperparameters are meticulously tuned to achieve optimal performance. We treat fake news detection as a binary classification problem and our evaluation criteria include F1, Precision, Recall, F1 Macro, and F1 Micro  Xu et al. (2022  ###reference_b39###). For more implementation details, see the\nsource code in this repository666https://anonymous.4open.science/r/STEEL-6FD1/  ###reference_D1/###. Besides, cost details can be seen at A.1  ###reference_###."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Experiments Setup",
            "text": "To evaluate the performance of STEEL, we conduct extensive experiments on three real-world datasets, comprising two English datasets (LIAR333LIAR:https://www.cs.ucsb.edu/ william/data/liar_dataset.zip  ###reference_/liar_dataset.zip###  ###reference_/liar_dataset.zip### and PolitiFact444PolitiFact: https://www.politifact.com/  ###reference_www.politifact.com/###  ###reference_www.politifact.com/###) and one Chinese dataset (CHEF555CHEF: https://github.com/THU-BPM/CHEF  ###reference_github.com/THU-BPM/CHEF###  ###reference_github.com/THU-BPM/CHEF###).\nThe news in LIAR and PolitiFact are categorized into two distinct classes: real and fake news. The datasets were preprocessed to maintain their original meaning while fitting the task at hand, with key statistics outlined in Table 1  ###reference_###  ###reference_###.\n###table_2### We compare our STEEL with  baselines, which can be divided into two groups:\nThe first group (G1) is classical and recent advanced evidence-based methods. G1 contains seven baselines: DeClarE (EMNLP\u201918) Popat et al. (2018  ###reference_b24###  ###reference_b24###), HAN (ACL\u201919) Ma et al. (2019  ###reference_b18###  ###reference_b18###), EHIAN (IJCAI\u201920) Wu et al. (2020  ###reference_b37###  ###reference_b37###), MAC (ACL\u201921) Vo and Lee (2021  ###reference_b27###  ###reference_b27###), GET (WWW\u201922) Xu et al. (2022  ###reference_b39###  ###reference_b39###), MUSER (KDD\u201923) Liao et al. (2023  ###reference_b16###  ###reference_b16###) and ReRead\n(SIGIR\u201923) Hu et al. (2023  ###reference_b11###  ###reference_b11###).\nThe second group (G2) encompasses methods based on LLMs, either with or without a retrieval component. This group includes four methods: GPT-3.5-turbo OpenAI (2022  ###reference_b21###  ###reference_b21###), Vicuna-7B Chiang et al. (2023  ###reference_b5###  ###reference_b5###), WEBGLM (KDD\u201923) Liu et al. (2023  ###reference_b17###  ###reference_b17###)and ProgramFC (ACL\u201923) Pan et al. (2023  ###reference_b22###  ###reference_b22###).\nFor a detailed description of the baseline models, please refer to the Appendix A.2  ###reference_###  ###reference_###.\nSince our model does\nnot require a training set, we utilize all the data as\na test set. This approach is also applied to all the\ndatasets we use. In our method, the hyperparameter  is set to . For the LLMs, we set the temperature at , top-p at , and limit prompt tokens to . Hyperparameters for the baseline methods are aligned with those detailed in the respective papers and key hyperparameters are meticulously tuned to achieve optimal performance. We treat fake news detection as a binary classification problem and our evaluation criteria include F1, Precision, Recall, F1 Macro, and F1 Micro  Xu et al. (2022  ###reference_b39###  ###reference_b39###). For more implementation details, see the\nsource code in this repository666https://anonymous.4open.science/r/STEEL-6FD1/  ###reference_D1/###  ###reference_D1/###. Besides, cost details can be seen at A.1  ###reference_###  ###reference_###."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Main Results",
            "text": "Our model, STEEL, was benchmarked against 11 baseline approaches, comprising 7 evidence-based and 4 LLM-based methods. We classified these into two groups: G1 for evidence-based methods and G2 for LLM-based methods. Performance metrics are reported in Tables 2  ###reference_###, 3  ###reference_###, and 4  ###reference_###.\nKey observations from these results include the following.\nSTEEL consistently outperforms state-of-the-art methods in three real-world datasets, with more than a  increase in both F1-macro and F1-micro scores. This also underscores the model\u2019s superior detection capabilities.\nIn a detailed evaluation, we measured the performance of STEEL in three key metrics: F1, Precision, and Recall, classifying real news as positive and fake news as negative. STEEL demonstrated superior performance on these indicators.\nSTEEL surpasses all baselines in the detection of fake news, evidenced by improved detection metrics. For instance, on the LIAR dataset, we observed increases in F1 False, Precision False, and Recall False by , , and , respectively. Comparable significant gains were noted on other data sets.\nThe collective evidence affirms that STEEL is highly effective in detecting fake news, with significant advantages in both reasoning and accuracy."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Internet Search Comparison Study",
            "text": "To evaluate the relative effectiveness of our research mechanism compared to other methods in terms of improving the quality of evidence retrieval, we conducted a comparative experiment.\nThe results are presented in Table 5  ###reference_###.\n\"Re-search\" represents our proposed scheme.\nThe alternative methods used for comparison involve single searches.\n\"Direct search\" denotes the scenario where claims are directly used as queries for evidence retrieval. \"Search with Keywords\" involves the extraction of key terms from the claims before searching. \"Search after Paraphrase\" entails paraphrasing the claim before searching.\n###table_3### The results indicate that while certain conventional retrieval optimization methods employed by search engines, including keyword search and paraphrasing, offer improvements over the straightforward use of the claim as a query, their effectiveness remains notably inferior to that of the re-search module.\nThis discrepancy arises from the fact that evidence obtained in a single search is insufficient to make a conclusive judgment. The results illustrate the important role of the re-search module in our framework."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "Optimal Parameters in Evidence Selection",
            "text": "To enhance the quality of evidence post-retrieval, we experimented with two key parameters, the number of document links () and length of the evidence (). As shown in Table 6  ###reference_###, the most significant improvement was achieved when  and . This aligns with our expectation that comprehending and reasoning about a statement benefit from comprehensive and detailed information compared to fragmented or limited snippets."
        },
        {
            "section_id": "4.6",
            "parent_section_id": "4",
            "section_name": "Explainability Study",
            "text": "###figure_6### Case study\nIn this section, we demonstrate the performance of our model in generating explanatory text.\nAs shown in Figure 6  ###reference_###, we provide a specific example where a news claim asserted, \"Says House Democrats voted to use your tax dollars for abortions by voting against bill defunding Planned Parenthood.\" Through the extraction of key evidence and coherent reasoning, our model effectively identified this news claim as false. More notably, our model is capable of reorganizing reasoning, utilizing complete evidence to craft human-friendly explanatory responses. Furthermore, it can attribute the generated text, distinguishing between factual information and generated content. This significantly enhances interpretability, benefiting both the model\u2019s understanding and the user\u2019s comprehension.\n###table_5### User study\nWe assess whether real-world users can accurately discern the veracity of news claims using evidence obtained from STEEL. We selected  claims from the CHEF and LIAR datasets, including  authentic and  false claims from each, and compared the quality of evidence provided by our STEEL model with that of MUSER. We hired  college students to rate the evidence. To ensure methodological rigor, participants evaluated a randomized set of claims independently, without interaction.  participants evaluated the evidence quality, reviewing either MUSER or STEEL-retrieved evidence for each claim and determining its truthfulness within a 3-minute timeframe. Participants also rated their confidence using a 5-point Likert scale. The results, depicted in Table 10  ###reference_###, unequivocally demonstrate the superior performance of STEEL in evidence retrieval quality over MUSER."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we present an out-of-the-box, end-to-end framework designed for fake news detection that centers around retrieval-augmented LLMs. Our work is a preliminary attempt to address systemic risks in the field of fake news detection, It has been proven that fully leveraging LLMs can aid individuals in identifying fake news by assisting in the gathering of ample evidence and facilitating judgment by end users.\nConsidering the intricate challenges associated with identifying fake news, there is a significant need for the future to extend the framework\u2019s capabilities to encompass multimedia-based fake news, incorporating strategies to analyze and interpret information across text, images, videos, and audio. Addressing these areas will not only improve the accuracy and reliability of fake news detection but also broaden its applicability.\nOur study is constrained by two factors that warrant attention. A significant limitation of our methodology lies in the simplistic nature of the filtering algorithm utilized to identify fraudulent news sources. Currently, in the preprocessing of evidence, we employ a static blacklist to filter out recognized sources of disinformation. However, given the vast scale and rapid evolution of digital content, this approach may prove insufficient. We advocate for further investigation into this issue and the development of more advanced and diverse methods, including built-in mechanisms, for detecting and excluding counterfeit news outlets.\nAdditionally, the restricted context length of the input text poses another challenge, as it may not capture all relevant information adequately. This limitation underscores the need for additional research into the implications of context length restrictions within the domain of LLMs. Such exploration is essential for understanding their impact on efficacy and for identifying viable strategies for improvement.\nMoreover, the technical quality of our method is hampered by the limited computational power available for fine-tuning current Large Language Models (LLMs). Nevertheless, we present a novel approach using existing LLMs with retrieval techniques for fake news detection, thereby laying the groundwork for future research endeavors."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Appendix",
            "text": ""
        },
        {
            "section_id": "Appendix 2",
            "parent_section_id": null,
            "section_name": "Appendix B Prompts\u2019 Description",
            "text": ""
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T1.9\">\n<tr class=\"ltx_tr\" id=\"S4.T1.9.10\">\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T1.9.10.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.9.10.2\">LIAR</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.9.10.3\">CHEF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.9.10.4\">POLITIFACT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.3.3.4\">#Real News</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.3.3.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.6.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.6.6.4\">#Fake News</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.5.5.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.6.6.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.9.9.4\">#Total</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.7.7.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.8.8.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.9.9.3\"></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Statistics of the datasets.</figcaption>\n</figure>",
            "capture": "Table 1: Statistics of the datasets."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T2\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T2.3\" style=\"width:208.1pt;height:173.8pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-46.8pt,39.1pt) scale(0.689569886825254,0.689569886825254) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T2.3.1\">\n<tr class=\"ltx_tr\" id=\"S4.T2.3.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" id=\"S4.T2.3.1.1.1\" rowspan=\"2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T2.3.1.1.1.1\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"8\" id=\"S4.T2.3.1.1.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">LIAR</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.2.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">F1-Ma</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.2.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">F1-Mi</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.2.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">F1-T</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.2.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">P-T</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.2.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">R-T</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.2.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">F1-F</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.2.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">P-F</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.2.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">R-F</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.3.1\" rowspan=\"7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" id=\"S4.T2.3.1.3.1.1\">G1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.3.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">DeClarE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.3.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.573</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.3.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.571</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.3.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.531</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.3.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.550</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.3.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.546</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.3.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.619</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.3.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.587</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.3.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.597</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.1.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.4.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">HAN</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.4.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.588</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.4.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.591</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.4.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.563</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.4.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.545</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.4.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.532</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.4.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.606</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.4.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.618</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.4.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.611</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.1.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.5.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">EHIAN</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.5.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.591</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.5.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.593</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.5.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.559</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.5.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.543</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.5.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.548</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.5.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.630</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.5.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.603</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.5.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.617</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.1.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.6.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MAC</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.6.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.603</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.6.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.601</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.6.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.562</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.6.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.558</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.6.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.567</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.6.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.625</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.6.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.623</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.6.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.621</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.1.7\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.7.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">GET</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.7.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.614</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.7.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.610</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.7.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.572</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.7.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.567</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.7.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.579</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.7.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.641</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.7.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.654</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.7.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.632</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.1.8\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.8.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MUSER</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.8.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.645</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.8.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.642</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.8.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.647</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.8.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.640</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.8.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.654</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.8.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.643</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.8.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.650</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.8.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.636</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.1.9\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.9.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">ReRead</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.9.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.611</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.9.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.615</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.9.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.587</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.9.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.581</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.9.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.596</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.9.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.633</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.9.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.628</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.9.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.626</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.1.10\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.10.1\" rowspan=\"4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" id=\"S4.T2.3.1.10.1.1\">G2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.10.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">GPT-3.5-turbo</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.10.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.563</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.10.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.541</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.10.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.559</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.10.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.572</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.10.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.567</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.10.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.555</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.10.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.564</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.1.10.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.560</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.1.11\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.11.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Vicuna-7B</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.11.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.528</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.11.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.535</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.11.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.521</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.11.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.543</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.11.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.552</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.11.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.519</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.11.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.538</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.11.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.526</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.1.12\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.12.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">WEBGLM-2B</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.12.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.601</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.12.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.597</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.12.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.558</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.12.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.563</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.12.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.571</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.12.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.622</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.12.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.604</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.12.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.618</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.1.13\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.13.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">ProgramFC</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.13.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.631</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.13.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.613</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.13.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.637</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.13.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.607</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.13.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.639</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.13.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.625</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.13.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.611</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.1.13.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.628</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.1.14\">\n<td class=\"ltx_td ltx_border_bb\" id=\"S4.T2.3.1.14.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.3.1.14.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.1.14.2.1\">STEEL</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.3.1.14.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.1.14.3.1\">0.714*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.3.1.14.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.1.14.4.1\">0.689*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.3.1.14.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.1.14.5.1\">0.685*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.3.1.14.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.1.14.6.1\">0.680*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.3.1.14.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.1.14.7.1\">0.691*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.3.1.14.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.1.14.8.1\">0.743*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.3.1.14.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.1.14.9.1\">0.725*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.3.1.14.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.1.14.10.1\">0.752*</span></td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Performance comparison on LIAR of our model w.r.t. baselines. The experiment was repeated 5 times with average results calculated. \"F1-Ma\" and \"F1-Mi\" denote F1-Macro and F1-Micro metrics. \"-T\" represents \"True News as Positive,\" and \"-F\" denotes \"Fake News as Positive\" for precision and recall calculations. Statistically significant test () performed on 5 dataset splits. Superior outcomes are highlighted in bold, and statistically significant improvements are indicated by *.</figcaption>\n</figure>",
            "capture": "Table 2: Performance comparison on LIAR of our model w.r.t. baselines. The experiment was repeated 5 times with average results calculated. \"F1-Ma\" and \"F1-Mi\" denote F1-Macro and F1-Micro metrics. \"-T\" represents \"True News as Positive,\" and \"-F\" denotes \"Fake News as Positive\" for precision and recall calculations. Statistically significant test () performed on 5 dataset splits. Superior outcomes are highlighted in bold, and statistically significant improvements are indicated by *."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T3\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T3.1\" style=\"width:208.1pt;height:171.9pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-48.5pt,40.1pt) scale(0.682037751426839,0.682037751426839) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T3.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" id=\"S4.T3.1.1.1.1\" rowspan=\"2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T3.1.1.1.1.1\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"8\" id=\"S4.T3.1.1.1.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">CHEF</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">F1-Ma</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">F1-Mi</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">F1-T</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">P-T</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">R-T</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">F1-F</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">P-F</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">R-F</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.3.1\" rowspan=\"7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.1.3.1.1\">G1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.3.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">DeClarE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.3.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.589</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.3.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.581</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.3.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.637</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.3.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.583</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.3.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.625</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.3.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.568</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.3.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.544</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.3.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.581</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.4.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">HAN</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.4.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.557</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.4.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.543</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.4.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.581</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.4.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.533</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.4.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.574</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.4.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.541</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.4.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.532</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.4.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.558</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.5.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">EHIAN</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.5.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.600</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.5.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.571</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.5.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.621</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.5.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.583</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.5.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.628</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.5.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.577</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.5.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.516</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.5.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.586</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.6.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MAC</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.6.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.583</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.6.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.574</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.6.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.601</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.6.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.557</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.6.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.619</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.6.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.563</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.6.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.537</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.6.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.589</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.7\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.7.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">GET</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.7.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.602</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.7.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.588</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.7.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.623</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.7.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.585</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.7.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.630</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.7.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.556</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.7.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.582</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.7.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.574</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.8\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.8.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MUSER</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.8.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.612</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.8.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.607</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.8.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.641</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.8.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.603</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.8.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.658</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.8.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.566</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.8.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.631</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.8.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.591</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.9\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.9.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">ReRead</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.9.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.719</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.9.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.705</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.9.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.762</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.9.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.826</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.9.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.706</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.9.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.655</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.9.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.645</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.9.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.704</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.10\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.10.1\" rowspan=\"4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.1.10.1.1\">G2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.10.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">GPT-3.5-turbo</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.10.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.574</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.10.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.586</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.10.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.567</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.10.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.571</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.10.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.595</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.10.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.583</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.10.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.579</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.10.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.591</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.11\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.11.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Vicuna-7B</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.11.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.519</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.11.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.513</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.11.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.509</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.11.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.538</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.11.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.531</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.11.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.522</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.11.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.518</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.11.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.525</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.12\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.12.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">WEBGLM-2B</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.12.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.632</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.12.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.597</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.12.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.558</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.12.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.563</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.12.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.571</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.12.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.611</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.12.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.604</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.12.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.618</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.13\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.13.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">ProgramFC</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.13.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.708</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.13.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.694</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.13.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.751</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.13.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.723</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.13.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.697</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.13.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.665</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.13.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.642</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.13.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.683</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.14\">\n<td class=\"ltx_td ltx_border_bb\" id=\"S4.T3.1.1.14.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.1.1.14.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.14.2.1\">STEEL</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.1.1.14.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.14.3.1\">0.793*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.1.1.14.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.14.4.1\">0.781*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.1.1.14.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.14.5.1\">0.818*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.1.1.14.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.14.6.1\">0.850*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.1.1.14.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.14.7.1\">0.772*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.1.1.14.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.14.8.1\">0.768*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.1.1.14.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.14.9.1\">0.725*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.1.1.14.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.14.10.1\">0.784*</span></td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Performance comparison on CHEF of our model w.r.t. baselines.</figcaption>\n</figure>",
            "capture": "Table 3: Performance comparison on CHEF of our model w.r.t. baselines."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T4\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T4.1\" style=\"width:208.1pt;height:171.9pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-48.5pt,40.1pt) scale(0.682037751426839,0.682037751426839) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T4.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" id=\"S4.T4.1.1.1.1\" rowspan=\"2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T4.1.1.1.1.1\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"8\" id=\"S4.T4.1.1.1.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">PolitiFact</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">F1-Ma</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">F1-Mi</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">F1-T</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">P-T</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">R-T</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">F1-F</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">P-F</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">R-F</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.3.1\" rowspan=\"7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.1.3.1.1\">G1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.3.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">DeClarE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.3.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.654</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.3.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.651</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.3.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.656</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.3.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.689</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.3.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.673</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.3.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.651</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.3.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.613</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.3.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.664</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">HAN</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.661</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.660</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.679</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.676</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.682</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.643</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.650</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.637</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">EHIAN</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.664</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.663</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.674</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.680</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.651</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.650</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.628</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.627</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.6.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MAC</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.6.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.678</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.6.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.675</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.6.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.700</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.6.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.695</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.6.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.704</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.6.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.653</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.6.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.655</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.6.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.645</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.7\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.7.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">GET</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.7.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.694</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.7.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.692</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.7.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.725</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.7.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.712</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.7.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.770</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.7.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.669</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.7.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.720</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.7.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.665</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.8\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.8.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MUSER</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.8.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.732</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.8.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.729</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.8.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.757</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.8.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.735</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.8.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.780</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.8.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.702</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.8.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.728</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.8.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.681</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.9\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.9.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">ReRead</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.9.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.681</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.9.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.693</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.9.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.714</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.9.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.711</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.9.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.755</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.9.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.688</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.9.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.718</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.9.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.699</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.10\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.10.1\" rowspan=\"4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.1.10.1.1\">G2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.10.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">GPT-3.5-turbo</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.10.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.567</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.10.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.553</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.10.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.570</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.10.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.557</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.10.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.561</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.10.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.559</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.10.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.562</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.10.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.573</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.11\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.11.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Vicuna-7B</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.11.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.522</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.11.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.515</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.11.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.529</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.11.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.531</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.11.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.526</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.11.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.518</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.11.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.520</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.11.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.519</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.12\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.12.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">WEBGLM-2B</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.12.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.628</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.12.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.633</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.12.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.601</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.12.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.617</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.12.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.639</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.12.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.612</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.12.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.660</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.12.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.626</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.13\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.13.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">ProgramFC</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.13.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.684</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.13.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.678</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.13.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.733</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.13.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.725</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.13.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.741</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.13.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.635</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.13.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.622</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.13.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.643</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.14\">\n<td class=\"ltx_td ltx_border_bb\" id=\"S4.T4.1.1.14.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T4.1.1.14.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.14.2.1\">STEEL</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T4.1.1.14.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.14.3.1\">0.751*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T4.1.1.14.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.14.4.1\">0.753*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T4.1.1.14.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.14.5.1\">0.780*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T4.1.1.14.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.14.6.1\">0.749*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T4.1.1.14.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.14.7.1\">0.787*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T4.1.1.14.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.14.8.1\">0.722*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T4.1.1.14.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.14.9.1\">0.745*</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T4.1.1.14.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.14.10.1\">0.724*</span></td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Performance comparison on Politifact of our model w.r.t. baselines. </figcaption>\n</figure>",
            "capture": "Table 4: Performance comparison on Politifact of our model w.r.t. baselines. "
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T5\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T5.1\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T5.1.1.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T5.1.1.1.1\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\" id=\"S4.T5.1.1.2\">F1-Ma</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.2.1\">LIAR</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.2.2\">CHEF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.2.3\">PolitiFact</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.3.1\">Direct Search</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.3.2\">0.695</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.3.3\">0.771</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.3.4\">0.733</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.1.4.1\">Search with Keywords</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.4.2\">0.699</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.4.3\">0.775</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.4.4\">0.735</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.1.5.1\">Search after Paraphrase</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.5.2\">0.702</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.5.3\">0.780</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.5.4\">0.736</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S4.T5.1.6.1\">Re-search</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T5.1.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.6.2.1\">0.714</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T5.1.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.6.3.1\">0.793</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T5.1.6.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.6.4.1\">0.751</span></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>Performance comparison of various search strategies.</figcaption>\n</figure>",
            "capture": "Table 5: Performance comparison of various search strategies."
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T6\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T6.8\" style=\"width:208.1pt;height:148.1pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(28.2pt,-20.1pt) scale(1.37168416754992,1.37168416754992) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T6.8.8\">\n<tr class=\"ltx_tr\" id=\"S4.T6.8.8.9\">\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T6.8.8.9.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"5\" id=\"S4.T6.8.8.9.2\">F1-Ma</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.4.4.4\">\n<td class=\"ltx_td\" id=\"S4.T6.4.4.4.5\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T6.4.4.4.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.1.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.3.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.4.4.4.4\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.5.5.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T6.5.5.5.2\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T6.5.5.5.2.1\">LIAR</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.5.5.5.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.5.5.5.3\">0.631</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.5.5.5.4\">0.636</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.5.5.5.5\">0.643</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.5.5.5.6\">0.671</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.6.6.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.6.6.6.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.6.6.6.2\">0.650</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.6.6.6.3\">0.662</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.6.6.6.4\">0.677</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.6.6.6.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.6.6.6.5.1\">0.714</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.7.7.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.7.7.7.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.7.7.7.2\">0.673</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.7.7.7.3\">0.675</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.7.7.7.4\">0.684</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.7.7.7.5\">0.713</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.8.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T6.8.8.8.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T6.8.8.8.2\">0.669</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T6.8.8.8.3\">0.672</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T6.8.8.8.4\">0.680</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T6.8.8.8.5\">0.713</td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 6: </span>The impact of the number of URLs () and paragraphs per document () on performance.</figcaption>\n</figure>",
            "capture": "Table 6: The impact of the number of URLs () and paragraphs per document () on performance."
        },
        "7": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T7\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T7.1\" style=\"width:208.1pt;height:52.6pt;vertical-align:-0.4pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-147.2pt,36.9pt) scale(0.414245476598629,0.414245476598629) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T7.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T7.1.1.1.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T7.1.1.1.1.1\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\" id=\"S4.T7.1.1.1.2\">F1-Ma</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.2.1\">LIAR</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.2.2\">CHEF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.2.3\">PolitiFact</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T7.1.1.3.1\">Vanilla</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.3.2\">0.69</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.3.3\">0.75</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.3.4\">0.73</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T7.1.1.4.1\">Quadratic Answer <cite class=\"ltx_cite ltx_citemacro_cite\">Helbling et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.09747v1#bib.bib10\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.4.2\">0.69</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.4.3\">0.76</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.4.4\">0.74</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T7.1.1.5.1\">Response Correction <cite class=\"ltx_cite ltx_citemacro_cite\">Wang et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.09747v1#bib.bib31\" title=\"\">2023c</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.5.2\">0.69</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.5.3\">0.75</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.5.4\">0.74</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T7.1.1.6.1\">Chain of Thought <cite class=\"ltx_cite ltx_citemacro_cite\">Wang et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.09747v1#bib.bib29\" title=\"\">2023a</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.6.2\">0.69</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.6.3\">0.76</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.6.4\">0.74</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S4.T7.1.1.7.1\">Round Control (STEEL)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T7.1.1.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.7.2.1\">0.71</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T7.1.1.7.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.7.3.1\">0.79</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T7.1.1.7.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.7.4.1\">0.75</span></td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 7: </span>Comparison of experimental results between round control and other methods</figcaption>\n</figure>",
            "capture": "Table 7: Comparison of experimental results between round control and other methods"
        },
        "8": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T8\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T8.1\">\n<tr class=\"ltx_tr\" id=\"S4.T8.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T8.1.1.1\" rowspan=\"2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T8.1.1.1.1\" style=\"color:#FF0000;\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\" id=\"S4.T8.1.1.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T8.1.1.2.1\" style=\"color:#FF0000;\">F1-Ma</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T8.1.2.1.1\" style=\"color:#FF0000;\">LIAR</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.2.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T8.1.2.2.1\" style=\"color:#FF0000;\">CHEF</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.2.3\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T8.1.2.3.1\" style=\"color:#FF0000;\">PolitiFact</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T8.1.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T8.1.3.1.1\" style=\"color:#FF0000;\">STEEL w/o SSM</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.3.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T8.1.3.2.1\" style=\"color:#FF0000;\">0.702</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.3.3\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T8.1.3.3.1\" style=\"color:#FF0000;\">0.780</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.3.4\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T8.1.3.4.1\" style=\"color:#FF0000;\">0.739</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.1.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S4.T8.1.4.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T8.1.4.1.1\" style=\"color:#FF0000;\">STEEL</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S4.T8.1.4.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.4.2.1\" style=\"color:#FF0000;\">0.714</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S4.T8.1.4.3\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.4.3.1\" style=\"color:#FF0000;\">0.793</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S4.T8.1.4.4\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.4.4.1\" style=\"color:#FF0000;\">0.751</span></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"color:#FF0000;\"><span class=\"ltx_tag ltx_tag_table\">Table 8: </span>Experimental results of the ablation analysis of the semantic search module.</figcaption>\n</figure>",
            "capture": "Table 8: Experimental results of the ablation analysis of the semantic search module."
        },
        "9": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T9\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T9.1\" style=\"width:208.1pt;height:85.5pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-71.2pt,29.3pt) scale(0.593683050682436,0.593683050682436) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T9.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T9.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.1.1.1.1\" rowspan=\"2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.1.1.1\" style=\"color:#FF0000;\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"3\" id=\"S4.T9.1.1.1.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.1.2.1\" style=\"color:#FF0000;\">F1-Ma</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.1.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.2.1.1\" style=\"color:#FF0000;\">LIAR</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.2.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.2.2.1\" style=\"color:#FF0000;\">CHEF</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.2.3\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.2.3.1\" style=\"color:#FF0000;\">POLITIFACT</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.1.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.1.1.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.3.1.1\" style=\"color:#FF0000;\">Vicuna-7b</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.3.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.3.2.1\" style=\"color:#FF0000;\">0.528</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.3.3\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.3.3.1\" style=\"color:#FF0000;\">0.519</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.3.4\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.3.4.1\" style=\"color:#FF0000;\">0.522</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.1.1.4.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.4.1.1\" style=\"color:#FF0000;\">Vicuna-7b + BING 1-step search</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.1.1.4.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.4.2.1\" style=\"color:#FF0000;\">0.617</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.1.1.4.3\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.4.3.1\" style=\"color:#FF0000;\">0.683</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.1.1.4.4\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.4.4.1\" style=\"color:#FF0000;\">0.665</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.1.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.1.1.5.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.5.1.1\" style=\"color:#FF0000;\">Vicuna-7b + BING multi-stage search</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.1.1.5.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.5.2.1\" style=\"color:#FF0000;\">0.629</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.1.1.5.3\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.5.3.1\" style=\"color:#FF0000;\">0.701</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.1.1.5.4\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.5.4.1\" style=\"color:#FF0000;\">0.677</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.1.1.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.1.1.6.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.6.1.1\" style=\"color:#FF0000;\">GPT-3.5-turbo</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.6.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.6.2.1\" style=\"color:#FF0000;\">0.563</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.6.3\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.6.3.1\" style=\"color:#FF0000;\">0.574</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.6.4\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.6.4.1\" style=\"color:#FF0000;\">0.567</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.1.1.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.1.1.7.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.7.1.1\" style=\"color:#FF0000;\">GPT-3.5-turbo + BING 1-step search</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.1.1.7.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.7.2.1\" style=\"color:#FF0000;\">0.691</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.1.1.7.3\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.7.3.1\" style=\"color:#FF0000;\">0.770</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.1.1.7.4\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.7.4.1\" style=\"color:#FF0000;\">0.738</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.1.1.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T9.1.1.8.1\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text\" id=\"S4.T9.1.1.8.1.1\" style=\"color:#FF0000;\">GPT-3.5-turbo + BING multi-stage search(STEEL)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T9.1.1.8.2\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T9.1.1.8.2.1\" style=\"color:#FF0000;\">0.714</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T9.1.1.8.3\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T9.1.1.8.3.1\" style=\"color:#FF0000;\">0.793</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T9.1.1.8.4\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T9.1.1.8.4.1\" style=\"color:#FF0000;\">0.751</span></td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"color:#FF0000;\"><span class=\"ltx_tag ltx_tag_table\">Table 9: </span>Performence comparison of various combinations across three datasets.</figcaption>\n</figure>",
            "capture": "Table 9: Performence comparison of various combinations across three datasets."
        },
        "10": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T10\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T10.1\">\n<tr class=\"ltx_tr\" id=\"S4.T10.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T10.1.1.1\">Method</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T10.1.1.2\">F1-Ma</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T10.1.1.3\">Precision</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T10.1.1.4\">Agreement</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T10.1.2.1\">MUSER</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T10.1.2.2\">0.687</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T10.1.2.3\">0.698</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T10.1.2.4\">72.5%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T10.1.3.1\">STEEL</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T10.1.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T10.1.3.2.1\">0.773</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T10.1.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T10.1.3.3.1\">0.741</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T10.1.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T10.1.3.4.1\">78.2%</span></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 10: </span>Results of the user study. The agreement measure means the proportion of concurrence between the user\u2019s judgment and the model\u2019s judgment.</figcaption>\n</figure>",
            "capture": "Table 10: Results of the user study. The agreement measure means the proportion of concurrence between the user\u2019s judgment and the model\u2019s judgment."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.09747v1_figure_1.png",
            "caption": "Figure 1: A motivating example of our model. (a) Bert-driven methods: up-to-date evidence cannot be retrieved. (b) One-shot retrieval-enhanced LLMs: only partial evidence can be retrieved. (c) Strategic Internet-based LLMs: multi-round retrieval of evidence from the Internet facilitates more comprehensive and accurate assessments."
        },
        "2": {
            "figure_path": "2403.09747v1_figure_2.png",
            "caption": "Figure 2: The overview of the STEEL framework. Our framework unfolds in three parts: (a) Retrieval module. Use claim or updated queries to search for evidence via the search engine, sort and select based on the similarity between the searched documents and paragraphs of the claim. (b) Reasoning module. Feed the obtained evidence and established evidence to LLMs via carefully designed prompts, and LLMs will reason and output one of the three situations \"true, false, or NEI (Not Enough Information)\" with confidence levels. Even when the output is \"NEI\", LLMs will compress the newly obtained information to the pool of established evidence for subsequent search. (c) Re-search mechanism. Re-search for more evidence when the output is \"NEI\" or the confidence level is below 50%percent5050\\%50 %. We use LLMs to generate \"updated queries\" to improve the quality of retrieval evidence."
        },
        "3": {
            "figure_path": "2403.09747v1_figure_3.png",
            "caption": "Figure 3: Situations necessitating re-search: Irrelevant Evidence denotes evidence unrelated to the query or claim. Insufficient Evidence indicates inadequate evidence for reaching a valid conclusion. Lack of Confidence signifies uncertainty or low confidence in the conclusion\u2019s accuracy based on evidence."
        },
        "4": {
            "figure_path": "2403.09747v1_figure_4.png",
            "caption": "Figure 4: Ablation study results: STEEL denotes complete model performance, STEEL-RR represents removal of the re-search mechanism, and STEEL-RS represents GPT-3.5-Turbo without the search module."
        },
        "5": {
            "figure_path": "2403.09747v1_figure_5.png",
            "caption": "Figure 5: F1-Ma of various numbers of re-search rounds on three challenging claim verification datasets: LIAR (orange line), CHEF (red line), and PolitFact (blue line)."
        },
        "6": {
            "figure_path": "2403.09747v1_figure_6.png",
            "caption": "Figure 6: Explanation case study. Text with a colorful background indicates quoted evidence."
        },
        "7": {
            "figure_path": "2403.09747v1_figure_7.png",
            "caption": "Figure A1: \nLLMs can make decisions based on given evidence, including deciding if they need to re-search."
        }
    },
    "references": [
        {
            "1": {
                "title": "Retrieval-based language models and applications.",
                "author": "Akari Asai, Sewon Min, Zexuan Zhong, and Danqi Chen. 2023.",
                "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts, ACL 2023, Toronto, Canada, July 9-14, 2023, pages 41\u201346. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2023.acl-tutorials.6"
            }
        },
        {
            "2": {
                "title": "Improving language models by retrieving from trillions of tokens.",
                "author": "Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Simonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022.",
                "venue": "In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 2206\u20132240. PMLR.",
                "url": "https://proceedings.mlr.press/v162/borgeaud22a.html"
            }
        },
        {
            "3": {
                "title": "Content-based fake news detection with machine and deep learning: a systematic review.",
                "author": "Nicola Capuano, Giuseppe Fenza, Vincenzo Loia, and Francesco David Nota. 2023.",
                "venue": "Neurocomputing, 530:91\u2013103.",
                "url": "https://doi.org/10.1016/j.neucom.2023.02.005"
            }
        },
        {
            "4": {
                "title": "Combating misinformation in the age of llms: Opportunities and challenges.",
                "author": "Canyu Chen and Kai Shu. 2023.",
                "venue": "CoRR, abs/2311.05656.",
                "url": "https://doi.org/10.48550/ARXIV.2311.05656"
            }
        },
        {
            "5": {
                "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality.",
                "author": "Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, et al. 2023.",
                "venue": "See https://vicuna. lmsys. org (accessed 14 April 2023).",
                "url": null
            }
        },
        {
            "6": {
                "title": "Trends in combating fake news on social media - a survey.",
                "author": "Botambu Collins, Dinh Tuyen Hoang, Ngoc Thanh Nguyen, and Dosam Hwang. 2021.",
                "venue": "J. Inf. Telecommun., 5(2):247\u2013266.",
                "url": "https://doi.org/10.1080/24751839.2020.1847379"
            }
        },
        {
            "7": {
                "title": "Public wisdom matters! discourse-aware hyperbolic fourier co-attention for social text classification.",
                "author": "Karish Grover, S. M. Phaneendra Angara, Md. Shad Akhtar, and Tanmoy Chakraborty. 2022.",
                "venue": "In NeurIPS.",
                "url": "http://papers.nips.cc/paper_files/paper/2022/hash/3d57795f0e263aa69577f1bbceade46b-Abstract-Conference.html"
            }
        },
        {
            "8": {
                "title": "Realm: Retrieval-augmented language model pre-training.",
                "author": "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. 2020a.",
                "venue": "In Proceedings of the 37th International Conference on Machine Learning, ICML\u201920. JMLR.org.",
                "url": null
            }
        },
        {
            "9": {
                "title": "Retrieval augmented language model pre-training.",
                "author": "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. 2020b.",
                "venue": "In Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research, pages 3929\u20133938. PMLR.",
                "url": "http://proceedings.mlr.press/v119/guu20a.html"
            }
        },
        {
            "10": {
                "title": "LLM self defense: By self examination, llms know they are being tricked.",
                "author": "Alec Helbling, Mansi Phute, Matthew Hull, and Duen Horng Chau. 2023.",
                "venue": "CoRR, abs/2308.07308.",
                "url": "https://doi.org/10.48550/ARXIV.2308.07308"
            }
        },
        {
            "11": {
                "title": "Read it twice: Towards faithfully interpretable fact verification by revisiting evidence.",
                "author": "Xuming Hu, Zhaochen Hong, Zhijiang Guo, Lijie Wen, and Philip S. Yu. 2023.",
                "venue": "In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2023, Taipei, Taiwan, July 23-27, 2023, pages 2319\u20132323. ACM.",
                "url": "https://doi.org/10.1145/3539618.3592049"
            }
        },
        {
            "12": {
                "title": "Few-shot learning with retrieval augmented language models.",
                "author": "Gautier Izacard, Patrick S. H. Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. 2023.",
                "venue": "J. Mach. Learn. Res., 24:251:1\u2013251:43.",
                "url": "https://www.jmlr.org/papers/v24/23-0037.html"
            }
        },
        {
            "13": {
                "title": "Active retrieval augmented generation.",
                "author": "Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023.",
                "venue": "In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pages 7969\u20137992. Association for Computational Linguistics.",
                "url": "https://aclanthology.org/2023.emnlp-main.495"
            }
        },
        {
            "14": {
                "title": "Large language models struggle to learn long-tail knowledge.",
                "author": "Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel. 2023.",
                "venue": "In International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA, volume 202 of Proceedings of Machine Learning Research, pages 15696\u201315707. PMLR.",
                "url": "https://proceedings.mlr.press/v202/kandpal23a.html"
            }
        },
        {
            "15": {
                "title": "Explainable automated fact-checking: A survey.",
                "author": "Neema Kotonya and Francesca Toni. 2020.",
                "venue": "In Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020, Barcelona, Spain (Online), December 8-13, 2020, pages 5430\u20135443. International Committee on Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2020.coling-main.474"
            }
        },
        {
            "16": {
                "title": "MUSER: A multi-step evidence retrieval enhancement framework for fake news detection.",
                "author": "Hao Liao, Jiahao Peng, Zhanyi Huang, Wei Zhang, Guanghua Li, Kai Shu, and Xing Xie. 2023.",
                "venue": "In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2023, Long Beach, CA, USA, August 6-10, 2023, pages 4461\u20134472. ACM.",
                "url": "https://doi.org/10.1145/3580305.3599873"
            }
        },
        {
            "17": {
                "title": "Webglm: Towards an efficient web-enhanced question answering system with human preferences.",
                "author": "Xiao Liu, Hanyu Lai, Hao Yu, Yifan Xu, Aohan Zeng, Zhengxiao Du, Peng Zhang, Yuxiao Dong, and Jie Tang. 2023.",
                "venue": "In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2023, Long Beach, CA, USA, August 6-10, 2023, pages 4549\u20134560. ACM.",
                "url": "https://doi.org/10.1145/3580305.3599931"
            }
        },
        {
            "18": {
                "title": "Sentence-level evidence embedding for claim verification with hierarchical attention networks.",
                "author": "Jing Ma, Wei Gao, Shafiq R. Joty, and Kam-Fai Wong. 2019.",
                "venue": "In Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers, pages 2561\u20132571. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/p19-1244"
            }
        },
        {
            "19": {
                "title": "Divide-and-conquer: Post-user interaction network for fake news detection on social media.",
                "author": "Erxue Min, Yu Rong, Yatao Bian, Tingyang Xu, Peilin Zhao, Junzhou Huang, and Sophia Ananiadou. 2022.",
                "venue": "In WWW \u201922: The ACM Web Conference 2022, Virtual Event, Lyon, France, April 25 - 29, 2022, pages 1148\u20131158. ACM.",
                "url": "https://doi.org/10.1145/3485447.3512163"
            }
        },
        {
            "20": {
                "title": "Webgpt: Browser-assisted question-answering with human feedback.",
                "author": "Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. 2021.",
                "venue": "CoRR, abs/2112.09332.",
                "url": "http://arxiv.org/abs/2112.09332"
            }
        },
        {
            "21": {
                "title": "Chatgpt.",
                "author": "OpenAI. 2022.",
                "venue": "https://chat.openai.com.",
                "url": null
            }
        },
        {
            "22": {
                "title": "Fact-checking complex claims with program-guided reasoning.",
                "author": "Liangming Pan, Xiaobao Wu, Xinyuan Lu, Anh Tuan Luu, William Yang Wang, Min-Yen Kan, and Preslav Nakov. 2023.",
                "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 6981\u20137004. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2023.acl-long.386"
            }
        },
        {
            "23": {
                "title": "Who funds misinformation? A systematic analysis of the ad-related profit routines of fake news sites.",
                "author": "Emmanouil Papadogiannakis, Panagiotis Papadopoulos, Evangelos P. Markatos, and Nicolas Kourtellis. 2023.",
                "venue": "In Proceedings of the ACM Web Conference 2023, WWW 2023, Austin, TX, USA, 30 April 2023 - 4 May 2023, pages 2765\u20132776. ACM.",
                "url": "https://doi.org/10.1145/3543507.3583443"
            }
        },
        {
            "24": {
                "title": "DeClarE: Debunking fake news and false claims using evidence-aware deep learning.",
                "author": "Kashyap Popat, Subhabrata Mukherjee, Andrew Yates, and Gerhard Weikum. 2018.",
                "venue": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 22\u201332.",
                "url": "https://doi.org/10.18653/v1/D18-1003"
            }
        },
        {
            "25": {
                "title": "In-context retrieval-augmented language models.",
                "author": "Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham. 2023.",
                "venue": "Transactions of the Association for Computational Linguistics, 11:1316\u20131331.",
                "url": "https://doi.org/10.1162/tacl_a_00605"
            }
        },
        {
            "26": {
                "title": "REPLUG: retrieval-augmented black-box language models.",
                "author": "Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih. 2023.",
                "venue": "CoRR, abs/2301.12652.",
                "url": "https://doi.org/10.48550/arXiv.2301.12652"
            }
        },
        {
            "27": {
                "title": "Hierarchical multi-head attentive network for evidence-aware fake news detection.",
                "author": "Nguyen Vo and Kyumin Lee. 2021.",
                "venue": "In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume., page 965\u2013975.",
                "url": null
            }
        },
        {
            "28": {
                "title": "Explainable claim verification via knowledge-grounded reasoning with large language models.",
                "author": "Haoran Wang and Kai Shu. 2023.",
                "venue": "In Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023, pages 6288\u20136304. Association for Computational Linguistics.",
                "url": "https://aclanthology.org/2023.findings-emnlp.416"
            }
        },
        {
            "29": {
                "title": "Self-consistency improves chain of thought reasoning in language models.",
                "author": "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2023a.",
                "venue": "In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net.",
                "url": "https://openreview.net/pdf?id=1PL1NIMMrw"
            }
        },
        {
            "30": {
                "title": "Self-knowledge guided retrieval augmentation for large language models.",
                "author": "Yile Wang, Peng Li, Maosong Sun, and Yang Liu. 2023b.",
                "venue": "In Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023, pages 10303\u201310315. Association for Computational Linguistics.",
                "url": "https://aclanthology.org/2023.findings-emnlp.691"
            }
        },
        {
            "31": {
                "title": "Factcheck-gpt: End-to-end fine-grained document-level fact-checking and correction of LLM output.",
                "author": "Yuxia Wang, Revanth Gangi Reddy, Zain Muhammad Mujahid, Arnav Arora, Aleksandr Rubashevskii, Jiahui Geng, Osama Mohammed Afzal, Liangming Pan, Nadav Borenstein, Aditya Pillai, Isabelle Augenstein, Iryna Gurevych, and Preslav Nakov. 2023c.",
                "venue": "CoRR, abs/2311.09000.",
                "url": "https://doi.org/10.48550/ARXIV.2311.09000"
            }
        },
        {
            "32": {
                "title": "Unleashing cognitive synergy in large language models: A task-solving agent through multi-persona self-collaboration.",
                "author": "Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, and Heng Ji. 2023d.",
                "venue": "CoRR, abs/2307.05300.",
                "url": "https://doi.org/10.48550/ARXIV.2307.05300"
            }
        },
        {
            "33": {
                "title": "Emergent abilities of large language models.",
                "author": "Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022a.",
                "venue": "Trans. Mach. Learn. Res., 2022.",
                "url": "https://openreview.net/forum?id=yzkSU5zdwD"
            }
        },
        {
            "34": {
                "title": "Chain-of-thought prompting elicits reasoning in large language models.",
                "author": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2022b.",
                "venue": "In NeurIPS.",
                "url": "http://papers.nips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html"
            }
        },
        {
            "35": {
                "title": "Misinformation in and about science.",
                "author": "Jevin D. West and Carl T. Bergstrom. 2020.",
                "venue": "Proceedings of the National Academy of Sciences.",
                "url": "https://doi.org/10.1073/pnas.1912444117"
            }
        },
        {
            "36": {
                "title": "Prompt-and-align: Prompt-based social alignment for few-shot fake news detection.",
                "author": "Jiaying Wu, Shen Li, Ailin Deng, Miao Xiong, and Bryan Hooi. 2023.",
                "venue": "In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management, CIKM 2023, Birmingham, United Kingdom, October 21-25, 2023, pages 2726\u20132736. ACM.",
                "url": "https://doi.org/10.1145/3583780.3615015"
            }
        },
        {
            "37": {
                "title": "Evidence-aware hierarchical interactive attention networks for explainable claim verification.",
                "author": "Lianwei Wu, Yuan Rao, Xiong Yang, Wanzhen Wang, and Ambreen Nazir. 2020.",
                "venue": "In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, pages 1388\u20131394.",
                "url": "https://doi.org/10.24963/ijcai.2020/193"
            }
        },
        {
            "38": {
                "title": "Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms.",
                "author": "Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, and Bryan Hooi. 2023.",
                "venue": "CoRR, abs/2306.13063.",
                "url": "https://doi.org/10.48550/arXiv.2306.13063"
            }
        },
        {
            "39": {
                "title": "Evidence-aware fake news detection with graph neural networks.",
                "author": "Weizhi Xu, Junfei Wu, Qiang Liu, Shu Wu, and Liang Wang. 2022.",
                "venue": "In Proceedings of the ACM Web Conference 2022, page 2501\u20132510.",
                "url": "https://doi.org/10.1145/3485447.3512122"
            }
        },
        {
            "40": {
                "title": "Tree of thoughts: Deliberate problem solving with large language models.",
                "author": "Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. 2023a.",
                "venue": "CoRR, abs/2305.10601.",
                "url": "https://doi.org/10.48550/arXiv.2305.10601"
            }
        },
        {
            "41": {
                "title": "React: Synergizing reasoning and acting in language models.",
                "author": "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R. Narasimhan, and Yuan Cao. 2023b.",
                "venue": "In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net.",
                "url": "https://openreview.net/pdf?id=WE_vluYUL-X"
            }
        },
        {
            "42": {
                "title": "The unreliability of explanations in few-shot prompting for textual reasoning.",
                "author": "Xi Ye and Greg Durrett. 2022.",
                "venue": "In NeurIPS.",
                "url": "http://papers.nips.cc/paper_files/paper/2022/hash/c402501846f9fe03e2cac015b3f0e6b1-Abstract-Conference.html"
            }
        },
        {
            "43": {
                "title": "Generate rather than retrieve: Large language models are strong context generators.",
                "author": "Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal, Chenguang Zhu, Michael Zeng, and Meng Jiang. 2023.",
                "venue": "In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net.",
                "url": "https://openreview.net/pdf?id=fB0hRu9GZUS"
            }
        },
        {
            "44": {
                "title": "An overview of online fake news: Characterization, detection, and discussion.",
                "author": "Xichen Zhang and Ali A. Ghorbani. 2020.",
                "venue": "Inf. Process. Manag., 57(2):102025.",
                "url": "https://doi.org/10.1016/j.ipm.2019.03.004"
            }
        },
        {
            "45": {
                "title": "A survey of fake news: Fundamental theories, detection methods, and opportunities.",
                "author": "Xinyi Zhou and Reza Zafarani. 2020.",
                "venue": "ACM Computing Surveys (CSUR), 53(5):1\u201340.",
                "url": null
            }
        },
        {
            "46": {
                "title": "A survey of fake news: Fundamental theories, detection methods, and opportunities.",
                "author": "Xinyi Zhou and Reza Zafarani. 2021.",
                "venue": "ACM Comput. Surv., 53(5):109:1\u2013109:40.",
                "url": "https://doi.org/10.1145/3395046"
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.09747v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2.1",
            "2.2"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.2"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4.5"
        ]
    },
    "research_context": {
        "paper_id": "2403.09747v1",
        "paper_title": "Re-Search for The Truth: Multi-round Retrieval-augmented Large Language Models are Strong Fake News Detectors",
        "research_background": "### Paper Motivation:\nThe paper is driven by the urgent need to combat the escalating threat of fake news, which significantly impacts political, economic, and social realms. Traditional methods of detecting fake news are often dataset-specific, which limits their scalability, transferability, and robustness. This necessitates the development of versatile models capable of efficiently detecting fake news in zero-shot or few-shot learning settings.\n\n### Research Problem:\nThe main research problem addressed in this paper is the inadequacy of current fake news detection methods to scale, transfer, and remain robust across different datasets. These existing methods are typically constrained by the specific databases they utilize, such as Wikipedia, or rely on single-step retrieval processes, which are not sufficient in the dynamic and diverse real-world scenarios filled with AI-generated disinformation. Therefore, there is a critical need to devise a more sophisticated and versatile approach that can handle the complexities and evolving nature of fake news.\n\n### Relevant Prior Work:\nThe study builds on prior efforts in three main approaches to fake news detection:\n1. **Content-based approaches** as referenced by Zhou and Zafarani (2021, ###reference_b46###) and Capuano et al. (2023, ###reference_b3###).\n2. **Evidence-based approaches** exemplified by Kotonya and Toni (2020, ###reference_b15###) and Min et al. (2022, ###reference_b19###).\n3. **Social context-based approaches** such as those referenced by Collins et al. (2021, ###reference_b6###) and Grover et al. (2022, ###reference_b7###).\n\nAdditionally, the study acknowledges the limitations of current methodologies using Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs), which are largely dependent on specific databases and simple retrieval processes, as highlighted by Izacard et al. (2023, ###reference_b12###) and Guu et al. (2020a, ###reference_b8###).\n\n### Innovation and Contribution:\nThe paper proposes the STEEL framework, leveraging LLMs for a multi-round, adaptive retrieval process from the expansive Internet to address the constraints and evolving challenges in fake news detection. This framework aims to offer a more robust and scalable solution while also improving interpretability and ease-of-use compared to existing state-of-the-art methods.",
        "methodology": "In this section, we present our model, STEEL. The input of this method consists of a claim \\(c\\). Initially, a set of relevant evidence \\(e_1,...,e_n\\) are retrieved from the Internet. Subsequently, LLMs (Large Language Models) evaluate the sufficiency of the gathered evidence. If the evidence is deemed adequate, the results will be output promptly. Otherwise, the search for additional evidence continues. To construct an affordable, ready-to-use framework, we leverage the APIs (Application Programming Interfaces) of leading AI companies. Specifically, we utilize BING Search for web evidence retrieval and OPENAI\u2019s GPT-3.5-turbo (OpenAI, 2022) for verification. The output is the prediction of this claim \\(\\hat{c}^\\*\\), along with explanatory text \\(t\\). Here, \\(t\\) refers to the LLMs responsible for generating the output. \\(\\hat{c}^\\*\\) is a binary classification, where \\(\\texttt{true}\\) or \\(\\texttt{false}\\) indicates the assessment of the news claims as true or false. Our model mainly comprises two key components: a retrieval module and a reasoning module. These two modules are integrated within the overarching framework of the re-search mechanism.",
        "main_experiment_and_results": "**Main Experiment Setup and Results:**\n\n**Experimental Setup**\n1. **Purpose:** Evaluate the efficacy of the STEEL model in identifying fake news, focusing on three main aspects: efficiency of evidence retrieval, the role of the re-search mechanism, and the influence of varying retrieval steps and prompts.\n   \n2. **Datasets:** \n   - **LIAR (English):** News data categorized into real and fake.\n   - **PolitiFact (English):** Similar categorization as LIAR.\n   - **CHEF (Chinese):** Also split into real and fake news.\n\n3. **Baselines:** Divided into two groups:\n   - **G1:** Classical and advanced evidence-based methods including DeClarE, HAN, EHIAN, MAC, GET, MUSER, and ReRead.\n   - **G2:** Methods based on Large Language Models (LLMs), with or without a retrieval component. This includes GPT-3.5-turbo, Vicuna-7B, WEBGLM, and ProgramFC.\n   \n4. **Experiment Conditions:** \n   - All datasets are used as testing sets since no training set is required for the STEEL model.\n   - Hyperparameters are set specifically for STEEL and LLMs, and meticulously tuned for all other baselines as per their respective papers.\n   - **Evaluation Metrics:** F1, Precision, Recall, F1 Macro, and F1 Micro.\n   \n5. **Implementation Details:** Source code and further details for reproducing the experiments are available in the provided URL. Additional cost details and implementation specifics are found in Appendix A.1 of the paper.\n\n**Main Experimental Results**\n1. **Performance Across Datasets:** The STEEL model demonstrated superior performance across all evaluation metrics compared to both groups of baselines (G1 and G2).\n   \nOverall, the experimental results emphasize the robustness and efficiency of the STEEL model in detecting fake news, outperforming existing baselines and establishing its potential for real-world applications."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To evaluate the impact of each module within the proposed retrieval-augmented LLM framework and to determine the contributions of these modules to the overall effectiveness of the fake news detection system.",
            "experiment_process": "The ablation study involved creating specific model variants by removing key modules, labeled '-RS' for the model without the retrieval module and '-RR' for the removal of the re-search mechanism. Performance metrics were evaluated for these variants. Additionally, the impact of the semantic search module was analyzed, and a distinct study examined the effects of various step searches using different LLMs. Multiple prompts were tested, including 'vanilla' prompts, 'quadratic answer' prompts, 'response correction' prompts, and 'Chain of Thought' prompts. The evaluation metrics were collected and presented in tables and figures based on specific dataset performance.",
            "result_discussion": "The results demonstrated that the exclusion of any single module led to a decrease in performance, confirming the importance of each component. The retrieval module, in particular, was crucial for performance enhancement as it effectively retrieved relevant evidence. Multi-step retrieval processes were found to improve consistency and performance, peaking at three steps before deterioration. Prompt adjustments alone did not consistently enhance performance and could even degrade it, underscoring the value of the retrieval mechanism. The optimal number of retrieval steps remained consistent across varying dataset difficulties.",
            "ablation_id": "2403.09747v1.No1"
        },
        {
            "research_objective": "To investigate the influence of different LLM prompt types on the performance of the retrieval-augmented fake news detection framework.",
            "experiment_process": "We experimented with four categories of prompts: 'vanilla' prompts, 'quadratic answer' prompts, 'response correction' prompts, and 'Chain of Thought' prompts, which include illustrative examples to guide response generation. The prompts were designed to assess self-consistency, coherence, and the influence of explanatory text versus direct answers. Performance metrics were compared across these different prompt types.",
            "result_discussion": "The results indicated that altering prompt types typically did not lead to improvements and could potentially deteriorate performance. This suggests that solely relying on prompt modifications for performance gains may be insufficient. The study highlighted that the re-search mechanism for retrieving pertinent evidence provided a more effective approach for enhancing the model's accuracy and reliability.",
            "ablation_id": "2403.09747v1.No2"
        }
    ]
}