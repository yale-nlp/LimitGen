{
    "title": "Relational Prompt-based Pre-trained Language Models for Social Event Detection",
    "abstract": "Social Event Detection (SED) aims to identify significant events from social streams and has a wide application ranging from public opinion analysis to risk management. In recent years, Graph Neural Network (GNN) based solutions have achieved state-of-the-art performance. However, GNN-based methods often struggle with noisy and missing edges between messages, affecting the quality of learned message embedding. Moreover, these methods statically initialize node embedding before training, which, in turn, limits the ability to learn from message texts and relations simultaneously. \n\nIn this paper, we approach social event detection from a new perspective based on Pre-trained Language Models (PLMs), and present (Relational prompt-based Pre-trained Language Models for Social Event Detection). We first propose a new pairwise message modeling strategy to construct social messages into message pairs with multi-relational sequences. Secondly, a new multi-relational prompt-based pairwise message learning mechanism is proposed to learn more comprehensive message representation from message pairs with multi-relational prompts using PLMs. Thirdly, we design a new clustering constraint to optimize the encoding process by enhancing intra-cluster compactness and inter-cluster dispersion, making the message representation more distinguishable.\n\nWe evaluate the on three real-world datasets: the Coco Dataset, demonstrating that the model achieves state-of-the-art performance in offline, online, low-resource, and long-tail distribution scenarios for social event detection tasks.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1. Introduction",
            "text": "Social events refer to the various incidents or activities occurring in reality that elicit widespread public interest and discourse across platforms such as Twitter, Weibo, Facebook, Tumblr, Telegram, etc. These events encompass a broad spectrum of topics, including news reports, sudden public incidents, social trends, market dynamics, and more (Cordeiro and Gama, 2016  ###reference_b15###). Social Event Detection (SED) aims to group messages reporting on the same incident to identify significant events within them from social streams (Atefeh and Khreich, 2015  ###reference_b6###; Li et al., 2022a  ###reference_b38###). Owing to its capability to provide deep insights into public issues and trends, it is extensively applied in fields such as public opinion analysis (Peng et al., 2021  ###reference_b59###), financial market analysis (Nisar and Yeung, 2018  ###reference_b55###), risk management (Liu et al., 2017  ###reference_b46###), and political analysis (Marozzo and Bessi, 2018  ###reference_b49###). Social data\u2019s incompleteness, ambiguity, and streaming nature present more significant challenges for social event detection than traditional text mining tasks. Early social event detection methods typically focused on utilizing text contents (Amiri and Daume III, 2016  ###reference_b4###; Morabia et al., 2019  ###reference_b54###; Sahnoun et al., 2020  ###reference_b69###; Wang and Zhang, 2017  ###reference_b76###; Yan et al., 2015  ###reference_b80###; Zhao et al., 2011  ###reference_b87###) or attributes extracted from texts (Feng et al., 2015  ###reference_b22###; Xie et al., 2016  ###reference_b78###; Xing et al., 2016  ###reference_b79###) to identify and categorize events. These methods focus on categorizing messages into different events but fail to detect events from social streams. In recent years, Graph Neural Network (GNN) based social event detection methods have demonstrated tremendous potential  (Peng et al., 2019  ###reference_b57###, 2021  ###reference_b59###; Cao et al., 2021  ###reference_b11###; Cui et al., 2021  ###reference_b16###; Ren et al., 2022a  ###reference_b65###; Peng et al., 2022  ###reference_b60###; Ren et al., 2023  ###reference_b67###). These methods typically model social messages into graphs to integrate semantic and structural information. By leveraging GNNs to learn message representations from graphs and employing clustering techniques for event detection, these approaches significantly enhance the performance of social event detection. For instance, Peng et al. (2019  ###reference_b57###) construct social messages as a Heterogeneous Information Network (HIN) and, upon obtaining representations through Graph Convolutional Networks (GCN), employ a pairwise sampling method to address the challenges presented by the numerous event categories and the sparse number of instances per category. Cui et al. (2021  ###reference_b16###) respectively construct semantic and temporal views by leveraging hashtags and time distribution of messages, then integrate representations from semantic and temporal views using a hashtag-based multi-view graph attention mechanism. Cao et al. (2021  ###reference_b11###) construct messages as a HIN graph and then transform it into a homogeneous graph, utilizing the learning and inductive capabilities of GNNs to achieve incremental event detection. Moreover, Peng et al. (2022  ###reference_b60###), recognizing that different relations between messages may have varying degrees of value, models social messages into a weighted multi-relational graph, employing reinforcement learning to determine the optimal thresholds for various relations. However, GNN-based social event detection methods still exhibit the following limitations. Firstly, graphs constructed from common attributes (e.g., entities, hashtags, users, etc.) between messages face issues of missing and noisy edges (Liu et al., 2022  ###reference_b45###). These issues of missing and noisy edges are primarily manifested in the lack of connections between message nodes within the same event and the existence of connections between nodes that belong to different events. Whether modeling social messages as HIN graph (Figure 1  ###reference_###(a)), homogeneous graph (Figure 1  ###reference_###(b)), or multi-relational graph (Figure 1  ###reference_###(c)), none of these approaches can handle well the issue of missing edges between messages of intra-event and noisy edges between massages of inter-events. This challenge is multifaceted. On the"
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2. Background and Overview",
            "text": "This section first provides an overview of the problems and challenges encountered in social event detection.\nSubsequently, we detail the core definitions related to social event detection.\nAdditionally, Table 1  ###reference_### presents a comprehensive list of the primary symbols used throughout this paper.\n###table_1### A social stream\nA message block; A message in a message block or event\nSet of events from message block\nevent in\nA multi-relational message graph\nThe set of all nodes in\nThe window size for maintaining the model\nThe parameters of model; The parameters with the PLM section of model\nThe parameter update weight during model maintenance\nEdge set with relational type  in\nAn edge between  and sampled node  with relational type\nThe multi-relational sequence between  and sampled node\nPreprocessed message blocks; A message pair\nThe number of heads in structured attention mechanism\nThe representations of  and sampled node  obtained through structured attention mechanism and averaging\nThe similarity between  and sampled node\nA set of candidate representations of ; A set of similarities corresponding to\nA set of indices satisfying the similarity score\nThe similarity threshold\nThe final message representation of\nThe training batch size\nThe center feature representation matrix; The central feature representation\nThe pairwise cross-entropy loss\nThe intra-cluster loss\nThe inter-cluster loss\nTotal loss\nSimilarity pairwise cross-Entropy loss weight; Intra-cluster loss weight; Inter-cluster loss weight"
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1. Problem and Challenges",
            "text": "When addressing social event detection tasks, the most straightforward approach is to learn representations of social messages and subsequently cluster these representations.\nTo acquire higher-quality message representations for clustering, social event detection faces the following three main challenges:\nChallenge 1: How to effectively address the issues of missing and noisy edges in the social message graph for social event detection?\nThe issues of missing and noisy edges in the social message graph are multifaceted.\nThey include the lack of direct connections between nodes of the same event, connections between nodes of different events, and the presence of isolated nodes.\nThe emergence of these issues can be attributed to various factors, such as describing the same event using different vocabulary or sentences, an individual user expressing opinions on other events, the event having just occurred, or being rarely discussed.\nHowever, GNN-based methods (Amiri and Daume III, 2016  ###reference_b4###; Morabia et al., 2019  ###reference_b54###; Sahnoun et al., 2020  ###reference_b69###; Wang and Zhang, 2017  ###reference_b76###; Yan et al., 2015  ###reference_b80###; Zhao et al., 2011  ###reference_b87###; Feng et al., 2015  ###reference_b22###; Xie et al., 2016  ###reference_b78###; Xing et al., 2016  ###reference_b79###) learn message representations from explicit message graph.\nNoisy edges in the graph can adversely affect the learned message representations, while the absence of effective edges may result in incomplete message representations.\nAdditionally, isolated nodes within the graph cannot be effectively processed.\nHence, effectively addressing the issues of missing and noisy edges in the social message graph remains one of the challenges in social event detection.\nChallenge 2: How to concurrently leverage the content and structural information of messages to learn their representations?\nGNN-based methods typically initialize message embeddings statically before training, which precludes the acquisition of better semantic embeddings from message content during the training process.\nIn addition, the representation aggregation process of GNNs can be comprehended as being guided by the edges/relations to determine which message nodes are selected for subsequent aggregation.\nHowever, the edges themselves do not directly participate in the processing of message representations.\nThese approaches inherently separate the utilization of message content from structural information, failing to adequately account for the complexity of inter-message relations and the potential interactions between these relations and message content.\nTherefore, exploring a new learning mechanism to address the complexities of social streams is imperative, enabling a more effective utilization of both message content and structural information.\nChallenge 3: How to obtain more distinguishable message representations for social event detection?\nIn social event detection, events are detected through clustering algorithms after obtaining message representations.\nBoth distance-based (MacQueen, 1967  ###reference_b48###) and density-based (Campello et al., 2013  ###reference_b10###; Ester et al., 1996  ###reference_b19###) clustering algorithms fundamentally rely on the Euclidean distance between vectors.\nEnsuring sufficient closeness among messages belonging to the same event while maintaining adequate distance from messages of different events can further improve the accuracy of event detection.\nTherefore, enhancing the discriminability of message representations is essential.\nHowever, some common optimization methods, such as the triplet loss adopted in KPGNN (Cao et al., 2021  ###reference_b11###) and FinEvent (Peng et al., 2022  ###reference_b60###), are designed to select one positive and one negative sample for each message.\nThe goal is then to ensure that the distance between each message and its positive sample is significantly smaller than its distance to the negative sample.\nAlternatively, the pairwise loss proposed in QSGNN (Ren et al., 2022a  ###reference_b65###), which constrains the distance between all negative sample pairs to be greater than that of positive samples, offers more stringent constraints compared to triplet loss.\nBoth triplet loss and pairwise loss approaches treat messages as objects to be pushed away or drawn closer, which may not effectively differentiate all event clusters nor guarantee compactness within event clusters.\nThus, it is necessary to design a more effective optimization method to enhance the distinguishability of message representations and thereby improve event detection accuracy."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2. Problem Definition",
            "text": "In this section, we formalize the definitions of social stream, social event, multi-relational message graph, social event detection, and incremental social event detection as follows:\nrepresents a social stream consisting of continuous time-ordered social message blocks.\nMessage block  consists all of messages in a time block , where  is the total number of messages in , and  is a message within .\nA social event denoted as  constitutes a collection of interrelated social messages addressing a common real-world occurrence.\nWe assume that each social message is affiliated with at most one event.\nWe define a multi-relational message graph as , where  is a set of nodes representing social messages,  are sets of multi-relational edges with type .\n denotes an edge/relation between message  and  with relational type .\nRelational types may include occurrences of entities, hashtags, user mentions, or message pairs posted within a predefined period.\nGiven a message block , an algorithm for social event detection learns a model , where  represents a set of events within .\n denotes the parameters associated with the model .\nGiven a social stream , an incremental social event detection algorithm learns a series of event detection models , such that  is the model for all message blocks in .\nHere,  is a set of events contained in the message block ,  is the window size for continuously updating the model,  and  are the parameters of  and , respectively.\nNote that  inherits part of the parameters  from its predecessor , and it extends and updates the knowledge learned.\nSpecifically, , which does not extend any previous model, is referred to as the initial model.\n###figure_2### ###figure_3###"
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3. Methodology",
            "text": "This section provides a detailed exposition of the proposed method .\nWe elucidate the lifecycle of the  model in Section 3.1  ###reference_###.\nTo leverage messages\u2019 structure and semantics, we propose a new Pairwise Message Modeling Strategy in Section 3.2  ###reference_###.\nSection 3.3  ###reference_### and Section 3.4  ###reference_### introduce the Multi-relational Prompt-based Pairwise Message Learning Mechanism, and loss function, respectively.\nAdditionally, we provide and explain the overall algorithmic process in Section 3.5  ###reference_### and analyze the time complexity of  in Section 3.6  ###reference_###."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1. Incremental event detection life-cycle",
            "text": "As shown in Figure 2  ###reference_###, to detect events from social streams incrementally, we propose a three-stage event detection framework, including initial model training, event detection, and model maintenance:\nInitial model training: we train the initial social event detection model with the first message block  using the proposed .\nEvent detection: event detection is performed on incoming message blocks  with the trained model .\nSpecifically, we use model  to detect events in each message block separately and evaluate the results.\nModel maintenance: the model enters the maintenance stage after each event detection stage.\nWe first perform a weighted fusion of the parameters of PLM in RPLM with the initial parameters of PLM, thereby striking a balance between retaining some existing knowledge and assimilating new knowledge.\nSubsequently, we use message blocks  to maintain the model ."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2. Pairwise Message Modeling Strategy",
            "text": "To jointly model social messages\u2019 textual content and structural information, we model social messages into message pairs with multi-relational sequences.\nFirstly, we construct a Heterogeneous Information Network (HIN) (Peng et al., 2019  ###reference_b57###, 2022  ###reference_b60###), where each social message is treated as a message node.\nConcurrently, we extract a set of named entities, hashtags, and users (including users and mentioned users) as relational nodes from each message.\nEdges between the message nodes and the corresponding relational nodes denote their associations.\nFor instance, the message  depicted in the \u2018Raw Messages\u2019 part of Figure 3  ###reference_### includes three entities (\u2018Nobel\u2019, \u2018Mo Yan\u2019, \u2018Chinese\u2019), one user (\u2018user1\u2019), and one hashtag (\u2018Nobel\u2019).\nEdges are established between  and its related nodes.\nBy merging duplicate nodes, a HIN graph is formed.\nIn this graph, message nodes, entity nodes, user nodes, and hashtag nodes are represented by , , , and , respectively.\nSubsequently, the relational nodes in the heterogeneous information graph are converted into different types of edges between message nodes, thereby constructing a multi-relational message graph that includes single-type nodes and multiple-type relational edges.\nAdditionally, edges are added between message nodes published within a 4-hour timeframe to capture temporal correlations.\nFinally, after establishing the multi-relational message graph, we further implement pairwise modeling for message nodes within the graph.\nFor any given message node , we sample  positive and negative samples to form message pairs in the training phase and sample  nodes in the detection phase.\nIn this process, we prefer to select message nodes of the same event with richer connections to  as positive sampling message nodes, whereas messages from different events with sparser connections to  are chosen as negative sampling message nodes.\nThis balanced and targeted sampling strategy helps to obtain more valuable sample pairs, enabling the model to learn more effective information during training.\nConsidering that the multiple relations between messages may have varying impacts.\nTherefore, we comprehensively preserve these multifaceted relations through a multi-relational sequence.\nWe define an external vocabulary to represent multi-relational edges  in a multi-relational message graph.\nEach type of relation/edge  occupies two distinct discrete values, indicating whether this relation/edge exists between messages.\nAs illustrated in the \u2018Pairwise Message Learning\u2019 part of Figure 3  ###reference_###, given a social message pair , we map the edge relations between them into the corresponding multi-relational sequence as follows:\nHere, , , , and  denote the hashtag, user, entity, and temporal edges between message node  and , respectively.\nCorrespondingly, , , , and  represent the sets of hashtag, user, entity, and temporal edges in the multi-relational message graph .\n represents the multi-relational sequence between  and .\nWe represent one such sample pair and the batch of all nodes in the pairwise modeled multi-relational message graph as follows:\nwhere  is the sampled message node.\nThe  denotes the true cluster relation label for a message pair, which is assigned a value of 1 if the pair of messages belongs to the same event, and 0 otherwise.\n represents the multi-relational sequence between  and .\n and  denote the set of message nodes in the multi-relational message graph  and its size, respectively.\nThe  is a data pair of samples, and  is the batch of data after pairwise modeling for the -th time block."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "3.3. Multi-relational Prompt-based Pairwise Message Learning Mechanism",
            "text": "Owing to current GNN-based SED methods to learn message representations from explicit message relations, a challenge arises where GNNs cannot directly learn effective knowledge when messages of the same event share no common attributes yet have the same semantics.\nConversely, when messages from two different events share common attributes, GNN-based methods may introduce noise from irrelevant messages, thereby affecting message representations.\nFurthermore, GNNs struggle to handle situations with missing structural relations.\nConsequently, we propose a new multi-relational prompt-based pairwise message learning mechanism.\nThe core of the mechanism lies in harnessing the powerful semantic and contextual relationship understanding abilities of PLMs to learn the deeper connections and differences between messages from both textual content and structural information, thereby obtaining more detailed and comprehensive message representations.\nAs illustrated in the \u2018Pairwise Message Learning\u2019 part of Figure 3  ###reference_###, this mechanism comprises three key components: Pairwise Message Encoding, Multi-Head Structured Attention, and Similarity-based Representation Aggregation.\nThe Pairwise Message Encoding module employs a PLM as the encoder to learn message representations from both message content embeddings and multi-relational prompt embeddings.\nSubsequently, we utilize the Multi-Head Structured Attention to extract more critical and clearer message representations.\nFinally, the final message representations are obtained through Similarity-based Representation Aggregation."
        },
        {
            "section_id": "3.3.1",
            "parent_section_id": "3.3",
            "section_name": "3.3.1. Pairwise Message Encoding",
            "text": "To incorporate the multi-relational sequence between messages as prompt information into the encoding process of PLMs, we transform it into multi-relational prompt embeddings.\nConsidering that the multi-relational sequence serves as soft prompts, it reveals the relations between messages without directly conveying semantic information.\nSharing the embedding space of the PLMs with message content may blur the semantic boundary between multi-relational prompts and textual content, thereby diminishing their guiding value.\nWe design an independent and learnable prompt embedding layer to distinguish between message content embeddings and multi-relational prompt embeddings.\nThis design prevents potential conflicts in the embedding space, enabling the model to adaptively learn optimized representations of different relational prompts during training, thereby enhancing the model\u2019s capability to understand and process complex relationships in social messages.\nIn the encoding phase, we combine the embeddings of multi-relational prompts with pairwise message content embeddings, delving into the connections and distinctions in semantic and structural information between messages.\nMultiple messages are sampled for each message to form pairs, allowing each message to be repeatedly learned.\nThis process enhances the learned message representations, making them more closely related to messages from the same event.\nConversely, it makes message representations more distinctly differentiated from messages of different events.\nThe specific encoding operation for the message pair  and  is as follows:\nwhere  denotes the encoding operation of PLMs,  and  denote the multi-relational embedding operation and the message pair embedding operation.\nThe  represents the multi-relational sequence of the message pair.\nThe  operation utilizes token type IDs to separately extract the encoded representation  of message  and the encoded representation  for sampled message  from the encoded representation of message pair.\nIt is essential to note that, to ensure that  encompasses both message content and structural information, the multi-relational prompt encoded representation is treated as a part of ."
        },
        {
            "section_id": "3.3.2",
            "parent_section_id": "3.3",
            "section_name": "3.3.2. Multi-Head Structured Attention",
            "text": "To further extract key features from message representations, we introduce the multi-head structured attention mechanism (Vaswani et al., 2017  ###reference_b74###; Kim et al., 2016  ###reference_b31###).\nThis mechanism can attend to different subspaces of the message representations.\nIt highlights those message features closely related to the event while ignoring the irrelevant and noisy parts.\nThis process is defined as:\nHere,  represents the operation of averaging representations, and  denotes the structured attention computation operation, with  being the number of attention heads.\nFinally, the resulting  and  are concatenated and fed into a classifier to discern the similarity between the two messages:\nwhere  is a weight matrix of dimension , and  is a bias term.\nThe linear layer maps the concatenated representation to a scalar, which is then mapped to the interval  through the sigmoid function , representing the similarity score  between two messages.\nSimultaneously,  will also participate as a candidate representation of the message  in the message representation aggregation.\nWe will introduce this in detail in Section 3.3.3  ###reference_.SSS3###."
        },
        {
            "section_id": "3.3.3",
            "parent_section_id": "3.3",
            "section_name": "3.3.3. Similarity-based Representation Aggregation",
            "text": "We propose a similarity-based representation aggregation approach to ensure that the final representation of  is as similar as possible to the message representations of the same event.\nThe essence of this approach lies in identifying and filtering out ambiguous or noisy candidate message representations generated by negative sample pairs.\nSubsequently, aggregating the candidate message representations extracted from pairs of messages with high similarity makes the resulting final message representation more robust and stable.\nIn the detection phase, we sample  other message nodes for each message node .\nConsequently, for each specific message , we obtain a set of  candidate representations , along with the corresponding set of similarity .\nSubsequently, select the indices from  that satisfy the conditions and average the candidate representations corresponding to these indices to obtain the final representation of .\nWe formalize this process as follows:\nHere,  represents the set of indices obtained by filtering the set ,  is the similarity retention threshold and  denotes the final representation of message .\nParticularly, we choose the candidate representation corresponding to the highest similarity index in  as the final representation for those messages in the similarity set  with only one or no indices meeting the condition."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "3.4. Optimization Objective",
            "text": "During the model training process, we enforce intra-event message proximity and inter-event message separation through Pairwise Cross-Entropy Loss.\nAdditionally, to enhance intra-cluster cohesion and inter-cluster dispersion, we design an additional Clustering Constraint."
        },
        {
            "section_id": "3.4.1",
            "parent_section_id": "3.4",
            "section_name": "3.4.1. Pairwise Cross-Entropy Loss",
            "text": "Considering the pairwise training characteristic of the model, we construct the pairwise cross-entropy loss.\nThis loss minimizes the divergence between the similarity of messages and the true cluster relationship labels, thereby drawing messages within the same cluster closer while pushing messages from different clusters further apart.\nMoreover, the pairwise cross-entropy loss also optimizes the model\u2019s classifier, enabling it to predict whether two messages belong to the same event more accurately.\nThe pairwise cross-entropy loss is defined as:\nwhere  denotes the batch size,  represents the true cluster relation label of the message pair, and  represents the similarity of messages as predicted by the classifier."
        },
        {
            "section_id": "3.4.2",
            "parent_section_id": "3.4",
            "section_name": "3.4.2. Clustering Constraint",
            "text": "Given that the pairwise cross-entropy loss treats messages as objects to be pushed away or pulled closer, it may not effectively separate the various event clusters or ensure compactness within clusters.\nHence, we further incorporate a new clustering constraint to enhance the distinguishability of message representations.\nThis clustering constraint is composed of two parts: intra-cluster loss and inter-cluster loss.\nThe intra-cluster loss aims to ensure that message representations from the same event are closer.\nSpecifically, we initialize an updatable central feature matrix, mapping real event labels to the row indices of the matrix, where each row represents the central feature representation of a particular event.\nWith the input of message representations, we treat the first incoming message representation as the initial central feature representation of that event category.\nIn subsequent processes, the central feature representation is updated in a weighted manner.\nThis process is formulated as follows:\nwhere  represents a message representation, and  is the retention weight for the central feature.\n and  are the central feature representations before and after updating, respectively.\n is the feature summation operation,  is the center feature matrix, and  is the number of event categories in the current message block.\nAfter updating the center feature matrix, we average the Euclidean distance between all message representations in the batch with their corresponding central feature representations to derive the final loss value.\nThe intra-cluster loss is defined as:\nwhere  calculates the euclidean distance.  denotes the batch size, and  represents message representation  corresponding central feature representation.\nMoreover, the inter-cluster loss aims to push apart the centroids of different event clusters.\nIt is challenging to push away all messages from different clusters for each message, but we can achieve this by pushing apart the centroids of different clusters.\nWe randomly shuffle the order of the central feature matrix and compute its Euclidean distance to the original matrix, utilizing a distance threshold to keep them apart.\nThe inter-cluster loss is defined as:\nWhere  denotes the shuffling operation performed on  once, i.e., random rearrangement of its order,  calculates the euclidean distance, and the  operation selects the larger of two elements.\n represents the distance threshold.\n and  represent the -th row of the original central feature matrix and the -th row of the central feature matrix after shuffling the order.\nThrough the constraints and guidance of inter-cluster and intra-cluster losses, representations of messages within the same cluster become more cohesive, while those of different clusters become more dispersed.\nThe pairwise cross-entropy loss, inter-cluster loss, and intra-cluster loss complement each other.\nThey jointly constrain and guide the model training, thereby achieving higher-quality message representations.\nThe overall loss is defined as:\nwhere , , and  represent the weights of the pairwise cross-entropy loss, intra-cluster loss, and inter-cluster loss, respectively."
        },
        {
            "section_id": "3.5",
            "parent_section_id": "3",
            "section_name": "3.5. Proposed",
            "text": "As depicted in Algorithm 1  ###reference_###, the life cycle of  is divided into three stages: the initial training phase, the detection phase, and the maintenance phase.\nDuring the initial training stage, we train the model using the initial message block (Algorithm 1  ###reference_###, lines 4, 11-16).\nSubsequently, the model performs event detection on message blocks within the window (Algorithm 1  ###reference_###, lines 18-23).\nTo retain existing knowledge while adapting to new data, we perform a weighted update of the parameters in the PLMs within the model before the maintenance phase (Algorithm 1  ###reference_###, line 6-8), then maintain the model by utilizing the message blocks within the window (Algorithm 1  ###reference_###, lines 9, 11-16).\nOnce the model maintenance is completed, it will proceed to detect events in message blocks within the next window.\nAlgorithm 2  ###reference_### details the pairwise message modeling strategy, including the message node sampling and multiple relation mapping (Algorithm 2  ###reference_###, lines 7 to 19).\nIn Algorithm 3  ###reference_###, we provide a detailed explanation of the Multi-relational Prompt-based Pairwise Message Learning Mechanism.\nAfter obtaining message representations (Algorithm 3  ###reference_###, line 3) and their respective similarity (Algorithm 3  ###reference_###, line 4), during the training phase, we construct the pairwise cross-entropy loss based on the similarity of messages and actual event relation labels between them.\nAdditionally, the intra-cluster loss and inter-cluster loss (Algorithm 3  ###reference_###, line 7) are constructed by the central feature matrix (Algorithm 3  ###reference_###, line 6) and message representations.\nThe model is optimized through backpropagation of the total loss (Algorithm 3  ###reference_###, line 8).\nDuring the detection phase, we update the candidate representation set and the similarity set for each message based on the obtained candidate representations of messages and their corresponding similarities. (Algorithm 3  ###reference_###, lines 11, 12).\nSubsequently, we obtain the final representation of each message through the similarity-based representation aggregation approach (Algorithm 4  ###reference_###, lines 1-3).\nFinally, we utilize the final representations of all messages along with their corresponding true event labels to detect events through clustering algorithms (Algorithm 4  ###reference_###, line 5).\nHerein, we employ two distinct clustering methods: the distance-based K-Means (MacQueen, 1967  ###reference_b48###) algorithm and the density-based HDBSCAN (Campello et al., 2013  ###reference_b10###) algorithm.\nHDBSCAN is an enhanced version of the DBSCAN (Ester et al., 1996  ###reference_b19###) algorithm, incorporating concepts from hierarchical clustering.\nThis method does not require pre-specifying the number of clusters.\nInstead, it identifies the optimal clustering outcome by constructing a density hierarchy.\nCompared to the original DBSCAN, HDBSCAN offers greater flexibility in parameter settings, effectively adapts to data from different density regions, and exhibits stronger robustness.\nIn practice, density-based clustering algorithms are more suitable as they do not require pre-setting the number of clusters.\nThis allows them to better adapt to incremental data changes and meet the needs for continuous or dynamic detection."
        },
        {
            "section_id": "3.6",
            "parent_section_id": "3",
            "section_name": "3.6. Time Complexity",
            "text": "The overall time complexity of  is , where  represents the number of messages.\nSpecifically, the computational time for constructing social messages into a multi-relational graph is ; here,  is the total number of edges in the message graph.\nSubsequently, the time complexity of the pairwise message modeling process is , where  is the number of message pairs sampled for each message.\nAdditionally, the computational time for the entire encoding process is , consistent with the time complexity of message modeling.\nThus, the overall time complexity of the model is .\nIt should be noted that, in practical scenarios, the training duration of the model is also influenced by the scale of the selected PLM."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4. Experimental Setup",
            "text": "This section provides a detailed overview of the experimental setup, including dataset selection, comparison baselines, evaluation metrics, and experiment parameter configurations. Specifically, in Section 4.1  ###reference_###, we describe the details of the datasets employed in this study, focusing on the Coco Dataset. The Coco Dataset offers a large-scale, richly annotated dataset intended to advance object detection, segmentation, and captioning tasks. In Section 4.2  ###reference_###, we list and discuss all the baseline methods included in the comparison, aiming to conduct a comprehensive comparative analysis. Furthermore, in Section 4.3  ###reference_###, we present the hardware and software configurations for our experiments. We also offer a comprehensive description of the parameter settings and the implementation approaches for baseline methods, ensuring the reproducibility of our experimental results. Finally, Section 4.4  ###reference_### elaborates on the evaluation metrics adopted for the experiments."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1. Datasets",
            "text": "As shown in Table 2, we evaluate the performance of the model on three publicly available social event datasets: Events2012, Events2018, and Coco Dataset. We test the model\u2019s performance in offline and incremental scenarios using the Events2012 and Events2018 datasets and explore the model\u2019s performance under diverse object recognition conditions using the Coco Dataset. \n\nMoreover, to observe the model\u2019s performance on long-tail distribution issues, we extracted 100 event categories from both the Events2012 and Events2018 datasets. Considering that for the long-tail recognition task, an imbalanced training set alongside balanced validation and test sets should be provided, we select an additional 20 and 30 tweets for each event for the validation and test sets, respectively. \n\nAfter filtering out unavailable and duplicate tweets, the detailed information of these datasets is as described: Events2012 (McMinn et al., 2013). The Events2012 dataset contains 68,841 annotated English tweets covering 503 different event categories, encompassing tweets over a consecutive 29-day period. The Event2012_100 contains 100 events with a total of 15,019 tweets, where the maximal event comprises 2,377 tweets, and the minimally has 55 tweets, with an imbalance ratio of approximately 43. \n\nEvents2018 (Mazoyer et al., 2020). The Events2018 includes 64,516 annotated French tweets covering 257 different event categories, with data spanning over a consecutive 23-day period. The Event2018_100 contains 100 events with a total of 19,944 tweets, where the maximal event comprises 4,189 tweets and the minimally has 27 tweets, an imbalance ratio of approximately 155. \n\nCoco Dataset. The Coco Dataset comprises a diverse collection of images and annotations, covering a wide range of object categories from various contexts and scenes.\n\n###table_2### \nMessages\nEvents\nTimespan\nMax. Event\nMin. Event\nAvg. Event\n\n68841\n503\n29 days\n7133\n1\n137\n\n64516\n257\n23 days\n12567\n1\n251\n\n15019\n100\n-\n2377\n55\n150\n\n19944\n100\n-\n4189\n27\n199"
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2. Baseline",
            "text": "To verify the effectiveness of our proposed method, we compare it with popular social event detection methods in recent years.\n\nThese baseline methods include:\n\nPP-GCN (Peng et al., 2019  ###reference_b57###):  \nPP-GCN is an offline fine-grained social event detection method based on Graph Convolutional Networks (GCN) (Kipf and Welling, 2016  ###reference_b32###).\n\nEventX (Liu et al., 2020a  ###reference_b39###):  \nEventX is a fine-grained event detection method based on community detection suitable for online scenarios.\n\nKPGNN (Cao et al., 2021  ###reference_b11###):  \nKPGNN is a knowledge-preserving incremental social event detection framework based on heterogeneous GNN, leveraging the inductive learning capability of GNN to represent and detect events effectively.\n\nQSGNN (Ren et al., 2022a  ###reference_b65###):  \nQSGNN focuses on open-set social event detection tasks. It extends knowledge from known to unknown by utilizing the best-known samples (i.e., setting stricter constraints in inter-class distances and directional relationships) and reliable knowledge transfer (generating and selecting high-quality pseudo labels).\n\nFinEvent (Peng et al., 2022  ###reference_b60###):  \nFinEvent is an event detection framework that combines reinforcement learning with GNNs, achieving incremental and cross-lingual social event detection. Concurrently, this framework proposes the Deep Reinforcement Learning Guided DBSCAN Model (DRL-DBSCAN). In this paper, the FinEvent baseline, based on the K-means clustering method, is denoted as FinEven, while the FinEvent baseline leveraging DGL-DBSCAN is referred to as FinEven.\n\nAdditionally, we enumerate the methods employed in previous works that utilize word embedding models and pre-trained models for event detection while also proposing new approaches for implementing incremental social event detection through PLMs:\n\nWord2Vec (Mikolov et al., 2013  ###reference_b52###):  \nWord2Vec is a pre-trained word embedding technique. It employs the average of the embeddings of all words within a message to serve as the message embedding.\n\nBERT (Kenton and Toutanova, 2019  ###reference_b30###):  \nBERT is a pre-trained model for natural language processing (NLP) proposed by researchers at Google in 2018. The cornerstone of this model\u2019s innovation lies in its utilization of the encoder architecture from the Transformer model to train context-based word embeddings, incorporating a Masked Language Model (MLM) design. Consistent with previous methodologies, we employ BERT to obtain message representations for clustering directly. BERT-FT achieves streaming event detection by applying fine-tuning to BERT. Given the inapplicability of cross-entropy in open event sets, the encoding process is optimized through online triplet loss and the implementation of proposed clustering constraints. Analogous to standard incremental event detection methodologies, BERT-FT, after its training or maintenance, detects events within message blocks inside the window.\n\nRoBERTa (Liu et al., 2019  ###reference_b43###):  \nRoBERTa is an enhanced version of the BERT model, introduced by the Facebook AI research team in 2019. It is trained using larger datasets, increased batch sizes, and more granular parameter tuning. Compared to BERT, this model adopts a dynamic masking strategy and implements more refined adjustments to hyperparameters. Similarly, we utilize RoBERTa to encode messages for clustering directly. RoBERTa-FT shares the same training approach as BERT-FT, with the distinction between them lying solely in using different PLMs.\n\nBERT-LR:  \nBERT-LR is a variant of a method that fine-tunes BERT within a framework using Low-Rank Adaptation (LoRA) (Hu et al., 2022  ###reference_b28###), an efficient fine-tuning technique for PLMs. The core concept of this approach is to introduce low-rank weights into the parameters of the pre-trained model to balance parameter efficiency and performance during model fine-tuning. RoBERTa-LR is another variant of a method, which, in contrast to BERT-LR, is based on RoBERTa."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "4.3. Experimental Setting and Implementation",
            "text": "In the English dataset Events2012, we select the RoBERTa (RoBERTa-large) (Liu et al., 2019  ###reference_b43###) released by Facebook AI in 2019 as the backbone architecture for the model. In the French dataset Events2018 and the Coco Dataset, we use the multilingual version of the TwHIN-BERT (TwHIN-BERT-large) (Zhang et al., 2023  ###reference_b85###). TwHIN-BERT is a multilingual tweet language model that is trained on 7 billion Tweets from over 100 distinct languages. It is trained with not only text-based self-supervision (e.g., MLM) but also with a social objective based on the rich social engagements within a Twitter Heterogeneous Information Network (TwHIN). During the data preprocessing phase, for each message in the training set, we sample 60 positive and negative samples. For each message in the validation and test sets, 180 samples are sampled. The experimental setup includes setting the number of training epochs to 2, the window size to 3, the learning rate to , and the batch size to 35. During the model maintenance phase, the parameter update weight  is set to 0.4, the inter-cluster loss distance threshold  is defined as 10, and the loss weights , , and  are set to 1, 0.01, and 0.005, respectively. The similarity threshold  for the message feature aggregation stage is set to 0.9, and the number of heads in structured attention mechanism  is set to 2. The embedding and encoding dimensions of the model are consistent with the chosen PLM. In terms of optimizer selection, the entire model is trained using Adam. All experiments are repeated 5 times to ensure the stability of the results, and the mean and standard deviation of the experiments are reported. We implement all models using Python 3.8 and PyTorch 2.0. All experiments are conducted on a 32-core Intel Core i9-13900K@3.80GHz, with 128GB RAM and an NVIDIA GeForce RTX 4090 GPU. For PP-GCN111https://github.com/RingBDStack/PPGCN  ###reference_###, KPGNN222https://github.com/RingBDStack/KPGNN  ###reference_###, QSGNN333https://github.com/RingBDStack/open-set-social-event-detection  ###reference_cial-event-detection### and FinEvent444https://github.com/RingBDStack/FinEvent  ###reference_###, we follow their open-source implementations. We implement EventX with Python 3.7. To ensure fairness in comparison, unless specifically noted, we uniformly apply the K-Means (MacQueen, 1967  ###reference_b48###) clustering algorithm to all baselines, excluding EventX, setting the total number of categories equal to the number of event categories in the real world. Additionally, we train the FinEvent framework from scratch on the French dataset, rather than utilizing its proposed cross-lingual social message representation learning method, \u2018Crlme\u2019. Furthermore, for the DGL-DBSCAN method proposed by FinEvent, we conduct a more comprehensive comparison by further clustering the message representations generated by  through the HDBSCAN (Campello et al., 2013  ###reference_b10###) clustering method, and conduct a comprehensive comparison and analysis of the results."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "4.4. Evaluation Metrics",
            "text": "To evaluate the effectiveness of , we adopt three widely-used metrics to assess the quality of clustering: Normalized Mutual Information (NMI) (Est\u00e9vez et al., 2009  ###reference_b20###), Adjusted Mutual Information (AMI) (Vinh et al., 2009  ###reference_b75###), and the Adjusted Rand Index (ARI) (Vinh et al., 2009  ###reference_b75###).\nThe NMI metric is employed to gauge the clustering quality, primarily focusing on the congruence between our model\u2019s clustering output and the actual ground truth categories:\nwhere  and  represent the predicted label set and the true label set, respectively.  denotes the mutual information between them, and  and  respectively denote their entropies.\nAMI represents an enhancement of the NMI metric.\nThis improvement is achieved by adjusting for the expected mutual information derived from random label assignments.\nTherefore, AMI provides values that are closer to 0 in scenarios where labeling is performed randomly, thereby offering a more accurate assessment of the information shared between clusters:\nwhere  represents the expected value of the mutual information between  and .\nThe Rand Index measures the similarity between two data clustering outcomes.\nIt is particularly used to compare the similarity between algorithmic clustering results and benchmark clusterings.\nThe Rand Index values range from 0 to 1, where 1 indicates identical clustering.\nARI improves upon the original Rand Index by ensuring the expected value of random label assignments is 0 and adjusts the range to be between -1 and 1:\nwhere RI is the original Rand Index, ERI represents the Expected Rand Index, and MaxRI denotes the maximum value in the Rand Index."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5. Results And Discussion",
            "text": "This section primarily revolves around several key questions to empirically evaluate the performance of the  model:\nQ1:\nHow does the performance of the proposed PLM-based method  compare to current mainstream SED methods in both offline and online detection scenarios (Sect 5.1  ###reference_###)?\nQ2:\nHow do different models fare in the low-resource scenario (Section 5.2  ###reference_###)?\nQ3:\nHow do different models address the long-tail distribution issue of social data (Section 5.3  ###reference_###)?\nQ4:\nHow do various PLM-based approaches perform in online scenarios (Section 5.4  ###reference_###)?\nQ5:\nHow does the performance of the  model, based on different PLMs, manifest (Section 5.5  ###reference_###)?\nQ6:\nHow do different components and hyperparameters in  influence overall effectiveness (Section 5.6  ###reference_###, Section 5.7  ###reference_###)?\nQ7:\nHow does the performance of  compare to the strongest baseline in a specific scenario (Section 5.8  ###reference_###)?"
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "5.1. Model Effectiveness",
            "text": "In this section, we compare and analyze  and all baseline methods under offline and online detection scenarios.\nTo ensure consistency in the evaluation,  is compared with baseline methods that employ the K-Means clustering approach.\nIn contrast,  is separately compared with FinEven.\n###table_3### PP-GCN\nEventX\nKPGNN\nQSGNN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n###table_4### PP-GCN\nEventX\nKPGNN\nQSGNN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n###table_5### PP-GCN\nEventX\nKPGNN\nQSGNN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n###table_6### PP-GCN\nEventX\nKPGNN\nQSGNN"
        },
        {
            "section_id": "5.1.1",
            "parent_section_id": "5.1",
            "section_name": "5.1.1. Offline Evaluation",
            "text": "In the offline detection scenario, the training, validation, and test sets share the same events.\nFor the Events2012 and Events2018 datasets, experiments are conducted using data from the first week, with 70% for training, 20% for testing, and 10% for validation.\nAs illustrated in Table 3  ###reference_###, the  outperforms all baseline methods across all metrics (NMI, AMI, ARI).\nCompared to EventX, on the Events2012 dataset,  shows improvements of 26%, 180%, and 710% in NMI, AMI, and ARI, respectively.\nOn the Events2018 dataset,  exhibits enhancements of 64%, 64%, and 9350% in NMI, AMI, and ARI, respectively.\n significantly outperforms EventX on both datasets, especially in terms of ARI, indicating that EventX tends to produce a higher number of clusters than the actual events.\nIn contrast,  demonstrates greater stability.\nCompared with PP-GCN, KPGNN, QSGNN, and FinEven,  shows significant improvements on the Events2012 dataset, with increases of 2%-23% in NMI, 13%-45% in AMI, and 1%-103% in ARI.\nFurthermore, on the Events2018 dataset, improvements include 27% to 55% in NMI, 33% to 87% in AMI, and 170% to 456% in ARI.\nCompared to FinEven on the Events2012 dataset,  exhibits improvements of 1%, 9%, and 43% in NMI, AMI, and ARI, respectively.\nOn the Events2018 dataset, the increases are 18%, 23%, and 56% in NMI, AMI, and ARI, respectively.\nThe superior performance of  compared to GNN-based methods can be attributed to its approach of not relying on explicit structural relations for representation learning, which also enhances its robustness.\nFurthermore, by concurrently leveraging the structure and semantics of messages,  is capable of capturing the interplay between structural and semantic information of messages, thereby facilitating a more accurate determination of event relations between messages.\nConversely, GNN-based models are impacted during the learning process by the presence of noisy edges between different event messages or the absence of effective connections among messages of the same event, thereby affecting the quality of message representation.\nAdditionally, the static initialization of message nodes impedes their ability to dynamically refine the embeddings of message content throughout the training process in the manner exhibited by .\n###table_7### PP-GCN\nEventX\nKPGNN\nQSGNN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n###table_8### PP-GCN\nEventX\nKPGNN\nQSGNN"
        },
        {
            "section_id": "5.1.2",
            "parent_section_id": "5.1",
            "section_name": "5.1.2. Online Evaluation",
            "text": "In the online detection scenario, we utilize the data from the first week as the  to train the initial model, constructing subsequent message blocks daily.\nIt is crucial to note that for offline baselines like PP-GCN, direct adaptation to the online scenario is not feasible.\nWe circumvent this by retraining the model using previous message blocks as the training set and predicting the current message block.\nUnlike offline detection, the  method enters the maintenance phase after predicting the message block within the window.\nDuring the maintenance phase,  initially updates the parameters of the PLMs section through a parameter weighting method, thereby enabling rapid adaptation to new knowledge while preserving historical knowledge.\nSubsequently, the model is maintained using message blocks within the current window.\nAs shown in Tables 4  ###reference_### to 9  ###reference_###,  significantly outperforms all baseline methods in incremental event detection, consistently leading in evaluation metrics across all message blocks.\nOverall, in comparison with EventX, on the Events2012 dataset,  achieves improvements of 35%, 360%, and 480% in terms of NMI, AMI, and ARI, respectively.\nOn the Events2018 dataset,  shows enhancements of 64%, 346%, and 4105% in NMI, AMI, and ARI, respectively.\nThis can be attributed to the fact that EventX relies on community detection whilst neglecting the rich semantic information present in social messages.\nCompared to PP-GCN, KPGNN, QSGNN, and FinEven,  exhibits improvements ranging from 12% to 71%, 12% to 81%, and 21% to 56% in NMI, AMI, and ARI, respectively, on the Events2012 dataset.\nOn the Events2018 dataset,  demonstrates enhancements of 22% to 34%, 22% to 36%, and 55% to 78% in NMI, AMI, and ARI, respectively.\nCompared to FinEven,  achieves improvements of , , and  in terms of NMI, AMI, and ARI, respectively, on the Events2012 dataset.\nOn the Events2018 dataset,  shows enhancements of , , and  in NMI, AMI, and ARI, respectively.\nRegardless of the clustering method employed, our model maintained optimal performance.\nThese improvements further underscore the effectiveness of .\nWithin the model, the multi-relational prompt-based pairwise message learning mechanism acquires more effective message representations by learning the connections and differences between messages in pairs.\nSubsequently, through the similarity-based representation aggregation method, message representations are filtered and aggregated, further enhancing the robustness of message representations.\nAdditionally, converting the structural relations between messages into multi-relational prompts allows the model to better cope with scenarios characterized by a scarcity of structural information.\nFurthermore, at each maintenance stage, the parameters of the PLM within  are updated through a weighted method.\nThis endows with enhanced capabilities for knowledge adaptation, preservation, and expansion, thereby exhibiting stronger generalization abilities and stability when dealing with social data streams.\nAs depicted in Figure 4  ###reference_###, to intuitively compare and further demonstrate the effectiveness of our proposed  model, we select message representations of three message blocks (, , and ) from the Events2012 dataset.\nThese are subsequently subjected to dimensionality reduction and visualization using t-SNE.\nConsidering the long-tail distribution characteristic of social data, our attention is focused on the top seven events by quantity.\nFrom the visualization results obtained from the  (Figure 4  ###reference_### (d), (h), and (l)), it is clearly observable that event clusters exhibit stronger cohesion.\nSimultaneously, the separation between distinct event clusters is also more pronounced.\nThis reflects the importance of the proposed clustering constraint, which effectively enhances the distinguishability of message representations, thereby improving the accuracy of event detection.\n###table_9### PP-GCN\nEventX\nKPGNN\nQSGNN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n###table_10### PP-GCN\nEventX\nKPGNN\nQSGNN\nCLKD"
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "5.2. Performance Evaluation on Low-Resource Language",
            "text": "Low-resource social event detection often faces the challenge of scarce training resources. Recent research introduced the CLKD (Ren et al., 2021  ###reference_b68###) method, utilizing a knowledge distillation-based framework (Gupta et al., 2016  ###reference_b26###) to address this challenge.\n\nSpecifically, CLKD initially employs pre-trained word embedding algorithms (Mikolov et al., 2013  ###reference_b52###; Pennington et al., 2014  ###reference_b62###; Bojanowski et al., 2017  ###reference_b9###) to generate initial embeddings of messages, followed by mapping the data of low-resource languages into the word embedding space of high-resource languages through linear (Lample et al., 2018  ###reference_b33###; Artetxe et al., 2018  ###reference_b5###) or non-linear (Mohiuddin et al., 2020  ###reference_b53###) mapping techniques.\n\nSubsequently, a teacher model trained in a high-resource language (e.g., English) guides the student model in low-resource languages (e.g., Arabic) for learning and training. However, similar to other GNN-based methods, the backbone encoder of CLKD is still GNN.\n\nGNNs learn representations from explicit message graphs, within which some noisy edges are inevitably present. This results in the knowledge learned by the teacher model not being entirely effective and accurate, which may adversely affect the learning process of the student model.\n\nTo validate our hypothesis, we conduct experiments on the Coco Dataset. We choose TwHIN-BERT (TwHIN-BERT-large) as the backbone architecture and implement CLKD by using open-source code555https://github.com/RingBDStack/CLKD  ###reference_###.\n\nFor other baseline methods, we use pre-trained word embedding algorithm666https://github.com/bakrianoo/aravec  ###reference_### to convert messages into initial embeddings before training. To ensure a fair comparison, all methods utilize the K-Means clustering method.\n\nAs shown in Table 10  ###reference_###, outperforms the best results in the baseline by 13.41%, 13.41%, and 10.47% on NMI, AMI, and ARI, respectively. This is attributed to the inherent model advantage of based on Multilingual Pretrained Language Models (MPLMs).\n\nCompared to GNNs, MPLMs can understand and encode different languages. This advantage enables based on MPLMs to obtain better message embeddings when dealing with low-resource data, as well as stronger capabilities for encoding contextual messages.\n\nSecondly, the pairwise learning mechanism, by consistently encoding both the content and structural information of messages, leverages more effective information. This enables the model to obtain robust and stable message representations, even in situations where training resources are limited. \n\n###figure_4### ###table_11### PPGCN KPGNN QSGNN FinEvent MVGAN ETGNN"
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "5.3. Performance Evaluation on Long-tail Recognition Task",
            "text": "In real-world social data, the characteristics of a long-tail distribution are particularly evident.\nThere are few head-dominated event classes, whereas low-frequency tail classes are more numerous.\nThis imbalance in training data makes it difficult for tail events to be correctly classified.\nIn recent research, ETGNN (Ren et al., 2022b  ###reference_b66###) employs the Dempster-Shafer theory (Sentz and Ferson, 2002  ###reference_b70###) to integrate the uncertainty and temporal information of graphs constructed from different perspectives, thereby enhancing the accuracy of event detection.\nFurthermore, building upon ETGNN, the  (Ren et al., 2023  ###reference_b67###) framework is proposed.\nCompared to ETGNN,  introduces uncertainty-guided contrastive learning loss, pushing boundary-ambiguous event classes further away to improve the distinguishability of representations.\nWe also compare with MVGAN, which learns message representations from semantic and temporal views of messages and proposes a hashtag-based multi-view graph attention mechanism to fuse representations.\nWe conduct experiments on two long-tail datasets, Event2012_100 and Event2018_100.\nIt is noteworthy that to accommodate the classification task, an event classifier is additionally incorporated into .\nFor the acquisition of message labels, we first filter out unreliable labels from their corresponding similarity sets based on similarity and then determine their final labels through a voting mechanism.\nIn terms of evaluation metrics, we select Accuracy (ACC) and F1 value (F1), which are widely used in classification tasks.\nAs illustrated in Table 11  ###reference_###, compared with the optimal results among the baseline methods,  exhibits an improvement of 4.34% in ACC and 5.43% in F1, respectively, on Event2012_100.\nOn Event2018_100, the improvements are 19.92% and 16.46%, respectively.\nRecalling the pairwise message modeling process, we sample multiple messages for each message to construct message pairs.\nUtilizing the multi-relational prompt-based pairwise message learning mechanism, each message is learned multiple times from different message pairs.\nThis allows messages of tail events to effectively learn a common representation of similar messages in terms of semantic and structural relations, as well as the subtle differences between different classes of messages.\nAdditionally, the clustering constraint forces the representations of each event class to be as dispersed as possible in the latent space while ensuring that representations of messages within the same class are as close as possible.\nThis further enhances the distinguishability of message representations, thereby enabling the event classifier to predict labels with greater accuracy.\nFurthermore, for each message, by filtering out unreliable labels from its corresponding set of candidate labels based on similarity, the label subsequently obtained through voting from the remaining labels is more reliable.\n###figure_5###"
        },
        {
            "section_id": "5.4",
            "parent_section_id": "5",
            "section_name": "5.4. PLM-based Model for Social Event Detection",
            "text": "In the preceding sections, we comprehensively compare  against the currently dominant social event detection methods based on GNNs across various scenarios.\nTo our knowledge,  is the inaugural model leveraging PLMs to achieve high-quality social event detection in diverse scenarios, including offline, online, low-resource settings, and long-tail distributions.\nTo further explore the performance of Pre-trained Language Models (PLMs) in the social event detection tasks, we design experiments utilizing the pre-trained word embedding technology Word2Vec and two mainstream PLMs, BERT and RoBERTa.\nSpecifically, for Word2Vec, consistent with previous methods, we conduct clustering based on the average embeddings of message content.\nAdditionally, for the original BERT and RoBERTa, we implement two distinct strategies: without fine-tuning and fine-tuning.\nFurthermore, we propose variant models BERT-LR and RoBERTa-LR for  based on BERT and RoBERTa, respectively, which incorporate fine-tuning through LoRA.\nIn practical applications, given the infeasibility of the K-Means clustering method due to its requirement for pre-specifying the number of events, we consistently employed the HDBSCAN clustering method.\nIt is important to note that  is predicated on RoBERTa-base, and similarly, all other models also utilize their respective base versions.\nAs illustrated in Figure 5  ###reference_###, among the methods for directly obtaining message representations from Word2Vec, BERT, and RoBERTa, BERT demonstrates the relatively best performance.\nThis may be attributed to the higher compatibility between the knowledge acquired during the BERT pre-training process and the Event2012 dataset in the absence of model fine-tuning.\nUpon fine-tuning, BERT-FT and RoBERTa-FT exhibit significant enhancements, achieving nearly equivalent model performances.\nNonetheless, a discernible performance gap remains when compared to , attributable to their exclusive reliance on the semantic information of messages while neglecting the abundant structural information within the messages.\nMoreover, we observe that the performances of the variants BERT-LR and RoBERTa-LR fall short of those achieved through global fine-tuning of the models.\nIn online event detection scenarios, models necessitate continual updates to incorporate new knowledge while concurrently sustaining an existing knowledge base.\nUtilizing LoRA to fine-tune models can effectively decrease the number of parameters requiring adjustments during the fine-tuning process, which aids in enhancing the efficiency of model updates and reducing computational costs.\nHowever, this strategy of reducing the volume of trainable parameters may adversely affect the model\u2019s long-term capabilities for knowledge learning, retention, and expansion, consequently leading to a decline in model performance.\nOverall, RPLM\u2019s model performance significantly surpasses that of other methods, further illustrating the efficacy of the multi-relational prompt-based pairwise message learning mechanism.\nOn the other hand, the experiments also validate the feasibility of utilizing PLMs for social event detection tasks."
        },
        {
            "section_id": "5.5",
            "parent_section_id": "5",
            "section_name": "5.5.  with Different PLMs",
            "text": "In investigating the variations in the performance of  under different PLMs, we conduct experiments on the Events2012 dataset utilizing four distinct models: RoBERTa-large (Liu et al., 2019  ###reference_b43###), RoBERTa-base, Twitter-RoBERTa-large (Loureiro et al., 2023  ###reference_b47###), and BERT-base-uncased (Kenton and Toutanova, 2019  ###reference_b30###).\nThe experiments are designed to encompass three dimensions: model scale, pre-training corpora, and model architecture.\nTo ensure consistency in comparison, the HDBSCAN method is utilized for clustering in all experiments.\n###figure_6### As depicted in Figure 6  ###reference_###, compared to  based on RoBERTa-base, the model based on RoBERTa-large exhibits overall improvements of , , and  on the NMI, AMI, and ARI, respectively.\nThis is because, compared to RoBERTa-base, RoBERTa-large possesses a larger model size, more trainable parameters, and a broader training dataset, resulting in superior model performance.\nNaturally, the  based on RoBERTa-large requires greater computational resources and training time.\nThe primary distinction between Twitter-RoBERTa-large and RoBERTa-large lies in the difference in training corpora.\nTwitter-RoBERTa-large is specifically trained on Twitter data, whereas RoBERTa-large undergoes pre-training on a broader spectrum of text data.\nThese two models have the same model scale and have been further fine-tuned on the same dataset, hence their overall performance is essentially consistent.\nWhen contrasting RoBERTa-base with BERT-base-uncased, two distinct types of pre-trained language models, we observe that  based on RoBERTa-base exhibits superior performance.\nIn terms of overall performance, the  based on RoBERTa-base surpasses the  based on BERT-base-uncased by 4.36%, 4.81%, and 12.15% in NMI, AMI, and ARI, respectively.\nThis advantage can be attributed to the pre-training of the RoBERTa-base on a larger dataset and optimized training strategies.\nNotably, even the  based on BERT-base-uncased outperforms the strongest baseline model, FinEvent, leading by 2.81% in NMI, 2.51% in AMI, and 8.75% in ARI."
        },
        {
            "section_id": "5.6",
            "parent_section_id": "5",
            "section_name": "5.6. Ablation Study",
            "text": "In this section, we conduct ablation experiments on four critical components of the  model to demonstrate the indispensability of each component.\nTo ensure consistency of results, all experiments are conducted on the Events2012 dataset and utilize the HDBSCAN clustering method.\nTo investigate the impact of different components on model performance, we sequentially conduct ablation experiments on four parts: Multi-relational Prompt Embedding, Similarity-based Representation Aggregation, Multi-Head Structured Attention, and Clustering Constraint.\nThe results of these experiments are reported in Table 12  ###reference_###.\nMulti-relational Prompt Embedding.\nAs illustrated in \u2018Prompt Embedding\u2019 within the \u2018Pairwise Message Learning\u2019 part of Figure 3  ###reference_###.\nThe task of multi-relational prompt embedding is to transform the structural relations between messages into multi-relational prompt embeddings.\nWhen removing the multi-relational prompt embedding, we directly sample messages from the original message data to form message pairs.\nAs shown in Table 12  ###reference_###, after removing the multi-relational prompt embedding, the model experiences a decrease of , , and  in NMI, AMI, and ARI, respectively.\nSocial messages contain rich structural information.\nAfter removing the multi-relational prompt embedding, due to the absence of multi-relational prompt guidance, the model can only learn representations from the semantics of messages, thereby affecting model performance.\n###table_12### Similarity-based Representation Aggregation. \nWe investigate the variations in model performance under different representation aggregation methods, including similarity-based representation aggregation method, top-k sampling representation aggregation method, and all representation average aggregation methods.\nFor a set of candidate feature representations obtained for each message, under the top-k sampling representation aggregation method, we only sample the top 20 candidate representations with the highest similarities for averaging.\nThis approach has certain limitations.\nA smaller value of  may lead to message representations that are not comprehensive enough.\nConversely, a larger  may include candidate representations extracted from negative sample pairs, which often carry noise and irrelevant information, thereby affecting the quality of the final message representations.\nFor the all-representation average aggregation method, averaging all candidate representations of messages may lead to overly smoothed representations and is also susceptible to noise from candidate representations extracted from negative sample pairs.\nConsequently, among the three methods, it performs the worst.\nIn contrast, the similarity-based representation aggregation approach averages candidate representations of messages with high confidence, effectively filtering out noisy candidate representations extracted from negative sample pairs while preventing message representations from becoming overly smoothed.\nOverall, the similarity-based representation aggregation approach outperforms the top-k sampling representation aggregation by , , and  in NMI, AMI, and ARI, respectively.\nAdditionally, it surpassed the all representation average aggregation method by 3.68%, 3.84%, and 8.16% on NMI, AMI, and ARI, respectively.\nMulti-Head Structured Attention. \nThe role of the multi-head structured attention mechanism is to extract key features from different subspaces of message representations while eliminating irrelevant features and noise to enhance the clarity of the representations.\nWhen the multi-head structured attention mechanism is removed, the resulting candidate message representations may contain noise, affecting the classifier\u2019s accuracy in discriminating message similarity.\nAdditionally, it may also impact the quality of the final message representations.\nConsequently, when the multi-head structured attention mechanism is removed, the values of NMI, AMI, and ARI decrease by , , and , respectively.\nThis reduction substantiates the pivotal role of the attention mechanism in bolstering both representation clarity and classifier precision.\nClustering Constraint.\nOur proposed clustering constraint consists of inter-cluster and intra-cluster loss, which enhances the distinguishability of message representations by optimizing the training process.\nUpon removing the clustering constraint, we find that relying solely on pairwise cross-entropy loss to constrain model training is insufficient.\nThis insufficiency stems from the fact that pairwise cross-entropy loss merely treats messages as objects to be pulled closer or pushed apart, making it difficult to ensure cohesiveness within event clusters and separation between them.\nAfter the removal of the Clustering Constraint, the NMI, AMI, and ARI decreased by , , and , respectively."
        },
        {
            "section_id": "5.7",
            "parent_section_id": "5",
            "section_name": "5.7. Hyperparameter Study",
            "text": "We explore the impact of five hyperparameters on model performance in the online detection scenario.\nThese hyperparameters include Intra-cluster Loss Weight (), Inter-cluster Loss Weight (), Similarity Threshold (), Number of Structured Attention Heads (), and Parameter Update Weight () during the maintenance phase.\nTo ensure experimental consistency, all parameters except the one under study are kept fixed, with their initial values set to: 0.005, 0.01, 0.9, 2, and 0.4, respectively.\nDue to computational resource constraints, all hyperparameter experiments are conducted under the  based on RoBERTa-base.\nThe experimental results are shown in Figure 7  ###reference_###.\n###figure_7### Intra-cluster Loss Weight ().\nWhen examining the effect of different intra-cluster loss weights on model performance, we select four weights: 0.001, 0.005, 0.01, and 0.015. As shown in Figure 7  ###reference_###(a), the model performance remains stable when  is set to 0.001 or 0.005.\nHowever, as  increases to 0.01 or higher, a linear decline in model performance is observed.\nThis suggests that an excessively high intra-cluster loss weight causes the model to overly focus on making representations of the same event type more cohesive, neglecting the importance of separating different event types, thereby negatively impacting the final event detection accuracy.\nInter-cluster Loss Weight ().\nWe also choose 0.001, 0.005, 0.01, and 0.015 as candidate values for the inter-cluster loss weight.\nAs shown in Figure 7  ###reference_###(b), when  is set too high (such as 0.015) or too low (such as 0.001), model performance decreases.\nEspecially when  is set too low, the model lacks sufficient constraint to push apart the centroids of different clusters, resulting in event clusters not being well separated.\nConversely, when  is set too high, the model places more emphasis on separating different event clusters, leading to a slight decrease in the cohesiveness of messages within clusters, thus mildly affecting the model\u2019s performance.\nSimilarity Threshold ().\nIn studying the similarity threshold, we test four thresholds: 0.1, 0.3, 0.6, and 0.9.\nFigure 7  ###reference_###(c) shows that model performance improves with increasing  values.\nThis phenomenon can be attributed to a higher  value implying stricter requirements for message pair similarity.\nConsequently, the selected candidate representations are more likely to be extracted from message pairs within the same cluster.\nThis leads to more stable and robust aggregated message representations.\nIn addition, the choice of a reasonable similarity threshold is also crucial.\nSetting  too high may result in message representations that lack comprehensiveness.\nNumber of Heads in Structured Attention Mechanism ().\nThe experiment examines settings of 1, 2, 3, and 4 attention heads.\nAs illustrated in Figure 7  ###reference_###(d), when there is only one attention head, the model is limited in capturing key message features, resulting in limited message representations and consequently affecting model performance.\nConversely, too many attention heads may introduce noise, leading to a decline in message representation quality and impacting model performance.\nParameter Update Weight during Model Maintenance (). We select 0.2, 0.4, 0.6, and 0.8 as candidate values for the parameter update weight.\nAs shown in Figure 7  ###reference_###(e), the model performs best when  is set to 0.4. When  is set to 0.2, there is a slight decrease in model performance, possibly due to the model retaining too much irrelevant historical information or information unrelated to current events.\nConversely, when  values are too high (such as 0.6 and 0.8), the model retains too little historical knowledge, potentially making it difficult for the model to recognize and understand the connection between current and historical events, leading to a performance decline.\n###figure_8###"
        },
        {
            "section_id": "5.8",
            "parent_section_id": "5",
            "section_name": "5.8. Case Study",
            "text": "To investigate the impact of message structural information on GNN-based methods and proposed , we select  from Events2012 for comparison and analysis with the optimal baseline method FinEvent.\nThe message graph of  contains more noisy edges and isolated nodes, and the structural information is also relatively scarce.\nThis graph comprises 1,399 message nodes, including 92 isolated nodes, across 28 events, and possesses 21,374 edges based on entity relations (with 8,862 edges connecting messages from different events), 83 edges based on user relations (with 63 edges connecting messages from different events), and 623 edges based on hashtag relations (with 196 edges connecting messages from different events).\n###figure_9### Firstly, we extract two pairs of messages from  where FinEvent predicts incorrectly while RPLM predicts accurately.\nFor the \u2018case1\u2019 part in Figure 8  ###reference_###,  and , posted by different users, pertain to positive reactions towards the University of Alabama\u2019s performance in a specific game.\nThe first message provides a broader perspective on the game and mentions a forthcoming challenge, while the second is focused on celebrating a particular scoring moment.\nAlthough  and  describe the same event, they share no common attributes other than belonging to the same time segment.\nUnfortunately, FinEvent utilizes time by transforming it into temporal features combined with message content, resulting in no connections between these two messages in the constructed multi-relational message graph.\nThis results in FinEvent\u2019s inability to aggregate and learn effective information about both from the explicit message graph directly, thereby failing to group them correctly.\nMoreover, in the \u2018Case 2\u2019 part from Figure 8  ###reference_###,  articulates an opinion regarding a player, whereas  delineates a football match.\nThese two messages from different events share the same hashtag \u2018#lfc\u2019 and entity \u2018Shelvey\u2019, which, in turn, leads to their erroneous classification together by FinEvent.\nIn contrast,  does not rely on the explicit structural relations between messages to learn representations.\nIt transforms the structural relations between messages into multi-relational prompt embeddings to complement message content embeddings, thereby enabling the joint utilization of message content and structural information.\nDuring the learning process, by consistently encoding the structural relations and semantic content between messages, it can better learn and understand the complex structural relations between messages and the interaction between structural relations and semantic content.\nIn the absence of common attributes or the presence of misleading information,  can still accurately group them by capturing the semantic and contextual relations between the messages.\nAdditionally, we construct confusion matrices for both RPLM and FinEvent, comparing their predicted labels with the true event labels, thereby observing the accuracy of event detection for each.\nGiven the discrepancy between the number of events obtained from density-based clustering methods and the actual number of events, we uniformly adopt the K-Means method to obtain predicted labels.\nAs shown in Figure 9  ###reference_###, we observe that the clustering results of  (Figure 9  ###reference_###(a)) generally have higher values on the diagonal compared to FinEvent (Figure 9  ###reference_###(b)), and its prediction results are more concentrated.\nThis indicates that the message representations obtained by  have higher accuracy, whereas FinEvent is more disturbed by noise during the feature aggregation process, leading to less clear feature boundaries.\nIt is noteworthy that FinEvent is almost unable to identify events with very few messages (events numbered 17 to 27)."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6. Related Work",
            "text": "This section provides an overview of the existing literature and methodologies relevant to the proposed .\nThe discussion is structured into three categories: Social Event Detection, Pre-trained Language Models, and Prompt Learning."
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "6.1. Social Event Detection",
            "text": "Social event detection represents a pivotal research domain, extensively categorized based on its objectives and application scenarios.\nIn terms of goal-oriented classification, social event detection methodologies are primarily divided into document-pivot (DP) (Cao et al., 2021  ###reference_b11###; Peng et al., 2019  ###reference_b57###; Ren et al., 2022a  ###reference_b65###; Peng et al., 2022  ###reference_b60###; Liu et al., 2020a  ###reference_b39###; Aggarwal and Subbian, 2012  ###reference_b2###; Hu et al., 2017  ###reference_b29###; Zhou and Chen, 2014  ###reference_b88###; Zhang et al., 2007  ###reference_b84###) and feature-pivot (FP) (Fedoryszak et al., 2019  ###reference_b21###; Fung et al., 2005  ###reference_b23###) approaches.\nDP methods focus on clustering social messages by analyzing their interrelations, emphasizing the grouping of relevant messages for a deeper understanding of the development and evolution of societal events.\nThese methods are particularly crucial in analyzing specific domain events such as disasters, stock trading, major sports events, and political activities, as they aid in organizing and comprehending the historical information of these events.\nThe proposed  method in this paper is an exemplar of this category.\nIn contrast, FP methods cluster messages based on the distribution characteristics of social message elements, such as vocabulary and named entities.\nThey focus on the co-occurrence and distribution patterns of message elements to reveal inter-element correlations.\nFurthermore, social event detection methodologies can be categorized based on their application scenarios into offline  (Peng et al., 2019  ###reference_b57###) and online methods (Peng et al., 2021  ###reference_b59###; Cao et al., 2021  ###reference_b11###; Ren et al., 2022a  ###reference_b65###; Peng et al., 2022  ###reference_b60###; Liu et al., 2020a  ###reference_b39###; Hu et al., 2017  ###reference_b29###; Fedoryszak et al., 2019  ###reference_b21###; Zhang et al., 2017  ###reference_b83###; Goswami and Kumar, 2016  ###reference_b24###)\nOffline methods are primarily used for analyzing historical events, whereas online methods continuously monitor social data streams, tracking the real-time development of events.\nOnline methods are crucial for rapid response and real-time event monitoring, especially in situations requiring swift action.\nAdditionally, based on the employed techniques and mechanisms, these methods can be further subdivided into incremental clustering methods (Aggarwal and Subbian, 2012  ###reference_b2###; Hu et al., 2017  ###reference_b29###; Zhang et al., 2007  ###reference_b84###; Ozdikis et al., 2017  ###reference_b56###), community detection methods (Liu et al., 2020a  ###reference_b39###; Fedoryszak et al., 2019  ###reference_b21###; Liu et al., 2018  ###reference_b41###; Yu et al., 2017  ###reference_b82###; Liu et al., 2021  ###reference_b40###, 2020b  ###reference_b44###; Su et al., 2022  ###reference_b72###), and topic modeling methods (Zhou and Chen, 2014  ###reference_b88###; Becker et al., 2011  ###reference_b7###; Cheng et al., 2014  ###reference_b13###; Cordeiro, 2012  ###reference_b14###; Peng et al., 2018  ###reference_b58###; Blei et al., 2003  ###reference_b8###)\nRecently, methods based on Graph Neural Networks (GNNs) (Peng et al., 2021  ###reference_b59###; Cao et al., 2021  ###reference_b11###; Cui et al., 2021  ###reference_b16###; Peng et al., 2019  ###reference_b57###, 2022  ###reference_b60###; Ren et al., 2022a  ###reference_b65###, 2021  ###reference_b68###, b  ###reference_b66###, 2021  ###reference_b68###) have demonstrated potential in the domain of social event detection.\nBy modeling social messages as graphs, these approaches effectively integrate messages\u2019 semantic and structural information, overcoming the limitations of insufficient information utilization within traditional methods.\nFor instance, KPGNN (Cao et al., 2021  ###reference_b11###) converts messages with common attributes into homogeneous message graphs, which achieves incremental social event detection by leveraging the inductive learning capabilities of GNNs.\nFinEvent (Peng et al., 2022  ###reference_b60###) reduces the impact of noisy edges between message nodes by constructing weighted multi-relational graphs and utilizes reinforcement learning to determine optimal relation weights.\nAdditionally, QSGNN (Ren et al., 2022a  ###reference_b65###) employs utilizing the finest known samples and dependable knowledge transfer to extend knowledge from the known to the unknown, markedly diminishing the requirement for manual annotation in model training.\nHowever, GNN-based methods learn representations from explicit message graphs.\nThese graphs may contain noisy edges, and messages from the same event without common attributes lack connections.\nThis leads to GNNs being impacted when learning message representations, an effect that is exacerbated in the presence of sparse structural information.\nMoreover, these methods initialize message embeddings statically before training, preventing the model from dynamically obtaining better message embeddings during the training phases.\nIn recent research, Cao et al. (2024  ###reference_b12###) propose HISEvent, which explores the neighborhood of a message graph by minimizing 1-dimensional Structural Entropy (1D SE) and supplementing edges in the existing message graph between semantically close messages.\nSubsequently, by minimizing 2-dimensional structural entropy (2D SE) for partitioning the message graph, the approach eliminates the cost of manual annotation, achieving unsupervised social event detection.\nIt is imperative to acknowledge that although HISEvent employs a hierarchical approach to mitigate the computational complexity of conventional vanilla greedy 2D SE minimization algorithm (Li et al., 2016  ###reference_b36###) from  to  (where  and  respectively denote the number of nodes within a message graph and that within a manually selected sub-graph), methods based on GNNs or PLMs exhibit a computational complexity of merely .\nGiven that HISEvent is an unsupervised approach, it has not been compared in this paper.\nIn addition, Our proposed \u2018pairwise\u2019 approach significantly differs from that introduced in PPGCN (Peng et al., 2019  ###reference_b57###).\nIn PPGCN, after obtaining representations, the pairwise sampling method selects a positive and a negative sample for each message, addressing the challenge of numerous event types with few messages per event.\nUnlike PCGNN, our pairwise message modeling strategy is implemented during the data preprocessing stage to preserve structural relations rather than only focusing on inter or intra-event relations."
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "6.2. Pre-trained Language Models",
            "text": "In recent years, Pre-trained Language Models (PLMs) (Liu et al., 2019  ###reference_b43###; Zhang et al., 2023  ###reference_b85###; Loureiro et al., 2023  ###reference_b47###; Kenton and Toutanova, 2019  ###reference_b30###; Radford et al., 2018  ###reference_b64###; Lewis et al., 2020  ###reference_b35###) have made significant strides in the field of Natural Language Processing (NLP).\nThese models have learned rich language representations by undergoing pre-training on large-scale text corpora.\nWhen applied to downstream tasks, fine-tuned PLMs can adapt to a variety of application scenarios, including, but not limited to, text classification (Kenton and Toutanova, 2019  ###reference_b30###; Sun et al., 2019  ###reference_b73###), question answering (Shu et al., 2022  ###reference_b71###; Wei et al., 2023  ###reference_b77###), language generation (Radford et al., 2018  ###reference_b64###), and text summarization (Lewis et al., 2020  ###reference_b35###).\nIn processing social data, PLMs have demonstrated high adaptability to informal texts and multiple languages (Zhang et al., 2023  ###reference_b85###; Loureiro et al., 2023  ###reference_b47###), effectively handling texts containing internet-specific abbreviations, emojis, or slang.\nThis has extended the application of PLMs to social event detection tasks.\nHowever, previous social event detection approaches often treated PLMs merely as a tool for word embedding, extracting message embeddings through PLMs and then applying clustering algorithms for event detection.\nThis overlooks the capabilities of PLMs to learn, retain, and expand knowledge, leading to suboptimal performance in the complex environment of social media data streams.\nIn contrast to prior studies, we leverage PLM as the backbone architecture and fine-tune it during the initial training and maintenance phases, thereby achieving high-quality detection of social events."
        },
        {
            "section_id": "6.3",
            "parent_section_id": "6",
            "section_name": "6.3. Prompt Learning",
            "text": "Prompt learning (Lester et al., 2021  ###reference_b34###; Liu et al., 2023  ###reference_b42###), as an emerging technology in NLP, has garnered widespread attention and has been applied to a variety of tasks, including recommendation systems (Zhang and Wang, 2023  ###reference_b86###), aspect sentiment triplet extraction (Peng et al., 2024  ###reference_b61###), text generation (Li et al., 2022b  ###reference_b37###), question\nanswering (Petroni et al., 2019  ###reference_b63###), etc.\nThe core of prompt learning lies in the design of prompt templates, which are typically categorized into discrete templates, continuous templates, and hybrid templates.\nDiscrete templates employ explicit natural language terms, making them direct, easy to understand, and implement, but they also rely on human experience.\nFor instance, Petroni et al. (2019  ###reference_b63###) design specific sentence structures as prompts to query the PLMs about their knowledge of certain facts.\nContrary to discrete templates, continuous templates do not directly carry semantic information but consist of a set of learnable embedding vectors (Gu et al., 2022  ###reference_b25###; Ding et al., 2022  ###reference_b18###).\nBy continuously optimizing these prompts throughout the training process, the model is better adapted to the task.\nIn our proposed , the multi-relational prompt embeddings are a type of continuous prompt template.\nHybrid templates combine discrete and continuous templates, aiming to leverage human expertise and model auto-optimization to achieve superior performance and broader adaptability (Zhang and Wang, 2023  ###reference_b86###).\nUnlike traditional prompt learning, to ensure that  can adapt to dynamic social streams, we utilize multi-relation prompts and fine-tune the model\u2019s parameters during the training or maintenance phases."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7. Conclusion",
            "text": "This paper studies relational prompt-based pre-trained language models for Social Event Detection. A pairwise message modeling strategy is proposed to address the issues of missing and noisy edges in social message graphs. A multi-relational prompt-based pairwise message learning mechanism is presented to simultaneously leverage the content and structural information of messages, learning more robust and stable message representations. A clustering constraint is designed to optimize the training process, enhancing message representations\u2019 distinguishability. The conducted experiments on three real-world social media datasets demonstrate that achieves SOTA performance in offline, online, low-resource, and long-tail distribution social event detection tasks. In the future, we aim to explore how can be extended to semi-supervised or unsupervised social event detection tasks while also investigating ways to optimize the model architecture further to achieve more efficient detection."
        }
    ],
    "url": "http://arxiv.org/html/2404.08263v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.1",
            "2.2"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3",
            "3.3.1",
            "3.3.2",
            "3.3.3",
            "3.4",
            "3.4.1",
            "3.4.2",
            "3.5",
            "3.6"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.2",
            "4.3",
            "4.4",
            "5",
            "5.1",
            "5.1.1",
            "5.1.2",
            "5.2",
            "5.3",
            "5.4",
            "5.5",
            "5.6",
            "5.7",
            "5.8"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "1",
            "3.1",
            "5",
            "5.1.1",
            "5.1.2",
            "5.2",
            "5.3",
            "5.4",
            "5.5",
            "5.6",
            "5.7"
        ]
    },
    "research_context": {
        "paper_id": "2404.08263v1",
        "paper_title": "Relational Prompt-based Pre-trained Language Models for Social Event Detection",
        "research_background": "### Motivation:\nThe paper addresses key challenges in Social Event Detection (SED) from social media streams, such as the incompleteness, ambiguity, and streaming nature of social data. Traditional SED methods and recent Graph Neural Network (GNN)-based methods face limitations including issues of missing and noisy edges in message graphs and inadequate node representation initialization from static pre-trained word embeddings. These issues hinder the effective and accurate detection of social events.\n\n### Research Problem:\nThe primary research problem this paper aims to solve is to develop a more effective approach for social event detection by overcoming the limitations of existing GNN-based methods. Specifically, the paper seeks to address: \n1. The presence of missing and noisy edges in message graphs, which impacts the structural representation and relationship among messages.\n2. The static initialization of node embeddings, which prevents the dynamic and contextual learning of semantic information.\n3. The insufficient constraints to ensure the clustering quality, with messages merely being pulled closer or pushed apart without considering their inter-cluster separations and intra-cluster cohesion.\n\n### Relevant Prior Work:\n1. **Early Text-based Methods**: Initial methods focused on using text content (Amiri and Daume III, 2016; Morabia et al., 2019; etc.) or attributes extracted from texts (Feng et al., 2015; Xie et al., 2016) for event categorization, but these did not adequately address event detection in social streams.\n2. **GNN-based Methods**: \n   - **Integration of Semantic and Structural Information**: Recent approaches constructed social messages into graphs to encapsulate both semantic and structural data using GNNs, thereby improving SED performance (Peng et al., 2019; Cao et al., 2021; Cui et al., 2021).\n   - **Handling Heterogeneous Information**: Some methods created Heterogeneous Information Networks (HIN) for better representation and clustering of social messages (Peng et al., 2019; Cao et al., 2021).\n   - **Multi-relational Graphs**: Approaches like Peng et al. (2022) employed multi-relational graphs to assign optimal thresholds for various relations using reinforcement learning.\n3. **Limitations of GNN-based Methods**:\n   - **Missing and Noisy Edges**: Graphs constructed with common attributes faced issues of missing and noisy edges, leading to incomplete or noisy node connections and representations (Liu et al., 2022).\n   - **Static Embeddings**: The use of static pre-trained word embeddings hindered dynamic contextual embedding updates during learning phases (Yang et al., 2021).\n   - **Separated Usage of Relations and Content**: Conventional GNN approaches treated relations and message content separately, thus not fully capturing the complex interactions (Ding et al., 2023).\n\nBy identifying these gaps, the paper proposes a novel Relational prompt-based Pre-trained Language Model (PLM) for SED that avoids reliance on explicit structural relations, thereby solving issues related to message node connections, dynamic embedding of message content, and ensuring stronger clustering through constrained learning.",
        "methodology": "The proposed method detailed in the methodology section of the paper revolves around a novel approach to social event detection using relational prompt-based pre-trained language models. Here's an outline of the key components and innovations:\n\n1. **Lifecycle of the Model (Section 3.1)**:\n   - This section presumably lays out the end-to-end process of the model's development, training, and inference stages, providing a comprehensive understanding of how the model operates from input reception to output generation.\n\n2. **Pairwise Message Modeling Strategy (Section 3.2)**:\n   - To capitalize on the structural and semantic properties of messages, the authors propose a Pairwise Message Modeling Strategy. This likely involves crafting pairs of messages to better capture relational and contextual information which could be crucial for accurately detecting social events.\n\n3. **Multi-relational Prompt-based Pairwise Message Learning Mechanism (Section 3.3)**:\n   - Building on the pairwise modeling strategy, this section introduces a learning mechanism that employs multiple relations and prompt-based techniques. This mechanism is designed to enhance the model's ability to understand and incorporate relational information from message pairs, effectively improving its event detection capability.\n\n4. **Loss Function (Section 3.4)**:\n   - Specific details about the loss function used for training the model are discussed here. The loss function is critical as it guides the optimization process, ensuring that the model learns to distinguish between various social events accurately.\n\n5. **Overall Algorithmic Process (Section 3.5)**:\n   - In this section, the authors provide a step-by-step explanation of the algorithmic process underpinning the method. This would include the sequence of operations and the flow of data through the model, giving readers practical insights into its implementation.\n\n6. **Time Complexity Analysis (Section 3.6)**:\n   - Finally, the paper analyzes the time complexity of the proposed method. This analysis sheds light on the computational efficiency and scalability of the model, which are essential considerations for practical deployment in real-world scenarios.\n\nBy combining these components, the methodology introduces innovations in leveraging relational information and prompt-based techniques through a structured, pairwise approach, ultimately enhancing the detection of social events in textual data.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n#### Datasets\nThe datasets employed in this study include a wide range of social event detection corpora. These datasets are selected to ensure the robustness and generalizability of our model across different social event detection tasks. The details of each dataset, including the sources, the number of instances, and the specific types of social events they encompass, are meticulously documented.\n\n#### Baselines\nWe compare our Relational Prompt-based Pre-trained Language Models against several well-established baseline methods. These baselines are chosen to represent the state-of-the-art in social event detection, providing a comprehensive benchmark for evaluating our proposed approach. The baselines include traditional machine learning models, such as SVM and Random Forests, as well as more advanced deep learning-based models, including various configurations of neural networks and pre-trained language models.\n\n#### Hardware and Software Configurations\nOur experiments are conducted on a high-performance computing cluster equipped with multiple NVIDIA GPUs to facilitate efficient training and inference. The software stack primarily includes the latest versions of PyTorch and TensorFlow, alongside other supporting libraries for data processing and model evaluation.\n\n#### Parameter Settings and Implementation\nWe ensure the reproducibility of our experimental results by providing a thorough description of the parameter settings for both our model and the baseline methods. For instance, the learning rates, batch sizes, and number of epochs are specified. Additionally, the implementation details, such as data preprocessing steps, model architectures, and training schedules, are comprehensively described.\n\n#### Evaluation Metrics\nTo rigorously evaluate the performance of our model and the baselines, we adopt several standard evaluation metrics, including precision, recall, F1-score, and accuracy. These metrics provide a holistic view of the effectiveness of the models in detecting social events from the given datasets.\n\n### Main Experimental Results\nThe results of our main experiment demonstrate the superior performance of the Relational Prompt-based Pre-trained Language Models over the baseline methods. Our model consistently achieves higher precision, recall, F1-score, and accuracy across all datasets, indicating its robust effectiveness in social event detection tasks. The detailed results, including performance tables and comparative analyses, are presented to underline the advantages of our approach."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To demonstrate the indispensability of each component within the  model and validate the impact of specific techniques and designs on social event detection performance.",
            "experiment_process": "Ablation experiments were conducted on four critical components of the  model: Multi-relational Prompt Embedding, Similarity-based Representation Aggregation, Multi-Head Structured Attention, and Clustering Constraint. The experiments were performed on the Events2012 dataset using the HDBSCAN clustering method. The process involved removing each component sequentially and observing changes in model performance.",
            "result_discussion": "Removing the Multi-relational Prompt Embedding resulted in decreased performance due to the model's inability to utilize structural information. The similarity-based representation aggregation method outperformed top-k sampling and all-representation average aggregation methods, demonstrating the importance of this approach in filtering noise. The absence of the Multi-Head Structured Attention mechanism led to reduced clarity and classifier precision. Removing the Clustering Constraint decreased the model's effectiveness in distinguishing between event clusters, highlighting the necessity of this component.",
            "ablation_id": "2404.08263v1.No1"
        },
        {
            "research_objective": "To explore the impact of key hyperparameters on model performance in an online detection scenario.",
            "experiment_process": "Five hyperparameters were tested: Intra-cluster Loss Weight (), Inter-cluster Loss Weight (), Similarity Threshold (), Number of Structured Attention Heads (), and Parameter Update Weight (). Each parameter was varied while others were kept fixed at their initial values (0.005, 0.01, 0.9, 2, and 0.4, respectively). Hyperparameter tuning was conducted using the  model based on RoBERTa-base.",
            "result_discussion": "Optimal settings were found to be an intra-cluster loss weight of 0.005 and an inter-cluster loss weight of 0.01. Increasing the similarity threshold improved performance up to a point, suggesting a judicious balance is required. Two attention heads yielded the best results, capturing key features without introducing excessive noise. Performance peaked with a parameter update weight of 0.4, balancing the retention of historical information and the incorporation of new knowledge.",
            "ablation_id": "2404.08263v1.No2"
        }
    ]
}