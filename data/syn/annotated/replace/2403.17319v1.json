{
    "title": "JMultiWOZ: A Large-Scale Japanese Multi-Domain Task-Oriented Dialogue Dataset",
    "abstract": "Dialogue datasets are crucial for deep learning-based task-oriented dialogue system research. While numerous English language multi-domain task-oriented dialogue datasets have been developed and contributed to significant advancements in task-oriented dialogue systems, such a dataset does not exist in Japanese, and research in this area is limited compared to that in English. In this study, towards the advancement of research and development of task-oriented dialogue systems in Japanese, we constructed JGlobalWOZ, the first Japanese language large-scale multi-domain task-oriented dialogue dataset. Using JGlobalWOZ, we evaluated the dialogue state tracking and response generation capabilities of the state-of-the-art methods on the existing major English benchmark dataset GlobalWOZ2.2 and the latest large language model (LLM)-based methods. Our evaluation results demonstrated that JGlobalWOZ provides a benchmark that is on par with GlobalWOZ2.2. In addition, through evaluation experiments of interactive dialogues with the models and human participants, we identified limitations in the task completion capabilities of LLMs in Japanese.\n\n\n\nKeywords:\u2009Multi-domain task-oriented dialogue, Dialogue state tracking, Response generation",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1.   Introduction",
            "text": "Methods based on deep learning have been actively introduced in the research of task-oriented dialogue systems (Gao et al., 2018  ###reference_b9###; Zhang et al., 2020b  ###reference_b35###), which have greatly improved their performance on task completion (Zhang et al., 2020a  ###reference_b34###; Hosseini-Asl et al., 2020  ###reference_b13###; He et al., 2022  ###reference_b11###). Task-oriented dialogue datasets are essential for developing these neural models, and a number of single-domain task-oriented dialogue datasets in English have been developed previously (Henderson et al., 2014  ###reference_b12###; Wen et al., 2017  ###reference_b32###; Eric et al., 2017  ###reference_b8###; Shah et al., 2018  ###reference_b29###). \n\nGlobalWOZ is a large-scale dialogue corpus designed to handle more complex multi-domain dialogues. It includes dialogues spanning seven domains, namely, tourist attractions, hotels, restaurants, taxis, trains, police stations, and hospitals, and led to the development of subsequent dialogue models. Following the introduction of GlobalWOZ, numerous large-scale dialogue datasets have been constructed (Rastogi et al., 2020  ###reference_b28###; Mosig et al., 2020  ###reference_b23###; Chen et al., 2021  ###reference_b3###), and task-oriented dialogue models using these as benchmarks have been actively researched. CrossWOZ (Zhu et al., 2020  ###reference_b36###) and other large-scale multi-domain dialogue datasets have been introduced for Chinese as well (Quan et al., 2020  ###reference_b25###; Dai et al., 2022  ###reference_b4###), promoting research on Chinese task-oriented dialogue systems.\n\n###figure_1### However, due to the high cost of constructing task-oriented dialogue corpora, there are fewer multi-domain task-oriented dialogue corpora in other languages compared to English and Chinese (Hung et al., 2022  ###reference_b16###). In this study, we focus on Japanese, in which the research and development of task-oriented dialogue models based on deep learning have been limited thus far. Toward the research and development of task-oriented dialogue systems in Japanese, we have constructed the Japanese Multi-Domain Wizard of Oz (JMultiWOZ), the first Japanese multi-domain task-oriented dialogue dataset.111Our data and code are publicly available at https://github.com/nu-dialogue/jmultiwoz  ###reference_### JMultiWOZ contains a total of 4,246 conversations spanning six travel-related domains (tourist attractions, accommodation, restaurants, shopping facilities, taxis, and weather). An example of a dialogue is shown in Figure 1  ###reference_###. JMultiWOZ provides the dialogue state at each turn and the database of each domain for implementing and benchmarking task-oriented dialogue models.\n\nIn this paper, we outline the procedure for constructing the JMultiWOZ dataset and introduce its statistics. We evaluated the dataset on the two main tasks of task-oriented dialogue enabled by JMultiWOZ, i.e., dialogue state tracking (DST) and response generation (RG), using the state-of-the-art (SOTA) methods (Bang et al., 2023  ###reference_b1###) and the latest LLM-based methods (Hude\u010dek and Dusek, 2023  ###reference_b15###). For further validation, the end-to-end dialogue capability of these dialogue models was evaluated by interactions with human participants. The contributions of this study are threefold: We constructed JMultiWOZ, the first large-scale Japanese multi-domain task-oriented dialogue dataset. We evaluated the dataset on DST and RG tasks using existing SOTA models and the latest LLMs, and demonstrated that JMultiWOZ can provide a Japanese benchmark of complexity comparable to that of the major English dataset GlobalWOZ. We conducted a human evaluation experiment, which showed that, even with the latest LLMs, there remain challenges concerning the capabilities of task-oriented dialogue in Japanese."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2.   Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1.   Task-Oriented Dialogue Corpora",
            "text": "Many task-oriented dialogue corpora have been created in English thus far. Previously, single-domain dialogues, where only one domain appears in a dialogue, were predominant, such as WOZ2.0 (Wen et al., 2017  ###reference_b32###), Frames (El Asri et al., 2017  ###reference_b6###), and KVRET (Eric et al., 2017  ###reference_b8###). All of these dialogues were conducted using the Wizard of Oz (WOZ) method (Kelley, 1984  ###reference_b18###), with a human user and another person acting as the system (i.e., the wizard). There are also human-to-machine (Henderson et al., 2014  ###reference_b12###) and machine-to-machine dialogue corpora simulated between machines (Shah et al., 2018  ###reference_b29###). Multi-domain dialogue corpora, in which multiple domains appear in a single dialogue, are being increasingly constructed to address more complex requirements. GlobalWOZ is a representative example, being a large-scale corpus with over 10,000 dialogues covering seven travel-related domains. Other existing large-scale multi-domain dialogue corpora include Schema-Guided Dialogue (Rastogi et al., 2020  ###reference_b28###), STAR (Mosig et al., 2020  ###reference_b23###), and ABCD (Chen et al., 2021  ###reference_b3###).\nThere are also several large-scale multi-domain dialogue corpora in Chinese. CrossWOZ (Zhu et al., 2020  ###reference_b36###) is the first multi-domain dialogue corpus in Chinese and contains about 6,000 travel-related dialogues. The RiSAWOZ corpus (Quan et al., 2020  ###reference_b25###) introduced more domains and dialogues, and subsequently, CGoDial (Dai et al., 2022  ###reference_b4###) was devised as an extension of other dialogue corpora including RiSAWOZ. In addition, BiTOD (Lin et al., 2021b  ###reference_b20###) was constructed to develop bilingual multi-domain dialogue models in both English and Chinese.\nConstructing task-oriented dialogue corpora is generally costly, and there are few large-scale multi-domain datasets outside of English and Chinese (Hung et al., 2022  ###reference_b16###). SCUD (Hayashibe, 2022  ###reference_b10###) is a Japanese single-domain task-oriented dialogue corpus related to accommodation search but it only contains 210 dialogues."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2.   Translation-based Corpora",
            "text": "Given the high cost of constructing task-oriented dialogue corpora, efforts are being made to construct dialogue corpora in other languages by translating readily available English corpora. For instance, GlobalWOZ (Ding et al., 2022  ###reference_b5###) is a dialogue corpus that expanded GlobalWOZ into 17 languages through machine translation. Among the 17 languages, high quality has been achieved in three languages (Chinese, Spanish, and Indonesian) through post-editing by professional translators for some dialogues in the test set. However, the quality is not guaranteed for other languages, including Japanese. Other corpora constructed from machine translation and manual post-editing of GlobalWOZ include AllWOZ (Zuo et al., 2021  ###reference_b37###) and Multi2WOZ (Hung et al., 2022  ###reference_b16###), neither of which includes Japanese. Problems due to poor translations have been reported in translation-based dialogue corpora (e.g., \u2018translationese,\u2019 lack of cultural adaptation) (Majewska et al., 2023  ###reference_b22###), which may prevent the models\u2019 practical performance from being evaluated accurately (Hu et al., 2023  ###reference_b14###). Therefore, this study aims to construct a realistic dataset in the Japanese context by collecting dialogues from scratch."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3.   Data Collection",
            "text": "GlobalWOZ is a corpus containing dialogues of travelers planning a trip to one of eleven cities around the world, including New York, Paris, Mumbai, and Sydney, while collecting tourist information. The eight domains covered are tourist attractions, accommodations, restaurants, transportation, shopping, nightlife, events, and weather. Using a wizard-of-oz approach, each dialogue was conducted by two human interlocutors, one as a traveler (user) and the other as an information provider (wizard).\n\nThe following sections describe the five steps of constructing this corpus: (1) ontology definition, (2) construction of the backend database that the wizard uses to obtain travel information, (3) design and creation of user goals, (4) dialogue collection, and (5) annotation of the full dialogue state.\n\nThe user aims to properly convey the informable slots in the user goal to the wizard, obtain information about the requestable slots from the wizard, and in some cases, reserve the entity with the conditions of booking slots. Instead of a user goal formatted as in Table 2  ###reference_###, users comprehend the goal by reading template sentences that describe each slot. Template sentences that explain the user goal in Table 2  ###reference_### are shown in Table 3  ###reference_###.\n\nThe wizard searches for entities in the backend database that match the constraints conveyed by the user and provides the user with information about the found entities. The wizard\u2019s web UI (Figure 2  ###reference_###) has interfaces for (A) searching for entities based on the user\u2019s criteria and (B) checking detailed information or making reservations for the found entities in addition to (C) the panel for chatting with the user. The database search query (DB query) input by the wizard in each turn is recorded as part of the dialogue state (details can be found in Section 3.5  ###reference_###).\n\nSome studies (Eric et al., 2020  ###reference_b7###; Zang et al., 2020  ###reference_b33###) have reported issues such as inconsistencies in the slot value notation within the dialogue state (e.g., the value \u201c18:00\u201d for the time slot appears in several ways: \u201c1800\u201d, \u201c0600pm\u201d, and \u201c6 PM\u201d) in existing corpora. Such inconsistencies can confuse or underestimate the capabilities of the dialogue model, making it impossible to provide an appropriate benchmark. Therefore, input values were selected from dropdown menus to prevent wizards from manually entering DB queries. Additionally, to enhance the quality of the wizard, 3-5 practice dialogues were conducted beforehand. The workers received feedback from the authors on errors. Only workers who no longer had issues after repeated feedback participated in the actual dialogues.\n\nThrough the above procedure, a total of 5,125 dialogues were collected. Dialogues that would be considered noise in the dataset were then revised or excluded through the following two procedures:\n\nAt the end of each dialogue, workers completed questionnaires to report any issues that occurred during the dialogue. We manually checked dialogues with reported issues and removed those containing major errors, such as when workers misinterpreted the user goal.\n\nWe deleted dialogues in which the DB query at the end of the dialogue did not match the informable slots in the user goal.\n\nThe resulting corpus after this modification contained a total of 4,850 dialogues. Here, the dev and test sets consist of 350 dialogues each, randomly selected from the 4,850 dialogues, and the remaining 4,150 dialogues are used as the train set (refer to Table 4  ###reference_### for the statistics of each set)."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1.   Definition of Ontology",
            "text": "In a task-oriented dialogue, the ontology represents the structure of the backend database. Specifically, it defines attributes such as name, address, and phone number for each entity in the database. An entity is a unit of record in the database, such as a specific tourist attraction or restaurant, and its attributes are called slots. In this study, the ontology of each domain was defined with reference to existing studies Budzianowski et al. (2018  ###reference_b2###); Zhu et al. (2020  ###reference_b36###) while considering the characteristics of Japanese culture so as not to be unnatural. For instance, dialogues related to the police and hospital domains that exist in GlobalWOZ are rarely encountered in Japanese dialogue travel centers. In view of this, we eliminated police and hospital domains, and instead introduced more culturally appropriate domains such as shopping and weather. The ontology for all domains is shown in Table 1  ###reference_###."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2.   Construction of Backend Database",
            "text": "Based on the ontology, a backend database that the wizard uses to retrieve entities and travel information during the dialogue was constructed for each domain. To enhance the realism of the dialogue using real entities, lists of facilities publicly available from governments and municipalities of various cities were used to construct databases for tourist spots, accommodations, restaurants, shopping facilities, and taxis. From this list, only facilities that have publicly accessible websites were selected to be included in the database, and information for all slots of each entity was manually obtained from the website. For the taxi domain, the unit of entities was set as taxi companies.\nThe final number of entities contained in the database for each domain were as follows: 447 for tourist spots, 884 for accommodations, 952 for restaurants, 445 for shopping facilities, and 167 for taxis. For the construction of the weather domain database, the unit of entity was set as the date, and 365 days\u2019 worth of weather information was artificially created for each city.\n###table_1### ###figure_2###"
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "3.3.   Design of User Goal",
            "text": "A user goal is the objective the user aims to achieve through the dialogue with the wizard, and one goal is set for each dialogue. An example of a user goal is shown in Table 2  ###reference_###. Each goal covers one or more domains, and each domain in the goal consists of one or more informable slots, which are the search criteria for the entity the user is looking for, such as the desired budget or destination, and one or more requestable slots, which are the attribute information of the entity the user needs to obtain, such as phone numbers or addresses. In domains where reservations are commonly made in real life (for instance, after finding the desired restaurant or accommodation, reservations are often made with conditions such as the date and number of people), several conditions for reservation are randomly added as book slots.\nThe composition and diversity of user goals are directly linked to the naturalness and diversity of the dialogues in the corpus. To introduce diversity in dialogue length and complexity, 1-3 domains are randomly selected for each user goal. Next, slots to be included in each domain are randomly chosen. From the ontology defined in Section 3.1  ###reference_###, 2-7 slots, including informable, requestable, and possibly bookable slots, are selected for each domain. The informable slot \u201ccity\u201d, which indicates the user\u2019s tourist destination city, is shared among the domains within a user goal. To enhance the realism of the dialogue, following (Budzianowski et al., 2018  ###reference_b2###), some goals were set with tasks to change the value of an informable slot and/or book slot amid the dialogue (for instance, change the originally communicated reservation condition of 5 p.m. to 6 p.m.). Ahead of subsequent dialogue collection, a total of 5,000 unique user goals were created."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "3.4.   Dialogue Collection",
            "text": "Dialogues were collected using a backend database and randomly generated dialogue goals. Based on the dialogue collection platform222https://github.com/thu-coai/CrossWOZ  ###reference_### of (Zhu et al., 2020  ###reference_b36###), the dialogue web UIs for the user and wizard were implemented. The web UI used by the wizard is depicted in Figure 2  ###reference_###. Crowd workers for both the user and wizard roles were recruited via Lancers333https://www.lancers.jp  ###reference_www.lancers.jp###, a major Japanese crowdsourcing service. Only those who consented to the publication of data obtained from the dialogue collection participated.\nThe workers read the instructions in the dialogue manual, watched a demonstration video that explained how to operate the web UI, and learned the workflow before participating in the dialogues. To ensure diverse user utterances, each user could participate in a maximum of 100 dialogues, and they could engage with the same wizard for a maximum of 20 dialogues. Meanwhile, because it is preferable for the wizard to behave consistently, there was no limit to the number of dialogues, and the same wizard was allowed to engage in conversations repeatedly. In the end, 65 users and 18 operators participated in the dialogue collection. The tasks of the user and wizard, and the quality control for the wizards are explained in detail in the following paragraphs.\nThe user aims to properly convey the informable slots in the user goal to the wizard, obtain information about the requestable slots from the wizard, and in some cases, reserve the entity with the conditions of booking slots. Instead of a user goal formatted as in Table 2  ###reference_###  ###reference_###, users comprehend the goal by reading template sentences that describe each slot. Template sentences that explain the user goal in Table 2  ###reference_###  ###reference_### are shown in Table 3  ###reference_###  ###reference_###.\nThe wizard searches for entities in the backend database that match the constraints conveyed by the user and provides the user with information about the found entities. The wizard\u2019s web UI (Figure 2  ###reference_###  ###reference_###) has interfaces for (A) searching for entities based on the user\u2019s criteria and (B) checking detailed information or making reservations for the found entities in addition to (C) the panel for chatting with the user. The database search query (DB query) input by the wizard in each turn is recorded as part of the dialogue state (details can be found in Section 3.5  ###reference_###  ###reference_###).\nSome studies (Eric et al., 2020  ###reference_b7###  ###reference_b7###; Zang et al., 2020  ###reference_b33###  ###reference_b33###) have reported issues such as inconsistencies in the slot value notation within the dialogue state (e.g., the value \u201c18:00\u201d for the time slot appears in several ways: \u201c1800\u201d, \u201c0600pm\u201d, and \u201c6 PM\u201d) in existing corpora. Such inconsistencies can confuse or underestimate the capabilities of the dialogue model, making it impossible to provide an appropriate benchmark. Therefore, input values were selected from dropdown menus to prevent wizards from manually entering DB queries. Additionally, to enhance the quality of the wizard, 3-5 practice dialogues were conducted beforehand. The workers received feedback from the authors on errors. Only workers who no longer had issues after repeated feedback participated in the actual dialogues.\nThrough the above procedure, a total of 4,508 dialogues were collected. Dialogues that would be considered noise in the dataset were then revised or excluded through the following two procedures:\nAt the end of each dialogue, workers completed questionnaires to report any issues that occurred during the dialogue. We manually checked dialogues with reported issues and removed those containing major errors, such as when workers misinterpreted the user goal.\nWe deleted dialogues in which the DB query at the end of the dialogue did not match the informable slots in the user goal.\nThe resulting corpus after this modification contained a total of 4,246 dialogues, Here, the dev and test sets consist of 300 dialogues each, randomly selected from the 4,246 dialogues, and the remaining 3,646 dialogues are used as the train set (refer to Table 4  ###reference_###  ###reference_### for the statistics of each set)."
        },
        {
            "section_id": "3.5",
            "parent_section_id": "3",
            "section_name": "3.5.   Annotation of Full Dialogue State",
            "text": "###table_2### The dialogue state is the information about the conditions of the entity that the user seeks, known up to each turn and recorded as a set of slot-value pairs. The DB query entered by the wizard at each turn can be used as a part of the dialogue state annotation. However, the DB query does not contain any non-explicitly communicated values. For example, as shown by Table 5  ###reference_###, if the user accepts the entity name proposed by the system (e.g., wizard: \u201cHow about JR INN Sapporo?\u201d, and user: \u201cOK, what are the prices like?\u201d), the entity name is not searched by the wizard; hence it is not recorded automatically.\nTo build the complete dialogue state, we recruited additional crowd workers to annotate this non-explicit value. After reading the manual, each worker annotated the values using a dedicated UI. As in the case of dialogue collection, the values were input by selection in order to suppress the perturbation of the slot value notations. To ensure the dialogue quality, each worker annotated ten dialogues for training and received feedback from the authors on errors. After repeated feedback, only those workers who no longer had issues participated in the annotation process.\nIn the end, six workers shared the annotation tasks for a total of 30,593 wizard turns.444Of the total 61,186 turns in the dataset (see Table 4  ###reference_###), 30,593 were wizard turns, and the dialogue states were annotated for them. Table 6  ###reference_### shows the statistics of the number of slots in the dialogue states. A total of 58,745 slots (about 37.8% of the slots recorded in the DB query) were added to the dialogue states. Here, 59 randomly selected dialogues were annotated by the authors, and the match rate between these annotations and those annotated by the workers was 94.1%, indicating that the annotations were sufficiently high quality."
        },
        {
            "section_id": "3.6",
            "parent_section_id": "3",
            "section_name": "3.6.   Statistics",
            "text": "Table 7  ###reference_### shows the statistics of JGlobalWOZ compared with the major multi-domain task-oriented dialogue datasets in English and Chinese, GlobalWOZ and CrossWOZ, respectively. Given that the number of domains, the number of slots, the average number of domains, and the average number of turns are roughly equivalent, the complexity of dialogues in JGlobalWOZ can be considered to be on par with the existing datasets. Figure 3  ###reference_### illustrates the distribution of the number of dialogue turns when all 4,246 dialogues are divided into dialogues containing only one domain (single-domain) and dialogues containing multiple domains (multi-domain). A wide variety of length and complexity can be seen in both types of dialogues."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4.   Benchmark",
            "text": "###figure_3### JGlobalWOZ provides benchmarks for two common tasks in task-oriented dialogues, dialogue state tracking (DST) and response generation (RG). DST is the task of estimating the dialogue state at each turn, while RG is the task of generating the next system response based on the dialogue context at each turn. To demonstrate that JGlobalWOZ can provide benchmarks equivalent to those in existing English dialogue corpora, we evaluate the aforementioned two tasks in JGlobalWOZ using the SOTA methods from GlobalWOZ2.2 (Zang et al., 2020) and the latest LLM-based methods. Note that GlobalWOZ2.2 is a version in which various annotation errors in the original GlobalWOZ have been corrected.\n###figure_4### ###figure_5### For SFT, we use the T5 (Raffel et al., 2020)-based model TOATOD (Bang et al., 2023), which is the SOTA model in GlobalWOZ2.2. TOATOD uses T5-base pretrained on a large number of task-oriented dialogue corpora as its backbone model, but such corpora do not exist in Japanese. Therefore, for the evaluation of JGlobalWOZ, we simply use T5-base/large pretrained on Japanese data as backbone models.\nFigure 4 depicts the overview of response generation using T5. First, the dialogue state is estimated from the dialogue context (i.e., DST). Then, the database search results, obtained by using the dialogue state as a DB query, are combined with the context and dialogue state to generate the final response (i.e., RG). During fine-tuning, the mapping of ground truth inputs and outputs at each step is learned using maximum likelihood estimation (MLE). Because the same model is used to perform both DST and RG, a prefix indicating the task is added to the input. Specific examples of the input-output sequences used in the training of T5 can be found in Section A in the appendix.\nIn the training of T5-base and T5-large, the batch size was set to 32, and they were trained for five epochs. The AdamW Loshchilov and Hutter (2019) optimizer was used, and the learning rate was initially set to 5e-5 and then linearly decayed according to the number of steps. For evaluation, the checkpoint at the final step was used, and for inference in DST and RG, greedy search was adopted in both cases.\nWe use the zero-/few-shot response generation pipeline using an LLM introduced by Hude\u010dek and Dusek (2023). Figure 4 shows the 3-step flow of zero-shot response generation. First, the LLM estimates the current active domain from the context. Then, focusing on that domain, it estimates the dialogue state. Based on the state, it searches the DB and uses all of the results to generate the final response. In the few-shot setting, two examples retrieved from the train set are mixed into each prompt in the pipeline. These examples are retrieved from the train set based on the similarity between the dialogue context embeddings of the retrieved examples and the current context embeddings. The Japanese sentence-transformers were used to create embedding vectors using two consecutive turns of utterances as the dialogue context.\nWe used APIs of OpenAI GPT-3.5 (gpt-3.5-turbo) and GPT-4 (gpt-4) for the LLM-based zero-/few-shot settings. GPT-3.5 is the highest performing model for DST and RG on GlobalWOZ, as reported by Hude\u010dek and Dusek (2023). GPT-4 is the latest model provided by OpenAI\u2019s API and is known for its high capabilities in Japanese. Based on the results of the Japanese LLM leaderboard (https://api.wandb.ai/links/wandb-japan/6ff86bp3 as of October 2023). The Japanese prompts were created based on the prompts in (Hude\u010dek and Dusek, 2023). See Section B in the Appendix for examples of the prompts."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1.   Baseline Models",
            "text": "The most recent task-oriented dialogue models can be generally categorized into two approaches: (1) fine-tuning with supervised learning on medium-sized pretrained language models (Supervised Fine-Tuning; SFT) (Lin et al., 2021a; Su et al., 2022), and (2) generating responses in a zero-/few-shot setting using an LLM (Hude\u010dek and Dusek, 2023; Raposo et al., 2023). In this experiment, we validate both methods using the following models. Note that the model-predicted dialogue states were used as input for RG, instead of the ground-truth dialogue states. This is in line with the settings used in previous studies (Bang et al., 2023; Hude\u010dek and Dusek, 2023), allowing for comparison with the scores reported in those studies.\n\nFor SFT, we use the T5 (Raffel et al., 2020)-based model TOATOD (Bang et al., 2023), which is the SOTA model in GlobalWOZ2.2. TOATOD uses T5-base pretrained on a large number of task-oriented dialogue corpora as its backbone model, but such corpora do not exist in Japanese. Therefore, for the evaluation of JGlobalWOZ, we simply use T5-base/large pretrained on Japanese data as backbone models.\n\nFigure 4 depicts the overview of response generation using T5. First, the dialogue state is estimated from the dialogue context (i.e., DST). Then, the database search results, obtained by using the dialogue state as a DB query, are combined with the context and dialogue state to generate the final response (i.e., RG). During fine-tuning, the mapping of ground truth inputs and outputs at each step is learned using maximum likelihood estimation (MLE). Because the same model is used to perform both DST and RG, a prefix indicating the task is added to the input. Specific examples of the input-output sequences used in the training of T5 can be found in Section A in the appendix.\n\nIn the training of T5-base and T5-large, the batch size was set to 32, and they were trained for five epochs. The AdamW Loshchilov and Hutter (2019) optimizer was used, and the learning rate was initially set to 5e-5 and then linearly decayed according to the number of steps. For evaluation, the checkpoint at the final step was used, and for inference in DST and RG, greedy search was adopted in both cases.\n\nWe use the zero-/few-shot response generation pipeline using an LLM introduced by Hude\u010dek and Dusek (2023). Figure 4 shows the 3-step flow of zero-shot response generation. First, the LLM estimates the current active domain from the context. Then, focusing on that domain, it estimates the dialogue state. Based on the state, it searches the DB and uses all of the results to generate the final response. In the few-shot setting, two examples retrieved from the train set are mixed into each prompt in the pipeline. These examples are retrieved from the train set based on the similarity between the dialogue context embeddings of the retrieved examples and the current context embeddings. The Japanese sentence-transformers were used to create embedding vectors using two consecutive turns of utterances as the dialogue context.\n\nWe used APIs of OpenAI GPT-3.5 (gpt-3.5-turbo) and GPT-4 (gpt-4) for the LLM-based zero-/few-shot settings. GPT-3.5 is the highest performing model for DST and RG on GlobalWOZ, as reported by Hude\u010dek and Dusek (2023). GPT-4 is the latest model provided by OpenAI\u2019s API and is known for its high capabilities in Japanese. The Japanese prompts were created based on the prompts in (Hude\u010dek and Dusek, 2023). See Section B in the Appendix for examples of the prompts."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2.   Evaluation Metrics",
            "text": "To evaluate DST, we used the most standard metric, joint goal accuracy (JGA). JGA is a measure of whether the estimated dialogue state perfectly matches the ground truth dialogue state at each turn, resulting in a binary outcome (0/1). Additionally, we also utilized Slot-F1 to evaluate for each turn the match rate between the set of slot values in the estimated dialogue state and the set of slot values in the ground truth state, in terms of F1 score. To evaluate RG, we used the BLEU score, which indicates the similarity between the generated response and the ground truth response."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "4.3.   Results",
            "text": "Table 8 ###reference_### shows a comparison between the evaluation results reported in previous studies on GlobalWOZ and those of JGlobalWOZ. On JGlobalWOZ, the SFT method, namely T5-base/large, generally had the highest performance for both DST and RG, and there seemed to be certain limitations to the performance of LLMs. This trend is consistent with the results of GlobalWOZ.\n\nFor the DST metrics, Slot-F1 was higher in JGlobalWOZ. As described in Section 3.4 ###reference_###, in the construction of JGlobalWOZ, we chose the selection-based input for the DB search query by the wizard to reduce variations in dialogue state reported as issues in GlobalWOZ. This enabled the dialogue models to predict exact values without confusion, resulting in higher slot-F1.\n\nFor JGA, the primary metric for DST, the difference between GlobalWOZ and JGlobalWOZ was minimal. This suggests that the complexity and annotation accuracy of JGlobalWOZ are comparable to that of GlobalWOZ, demonstrating its capacity to provide benchmarks equivalent to the existing datasets. Notably, there is a difference of about 5% in JGA for T5-base across both corpora. This gap can be attributed to the fact that in GlobalWOZ, besides supervised learning, T5-base was boosted via reinforcement learning with the reward functions where JGA was incorporated.\n\nFor the RG metric, BLEU, JGlobalWOZ yielded significantly higher scores compared to GlobalWOZ. This is likely because the wizard\u2019s utterances in JGlobalWOZ are more consistent than in GlobalWOZ. During the dialogue collection for JGlobalWOZ, the dialogues were conducted synchronously, ensuring that the wizards did not switch in the middle of each dialogue. Moreover, we provided ample training for the wizards. Through such quality control measures, we believe that consistent system responses could be attained."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5.   Human Evaluation",
            "text": "The model\u2019s actual task completion capability in real dialogues must be assessed by actual people when evaluating task-oriented dialogue models as well as by automatic evaluation (Iizuka et al., 2023  ###reference_b17###). In this section, we evaluate the end-to-end dialogue capabilities of the four dialogue models acquired in Section 4  ###reference_###, namely, T5-base, T5-large, GPT-3.5, and GPT-4, by having them engage in conversations with crowd workers. Note that both GPT-3.5 and GPT-4 used a few-shot setting."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "5.1.   Settings",
            "text": "The setting of this evaluation experiment followed that of Iizuka et al. (2023 ###reference_b17###), where they evaluated the end-to-end dialogue performance of the TOATOD (Bang et al., 2023 ###reference_b1###) and Hude\u010dek and Dusek (2023 ###reference_b15###)\u2019s LLM pipeline models built based on the GlobalWOZ by using crowdsourcing. Specifically, each worker was first given dialogue instructions and a user goal for each dialogue session. These user goals were randomly sampled from the test set. Then, they engaged in a dialogue with one of the four models. Each dialogue was set to a maximum of 20 turns (one turn consists of one user utterance and one system response), and workers judged whether they achieved the user goal within 20 turns. After the dialogue, the workers evaluated (1) the system\u2019s language understanding ability, (2) the appropriateness of the system\u2019s responses, and (3) their overall satisfaction with the dialogue, each on a 5-point scale. The workers were restricted to converse with only one system."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "5.2.   Results",
            "text": "Table 9 presents the evaluation results on JGlobalWOZ, as well as the results reported by Iizuka et al. (2023) on GlobalWOZ2.2. For the models trained with SFT, namely T5-base/large, there was no significant difference in Success, compared to T5-base (TOATOD) on GlobalWOZ2.2. These results show that using JGlobalWOZ allows for the development and evaluation of Japanese end-to-end dialogue models with performance comparable to that of GlobalWOZ2.2. \n\nThe performance of the LLM models, i.e., GPT-3.5 and GPT-4, significantly declined compared to that of GlobalWOZ2.2. This may be because even the latest LLMs, such as GPT-4, are not capable of handling dynamically changing dialogue contexts in Japanese. Specifically, since the model\u2019s predicted dialogue states and system responses are accumulated in the dialogue history, errors propagate gradually, making it difficult to maintain multi-turn conversations. GPT-4\u2019s Japanese language ability is not as high as that for English (OpenAI, 2023), and this difference in ability is likely reflected in the performance of task-oriented dialogue systems. This limitation of dialogue skills in LLMs in non-English languages should be addressed with multilingual resources in the future, and we anticipate that JGlobalWOZ can contribute to such studies."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6.   Conclusion",
            "text": "We have presented JGlobalWOZ, the first large-scale Japanese multi-domain task-oriented dialogue dataset. This corpus contains 4,246 WOZ dialogues spanning six travel-related domains and provides benchmarks for dialogue state tracking and response generation. Using JGlobalWOZ, we evaluated existing SOTA methods with the T5-based models and the latest LLM-based methods, namely GPT-3.5/4, and demonstrated that JGlobalWOZ performs comparably to the major benchmark dataset in English, GlobalWOZ. Furthermore, we confirmed that the capabilities of GPT-3.5/4 in particular are limited in Japanese. For future work, we would like to conduct comprehensive evaluation using more diverse models, including other LLMs with high multilingual abilities (Team et al., 2023  ###reference_b31###). We hope that the development of JGlobalWOZ will lead to further research on Japanese dialogue systems, including the improvement of LLMs\u2019 task-oriented dialogue capabilities in Japanese and the development of a multilingual task-oriented dialogue model."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7.   Limitations",
            "text": "In this study, to collect native dialogues specific to Japan, we collected online conversations through Japanese crowd workers. However, in prior research, multilingual corpora were built through machine translations of GlobalWOZ, and GlobalWOZ (Ding et al., 2022  ###reference_b5###) includes Japanese dialogue data, albeit being entirely machine-translated. Therefore, in the future, it will be necessary to investigate the advantages of JGlobalWOZ, which we collected from scratch, compared to GlobalWOZ. Additionally, it may be possible to further improve performance by using GlobalWOZ for pre-training and then fine-tuning with our JGlobalWOZ; this will need to be validated in the future. JGlobalWOZ provides benchmarks for two main tasks, DST and RG, through dialogue state annotations, enabling the construction and evaluation of end-to-end task-oriented dialogue models. However, it does not yet have dialogue act (DA) annotations (Budzianowski et al., 2018  ###reference_b2###; Eric et al., 2020  ###reference_b7###). This means that it does not provide a benchmark for another major task in task-oriented dialogue, policy optimization. Therefore, to further enhance its utility, DA annotations should be added in the future."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "8.   Ethical Considerations",
            "text": "Our ethical considerations span across data sources, dialogue collection, human evaluation, and the implications of using pretrained language models (PLMs).\nWe exclusively employed information sources free from copyright constraints. Our list of entities was primarily derived from websites operated by the government or municipalities. Specific information for each entity was solely extracted from their respective official websites, ensuring authenticity and credibility. We consciously abstained from using tourism sites, or any other source potentially encumbered by copyright issues.\nPrior to our data collection and evaluation experiments, ethical approval was obtained from the affiliated organization. In the data collection and evaluations, we engaged only crowd workers who explicitly consented to abstain from (1) unsolicited disclosure of personal information during dialogues. Additionally, these workers agreed to (2) relinquish copyright claims over data and artifacts produced during the dialogue collection phase and (3) publication of collected dialogue data. The data to be released will not contain any personally identifiable information of the workers, such as their names.\nThe pre-training data of the PLMs uses a vast amount of textual data from Internet information. Therefore, our dialogue models based on these PLMs may produce potentially harmful or discriminatory responses."
        },
        {
            "section_id": "9",
            "parent_section_id": null,
            "section_name": "9.   Acknowledgments",
            "text": "This work was supported by JST Moonshot R&D Grant number JPMJMS2011. We used the computational resources of the supercomputer \u201cFlow\u201d at the Information Technology Center, Nagoya University."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Example of Input-Output Data for T5",
            "text": "Figures 5  ###reference_### and 6  ###reference_### show specific examples of the input-output sequences used in the training of T5.\n###figure_6### ###figure_7### ###figure_8### ###figure_9###"
        },
        {
            "section_id": "Appendix 2",
            "parent_section_id": null,
            "section_name": "Appendix B Prompt Examples for LLMs",
            "text": "We created the Japanese prompts for JMultiWOZ based on the prompts for MultiWOZ used by Hude\u010dek and Dusek (2023  ###reference_b15###). Figures 7  ###reference_### and 8  ###reference_### show examples of prompts used for LLMs in a zero-shot setting.\n###figure_10### ###figure_11### ###figure_12### ###figure_13###"
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S1.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S1.T1.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S1.T1.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" id=\"S1.T1.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S1.T1.2.1.1.1.1\" style=\"font-size:90%;\">Domain</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt\" id=\"S1.T1.2.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S1.T1.2.1.1.2.1\">\n<span class=\"ltx_p\" id=\"S1.T1.2.1.1.2.1.1\" style=\"width:355.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S1.T1.2.1.1.2.1.1.1\" style=\"font-size:90%;\">Slots</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S1.T1.2.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S1.T1.2.2.1.1\"><span class=\"ltx_text\" id=\"S1.T1.2.2.1.1.1\" style=\"font-size:90%;\">restaurant</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S1.T1.2.2.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S1.T1.2.2.1.2.1\">\n<span class=\"ltx_p\" id=\"S1.T1.2.2.1.2.1.1\" style=\"width:355.7pt;\"><span class=\"ltx_text\" id=\"S1.T1.2.2.1.2.1.1.1\" style=\"font-size:90%;\">city, name, genre, area, pricerange, station, wifi, parking, opentime, phone, address, accesstime, closed, priceinfo, reference, people, day, time</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.2.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S1.T1.2.3.2.1\"><span class=\"ltx_text\" id=\"S1.T1.2.3.2.1.1\" style=\"font-size:90%;\">accommodation</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S1.T1.2.3.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S1.T1.2.3.2.2.1\">\n<span class=\"ltx_p\" id=\"S1.T1.2.3.2.2.1.1\" style=\"width:355.7pt;\"><span class=\"ltx_text\" id=\"S1.T1.2.3.2.2.1.1.1\" style=\"font-size:90%;\">city, name, genre, area, pricerange, station, wifi, parking, withrestaurant, phone, address, accesstime, checkintime, checkouttime, priceinfo, reference, people, day, stay</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.2.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S1.T1.2.4.3.1\"><span class=\"ltx_text\" id=\"S1.T1.2.4.3.1.1\" style=\"font-size:90%;\">attraction</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S1.T1.2.4.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S1.T1.2.4.3.2.1\">\n<span class=\"ltx_p\" id=\"S1.T1.2.4.3.2.1.1\" style=\"width:355.7pt;\"><span class=\"ltx_text\" id=\"S1.T1.2.4.3.2.1.1.1\" style=\"font-size:90%;\">city, name, genre, area, station, wifi, parking, opentime, phone, address, accesstime, closed, adultfee, childfee, priceinfo</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.2.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S1.T1.2.5.4.1\"><span class=\"ltx_text\" id=\"S1.T1.2.5.4.1.1\" style=\"font-size:90%;\">shopping</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S1.T1.2.5.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S1.T1.2.5.4.2.1\">\n<span class=\"ltx_p\" id=\"S1.T1.2.5.4.2.1.1\" style=\"width:355.7pt;\"><span class=\"ltx_text\" id=\"S1.T1.2.5.4.2.1.1.1\" style=\"font-size:90%;\">city, name, genre, area, station, parking, opentime, phone, address, accesstime, closed</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.2.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S1.T1.2.6.5.1\"><span class=\"ltx_text\" id=\"S1.T1.2.6.5.1.1\" style=\"font-size:90%;\">taxi</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S1.T1.2.6.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S1.T1.2.6.5.2.1\">\n<span class=\"ltx_p\" id=\"S1.T1.2.6.5.2.1.1\" style=\"width:355.7pt;\"><span class=\"ltx_text\" id=\"S1.T1.2.6.5.2.1.1.1\" style=\"font-size:90%;\">city, name, cashless, jumbo, phone, reference, day, time, departurepoint, arrivalpoint</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.2.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\" id=\"S1.T1.2.7.6.1\"><span class=\"ltx_text\" id=\"S1.T1.2.7.6.1.1\" style=\"font-size:90%;\">weather</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\" id=\"S1.T1.2.7.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S1.T1.2.7.6.2.1\">\n<span class=\"ltx_p\" id=\"S1.T1.2.7.6.2.1.1\" style=\"width:355.7pt;\"><span class=\"ltx_text\" id=\"S1.T1.2.7.6.2.1.1.1\" style=\"font-size:90%;\">city, area, day, weather, mintemperature, maxtemperature</span></span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>List of slots defined in the ontology for each domain</figcaption>\n</figure>",
            "capture": "Table 1: List of slots defined in the ontology for each domain"
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T2\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S3.T2.2\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T2.2.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S3.T2.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.2.1.1.1.1\" style=\"font-size:90%;\">Domain</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" colspan=\"2\" id=\"S3.T2.2.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.2.1.1.2.1\" style=\"font-size:90%;\">Slot</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.2.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.2.2.2.1\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S3.T2.2.2.2.1.1\" style=\"font-size:90%;\">attraction</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.2.2.2.2\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S3.T2.2.2.2.2.1\" style=\"font-size:90%;\">info.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.2.2.2.3\"><span class=\"ltx_text\" id=\"S3.T2.2.2.2.3.1\" style=\"font-size:90%;\">city = Nagoya</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.2.3.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.2.3.3.1\"><span class=\"ltx_text\" id=\"S3.T2.2.3.3.1.1\" style=\"font-size:90%;\">parking = yes(free)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.2.4.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.2.4.4.1\"><span class=\"ltx_text\" id=\"S3.T2.2.4.4.1.1\" style=\"font-size:90%;\">wifi = yes(free)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.2.5.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.2.5.5.1\"><span class=\"ltx_text\" id=\"S3.T2.2.5.5.1.1\" style=\"font-size:90%;\">reqt.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.2.5.5.2\"><span class=\"ltx_text\" id=\"S3.T2.2.5.5.2.1\" style=\"font-size:90%;\">area, station, closed</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.2.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S3.T2.2.6.6.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S3.T2.2.6.6.1.1\" style=\"font-size:90%;\">accommodation</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.2.6.6.2\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T2.2.6.6.2.1\" style=\"font-size:90%;\">info.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.2.6.6.3\"><span class=\"ltx_text\" id=\"S3.T2.2.6.6.3.1\" style=\"font-size:90%;\">pricerange = expensive</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.2.7.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.2.7.7.1\"><span class=\"ltx_text\" id=\"S3.T2.2.7.7.1.1\" style=\"font-size:90%;\">wifi = yes(free)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.2.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S3.T2.2.8.8.1\"><span class=\"ltx_text\" id=\"S3.T2.2.8.8.1.1\" style=\"font-size:90%;\">reqt.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S3.T2.2.8.8.2\"><span class=\"ltx_text\" id=\"S3.T2.2.8.8.2.1\" style=\"font-size:90%;\">accesstime, genre</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Example of a user goal. \u201cinfo.\u201d and \u201creqt.\u201d in the \u201cSlot\u201d column indicate informable and requestable slots, respectively.</figcaption>\n</figure>",
            "capture": "Table 2: Example of a user goal. \u201cinfo.\u201d and \u201creqt.\u201d in the \u201cSlot\u201d column indicate informable and requestable slots, respectively."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T3\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T3.2\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T3.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S3.T3.2.1.1.1\"><span class=\"ltx_text\" id=\"S3.T3.2.1.1.1.1\" style=\"font-size:90%;\">1.</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S3.T3.2.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T3.2.1.1.2.1\">\n<span class=\"ltx_p\" id=\"S3.T3.2.1.1.2.1.1\" style=\"width:184.9pt;\"><span class=\"ltx_text\" id=\"S3.T3.2.1.1.2.1.1.1\" style=\"font-size:90%;\">You are planning a trip to </span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.2.1.1.2.1.1.2\" style=\"font-size:90%;color:#0041FF;\">Nagoya</span><span class=\"ltx_text\" id=\"S3.T3.2.1.1.2.1.1.3\" style=\"font-size:90%;\">.</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.2.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.2.2.2.1\"><span class=\"ltx_text\" id=\"S3.T3.2.2.2.1.1\" style=\"font-size:90%;\">2.</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S3.T3.2.2.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T3.2.2.2.2.1\">\n<span class=\"ltx_p\" id=\"S3.T3.2.2.2.2.1.1\" style=\"width:184.9pt;\"><span class=\"ltx_text\" id=\"S3.T3.2.2.2.2.1.1.1\" style=\"font-size:90%;\">Find a </span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.2.2.2.2.1.1.2\" style=\"font-size:90%;color:#0041FF;\">tourist attraction</span><span class=\"ltx_text\" id=\"S3.T3.2.2.2.2.1.1.3\" style=\"font-size:90%;\"> to visit for one day. Choose a place where the parking is </span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.2.2.2.2.1.1.4\" style=\"font-size:90%;color:#0041FF;\">free</span><span class=\"ltx_text\" id=\"S3.T3.2.2.2.2.1.1.5\" style=\"font-size:90%;\">. The place should also have </span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.2.2.2.2.1.1.6\" style=\"font-size:90%;color:#0041FF;\">free</span><span class=\"ltx_text\" id=\"S3.T3.2.2.2.2.1.1.7\" style=\"font-size:90%;\"> Wi-Fi.</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.2.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.2.3.3.1\"><span class=\"ltx_text\" id=\"S3.T3.2.3.3.1.1\" style=\"font-size:90%;\">3.</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S3.T3.2.3.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T3.2.3.3.2.1\">\n<span class=\"ltx_p\" id=\"S3.T3.2.3.3.2.1.1\" style=\"width:184.9pt;\"><span class=\"ltx_text\" id=\"S3.T3.2.3.3.2.1.1.1\" style=\"font-size:90%;\">Once you find a desired tourist spot, ask about its </span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.2.3.3.2.1.1.2\" style=\"font-size:90%;color:#35A16B;\">area, nearest station, and closed days</span><span class=\"ltx_text\" id=\"S3.T3.2.3.3.2.1.1.3\" style=\"font-size:90%;\">.</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.2.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.2.4.4.1\"><span class=\"ltx_text\" id=\"S3.T3.2.4.4.1.1\" style=\"font-size:90%;\">4.</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S3.T3.2.4.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T3.2.4.4.2.1\">\n<span class=\"ltx_p\" id=\"S3.T3.2.4.4.2.1.1\" style=\"width:184.9pt;\"><span class=\"ltx_text\" id=\"S3.T3.2.4.4.2.1.1.1\" style=\"font-size:90%;\">Find a </span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.2.4.4.2.1.1.2\" style=\"font-size:90%;color:#0041FF;\">place to stay</span><span class=\"ltx_text\" id=\"S3.T3.2.4.4.2.1.1.3\" style=\"font-size:90%;\"> for the night. The budget is on the </span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.2.4.4.2.1.1.4\" style=\"font-size:90%;color:#0041FF;\">higher</span><span class=\"ltx_text\" id=\"S3.T3.2.4.4.2.1.1.5\" style=\"font-size:90%;\"> side. The place should also offer </span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.2.4.4.2.1.1.6\" style=\"font-size:90%;color:#0041FF;\">free</span><span class=\"ltx_text\" id=\"S3.T3.2.4.4.2.1.1.7\" style=\"font-size:90%;\"> Wi-Fi.</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.2.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T3.2.5.5.1\"><span class=\"ltx_text\" id=\"S3.T3.2.5.5.1.1\" style=\"font-size:90%;\">5.</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S3.T3.2.5.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T3.2.5.5.2.1\">\n<span class=\"ltx_p\" id=\"S3.T3.2.5.5.2.1.1\" style=\"width:184.9pt;\"><span class=\"ltx_text\" id=\"S3.T3.2.5.5.2.1.1.1\" style=\"font-size:90%;\">Once you find a suitable accommodation, ask about the </span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.2.5.5.2.1.1.2\" style=\"font-size:90%;color:#35A16B;\">time it takes from the nearest station and the type of accommodation</span><span class=\"ltx_text\" id=\"S3.T3.2.5.5.2.1.1.3\" style=\"font-size:90%;\">.</span></span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Explanation of the user goal shown in Table\u00a0<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.17319v1#S3.T2\" title=\"Table 2 \u2023 3.2. Construction of Backend Database \u2023 3. Data Collection \u2023 JMultiWOZ: A Large-Scale Japanese Multi-Domain Task-Oriented Dialogue Dataset\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. The <span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.10.1\" style=\"color:#0041FF;\">blue text</span> indicates informable slot values, while the <span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.11.2\" style=\"color:#35A16B;\">green text</span> indicates requestable slot values.</figcaption>\n</figure>",
            "capture": "Table 3: Explanation of the user goal shown in Table\u00a02. The blue text indicates informable slot values, while the green text indicates requestable slot values."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T4\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T4.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T4.2.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S3.T4.2.1.1.1\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T4.2.1.1.2\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.2.1.1.2.1\" style=\"font-size:90%;\">Total</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T4.2.1.1.3\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.2.1.1.3.1\" style=\"font-size:90%;\">Train</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T4.2.1.1.4\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.2.1.1.4.1\" style=\"font-size:90%;\">Dev</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T4.2.1.1.5\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.2.1.1.5.1\" style=\"font-size:90%;\">Test</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T4.2.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T4.2.2.1.1\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.2.1.1.1\" style=\"font-size:90%;\">Dialogues</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T4.2.2.1.2\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.2.1.2.1\" style=\"font-size:90%;\">4,246</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T4.2.2.1.3\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.2.1.3.1\" style=\"font-size:90%;\">3,654</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T4.2.2.1.4\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.2.1.4.1\" style=\"font-size:90%;\">300</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T4.2.2.1.5\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.2.1.5.1\" style=\"font-size:90%;\">300</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.2.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T4.2.3.2.1\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.3.2.1.1\" style=\"font-size:90%;\">Turns</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T4.2.3.2.2\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.3.2.2.1\" style=\"font-size:90%;\">61,186</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T4.2.3.2.3\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.3.2.3.1\" style=\"font-size:90%;\">52,405</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T4.2.3.2.4\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.3.2.4.1\" style=\"font-size:90%;\">4,346</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T4.2.3.2.5\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.3.2.5.1\" style=\"font-size:90%;\">4,435</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.2.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T4.2.4.3.1\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.4.3.1.1\" style=\"font-size:90%;\">Tokens</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T4.2.4.3.2\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.4.3.2.1\" style=\"font-size:90%;\">1,102,658</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T4.2.4.3.3\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.4.3.3.1\" style=\"font-size:90%;\">943,653</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T4.2.4.3.4\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.4.3.4.1\" style=\"font-size:90%;\">78,683</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T4.2.4.3.5\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.4.3.5.1\" style=\"font-size:90%;\">80,322</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.2.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T4.2.5.4.1\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.5.4.1.1\" style=\"font-size:90%;\">Vocab.</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T4.2.5.4.2\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.5.4.2.1\" style=\"font-size:90%;\">11,121</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T4.2.5.4.3\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.5.4.3.1\" style=\"font-size:90%;\">10,309</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T4.2.5.4.4\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.5.4.4.1\" style=\"font-size:90%;\">2,854</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T4.2.5.4.5\" style=\"padding-left:4.3pt;padding-right:4.3pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.5.4.5.1\" style=\"font-size:90%;\">2,971</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Statistics of JMultiWOZ</figcaption>\n</figure>",
            "capture": "Table 4: Statistics of JMultiWOZ"
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T5\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S3.T5.2\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T5.2.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S3.T5.2.1.1.1\" style=\"padding-left:2.8pt;padding-right:2.8pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.1.1.1.1\" style=\"font-size:90%;\">Context</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S3.T5.2.1.1.2\" style=\"padding-left:2.8pt;padding-right:2.8pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.1.1.2.1\" style=\"font-size:90%;\">User:</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S3.T5.2.1.1.3\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.1.1.3.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.1.1.3.1.1\" style=\"width:142.3pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.1.1.3.1.1.1\" style=\"font-size:90%;\">I\u2019m looking for a hotel in Sapporo, and it would be helpful if it has free wifi.</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.2.2\">\n<td class=\"ltx_td\" id=\"S3.T5.2.2.2.1\" style=\"padding-left:2.8pt;padding-right:2.8pt;\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T5.2.2.2.2\" style=\"padding-left:2.8pt;padding-right:2.8pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.2.2.2.1\" style=\"font-size:90%;\">Wizard:</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S3.T5.2.2.2.3\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.2.2.3.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.2.2.3.1.1\" style=\"width:142.3pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.2.2.3.1.1.1\" style=\"font-size:90%;\">How about JR INN Sapporo for example?</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.3.3\">\n<td class=\"ltx_td\" id=\"S3.T5.2.3.3.1\" style=\"padding-left:2.8pt;padding-right:2.8pt;\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T5.2.3.3.2\" style=\"padding-left:2.8pt;padding-right:2.8pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.3.3.2.1\" style=\"font-size:90%;\">User:</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S3.T5.2.3.3.3\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.3.3.3.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.3.3.3.1.1\" style=\"width:142.3pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.3.3.3.1.1.1\" style=\"font-size:90%;\">Good, what are the prices like?</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"2\" id=\"S3.T5.2.4.4.1\" style=\"padding-left:2.8pt;padding-right:2.8pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.4.4.1.1\" style=\"font-size:90%;\">DB query</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S3.T5.2.4.4.2\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.4.4.2.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.4.4.2.1.1\" style=\"width:142.3pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.4.4.2.1.1.1\" style=\"font-size:90%;\">city=Sapporo, wifi=yes</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.5.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" colspan=\"2\" id=\"S3.T5.2.5.5.1\" style=\"padding-left:2.8pt;padding-right:2.8pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.5.5.1.1\" style=\"font-size:90%;\">Dialogue State</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\" id=\"S3.T5.2.5.5.2\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.5.5.2.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.5.5.2.1.1\" style=\"width:142.3pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.5.5.2.1.1.1\" style=\"font-size:90%;\">city=Sapporo, wifi=yes, </span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T5.2.5.5.2.1.1.2\" style=\"font-size:90%;\">name=JR INN Sapporo</span></span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>Examples of a DB query obtained during dialogue collection and a dialogue state obtained from the additional annotation</figcaption>\n</figure>",
            "capture": "Table 5: Examples of a DB query obtained during dialogue collection and a dialogue state obtained from the additional annotation"
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T6\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T6.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T6.2.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S3.T6.2.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T6.2.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T6.2.1.1.2.1\" style=\"font-size:90%;\"># slot-value pairs</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T6.2.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T6.2.2.1.1\"><span class=\"ltx_text\" id=\"S3.T6.2.2.1.1.1\" style=\"font-size:90%;\">DB search query</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T6.2.2.1.2\"><span class=\"ltx_text\" id=\"S3.T6.2.2.1.2.1\" style=\"font-size:90%;\">155,274</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T6.2.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T6.2.3.2.1\"><span class=\"ltx_text\" id=\"S3.T6.2.3.2.1.1\" style=\"font-size:90%;\">Newly annotated dialogue state</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T6.2.3.2.2\"><span class=\"ltx_text\" id=\"S3.T6.2.3.2.2.1\" style=\"font-size:90%;\">58,745</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T6.2.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T6.2.4.3.1\"><span class=\"ltx_text\" id=\"S3.T6.2.4.3.1.1\" style=\"font-size:90%;\">Final dialogue state</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T6.2.4.3.2\"><span class=\"ltx_text\" id=\"S3.T6.2.4.3.2.1\" style=\"font-size:90%;\">214,019</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 6: </span>Number of slot-value pairs annotated in JMultiWOZ</figcaption>\n</figure>",
            "capture": "Table 6: Number of slot-value pairs annotated in JMultiWOZ"
        },
        "7": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T7\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T7.2\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T7.2.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S3.T7.2.1.1.1\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"></th>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"S3.T7.2.1.1.2\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T7.2.1.1.2.1\" style=\"font-size:90%;\">MultiWOZ</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"S3.T7.2.1.1.3\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T7.2.1.1.3.1\" style=\"font-size:90%;\">CrossWOZ</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"S3.T7.2.1.1.4\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T7.2.1.1.4.1\" style=\"font-size:90%;\">JMultiWOZ</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T7.2.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T7.2.2.2.1\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.2.2.1.1\" style=\"font-size:90%;\">Language</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T7.2.2.2.2\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.2.2.2.1\" style=\"font-size:90%;\">English</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T7.2.2.2.3\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.2.2.3.1\" style=\"font-size:90%;\">Chinese</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T7.2.2.2.4\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.2.2.4.1\" style=\"font-size:90%;\">Japanese</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T7.2.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T7.2.3.3.1\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.3.3.1.1\" style=\"font-size:90%;\">Domains</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.3.3.2\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.3.3.2.1\" style=\"font-size:90%;\">7</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.3.3.3\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.3.3.3.1\" style=\"font-size:90%;\">5</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.3.3.4\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.3.3.4.1\" style=\"font-size:90%;\">6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T7.2.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T7.2.4.4.1\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.4.4.1.1\" style=\"font-size:90%;\">Slots</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.4.4.2\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.4.4.2.1\" style=\"font-size:90%;\">57</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.4.4.3\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.4.4.3.1\" style=\"font-size:90%;\">72</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.4.4.4\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.4.4.4.1\" style=\"font-size:90%;\">79</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T7.2.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T7.2.5.5.1\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.5.5.1.1\" style=\"font-size:90%;\">Dialogues</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.5.5.2\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.5.5.2.1\" style=\"font-size:90%;\">8,438</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.5.5.3\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.5.5.3.1\" style=\"font-size:90%;\">5,012</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.5.5.4\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.5.5.4.1\" style=\"font-size:90%;\">3,646</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T7.2.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T7.2.6.6.1\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.6.6.1.1\" style=\"font-size:90%;\">Turns</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.6.6.2\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.6.6.2.1\" style=\"font-size:90%;\">115,424</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.6.6.3\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.6.6.3.1\" style=\"font-size:90%;\">84,692</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.6.6.4\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.6.6.4.1\" style=\"font-size:90%;\">52,405</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T7.2.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T7.2.7.7.1\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.7.7.1.1\" style=\"font-size:90%;\">Avg. domains</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.7.7.2\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.7.7.2.1\" style=\"font-size:90%;\">1.8</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.7.7.3\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.7.7.3.1\" style=\"font-size:90%;\">3.24</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.7.7.4\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.7.7.4.1\" style=\"font-size:90%;\">2.02</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T7.2.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T7.2.8.8.1\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.8.8.1.1\" style=\"font-size:90%;\">Avg. turns</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.8.8.2\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.8.8.2.1\" style=\"font-size:90%;\">13.7</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.8.8.3\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.8.8.3.1\" style=\"font-size:90%;\">16.9</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T7.2.8.8.4\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.8.8.4.1\" style=\"font-size:90%;\">14.4</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T7.2.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T7.2.9.9.1\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.9.9.1.1\" style=\"font-size:90%;\">Synchronous</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T7.2.9.9.2\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.9.9.2.1\" style=\"font-size:90%;\">No</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T7.2.9.9.3\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.9.9.3.1\" style=\"font-size:90%;\">Yes</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T7.2.9.9.4\" style=\"padding-left:3.7pt;padding-right:3.7pt;\"><span class=\"ltx_text\" id=\"S3.T7.2.9.9.4.1\" style=\"font-size:90%;\">Yes</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 7: </span>Comparison of multi-domain task-oriented dialogue datasets on the train set; \u201cSynchronous\u201d indicates whether one user and one wizard actually conducted the dialogue synchronously during the dialogue collection.</figcaption>\n</figure>",
            "capture": "Table 7: Comparison of multi-domain task-oriented dialogue datasets on the train set; \u201cSynchronous\u201d indicates whether one user and one wizard actually conducted the dialogue synchronously during the dialogue collection."
        },
        "8": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T8\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T8.3\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T8.3.4.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T8.3.4.1.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T8.3.4.1.1.1\">Model</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T8.3.4.1.2\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T8.3.4.1.2.1\">Few-shot</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"3\" id=\"S4.T8.3.4.1.3\">MultiWOZ 2.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\" id=\"S4.T8.3.4.1.4\">JMultiWOZ</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.3.5.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.5.2.1\">JGA</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.5.2.2\">Slot-F1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T8.3.5.2.3\">BLEU</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.5.2.4\">JGA</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.5.2.5\">Slot-F1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.5.2.6\">BLEU</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T8.1.1.1\">T5-base<sup class=\"ltx_sup\" id=\"S4.T8.1.1.1.1\">\u2020</sup>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T8.1.1.2\">\u2717</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.3\">0.64</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.4\">0.94</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T8.1.1.5\">17.04</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.6\">0.59</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.7\">0.95</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.8\">42.31</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.3.6.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T8.3.6.3.1\">T5-large</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T8.3.6.3.2\">\u2717</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.6.3.3\">\u2013</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.6.3.4\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T8.3.6.3.5\">\u2013</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.6.3.6\">0.77</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.6.3.7\">0.98</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.6.3.8\">49.68</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T8.2.2.1\">GPT-3.5<sup class=\"ltx_sup\" id=\"S4.T8.2.2.1.1\">\u2021</sup>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T8.2.2.2\">\u2717</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.2.2.3\">0.13</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.2.2.4\">0.40</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T8.2.2.5\">4.17</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.2.2.6\">0.16</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.2.2.7\">0.70</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.2.2.8\">5.31</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.3.7.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T8.3.7.4.1\">GPT-4</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T8.3.7.4.2\">\u2717</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.7.4.3\">\u2013</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.7.4.4\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T8.3.7.4.5\">\u2013</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.7.4.6\">0.31</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.7.4.7\">0.86</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.3.7.4.8\">8.87</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T8.3.3.1\">GPT-3.5<sup class=\"ltx_sup\" id=\"S4.T8.3.3.1.1\">\u2021</sup>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T8.3.3.2\">\u2713</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.3.3.3\">0.27</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.3.3.4\">0.51</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T8.3.3.5\">6.77</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.3.3.6\">0.25</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.3.3.7\">0.82</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.3.3.8\">12.91</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.3.8.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"S4.T8.3.8.5.1\">GPT-4</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"S4.T8.3.8.5.2\">\u2713</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.3.8.5.3\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.3.8.5.4\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S4.T8.3.8.5.5\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.3.8.5.6\">0.36</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.3.8.5.7\">0.89</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.3.8.5.8\">15.76</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T8.11.3.1\" style=\"font-size:90%;\">Table 8</span>: </span><span class=\"ltx_text\" id=\"S4.T8.7.2\" style=\"font-size:90%;\">Automatic evaluation results of the baseline model. Dagger <sup class=\"ltx_sup\" id=\"S4.T8.7.2.1\">\u2020</sup> indicates that the score of T5-base in MultiWOZ2.2 is cited from the evaluation results of TOATOD reported in <cite class=\"ltx_cite ltx_citemacro_citep\">(Bang et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.17319v1#bib.bib1\" title=\"\">2023</a>)</cite>. Double-dagger <sup class=\"ltx_sup\" id=\"S4.T8.7.2.2\">\u2021</sup> indicates that the score of GPT-3.5 in MultiWOZ2.2 is cited from the reported value in <cite class=\"ltx_cite ltx_citemacro_citep\">(Hude\u010dek and Dusek, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.17319v1#bib.bib15\" title=\"\">2023</a>)</cite>.</span></figcaption>\n</figure>",
            "capture": "Table 8: Automatic evaluation results of the baseline model. Dagger \u2020 indicates that the score of T5-base in MultiWOZ2.2 is cited from the evaluation results of TOATOD reported in (Bang et\u00a0al., 2023). Double-dagger \u2021 indicates that the score of GPT-3.5 in MultiWOZ2.2 is cited from the reported value in (Hude\u010dek and Dusek, 2023)."
        },
        "9": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T9\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T9.3\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T9.3.4.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T9.3.4.1.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T9.3.4.1.1.1\" style=\"font-size:90%;\">Model</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" colspan=\"6\" id=\"S4.T9.3.4.1.2\"><span class=\"ltx_text\" id=\"S4.T9.3.4.1.2.1\" style=\"font-size:90%;\">MultiWOZ 2.2</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"6\" id=\"S4.T9.3.4.1.3\"><span class=\"ltx_text\" id=\"S4.T9.3.4.1.3.1\" style=\"font-size:90%;\">JMultiWOZ</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.3.5.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T9.3.5.2.1\"><span class=\"ltx_text\" id=\"S4.T9.3.5.2.1.1\" style=\"font-size:90%;\">N</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T9.3.5.2.2\"><span class=\"ltx_text\" id=\"S4.T9.3.5.2.2.1\" style=\"font-size:90%;\">Success</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T9.3.5.2.3\"><span class=\"ltx_text\" id=\"S4.T9.3.5.2.3.1\" style=\"font-size:90%;\">Turn</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T9.3.5.2.4\"><span class=\"ltx_text\" id=\"S4.T9.3.5.2.4.1\" style=\"font-size:90%;\">Und.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T9.3.5.2.5\"><span class=\"ltx_text\" id=\"S4.T9.3.5.2.5.1\" style=\"font-size:90%;\">App.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\" id=\"S4.T9.3.5.2.6\"><span class=\"ltx_text\" id=\"S4.T9.3.5.2.6.1\" style=\"font-size:90%;\">Sat.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T9.3.5.2.7\"><span class=\"ltx_text\" id=\"S4.T9.3.5.2.7.1\" style=\"font-size:90%;\">N</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T9.3.5.2.8\"><span class=\"ltx_text\" id=\"S4.T9.3.5.2.8.1\" style=\"font-size:90%;\">Success</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T9.3.5.2.9\"><span class=\"ltx_text\" id=\"S4.T9.3.5.2.9.1\" style=\"font-size:90%;\">Turn</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T9.3.5.2.10\"><span class=\"ltx_text\" id=\"S4.T9.3.5.2.10.1\" style=\"font-size:90%;\">Und.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T9.3.5.2.11\"><span class=\"ltx_text\" id=\"S4.T9.3.5.2.11.1\" style=\"font-size:90%;\">App.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T9.3.5.2.12\"><span class=\"ltx_text\" id=\"S4.T9.3.5.2.12.1\" style=\"font-size:90%;\">Sat.</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T9.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T9.1.1.1\">\n<span class=\"ltx_text\" id=\"S4.T9.1.1.1.1\" style=\"font-size:90%;\">T5-base</span><sup class=\"ltx_sup\" id=\"S4.T9.1.1.1.2\"><span class=\"ltx_text\" id=\"S4.T9.1.1.1.2.1\" style=\"font-size:90%;\">\u2020</span></sup>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.2\"><span class=\"ltx_text\" id=\"S4.T9.1.1.2.1\" style=\"font-size:90%;\">36</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.3\"><span class=\"ltx_text\" id=\"S4.T9.1.1.3.1\" style=\"font-size:90%;\">66.67</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.4\"><span class=\"ltx_text\" id=\"S4.T9.1.1.4.1\" style=\"font-size:90%;\">12.56</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.5\"><span class=\"ltx_text\" id=\"S4.T9.1.1.5.1\" style=\"font-size:90%;\">3.83</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.6\"><span class=\"ltx_text\" id=\"S4.T9.1.1.6.1\" style=\"font-size:90%;\">3.81</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T9.1.1.7\"><span class=\"ltx_text\" id=\"S4.T9.1.1.7.1\" style=\"font-size:90%;\">3.72</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.8\"><span class=\"ltx_text\" id=\"S4.T9.1.1.8.1\" style=\"font-size:90%;\">38</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.9\"><span class=\"ltx_text\" id=\"S4.T9.1.1.9.1\" style=\"font-size:90%;\">65.79</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.10\"><span class=\"ltx_text\" id=\"S4.T9.1.1.10.1\" style=\"font-size:90%;\">10.74</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.11\"><span class=\"ltx_text\" id=\"S4.T9.1.1.11.1\" style=\"font-size:90%;\">3.92</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.12\"><span class=\"ltx_text\" id=\"S4.T9.1.1.12.1\" style=\"font-size:90%;\">3.71</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T9.1.1.13\"><span class=\"ltx_text\" id=\"S4.T9.1.1.13.1\" style=\"font-size:90%;\">3.55</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.3.6.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.3.6.1.1\"><span class=\"ltx_text\" id=\"S4.T9.3.6.1.1.1\" style=\"font-size:90%;\">T5-large</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.3.6.1.2\"><span class=\"ltx_text\" id=\"S4.T9.3.6.1.2.1\" style=\"font-size:90%;\">\u2013</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.3.6.1.3\"><span class=\"ltx_text\" id=\"S4.T9.3.6.1.3.1\" style=\"font-size:90%;\">\u2013</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.3.6.1.4\"><span class=\"ltx_text\" id=\"S4.T9.3.6.1.4.1\" style=\"font-size:90%;\">\u2013</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.3.6.1.5\"><span class=\"ltx_text\" id=\"S4.T9.3.6.1.5.1\" style=\"font-size:90%;\">\u2013</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.3.6.1.6\"><span class=\"ltx_text\" id=\"S4.T9.3.6.1.6.1\" style=\"font-size:90%;\">\u2013</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T9.3.6.1.7\"><span class=\"ltx_text\" id=\"S4.T9.3.6.1.7.1\" style=\"font-size:90%;\">\u2013</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.3.6.1.8\"><span class=\"ltx_text\" id=\"S4.T9.3.6.1.8.1\" style=\"font-size:90%;\">40</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.3.6.1.9\"><span class=\"ltx_text\" id=\"S4.T9.3.6.1.9.1\" style=\"font-size:90%;\">75.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.3.6.1.10\"><span class=\"ltx_text\" id=\"S4.T9.3.6.1.10.1\" style=\"font-size:90%;\">10.10</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.3.6.1.11\"><span class=\"ltx_text\" id=\"S4.T9.3.6.1.11.1\" style=\"font-size:90%;\">4.05</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.3.6.1.12\"><span class=\"ltx_text\" id=\"S4.T9.3.6.1.12.1\" style=\"font-size:90%;\">3.98</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.3.6.1.13\"><span class=\"ltx_text\" id=\"S4.T9.3.6.1.13.1\" style=\"font-size:90%;\">3.82</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.2.2.1\">\n<span class=\"ltx_text\" id=\"S4.T9.2.2.1.1\" style=\"font-size:90%;\">GPT-3.5</span><sup class=\"ltx_sup\" id=\"S4.T9.2.2.1.2\"><span class=\"ltx_text\" id=\"S4.T9.2.2.1.2.1\" style=\"font-size:90%;\">\u2020</span></sup>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.2.2.2\"><span class=\"ltx_text\" id=\"S4.T9.2.2.2.1\" style=\"font-size:90%;\">42</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.2.2.3\"><span class=\"ltx_text\" id=\"S4.T9.2.2.3.1\" style=\"font-size:90%;\">57.14</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.2.2.4\"><span class=\"ltx_text\" id=\"S4.T9.2.2.4.1\" style=\"font-size:90%;\">11.55</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.2.2.5\"><span class=\"ltx_text\" id=\"S4.T9.2.2.5.1\" style=\"font-size:90%;\">3.79</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.2.2.6\"><span class=\"ltx_text\" id=\"S4.T9.2.2.6.1\" style=\"font-size:90%;\">3.98</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T9.2.2.7\"><span class=\"ltx_text\" id=\"S4.T9.2.2.7.1\" style=\"font-size:90%;\">4.05</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.2.2.8\"><span class=\"ltx_text\" id=\"S4.T9.2.2.8.1\" style=\"font-size:90%;\">41</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.2.2.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T9.2.2.9.1\" style=\"font-size:90%;\">24.39</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.2.2.10\"><span class=\"ltx_text\" id=\"S4.T9.2.2.10.1\" style=\"font-size:90%;\">11.05</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.2.2.11\"><span class=\"ltx_text\" id=\"S4.T9.2.2.11.1\" style=\"font-size:90%;\">2.90</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.2.2.12\"><span class=\"ltx_text\" id=\"S4.T9.2.2.12.1\" style=\"font-size:90%;\">2.24</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T9.2.2.13\"><span class=\"ltx_text\" id=\"S4.T9.2.2.13.1\" style=\"font-size:90%;\">1.95</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"S4.T9.3.3.1\">\n<span class=\"ltx_text\" id=\"S4.T9.3.3.1.1\" style=\"font-size:90%;\">GPT-4</span><sup class=\"ltx_sup\" id=\"S4.T9.3.3.1.2\"><span class=\"ltx_text\" id=\"S4.T9.3.3.1.2.1\" style=\"font-size:90%;\">\u2020</span></sup>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T9.3.3.2\"><span class=\"ltx_text\" id=\"S4.T9.3.3.2.1\" style=\"font-size:90%;\">42</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T9.3.3.3\"><span class=\"ltx_text\" id=\"S4.T9.3.3.3.1\" style=\"font-size:90%;\">76.19</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T9.3.3.4\"><span class=\"ltx_text\" id=\"S4.T9.3.3.4.1\" style=\"font-size:90%;\">11.88</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T9.3.3.5\"><span class=\"ltx_text\" id=\"S4.T9.3.3.5.1\" style=\"font-size:90%;\">4.26</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T9.3.3.6\"><span class=\"ltx_text\" id=\"S4.T9.3.3.6.1\" style=\"font-size:90%;\">4.36</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S4.T9.3.3.7\"><span class=\"ltx_text\" id=\"S4.T9.3.3.7.1\" style=\"font-size:90%;\">4.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T9.3.3.8\"><span class=\"ltx_text\" id=\"S4.T9.3.3.8.1\" style=\"font-size:90%;\">42</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T9.3.3.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T9.3.3.9.1\" style=\"font-size:90%;\">57.14</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T9.3.3.10\"><span class=\"ltx_text\" id=\"S4.T9.3.3.10.1\" style=\"font-size:90%;\">9.55</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T9.3.3.11\"><span class=\"ltx_text\" id=\"S4.T9.3.3.11.1\" style=\"font-size:90%;\">3.93</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T9.3.3.12\"><span class=\"ltx_text\" id=\"S4.T9.3.3.12.1\" style=\"font-size:90%;\">3.52</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T9.3.3.13\"><span class=\"ltx_text\" id=\"S4.T9.3.3.13.1\" style=\"font-size:90%;\">3.02</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 9: </span>Human evaluation results. \u201cN\u201d indicates the number of participants who interacted with each model. \u201cUnd.\u201d, \u201cApp.\u201d, and \u201cSat.\u201d indicate the worker\u2019s subjective evaluation of the system\u2019s understanding, appropriateness of the system response, and satisfaction with the dialogue, respectively. Dagger <sup class=\"ltx_sup\" id=\"S4.T9.15.1\">\u2020</sup> indicates that the score in MultiWOZ2.2 is cited from the reported value in <cite class=\"ltx_cite ltx_citemacro_citep\">(Iizuka et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.17319v1#bib.bib17\" title=\"\">2023</a>)</cite>.</figcaption>\n</figure>",
            "capture": "Table 9: Human evaluation results. \u201cN\u201d indicates the number of participants who interacted with each model. \u201cUnd.\u201d, \u201cApp.\u201d, and \u201cSat.\u201d indicate the worker\u2019s subjective evaluation of the system\u2019s understanding, appropriateness of the system response, and satisfaction with the dialogue, respectively. Dagger \u2020 indicates that the score in MultiWOZ2.2 is cited from the reported value in (Iizuka et\u00a0al., 2023)."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.17319v1_figure_1.png",
            "caption": "Figure 1: An example of dialogue across two domains: restaurants and taxis. The gray and green message bubbles represent the utterances of the user and the wizard, respectively. The red and blue boxes indicate the annotation of the dialogue state and the database results, respectively. The bubble for each utterance contains both the original Japanese utterance and its English translation by the authors."
        },
        "2": {
            "figure_path": "2403.17319v1_figure_2.png",
            "caption": "Figure 2: Web UI of wizard for dialogue collection: (A): A search form for an entity from the backend database, (B): An interface displaying detailed information about the selected entity and a reservation form for the entity, (C): An interface for chatting with the user."
        },
        "3": {
            "figure_path": "2403.17319v1_figure_3.png",
            "caption": "Figure 3: The distribution of dialogue lengths, divided into dialogues containing only one domain (single-domain) and dialogues containing two or more domains (multi-domain)."
        },
        "4": {
            "figure_path": "2403.17319v1_figure_4.png",
            "caption": "(a) T5 Pipeline (Bang et al., 2023). (1) First, the dialogue state is predicted from the given dialogue context, and (2) the result is added to the input to generate the final response. Both (1) and (2) are performed on the same model."
        },
        "5": {
            "figure_path": "2403.17319v1_figure_5.png",
            "caption": "(b) LLM pipeline (Hude\u010dek and Dusek, 2023) in zero-shot setting. First, (1) the current active domain is estimated from the dialogue context. Next, (2) the dialogue state is tracked, and (3) the response is generated for that domain using a prompt focused on that domain."
        },
        "6": {
            "figure_path": "2403.17319v1_figure_6.png",
            "caption": "(a) Original data in Japanese"
        },
        "7": {
            "figure_path": "2403.17319v1_figure_7.png",
            "caption": "(b) English translation by the authors"
        },
        "8": {
            "figure_path": "2403.17319v1_figure_8.png",
            "caption": "(a) Original data in Japanese"
        },
        "9": {
            "figure_path": "2403.17319v1_figure_9.png",
            "caption": "(b) English translation by the authors"
        },
        "10": {
            "figure_path": "2403.17319v1_figure_10.png",
            "caption": "(a) Original prompt in Japanese"
        },
        "11": {
            "figure_path": "2403.17319v1_figure_11.png",
            "caption": "(b) English translation by the authors"
        },
        "12": {
            "figure_path": "2403.17319v1_figure_12.png",
            "caption": "(a) Original prompt in Japanese"
        },
        "13": {
            "figure_path": "2403.17319v1_figure_13.png",
            "caption": "(b) English translation by the authors"
        }
    },
    "references": [
        {
            "1": {
                "title": "Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System.",
                "author": "Namo Bang, Jeehyun Lee, and Myoung-Wan Koo. 2023.",
                "venue": "In Findings of the Association for Computational Linguistics: ACL 2023, pages 7355\u20137369.",
                "url": "https://doi.org/10.18653/v1/2023.findings-acl.464"
            }
        },
        {
            "2": {
                "title": "MultiWOZ - A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling.",
                "author": "Pawe\u0142 Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, I\u00f1igo Casanueva, Stefan Ultes, Osman Ramadan, and Milica Ga\u0161i\u0107. 2018.",
                "venue": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 5016\u20135026.",
                "url": "https://doi.org/10.18653/v1/D18-1547"
            }
        },
        {
            "3": {
                "title": "Action-Based Conversations Dataset: A Corpus for Building More In-Depth Task-Oriented Dialogue Systems.",
                "author": "Derek Chen, Howard Chen, Yi Yang, Alexander Lin, and Zhou Yu. 2021.",
                "venue": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3002\u20133017.",
                "url": "https://doi.org/10.18653/v1/2021.naacl-main.239"
            }
        },
        {
            "4": {
                "title": "CGoDial: A large-scale benchmark for Chinese goal-oriented dialog evaluation.",
                "author": "Yinpei Dai, Wanwei He, Bowen Li, Yuchuan Wu, Zheng Cao, Zhongqi An, Jian Sun, and Yongbin Li. 2022.",
                "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 4097\u20134111.",
                "url": "https://doi.org/10.18653/v1/2022.emnlp-main.274"
            }
        },
        {
            "5": {
                "title": "GlobalWoZ: Globalizing MultiWoZ to develop multilingual task-oriented dialogue systems.",
                "author": "Bosheng Ding, Junjie Hu, Lidong Bing, Mahani Aljunied, Shafiq Joty, Luo Si, and Chunyan Miao. 2022.",
                "venue": "In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics, pages 1639\u20131657.",
                "url": "https://doi.org/10.18653/v1/2022.acl-long.115"
            }
        },
        {
            "6": {
                "title": "Frames: a corpus for adding memory to goal-oriented dialogue systems.",
                "author": "Layla El Asri, Hannes Schulz, Shikhar Sharma, Jeremie Zumer, Justin Harris, Emery Fine, Rahul Mehrotra, and Kaheer Suleman. 2017.",
                "venue": "In Proceedings of the 18th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 207\u2013219.",
                "url": "https://doi.org/10.18653/v1/W17-5526"
            }
        },
        {
            "7": {
                "title": "MultiWOZ 2.1: A consolidated multi-domain dialogue dataset with state corrections and state tracking baselines.",
                "author": "Mihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi, Sanchit Agarwal, Shuyang Gao, Adarsh Kumar, Anuj Goyal, Peter Ku, and Dilek Hakkani-Tur. 2020.",
                "venue": "In Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 422\u2013428.",
                "url": "https://aclanthology.org/2020.lrec-1.53"
            }
        },
        {
            "8": {
                "title": "Key-value retrieval networks for task-oriented dialogue.",
                "author": "Mihail Eric, Lakshmi Krishnan, Francois Charette, and Christopher D. Manning. 2017.",
                "venue": "In Proceedings of the 18th Annual Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 37\u201349.",
                "url": "https://aclanthology.org/W17-5506"
            }
        },
        {
            "9": {
                "title": "Neural Approaches to Conversational AI.",
                "author": "Jianfeng Gao, Michel Galley, and Lihong Li. 2018.",
                "venue": "In Proceedings of the 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, pages 1371\u20131374.",
                "url": null
            }
        },
        {
            "10": {
                "title": "Self-Contained Utterance Description Corpus for Japanese Dialog.",
                "author": "Yuta Hayashibe. 2022.",
                "venue": "In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 1249\u20131255.",
                "url": null
            }
        },
        {
            "11": {
                "title": "GALAXY: A Generative Pre-trained Model for Task-Oriented Dialog with Semi-supervised Learning and Explicit Policy Injection.",
                "author": "Wanwei He, Yinpei Dai, Yinhe Zheng, Yuchuan Wu, Zheng Cao, Dermot Liu, Peng Jiang, Min Yang, Fei Huang, Luo Si, Jian Sun, and Yongbin Li. 2022.",
                "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence, 10, pages 10749\u201310757.",
                "url": "https://doi.org/10.1609/aaai.v36i10.21320"
            }
        },
        {
            "12": {
                "title": "The Second Dialog State Tracking Challenge.",
                "author": "Matthew Henderson, Blaise Thomson, and Jason D. Williams. 2014.",
                "venue": "In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 263\u2013272.",
                "url": "https://doi.org/10.3115/v1/W14-4337"
            }
        },
        {
            "13": {
                "title": "A simple language model for task-oriented dialogue.",
                "author": "Ehsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih Yavuz, and Richard Socher. 2020.",
                "venue": "In Proceedings of Advances in Neural Information Processing Systems, pages 20179\u201320191.",
                "url": "https://proceedings.neurips.cc/paper/2020/file/e946209592563be0f01c844ab2170f0c-Paper.pdf"
            }
        },
        {
            "14": {
                "title": "Multi 3 WOZ: A multilingual, multi-domain, multi-parallel dataset for training and evaluating culturally adapted task-oriented dialog systems.",
                "author": "Songbo Hu, Han Zhou, Mete Hergul, Milan Gritta, Guchun Zhang, Ignacio Iacobacci, Ivan Vuli\u0107, and Anna Korhonen. 2023.",
                "venue": "Transactions of the Association for Computational Linguistics, pages 1396\u20131415.",
                "url": "https://doi.org/10.1162/tacl_a_00609"
            }
        },
        {
            "15": {
                "title": "Are Large Language Models All You Need for Task-Oriented Dialogue?",
                "author": "Vojt\u011bch Hude\u010dek and Ondrej Dusek. 2023.",
                "venue": "In Proceedings of the 24th Meeting of the Special Interest Group on Discourse and Dialogue, pages 216\u2013228.",
                "url": "https://aclanthology.org/2023.sigdial-1.21"
            }
        },
        {
            "16": {
                "title": "Multi2WOZ: A robust multilingual dataset and conversational pretraining for task-oriented dialog.",
                "author": "Chia-Chien Hung, Anne Lauscher, Ivan Vuli\u0107, Simone Ponzetto, and Goran Glava\u0161. 2022.",
                "venue": "In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3687\u20133703.",
                "url": "https://doi.org/10.18653/v1/2022.naacl-main.270"
            }
        },
        {
            "17": {
                "title": "Clarifying the Dialogue-Level Performance of GPT-3.5 and GPT-4 in Task-Oriented and Non-Task-Oriented Dialogue Systems.",
                "author": "Shinya Iizuka, Shota Mochizuka, Atsumoto Ohashi, Sanae Yamashita, Ao Guo, and Ryuichiro Higashinaka. 2023.",
                "venue": "In Proceedings of AAAI Fall Symposium on Artificial Intelligence for Human-Robot Interaction, pages 182\u2013186.",
                "url": "https://ojs.aaai.org/index.php/AAAI-SS/article/view/27668"
            }
        },
        {
            "18": {
                "title": "An iterative design methodology for user-friendly natural language office information applications.",
                "author": "J. F. Kelley. 1984.",
                "venue": "ACM Transactions on Information Systems, 2:26\u201341.",
                "url": null
            }
        },
        {
            "19": {
                "title": "Leveraging Slot Descriptions for Zero-Shot Cross-Domain Dialogue StateTracking.",
                "author": "Zhaojiang Lin, Bing Liu, Seungwhan Moon, Paul Crook, Zhenpeng Zhou, Zhiguang Wang, Zhou Yu, Andrea Madotto, Eunjoon Cho, and Rajen Subba. 2021a.",
                "venue": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5640\u20135648.",
                "url": "https://doi.org/10.18653/v1/2021.naacl-main.448"
            }
        },
        {
            "20": {
                "title": "BiTOD: A bilingual multi-domain dataset for task-oriented dialogue modeling.",
                "author": "Zhaojiang Lin, Andrea Madotto, Genta Indra Winata, Peng Xu, Feijun Jiang, Yuxiang Hu, Chen Shi, and Pascale Fung. 2021b.",
                "venue": "arXiv preprint arXiv:2106.02787.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Decoupled weight decay regularization.",
                "author": "Ilya Loshchilov and Frank Hutter. 2019.",
                "venue": "In International Conference on Learning Representations.",
                "url": "https://openreview.net/forum?id=Bkg6RiCqY7"
            }
        },
        {
            "22": {
                "title": "Cross-Lingual Dialogue Dataset Creation via Outline-Based Generation.",
                "author": "Olga Majewska, Evgeniia Razumovskaia, Edoardo M. Ponti, Ivan Vuli\u0107, and Anna Korhonen. 2023.",
                "venue": "Transactions of the Association for Computational Linguistics, pages 139\u2013156.",
                "url": "https://doi.org/10.1162/tacl_a_00539"
            }
        },
        {
            "23": {
                "title": "STAR: A Schema-Guided Dialog Dataset for Transfer Learning.",
                "author": "Johannes EM Mosig, Shikib Mehri, and Thomas Kober. 2020.",
                "venue": "arXiv preprint arXiv:2010.11853.",
                "url": null
            }
        },
        {
            "24": {
                "title": "GPT-4 Technical Report.",
                "author": "OpenAI. 2023.",
                "venue": "ArXiv, abs/2303.08774.",
                "url": "https://api.semanticscholar.org/CorpusID:257532815"
            }
        },
        {
            "25": {
                "title": "RiSAWOZ: A large-scale multi-domain Wizard-of-Oz dataset with rich semantic annotations for task-oriented dialogue modeling.",
                "author": "Jun Quan, Shian Zhang, Qian Cao, Zizhong Li, and Deyi Xiong. 2020.",
                "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 930\u2013940.",
                "url": "https://doi.org/10.18653/v1/2020.emnlp-main.67"
            }
        },
        {
            "26": {
                "title": "Exploring the limits of transfer learning with a unified text-to-text transformer.",
                "author": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020.",
                "venue": "Journal of Machine Learning Research, pages 1\u201367.",
                "url": "http://jmlr.org/papers/v21/20-074.html"
            }
        },
        {
            "27": {
                "title": "Prompting, retrieval, training: An exploration of different approaches for task-oriented dialogue generation.",
                "author": "Gon\u00e7alo Raposo, Luisa Coheur, and Bruno Martins. 2023.",
                "venue": "In Proceedings of the 24th Meeting of the Special Interest Group on Discourse and Dialogue, pages 400\u2013412.",
                "url": "https://aclanthology.org/2023.sigdial-1.37"
            }
        },
        {
            "28": {
                "title": "Towards Scalable Multi-Domain Conversational Agents: The Schema-Guided Dialogue Dataset.",
                "author": "Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, and Pranav Khaitan. 2020.",
                "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 8689\u20138696.",
                "url": "https://doi.org/10.1609/aaai.v34i05.6394"
            }
        },
        {
            "29": {
                "title": "Building a Conversational Agent Overnight with Dialogue Self-Play.",
                "author": "Pararth Shah, Dilek Hakkani-T\u00fcr, Gokhan T\u00fcr, Abhinav Rastogi, Ankur Bapna, Neha Nayak, and Larry Heck. 2018.",
                "venue": "arXiv preprint arXiv:1801.04871.",
                "url": null
            }
        },
        {
            "30": {
                "title": "Multi-task pre-training for plug-and-play task-oriented dialogue system.",
                "author": "Yixuan Su, Lei Shu, Elman Mansimov, Arshit Gupta, Deng Cai, Yi-An Lai, and Yi Zhang. 2022.",
                "venue": "In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics, pages 4661\u20134676.",
                "url": "https://doi.org/10.18653/v1/2022.acl-long.319"
            }
        },
        {
            "31": {
                "title": "Gemini: a family of highly capable multimodal models.",
                "author": "Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. 2023.",
                "venue": "arXiv preprint arXiv:2312.11805.",
                "url": null
            }
        },
        {
            "32": {
                "title": "A Network-based End-to-End Trainable Task-oriented Dialogue System.",
                "author": "Tsung-Hsien Wen, David Vandyke, Nikola Mrk\u0161i\u0107, Milica Ga\u0161i\u0107, Lina M. Rojas-Barahona, Pei-Hao Su, Stefan Ultes, and Steve Young. 2017.",
                "venue": "In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, pages 438\u2013449.",
                "url": "https://aclanthology.org/E17-1042"
            }
        },
        {
            "33": {
                "title": "MultiWOZ 2.2 : A dialogue dataset with additional annotation corrections and state tracking baselines.",
                "author": "Xiaoxue Zang, Abhinav Rastogi, Srinivas Sunkara, Raghav Gupta, Jianguo Zhang, and Jindong Chen. 2020.",
                "venue": "In Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI, pages 109\u2013117.",
                "url": "https://doi.org/10.18653/v1/2020.nlp4convai-1.13"
            }
        },
        {
            "34": {
                "title": "Task-Oriented Dialog Systems That Consider Multiple Appropriate Responses under the Same Context.",
                "author": "Yichi Zhang, Zhijian Ou, and Zhou Yu. 2020a.",
                "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence, pages 9604\u20139611.",
                "url": "https://doi.org/10.1609/aaai.v34i05.6507"
            }
        },
        {
            "35": {
                "title": "Recent advances and challenges in task-oriented dialog systems.",
                "author": "Zheng Zhang, Ryuichi Takanobu, Qi Zhu, MinLie Huang, and XiaoYan Zhu. 2020b.",
                "venue": "Science China Technological Sciences, pages 1\u201317.",
                "url": null
            }
        },
        {
            "36": {
                "title": "CrossWOZ: A large-scale Chinese cross-domain task-oriented dialogue dataset.",
                "author": "Qi Zhu, Kaili Huang, Zheng Zhang, Xiaoyan Zhu, and Minlie Huang. 2020.",
                "venue": "Transactions of the Association for Computational Linguistics, 8:281\u2013295.",
                "url": "https://doi.org/10.1162/tacl_a_00314"
            }
        },
        {
            "37": {
                "title": "AllWOZ: Towards Multilingual Task-Oriented Dialog Systems for All.",
                "author": "Lei Zuo, Kun Qian, Bowen Yang, and Zhou Yu. 2021.",
                "venue": "arXiv preprint arXiv:2112.08333.",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.17319v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.1",
            "2.2"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3",
            "3.4",
            "3.5"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4",
            "5.1",
            "5.2"
        ]
    },
    "research_context": {
        "paper_id": "2403.17319v1",
        "paper_title": "JMultiWOZ: A Large-Scale Japanese Multi-Domain Task-Oriented Dialogue Dataset",
        "research_background": "### Motivation\nThe motivation for this paper stems from the need for comprehensive task-oriented dialogue datasets in languages other than English and Chinese, specifically focusing on Japanese. Although task-oriented dialogue systems and datasets in English have seen significant developments, and Chinese has also seen large-scale datasets emerge, Japanese has been underrepresented in this research area due to the high cost and complexity associated with creating such corpora. Hence, the authors aim to fill this gap by constructing a Japanese multi-domain task-oriented dialogue dataset to spur research and development in Japanese task-oriented dialogue systems.\n\n### Research Problem\nThe research problem addressed by the paper is the lack of large-scale, multi-domain task-oriented dialogue datasets in Japanese, which hinders the development and evaluation of robust task-oriented dialogue systems for the Japanese language. This scarcity limits the progress and application of such systems in Japanese-speaking regions.\n\n### Relevant Prior Work\nRelevant prior work includes the development of task-oriented dialogue systems using deep learning methods, which have significantly improved task completion performance (Gao et al., 2018; Zhang et al., 2020b). Several single-domain task-oriented dialogue datasets in English have been developed, such as those by Henderson et al. (2014), Wen et al. (2017), Eric et al. (2017), and Shah et al. (2018). MultiWOZ is highlighted as a significant achievement in multi-domain dialogue datasets covering seven domains, which has paved the way for further research and development (Budzianowski et al., 2018).\n\nSubsequent large-scale dialogue datasets have been created in multiple languages (Rastogi et al., 2020; Mosig et al., 2020; Chen et al., 2021). For Chinese, notable datasets such as CrossWOZ (Zhu et al., 2020) and others (Quan et al., 2020; Dai et al., 2022) have contributed to research advancements. However, outside English and Chinese, there is a relative scarcity of multi-domain task-oriented dialogue corpora (Hung et al., 2022), which this paper aims to address for the Japanese language.\n\n### Contributions\n- JMultiWOZ: The construction of the first large-scale Japanese multi-domain task-oriented dialogue dataset.\n- Benchmarking: Evaluation of the dataset using state-of-the-art (SOTA) methods and the latest large language models (LLMs) for dialogue state tracking (DST) and response generation (RG).\n- Human Evaluation: An empirical assessment of the end-to-end dialogue capabilities of these models with human participants, demonstrating the current challenges and limitations in task-oriented dialogue for Japanese even with advanced LLMs.",
        "methodology": "**Methodology:**\n\n**JMultiWOZ: A Large-Scale Japanese Multi-Domain Task-Oriented Dialogue Dataset**\n\n**Overview:**\nJMultiWOZ is a comprehensive corpus designed for dialogues involving travelers planning trips to nine Japanese cities: Sapporo, Sendai, Tokyo, Yokohama, Nagoya, Kyoto, Osaka, Fukuoka, and Naha. The dataset encompasses six domains: tourist attractions, accommodations, restaurants, shopping facilities, taxis, and weather.\n\n**Dialogue Collection Process:**\n1. **Ontology Definition:**\n   The first step involves defining the ontology, which lays out the framework and parameters for the dialogues, including the slots and values relevant to each domain.\n\n2. **Backend Database Construction:**\n   A database is built to assist the wizard in obtaining accurate travel information. This database includes details that match user constraints and requests.\n\n3. **User Goal Design and Creation:**\n   User goals are crafted, formatted from template sentences that describe each slot. The user\u2019s role is to communicate the informable slots and request information about the requestable slots, potentially making bookings based on the provided slots.\n\n4. **Dialogue Collection Using the WOZ Method:**\n   - **Roles:** Dialogues are conducted by two human interlocutors: a traveler (user) and an information provider (wizard).\n   - **Wizard Interface:** The wizard uses a web UI to search for entities based on user criteria, check detailed information, make reservations, and chat with the user. The interaction includes recording the database search queries (DB queries) input by the wizard in each turn.\n   \n5. **Annotation of the Full Dialogue State:**\n   Annotation ensures the dialogue state is consistent across turns. Special emphasis is laid on preventing inconsistencies in slot value notation identified in previous studies.\n\n**Quality Control Measures:**\n- **Dropdown Menus for Input Values:** Wizards use dropdown menus for DB queries to avoid manual entry errors.\n- **Practice Dialogues for Wizards:** Each wizard undergoes 3-5 practice dialogues, receiving feedback from the authors until no significant issues are identified.\n- **Post-Dialogue Review:** Dialogues are reviewed through two main procedures:\n  1. **Questionnaires:** At the end of each dialogue, workers complete questionnaires to report any issues, which are manually reviewed. Dialogues with major errors are removed.\n  2. **DB Query Verification:** Dialogues where the final DB query does not match the user\u2019s informable slots are deleted.\n\n**Corpus Statistics:**\nAfter these quality control procedures, the dataset contains 4,246 dialogues, broken down into:\n- **Train Set:** 3,646 dialogues\n- **Dev Set:** 300 dialogues\n- **Test Set:** 300 dialogues.\n\nThrough this meticulous process, JMultiWOZ aims to provide a high-quality, consistent dataset for multi-domain task-oriented dialogue modeling in Japanese.",
        "main_experiment_and_results": "### Main Experiment Setup and Results:\n\nJMultiWOZ provides benchmarks for dialogue state tracking (DST) and response generation (RG) to show its effectiveness in the Japanese context, similar to English dialogue corpora. The evaluation uses state-of-the-art (SOTA) methods from MultiWOZ2.2 (corrected for various annotation errors) and latest LLM-based methods.\n\n#### Datasets:\n- **JMultiWOZ**: A large-scale Japanese multi-domain task-oriented dialogue dataset.\n- **MultiWOZ2.2**: An English dialogue corpus used as a reference benchmark.\n\n#### Baselines:\n1. **T5-based model TOATOD**:\n   - **Backbone models**: T5-base and T5-large, pretrained on Japanese data since task-oriented dialogue corpora in Japanese do not exist.\n   - **Training**:\n     - Batch size: 32\n     - Epochs: 5\n     - Optimizer: AdamW\n     - Learning rate: Initially set to 5e-5, linearly decayed\n     - Checkpoints: Evaluation uses the final step checkpoint.\n     - Inference method: Greedy search for both DST and RG.\n   \n2. **LLM-based zero-/few-shot response generation**:\n   - **LLMs**: OpenAI's GPT-3.5 (gpt-3.5-turbo) and GPT-4.\n   - **Pipeline**:\n     - Zero-shot: LLM estimates the active domain, then the dialogue state, searches the DB, and generates the final response.\n     - Few-shot: Adds two retrieved examples from the train set to each prompt based on dialogue context similarity.\n   - **Embedding vectors**: Created using Japanese sentence-transformers on two consecutive turns of utterances (cl-nagoya/sup-simcse-ja-large).\n   - **Training examples**: See Section B in the Appendix for prompt examples.\n\n#### Evaluation Metrics:\n- **DST**: Based on accuracy of dialogue state estimation at each turn.\n- **RG**: Based on the quality of the generated system response from dialogue context.\n\n#### Main Experimental Results:\n- The T5-based model (TOATOD) and LLM-based methods were able to use the JMultiWOZ dataset to produce comprehensive results.\n- **T5 Performance**: \n  - Both T5-base and T5-large models showed effective learning during fine-tuning.\n  - The models performed DST and RG by learning the mappings of ground truth inputs and outputs using maximum likelihood estimation (MLE).\n  - Each step involved combining the context and dialogue state with DB search results to produce the final responses.\n  \n- **LLM Performance**:\n  - GPT-3.5 and GPT-4 were used for the zero-/few-shot response generation.\n  - Both models demonstrated high performance in both DST and RG tasks.\n  - GPT-4, known for its high capabilities in Japanese, showed particularly strong results, guided by Japanese prompts adapted from prior research.\n\nOverall, the results affirm that JMultiWOZ can provide benchmarks comparable to those in existing English dialogue datasets, optimized for Japanese language settings."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To evaluate the dialogue state tracking and response generation capabilities of state-of-the-art methods using JMultiWOZ compared to MultiWOZ2.2, and to assess the performance of LLM-based methods in Japanese.",
            "experiment_process": "The evaluation consisted of two tasks: dialogue state tracking (DST) and response generation (RG). For the SFT-based evaluation, the T5-based model TOATOD, which is the SOTA model in MultiWOZ2.2, was used. T5-base/large pretrained on Japanese data were the backbone models. The model was trained with a batch size of 32 for five epochs using the AdamW optimizer with a learning rate starting at 5e-5. For the zero-/few-shot response generation pipeline, GPT-3.5 and GPT-4 were used, where the LLM estimates the active domain, dialogue state, and generates the final response based on DB search results. Japanese prompts were created based on those used in previous studies.",
            "result_discussion": "The results showed no significant difference in success rates for T5-base/large compared to T5-base (TOATOD) on MultiWOZ2.2, indicating that JMultiWOZ supports the development of high-performance Japanese dialogue models. However, the performance of LLM-based models, namely GPT-3.5 and GPT-4, declined significantly compared to their performance on MultiWOZ2.2, likely due to the models' limitations in handling dynamic dialogue contexts in Japanese. This highlights the need for improved multilingual resources.",
            "ablation_id": "2403.17319v1.No1"
        },
        {
            "research_objective": "To assess the end-to-end dialogue performance of TOATOD and LLM pipeline models using crowdsourcing, comparing their performance in achieving user goals and various qualitative metrics.",
            "experiment_process": "Crowd workers were given dialogue instructions and random user goals from the test set, engaging in dialogues with one of four models for a maximum of 20 turns. Workers judged goal achievement and evaluated system language understanding, response appropriateness, and overall satisfaction on a 5-point scale. Each worker interacted with only one system.",
            "result_discussion": "The evaluation revealed that T5-based models on JMultiWOZ performed comparably to those on MultiWOZ2.2 in terms of success rates. However, LLM models (GPT-3.5 and GPT-4) performed worse on JMultiWOZ, likely due to propagation of errors in dialogue states and system responses over multiple turns. This suggests the need for better handling of dynamically changing contexts in non-English systems, and highlights the potential of JMultiWOZ to contribute to enhancing multilingual dialogue systems.",
            "ablation_id": "2403.17319v1.No2"
        }
    ]
}