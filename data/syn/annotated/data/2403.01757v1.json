{
    "title": "How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems",
    "abstract": "Recently, large language models (LLMs) have notably positioned them as capable tools for addressing complex optimization challenges. Despite this recognition, a predominant limitation of existing LLM-based optimization methods is their struggle to capture the relationships among decision variables when relying exclusively on numerical text prompts, especially in high-dimensional problems. Keeping this in mind, we first propose to enhance the optimization performance using multimodal LLM capable of processing both textual and visual prompts for deeper insights of the processed optimization problem. This integration allows for a more comprehensive understanding of optimization problems, akin to human cognitive processes. We have developed a multimodal LLM-based optimization framework that simulates human problem-solving workflows, thereby offering a more nuanced and effective analysis. The efficacy of this method is evaluated through extensive empirical studies focused on a well-known combinatorial optimization problem, i.e., capacitated vehicle routing problem. The results are compared against those obtained from the LLM-based optimization algorithms that rely solely on textual prompts, demonstrating the significant advantages of our multimodal approach.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Optimization problems arise in various domains, such as supply chain management Cox (1999  ###reference_b5###), logistics Pfohl (2010  ###reference_b14###), engineering Deb (2012  ###reference_b7###), and machine learning Sra et al. (2012  ###reference_b18###). These problems are typically solved by traditional heuristic search methods, such as evolutionary algorithm Yu and Gen (2010  ###reference_b22###), ant colony algorithm Blum (2005  ###reference_b2###), simulated annealing Bertsimas and\nTsitsiklis (1993  ###reference_b1###), and so on. Despite the success of these algorithms on various optimization problems, the no free lunch theory Wolpert and Macready (1997  ###reference_b20###) indicates that their operators are not universally effective, which means that they may perform poorly on newly arrived problems. Moreover, developing new algorithms for novel problems entails a rigorous and laborious process, which often requires much expert knowledge. Hence, it would be advantageous to have a more intelligent optimization engine, which can automatically acquire the features of the optimization problem and adopt suitable search strategies to enhance the search performance.\nVery recently, large language models (LLMs) have emerged as a powerful technique for natural language understanding and generation Bubeck et al. (2023  ###reference_b4###), as well as for other modalities such as images and videos Bubeck et al. (2023  ###reference_b4###); Huang et al. (2023  ###reference_b9###). By processing massive amounts of data and learning from diverse sources of information, LLMs are capable of performing various tasks across domains. Additionally, LLMs can be conveniently accessed and queried by using natural language prompts, which renders them attractive for users who lack familiarity with formal languages or programming. Inspired by these benefits, some efforts have been made to investigate the use of LLMs as optimizers, where the optimization problem is expressed in natural language and the LLM produces optimization solutions according to the prompts. For instance, Yang et al. introduced Optimization by PROmpting (OPRO) that exploits LLMs to solve optimization problems Yang et al. (2023  ###reference_b21###). Li et al. developed OptiGuide that uses LLMs to provide insights and guidance for supply chain optimization Li et al. (2023  ###reference_b11###). Liu et al. proposed a novel framework that combines LLMs and evolutionary algorithms to solve multi-objective optimization problemsLiu et al. (2023  ###reference_b12###). Moreover, Cummins et al. used LLMs to generate compiler optimization sequences Cummins et al. (2023  ###reference_b6###). Pluhacek et al. leveraged LLMs to generate novel meta-heuristic optimization algorithms that can adapt to different problem domains Pluhacek et al. (2023  ###reference_b15###). Romera et al. showed that LLMs can discover new mathematical theorems and proofs from natural language descriptions of mathematical problems Romera-Paredes et al. (2023  ###reference_b16###). These works demonstrate the remarkable ability of LLMs to learn from natural language and generate optimization solutions across different domains.\nHowever, most existing LLM-based optimization methods adopt numerical text prompts to model the optimization problem, which restricts the LLMs\u2019 ability to capture the relationships between the decision variables. As the number of decision variables grows, the text prompts become longer and more complicated, which further impairs the problem representation and diminishes the performance of the LLMs. Nevertheless, the optimization problems in real-world frequently involve multiple forms of representation. For example, capacitated vehicle routing problem (CVRP) can be represented by text to show the information of each customer node, or by image to visualize the layout of the nodes.\nKeeping the above in mind, we propose to use multimodal LLM (MLLM) for optimization, which can handle both textual and visual inputs for enhanced optimization performance. MLLMs leverage the complementary information from various modalities and offer more rich and expressive representations of the optimization problem at hand. In this work, we present a MLLM-based optimization framework, where the optimization problem is represented by a mix of textual and visual prompts, and the LLM generates optimization solutions based on both modalities. To evaluate the performance of the proposed method, the framework is applied to a well-known combinatorial optimization problem, i.e., CVRP, which entails assigning a set of customers to a fleet of vehicles with limited capacity, while minimizing the total traveling distance. Furthermore, We compare our method with the LLM-based optimization algorithm that uses only text input, and demonstrate that our method outperforms it in terms of solution quality. The main contributions of this paper are outlined as follows:\nThe proposed method incorporates both textual and visual prompts simultaneously to facilitate the comprehensive understanding of optimization problems and further improve optimization performance. To the best of our knowledge, this is the first multi-modal solution for optimization.\nA novel XML text prompt is proposed in this work for the optimization problem, which allows the MLLM model to capture more precise relationships among the decision variables.\nWith the assistance of LLM, the framework of MLLM has been specially designed to emulate the workflow of human beings in solving optimization problems. This endows MLLM with enhanced generalization capabilities, enabling its application to various optimization problems that can benefit from the introduction of graphical illustrations.\nUsing a well-known combinatorial optimization problem, CVRP, we evaluate our proposed framework that exploits both textual and visual inputs, and compare it with the ones that use only textual inputs.\nThe rest of the paper is organized as follows. The CVRP is introduced in Section 2 as a case study to assess the optimization efficacy of MLLM. The application of LLM to optimization problems is also surveyed in this section Furthermore, section 3 describes the proposed optimization framework based on MLLM. Subsequently, section 4 reports and analyzes the experimental outcomes of our method. Lastly, section 5 summarizes the paper and outlines the directions for future work."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Background",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Capacitated Vehicle Routing Problem",
            "text": "CVRP is a well-known combinatorial optimization problem that entails finding the optimal routes for a fleet of vehicles to serve a given set of customers (i.e., nodes) subject to the constraint of vehicle capacity Toth and Vigo (2014  ###reference_b19###). The CVRP and its variants have numerous applications in various domains, such as smart logistics Sajid et al. (2021  ###reference_b17###) and distributing medical supplies for emergencies Zheng et al. (2023  ###reference_b23###). Mathematically, let  be an undirected connection graph for a CVRP, where  and  denote the sets of edges and customers, respectively, and  is the demand set of customers. Given  vehicles of capacity , the objective of the CVRP is to find a set of routes , each originating and terminating at a depot , where the vehicles are stationed, such that:\nEvery customer  is served by exactly one vehicle and served only once.\nTotal demand of the customers on each route does not exceed the vehicle capacity: .\nThe sum of the distances of all the routes is minimized.\nAs shown in Fig. 1  ###reference_###, an optimal solution for a CVRP instance depends largely on the spatial distribution of customers. This motivates us to introduce the MLLM to handle both textual and visual inputs, and thus gain a deeper understanding of the problems require to solve.\n###figure_1###"
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Literature Review",
            "text": "Despite the LLMs have been applied to various problems in human beings\u2019 daily life, the study on using LLMs for optimization remains nascent. Existing LLM-assisted optimization methods can be briefly divided into two classes. The first class is to use LLMs as black-box optimizers that can generate new solutions from a numerical textual prompt, which contains the current solutions and their fitness values. For instance, OPRO Yang et al. (2023  ###reference_b21###) employed LLMs to solve optimization problems without gradients. OptiGuide Li et al. (2023  ###reference_b11###) leveraged LLMs to offer insights and guidance for supply chain optimization. Moreover, Meyerson et al. Meyerson et al. (2023  ###reference_b13###) devised Language Model Crossover, a simple technique to evolve semantically-rich text representations for various domains. Brownlee et al. Brownlee et al. (2023  ###reference_b3###) assessed the use of LLMs as mutation operators to enhance the search process. However, since these methods use numerical prompts to guide the LLMs, they have difficulty in handling the complex relationships between decision variables, which thus hinders the LLMs\u2019 optimization efficacy on broader scopes with larger scales.\nOn the other hand, the second class is to use LLMs as meta-heuristics that can design novel functions or heuristics for solving complex problems, by leveraging their natural language processing abilities. In particular, Guo et al. Guo et al. (2023  ###reference_b8###) used LLMs to optimize the hyperparameters of gradient-based methods, such as learning rate, momentum, and weight decay. Cummins et al. Cummins et al. (2023  ###reference_b6###) introduced LLMs to generate compiler optimization sequences that outperform human experts and state-of-the-art methods. Pluhacek et al. Pluhacek et al. (2023  ###reference_b15###) leveraged LLMs to generate novel meta-heuristic optimization algorithms that can adapt to different problem domains. Moreover, FunsearchRomera-Paredes et al. (2023  ###reference_b16###) employed LLMs to discover new mathematical functions that surpass human performance. However, the LLMs employed in these studies are solely prompted with textual data, which might hinder their ability to grasp the intricacies and nuances of the problem domain.\nBearing the above in mind, we first present a new framework that uses MLLM to help solve optimization problems, which can take advantage of both visual and textual information."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Multimodal LLM for Optimization",
            "text": "In this section, we present our optimization framework based on MLLMs, which is a general approach that mirrors the nuanced steps inherent in human problem-solving methodologies applied to complex optimization scenarios. The entire workflow has been depicted in Fig .2  ###reference_###. As can be observed, the framework encompasses three pivotal steps: 1) heuristic extraction from solved problems; 2) solution generation via learned heuristics; and 3) solution evaluation and refinement. In what follows, the details for each step are provided.\n###figure_2###"
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Solution Generation via learned heuristics",
            "text": "The second step of our proposed framework is to generate a preliminary solution via MLLM by applying the heuristics learned from the previous observations. To this end, we use MLLM again, but with a different input and output format. Particularly, we prompt the MLLM with the description of the problem to solve, which consists of the textual and visual prompts, without the optimal solution (the \u201cSolution\u201d in the XML text and the sub-figure \u201cB\u201d are removed). The MLLM is then expected to generate an initial solution in the form of an XML document, which contains only the \u201cSolution\u201d tag with the traveling routes. The heuristics assist the MLLM in generating the initial solution by providing it with guidance from the historical chats. However, the MLLM is not restricted by these historically derived heuristics, and it can also investigate new possibilities and produce novel solutions by applying its own knowledge. An example of this step has been provided in what follows. As can be observed, the prompts indicate that the MLLM should produce a brief and accurate routing solution that covers all the customers.\nNow you are presented with the unsolved CVRPs with the description of XML text (without SOLUTION{}/SOLUTION) and topological layout picture (without the figure of optimal traveling routes)\u2026\nCVRP name={} n_customer={} capacity={}\nDepot\u2026/Depot\nCustomers\u2026/Customers\n/CVRP\nKindly return me the complete preliminary solution of \u2026in XML format, adhering to the heuristics that you have previously acquired.\nNo Explanation Needed."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Solution Evaluation and Refinement",
            "text": "The third final step of the proposed framework is to evaluate and revise the solution produced by the MLLM based on the MLLM\u2019s response. As a generative model that relies on probabilistic inference, MLLM cannot guarantee the correctness and completeness of the routing solution it produces, particularly when the problem dimensionality increases. Hence, we iteratively guide the MLLM to correct the invalid result by supplying the errors detected in the solution. More specifically, after obtaining the generated solution from the MLLM using its learned heuristics, the solution will be passed to a validation function that verifies the customer IDs in the solution. The validation component will detect for the following errors: missing customer IDs, repeated customer IDs, and customer IDs that should not be in the solution. It then returns the invalid solution to the MLLM with the error prompts to assist the MLLM in correcting the solution. Once the MLLM produces a solution with valid customer IDs for each route, we use the \u201cRepair\u201d operator to adjust the routes in case of capacity violation. This operator may create additional routes for serving the extra customers. We provide an example of this step in the following:\nYour routing solution is invalid. To return valid routes, refine the ones below by removing duplicate customer IDs and adding missing ones:\nSOLUTION\nroute id=1\u2026[1,3,7,9,9]/route\nroute id=2\u2026[2,4,6,8,10,11]/route\n\u2026\n/SOLUTION\nThe duplicated customer IDs are given by: [9], the missed customer IDs are given by: [5], and the customer IDs which should not appear are given by: [11]\nPlease remove the duplicated IDs and the IDs should not appear, and add the missed IDs to the route with minimum customers\nNo Explanations Needed\nMoreover, to facilitate the complete grasp of this study, an exhaustive illustration of chats is attached to the document as a reference."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experimental Study",
            "text": "In this study, we propose a novel framework for solving the CVRP, which is a challenging combinatorial optimization problem with many real-world applications. To test the effectiveness of our proposed method, we use a set of widely adopted CVRP benchmarks111https://vrp.atd-lab.inf.puc-rio.br/index.php/en/ that vary in customer size and vertex layout. Specifically, we classify these benchmarks into two categories: small-scale problems with up to 50 nodes and large-scale problems with around 160 nodes. Additionally, we leverage three CVRPs with known optimal solutions, namely \u201cA-n45-k6\u201d, \u201cP-n60-k10\u201d and \u201cE-n101-k14\u201d, as knowledge prompts to facilitate the learning and reasoning process of the proposed method.\nThe problem properties of each CVRP instance have been tabulated in Table 1  ###reference_###, where \u201c\u201d, \u201c\u201d and \u201cCapacity\u201d denote the number of vertexes (depot involved), the number of vehicles and the capacity of each vehicle, respectively. To demonstrate the superiority of our proposed framework (namely MLLM-V), comparative analysis has been conducted against the baseline that solely relies on textual prompts (namely MLLM-T). It should be noted that, both methods employ a same multimodal language model, namely GPT-4-vision-preview, without any further fine-tuning. The only difference between MLLM-V and MLLM-T lies in the use of visual prompts and their corresponding descriptions."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Results",
            "text": "In this section, we present the results of our numerical experiments, where the performance of our proposed MLLM-V method is compared with the MLLM-T method on a set of representative CVRP benchmarks. Table 2  ###reference_### summarizes the results of both methods, where the lowest cost () and the average cost () over 5 runs for each problem are reported. In addition, the best-known lowest traveling cost of each CVRP instance is also shown via \u201cOptimal\u201d for reference. The \u201c\u201d measures the difference between the gained result against the optimal solution, which is calculated via , where  and  denote the obtained average traveling cost and the lowest traveling cost, respectively. Superior results gained by our proposed MLLM-V and the baseline MLLM-T have been highlighted using bold font.\nAs can be observed from the table, MLLM-V achieves better results than MLLM-T on most of the CVRP instances. For instance, the average traveling costs attained by the proposed MLLM-V method on the \u201cP-n19-k2\u201d and \u201cA-n44-k6\u201d problems were 260 and 1445, respectively, exceeding the optimal solution of the MLLM-T method on these cases. This indicates that the utilization of visual prompts and their descriptions can significantly enhance the learning and optimization capabilities of the MLLM, resulting in more effective and efficient vehicle routing. Furthermore, by leveraging the rich multimodal information accessible from maps, traffic data, and other resources, MLLM-V can unveil new prospects for tackling challenging optimization problems with a handful of observations from similar solved problems, which is intractable to conventional machine learning methods.\n###figure_3### ###figure_4### ###figure_5### ###figure_6### To illustrate the differences between the optimization framework based on MLLM-V and MLLM-T, we compare the traveling routes for \u201cP-n19-k2\u201d generated by random method, MLLM-T with text prompt only and our proposed MLLM-T with both textual and visual prompts in Fig. 3  ###reference_###. Furthermore, the optimal traveling routes of \u201cP-n19-k2\u201d are also provide for reference. As can be observed from Fig. 3  ###reference_###, the optimal traveling routes (a) are concise and efficient paths connecting all points with minimal overlap and distance covered. In contrast, the randomly generated routes (b) exhibit a chaotic pattern with excessive overlaps, resulting in inefficient paths. The MLLM-T with text prompt only shows improvements over the random method but still has room for optimization as some overlaps occur. When we employ the MLLM-V that incorporates both textual and visual prompts (d) for vehicle routing, there is a noticeable enhancement in the optimization of traveling routes. As can be observed, the paths are more coherent, with reduced overlaps and structures more akin to the optimal routes. This reveals the efficacy of MLLM in enhancing optimization processes by leveraging both textual and visual data to generate more effective and efficient routing solutions.\nMoreover, we have conducted a further investigation on the route construction processes for the \u201cP-n19-k2\u201d instance. The MLLM-T\u2019s response is given below:\n- Route 1: The route starts with customer 1 as it is one of the nearest customers to the depot. The vehicle then serves customers 10, 4, 11, 14, and 12 in sequence, following the principle of proximity and creating a path that leads away from the depot towards the top of the map. The vehicle then continues to customers 3, 8, and 16, which form a natural cluster in the top right corner. Finally, the vehicle visits customer 17, which is a bit further away but still in the same general direction, before heading back to the depot. The entire route forms a convex shape that encompasses the northern customers.\n- Route 2: This route begins with customer 2, which is the closest to the depot among the remaining customers. The vehicle then visits customers 7, 5, and 18, which are all relatively close to each other and the depot, forming a small loop. Next, the vehicle heads to customer 6, which is a bit further but still on the way to customers 13 and 15, which are the farthest in this route. The vehicle serves customer 9 last before returning to the depot as it is the most easterly customer and forms a convex polygon when connected with the previous customers and the depot.\nThe MLLM-V\u2019s routes construction process for the same instance is given below:\n-Route 1: The route begins with customer 1, who is nearest to the depot. From there, the vehicle serves customer 10, following the principle of proximity, and continues to customer 4, which forms a line segment with the previous customers. The route then extends to customers 11, 14, and 12, which are all located in the upper part of the map, close to each other. The vehicle then moves to the right, serving customer 3, and continues to 8, 16, and finally 17, which are all in close proximity, forming an almost convex shape. This route utilizes the vehicle\u2019s capacity well, with a total demand of 158, just below the capacity limit of 160.\n-Route 2: This route starts with customer 2, who is relatively close to the depot but on the right side. The vehicle then serves customer 7, followed by 9, which are both nearby. The route extends to customer 15, who is further to the right, and then to 13, which is on the bottom right corner of the map. The vehicle then serves customer 5 and heads back towards the depot, stopping at customer 18 and finally at 6, which is close to the depot. This route also makes good use of the vehicle\u2019s capacity, with a total demand of 150, and covers customers in the lower and right-hand side of the map, ensuring that the vehicle\u2019s path is compact and efficient.\nAs can be observed from the two responses, both methods (even without vertex distribution layout picture) can remember the accurate orientation of the vertexes in the first route. However, the MLLM-T failed to remember the orientation of the vertexes in the second route, thus resulting in a bad solution. In contrast, the MLLM-V can remember the accurate orientation of vertexes based on the distribution layout map, which demonstrates the advantages of using MLLM for optimization. Moreover, both of the methods failed to calculate the correct total demand of the second route, which again confirms that the MLLM is hard to remember accurate tail information as the demand is only given via text."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Why MLLM-V performs better than MLLM-T",
            "text": "To give a deeper insight of the superiority of the proposed MLLM-V, we analyze the different heuristics captured by the model from both the textual and image observations. We compare them with the heuristics captured by the MLLM-T model, which only uses textual observations. We highlight the heuristics that are unique to the MLLM-V model in bold. The heuristics captured from the textual observations are given by:\n- Start by creating clusters of customers based on their proximity to minimize traveling distance within each route.\n- Ensure that the total demand for each route is as close to the vehicle\u2019s capacity as possible without exceeding it.\n- Consider the total traveling cost when constructing routes, aiming to keep it as low as possible.\n- Allow for flexibility in route lengths to achieve overall efficiency.\n- Make sure each customer is visited once and that all routes start and end at the depot.\nAs can be observed, these heuristics are common to both the MLLM-V and MLLM-T models, as they are derived from the problem definition and the objective function, which reflect the basic principles of the vehicle routing problem, such as minimizing total traveling cost, while satisfying the demand and capacity constraints. On the other hand, the heuristics captured from both the textual and image observations are given by:\n- Starting with a clustering approach to group customers based on geographic proximity.\n- Balancing the demand across routes to maximize vehicle capacity utilization.\n- Planning routes that begin and end close to the depot to minimize empty travel.\n- Minimizing the overlap of routes to ensure distinct paths for each vehicle.\n- Considering the directness of travel between customers within the same route.\n- Strategically incorporating outliers into routes without significantly increasing costs.\n- Ensuring that edge cases are handled in a way that does not compromise the efficiency of other routes.\nThe unique heuristics found by MLLM-V have been highlighted in bold font. As can be observed, by incorporating both textual and visual data, the proposed MLLM-V captures more advanced heuristics for vehicle routing than MLLM-T, which learn heuristics based on textual observations alone. These heuristics reveal the superiority of the MLLM-V model over the MLLM-T model, as they provide clear steps to construct cost-efficient traveling routes that lead to more effective outcomes."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we presents a new approach to enhance the optimization performance of LLMs by incorporating multimodal inputs, i.e., text and images. We apply the MLLM to a classic combinatorial optimization problem (i.e., CVRP), and conduct empirical studies and analysis to demonstrate its effectiveness. Our experimental results reveal that MLLMs can grasp the inter-dependencies among decision variables and offer more profound insights into the optimization problem, as opposed to LLMs that depend solely on numerical text prompts. Our work illustrates the potential of MLLMs for tackling complex optimization problems and suggests promising directions for future research in this domain.\nAs future work, we would like to extend the application of MLLMs to other challenging optimization problems. Moreover, we aim to improve the optimization performance of MLLMs by generating heuristic functions from the observations, rather than directly producing solutions of problems encountered."
        }
    ],
    "appendix": [],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T1\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Problem properties of the employed CVRP instances.</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T1.2.2.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">Benchmark</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T1.2.2.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">Problem</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.2.2.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.2.2.5\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">Capacity</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.2.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.2.3.1.1\" rowspan=\"7\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"><span class=\"ltx_text\" id=\"S4.T1.2.3.1.1.1\">Small</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.2.3.1.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">P-n19-k2</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.2.3.1.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">18</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.2.3.1.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">2</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.2.3.1.5\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">160</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.4.2.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">A-n32-k5</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.4.2.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">32</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.4.2.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">5</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.4.2.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">100</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.5.3.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">A-n36-k5</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.5.3.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">36</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.5.3.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">5</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.5.3.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">100</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.6.4.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">A-n38-k5</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.6.4.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">38</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.6.4.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">5</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.6.4.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">100</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.7.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.7.5.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">A-n39-k5</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.7.5.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">39</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.7.5.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">5</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.7.5.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">100</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.8.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.8.6.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">A-n44-k6</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.8.6.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">44</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.8.6.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">6</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.8.6.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">100</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.9.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.9.7.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">A-n46-k7</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.9.7.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">46</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.9.7.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">7</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.9.7.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">100</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.10.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.2.10.8.1\" rowspan=\"10\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"><span class=\"ltx_text\" id=\"S4.T1.2.10.8.1.1\">Large</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.2.10.8.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">E-n51-k5</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.2.10.8.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">51</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.2.10.8.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">5</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.2.10.8.5\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">160</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.11.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.11.9.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">A-n65-k9</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.11.9.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">65</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.11.9.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">9</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.11.9.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">100</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.12.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.12.10.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">A-n69-k9</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.12.10.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">69</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.12.10.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">9</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.12.10.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">100</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.13.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.13.11.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">P-n55-k10</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.13.11.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">55</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.13.11.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.13.11.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">115</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.14.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.14.12.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">P-n65-k10</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.14.12.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">65</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.14.12.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.14.12.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">130</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.15.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.15.13.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">P-n70-k10</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.15.13.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.15.13.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.15.13.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">135</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.16.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.16.14.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">X-n139-k10</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.16.14.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">139</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.16.14.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.16.14.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">106</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.17.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.17.15.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">X-n143-k7</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.17.15.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">143</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.17.15.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">7</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.17.15.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">1190</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.18.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.18.16.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">X-n153-k22</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.18.16.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">153</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.18.16.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">23</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.18.16.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">144</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.19.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.19.17.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">X-n162-k11</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.19.17.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">162</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.19.17.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">11</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.19.17.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">1174</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.20.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\" id=\"S4.T1.2.20.18.1\" rowspan=\"3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"><span class=\"ltx_text\" id=\"S4.T1.2.20.18.1.1\">Solved</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.2.20.18.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">A-n45-k6</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.2.20.18.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">45</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.2.20.18.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">6</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.2.20.18.5\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">100</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.21.19\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.2.21.19.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">P-n60-k10</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.21.19.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.21.19.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.2.21.19.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">120</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.22.20\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T1.2.22.20.1\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">E-n101-k14</th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T1.2.22.20.2\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">101</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T1.2.22.20.3\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">14</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T1.2.22.20.4\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\">112</td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 1: Problem properties of the employed CVRP instances."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T2\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Numerical results gained by MLLM-T and MLLM-V where \u201c\u201d and \u201c\u201d represent the averaged traveling cost and the lowest traveling cost over 5 independent runs, respectively. Superior performance is highlighted in bold.</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.10\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.10.7.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.10.7.1.1\" rowspan=\"2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T2.10.7.1.1.1\">Problem</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.10.7.1.2\" rowspan=\"2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T2.10.7.1.2.1\">Optimal</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S4.T2.10.7.1.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">MLLM-T</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S4.T2.10.7.1.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">MLLM-V</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.6\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S4.T2.5.1.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S4.T2.6.2.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S4.T2.7.3.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S4.T2.8.4.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S4.T2.9.5.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S4.T2.10.6.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.10.8.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T2.10.8.1.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">P-n19-k2</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.10.8.1.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">213</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.10.8.1.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">263</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.10.8.1.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">292</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.10.8.1.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">31%</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.10.8.1.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">235</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.10.8.1.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.8.1.7.1\">260</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.10.8.1.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.8.1.8.1\">22</span>%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.9.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.9.2.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">A-n32-k5</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.9.2.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">788</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.9.2.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1073</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.9.2.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1161</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.9.2.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">47%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.9.2.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1040</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.9.2.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.9.2.7.1\">1141</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.9.2.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.9.2.8.1\">45</span>%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.10.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.10.3.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">A-n36-k5</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.10.3.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">802</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.10.3.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1068</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.10.3.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.10.3.4.1\">1210</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.10.3.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.10.3.5.1\">51</span>%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.10.3.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1147</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.10.3.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1229</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.10.3.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">53%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.11.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.11.4.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">A-n38-k5</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.11.4.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">734</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.11.4.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">981</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.11.4.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1132</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.11.4.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">54%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.11.4.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">982</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.11.4.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.11.4.7.1\">1040</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.11.4.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.11.4.8.1\">42</span>%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.12.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.12.5.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">A-n39-k5</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.12.5.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">829</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.12.5.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1222</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.12.5.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1366</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.12.5.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">65%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.12.5.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1112</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.12.5.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.12.5.7.1\">1300</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.12.5.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.12.5.8.1\">57</span>%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.13.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.13.6.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">A-n44-k6</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.13.6.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">939</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.13.6.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1449</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.13.6.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1568</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.13.6.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">67%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.13.6.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1319</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.13.6.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.13.6.7.1\">1445</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.13.6.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.13.6.8.1\">54</span>%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.14.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.14.7.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">A-n46-k7</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.14.7.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">918</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.14.7.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1388</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.14.7.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1566</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.14.7.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">70%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.14.7.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1430</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.14.7.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.14.7.7.1\">1565</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.14.7.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.14.7.8.1\">70</span>%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.15.8\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.15.8.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">A-n65-k9</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.15.8.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1182</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.15.8.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1979</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.15.8.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">2143</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.15.8.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">81%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.15.8.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1848</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.15.8.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.15.8.7.1\">2124</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.15.8.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.15.8.8.1\">80</span>%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.16.9\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.16.9.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">A-n69-k9</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.16.9.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1166</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.16.9.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">2062</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.16.9.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">2161</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.16.9.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">85%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.16.9.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1807</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.16.9.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.16.9.7.1\">2104</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.16.9.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.16.9.8.1\">80</span>%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.17.10\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.17.10.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">E-n51-k5</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.17.10.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">525</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.17.10.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">897</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.17.10.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1022</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.17.10.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">95%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.17.10.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">825</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.17.10.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.17.10.7.1\">881</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.17.10.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.17.10.8.1\">68</span>%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.18.11\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.18.11.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">P-n55-k10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.18.11.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">698</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.18.11.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">991</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.18.11.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1045</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.18.11.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">50%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.18.11.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">892</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.18.11.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.18.11.7.1\">985</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.18.11.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.18.11.8.1\">41</span>%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.19.12\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.19.12.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">P-n65-k10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.19.12.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">797</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.19.12.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1205</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.19.12.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1269</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.19.12.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">59%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.19.12.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1098</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.19.12.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.19.12.7.1\">1223</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.19.12.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.19.12.8.1\">54</span>%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.20.13\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.20.13.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">P-n70-k10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.20.13.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">830</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.20.13.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1417</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.20.13.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1558</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.20.13.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">88%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.20.13.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">1218</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.20.13.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.20.13.7.1\">1299</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.20.13.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.20.13.8.1\">56</span>%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.21.14\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.21.14.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">X-n139-k10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.21.14.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">13596</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.21.14.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">30763</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.21.14.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">42475</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.21.14.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">212%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.21.14.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">28568</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.21.14.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.21.14.7.1\">33163</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.21.14.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.21.14.8.1\">144</span>%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.22.15\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.22.15.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">X-n143-k7</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.22.15.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">15697</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.22.15.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">46831</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.22.15.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.22.15.4.1\">51238</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.22.15.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.22.15.5.1\">226</span>%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.22.15.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">38493</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.22.15.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">52339</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.22.15.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">233%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.23.16\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.10.23.16.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">X-n153-k22</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.23.16.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">21227</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.23.16.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">44070</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.23.16.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">53435</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.23.16.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">152%</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.23.16.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">39955</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.23.16.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.23.16.7.1\">49732</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.10.23.16.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.23.16.8.1\">134</span>%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.10.24.17\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T2.10.24.17.1\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">X-n162-k11</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T2.10.24.17.2\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">14139</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T2.10.24.17.3\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">33193</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T2.10.24.17.4\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">42320</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T2.10.24.17.5\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">199%</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T2.10.24.17.6\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">31518</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T2.10.24.17.7\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.24.17.7.1\">38227</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T2.10.24.17.8\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.10.24.17.8.1\">170</span>%</td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 2: Numerical results gained by MLLM-T and MLLM-V where \u201c\u201d and \u201c\u201d represent the averaged traveling cost and the lowest traveling cost over 5 independent runs, respectively. Superior performance is highlighted in bold."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.01757v1_figure_1.png",
            "caption": "Figure 1: Illustration of a CVRP with optimal visiting routes."
        },
        "2": {
            "figure_path": "2403.01757v1_figure_2.png",
            "caption": "Figure 2: Workflow of our proposed method with three steps."
        },
        "3": {
            "figure_path": "2403.01757v1_figure_3.png",
            "caption": "(a) Optimal"
        },
        "4": {
            "figure_path": "2403.01757v1_figure_4.png",
            "caption": "(b) Randomly Generated"
        },
        "5": {
            "figure_path": "2403.01757v1_figure_5.png",
            "caption": "(c) Text Prompt Only"
        },
        "6": {
            "figure_path": "2403.01757v1_figure_6.png",
            "caption": "(d) With Vision Prompt"
        }
    },
    "references": [
        {
            "1": {
                "title": "Simulated annealing.",
                "author": "Dimitris Bertsimas and John Tsitsiklis.",
                "venue": "Statistical science, 8(1):10\u201315, 1993.",
                "url": null
            }
        },
        {
            "2": {
                "title": "Ant colony optimization: Introduction and recent trends.",
                "author": "Christian Blum.",
                "venue": "Physics of Life reviews, 2(4):353\u2013373, 2005.",
                "url": null
            }
        },
        {
            "3": {
                "title": "Enhancing genetic improvement mutations using large language models.",
                "author": "Alexander EI Brownlee, James Callan, Karine Even-Mendoza, Alina Geiger, Carol\nHanna, Justyna Petke, Federica Sarro, and Dominik Sobania.",
                "venue": "In International Symposium on Search Based Software\nEngineering, pages 153\u2013159. Springer, 2023.",
                "url": null
            }
        },
        {
            "4": {
                "title": "Sparks of artificial general intelligence: Early experiments with\ngpt-4.",
                "author": "S\u00e9bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric\nHorvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg,\net al.",
                "venue": "arXiv preprint arXiv:2303.12712, 2023.",
                "url": null
            }
        },
        {
            "5": {
                "title": "Power, value and supply chain management.",
                "author": "Andrew Cox.",
                "venue": "Supply chain management: An international journal,\n4(4):167\u2013175, 1999.",
                "url": null
            }
        },
        {
            "6": {
                "title": "Large language models for compiler optimization.",
                "author": "Chris Cummins, Volker Seeker, Dejan Grubisic, Mostafa Elhoushi, Youwei Liang,\nBaptiste Roziere, Jonas Gehring, Fabian Gloeckle, Kim Hazelwood, Gabriel\nSynnaeve, et al.",
                "venue": "arXiv preprint arXiv:2309.07062, 2023.",
                "url": null
            }
        },
        {
            "7": {
                "title": "Optimization for engineering design: Algorithms and examples.",
                "author": "Kalyanmoy Deb.",
                "venue": "PHI Learning Pvt. Ltd., 2012.",
                "url": null
            }
        },
        {
            "8": {
                "title": "Towards optimizing with large language models.",
                "author": "Pei-Fu Guo, Ying-Hsuan Chen, Yun-Da Tsai, and Shou-De Lin.",
                "venue": "arXiv preprint arXiv:2310.05204, 2023.",
                "url": null
            }
        },
        {
            "9": {
                "title": "Chatgpt for shaping the future of dentistry: the potential of\nmulti-modal large language model.",
                "author": "Hanyao Huang, Ou Zheng, Dongdong Wang, Jiayi Yin, Zijin Wang, Shengxuan Ding,\nHeng Yin, Chuan Xu, Renjie Yang, Qian Zheng, et al.",
                "venue": "International Journal of Oral Science, 15(1):29, 2023.",
                "url": null
            }
        },
        {
            "10": {
                "title": "The nature of heuristics.",
                "author": "Douglas B Lenat.",
                "venue": "Artificial intelligence, 19(2):189\u2013249, 1982.",
                "url": null
            }
        },
        {
            "11": {
                "title": "Large language models for supply chain optimization.",
                "author": "Beibin Li, Konstantina Mellou, Bo Zhang, Jeevan Pathuri, and Ishai Menache.",
                "venue": "arXiv preprint arXiv:2307.03875, 2023.",
                "url": null
            }
        },
        {
            "12": {
                "title": "Large language model for multi-objective evolutionary optimization.",
                "author": "Fei Liu, Xi Lin, Zhenkun Wang, Shunyu Yao, Xialiang Tong, Mingxuan Yuan, and\nQingfu Zhang.",
                "venue": "arXiv preprint arXiv:2310.12541, 2023.",
                "url": null
            }
        },
        {
            "13": {
                "title": "Language model crossover: Variation through few-shot prompting.",
                "author": "Elliot Meyerson, Mark J Nelson, Herbie Bradley, Arash Moradi, Amy K Hoover, and\nJoel Lehman.",
                "venue": "arXiv preprint arXiv:2302.12170, 2023.",
                "url": null
            }
        },
        {
            "14": {
                "title": "Logistics systems.",
                "author": "H Chr Pfohl.",
                "venue": "Springer, 2010.",
                "url": null
            }
        },
        {
            "15": {
                "title": "Leveraging large language models for the generation of novel\nmetaheuristic optimization algorithms.",
                "author": "Michal Pluhacek, Anezka Kazikova, Tomas Kadavy, Adam Viktorin, and Roman\nSenkerik.",
                "venue": "In Proceedings of the Companion Conference on Genetic and\nEvolutionary Computation, pages 1812\u20131820, 2023.",
                "url": null
            }
        },
        {
            "16": {
                "title": "Mathematical discoveries from program search with large language\nmodels.",
                "author": "Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej\nBalog, M Pawan Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan S Ellenberg,\nPengming Wang, Omar Fawzi, et al.",
                "venue": "Nature, pages 1\u20133, 2023.",
                "url": null
            }
        },
        {
            "17": {
                "title": "A novel algorithm for capacitated vehicle routing problem for smart\ncities.",
                "author": "Mohammad Sajid, Jagendra Singh, Raza Abbas Haidri, Mukesh Prasad, Vijayakumar\nVaradarajan, Ketan Kotecha, and Deepak Garg.",
                "venue": "Symmetry, 13(10):1923, 2021.",
                "url": null
            }
        },
        {
            "18": {
                "title": "Optimization for machine learning.",
                "author": "Suvrit Sra, Sebastian Nowozin, and Stephen J Wright.",
                "venue": "Mit Press, 2012.",
                "url": null
            }
        },
        {
            "19": {
                "title": "Vehicle routing: problems, methods, and applications.",
                "author": "Paolo Toth and Daniele Vigo.",
                "venue": "SIAM, 2014.",
                "url": null
            }
        },
        {
            "20": {
                "title": "No free lunch theorems for optimization.",
                "author": "David H Wolpert and William G Macready.",
                "venue": "IEEE transactions on evolutionary computation, 1(1):67\u201382,\n1997.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Large language models as optimizers.",
                "author": "Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou, and\nXinyun Chen.",
                "venue": "arXiv preprint arXiv:2309.03409, 2023.",
                "url": null
            }
        },
        {
            "22": {
                "title": "Introduction to evolutionary algorithms.",
                "author": "Xinjie Yu and Mitsuo Gen.",
                "venue": "Springer Science & Business Media, 2010.",
                "url": null
            }
        },
        {
            "23": {
                "title": "Multi-objective medical supplies distribution open vehicle routing\nproblem with fairness and timeliness under major public health emergencies.",
                "author": "Fanfan Zheng, Lijing Du, Xiaohuan Li, Jianna Zhang, Bingwei Tian, and Ra\u2019fat\nJallad.",
                "venue": "Management System Engineering, 2(1):5, 2023.",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.01757v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2.2"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.2"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4",
            "4.1",
            "4.2"
        ]
    },
    "research_context": {
        "paper_id": "2403.01757v1",
        "paper_title": "How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems",
        "research_background": "### Paper's Motivation\nThe motivation for this paper comes from the need for an intelligent optimization engine that can automatically understand the features of optimization problems and adopt suitable strategies to enhance search performance. Traditional heuristic search methods, while successful, are not universally effective for all problems and developing new algorithms for novel problems requires significant expert involvement. The recent advancements in large language models (LLMs) have shown promise in solving optimization problems using natural language prompts. However, most existing methods use purely numerical text prompts, which limits the LLMs' ability to capture the relationships between decision variables, especially as the complexity of the problem increases.\n\n### Research Problem\nThe research problem addressed by this paper is the limitation of current LLM-based optimization methods that rely solely on textual prompts, which can hinder the effective representation and solution of complex optimization problems. The paper proposes using a Multimodal LLM (MLLM) that combines both textual and visual inputs to improve the representation and solution of optimization problems, specifically focusing on the capacitated vehicle routing problem (CVRP).\n\n### Relevant Prior Work\n1. **Optimization Techniques:**\n   - Traditional heuristic search methods such as evolutionary algorithms, ant colony algorithms, and simulated annealing have been employed for various optimization problems (Yu and Gen, 2010; Blum, 2005; Bertsimas and Tsitsiklis, 1993).\n2. **No Free Lunch Theory:**\n   - Indicates that no single optimization algorithm can be universally effective across all problems (Wolpert and Macready, 1997).\n3. **LLMs in Optimization:**\n   - Yang et al. developed Optimization by PROmpting (OPRO) to solve optimization problems.\n   - Li et al. introduced OptiGuide for supply chain optimization using LLMs.\n   - Liu et al. combined LLMs with evolutionary algorithms for multi-objective optimization problems.\n   - Cummins et al. used LLMs to generate compiler optimization sequences.\n   - Pluhacek et al. created novel meta-heuristic optimization algorithms with LLMs adaptable to different domains.\n   - Romera-Paredes et al. demonstrated that LLMs could discover new mathematical theorems and proofs.\n4. **Limitations of Existing LLM-based Methods:**\n   - Most existing methods use purely text-based numerical prompts, which limits the capture of relationships between decision variables and impairs problem representation as complexity grows.\n\nThe proposed multimodal approach aims to leverage the complementary information from both textual and visual inputs to provide richer and more expressive representations, ultimately improving the performance of optimization tasks like the CVRP.",
        "methodology": "In the methodology section of our paper titled \"How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems,\" we present our optimization framework based on Multimodal Large Language Models (MLLMs). This framework emulates the detailed steps typically undertaken in human problem-solving strategies for complex optimization issues. The framework is structured around three main steps:\n\n1. **Heuristic Extraction from Solved Problems**:\n   - In this initial phase, the system analyzes previously solved problems to identify and extract useful heuristics. These heuristics represent strategies or rules of thumb that were effective in earlier scenarios and can be applied to new problems.\n\n2. **Solution Generation via Learned Heuristics**:\n   - Utilizing the heuristics gleaned from the first step, the system then generates solutions for new problems. This involves applying the learned strategies to devise potential solutions efficiently.\n\n3. **Solution Evaluation and Refinement**:\n   - In the final step, the generated solutions are evaluated to ensure their effectiveness. The system refines these solutions iteratively, incorporating feedback to enhance their quality. This step ensures that the solutions meet the desired optimization criteria optimally.\n\nIn summary, our framework integrates learned heuristics into the solution generation process and iteratively improves these solutions through evaluation and refinement, drawing analogies to heuristic-based human problem-solving methodologies.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\nThe main experiment examines the effectiveness of the proposed multimodal framework (MLLM-V) for solving Capacitated Vehicle Routing Problems (CVRPs). The setup uses a set of widely recognized CVRP benchmarks, detailing two categories based on customer size: **small-scale problems** (up to 50 nodes) and **large-scale problems** (around 160 nodes). \n\n#### Datasets\n\n- **Benchmark Categories**:\n  - **Small-Scale Problems**: Instances with up to 50 nodes.\n  - **Large-Scale Problems**: Instances with around 160 nodes.\n- **Knowledge Prompts**: Three CVRPs with known optimal solutions are selected as knowledge prompts:\n  - \"A-n45-k6\"\n  - \"P-n60-k10\"\n  - \"E-n101-k14\"\n\nThese instances serve to enhance the learning and reasoning capabilities of the proposed method.\n\n#### Baselines\n\nThe study includes a comparative analysis against a baseline method as follows:\n- **MLLM-T**: This baseline solely relies on textual prompts.\n- **MLLM-V**: The proposed method employs both visual prompts and their corresponding descriptions.\n\nBoth MLLM-T and MLLM-V utilize the same multimodal language model (GPT-4-vision-preview) and do not undergo additional fine-tuning.\n\n#### Evaluation Metrics\n\nWhile the specific evaluation metrics are not explicitly detailed in the provided text, common measures in CVRP studies typically include:\n- Solution Quality: Evaluated based on the cost or distance of the proposed routes (i.e., the total distance traveled by all vehicles).\n- Optimality: Compared against known optimal solutions to gauge closeness.\n\nGiven these are widely adopted benchmarks, these metrics are implied for use in assessing the results.\n\n#### Main Experimental Results\n\nThe results of this comparison highlight the performance of MLLM-V against MLLM-T. However, the specific quantitative outcomes, numerical results, or performance metrics between these methods are not included in the given text. Nonetheless, the claim is that the MLLM-V method demonstrates superiority over the baseline MLLM-T, indicating the added benefit of incorporating multimodal prompts for solving CVRPs.\n\nThe general takeaway is that the proposed MLLM-V framework enhances the solution quality and reasoning for CVRP instances by leveraging both visual and textual information, compared to using textual prompts alone."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To improve the optimization performance of large language models (LLMs) on the Capacitated Vehicle Routing Problem (CVRP) by leveraging multimodal LLMs that can process both textual and visual prompts.",
            "experiment_process": "The study uses a set of widely adopted CVRP benchmarks that vary in customer size and vertex layout. Benchmarks are categorized into small-scale problems with up to 50 nodes and large-scale problems with around 160 nodes. Three CVRPs with known optimal solutions, 'A-n45-k6', 'P-n60-k10', and 'E-n101-k14', are used as knowledge prompts. Comparative analysis is conducted between the proposed framework MLLM-V (multimodal LLM with visual prompts) and MLLM-T (multimodal LLM with textual prompts only). Both methods use GPT-4-vision-preview without further fine-tuning, differing only in their use of visual prompts and their descriptions. Evaluation metrics include the lowest cost and average cost over 5 runs, and comparisons are made with best-known lowest traveling costs for reference.",
            "result_discussion": "MLLM-V achieves better results than MLLM-T on most CVRP instances, with significant improvements in average traveling costs. For example, MLLM-V attained costs of 260 and 1445 on 'P-n19-k2' and 'A-n44-k6' compared to MLLM-T. This shows that visual prompts enhance learning and optimization capabilities. By leveraging multimodal information, MLLM-V can tackle challenging optimization problems more effectively. Visualizations demonstrate that MLLM-V produces more coherent and efficient routing paths compared to MLLM-T and random methods. Further analysis shows that although both methods remember vertex orientations in the first route, MLLM-T fails in the second route, whereas MLLM-V accurately remembers orientations due to the layout map. The study confirms that multimodal integration enhances optimization processes by capturing advanced heuristics for vehicle routing.",
            "ablation_id": "2403.01757v1.No1"
        },
        {
            "research_objective": "To understand why the multimodal LLM utilizing both textual and visual prompts (MLLM-V) performs better than the LLM relying solely on textual prompts (MLLM-T).",
            "experiment_process": "The study analyzes different heuristics captured by MLLM-V from both textual and image observations, compared with those captured by MLLM-T from textual observations alone. Common heuristics identified include: clustering customers based on proximity, ensuring demand close to vehicle capacity, minimizing traveling cost, allowing flexible route lengths, and visiting each customer once. Unique heuristics captured by MLLM-V involve minimizing route overlaps, considering directness of travel within a route, and strategically incorporating outliers.",
            "result_discussion": "The unique heuristics found by MLLM-V reveal its superiority over MLLM-T by providing clear steps for constructing cost-efficient traveling routes. These heuristics show that MLLM-V captures more advanced principles of vehicle routing that lead to more effective outcomes. By integrating both textual and visual data, MLLM-V can produce highly optimized solutions that traditional textual methods struggle to achieve.",
            "ablation_id": "2403.01757v1.No2"
        }
    ]
}