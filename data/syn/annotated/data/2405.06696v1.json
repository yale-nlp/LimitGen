{
    "title": "Multi-level Shared Knowledge Guided Learning for Knowledge Graph Completion",
    "abstract": "In the task of Knowledge Graph Completion (KGC), the existing datasets and their inherent subtasks carry a wealth of shared knowledge that can be utilized to enhance the representation of knowledge triplets and overall performance. However, no current studies specifically address the shared knowledge within KGC. To bridge this gap, we introduce a multi-level Shared Knowledge Guided learning method (SKG) that operates at both the dataset and task levels. On the dataset level, SKG-KGC broadens the original dataset by identifying shared features within entity sets via text summarization. On the task level, for the three typical KGC subtasks \u2013 head entity prediction, relation prediction, and tail entity prediction \u2013 we present an innovative multi-task learning architecture with dynamically adjusted loss weights. This approach allows the model to focus on more challenging and underperforming tasks, effectively mitigating the imbalance of knowledge sharing among subtasks. Experimental results demonstrate that SKG-KGC outperforms existing text-based methods significantly on three well-known datasets, with the most notable improvement on WN18RR (MRR: 66.6%72.2%, Hit@1: 58.7%67.0%).",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Knowledge Graphs (KGs) are directed multi-relation graphs, with entities as nodes and relations as edges, denoted as a set of triples . Their distinctive advantage lies in efficiently representing and managing extensive knowledge, offering high-quality structured information for diverse downstream tasks, including question answering Saxena et al. (2020  ###reference_b24###), information retrieval systems Bounhas et al. (2020  ###reference_b4###), and recommendation systems Gao et al. (2023  ###reference_b10###). Despite these strengths, existing knowledge graphs still lack a substantial amount of valuable information. Effectively addressing this gap in knowledge completeness has given rise to the field of Knowledge Graph Completion (KGC). KGC aims to infer the missing entities and relations from knowledge graphs, significantly enhancing both the quality and coverage of these valuable knowledge repositories.\nExisting KGC methods are mainly divided into structure-based methods and text-based methods. Structure-based methods Bordes et al. (2013  ###reference_b3###); Sun et al. (2019  ###reference_b25###); Balazevic et al. (2019  ###reference_b1###) typically map entities and relations into low-dimensional vectors and calculate the probability of valid triples by various scoring functions. Text-based methods Yao et al. (2019  ###reference_b36###); Xie et al. (2022  ###reference_b33###); Kim et al. (2020  ###reference_b15###); Yao et al. (2024  ###reference_b37###) adopt pre-trained language models to semantically encode textual descriptions of entities. They can encode unseen entities in training time, while making reasoning less efficient. Recent advancements, such as the bi-encoder structure proposed in studies like Wang et al. (2021a  ###reference_b29###, 2022  ###reference_b30###), aim to reduce the training cost of language model encoders. This shift has led to text-based methods beginning to surpass structure-based methods in terms of performance.\n###figure_1### ###figure_2### While these methods exhibit a strong capability to complete knowledge graphs, challenges persist in the effective sharing of knowledge among datasets and subtasks. Specifically, we find that the same  or  often appear in different triples . According to our analysis in Figure 1a  ###reference_sf1###, 42.1% of triples can find other triples sharing the same  with themselves, and 66.9% of triples can find those sharing the same  with themselves in the WN18RR training set. For instance, (Kirsten Dunst, film actor, Spider-Man), (Willem Dafoe, film actor, Spider-Man), (James Franco, film actor, Spider-Man) all have the same relations and tail entities. This suggests the potential existence of shared knowledge, such as \"American film actor,\" among various head entities. Leveraging this dataset-level shared knowledge is essential to enhance the learning ability of triples and assist the model in correctly identifying answers from lexically similar candidates.\nNotably, we observe considerable performance variations across various KGC subtasks, even when applied to the same dataset. For KG-BERT Yao et al. (2019  ###reference_b36###) on the WN18RR dataset, the Hit@10 prediction results differ notably for head entities (54%) and tail entities (60.7%). This discrepancy arises from certain relations, such as gender and city, linking more head (tail) entities and fewer tail (head) entities. As shown in Figure 1b  ###reference_sf2###, the issue of imbalanced distribution of head entities and tail entities is prevalent in knowledge graphs, yet it receives limited attention in research. Existing multi-task learning methods treat head entity and tail entity prediction equally, ignoring the intricacies of more complex tasks. Therefore, making the model focus on more challenging tasks while learning the shared knowledge across multiple subtasks becomes an urgent concern. This task-level shared knowledge can enhance the model\u2019s learning of entity and relation embeddings.\nIn this paper, we introduce a multi-level Shared Knowledge Guided learning method (SKG) for knowledge graph completion. To capture dataset-level shared knowledge within specific entity sets, we jointly train original triples, triples with identical head entities and relations, and triples with identical relations and tail entities. For task-level knowledge sharing, we incorporate relation prediction in multi-task learning to assist entity prediction task, enabling the model to acquire more relation-aware entity information. In each iteration, our loss weight allocation scheme assigns higher loss weights to tasks that are more challenging and underperforming, effectively addressing the imbalanced distribution of head and tail entities. In summary, our contributions include:\nWe extract dataset-level shared knowledge by extending the original dataset, bolstering the model\u2019s ability to identify correct answers from lexically similar candidates in the bi-encoder architecture.\nWe design a novel multi-task learning architecture with dynamically adjusted loss weights for task-level knowledge sharing. This ensures the model focuses more on challenging and underperforming tasks, alleviating the imbalance of subtasks in KGC.\nSKG-KGC is evaluated on three benchmark datasets: WN18RR, FB15k-237 and Wikidata5M. Experimental results demonstrate the competitive performance of our model in both transductive and inductive settings, with notable success on the WN18RR dataset."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": "Knowledge graph completion KGC has been extensively studied for many years as a popular research topic. It can be divided into three subtasks: head entity prediction, relation prediction and tail entity prediction. Structure-based methods, such as TransE Dou et al. (2021  ###reference_b9###), RotatE Sun et al. (2019  ###reference_b25###), TuckER Balazevic et al. (2019  ###reference_b1###) and Complex-N3 Jain et al. (2020  ###reference_b13###), map entities and relations to low-dimensional vector spaces and measure the plausibility of triples by various scoring functions. Recent text-based methods represented by KG-BERT Yao et al. (2019  ###reference_b36###) attempt to integrate pre-trained language models for encoding textual descriptions of entities and relations. PKGC Lv et al. (2022  ###reference_b19###) converts each triple into natural prompt sentences, utilizing a single encoder for triple encoding. Xie et al. (2022  ###reference_b33###), Saxena et al. (2022  ###reference_b23###), Yao et al. (2024  ###reference_b37###) formulate KGC as a sequence-to-sequence generation task and explore Seq2Seq PLM models to directly generate required text. StAR Wang et al. (2021a  ###reference_b29###) simultaneously learns graph embeddings and contextual information of the text encoding method. Chen et al. (2023  ###reference_b5###) employs conditional soft prompts to integrate textual description and structural knowledge. In contrast, SimKGC Wang et al. (2022  ###reference_b30###) introduces contrastive learning and a bi-encoder with a pre-trained language model to encode entities and relations separately. It proves highly efficient for training with a large negative sample size, enhancing the efficiency of KGC training and inference.\nMulti-task Learning MTL aims to concurrently train deep learning models by leveraging information from multiple interconnected tasks. Balancing losses during training facilitates tasks in providing valuable insights to each other, resulting in a more proficient and robust model. For the KGC task, Kim et al. (2020  ###reference_b15###) first propose a multi-task learning method, integrating relation prediction, relevance ranking, and link prediction tasks. Subsequent models focus on introducing additional knowledge or potent pre-trained language models (PLM). For instance, Dou et al. (2021  ###reference_b9###) propose a novel embedding framework for multi-task learning, enabling the transfer of structural knowledge across different KGs. Incorporating the ALBERT-large Lan et al. (2020  ###reference_b16###) model with more parameters as the text encoder, Tian et al. (2022  ###reference_b26###) enhances model performance at the expense of increased training costs. Meanwhile, Li et al. (2023  ###reference_b17###) employ a multi-task pre-training strategy to capture relational information and unstructured semantic knowledge within structured knowledge graphs. These studies emphasize the interconnectedness of various KGC subtasks, highlighting that knowledge sharing among them can enhance overall performance.\nHowever, they overlook the distinction between head entity prediction and tail entity prediction tasks, which arises from the imbalanced distribution of head and tail entities. Recognizing this, our SKG-KGC model explicitly distinguishes between head entity prediction and tail entity prediction in the context of multi-task learning. We attempt to achieve superior performance and scalability by employing the basic PLM model and fewer subtasks."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Method",
            "text": "In this section, we introduce a multi-level Shared Knowledge Guided learning method (SKG) for knowledge graph completion. We elaborate the entire architecture of the proposed model in section 3.1  ###reference_###. In sections 3.2  ###reference_### and 3.4  ###reference_###, we illustrate how our method captures shared knowledge at both dataset and task levels for KGC. These insights are seamlessly integrated at the bi-encoder architecture, as explained in section 3.3  ###reference_###. The following sections provide a detailed overview of the training and inference processes of our model."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Model Structure",
            "text": "###figure_3### Figure 2  ###reference_### illustrates the overview of the SKG-KGC model. Our model consists of three parts:\nDataset level: During training, the model is simultaneously trained with original triples, triples with identical , and triples with identical . This approach strengthens the learning of shared features among entity sets while reducing text redundancy.\nBi-Encoder Architecture: Two encoders are initialized with the same pre-trained model but do not share parameters. The primary encoder computes the joint embedding of the two known elements in triples, while the secondary encoder computes the representation of the missing entities.\nTask level: We design balanced multi-task learning by introducing a relation prediction subtask to assist link prediction. In each iteration, the model assigns higher loss weights to challenging and underperforming subtasks, facilitating dynamic knowledge sharing across different subtasks."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Dataset Expansion",
            "text": "In addition to the original triples, our proposed model also incorporates triples with the same head entity and relation and triples with the same relation and tail entity. Common features among different entities in triples are identified through text summarization. For instance, and are valid triples in the training dataset, where the relation and the tail entity are consistent. Consequently, the three head entities may share common or similar features. If a new entity also contains these common features within the head entity set, the triplet is more likely to be considered reasonable. The model takes text sequences as input, corresponding to the three types of triples for knowledge graph completion. Each entity text sequence comprises the entity\u2019s name and its corresponding text description. For the triple ({04692908, 00387897}, derivationally related form, 01259005), the input sequence is: \"[CLS] chip, a mark left after a small piece has been chopped or broken off of something [PSEP] snick, a small cut [SEP] derivationally related form [SEP] nick, cut a nick into [SEP]\". The bold font indicates the name of each head entity. [PSEP] serves as the separator for entities in the head entity set. The use of [CLS] and [SEP] aligns with the BERT-base model. Further details regarding different subtasks are provided in Table 1 ###reference_###."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Bi-Encoder Architecture",
            "text": "Unlike MTL-KGC Kim et al. (2020  ###reference_b15###) using a single encoder, our proposed model employs two encoders initialized with the same pre-trained language model but without sharing parameters. Each encoder autonomously acquires shared knowledge at both the dataset and task levels. The primary encoder computes the joint embedding of the two known elements in triples, while the secondary encoder computes the representation of the missing entities.\nHead Entity Prediction Given a triple , the main encoder concatenates the text descriptions of the relation  and the tail entity  with [SEP], calculating the relationship-aware embedding of the tail entity . Meanwhile, the secondary encoder encodes the head entity . This method, as demonstrated in previous approaches Wang et al. (2021a  ###reference_b29###, 2022  ###reference_b30###), proves to be more efficient than encoding the entire triple simultaneously. Subsequently, we employ mean pooling and L2 normalization strategies to derive fixed-size embeddings. The similarity score between the head entity embedding  and the relation-aware tail entity embedding  is determined by cosine similarity, expressed by the following formula:\nTail Entity Prediction The identical bi-encoder computes the similarity score between the tail entity embedding  and the relation-aware head entity embedding  for tail entity prediction . The formula is as follows:\nWe incorporate the idea of contrastive learning to make the anchor point closer to positive samples  and farther from negative samples  or . The proper selection of negative samples significantly impacts the training model\u2019s performance. For ease of comparison, our model employs negative samples consistent with those constructed in SimKGC.\nRelation Prediction The goal of relation prediction  is to predict the missing relation between two given entities. Due to the absence of detailed descriptions of relations, separately encoding relations, as done in the previous two tasks, is impractical. Therefore, we treat relation prediction as a multi-classification task. The scoring function  for the relation label is expressed as follows:\nHere,  represents the head entity and tail entity embeddings encoded by the shared main encoder, and  is the parameter matrix of the classification layer used for relation prediction."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Balanced Multi-Task Learning",
            "text": "In multi-task learning, simultaneously training multiple tasks can be challenging or inefficient without achieving a proper balance among them. Thus, we introduce a dynamic and balanced multi-task weight allocation scheme to ensure equilibrium among the three subtasks: head entity prediction, relation prediction, and tail entity prediction. This approach dynamically takes into account the learning difficulty and accuracy of tasks during each iteration, assigning a higher loss weight to tasks that are challenging to learn and exhibit lower performance. We use  to assess the difficulty and accuracy of task  in the -th epoch as follows:\nHere,  is calculated similarly to focal loss Lin et al. (2020  ###reference_b18###), augmenting the weight of difficult-to-distinguish samples. Although focal loss is originally designed for classification Romdhane et al. (2020  ###reference_b22###), we extend its application to multi-task weight assignment. For task ,  denotes the normalized accuracy metric of the validation set during the iteration immediately before . An increased accuracy metric  indicates enhanced learning capability of the model for the task, thus suggesting a reduction in weight allocation. The focusing parameter  smoothly adjusts the proportion of tasks that are down-weighted. As the task becomes simpler, it is accorded less weight.\nIn this paper, the focusing parameter  primarily mirrors the learning difficulty of the head entity prediction and tail entity prediction tasks, denoted as the ratio of the average number of connected entities in many-to-one and one-to-many relations. A higher count of entities connected by many-to-one relations increases the learning complexity of the head entity prediction task. The tail entity prediction task is also influenced by the number of entities connected by one-to-many relations. The default value of  for the relation prediction task is set to 1.\nSubsequently, we normalize  using the softmax function and multiply it by the number of tasks , ensuring . Finally, we obtain the loss weight  for task  in the -th epoch.\nFor  =1, we initialize the loss weight  of each task to 1, though introducing any non-balanced initialization weight based on prior knowledge is also viable."
        },
        {
            "section_id": "3.5",
            "parent_section_id": "3",
            "section_name": "Training",
            "text": "For different subtasks in KGC, we optimize our proposed model using InfoNCE loss and cross-entropy loss, respectively.\nInfoNCE loss We treat both head entity prediction (HP) and tail entity prediction (TP) as candidate entity ranking tasks. Therefore, we employ the InfoNCE loss with additive margin softmax Yang et al. (2019  ###reference_b35###); Wang et al. (2022  ###reference_b30###) for  and . The loss  is defined as follows:\nThe scoring function  for triples is the cosine similarity of and . The additive margin  enhances the separation between true triples and false triples. We utilize the temperature  to adjust the relative importance of negatives in triples and introduce  as a learnable parameter during training.  represents the number of negative samples. The same approach is applicable to obtain the loss .\nCross-entropy loss For the relation prediction subtask (RP), we train the model by minimizing the cross-entropy loss between the true relations and the predicted relations. The cross-entropy loss function is given by:\nHere,  is a one-hot encoding of relation .  denotes the output score of the relation prediction.\nThroughout the training process, we employ the mini-batch stochastic gradient descent algorithm to optimize the objective function. For each training step, a mini-batch is randomly selected from the entire training dataset . Subsequently, the model is trained sequentially for the task associated with the specific mini-batch. Finally, we multiply the three loss functions by their corresponding weights and sum them up to obtain the overall loss function . The formula is as follows:"
        },
        {
            "section_id": "3.6",
            "parent_section_id": "3",
            "section_name": "Inference",
            "text": "Assume there are  test triples and  candidate entities in the head entity prediction task. Traditional cross encoders, such as KG-BERT Yao et al. (2019  ###reference_b36###) and MTL-KGC Kim et al. (2020  ###reference_b15###), traverse  entities for each test triple . They replace the head entity in the test triplet repeatedly and select the highest-ranking entity as the candidate. This means a test triple requires  computations, and  triples need  computations in total. In contrast, our method employs two independent encoders similar to SimKGC Wang et al. (2022  ###reference_b30###). The primary encoder computes the relation-aware tail entity embeddings for  test triples, while the secondary encoder necessitates only a one-time computation for  candidate entities without re-traversing all entities. The embeddings from the two encoders are combined using a dot product operation to obtain the ranking scores for all entities. This reduces the required BERT forward passes to , significantly reducing inference time.\nLikewise, the reasoning process for the tail entity prediction subtask follows a comparable pattern. The computational complexity also shifts from  to . The inference complexity of the relation prediction subtask remains , owing to the retention of the cross-encoder. Moreover, we have the capability to pre-compute the embeddings of unseen entities or relations based on their text descriptions. Consequently, our model can also facilitate inductive reasoning for some unseen entities or relations."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": ""
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Experimental Setup",
            "text": "Dataset Our model is evaluated on three benchmark datasets: WN18RR Dettmers et al. (2018  ###reference_b7###), FB15k-237 Toutanova and Chen (2015  ###reference_b27###), and Wikidata5M Wang et al. (2021b  ###reference_b31###). Further details regarding dataset statistics are provided in Table 2  ###reference_###. WN18RR is a subset of WordNet Miller (1995  ###reference_b21###), containing about 41k entities and 11 semantic relations between words. FB15k-237, a subset of FreeBase Bollacker et al. (2008  ###reference_b2###), consists of about 15k entities and 237 relations. For text descriptions in WN18RR and FB15k237, we follow the data provided by KG-BERT Yao et al. (2019  ###reference_b36###). Wikidata5M integrates the Wikidata knowledge graph and Wikipediapages, comprising nearly 5 million entities and about 20 million triples. It is used for both transductive and inductive KGC tasks. In the transductive setting, entities appearing in the test set are encountered in the training set, while in the inductive setting, entities in the test set have never appeared in the training set.\nEvaluation Metrics For each test triple , our model predicts the tail entity  by ranking all entities based on , and similarly, predicts the head entity  by ranking all entities based on . The evaluation employs four metrics: mean reciprocal rank (MRR), Hit@1, Hit@3 and Hit@10. MRR is the average reciprocal rank of all test triples, while Hit@k represents the proportion of correct entities ranked within the top-k candidates. All metrics are reported under the filtered setting Bordes et al. (2013  ###reference_b3###), and computations involve averaging over head entity prediction  and tail entity prediction  tasks.\nHyperparameters The SimKGC model Wang et al. (2022  ###reference_b30###) serves as our benchmark, with most hyperparameters aligning with it. The encoders are initialized with BERT-base-uncased (English). The AdamW optimizer with linear learning rate decay is employed. All models are trained with batch size 1024 on 4 A100 GPUs. We conduct a grid search on learning rates within . Entity descriptions are truncated to a maximum of 50 tokens. In the TextRank algorithm, we set the damping ratio  at 0.85 and select the top three sentences as the summarized text. Each task\u2019s initial weight in multitask learning is set to 1. The temperature  initializes at 0.05, and the additive margin  for InfoNCE loss is 0.02. For the WN18RR, FB15k-237, and Wikidata5M datasets, we train for 50, 10, and 1 epochs, respectively."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Main Results",
            "text": "We compare the performance of SKG-KGC with state-of-the-art baseline models, covering both structure-based methods and text-based methods. Table 3  ###reference_### illustrates the main results on the WN18RR and FB15K-237 datasets, while Table 4  ###reference_### shows the performance on the Wikidata5M dataset under transductive and inductive settings.\nOn the WN18RR dataset, the SKG-KGC model outperforms other models significantly. It exhibits notable improvements over the state-of-the-art (SOTA) method in MRR, Hit@1, Hit@3, and Hit@10, with gains of 5.6%, 8.3%, 3.4%, and 1.6% respectively. The most substantial enhancement is observed in Hit@1, potentially attributed to the presence of more lexically similar entities and a sparser graph structure in the WN18RR dataset. We argue that shared knowledge aids the model in learning crucial textual descriptions, enhancing its ability to identify similar candidate entities. The dynamic and balanced loss weight scheme in multi-task learning enables the model to concentrate more on specific subtasks, enhancing its efficacy in handling sparse data in WN18RR. Moreover, text-based methods consistently outperform structure-based methods, underscoring their advantage in grasping the semantics of words.\nCompared to the WN18RR dataset, the FB15K-237 dataset features richer relations and fewer entities. Our model exhibits improved experimental performance among text-based methods, with the exception of MIL-KGC, which utilizes the more potent AlBERT-large encoder and undergoes longer training times. This outcome underscores the effectiveness of shared knowledge and balanced multi-task learning in SKG-KGC for leveraging text information. However, our model still falls short when compared to structured methods like TuckeER and Complex-N3. Two main reasons contribute to this shortfall. Firstly, the limited number of entities in the FB15K-237 dataset results in inadequate learning of entity textual descriptions. Additionally, structured methods contribute to a more effective understanding of generalizable inference rules, which proves advantageous for the FB15K-237 dataset.\nThe Wikidata5M dataset spans various domains and boasts a much larger scale compared to WN18RR and FB15K-237. As indicated in Table 4  ###reference_###, our model demonstrates state-of-the-art (SOTA) performance in both transductive and inductive settings when compared to existing structure-based and text-based methods. Notably, the million-scale data results in a prolonged training time for our model in a single iteration. To facilitate comparisons and minimize training costs, we adopt the approach from SimKGC, maintaining the epoch at 1 during training. Consequently, the dynamic and balanced loss weight allocation scheme is not applied to this dataset. Although extending the existing dataset and incorporating the relation prediction subtask in multi-task learning contribute to some performance enhancement, further improvements can be achieved. Additionally, the exceptional performance on the Wikidata5M_inds dataset underscores our model\u2019s capability to infer entities not encountered in the training set."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Ablation Studies",
            "text": "We conduct the ablation studies to explore the impact of each specific component on the SKG-KGC model. Specifically, \"w/o dataset expansion\" means that the model is trained only using original triples. \"w/o balanced multi-task learning\" refers to treating the loss weights of multiple subtasks as 1. \"w/o multi-level shared knowledge\" means removing both components that gather dataset-level and task-level knowledge. \"w/o bi-encoder architecture\" indicates that we only use one encoder for all triple elements. The results shown in Table 5  ###reference_### highlight that removing any of these components greatly reduces the model\u2019s performance.\nEffect of dataset expansion Removing dataset expansion causes a significant decrease in our model\u2019s performance on the WN18RR and FB15K-237 datasets. Particularly on the WN18RR dataset, which features more textual descriptions, MRR, Hit@1, Hit@3, and Hit@10 metrics all drop by 3.7%, 5.4%, 2.5% and 1.3%, respectively. This emphasizes the effectiveness of common knowledge within entity sets sharing the same  or . Such dataset-level shared knowledge enhances the model\u2019s ability to learn common features among interconnected entities.\nEffect of balanced multi-task learning On the WN18RR and FB15K-237 datasets, when balanced multi-task learning is excluded, the MRR, Hit@1, and Hit@3 of the model show a decrease, but the Hit@10 metric is still comparable. This highlights the advantage of our proposed loss weight allocation scheme for multiple subtasks in multi-task learning. The scheme facilitates more accurate identification of the expected entity from candidate entity sets, despite facing challenges in identifying the top-10 entities.\nEffect of bi-encoder architecture The removal of the bi-encoder architecture results in a 4% decrease in MRR on WN18RR, and a 1.7% decrease on the FB15K-237 dataset. This indicates that it is reasonable for the model to use two independent encoders to encode unknown and known elements separately, thereby avoiding some potential confusion in the single encoder configuration. These findings highlight the effectiveness of the bi-encoder architecture in seamlessly integrating dataset-level and task-level shared knowledge, significantly improving the model\u2019s proficiency in knowledge graph completion."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "Further Exploration of Dataset-level Knowledge",
            "text": "During dataset expansion, we study how different input texts, the number of sentences, and entity sets affect our model, aiming at further exploration of dataset-level knowledge.\nExperiment 1: Effect of input texts In this experiment, we assess the impact of different input texts on the model performance. We examine four scenarios: without entity descriptions, without entity names, with both but without text summarization, and with both including text summarization.\nThe results in Table 6  ###reference_### indicate that the removal of entity descriptions and names leads to a 30.7% and 6.9% decrease in the model\u2019s MRR, respectively, underscoring the importance of these features in capturing in-depth semantic relations in the text-based KGC methods. Importantly, entity descriptions contribute significantly to providing an extensive textual context. Furthermore, the application of the TextRank text summarization algorithm yields a 1.7% increase in MRR, effectively addressing the issue of text redundancy due to an excess of entities.\nExperiment 2: Selection of top- sentences During text summarization, we select the top  sentences with the highest TextRank values to serve as concise text, providing the model with the necessary but succinct descriptive information. Accordingly, we explore the impact of the number of sentences on the model\u2019s overall performance.\n###figure_4### Figure 3  ###reference_### presents the experimental outcomes of selecting the top- sentences () on the WN18RR dataset. When , the MRR and Hit@1 metrics of the SKG-KGC model reach their optimal value. When  is less than 3, the model may face challenges in fully comprehending more detailed information regarding the entity context. Conversely, when  increases, the influx of descriptive information might lead to information overload and confusion, making it challenging to identify the more critical contextual information about entities. Consequently, the top three sentences are ultimately selected as the summarized text.\nExperiment 3: Effect of entity sets We compare SKG-KGC with its two variants that remove head entity sets  and tail entity sets  on the WN18RR dataset.\nTable 7  ###reference_### shows the effect of such exclusions on the model\u2019s performance in predicting head and tail entities. Removing head entity sets significantly reduces the performance of tail entity prediction (MRR decreases by 3.6%), while removing tail entity sets only slightly affects head entity prediction (MRR decreases by 1.1%). The overall performance in entity prediction benefits from shared knowledge across all dataset levels, notably for the tail entity prediction task. We attribute this observed phenomenon to the proportion of triples sharing the same  or , as depicted in Figure 1a  ###reference_sf1###. The WN18RR dataset contains more triples with the same , thereby providing a wealth of knowledge about head entity sets and resulting in a more significant enhancement in the tail entity prediction task."
        },
        {
            "section_id": "4.5",
            "parent_section_id": "4",
            "section_name": "Further Exploration of Balanced Multi-Task Learning",
            "text": "We analyze SKG-KGC alongside weight-unadjusted methods from two perspectives: different datasets and different subtasks of the WN18RR dataset.\nExperiment 1: Performance of balanced multi-task learning on different datasets As shown in Table 5  ###reference_###, balanced multi-task learning works well on WN18RR, but shows only slight improvements on the larger FB15k-237 dataset. We attribute this performance to two main factors. First, the scheme is designed for addressing the issue of imbalanced loss weights among tasks, so it works well when task differences are significant. As shown in Figure 1a  ###reference_sf1###, the proportion of triples sharing the same (r, t) or (h, r) is 84.3% and 74.8% on the FB15K-237 dataset, respectively, which means less task disparity compared to the 24.8% on WN18RR. Secondly, our scheme dynamically updates the loss weights of all tasks after each iteration. Due to computational resource limitations, the number of iterations performed on larger datasets is reduced, leading to less pronounced changes in task weights. Therefore, our proposed scheme performs better when applied to smaller datasets and more diverse tasks.\nExperiment 2: Performance of balanced multi-task learning on different subtasks Furthermore, Table 8  ###reference_### provides detailed results on the WN18RR dataset, including head entity and tail entity prediction outcomes.\nNotably, tail entity prediction consistently outperforms head entity prediction. We attribute this to the smaller average number of entities connected in one-to-many relations. Moreover, Figure 1b  ###reference_sf2### underscores the imbalanced distribution of head entities and tail entities. While our proposed SKG-KGC improves experimental performance through a designed loss weight allocation scheme in multi-task learning, the challenge of significant performance differences between head entities and tail entities persists."
        },
        {
            "section_id": "4.6",
            "parent_section_id": "4",
            "section_name": "Parameter Analysis in Bi-Encoder Architecture",
            "text": "In our experiment, we utilize two types of encoders: BERT-base-uncased with 110M parameters and BERT-large-uncased with 340M parameters, to assess their performance on WN18RR. Each model is evaluated in two configurations: single-encoder uses one encoder for all elements, while bi-encoder uses two separate encoders for known and unknown elements.\nAs shown in Table 9  ###reference_###, within a bi-encoder architecture, the Hit@10 metric improves with the substantial increase in parameter volume of BERT-large. However, the more critical MRR and Hit@1 metrics decline significantly by 1.4% and 3.2%, respectively, potentially due to the curse of dimensionality and overfitting. This observation indicates that an increase in parameter volume does not necessarily lead to an overall improvement in model performance, as supported by previous research Tian et al. (2022  ###reference_b26###).\nFurthermore, when comparing the performance between single and bi-encoder configurations, it is evident that the bi-encoder consistently outperforms the single encoder configuration. We speculate this could be attributed to the bi-encoder\u2019s explicit differentiation between the embeddings of known and unknown elements in the triplets, thereby avoiding potential confusion in the single encoder configuration. Hence, when selecting encoders and architectures for similar tasks, priority should be given to the selection of architecture rather than simply increasing the model\u2019s parameter volume."
        },
        {
            "section_id": "4.7",
            "parent_section_id": "4",
            "section_name": "Efficiency Analysis",
            "text": "Since our model and MTL-KGC Kim et al. (2020  ###reference_b15###) both engage in multi-task learning in KGC, we employ the same task settings and encoders for comparative analysis. Table 10  ###reference_### reports the approximate time cost for training and inference.\nCompared with MTL-KGC, SKG-KGC demonstrates superior speed in training and test datasets. This efficiency improvement emerges from our model\u2019s use of independent candidate entity encoders for calculating entity rankings, similar to the approaches employed by StAR Wang et al. (2021a  ###reference_b29###) and SimKGC Wang et al. (2022  ###reference_b30###). While not pioneering fast inference, our proposed model achieves a trade-off between efficiency and effectiveness, with a focus on improving the latter. Notably, our model surpasses MTL-KGC in both training and inference speed, aligning with the theoretical analysis outlined in section 3.6  ###reference_###."
        },
        {
            "section_id": "4.8",
            "parent_section_id": "4",
            "section_name": "Case study",
            "text": "To conduct a qualitative analysis of the multi-level shared knowledge, we show the top two entities as ranked by SKG-KGC, SKG-KGC without shared knowledge, and the most competitive baseline SimKGC in Table 11  ###reference_###.\nIn the first case, SKG-KGC correctly predicts the entity \"Rome\" and also unexpectedly predicts \"City of London\", possibly due to the influence of \"London\" in the shared tail entity sets. In the second case, SKG-KGC correctly identifies \"United States of America\" by utilizing shared knowledge from candidate entity sets, while other models fail due to an overemphasis on textual similarity between \"Pittsburgh\" / \"Allentown\" and \"Philadelphia\". However, in the third case, the training set only reveals that Flo Rida\u2019s profession is that of an actor and songwriter, and the correct tail entity should be Artist-GB. All three models predict incorrectly due to the presence of the word \"song\" in Flo Rida\u2019s description. Thus, we suspect that text-based methods may excessively focus on certain text descriptions of the entities themselves and overlook structural information in the knowledge graph.\nThese results highlight that SKG-KGC can mitigate the over-reliance on semantic similarity as compared to previous methods, and effectively improve the ability to identify correct entities from similar candidate entities. Furthermore, these insights prove valuable for considering both textual and structural information in KGC."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we introduce a multi-level shared knowledge guided method for efficient knowledge graph completion. Our approach effectively addresses the challenges of inadequate knowledge learning and imbalanced subtasks in multi-task learning. Through extensive experiments on benchmark datasets, we demonstrate that SKG-KGC consistently outperforms competitive baseline models, particularly excelling on WN18RR with its extensive entity descriptions. These findings provide new insights for multi-task learning and other tasks related to knowledge graphs. In future research, we aim to explore the integration of text-based methods with graph embeddings to extract the semantic and structural information in knowledge graphs."
        }
    ],
    "url": "http://arxiv.org/html/2405.06696v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3",
            "3.4",
            "3.5",
            "3.6"
        ],
        "main_experiment_and_results_sections": [
            "4.1",
            "4.2"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4.3",
            "4.4",
            "4.5"
        ]
    },
    "research_context": {
        "paper_id": "2405.06696v1",
        "paper_title": "Multi-level Shared Knowledge Guided Learning for Knowledge Graph Completion",
        "research_background": "### Paper's Motivation:\nThe paper is motivated by the incomplete nature of current Knowledge Graphs (KGs) and the necessity to enhance their quality and coverage. Despite their substantial advantages for various downstream tasks such as question answering, information retrieval, and recommendation systems, KGs still lack a significant amount of valuable information. Addressing this deficiency has given rise to the field of Knowledge Graph Completion (KGC), which aims to infer missing entities and relations to fill these gaps.\n\n### Research Problem:\nThe research problem addressed in this paper involves the challenges of effectively sharing knowledge among datasets and subtasks within the domain of Knowledge Graph Completion (KGC). There are two primary issues identified:\n1. **Dataset-Level Shared Knowledge**: The problem that similar entities or relations often appear in different triples but are not efficiently leveraged by existing methods. This shared knowledge could enhance the learning ability of triples.\n2. **Task-Level Knowledge Sharing**: Discrepancies in performance across various KGC subtasks, often due to imbalanced distributions of head and tail entities, leading to particular tasks being more complex and challenging. Existing methods inadequately address these imbalances and subtasks' intrinsic complexities.\n\n### Relevant Prior Work:\nThe paper references prior work in two main categories of KGC methods:\n1. **Structure-Based Methods**: These methods, exemplified by Bordes et al. (2013), Sun et al. (2019), and Balazevic et al. (2019), typically map entities and relations into low-dimensional vectors and use various scoring functions to calculate the probability of valid triples.\n2. **Text-Based Methods**: Representative studies include Yao et al. (2019), Xie et al. (2022), and Kim et al. (2020), which utilize pre-trained language models to semantically encode textual descriptions of entities. While these methods can encode unseen entities during training, they often struggle with reasoning efficiency. Recent advancements like the bi-encoder structure mentioned in Wang et al. (2021a, 2022) aim to reduce the training cost of language model encoders, positioning text-based methods to outperform structure-based ones.\n\n### Paper\u2019s Contributions:\nTo address the research problem, the paper introduces a multi-level Shared Knowledge Guided learning method (SKG) for KGC:\n1. **Dataset-Level Knowledge Sharing**: Joint training on original triples and triples with identical head entities and relations or identical relations and tail entities to leverage shared knowledge within the dataset.\n2. **Task-Level Knowledge Sharing**: Incorporate relation prediction in multi-task learning to assist entity prediction and employ a dynamic loss weight allocation scheme to focus more on challenging tasks and address the imbalance of head and tail entities.\n\nThe paper claims that their approach:\n- Enhances the model\u2019s capability to identify correct answers from lexically similar candidates.\n- Provides a balanced and focused learning process for more complex and underperforming subtasks.\n\n### Evaluation and Results:\nThe SKG-KGC method is validated on three benchmark datasets\u2014WN18RR, FB15k-237, and Wikidata5M. The experimental results show competitive performance in both transductive and inductive settings, notably excelling on the WN18RR dataset.",
        "methodology": "**Multi-level Shared Knowledge Guided Learning for Knowledge Graph Completion**\n\n**Methodology:**\n\nIn this section, we introduce a multi-level Shared Knowledge Guided learning method (SKG) for knowledge graph completion (KGC). The proposed method is designed to enhance the ability of KGC models by leveraging shared knowledge across different datasets and tasks. Below is a brief overview of the key components and innovations included in our model:\n\n**Architecture Overview:**\nThe entire architecture of the proposed model is detailed in section 3.1  ###reference_###. The architecture comprises a bi-encoder system which is crucial for integrating shared knowledge effectively.\n\n**Capturing Shared Knowledge:**\nIn sections 3.2  ###reference_### and 3.4  ###reference_###, we explain the methodology used to capture shared knowledge at both dataset and task levels:\n- **Dataset Level Knowledge:** The model captures common patterns and relations from multiple datasets, which can be used to improve the generalization capabilities of the KGC system.\n- **Task Level Knowledge:** The model also captures shared patterns and insights across different tasks related to knowledge graph completion, allowing it to apply learned knowledge to new but related tasks seamlessly.\n\n**Bi-encoder Architecture:**\nIn section 3.3  ###reference_###, we describe the bi-encoder architecture in greater detail. This component is critical for the integration of shared knowledge captured at different levels. The bi-encoder architecture consists of:\n- **Entity Encoder:** Responsible for encoding the entities within the knowledge graph.\n- **Relation Encoder:** Responsible for encoding the relationships between entities.\n\n**Training and Inference:**\nSubsequent sections provide a detailed overview of the training and inference processes:\n- During training, the model learns to identify and capture shared knowledge from both dataset and task levels.\n- During inference, the bi-encoder utilizes this shared knowledge to predict missing links in the knowledge graph, thereby completing it effectively.\n\n**Innovations:**\nThe primary innovations of the SKG method include:\n- The multi-level approach to capturing and integrating shared knowledge.\n- A robust bi-encoder architecture that seamlessly incorporates dataset and task-level insights.\n- Enhanced generalization and prediction accuracy for knowledge graph completion tasks through the use of shared knowledge.\n\nBy leveraging these innovations, the SKG method aims to provide a more efficient and accurate solution for knowledge graph completion tasks.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n**Dataset**\nThe main experiment evaluates the proposed model on three benchmark datasets: **WN18RR**, **FB15k-237**, and **Wikidata5M**.\n1. **WN18RR**: A subset of WordNet containing about 41k entities and 11 semantic relations between words.\n2. **FB15k-237**: A subset of FreeBase consisting of approximately 15k entities and 237 relations.\n3. **Wikidata5M**: Integrates the Wikidata knowledge graph and Wikipedia pages, including nearly 5 million entities and about 20 million triples. It supports both transductive and inductive Knowledge Graph Completion (KGC) tasks.\n\n**Evaluation Metrics**\n- The model predicts the tail entity \\(\\text{tail}\\) by ranking all entities based on \\(f(\\text{head}, \\text{relation}, \\text{tail})\\), and similarly, predicts the head entity \\(\\text{head}\\) by ranking all entities based on \\(f(\\text{tail}, \\text{relation}, \\text{head})\\).\n- Four evaluation metrics are employed: \n  - **Mean Reciprocal Rank (MRR)**: The average reciprocal rank of all test triples.\n  - **Hit@1**: Proportion of correct entities ranked within the top 1 candidate.\n  - **Hit@3**: Proportion of correct entities ranked within the top 3 candidates.\n  - **Hit@10**: Proportion of correct entities ranked within the top 10 candidates.\n  \nAll metrics are reported under the filtered setting, and computations involve averaging over head entity prediction and tail entity prediction tasks.\n\n**Hyperparameters and Training Details**\n- The SimKGC model is used as the benchmark, and most hyperparameters are aligned with it.\n- The encoders are initialized with BERT-base-uncased (English).\n- The AdamW optimizer with linear learning rate decay is utilized.\n- Models are trained with a batch size of 1024 on four A100 GPUs.\n- A grid search is conducted on learning rates.\n- Entity descriptions are truncated to a maximum of 50 tokens.\n- For the TextRank algorithm, the damping ratio is set at 0.85, and the top three sentences are selected as the summarized text.\n- Initial weight for each task in multitask learning is set to 1.\n- Temperature \\(\\tau\\) is initialized at 0.05.\n- The additive margin \\(\\gamma\\) for InfoNCE loss is 0.02.\n- Training epochs are set to 50 for WN18RR, 10 for FB15k-237, and 1 for Wikidata5M.\n\n**Main Experimental Results**\nThe experimental results denote the efficacy of the proposed model in knowledge graph completion, demonstrating significant performance across the specified metrics on the provided datasets. Specific numerical values for MRR, Hit@1, Hit@3, and Hit@10 would provide deeper insights into the comparative performance and improvements over existing models."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To explore the impact of each specific component on the SKG-KGC model.",
            "experiment_process": "\"w/o dataset expansion\" means training the model only using original triples. \"w/o balanced multi-task learning\" treats the loss weights of multiple subtasks as 1. \"w/o multi-level shared knowledge\" removes both components that gather dataset-level and task-level knowledge. \"w/o bi-encoder architecture\" indicates using only one encoder for all triple elements. The results are shown in Table 5.",
            "result_discussion": "Removing any of these components greatly reduces the model's performance. Dataset expansion shows a significant performance decrease, especially on the WN18RR dataset with metrics dropping up to 5.4%, emphasizing the importance of common knowledge within entity sets. Balanced multi-task learning improves accuracy despite challenges in identifying the top-10 entities. The bi-encoder architecture avoids confusion in encoding and improves proficiency significantly.",
            "ablation_id": "2405.06696v1.No1"
        },
        {
            "research_objective": "To study the impact of different input texts, the number of sentences, and entity sets during dataset expansion, aiming to explore dataset-level knowledge further.",
            "experiment_process": "Experiment 1 assesses four scenarios regarding input texts: without entity descriptions, without entity names, with both but without text summarization, and with both including text summarization. Experiment 2 explores the number of sentences selected based on TextRank values. Experiment 3 compares SKG-KGC with variants that remove head entity sets and tail entity sets on the WN18RR dataset.",
            "result_discussion": "The removal of entity descriptions and names leads to significant performance drops, highlighting their importance. Text summarization with TextRank increases MRR by 1.7%. Opting for the top three sentences as summarized text balances detailed and overloaded information. Removing head entity sets reduces tail entity prediction performance by 3.6%, while removing tail entity sets has a minor impact on head entity prediction, indicating the value of shared knowledge across dataset levels.",
            "ablation_id": "2405.06696v1.No2"
        },
        {
            "research_objective": "To analyze the performance of balanced multi-task learning on different datasets and subtasks, evaluating the effectiveness of the proposed method.",
            "experiment_process": "Experiment 1 compares the performance of balanced multi-task learning on WN18RR and FB15K-237 datasets as shown in Table 5. Experiment 2 details head and tail entity prediction outcomes on the WN18RR dataset, referencing Table 8.",
            "result_discussion": "Balanced multi-task learning shows significant improvements on WN18RR but only slight improvements on FB15K-237 due to less task disparity and fewer computational resources for iterations. Tail entity prediction consistently outperforms head entity prediction due to a smaller average number of entities in one-to-many relations. Although the designed loss weight allocation scheme improves performance, a significant performance disparity between head and tail entities remains.",
            "ablation_id": "2405.06696v1.No3"
        }
    ]
}