{
    "title": "Using LLMs to Model the Beliefs and Preferences of Targeted Populations",
    "abstract": "We consider the problem of aligning a large language model (LLM) to model the preferences of a human population. Modeling the beliefs, preferences, and behaviors of a specific population can be useful for a variety of different applications, such as conducting simulated focus groups for new products, conducting virtual surveys, and testing behavioral interventions, especially for interventions that are expensive, impractical, or unethical.\nExisting work has had mixed success using LLMs to accurately model human behavior in different contexts.\nWe benchmark and evaluate two well-known fine-tuning approaches and evaluate the resulting populations on their ability to match the preferences of real human respondents on a survey of preferences for battery electric vehicles (BEVs). We evaluate our models against their ability to match population-wide statistics as well as their ability to match individual responses, and we investigate the role of temperature in controlling the trade-offs between these two. Additionally, we propose and evaluate a novel loss term to improve model performance on responses that require a numeric response.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "In the last decade, large language models (LLMs) have evolved significantly for natural language processing tasks, code generation, and as conversational UIs (Zhao et al., 2023  ###reference_b22###).\nExisting work generally finds that it is possible to elicit strong agreement between LLM responses and human responses (Dubois et al., 2023  ###reference_b7###). This concordance suggests a possibility to\nuse LLMs as a statistical proxy to study human beliefs, preferences, and behaviors.\nThis would allow leveraging models that\nwere trained on large, internet-scale datasets in narrow domains where comparatively small amounts of data are\navailable.\nThis might be used, for example, for a company to leverage a comparatively small survey sample\nto understand customer preferences with respect to possible new products, to conduct virtual surveys, and to pilot behavioral interventions, such interventions to drive the adoption of\nsustainable technology. The value for intervention research is especially notable in the case when interventions would be impractical or unethical, such as building large amounts of infrastructure or restricting access to infrastructure. To enable such applications, it is crucial to ensure\nthat LLMs exhibit behavior that is a statistically accurate model of real human behaviors.\nExisting literature on this matter finds conflicting results. For example, Serapio-Garc\u00eda et al. (2023  ###reference_b16###) find that it is possible to prompt LLMs in the pathways language model (PaLM) family to exhibit consistent and clearly measurable personality traits.\nConversely, Gui & Toubia (2023  ###reference_b9###) find significant challenges in emulating human behaviors, specifically in the context of simulated demand for Coca-Cola. These experiments show that\nin general, it is difficult to say a priori whether a pre-trained LLM will accurately model a behavior of interest. In this paper, we consider the problem of aligning the beliefs and preferences of a language model so that it can serve as a statistical proxy for a real human population. We consider a macro, population-wide metric as well as a micro, per-individual metric, and we propose a novel penalty term in the loss function to improve performance on numerical survey questions.\nWe emphasize that the ultimate goal of this work is not to produce a survey-answering bot, but instead to align a language model with the beliefs and preferences of real humans as expressed in a survey. The ultimate goal is to arrive at interactive models that enable the study of a target population. Our results indicate that it is easier to model population-wide statistics than individuals, suggesting that one-on-one interviews may be difficult to replicate. However, our population-wide models may still be useful in the context of population-wide studies, for example in the context of marketing, or community-wide simulations, such as those of  Park et al. (2023  ###reference_b13###).\nIn our experiments, we leverage an existing survey on human beliefs and preferences about battery-electric vehicles (BEVs) (Arechiga et al., 2022  ###reference_b2###). This survey includes interventions intended to increase the preference for BEVs. The contributions of this paper are as follows.\nUsing the survey data of  Arechiga et al. (2022  ###reference_b2###) on real human study participants, we demonstrate the use of parameter-efficient fine-tuning techniques to improve the agreement of LLMs to human preferences as expressed in survey data.\nWe investigate the effects of model size, and find that larger pre-trained models provide the best out-of-the-box performance, but this advantage largely disappears after fine-tuning.\nWe investigate the effects of quantization and sampling temperature. We find that quantizing fine-tuning techniques such as QLoRA (Dettmers et al., 2023  ###reference_b4###) provide minimal degradation but large savings in computation. We find that the temperature parameter allows trading off between agreement with population-wide statistics vs matching per-individual responses.\nWe propose and evaluate a novel penalty term on the loss function to improve model performance on survey questions that require a numerical response.\nWe benchmark against two baseline algorithms trained de novo on given survey data, and demonstrate that the fine-tuned LLMs are able to outperform these baseline algorithms under specific settings. Section 2  ###reference_### describes related work, Section 3  ###reference_### provides the technical background of our work. Section 4  ###reference_### describes the problem statement and Section 5  ###reference_### describes our proposed approach. Section 6  ###reference_### presents our experiments and Section 7  ###reference_### concludes and describes directions for future work."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": "The possibilities of simulating humans and human behaviors using LLMs (Kaddour et al., 2023  ###reference_b12###), or role-play (Shanahan et al., 2023  ###reference_b17###; Wu et al., 2023  ###reference_b21###), have been discussed in recent work. By applying established psychometrics,\nSerapio-Garc\u00eda et al. (2023  ###reference_b16###) demonstrated that LLMs can reliably simulate personalities and that LLM-generated personality traits can be shaped and controlled to imitate specific personality profiles.\nDillion et al. (2023  ###reference_b6###) showed a strong alignment between GPT-3.5 and humans in moral judgments, with a correlation of 0.95. In addition, LLM-based generative agents, when organized as a collective in an interactive sandbox environment, were found to be able to produce believable behaviors not only on an individual level but also on a social level (Park et al., 2023  ###reference_b13###).\nThe ability of LLMs to generate human-like personalities, judgments, and behaviors hints at the opportunity of constructing synthetic human participants in behavioral studies. Several recent works show initial attempts in this direction.\nAher et al. (2023  ###reference_b1###) applied LLMs to simulate human subjects and found that they can reproduce three out of four economic, psycholinguistic, and social psychology experiments and replicate findings from prior studies with real human participants.\nH\u00e4m\u00e4l\u00e4inen et al. (2023  ###reference_b10###) evaluated LLMs\u2019 potential of generating synthetic human-computer interaction research data in the form of open-ended questionnaire responses and revealed their capability of generating plausible, human-like self-report data regarding subjective experiences.\nHowever, previous work simply measured concordance between LLMs and participant data, and other work such as that of  Gui & Toubia (2023  ###reference_b9###) find a lack of agreement in domains such as predicting product pricing. Our work provides a framework to align LLMs to human preferences and explores various techniques to improve the level of agreement."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Background",
            "text": "Auto-regressive large language models\nAutoregressive language models learn to predict the next token in a stream of language tokens. Formally, given a sequence of tokens\n, the model learns to predict a probability distribution . An important property of these models is\nthat they can be trained in an unsupervised way, i.e., no manually produced labels are required. All that is required is a large corpus of natural text. Many such\ncorpora have been assembled from the internet, for example Gao et al. (2020  ###reference_b8###) and Computer (2023  ###reference_b3###). A commonly used architecture is the\ntransformer architecture (Vaswani et al., 2017  ###reference_b19###), and specifically the decoder-only transformer with a causal mask, which prevents the model from using information from future tokens (Radford et al., 2018  ###reference_b15###).\nFine-tuning large language models\nA common approach to use LLMs is to pre-train on a large text corpus, and then fine-tune the resulting model for a specific downstream task (Radford et al., 2018  ###reference_b15###; Devlin et al., 2018  ###reference_b5###). Downstream tasks may include sentiment analysis, question answering, text summarization, etc. The fine-tuning procedure involves updating all of the parameters of the model, and can be computationally expensive for large model sizes.\nLow-Rank Adaptation (LoRA) (Hu et al., 2021  ###reference_b11###) is a technique for fine-tuning large language models\nthat relies on freezing pre-trained model weights and adding low-rank trainable matrices\nat various points throughout the model. This procedure dramatically reduces the\ncomputational cost of fine-tuning since only the low-rank adaptation matrices\nhave associated gradients at training time.\nQuantized LoRA (QLoRA) (Dettmers et al., 2023  ###reference_b4###) is a variation of LoRA that quantizes the model weights\nas 4-bit NormalFloats, a data type that efficiently compresses the model weights\nwhile discarding as little information as possible. QLoRA also introduces a number of memory optimization techniques, such as double quantization and paged optimizers to manage memory spikes."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Problem setting",
            "text": "The problem we consider assumes that a small amount of survey data is available from\na representative sample of a target human population. We further assume that\ndemographic information that is relevant to characterizing the target population is available.\nFormally, the answer  of a participant  who has demographics  is generated with .\n denotes the questionnaire .\nDemographics, such as age, gender, income, etc., are characteristics of each individual participant. The available demographics as well as their distribution within the target\ndata should be appropriate to the modeling task at hand.\nAs a specific example of the survey, we will use the EV-shift dataset (Arechiga et al., 2022  ###reference_b2###).\nThe EV-shift dataset examines the impact of interventions on the preference for electric vehicles (EVs) when compared to internal combustion vehicles.\nThis dataset resulted from a study aimed at identifying how effectively different text-based interventions changed people\u2019s preferences for EVs.\nTable 1  ###reference_### shows the number of answers and tokens in this dataset.\nIn the study, subjects began by providing an initial preference for EVs, which was a numerical rating from 0 to 100 (with higher numbers indicating greater preference for EVs). Subjects were then shown one of 35 text-based interventions aimed at increasing their preferences for EVs. After the intervention, subjects provided a post-intervention preference, which was also a numerical rating from 0 to 100.\nEach subject also provided demographic information.\nIn total, the dataset contains demographic information, one initial preference rating for each of the 4,045 subjects, the interventions seen by each subject (5 for most subjects), and the post-intervention preference ratings provided by subjects after each intervention."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Proposed method",
            "text": "Our proposed approach provides virtual survey participants with a prompted, fine-tuned LLM\nto generate survey responses that statistically match those of a target population.\nIn this section, we describe the implementation of the subjects by prompting and the fine-tuning procedure.\nFormalization and implementation\nEach virtual participant in the population is implemented by prompting an LLM to behave as a person with given demographic information.\nFormally, the virtual participants with a language model represent the distribution , where  is the generated token sequence. This generated token sequence corresponding to the answer from token sequence  corresponding to the demographics and survey question.\n is the vocabulary of the language model.\nAdditionally, let  be a function that preprocesses the output sequence  to produce an answer . This function is useful when the expected answer to a survey question is a structured output (e.g., a numerical rating, or a multiple choice answer), but the LLM embeds its answer within a longer explanation. The complexity of  may become quite high. In our experiments, we adhere to a simple function that allows some flexibility interpreting the model outputs, without becoming overly complex. We define\n as the function that extracts the first (possibly multi-digit) number that appears in the symbol sequence as a simple implementation.\n###figure_1### Figure 1  ###reference_### shows an example of formulating the prompt text from survey data.\nTo set the properties of the virtual participant, we use the following prompt,\n{itembox}[l]System prompt\nI want you to act as the following character. Answer all of the following questions from the point of view of this character, do not break character. {demographics}\n\n{demographics} contains a list of demographic characteristics.\nFor example, a man aged 18\u201325 is represented as {age: 18\u201325, gender: man}.\nOur implementation allows generating virtual participants with demographics drawn from any distribution, enabling targeting to different populations of interest, including demographics that a company believes are likely to be customers for a specific product. Although prompt engineering techniques are a rich area of inquiry, they are not the focus of our work, and for this reason we limit our prompts to the minimum amount of information required to explain the setting to the LLM. Naturally, our techniques can be combined with prompt engineering techniques to enhance their effectiveness.\nOur survey concerns preferences for battery electric vehicles. To check the preferences of a virtual participant given demographics, we use the following prompt,\n{itembox}[l]Survey prompt\n{intervention} On a scale from 0 to 100, what is your current preference for battery electric vehicles (BEVs)? Please reply with just a single number rating and no additional words or explanations. Score:\n\n{intervention} is blank for the initial preference question, and contains intervention text to produce post-intervention preferences.\nFor example, intervention sentence is \u201dSome BEV manufacturers may start offering free charging\u201d (interventions are described in Appendix A  ###reference_###).\nFine-tuning large language model with survey data\nNext, the pre-trained LLM is fine-tuned to emulate the preferences of the human survey participants.\nThe LLMs used for fine-tuning are auto-regressive LLMs for text generation.\nEach text corresponds to a set of question and answer for a specific subject, and the text contains a system prompt, a survey prompt, and an answer.\nNote that a single dataset contains multiple questions, i.e., both initial preference and post-intervention preference questions.\nFor most of our experiments, we use the conventional cross-entropy loss function.\nNumeric penalty function\nIn 6.4  ###reference_###, we seek to enhance model performance by adding a penalty term to the cross-entropy loss function. This specific penalty term is novel (to the best of our knowledge), and is represented by Equation 1  ###reference_###.\nFor this penalty term to be well-defined, we require that the vocabulary contain separate tokens for each of the possible numerical output tokens. Since we are using the Llama 2 family of models, and these models have separate tokens for the digits 0 through 9, we need to scale the survey data so that the possible answers are in the single-digit range in order to be able to use this penalty term.\nOur numerical penalty term is calculated by weighting the log generation probability of the answer set containing the subject\u2019s answers by a value  for each answer. This value is equal to  when the generated numerical answer  is exactly equal to the true answer , zero when  is further than a hyperparameter value  from , and a computed intermediate value in between, as shown in Equation 2  ###reference_###. This hyperparameter controls how much information the penalty term provides to nearby numerical values.\nThe goal of this penalty term is to improve the performance of a token generation model over questions that require a numerical response. The cross-entropy loss term merely provides feedback about whether a generated numerical token was correct or not. Our penalty term additionally provides feedback about whether the generated numerical token was close to or distant from the correct answer.\nThe combined loss function is .\n denotes the data,  denotes the parameters of the language model, and  denotes a mixing coefficient between the two loss terms.\nPerformance Measures\nFinally, we measure the agreement between LLMs and humans.\nWe use the test data portion of the survey data for this measurement.\nThe LLM responses are generated using the same demographics distribution as the survey data to be measured. The metrics we use to measure similarity between LLM responses and survey responses are KL-divergence and root mean square error (RMSE).\nIntuitively, we can think of the KL-divergence as measuring model agreement with the statistics of the population as a whole, whereas the RMSE measures model agreement with individual responses."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "In these experiments, we use Llama 2 (Touvron et al., 2023  ###reference_b18###).\nThe model sizes are 7B, 13B, and 70B, using chat models published on HuggingFace111https://huggingface.co/meta-llama  ###reference_huggingface.co/meta-llama###.\nWe set LoRA , and LoRA dropout  for fine-tuning.\nWe use 3 epochs across all experiments.\nWe split our dataset randomly into a training set, a validation set, and a test set using an 8:1:1 split by subject (so the number of subjects in train data is 3,237). Critically, subjects that occur in the training set do not appear in the test set.\nEvaluation on the test data was performed using the following procedure. Although the prompt asks the model for a numerical answer, sometimes the model replies with additional text. Since we do not want to construct arbitrarily complex logic to understand all possible\ngenerations, we sample a maximum of 8 output tokens,\nand the first number that appears from the beginning of the sentence is considered the answer.\nIf a number is not included in the generated sentence or is not an integer in the correct range, the generation is considered to have failed.\nKL-divergence and RMSE are calculated except in cases where the generation fails. KL-divergence is obtained by generated numbers that are discretized.\nThe discretization width is 10 in Section 6.1  ###reference_### to 6.3  ###reference_### and 1 in Section 6.4  ###reference_### for adapting a scale of the numerical answer.\nTo understand the performance of our language models, we compare the model against\nthree baselines that are not language models.\nThe first two are supervised learning algorithms, support vector regression (SVR) and CatBoost  (Prokhorenkova et al., 2018  ###reference_b14###). These algorithms are trained on the survey data, and they learn to map a vector of demographic information to a predicted preference value. The purpose of these benchmarks is to situate the performance of the language models with respect to highly effective supervised learning models. We note that in many configurations cases, the baseline models outperform the language models. For our use-case, however, the supervised learning algorithms cannot be used in downstream tasks, such as follow-up questions that involve conversational responses or user surveys.\nThe third benchmark model is a model that generates a random answer.\nThese baselines will be conducted to evaluate the positioning of LLM performance at individual-level and population-level by showing the curve of possible solutions that can be achieved by non-language methods, directly mapping from demographic characteristics to survey responses.\nFor SVR and CatBoost, we will refer to the resulting curve of performance values from models trained with multiple hyperparameters as the baseline curves.\nWe chose SVR as one of our baselines because it is a commonly used supervised learning method for regression problems, and CatBoost because it is a powerful gradient-boosting method for categorical variables.\nSVR and CatBoost are fitted with the EV-shift dataset for each questionnaire.\nFor SVR, categorical variables such as demographics and intervention text are converted to dummy variables.\nThe predicted preference is normalized between 0 to 1 for SVR and CatBoost.\nThe hyperparameters for SVR and CatBoost are shown in Appendix G  ###reference_###.\nWe detail our experiments in the sections below Section 6.1  ###reference_### investigate the effects of model size, Section 6.2  ###reference_### investigates the effect of model quantization, Section 6.3  ###reference_### investigates the effects of sampling temperature, and Section 6.4  ###reference_### investigates the effect of our proposed penalty term."
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "Effects of model size",
            "text": "First, we explore the effects of fine-tuning different model sizes. For this experiment, we will fine-tune three different model sizes (7B, 13B, and 70B) with QLoRA. We trained the model for 3 epochs, but rolled back to the 1 epoch checkpoint due to increases in the validation loss (see Appendix B  ###reference_###).\nThe RMSE-KL plots for each model and baseline are shown in Figure 2  ###reference_###.\nWe consider two sampling temperatures at the output of the model, corresponding to a temperature of zero and a temperature of one. These values are chosen due to their natural interpretations. A temperature of zero corresponds to greedily taking the token with the highest output probability, which can be interpreted as the token that the model most strongly believes is the correct value. We denote this setting as greedy sampling. A temperature of one corresponds to sampling output tokens with the probability distribution that is obtained by directly applying a softmax function to the logits of the neural network. Since in this case output tokens will appear with a distribution that corresponds exactly to the softmax distribution at the model output, we denote this setting as calibrated sampling. We will investigate the role of temperature in greater detail in Section 6.3  ###reference_###.\nComparing the results of the pre-trained model and QLoRA, the use of greedy sampling tends to reduce both KL-divergence and RMSE, while the use of calibrated sampling significantly reduces the KL-divergence.\nComparing results by model size, 70B had the best (lowest) performance on both metrics among the pre-trained models, and QLoRA improved KL-divergence for all model sizes.\nHowever, when calibrated sampling was used, the QLoRA model outperformed the baseline KL-divergence for all sizes.\nIn other words, with and without fine-tuning, 70B has a smaller KL-divergence than the other sizes, but the difference is smaller when fine-tuning is used.\nThese results indicate that fine-tuning not only reduces both RMSE and KL-divergence, but also can exceed the KL-divergence of the non-language model under some sampling conditions. Also, larger models tend to display lower KL-divergence. Although our language models with greedy sampling do not outperform the supervised learning benchmarks, using a language model is more versatile than a supervised learning model, since the language model can be queried with natural-language follow-up questions, or asked to provide natural-language responses in a user interview.\n###figure_2###"
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "Quantization effects",
            "text": "Next, we show the impact of the choice of fine-tuning method, specifically comparing LoRA (Hu et al., 2021  ###reference_b11###) and QLoRA (Dettmers et al., 2023  ###reference_b4###), which differ mainly in that QLoRA introduces parameter quantization.\nIn this experiment, we focus on the 7B parameter model.\nThe comparison of KL-divergence and RMSE for each question is shown in Table 5  ###reference_###.\nLoRA tended to produce lower (better) KL-divergence than QLoRA for initial preference questions, but higher (worse) KL-divergence for post-intervention questions. On the RMSE metric, LoRA performs slightly worse than QLoRA on the initial preference questions but slightly better on the post-preference questions.\nHowever, these differences are fairly small. When the preferences for each question were compared, Spearman\u2019s correlation coefficients were 0.9 and 0.81, indicating very high correlations.\nThese results indicate that the effect of quantization on the responses is small. Since QLoRA provides higher computational efficiency at fine-tuning time, our experiments corroborate the view that QLoRA is able to efficiently provide fine-tuning capabilities."
        },
        {
            "section_id": "6.3",
            "parent_section_id": "6",
            "section_name": "Temperature effects",
            "text": "In this section, we show the impact of the decoding temperature on our performance metrics.\nAccording to Wiher et al. (2022  ###reference_b20###), there are various decoding strategies. In this paper, (ancestral) sampling is used as calibrated sampling.\nIn these experiments, we fix our attention on a 7B model fine-tuned with QLoRA.\nThe RMSE-KL plots for varying the temperature parameter of the stochastic sampling are shown in Figure 4  ###reference_###.\nThe results show that greedy sampling has the lowest RMSE, and increasing temperature (and randomness) tends to decrease (improve) KL-divergence and increase (worsen) RMSE.\nFrom these results, we can see that the population-wide metric of KL-divergence and the per-individual metric of RMSE trade off against each other, and that the choice of temperature allows fine-grained control over this trade-off.\n###figure_3### ###figure_4###"
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Conclusions and Future Work",
            "text": "We have investigated the use of LLMs to model the beliefs and preferences of a human population. This can be useful, for example, to conduct simulated focus groups for new products, conduct virtual surveys, or pilot interventions that would be unethical or impractical to conduct on real humans. We found that out-of-the box pre-trained models provide comparatively poor performance at predicting the responses of human survey participants, but that the LLMs can be fine-tuned to provide a better model of the target population. We investigated the effects of model size, and found that larger models provide better performance, but this advantage shrinks after task-specific fine-tuning. We investigated the effects of quantization on the fine-tuning process, and found that the resulting degradation was minimal, confirming that quantization is a viable technique to reduce computation costs. We investigated the role of sampling temperature, and found that the temperature allows trading off the population-wide metric of KL-divergence against the per-individual metric of RMSE. Finally, we introduced a penalty loss term to improve the performance of the model on questions that require a numerical output, providing the model with additional information at training time about the relative correctness of different numerical responses.\nAlthough our approach demonstrates that it is possible to match responses on survey data, in future work we will study the extent to which this shift successfully aligns the model to unseen behavioral scenarios."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A EV-Shift Survey Details",
            "text": "There are some details about the EV-shift survey (Arechiga et al., 2022  ###reference_b2###).\nTable 6  ###reference_### shows questionnaires together with the possible choices to describe demographics.\nTable 7  ###reference_### shows a list of intervention texts."
        },
        {
            "section_id": "Appendix 2",
            "parent_section_id": null,
            "section_name": "Appendix B Effects of model size",
            "text": "Figure 5  ###reference_### shows the the learning curve for the QLoRA experiments.\nAfter 1 epoch, validation loss is increasing, indicating overfitting. In addition, the larger the model size, the faster the train loss tends to decrease.\nThe success rate for the test data is shown in Figure 6  ###reference_###.\nThe success rate of QLoRA is higher than that of the pre-trained model.\nTable 8  ###reference_### shows an example of a generated sentences.\nThis result indicates that the pre-trained model tends to generate non numerical tokens at the beginning of the answer.\nThese trends indicate a lack of ability to follow the instruction of \u201dPlease reply with just a single number rating and no additional\nwords or explanations\u201d that is prompted on the survey prompt\n(Section 5  ###reference_###) in the pre-trained model.\nAlthough the success rate could be improved with techniques such as prompt engineering and in-context learning, they are not the focus of this work.\n###figure_5### ###figure_6### ###figure_7### ###figure_8### ###figure_9### ###figure_10###"
        },
        {
            "section_id": "Appendix 3",
            "parent_section_id": null,
            "section_name": "Appendix C Quantization effects",
            "text": "Figure 7  ###reference_### shows the answer distribution for QLoRA and LoRA.\nThe results of Figure 7  ###reference_### and Figure 7  ###reference_### show that there is a high correlation between the two models, although individual responses may differ.\n###figure_11### ###figure_12### ###figure_13### ###figure_14### ###figure_15### ###figure_16###"
        },
        {
            "section_id": "Appendix 4",
            "parent_section_id": null,
            "section_name": "Appendix D Temperature effects",
            "text": "The generated preference distributions for different decoding strategies are shown in Figure 8  ###reference_###.\nIn the case of greedy sampling, the model tended to respond to a specific value out of the preference values from 0 to 100, while in the case of calibrated sampling, the response variation increased.\n###figure_17### ###figure_18### ###figure_19### ###figure_20### ###figure_21### ###figure_22###"
        },
        {
            "section_id": "Appendix 5",
            "parent_section_id": null,
            "section_name": "Appendix E Penalty term effects",
            "text": "The learning curve for the case with penalty term is shown in Figure 9  ###reference_###.\nThe model is shown for 7B with .\nIn both conditions, the validation loss begins to increase from 1 epoch, as in the case with only the cross-entropy term shown in Figure 5  ###reference_###.\nThe more  was increased, the smaller the change in loss.\nThis indicates that as  is increased, the weight to non-answer preference tokens increases, making it harder to decrease the loss compared to the cross-entropy, which evaluates the entire prompt.\n###figure_23###"
        },
        {
            "section_id": "Appendix 6",
            "parent_section_id": null,
            "section_name": "Appendix F Amount of data effects",
            "text": "The effect on the test data when the amount of training data is varied is shown in Figure 10  ###reference_###.\nThe training epochs are 30 epochs for 10% and 6 epochs for 50% in order to align with the case of 100% data volume respectively.\nThe model checkpoints before the increase in validation loss were used for evaluation.\nThe results show that KL and RMSE improve with higher data volume for some questionnaires.\n###figure_24###"
        },
        {
            "section_id": "Appendix 7",
            "parent_section_id": null,
            "section_name": "Appendix G Baselines",
            "text": "Table 10  ###reference_### and Table 10  ###reference_### show the hyperparameter combinations used for the SVR and CatBoost.\nIn addition, the KL-RMSE plots for each model are shown in Figure 11  ###reference_###.\nAlthough many of the models are non-dominated, it can be seen that the pareto fronts are generally consistent for the two models.\n###figure_25### ###figure_26###"
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T1.1.1.1.1\">Questionnaire</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.2\">#answer</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.3\">#token [B]</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.1.2.1.1\">Initial preference</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.1.2.1.2\">4,045</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.1.2.1.3\">0.87</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T1.1.3.2.1\">Post-intervention preference</th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T1.1.3.2.2\">20,217</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T1.1.3.2.3\">4.79</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Number of answers and tokens in EV-shift dataset. The number of tokens is the amount of tokenized prompt texts that is calculated by the tokenizer of Llama 2\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Touvron et\u00a0al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.20252v1#bib.bib18\" title=\"\">2023</a>)</cite>. Procedure to convert survey data to prompt described at section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.20252v1#S5\" title=\"5 Proposed method \u2023 Using LLMs to Model the Beliefs and Preferences of Targeted Populations\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>.</figcaption>\n</figure>",
            "capture": "Table 1: Number of answers and tokens in EV-shift dataset. The number of tokens is the amount of tokenized prompt texts that is calculated by the tokenizer of Llama 2\u00a0(Touvron et\u00a0al., 2023). Procedure to convert survey data to prompt described at section 5."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S6.T4\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Performance of QLoRA with calibrated sampling (). Bold values represent the minimum value between model sizes.</figcaption><div class=\"ltx_flex_figure\">\n<div class=\"ltx_flex_cell ltx_flex_size_2\">\n<figure class=\"ltx_figure ltx_figure_panel ltx_minipage ltx_align_top\" id=\"S6.T4.fig1\" style=\"width:178.9pt;\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Table 3: </span>Initial preference</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S6.T4.fig1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S6.T4.fig1.1.1.1\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T4.fig1.1.1.1.1\">Size</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T4.fig1.1.1.1.2\">KL-divergence</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T4.fig1.1.1.1.3\">RMSE</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S6.T4.fig1.1.2.1\">\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S6.T4.fig1.1.2.1.1\">7B</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S6.T4.fig1.1.2.1.2\">0.063</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S6.T4.fig1.1.2.1.3\">37.914</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.fig1.1.3.2\">\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T4.fig1.1.3.2.1\">13B</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T4.fig1.1.3.2.2\">0.046</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T4.fig1.1.3.2.3\">37.976</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.fig1.1.4.3\">\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S6.T4.fig1.1.4.3.1\">70B</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S6.T4.fig1.1.4.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.fig1.1.4.3.2.1\">0.042</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S6.T4.fig1.1.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.fig1.1.4.3.3.1\">37.799</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n</div>\n<div class=\"ltx_flex_cell ltx_flex_size_2\">\n<figure class=\"ltx_figure ltx_figure_panel ltx_minipage ltx_align_top\" id=\"S6.T4.fig2\" style=\"width:178.9pt;\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Table 4: </span>Post-intervention preference</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S6.T4.fig2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S6.T4.fig2.1.1.1\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T4.fig2.1.1.1.1\">Size</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T4.fig2.1.1.1.2\">KL-divergence</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T4.fig2.1.1.1.3\">RMSE</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S6.T4.fig2.1.2.1\">\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S6.T4.fig2.1.2.1.1\">7B</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S6.T4.fig2.1.2.1.2\">0.026</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S6.T4.fig2.1.2.1.3\">37.411</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.fig2.1.3.2\">\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T4.fig2.1.3.2.1\">13B</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T4.fig2.1.3.2.2\">0.025</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T4.fig2.1.3.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.fig2.1.3.2.3.1\">36.970</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.fig2.1.4.3\">\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S6.T4.fig2.1.4.3.1\">70B</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S6.T4.fig2.1.4.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.fig2.1.4.3.2.1\">0.019</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S6.T4.fig2.1.4.3.3\">37.266</td>\n</tr>\n</tbody>\n</table>\n</figure>\n</div>\n</div>\n</figure>",
            "capture": "Table 2: Performance of QLoRA with calibrated sampling (). Bold values represent the minimum value between model sizes."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S6.T5\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>Comparison between QLoRA and LoRA. (7B, greedy sampling)</figcaption>\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S6.T5.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S6.T5.1.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S6.T5.1.1.1.2\">KL-divergence</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S6.T5.1.1.1.3\">RMSE</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" id=\"S6.T5.1.2.2.1\">Method</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S6.T5.1.2.2.2\">Initial preference</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S6.T5.1.2.2.3\">Post preference</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S6.T5.1.2.2.4\">Initial preference</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S6.T5.1.2.2.5\">Post preference</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S6.T5.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S6.T5.1.3.1.1\">QLoRA</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S6.T5.1.3.1.2\">0.694</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S6.T5.1.3.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.3.1.3.1\">0.628</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S6.T5.1.3.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.3.1.4.1\">31.308</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S6.T5.1.3.1.5\">33.703</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S6.T5.1.4.2.1\">LoRA</th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S6.T5.1.4.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.4.2.2.1\">0.670</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S6.T5.1.4.2.3\">0.673</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S6.T5.1.4.2.4\">31.641</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S6.T5.1.4.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.4.2.5.1\">33.091</span></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 5: Comparison between QLoRA and LoRA. (7B, greedy sampling)"
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"A1.T6\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A1.T6.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.1\">\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T6.1.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.1.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.1.1.1.1\" style=\"width:56.9pt;\">Demographics</span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T6.1.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.1.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.1.2.1.1\" style=\"width:313.0pt;\">Options</span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T6.1.2.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.2.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.2.1.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.2.1.1.1.1\" style=\"width:56.9pt;\">Living state</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.2.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.2.1.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.2.1.2.1.1\" style=\"width:313.0pt;\">alabama, alaska, arizona, arkansas, california, colorado, connecticut, delaware, district of Columbia, florida, georgia, hawaii, idaho, illinois, indiana, iowa, kansas, kentucky, louisiana, maine, maryland, massachusetts, michigan, minnesota, mississippi, missouri, montana, nebraska, nevada, new hampshire, new jersey, new mexico, new york, north carolina, north dakota, ohio, oklahoma, oregon, pennsylvania, rhode island, south carolina, south dakota, tennessee, texas, utah, vermont, virginia, washington, west virginia, wisconsin, wyoming, I do not reside within the United States.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.3.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.3.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.3.2.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.3.2.1.1.1\" style=\"width:56.9pt;\">Living area</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.3.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.3.2.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.3.2.2.1.1\" style=\"width:313.0pt;\">Urban, Rural, Prefer not to answer</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.4.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.4.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.4.3.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.4.3.1.1.1\" style=\"width:56.9pt;\">Age</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.4.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.4.3.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.4.3.2.1.1\" style=\"width:313.0pt;\">18\u201325, 26\u201335, 36\u201345, 46\u201355, 56\u201365, 66 or older, Prefer not to answer</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.5.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.5.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.5.4.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.5.4.1.1.1\" style=\"width:56.9pt;\">Gender</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.5.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.5.4.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.5.4.2.1.1\" style=\"width:313.0pt;\">Woman, Man, Transgender, Non-conforming, A gender not listed here, Prefer not to answer</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.6.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.6.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.6.5.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.6.5.1.1.1\" style=\"width:56.9pt;\">Race</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.6.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.6.5.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.6.5.2.1.1\" style=\"width:313.0pt;\">Asian / Pacific Islander, Biracial, Black or African American, Hispanic or Latino, Middle Eastern or North African, Multiracial, Native American or American Indian, White, Other, Prefer not to answer</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.7.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.7.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.7.6.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.7.6.1.1.1\" style=\"width:56.9pt;\">Highest education</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.7.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.7.6.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.7.6.2.1.1\" style=\"width:313.0pt;\">Less than 8th grade, 8th grade, High School, Some college, no degree, Associate degree, Bachelor\u2019s degree, Master\u2019s degree, Professional degree, Doctorate degree, Prefer not to answer</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.8.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.8.7.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.8.7.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.8.7.1.1.1\" style=\"width:56.9pt;\">Marital status</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.8.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.8.7.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.8.7.2.1.1\" style=\"width:313.0pt;\">Married, Widowed, Divorced, Separated, Never married, Other, Prefer not to answer</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.9.8\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.9.8.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.9.8.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.9.8.1.1.1\" style=\"width:56.9pt;\">Number of children</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.9.8.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.9.8.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.9.8.2.1.1\" style=\"width:313.0pt;\">0, 1, 2, 3 or more, prefer not to answer</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.10.9\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.10.9.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.10.9.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.10.9.1.1.1\" style=\"width:56.9pt;\">Household</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.10.9.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.10.9.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.10.9.2.1.1\" style=\"width:313.0pt;\">I live alone, My spouse, My children, My siblings, My parents, My grandparents, Other relatives, Friends / Housemates, Prefer not to answer</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.11.10\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.11.10.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.11.10.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.11.10.1.1.1\" style=\"width:56.9pt;\">Employment status</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.11.10.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.11.10.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.11.10.2.1.1\" style=\"width:313.0pt;\">Employed full time (40 or more hours per week), Employed part time (up to 39 hours per week), Unemployed and currently looking for work, Unemployed not currently looking for work, Student, Retired, Homemaker, Self-employed, Unable to work, Prefer not to answer</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.12.11\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.12.11.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.12.11.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.12.11.1.1.1\" style=\"width:56.9pt;\">Income</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.12.11.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.12.11.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.12.11.2.1.1\" style=\"width:313.0pt;\">less than $10,000, $10,001 to $40,000, $40,001 to $80,000, $80,001 to $160,000, More than $160,000, Prefer not to answer</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.13.12\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.13.12.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.13.12.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.13.12.1.1.1\" style=\"width:56.9pt;\">Political</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.13.12.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.13.12.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.13.12.2.1.1\" style=\"width:313.0pt;\">Strongly liberal, Somewhat liberal, Somewhat conservative, Strongly conservative, Other, Prefer not to answer</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.14.13\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.14.13.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.14.13.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.14.13.1.1.1\" style=\"width:56.9pt;\">Religion</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T6.1.14.13.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.14.13.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.14.13.2.1.1\" style=\"width:313.0pt;\">Protestant, Catholic, Jewish, Buddhism, Hinduism, Islam, Orthodox-christian, Christian, Native American, Inter-nondenominational, Other (free text answer), None, Don\u2019t know, Prefer not to answer</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.15.14\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"A1.T6.1.15.14.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.15.14.1.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.15.14.1.1.1\" style=\"width:56.9pt;\">Participation frequency of religion</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"A1.T6.1.15.14.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.15.14.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.15.14.2.1.1\" style=\"width:313.0pt;\">Never, Less than once per year, Several times per year, Once per month, 2-3 times per month, Nearly every week, More than once per week, Prefer not to answer</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 6: </span>Demographics. For households, multiple options can be selected.</figcaption>\n</figure>",
            "capture": "Table 6: Demographics. For households, multiple options can be selected."
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"A1.T7\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A1.T7.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T7.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A1.T7.1.1.1.1\">Index</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T7.1.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.1.1.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.1.1.2.1.1\" style=\"width:341.4pt;\">Invervention statement</span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T7.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A1.T7.1.2.1.1\">1</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T7.1.2.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.2.1.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.2.1.2.1.1\" style=\"width:341.4pt;\">80% of BEV charging happens at home, and most trips do not involve public charging.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.3.2.1\">2</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.3.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.3.2.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.3.2.2.1.1\" style=\"width:341.4pt;\">Many people charge their BEVs at home with no additional equipment required. That means no trips to the gas station.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.4.3.1\">3</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.4.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.4.3.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.4.3.2.1.1\" style=\"width:341.4pt;\">The number of public charging stations is rapidly increasing due to additional government funding and business initiatives. That means shorter wait times and shorter charging trips.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.5.4.1\">4</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.5.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.5.4.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.5.4.2.1.1\" style=\"width:341.4pt;\">Analysts predict a decline in gas stations due to increased electric charging. That would make finding a nearby gas station more difficult.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.6.5.1\">5</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.6.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.6.5.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.6.5.2.1.1\" style=\"width:341.4pt;\">Charging at some public stations can be as fast as 6 minutes to add 100 miles.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.7.6.1\">6</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.7.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.7.6.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.7.6.2.1.1\" style=\"width:341.4pt;\">Charging at some public stations can be as fast as 30 minutes for 250 miles.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.8.7.1\">7</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.8.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.8.7.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.8.7.2.1.1\" style=\"width:341.4pt;\">BEVs maximum range is already approaching 400 miles, with forecasts for a 1000-mile range in the near future.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.9.8.1\">8</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.9.8.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.9.8.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.9.8.2.1.1\" style=\"width:341.4pt;\">Various programs offer different incentives (e.g. $7,500 tax credit) for new BEV purchases.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.10.9.1\">9</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.10.9.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.10.9.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.10.9.2.1.1\" style=\"width:341.4pt;\">Some BEV manufacturers may start offering free charging.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.11.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.11.10.1\">10</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.11.10.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.11.10.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.11.10.2.1.1\" style=\"width:341.4pt;\">People spend about 30% less on vehicle maintenance of BEVs than on ICEVs.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.12.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.12.11.1\">11</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.12.11.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.12.11.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.12.11.2.1.1\" style=\"width:341.4pt;\">Over its lifetime, a BEV can be $8,000 cheaper to maintain and operate than an ICEV.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.13.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.13.12.1\">12</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.13.12.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.13.12.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.13.12.2.1.1\" style=\"width:341.4pt;\">BEVs can be 4 cents per mile cheaper to maintain and operate than ICEVs.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.14.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.14.13.1\">13</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.14.13.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.14.13.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.14.13.2.1.1\" style=\"width:341.4pt;\">The cost of BEVs is much cheaper than it used to be.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.15.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.15.14.1\">14</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.15.14.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.15.14.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.15.14.2.1.1\" style=\"width:341.4pt;\">BEVs are expected to become cheaper than ICEVs in the near future.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.16.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.16.15.1\">15</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.16.15.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.16.15.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.16.15.2.1.1\" style=\"width:341.4pt;\">BEVs protect owners from the instability of the oil market.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.17.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.17.16.1\">16</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.17.16.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.17.16.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.17.16.2.1.1\" style=\"width:341.4pt;\">Most used BEVs are cheaper than comparable used ICEVs.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.18.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.18.17.1\">17</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.18.17.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.18.17.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.18.17.2.1.1\" style=\"width:341.4pt;\">Fossil fuels are expected to become more expensive over time.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.19.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.19.18.1\">18</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.19.18.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.19.18.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.19.18.2.1.1\" style=\"width:341.4pt;\">You need to replace the tires of a BEV less frequently than the tires of an ICEV.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.20.19\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.20.19.1\">19</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.20.19.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.20.19.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.20.19.2.1.1\" style=\"width:341.4pt;\">Lithium batteries are now 30 times cheaper than when they were first introduced to the market.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.21.20\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.21.20.1\">20</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.21.20.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.21.20.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.21.20.2.1.1\" style=\"width:341.4pt;\">A Level 1 home charger can cost as little as $300 (before labor).</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.22.21\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.22.21.1\">21</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.22.21.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.22.21.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.22.21.2.1.1\" style=\"width:341.4pt;\">BEVs have a smaller carbon footprint than ICEVs.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.23.22\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.23.22.1\">22</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.23.22.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.23.22.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.23.22.2.1.1\" style=\"width:341.4pt;\">ICEVs are more damaging to public health than BEVs due to carbon emissions.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.24.23\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.24.23.1\">23</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.24.23.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.24.23.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.24.23.2.1.1\" style=\"width:341.4pt;\">The towing capacity of BEVs already exceeds the towing capacity of comparable ICEVs.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.25.24\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.25.24.1\">24</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.25.24.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.25.24.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.25.24.2.1.1\" style=\"width:341.4pt;\">BEVs typically have greater acceleration and better passing abilities.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.26.25\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.26.25.1\">25</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.26.25.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.26.25.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.26.25.2.1.1\" style=\"width:341.4pt;\">BEVs are much quieter both in city and highway driving.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.27.26\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.27.26.1\">26</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.27.26.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.27.26.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.27.26.2.1.1\" style=\"width:341.4pt;\">BEVs\u2019 AWD systems provide greater low-speed control when driving off-road.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.28.27\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.28.27.1\">27</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.28.27.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.28.27.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.28.27.2.1.1\" style=\"width:341.4pt;\">BEVs provide better weight balance which improves handling.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.29.28\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.29.28.1\">28</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.29.28.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.29.28.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.29.28.2.1.1\" style=\"width:341.4pt;\">There is already availability of different types of BEVs, including sedans, sport cars, crossovers, trucks and minivans.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.30.29\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.30.29.1\">29</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.30.29.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.30.29.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.30.29.2.1.1\" style=\"width:341.4pt;\">BEV owners report greater satisfaction than ICEV owners</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.31.30\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.31.30.1\">30</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.31.30.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.31.30.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.31.30.2.1.1\" style=\"width:341.4pt;\">Cheaper BEVs have much better reliability than cheaper ICEVs.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.32.31\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.32.31.1\">31</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.32.31.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.32.31.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.32.31.2.1.1\" style=\"width:341.4pt;\">The new regulations for BEVs will require from manufacturers a 10-year / 150,000 miles warranty for batteries.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.33.32\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.33.32.1\">32</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.33.32.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.33.32.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.33.32.2.1.1\" style=\"width:341.4pt;\">Highly reputable car companies are adding BEVs to their model lineups.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.34.33\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.34.33.1\">33</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.34.33.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.34.33.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.34.33.2.1.1\" style=\"width:341.4pt;\">BEVs have lower center of gravity which increases stability in turns.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.35.34\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A1.T7.1.35.34.1\">34</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A1.T7.1.35.34.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.35.34.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.35.34.2.1.1\" style=\"width:341.4pt;\">Greater adoption of BEVs will increase energy independence and can help national security.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.36.35\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"A1.T7.1.36.35.1\">35</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"A1.T7.1.36.35.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.36.35.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.36.35.2.1.1\" style=\"width:341.4pt;\">New government initiatives regarding BEVs will require battery production in the USA, which will create jobs and boost the economy.</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 7: </span>Interventions</figcaption>\n</figure>",
            "capture": "Table 7: Interventions"
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"A2.T8\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 8: </span>Examples of the generated sentence for initial preference. There are three samples for each model. Pre-trained was generated with a maximum token number of 64. Red strings represent the range generated for a maximum token number of 8. The results indicate that the pre-trained model tends to generate responses other than preferences first.</figcaption>\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A2.T8.3\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T8.3.4.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A2.T8.3.4.1.1\">Model</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T8.3.4.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.3.4.1.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.3.4.1.2.1.1\" style=\"width:313.0pt;\">Generated sentence</span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T8.3.5.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T8.3.5.1.1\">7B</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A2.T8.3.5.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.3.5.1.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.3.5.1.2.1.1\" style=\"width:313.0pt;\"><span class=\"ltx_text\" id=\"A2.T8.3.5.1.2.1.1.1\" style=\"color:#FF0000;\">As a 52-year</span>-old white man living in an urban area of Minnesota, employed full-time with a bachelor\u2019s degree and a household income of $120,000, I would rate my current preference for battery electric vehicles (BEVs) as a</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.3.6.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.3.6.2.1\">7B</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.3.6.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.3.6.2.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.3.6.2.2.1.1\" style=\"width:313.0pt;\"><span class=\"ltx_text\" id=\"A2.T8.3.6.2.2.1.1.1\" style=\"color:#FF0000;\">As a 36-4</span>5 year old white woman living in urban Indiana with a Master\u2019s degree, I would rate my current preference for battery electric vehicles (BEVs) as a 60. While I recognize the potential benefits of BEVs, such as reduced emissions and lower operating</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.3.7.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.3.7.3.1\">7B</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.3.7.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.3.7.3.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.3.7.3.2.1.1\" style=\"width:313.0pt;\"><span class=\"ltx_text\" id=\"A2.T8.3.7.3.2.1.1.1\" style=\"color:#FF0000;\">As a 26-3</span>5 year old white woman living in urban Oregon with a Bachelor\u2019s degree, I would rate my current preference for battery electric vehicles (BEVs) as a 90. I strongly support the transition to sustainable and environmentally-friendly transportation,</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.3.8.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.3.8.4.1\">70B</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.3.8.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.3.8.4.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.3.8.4.2.1.1\" style=\"width:313.0pt;\"><span class=\"ltx_text\" id=\"A2.T8.3.8.4.2.1.1.1\" style=\"color:#FF0000;\">I\u2019m just an AI</span>, I don\u2019t have personal preferences or beliefs, but I can provide information and answer questions based on the given character\u2019s profile./n/nAs a 46-55-year-old white man living in urban California, working full-time and</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.3.9.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.3.9.5.1\">70B</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.3.9.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.3.9.5.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.3.9.5.2.1.1\" style=\"width:313.0pt;\"><span class=\"ltx_text\" id=\"A2.T8.3.9.5.2.1.1.1\" style=\"color:#FF0000;\">BEV preference score: 4</span>3.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.3.10.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.3.10.6.1\">70B</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.3.10.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.3.10.6.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.3.10.6.2.1.1\" style=\"width:313.0pt;\"><span class=\"ltx_text\" id=\"A2.T8.3.10.6.2.1.1.1\" style=\"color:#FF0000;\">My current preference for battery electric vehicles</span> (BEVs) is 75.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.1.1.2\">7B+QLoRA</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.1.1.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.1.1.1.1.1\" style=\"width:313.0pt;\">10 <span class=\"ltx_ERROR undefined\" id=\"A2.T8.1.1.1.1.1.1\">\\scalerel</span>*<img alt=\"[Uncaptioned image]\" class=\"ltx_graphics ltx_img_square\" height=\"36\" id=\"A2.T8.1.1.1.1.1.g1\" src=\"extracted/2403.20252v1/emoji/1f612.png\" width=\"36\"/>\u25cb</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.2.2.2\">7B+QLoRA</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.2.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.2.2.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.2.2.1.1.1\" style=\"width:313.0pt;\">80 <span class=\"ltx_ERROR undefined\" id=\"A2.T8.2.2.1.1.1.1\">\\scalerel</span>*<img alt=\"[Uncaptioned image]\" class=\"ltx_graphics ltx_img_square\" height=\"29\" id=\"A2.T8.2.2.1.1.1.g1\" src=\"extracted/2403.20252v1/emoji/1f697.png\" width=\"29\"/>\u25cb</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.3.3.2\">7B+QLoRA</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.3.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.3.3.1.1\">\n<span class=\"ltx_p\" id=\"A2.T8.3.3.1.1.1\" style=\"width:313.0pt;\">80 <span class=\"ltx_ERROR undefined\" id=\"A2.T8.3.3.1.1.1.1\">\\scalerel</span>*<img alt=\"[Uncaptioned image]\" class=\"ltx_graphics ltx_img_square\" height=\"36\" id=\"A2.T8.3.3.1.1.1.g1\" src=\"extracted/2403.20252v1/emoji/1f50b.png\" width=\"36\"/>\u25cb</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.3.11.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.3.11.7.1\">70B+QLoRA</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.3.11.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.3.11.7.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.3.11.7.2.1.1\" style=\"width:313.0pt;\">0</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.3.12.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T8.3.12.8.1\">70B+QLoRA</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"A2.T8.3.12.8.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.3.12.8.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.3.12.8.2.1.1\" style=\"width:313.0pt;\">50</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.3.13.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"A2.T8.3.13.9.1\">70B+QLoRA</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"A2.T8.3.13.9.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A2.T8.3.13.9.2.1\">\n<span class=\"ltx_p\" id=\"A2.T8.3.13.9.2.1.1\" style=\"width:313.0pt;\">10</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 8: Examples of the generated sentence for initial preference. There are three samples for each model. Pre-trained was generated with a maximum token number of 64. Red strings represent the range generated for a maximum token number of 8. The results indicate that the pre-trained model tends to generate responses other than preferences first."
        },
        "7": {
            "table_html": "<figure class=\"ltx_table\" id=\"A7.T10\">\n<div class=\"ltx_flex_figure ltx_flex_table\">\n<div class=\"ltx_flex_cell ltx_flex_size_2\">\n<figure class=\"ltx_figure ltx_figure_panel ltx_minipage ltx_align_top\" id=\"A7.T10.3\" style=\"width:178.9pt;\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Table 9: </span>Searched hyperparameters for SVR</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A7.T10.3.3\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A7.T10.3.3.4.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A7.T10.3.3.4.1.1\">Parameter</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A7.T10.3.3.4.1.2\">Values</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"A7.T10.3.3.5.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"A7.T10.3.3.5.2.1\">kernel</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"A7.T10.3.3.5.2.2\">linear, poly, rbf, sigmoid</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A7.T10.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A7.T10.1.1.1.2\">c</th>\n<td class=\"ltx_td ltx_align_left\" id=\"A7.T10.1.1.1.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A7.T10.2.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A7.T10.2.2.2.2\">epsilon</th>\n<td class=\"ltx_td ltx_align_left\" id=\"A7.T10.2.2.2.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A7.T10.3.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"A7.T10.3.3.3.2\">gamma</th>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A7.T10.3.3.3.1\"></td>\n</tr>\n</tbody>\n</table>\n</figure>\n</div>\n<div class=\"ltx_flex_cell ltx_flex_size_2\">\n<figure class=\"ltx_figure ltx_figure_panel ltx_minipage ltx_align_top\" id=\"A7.T10.8\" style=\"width:178.9pt;\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Table 10: </span>Searched hyperparameter for CatBoost</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A7.T10.8.5\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A7.T10.8.5.6.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A7.T10.8.5.6.1.1\">Parameter</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A7.T10.8.5.6.1.2\">Values</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A7.T10.4.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A7.T10.4.1.1.2\">learning rate</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A7.T10.4.1.1.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A7.T10.5.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A7.T10.5.2.2.2\">random strength</th>\n<td class=\"ltx_td ltx_align_left\" id=\"A7.T10.5.2.2.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A7.T10.6.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A7.T10.6.3.3.2\">one hot max size</th>\n<td class=\"ltx_td ltx_align_left\" id=\"A7.T10.6.3.3.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A7.T10.7.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A7.T10.7.4.4.2\">l2 leaf reg</th>\n<td class=\"ltx_td ltx_align_left\" id=\"A7.T10.7.4.4.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A7.T10.8.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"A7.T10.8.5.5.2\">bagging temperature</th>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A7.T10.8.5.5.1\"></td>\n</tr>\n</tbody>\n</table>\n</figure>\n</div>\n</div>\n</figure>",
            "capture": "Table 9: Searched hyperparameters for SVR"
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.20252v1_figure_1.png",
            "caption": "Figure 1: Convert survey data to prompt text. Left: Initial preference questionnaire. Right: Post-intervention preference questionnaire."
        },
        "2": {
            "figure_path": "2403.20252v1_figure_2.png",
            "caption": "Figure 2: Benchmark results. Line plots indicate the baseline points for each hyper-parameter. The left two plots show greedy sampling results (t=0\ud835\udc610t=0italic_t = 0). With greedy sampling, the fine-tuned models all outperform the pre-trained models. The largest model attains the best KL-divergence, but not the best RMSE score. None of the models outperform the supervised learning baselines on either RMSE or KL-divergence. The right two plots show calibrated sampling (t=1\ud835\udc611t=1italic_t = 1). All models outperform the baselines on KL-divergence, but not on RMSE. The square boxes overlap because the difference in fine-tuned model performance is small. Each value of fine-tuned models is described on Table 4."
        },
        "3": {
            "figure_path": "2403.20252v1_figure_3.png",
            "caption": "Figure 3: Sampling temperature effects. 7B+QLoRA. A temperature of 0.0 corresponds to greedy sampling, and a temperature of 1.0 corresponds to calibrated sampling. Varying the temperature allows trading off the population-wide statistical metric of KL-divergence against the per-individual RMSE metric."
        },
        "4": {
            "figure_path": "2403.20252v1_figure_4.png",
            "caption": "Figure 4: Numerical penalty term effects. 7B+QLoRA. The coefficient \u03b1\ud835\udefc\\alphaitalic_\u03b1 of the penalty term is fixed at 0.5. Penalty term allowed to decrease RMSE, It tends to decrease RMSE the most when d=10\ud835\udc5110d=10italic_d = 10."
        },
        "5": {
            "figure_path": "2403.20252v1_figure_5.png",
            "caption": "Figure 5: Learning curve (dash line indicate 1 epoch position.)"
        },
        "6": {
            "figure_path": "2403.20252v1_figure_6.png",
            "caption": "(a) Greedy sampling"
        },
        "7": {
            "figure_path": "2403.20252v1_figure_7.png",
            "caption": "(b) Calibrated sampling (t=1\ud835\udc611t=1italic_t = 1)"
        },
        "8": {
            "figure_path": "2403.20252v1_figure_8.png",
            "caption": "(a) 7B+QLoRA"
        },
        "9": {
            "figure_path": "2403.20252v1_figure_9.png",
            "caption": "(a) 7B+QLoRA"
        },
        "10": {
            "figure_path": "2403.20252v1_figure_10.png",
            "caption": "(a) 7B+QLoRA"
        },
        "11": {
            "figure_path": "2403.20252v1_figure_11.png",
            "caption": "(a) 7B+QLoRA"
        },
        "12": {
            "figure_path": "2403.20252v1_figure_12.png",
            "caption": "(b) 7B+LoRA"
        },
        "13": {
            "figure_path": "2403.20252v1_figure_13.png",
            "caption": "(c) 7B+LoRA vs QLoRA"
        },
        "14": {
            "figure_path": "2403.20252v1_figure_14.png",
            "caption": "(d) 7B+QLoRA"
        },
        "15": {
            "figure_path": "2403.20252v1_figure_15.png",
            "caption": "(e) 7B+LoRA"
        },
        "16": {
            "figure_path": "2403.20252v1_figure_16.png",
            "caption": "(f) 7B+LoRA vs QLoRA"
        },
        "17": {
            "figure_path": "2403.20252v1_figure_17.png",
            "caption": "(a) Greedy"
        },
        "18": {
            "figure_path": "2403.20252v1_figure_18.png",
            "caption": "(b) Calibrated sampling (t=1\ud835\udc611t=1italic_t = 1)"
        },
        "19": {
            "figure_path": "2403.20252v1_figure_19.png",
            "caption": "(c) Comparison between greedy and calibrated sampling (t=1\ud835\udc611t=1italic_t = 1)"
        },
        "20": {
            "figure_path": "2403.20252v1_figure_20.png",
            "caption": "(d) Greedy"
        },
        "21": {
            "figure_path": "2403.20252v1_figure_21.png",
            "caption": "(e) Calibrated sampling (t=1\ud835\udc611t=1italic_t = 1)"
        },
        "22": {
            "figure_path": "2403.20252v1_figure_22.png",
            "caption": "(f) Comparison between greedy and calibrated sampling (t=1\ud835\udc611t=1italic_t = 1)"
        },
        "23": {
            "figure_path": "2403.20252v1_figure_23.png",
            "caption": "Figure 9: Learning curve of Section 6.4 experiments (dash line indicate 1 epoch position.)"
        },
        "24": {
            "figure_path": "2403.20252v1_figure_24.png",
            "caption": "Figure 10: Training data amount effects. For the 10% and 50%, data were randomly selected from the training data. Error bars represent the standard deviation for 3 trials of fine-tuning."
        },
        "25": {
            "figure_path": "2403.20252v1_figure_25.png",
            "caption": "(a) Baselines for 0-100 preference"
        },
        "26": {
            "figure_path": "2403.20252v1_figure_26.png",
            "caption": "(b) Baselines for 0-9 preference"
        }
    },
    "references": [
        {
            "1": {
                "title": "Using large language models to simulate multiple humans and replicate human subject studies.",
                "author": "Gati V Aher, Rosa I Arriaga, and Adam Tauman Kalai.",
                "venue": "In International Conference on Machine Learning, pp.  337\u2013371. PMLR, 2023.",
                "url": null
            }
        },
        {
            "2": {
                "title": "Understanding and shifting preferences for battery electric vehicles, 2022.",
                "author": "Nikos Arechiga, Francine Chen, Rumen Iliev, Emily Sumner, Scott Carter, Alex Filipowicz, Nayeli Bravo, Monica Van, Kate Glazko, Kalani Murakami, Laurent Denoue, Candice Hogan, Katharine Sieck, Charlene Wu, and Kent Lyons.",
                "venue": "URL https://arxiv.org/abs/2202.08963.",
                "url": null
            }
        },
        {
            "3": {
                "title": "Redpajama: an open dataset for training large language models, 2023.",
                "author": "Together Computer.",
                "venue": "URL https://github.com/togethercomputer/RedPajama-Data.",
                "url": null
            }
        },
        {
            "4": {
                "title": "Qlora: Efficient finetuning of quantized llms.",
                "author": "Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer.",
                "venue": "Advances in Neural Information Processing Systems, 2023.",
                "url": null
            }
        },
        {
            "5": {
                "title": "BERT: pre-training of deep bidirectional transformers for language understanding.",
                "author": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.",
                "venue": "CoRR, abs/1810.04805, 2018.",
                "url": null
            }
        },
        {
            "6": {
                "title": "Can ai language models replace human participants?",
                "author": "Danica Dillion, Niket Tandon, Yuling Gu, and Kurt Gray.",
                "venue": "Trends in Cognitive Sciences, 2023.",
                "url": null
            }
        },
        {
            "7": {
                "title": "Alpacafarm: A simulation framework for methods that learn from human feedback.",
                "author": "Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, and Tatsunori Hashimoto.",
                "venue": "In Thirty-seventh Conference on Neural Information Processing Systems, 2023.",
                "url": null
            }
        },
        {
            "8": {
                "title": "The Pile: An 800gb dataset of diverse text for language modeling.",
                "author": "Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy.",
                "venue": "arXiv preprint arXiv:2101.00027, 2020.",
                "url": null
            }
        },
        {
            "9": {
                "title": "The challenge of using llms to simulate human behavior: A causal inference perspective.",
                "author": "George Gui and Olivier Toubia.",
                "venue": "SSRN Electronic Journal, 2023.",
                "url": null
            }
        },
        {
            "10": {
                "title": "Evaluating large language models in generating synthetic hci research data: a case study.",
                "author": "Perttu H\u00e4m\u00e4l\u00e4inen, Mikke Tavast, and Anton Kunnari.",
                "venue": "In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, pp.  1\u201319, 2023.",
                "url": null
            }
        },
        {
            "11": {
                "title": "Lora: Low-rank adaptation of large language models.",
                "author": "Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, and Weizhu Chen.",
                "venue": "CoRR, abs/2106.09685, 2021.",
                "url": null
            }
        },
        {
            "12": {
                "title": "Challenges and applications of large language models.",
                "author": "Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, and Robert McHardy.",
                "venue": "arXiv preprint arXiv:2307.10169, 2023.",
                "url": null
            }
        },
        {
            "13": {
                "title": "Generative agents: Interactive simulacra of human behavior, 2023.",
                "author": "Joon Sung Park, Joseph C. O\u2019Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein.",
                "venue": null,
                "url": null
            }
        },
        {
            "14": {
                "title": "Catboost: unbiased boosting with categorical features.",
                "author": "Liudmila Prokhorenkova, Gleb Gusev, Aleksandr Vorobev, Anna Veronika Dorogush, and Andrey Gulin.",
                "venue": "In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.",
                "url": null
            }
        },
        {
            "15": {
                "title": "Improving language understanding by generative pre-training, 2018.",
                "author": "Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever.",
                "venue": null,
                "url": null
            }
        },
        {
            "16": {
                "title": "Personality traits in large language models, 2023.",
                "author": "Greg Serapio-Garc\u00eda, Mustafa Safdari, Cl\u00e9ment Crepy, Luning Sun, Stephen Fitz, Peter Romero, Marwa Abdulhai, Aleksandra Faust, and Maja Matari\u0107.",
                "venue": null,
                "url": null
            }
        },
        {
            "17": {
                "title": "Role-play with large language models, 2023.",
                "author": "Murray Shanahan, Kyle McDonell, and Laria Reynolds.",
                "venue": null,
                "url": null
            }
        },
        {
            "18": {
                "title": "Llama 2: Open foundation and fine-tuned chat models, 2023.",
                "author": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas\nScialom.",
                "venue": null,
                "url": null
            }
        },
        {
            "19": {
                "title": "Attention is all you need.",
                "author": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin.",
                "venue": "Advances in neural information processing systems, 30, 2017.",
                "url": null
            }
        },
        {
            "20": {
                "title": "On decoding strategies for neural text generators.",
                "author": "Gian Wiher, Clara Meister, and Ryan Cotterell.",
                "venue": "Transactions of the Association for Computational Linguistics, 10:997\u20131012, 2022.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Large language models are diverse role-players for summarization evaluation, 2023.",
                "author": "Ning Wu, Ming Gong, Linjun Shou, Shining Liang, and Daxin Jiang.",
                "venue": null,
                "url": null
            }
        },
        {
            "22": {
                "title": "A survey of large language models, 2023.",
                "author": "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen.",
                "venue": null,
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.20252v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2"
        ],
        "methodology_sections": [
            "3",
            "4",
            "5"
        ],
        "main_experiment_and_results_sections": [
            "6",
            "6.1",
            "6.2",
            "6.3",
            "6.4"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "6.1",
            "6.2",
            "6.3",
            "6.4"
        ]
    },
    "research_context": {
        "paper_id": "2403.20252v1",
        "paper_title": "Using LLMs to Model the Beliefs and Preferences of Targeted Populations",
        "research_background": "### Paper's Motivation:\nThe paper is motivated by the significant evolution of large language models (LLMs) over the last decade and their successful application across various natural language processing tasks, code generation, and conversational UIs. One key motivation is the emerging potential for using LLMs as statistical proxies to study human beliefs, preferences, and behaviors, especially in scenarios where obtaining large-scale human data is challenging or impractical. For instance, companies could leverage LLMs to better understand customer preferences, conduct virtual surveys, and test behavioral interventions aimed at promoting sustainable technology adoption. There is considerable value in using LLMs in intervention research, particularly in cases where it would be impractical or unethical to perform large-scale human interventions. Thus, the ultimate goal is to ensure that LLMs can accurately model real human behaviors to enable these applications.\n\n### Research Problem:\nThe primary research problem tackled in the paper is the alignment of the beliefs and preferences of language models (LLMs) to serve as accurate statistical proxies for real human populations. It seeks to develop methods to ensure that LLMs exhibit behavior consistent with human reactions, especially in the context of population-wide statistics and individual preferences. The paper addresses the challenge of aligning LLMs' responses with real human survey data and proposes a novel penalty term in the loss function to improve performance on numerical survey questions. The research aims to fine-tune LLMs for better agreement with human preferences, investigate the effects of model size and other parameters, and benchmark these fine-tuned models against baseline algorithms.\n\n### Relevant Prior Work:\nThe paper builds on several strands of existing research. Key prior works referenced include:\n\n1. **Zhao et al. (2023)**: Discusses the advancements of LLMs in various domains over the last decade.\n2. **Dubois et al. (2023)**: Indicates that LLM responses can show strong agreement with human responses, suggesting their potential as proxies for studying human beliefs and behaviors.\n3. **Serapio-Garc\u00eda et al. (2023)**: Finds that LLMs in the PaLM family can be prompted to exhibit consistent, measurable personality traits.\n4. **Gui & Toubia (2023)**: Identifies significant challenges in using LLMs to emulate human behaviors, particularly in predicting demand for products like Coca-Cola.\n5. **Park et al. (2023)**: Provides previous work on community-wide simulations, which could be applied in conjunction with population-wide modeled LLMs.\n6. **Arechiga et al. (2022)**: Their survey on human beliefs and preferences concerning battery-electric vehicles (BEVs) is leveraged in the paper's experiments.\n7. **Dettmers et al. (2023)**: Discusses quantization techniques like QLoRA that offer computational savings with minimal performance degradation.\n\nThe paper also explores the effects of model size, quantization, and sampling temperature on LLM performance, contributing novel insights to the field.",
        "methodology": "### Methodology: Using LLMs to Model the Beliefs and Preferences of Targeted Populations\n\n#### Autoregressive Large Language Models\nAutoregressive language models specialize in predicting the next token in a sequence of language tokens. Formally, given a sequence of tokens `[t1, t2, ..., tn]`, these models aim to predict a probability distribution for the token `tn+1`. One of the significant advantages of these models is their ability to be trained in an unsupervised manner, meaning no manually produced labels are required. The requirement is simply a sizable corpus of natural text, which can be obtained from various sources, such as the internet. Examples of such corpora have been compiled by researchers (e.g., Gao et al., 2020 and Computer, 2023).\n\nThe architecture commonly employed for these models is the transformer architecture introduced by Vaswani et al. (2017). Specifically, the decoder-only transformer with a causal mask is often utilized. This causal mask ensures that the model does not have access to future tokens during the prediction process, a technique that was detailed by Radford et al. (2018).\n\n#### Fine-tuning Large Language Models\nOnce pre-trained on extensive text corpora, large language models (LLMs) can be adapted for specific downstream tasks. This fine-tuning involves updating the model parameters to cater to tasks such as sentiment analysis, question answering, or text summarization. While effective, this process can be computationally intensive, especially for large model sizes\u2014with guidelines and practices discussed by Radford et al. (2018) and Devlin et al. (2018).\n\nTo address the computational challenges associated with fine-tuning, various optimization techniques have been developed:\n\n1. **Low-Rank Adaptation (LoRA)**: Proposed by Hu et al. (2021), LoRA offers a more efficient method for fine-tuning large language models. It works by freezing the weights of the pre-trained model and introducing low-rank trainable matrices at strategic locations throughout the model. This dramatically reduces computational costs because only the new matrices require gradients during training, not the entire model.\n\n2. **Quantized LoRA (QLoRA)**: An extension of the LoRA technique, QLoRA further enhances efficiency by quantizing the model weights into 4-bit NormalFloats. This quantization compresses the model weights while retaining as much information as possible. Dettmers et al. (2023) introduced QLoRA along with several memory optimization techniques like double quantization and paged optimizers to handle memory spikes effectively.\n\nThese innovative adaptations\u2014LoRA and QLoRA\u2014enable the fine-tuning of large language models more economically, in terms of both computational power and memory usage, thereby broadening the practical application of these models in modeling the beliefs and preferences of targeted populations.",
        "main_experiment_and_results": "**Main Experiment Setup and Results:**\n\n**Experiment Setup:**\n1. **Models**: The main experiment uses various sizes of the Llama 2 model (7B, 13B, and 70B) which are chat models available on HuggingFace111.\n2. **Fine-tuning**: Models are fine-tuned using LoRA with specific LoRA dropout, over 3 epochs.\n3. **Data Splits**: The dataset is split into training, validation, and test sets with an 8:1:1 ratio by subject, ensuring no overlap of subjects between training and testing.\n4. **Evaluation Procedure**: The model is prompted for numerical answers, and the first number appearing within the generated text (sampled up to 8 tokens) is considered the model's response. Failures include non-numerical responses or numbers outside the correct range.\n5. **Metrics**: The evaluation metrics are KL-divergence and RMSE calculated from non-failed generations. Discretization widths of 10 and 1 are used in different sections to adapt scales.\n\n**Baselines:**\n1. **Support Vector Regression (SVR)** and **CatBoost**:\n   - These supervised learning algorithms are trained on survey data to predict preference values from a vector of demographic information.\n   - Categorical predictors are converted to dummy variables for SVR.\n   - Predicted preferences are normalized between 0 to 1.\n   - SVR and CatBoost's performance curves, obtained by training with multiple hyperparameters, are used for comparison.\n2. **Random Answer Model**:\n   - A model generating random answers as an additional benchmark.\n\n**Comparison Purpose**: \n- Evaluates performance at both individual and population levels, showcasing the potential solutions attainable with non-language models mapping demographic characteristics to survey responses.\n\n**Main Experimental Results:**\n- Performance is compared against the baseline models (SVR and CatBoost).\n- Results indicate that in many cases, supervised learning models outperform the language models.\n- It is noted that despite supervised learning algorithms' superior performance in some configurations, they are not suitable for downstream tasks like follow-up conversational responses or user surveys where language model capabilities are beneficial."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To analyze the effects of fine-tuning different model sizes on their ability to model human preferences, specifically focusing on the use of QLoRA for fine-tuning.",
            "experiment_process": "Three different model sizes (7B, 13B, and 70B) were fine-tuned using QLoRA and trained for 3 epochs, but final results were based on the 1 epoch checkpoint due to validation loss increase. Two sampling temperatures (0 and 1) were considered, representing greedy sampling and calibrated sampling, respectively. The models were evaluated using RMSE and KL-divergence metrics.",
            "result_discussion": "Fine-tuning with QLoRA reduced both RMSE and KL-divergence across all model sizes, with larger models showing lower KL-divergence. The 70B model performed best in both metrics, especially under calibrated sampling conditions. Although greedy sampling did not outperform supervised learning benchmarks, language models offer greater versatility for natural-language queries.",
            "ablation_id": "2403.20252v1.No1"
        },
        {
            "research_objective": "To compare the impact of the choice of fine-tuning method (LoRA vs QLoRA) on model performance.",
            "experiment_process": "A 7B parameter model was fine-tuned using LoRA and QLoRA, which differ mainly in parameter quantization. The models' performance was evaluated using KL-divergence and RMSE for initial preference questions and post-intervention questions, with results compared for each fine-tuning method.",
            "result_discussion": "LoRA produced better (lower) KL-divergence for initial preference questions and worse for post-intervention, while RMSE showed opposite trends. Differences were small, with high Spearman correlation coefficients for preferences (0.9 and 0.81). QLoRA, providing higher computational efficiency, was corroborated as an effective fine-tuning method.",
            "ablation_id": "2403.20252v1.No2"
        },
        {
            "research_objective": "To investigate how decoding temperature impacts model performance metrics, particularly the trade-off between population-wide and per-individual metrics.",
            "experiment_process": "A 7B model fine-tuned with QLoRA was evaluated using different decoding temperatures during stochastic sampling. RMSE and KL-divergence metrics were used to compare performance.",
            "result_discussion": "Greedy sampling had the lowest RMSE, while increasing temperature decreased KL-divergence but increased RMSE. This indicates a trade-off between KL-divergence and RMSE, with temperature enabling fine-grained control over this trade-off.",
            "ablation_id": "2403.20252v1.No3"
        },
        {
            "research_objective": "To evaluate the impact of introducing a numerical penalty term on model performance.",
            "experiment_process": "A 7B model fine-tuned with QLoRA over 3 epochs was used, leveraging a checkpoint at epoch 1 due to validation loss increase. Preference values scaled to 0-9 to apply the penalty term. Comparisons were made between no penalty term and variable penalty term hyperparameters, measured by RMSE and KL-divergence.",
            "result_discussion": "The introduction of a penalty term generally decreased both RMSE and KL-divergence compared to the case without it. The best value for the penalty term was identified, balancing cross-entropy loss and numerical penalty to improve model performance.",
            "ablation_id": "2403.20252v1.No4"
        }
    ]
}