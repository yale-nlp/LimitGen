{
    "title": "Explainable Few-shot Knowledge Tracing",
    "abstract": "Knowledge tracing (KT), aiming to mine students\u2019 mastery of knowledge by their exercise records and predict their performance on future test questions, is a critical task in educational assessment. While researchers achieved tremendous success with the rapid development of deep learning techniques, current knowledge tracing tasks fall into the cracks from real-world teaching scenarios. Relying heavily on extensive student data and solely predicting numerical performances differs from the settings where teachers assess students\u2019 knowledge state from limited practices and provide explanatory feedback. To fill this gap, we explore a new task formulation: Explainable Few-shot Knowledge Tracing. By leveraging the powerful reasoning and generation abilities of large language models (LLMs), we then propose a cognition-guided framework that can track the student knowledge from a few student records while providing natural language explanations. Experimental results from three widely used datasets show that LLMs can perform comparable or superior to competitive deep knowledge tracing methods. We also discuss potential directions and call for future improvements in relevant topics.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Knowledge tracing is a well-established problem originated from educational assessment [1  ###reference_b1###] aiming to dynamically model students\u2019 knowledge mastery and predict their future learning performances.\nWith the advancement of deep learning, models leveraging recurrent neural networks (RNNs) and attention mechanisms have gradually become mainstream for knowledge tracing [2  ###reference_b2###, 3  ###reference_b3###, 4  ###reference_b4###]. In recent years, KT research has shown two notable and promising directions. On the one hand, researchers attempt to incorporate multiple types of side information (e.g., exercise texts [5  ###reference_b5###], knowledge concept relationships and mappings [6  ###reference_b6###, 7  ###reference_b7###], students\u2019 problem-solving behaviors [8  ###reference_b8###]) with students\u2019 exercise history to more accurately model their knowledge states. On the other hand, they try to reveal the links between the latent representations learned by the models and factual data to provide interpretability for the knowledge tracing models [9  ###reference_b9###, 10  ###reference_b10###, 11  ###reference_b11###].\nDespite the numerous attempts and decent success, the current knowledge tracing task leaves gaps in reflecting real-world scenarios where teachers evaluate students\u2019 knowledge states. On the one hand, It relies on extensive student exercise records to train deep learning knowledge tracing models to achieve remarkable performance. In contrast, in real teaching scenarios, teachers can analyze students\u2019 mastery of knowledge from a limited number of practices. On the other hand, unlike teachers can infer students\u2019 answers by analyzing and explaining their knowledge mastery, the current task is simplified to only predicting whether a student will answer the test questions correctly, mainly by deep learning sequential predictive models. The black-box nature inherent in these models hampers exploring interpretability as they represent student knowledge states as hidden vectors. Apart from the abovementioned gaps, knowledge tracing models or frameworks encounter difficulties unifying and utilizing the multi-dimensional information collected from learning environments (e.g., student behaviors, question text, knowledge relations). Primarily proposed non-generative sequential models make it challenging for such tasks to come out of numerical prediction and extend to other scenarios, such as open-ended exercising and programming learning.\nIn recent years, the emergence and widespread utilization of large language models (LLMs) have provided potential solutions to fill the gaps. LLMs\u2019 capability to follow complex instructions with only a few examples and provide natural language feedback makes it possible to reform the current knowledge tracing paradigm.\nInspired by the success of LLMs in other fields, we improve upon the existing knowledge tracing task formulation and propose Explainable Few-shot Knowledge Tracing. As illustrated in Figure 1  ###reference_###, compared to traditional knowledge tracing, explainable few-shot knowledge tracing takes a small number of informative student exercise records as input, tracks students\u2019 mastery of knowledge, and predicts future performances through reasoning while providing reasonable explanations.\nFurthermore, leveraging LLMs\u2019 strong reasoning and generation abilities, the knowledge tracing task can readily adapt to diverse teaching scenarios with simple adjustments, presenting new opportunities for applying knowledge tracing in multiple educational scenarios.\nThe key contributions of this paper are as follows:\nWe analyze the deficiencies of conventional knowledge tracing and propose the explainable few-shot knowledge tracing task that aligns better with real teaching scenarios.\nWe introduce a cognition-guided framework that combines large language models and educational assessment principles to practice explainable few-shot knowledge tracing.\nWe adapt three public datasets and conduct experiments using open-source and closed-source LLMs. The results demonstrate that LLMs can perform comparable or superior to competitive knowledge tracing models. Furthermore, based on empirical observations from multi-perspective experiments, we suggest several potential directions for improvement.\n###figure_1###"
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Background",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Knowledge Tracing",
            "text": "Educational Assessment and Bayesian Knowledge Tracing\nEducational assessment aims to analyze students\u2019 knowledge states, and an assessment system is generally considered to comprise three main components: observation, cognition, and interpretation [12  ###reference_b12###]. Cognition refers to a model of how students represent knowledge. With the introduction of the knowledge tracing concept [1  ###reference_b1###], researchers have estimated students\u2019 knowledge states by analyzing their response records. Traditional knowledge tracing (KT) methods consist of two classics: Bayesian knowledge tracing (BKT) and factor analysis models [13  ###reference_b13###]. BKT is a hidden Markov model that treats each learner\u2019s knowledge state as a binary variable and utilizes Bayesian inference to update the state [14  ###reference_b14###]. In contrast, factor analysis models aim to learn generalized parameters from historical data [15  ###reference_b15###].\nDeep Knowledge Tracing\nRecently, numerous researchers have integrated deep neural networks into KT tasks for their effectiveness and outstanding performance. Piech et al. pioneered deep learning for KT using recurrent neural networks (RNNs) to process interaction sequences over time [2  ###reference_b2###] and proposed deep knowledge tracing task setting. With the success of deep learning techniques in other domains, such as word2vec [16  ###reference_b16###] and graph neural networks [17  ###reference_b17###, 18  ###reference_b18###], researchers recognized the potential to leverage these techniques by incorporating auxiliary information of questions [3  ###reference_b3###, 5  ###reference_b5###], knowledge concepts [6  ###reference_b6###, 9  ###reference_b9###], and students\u2019 learning behaviours [19  ###reference_b19###]. Moreover, attention-based models [4  ###reference_b4###, 20  ###reference_b20###] were introduced to tackle the computational expense and instability with long sequences of RNNs.\nWhile achieving success in performances, the lack of interpretability raised greater attention, as the model should provide transparency and understanding of the reasoning behind learning behaviors over just the outcomes. Models incorporating educational theories like the Rasch model [3  ###reference_b3###, 21  ###reference_b21###] and the transfer of knowledge [9  ###reference_b9###] were proposed to enhance interpretability. Minn et al. [10  ###reference_b10###] introduced causal relationships within latent features extracted from students\u2019 behaviors. Zhu et al. [11  ###reference_b11###] attempted to introduce causal inference for explanatory KT analysis.\nDespite the remarkable success, deep knowledge tracing tasks remain a few challenges. Most methods demand extensive student exercise logs for model training, aiming to make binary predictions, which differ from the real analyzing scenarios. The black-box nature inherent in deep learning models and numerical predictions limits the explainability and struggle to generalize to other teaching scenarios, such as open-ended knowledge tracing [22  ###reference_b22###, 23  ###reference_b23###] and programming learning [24  ###reference_b24###]."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Large Language Models",
            "text": "Large language models (LLMs) typically refer to transformer-based models containing hundreds of billions of parameters with multi-head attention layers stacked in very deep neural networks [25  ###reference_b25###]. LLMs can be categorized as open-sourced, like the LLaMA [26  ###reference_b26###] and GLM [27  ###reference_b27###] series, or close-sourced, like GPT-4. Trained on massive text data, LLMs exhibit solid natural language understanding to follow complex instructions and solve complex tasks due to their \"emergent abilities\" - capabilities not present in small language models but arising in large ones [28  ###reference_b28###]. Additionally, LLMs can leverage multi-dimensional information for reasoning and generate natural language responses.\nCurrently, researchers have achieved decent success across domains like weather forecasting [29  ###reference_b29###], recommendation [30  ###reference_b30###], and medicine [31  ###reference_b31###].\nAdvances in LLMs also brought new possibilities for education, where multiple aspects (e.g., teacher assistance, adaptive learning, and learning tools) benefit from the application of LLMs [13  ###reference_b13###, 32  ###reference_b32###, 33  ###reference_b33###, 34  ###reference_b34###].\nThe accomplishments in other fields indicate that applying LLMs to knowledge tracing could lead to similar success.\nHowever, of the less exploration is the work of utilizing LLMs for knowledge tracing. Neshaei et al. [35  ###reference_b35###] explore extending the sequence modeling capabilities of LLMs to knowledge tracing. It was found that fine-tuned LLMs outperformed naive baselines and matched Bayesian knowledge tracing, suggesting further refinements and a deeper understanding of their predictive mechanisms could enhance performance. Despite the first attempt, it is limited by the original knowledge tracing task settings, where LLMs cannot handle such extensive student exercise records. It motivates us to explore a knowledge tracing paradigm for the era of large language models, and to leverage the advantages of LLMs to address the shortcomings of traditional knowledge tracing settings."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Explainable Few-shot Knowledge Tracing",
            "text": "Deep knowledge tracing task [2  ###reference_b2###] is formulated as estimating student next state  given student records , questions , knowledge concepts  and a knowledge tracing model , denoted as,\nwhere  denotes the mapping relations of exercises and knowledge concepts.\nWe then define the explainable few-shot knowledge tracing by integrating selected student records , preditive model , questions  and knowledge concepts  with extended information to output estimated student states  and generate explanation , further formulated as,"
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Overview",
            "text": "To further practice explainable few-shot knowledge tracing tasks, we propose a cognition-guided framework by leveraging large language models, which consists of three indispensable fundamental components [12  ###reference_b12###] originated from assessment systems: Observation, denoted as , defining the task scenario and collecting data, Cognition, represented as , which models learners\u2019 knowledge state and predict performances, and Interpretation, denoted as , providing explanations of assessing processes.\nNotably, most existing knowledge tracing models primarily function as the Cognition module, while a few explainable knowledge tracing methods partially assume the role of the Interpretation module. As depicted in Figure 2  ###reference_###, by leveraging large language models, we can unify the Cognition and Interpretation, enabling them to ingest the diverse data acquired by the Observation module, integrating the three components to form a cohesive system. We further dive into the three components and then clarify how they work together within the new task.\n###figure_2###"
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Observation",
            "text": "Observation, which is the task or situation that allows one to observe students\u2019 performance [12  ###reference_b12###], defines the learning environment within the assessment system, determining factors such as the type of knowledge acquired by the learner and the tasks they engage with. It collects multi-dimensional and multi-modal data from the designated learning environment, generating the necessary inputs for subsequent assessment processes, and thus comprises two sub-modules: Learning Data Collection and Learning Data Selection. \nLearning Data Collection determines the data types to be collected based on the task scenario and carrying out the collection process. Typically, it involves gathering information such as the student\u2019s response sequence, including correctness, timestamps, and duration, as well as question-related information like problem contents and knowledge concepts, and forms structured dataset. \nLearning Data Selection curates the processed data through strategic selection and reorganizing, providing the refined inputs to the cognition and interpretation modules as required. In the implementation, we select several exercise records to generate informative few-shots for LLMs to predict performance. For simplicity, we implement systematic sample selection based solely on a fixed interval without considering the context or needed information richness from student history exercise records. \nDeep knowledge tracing models often require vast amounts of student response data for accurate prediction. In contrast, educators can frequently gauge a learner\u2019s knowledge level from a limited yet information-rich set of response records. The advantage of large language models lies in their ability to leverage in-context learning and reasoning, enabling them to extract high-quality insights while seamlessly ingesting diverse inputs. It aligns with real-world instructional scenarios and lays the foundation for fully exploiting the strengths of LLMs for cognition and interpretation."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Cognition",
            "text": "Cognition, which is a model of how students represent knowledge & develop competence in the domain [12  ###reference_b12###], synthesizes a comprehensive representation of the learner\u2019s evolving knowledge state  and generate predictions  from . This module is divided into two sub-modules: Knowledge State Analysis  and Performance Prediction .\nKnowledge State Analysis dynamically analyzes the learner\u2019s mastery of knowledge throughout the practice process by , containing student response records, question information, and behavioral patterns. It generates reliable knowledge state estimates  as essential references for performance prediction and Interpretation, formulated as,\nwhere  is the estimated knowledge state with respect to  and .  is the prompts designed for knowledge state analysis, and  is the set of interpretation of  to , which is elaborated in section 3.4  ###reference_###.\nIn the implementation, LLMs are asked to generate student mastery of knowledge with ternary value (good, fair, or fail) for each concept contained in the exercise the student encounters. It is also worthwhile to explore other customized analysis, deriving the benefits from the flexibility and generalizability of large language models compared to functionally similar cognitive diagnosis models.\nPerformance Prediction forecasts the learner\u2019s performance  on predefined environment  by mining selected data , estimated state  and interpretation  from , denoted as,\nis the data of exercise to predict and  is the prompts designed for predicting performance.Traditionally, performance is quantified as the probability of correctness or percentage scores. However, by leveraging the generative capabilities of large language models, we can extend the prediction to a broader range of learning scenarios less explored by deep learning models, such as open-ended question answering and programming tasks."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Interpretation",
            "text": "Interpretation, which is a method for making sense of the data relative to our cognitive model [12  ###reference_b12###], leverages  from the previous modules to generate diagnostic feedback and interpretable analytical insights. These insights facilitate targeted pedagogical interventions to optimize the learner\u2019s educational experience and provide a mechanism to evaluate and justify the validity of the observation module\u2019s task design and data selection strategies. The interpretation module comprises two sub-modules: Learning Trajectory Interpretation  and Learner Proficiency Explanation .\nLearning Trajectory Interpretation harnesses data , and the knowledge estimates  to furnish natural language explanations  for the learner\u2019s historical practice behaviors, formulated as,\nwhere  is the interpretation of student records  and . For instance, if a learner exhibits proficiency in the concepts related to a question but still provides an incorrect answer, it may attribute the error to carelessness, offering a plausible explanation. Importantly, these explanations can inform and refine the knowledge state analysis and performance prediction within Cognition, accounting for transient factors without unduly penalizing the learner\u2019s estimated knowledge state. In contrast, conventional deep learning models may inaccurately degrade the learner\u2019s knowledge states due to occasional carelessness, resulting in erroneous predictions. The versatility of large language models enables us to encompass and interpret a wide array of learner behaviors, furnishing more reliable and effective natural language explanations than the numerical interpretations provided by existing explainable knowledge tracing models.\nLearner Proficiency Explanation integrates  from observation, the estimated knowledge state , and the explanations  to provide meaningful insights  into the performance predictions of the Cognition module. It clarifies the complex interplay between learners\u2019 proficiency levels, learning habits, and task performance by situating these predictions within specific instructional scenarios and learner task contexts. The final process can be formulated as,\npromotes a nuanced explanation of learners\u2019 competencies, empowering educators to make timely adjustments to teaching content and cater to individual needs."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "In this section, we detail the approach to practicing explainable few-shot knowledge tracing, including the construction of datasets and model implementation. We compare the performance of LLMs on this task against deep learning models on traditional knowledge tracing. Furthermore, we investigate potential improvement when employing LLMs for this task."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Task Setups",
            "text": "###figure_3### Datasets We selected three public datasets: FrcSub111http://staff.ustc.edu.cn/%7Eqiliuql/data/math2015.rar, MOOCRadar [36  ###reference_b36###], and XES3G5M [37  ###reference_b37###].\nThe detailed statistics of these three datasets are presented in Appendix A  ###reference_###.\nThe task can integrate multidimensional information as input by designing structured textual data and appropriate prompts.\nDepending on the type of side information incorporated, we created different modes:scant and sparse for three datasets, and additional moderate mode for MOOCRadar and XES3G5M, varying degrees of information richness, shown in Figure 3  ###reference_###. The scant mode utilizes only the primary student ID, exercise ID, skill ID, and student interaction records. The sparse mode builds upon scant by incorporating skill representation information. The moderate further includes textual descriptions of exercises over the sparse.\nMetrics\nWe collect accuracy, precision, recall, and F1 scores as evaluation metrics, as the area under the curve (AUC) cannot be employed since LLMs provide binary predictions. Due to page constraints, the experimental results of precision and recall metrics will be included in the Appendix F  ###reference_### and H  ###reference_###.\nBaselines\nWe select several commonly employed and competitive baselines in knowledge tracing:\n1) DKT [2  ###reference_b2###] employs LSTM layers to encode the students\u2019 knowledge state and predict their performance on exercises.\n2) DKVMN [38  ###reference_b38###] designs a static key matrix to capture relations between knowledge components and a dynamic value matrix to track the evolution of students\u2019 knowledge.\n3) GKT [6  ###reference_b6###] leverages graph structure to model interactions between exercises.\n4) AKT [3  ###reference_b3###] utilizes an attention mechanism to characterize the temporal distance between questions and the student\u2019s history interactions.\n5) SAKT [20  ###reference_b20###] incorporates a self-attention module to capture latent relations between exercises and student responses.\n6) SAINT [4  ###reference_b4###] adopts a transformer architecture to jointly model sequences of exercises and responses."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Overall Performance",
            "text": "We compared the best performance of GLM3-6B [27  ###reference_b27###], GLM4, and GPT-4 across all modes of three datasets with considered baselines. Notably, all considered baselines requires the full training set to achieve best performances, whereas ours only require a few, and such a small amount is far from enough for the baselines. The best three metrics in each column are marked using bold, underlined, and italics. Overall, GLM4 and GPT-4 performed comparable or superior to the baselines on all three datasets. Notably, on the MOOCRadar dataset, GLM4 and GPT-4 outperformed all baselines, showing improvements of 3.01% and 1.66% in Accuracy and F1 Score, respectively. It demonstrates that leveraging LLMs within explainable few-shot knowledge tracing can match or surpass conventional deep learning models. In contrast, GLM3-6B did not perform as well as expected, which could be attributed to the extensive input context. During experiments, we observed that the GLM3-6B often struggled to follow instructions, indicating that a fine-tuned small model may potentially achieve better performances. Specifically, we present more comprehensive results in Appendix F  ###reference_###, and the implementation details to achieve the best performance in Appendix B  ###reference_###.\n###table_1### ###figure_4### ###figure_5###"
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Case Study",
            "text": "We randomly select examples of all considered LLMs from the MOOCRadar-moderate. It involves estimating the student\u2019s knowledge state in student history records, predicting student performances, and providing an explanation. Identifiers are colored to correspond with modules in Figure 2  ###reference_###.\nThe content before <Exercise to Predict> contained the previous context, including four few-shots and the LLM\u2019s analysis of the student\u2019s responses based on the selected examples. <Exercise to Predict> contains the information of the test exercise. <Output Predicted is_correct> represented the LLM\u2019s prediction of the student\u2019s performance on <Exercise to Predict>, followed by an explanation for the prediction. For detailed prompts and more cases, please refer to Appendices I  ###reference_### and J  ###reference_###.\nGLM3-6B\nAs shown in Figure 5  ###reference_###, we removed the knowledge state analysis for each student exercise record to limit the input length for GLM3-6B. However, in many cases, even though it output predictions on all exercises the student had encountered, it failed to satisfactorily meet our required output format, which is only one 0 or 1 for a single test exercise.\nGLM4 & GPT-4\nIllustrated in Figure 5  ###reference_###, we highlighted the differences between the outputs of GLM4 and GPT-4 in gray. We observed that both models are able to follow the instructions and generate formatted explanations in most cases. Differences occurs where GPT-4 incorrectly assumed the student had answered Exercise 24 incorrectly and provided an explanation for this assumption. Furthermore, when explaining its prediction, GPT-4 failed to recognize the incorrectness of the student\u2019s performance and instead offered an explanation suggesting the student had answered correctly. This issue was also present in some cases for GLM4, possibly due to the models\u2019 limited context window to accurately identify such shot and specific information."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "Discussion",
            "text": "We will discuss empirical observations from designed experiments and the potential directions for improving performances when leveraging LLMs for explainable few-shot knowledge tracing.\n###table_2### ###figure_6### Exercise text helps a lot; knowledge concepts do a little.\nWe analyze the performance of GLM4 and GPT-4 on the different modes in FrcSub dataset and MOOCRadar dataset, as shown in Figure 6  ###reference_###. \"GLM4-acc\" denotes the accuracy metrics for GLM4 selecting first 4 few-shots.\nIt can be observed that the performances substantially improve from sparse to moderate mode in MOOCRadar. Integrating only knowledge concepts gains a relatively lower improvement or even a slight decline in Frcsub using GPT-4. It indicates that combining exercise textual information benefits more than knowledge concepts since exercise texts provide more contexts, and concepts provide less than those using IDs.\nTherefore, a key consideration for boosting performance lies in fully leveraging the existing datasets, formulating them into structured texts, and designing proper prompts that enable LLMs to utilize the additional information effectively.\nIncreasing the number of few-shots benefits, but too much leads to confusion.\nWe analyze GLM4\u2019s performance when using 4, 8, and 16 randomly selected few-shots to explore the impact of different numbers of few-shots on the final results.\nAs shown in Table 2  ###reference_###, increasing the number of few-shots leads to improved performance. Notably, for the XES3G5M-sparse dataset, the accuracy saw a significant 71.4% improvement from 0.4399 with four shots to 0.7542 with 16 shots, and the F1 score achieved an impressive 78.4% enhancement. These results highlight the substantial benefits of utilizing more few-shots, especially for student with long records, which is presented in Appendix E  ###reference_###.\nHowever, excessive few-shots would result in an overly long and repeated context, hampering the LLMs\u2019 capabilities. Even with 4 few-shots, for those that are relatively small, like GLM3-6B in Figure 4  ###reference_###, it fails to follow the instructions, and for GLM4 and GPT-4 in Figure 5  ###reference_###, it leads to incorrectly capturing the student behavior information. As a consequences, it may result in generating misguided information. Therefore, developing effective memory modules enabling LLMs to leverage more few-shots for tracking students\u2019 states remains an important direction to explore.\nRandom few-shots work better in long sequences. We investigate the impact of different few-shot selection strategies on the final performance. Figure 7  ###reference_### shows the performance of the \"First\" or \"Random\" selection strategies, using GLM3-6B and GLM4 on FrcSub-scant and MOOCRadar-scant datasets. Generally, the random selection outperforms selecting the first few exercises as few-shots. It is more pronounced in datasets with longer student interaction records. When student learning histories are extensive, the test exercises are more likely unrelated to the initial questions, as demonstrated in Appendix E  ###reference_###. It is worth noting that there remains significant room for improvement in selection strategies. We recommend exploring more optimal selection methods. For instance, one could select the most recent exercise records, similar exercises to the predicted ones, or utilize retrieval-augmented generation to construct informative few-shots.\n###figure_7###"
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusions",
            "text": "We formulated the explainable few-shot knowledge tracing task to fill the gap between the conventional knowledge tracing task and real teaching scenarios and proposed a cognition-guided framework to conduct this task. We further demonstrate that LLMs can achieve comparable or superior performances to competitive baselines in conventional knowledge tracing while providing more natural language explanations under our proposed framework. Then, we discuss potential directions for further enhancing LLM performance on this task, including providing more informative relevant few-shots. The ability of large language models enables understanding student essays or programming codes, even for multi-modal inputs (e.g., drawings, speech).\nBy modifying the prompts of modules in the framework and incorporating specific information, it is worthwhile to extend explainable few-shot knowledge tracing to new tasks, where of the less exploration by existing methods are tasks like open-ended question answering and programming knowledge tracing."
        }
    ],
    "url": "http://arxiv.org/html/2405.14391v2",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2.1",
            "2.2"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3",
            "3.4"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.2",
            "4.3",
            "4.4"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4.2",
            "4.4"
        ]
    },
    "research_context": {
        "paper_id": "2405.14391v2",
        "paper_title": "Explainable Few-shot Knowledge Tracing",
        "research_background": "### Motivation\nThe paper addresses the need to bridge the gap between real-world educational practices and current knowledge tracing (KT) models driven by deep learning. While conventional KT models achieve impressive performance by relying on extensive student exercise data and operate as black-box systems, they lack the interpretability and adaptability sought in real teaching scenarios. Teachers, differently, can gauge student knowledge with a few exercises and provide reasoned explanations\u2014a capability missing from present KT models.\n\n### Research Problem\nThe primary problems identified are:\n1. The over-reliance of current KT models on extensive student data, contrasting with the real-world scenario where teachers assess knowledge from limited exercises.\n2. A lack of interpretability in existing models, as they typically predict whether a student will answer test questions correctly without explaining the student's knowledge mastery.\n3. The difficulty in integrating and utilizing multi-dimensional information from various learning environments.\n4. The challenges with non-generative sequential models in extending beyond numerical predictions to broader educational contexts like open-ended exercises and programming.\n\n### Relevant Prior Work\n1. **Dynamic Student Modeling**: Existing KT models, especially those using recurrent neural networks (RNNs) and attention mechanisms, have become mainstream in capturing students' knowledge states and predicting learning outcomes [2  ###reference_b2###, 3  ###reference_b3###, 4  ###reference_b4###].\n2. **Incorporating Side Information**: Researchers have attempted to enhance KT models by integrating varied information such as exercise texts [5  ###reference_b5###], knowledge concept relationships [6  ###reference_b6###, 7  ###reference_b7###], and student problem-solving behaviors [8  ###reference_b8###].\n3. **Interpretability in KT Models**: Some studies tackle interpretability by trying to link the learned latent representations of KT models with factual data to shed light on the learning processes [9  ###reference_b9###, 10  ###reference_b10###, 11  ###reference_b11###].\n4. **Large Language Models (LLMs)**: The advent of LLMs, recognized for their complex instruction-following and language generation capabilities, presents an opportunity to revolutionize KT models by addressing the identified gaps.\n\n### Approach and Contributions\nThe paper introduces \"Explainable Few-shot Knowledge Tracing\" which aims to:\n1. Model students\u2019 knowledge with fewer exercise records while providing explanations akin to how teachers assess knowledge.\n2. Utilize LLMs to enable sophisticated reasoning and explanation capabilities, making KT models adaptable to a variety of educational contexts.\n3. Propose a novel cognition-guided framework combining LLMs with educational principles to enforce this explainable few-shot mechanism.\n4. Apply this framework to public datasets, demonstrating that LLM-based models can perform on par or better than traditional KT models, with added interpretability and adaptability.",
        "methodology": "**Methodology: Explainable Few-shot Knowledge Tracing**\n\nThe deep knowledge tracing task, as introduced in prior research [2 ###reference_b2###], involves predicting a student's next knowledge state based on their previous records. The prediction is based on an understanding of student records (), the questions they interacted with (), the underlying knowledge concepts (), and a pre-defined knowledge tracing model (). The relationship between exercises and knowledge concepts is denoted by , which helps to map exercises to specific knowledge areas.\n\nTo further refine this approach, we introduce the concept of explainable few-shot knowledge tracing. This method integrates selected student records (), a predictive model (), questions (), and knowledge concepts (), enhancing the process with additional information to produce two key outcomes: the estimated student states () and an explanation of the prediction. The process can be formally expressed as:\n\n**Key Components and Innovations:**\n\n1. **Integration of Extended Information**: The proposed model combines traditional elements (student records, questions, knowledge concepts, and a predictive model) with expanded information aimed at improving the accuracy of the estimated student states and the clarity of the generated explanations.\n\n2. **Explainability**: A significant innovation of this method is its focus on generating explanations alongside predictions. This is crucial for ensuring that the knowledge tracing process is transparent and interpretable for educators and students.\n\n3. **Few-shot Learning**: By utilizing a few-shot learning approach, the methodology is designed to make accurate predictions and provide meaningful explanations even when only limited student data is available.\n\nIn summary, our proposed method enhances traditional deep knowledge tracing by combining it with extended information and a focus on explainability, ensuring that predictions are not only accurate but also understandable, which has the potential to significantly benefit the educational process.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n**Experiment Setup:**\n\n- **Datasets:**\n  The primary datasets used for the experiments include standard educational datasets commonly utilized in knowledge tracing research. These datasets consist of student interaction logs, capturing the sequence of problems attempted by students and their corresponding correctness.\n\n- **Baselines:**\n  The performance of large language models (LLMs) is compared against traditional deep learning models used for knowledge tracing, such as Deep Knowledge Tracing (DKT) and other established approaches in the field.\n\n**Evaluation Metrics:**\n- The effectiveness of the models is measured using standard metrics for knowledge tracing tasks, including:\n  - AUC (Area Under the Receiver Operating Characteristic Curve)\n  - Accuracy, to evaluate the correctness of predictions regarding student knowledge state over time.\n\n**Main Experimental Results:**\n\n- **Performance Comparison:**\n  The comparison indicated that LLMs demonstrated comparable performance to traditional deep learning models on the knowledge tracing task. In some cases, LLMs outperformed these models, particularly in scenarios with fewer samples (the few-shot setting).\n\n- **Potential Improvement:**\n  The experiments further revealed that employing LLMs for knowledge tracing can lead to potential improvements in prediction accuracy and model robustness, especially in few-shot learning situations. This suggests that LLMs hold promise for enhancing the effectiveness of knowledge tracing techniques, providing more precise and explainable outcomes. \n\nBy leveraging the unique strengths of LLMs, such as their advanced language understanding capabilities, the study highlights a promising direction for the development of more accurate and explainable models in educational settings."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To investigate the impact of integrating exercise textual information and knowledge concepts on the performance of LLMs in explainable few-shot knowledge tracing.",
            "experiment_process": "The experiment analyzed the performance of GLM4 and GPT-4 on the FrcSub and MOOCRadar datasets in different modes. 'GLM4-acc' denotes the accuracy metrics for GLM4 selecting the first 4 few-shots. The experiment included varied combinations of exercise text and knowledge concepts and evaluated the performance using the accuracy metrics.",
            "result_discussion": "The performances substantially improve when transitioning from sparse to moderate mode in the MOOCRadar dataset. Integrating only knowledge concepts showed lower improvement or a slight decline in FrcSub when using GPT-4. This indicates that combining exercise text information is more beneficial as it provides more contextual information compared to knowledge concepts, which offer less value than IDs.",
            "ablation_id": "2405.14391v2.No1"
        },
        {
            "research_objective": "To assess the effect of increasing the number of few-shots on the performance of GLM4 in student knowledge tracing.",
            "experiment_process": "The performance of GLM4 was analyzed by selecting 4, 8, and 16 random few-shots from the XES3G5M-sparse dataset. The study measured the impact on accuracy and F1 score with different numbers of few-shots to determine the optimal number for best performance.",
            "result_discussion": "Increasing the number of few-shots led to significant improvement in performance. For instance, the accuracy in the XES3G5M-sparse dataset saw an improvement from 0.4399 with four shots to 0.7542 with 16 shots (a 71.4% increase), and the F1 score saw a 78.4% enhancement. However, using too many few-shots can lead to overly long and repeated context, hampering the LLMs' ability to follow instructions and causing incorrect behavior capture, leading to misguided information generation.",
            "ablation_id": "2405.14391v2.No2"
        },
        {
            "research_objective": "To evaluate the efficacy of different few-shot selection strategies on the performance of GLM3-6B and GLM4 in datasets with varying lengths of student interaction records.",
            "experiment_process": "The experiment compared the 'First' and 'Random' few-shot selection strategies using GLM3-6B and GLM4 on FrcSub-scant and MOOCRadar-scant datasets. The performance of the models was analyzed to see which strategy yielded better results.",
            "result_discussion": "The random selection strategy generally outperformed the 'First' selection strategy, especially in datasets with longer student interaction records. As student learning histories became more extensive, the initial questions became less related to the test exercises, making random selection more effective. The study suggests exploring more optimal selection methods, such as selecting the most recent or similar exercises or using retrieval-augmented generation for constructing informative few-shots.",
            "ablation_id": "2405.14391v2.No3"
        }
    ]
}