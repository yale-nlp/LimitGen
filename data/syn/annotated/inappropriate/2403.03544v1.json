{
    "title": "Prompt Mining for Language-based Human Mobility Forecasting",
    "abstract": "With the advancement of large language models, language-based forecasting has recently emerged as an innovative approach for predicting human mobility patterns. The core idea is to use prompts to transform the raw mobility data given as numerical values into natural language sentences so that the language models can be leveraged to generate the description for future observations. However, previous studies have only employed fixed and manually designed templates to transform numerical values into sentences. Since the forecasting performance of language models heavily relies on prompts, using fixed templates for prompting may limit the forecasting capability of language models. In this paper, we propose a novel framework for prompt mining in language-based mobility forecasting, aiming to explore diverse prompt design strategies. Specifically, the framework includes a prompt generation stage based on the information entropy of prompts and a prompt refinement stage to integrate mechanisms such as the chain of thought. Experimental results on real-world large-scale data demonstrate the superiority of generated prompts from our prompt mining pipeline. Additionally, the comparison of different prompt variants shows that the proposed prompt refinement process is effective. Our study presents a promising direction for further advancing language-based mobility forecasting.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1. Introduction",
            "text": "The forecasting of human mobility plays a crucial role in various domains, including urban planning, transportation management, public health preparedness, and disaster response. Accurate predictions of movement patterns and trends can facilitate better location-based services, proactive decision-making, optimize resource allocation, and enhance overall societal resilience.\nTraditional statistical forecasting methods (Calabrese et al., 2010  ###reference_b2###; Qiao et al., 2018  ###reference_b16###) often rely on numerical models, but they might fall short in capturing the complex human behaviour in real-world scenarios. In an effort to capture these complex patterns, more advanced deep learning forecasting methods (Feng et al., 2018  ###reference_b5###; Sun et al., 2020  ###reference_b19###; Yin et al., 2023  ###reference_b31###), particularly Transformer-based approaches(Xue and Salim, 2021  ###reference_b27###; Hong et al., 2022  ###reference_b7###; Xue et al., 2021  ###reference_b26###), have emerged. However, these methods often require very complicated model architectures.\nRecently, language-based forecasting approaches (Xue et al., 2022a  ###reference_b29###, b  ###reference_b30###; Xue and Salim, 2023  ###reference_b28###) have demonstrated another line of work and emerged as a promising alternative, harnessing the power of natural language processing (NLP), language generation frameworks, and advanced pre-trained language models to generate forecasts. These methods present a new paradigm (as shown in Figure 1  ###reference_### (b)) for forecasting human mobility.\nBy transforming numerical data into natural language sentences, these methods make it possible to use existing available language models to comprehend and predict human mobility patterns.\nThis shift towards language-based forecasting has opened up new avenues for enhancing predictive capabilities. Language models, such as Bert (Devlin et al., 2019  ###reference_b4###) and its successors, have demonstrated remarkable proficiency in understanding and generating human language. Leveraging their capabilities for mobility forecasting offers the potential to achieve accurate predictions while also reducing the need of designing complex specific forecasting models.\n###figure_1### However, a key challenge in language-based mobility forecasting lies in the design of effective prompts, that is, how to transform the numerical mobility data and associated auxiliary information into sentences for language models.\nThese prompts serve as the bridge between raw numerical data and natural language descriptions, shaping how well language models can capture the underlying mobility patterns.\nGenerally, different prompts can lead to varying language generation performance, consequently impacting the accuracy of the forecasting.\nTaking ChatGPT as an example, even for the same topic, using different prompts as inputs will largely result in different responses.\nHence, although using fixed manually designed templates for prompt generation as in existing work (Xue et al., 2022a  ###reference_b29###, b  ###reference_b30###; Xue and Salim, 2023  ###reference_b28###) is simple and straightforward, inadequate prompt template exploration can lead to inaccurate forecasts\nTo address these limitations, we propose a novel prompt mining framework for the language-based mobility forecasting task (Figure 1  ###reference_### (c)). Our framework is a multi-stage pipeline with prompt initialization, prompt generation, and prompt refinement stages.\nSpecifically, in the prompt generation stage, we introduce a Prompt Quality Evaluator that evaluates the quality of generated prompts based on a combination of heuristic classifier rules and prompt entropy. By doing so, we can quantitatively evaluate the quality of prompts, which enables the prompt generation model to receive feedback for generating high-quality prompts during training.\nThe prompt refinement stage aims to enhance the generated prompts through a series of sophisticated mechanisms including noise reduction, integration of a chain of thought, and the application of information gain-based temporal segmentation on mobility data. These strategies collectively contribute to generating more refined and contextually relevant prompts.\nThrough extensive experiments with real-world large-scale mobility data, we show the effectiveness of our prompt mining approach. Our results showcase the superiority of generated prompts compared to traditional fixed templates.\nIn summary, our work has 3 main contributions:\nWe propose a novel prompt mining framework that addresses the limitations of relying on fixed templates in existing methods. The chain of thought consideration is also integrated into the prompt mining pipeline.\nIn our framework, the concept of information entropy is explored in both the semantics of the prompt in the prompt generation stage as well as the distribution of the mobility data in the prompt refinement stage.\nWe conduct extensive experiments on real-world mobility data to empirically validate the efficacy of our proposed method. Our mined prompt variants show good performance under the language-based mobility forecasting setting."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2. Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1. Numerical Time Series Forecasting",
            "text": "Human mobility forecasting is often conceptualized as a special case within the broader scope of general time series forecasting. Consequently, methodologies developed for general time series forecasting are frequently applied to this domain.\nModern time series forecasting techniques heavily rely on deep learning, primarily utilizing Recurrent Neural Network (RNN) architectures such as Long Short Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997  ###reference_b6###) and Gated Recurrent Units (GRU) (Chung et al., 2014  ###reference_b3###).\nExamples within this RNN-based framework for predicting sequential human behavior include ST-RNN (Liu et al., 2016  ###reference_b11###) and DeepMove (Feng et al., 2018  ###reference_b5###).\nMotivated by the recent success of applying Transformer architecture (Vaswani et al., 2017  ###reference_b22###) in modeling nature language sequences, it has also been applied for human mobility forecasting (Xue and Salim, 2021  ###reference_b27###; Xue et al., 2021  ###reference_b26###) and general time series forecasting tasks (Zhou et al., 2021  ###reference_b37###; Xu et al., 2021  ###reference_b25###; Zhou et al., 2022  ###reference_b38###).\nThese methodologies, whether based on RNNs or advanced Transformer architectures, typically adopt a sequence-to-sequence approach, where historical numerical observations form the input sequence to predict future outcomes.\nAs the need to incorporate semantic information (e.g., a POI is a restaurant or a shop) arises to further improve forecasting performance, the complexity of model architectures tends to increase."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2. Language-based Forecasting",
            "text": "Efforts to integrate semantic information more directly and effectively have led to the introduction of shaping mobility forecasting as a language generation problem.\nXue et al. (Xue et al., 2022a  ###reference_b29###) introduced this approach, utilizing natural language sentences to describe historical observations and prediction targets, thereby transforming the forecasting task into a language generation format.\nBuilding upon this framework, (Xue et al., 2022b  ###reference_b30###) leverages language foundation models such as BERT (Devlin et al., 2019  ###reference_b4###) as the backbone network of the language generation part to conduct human mobility tasks.\nThe recent work (Xue and Salim, 2023  ###reference_b28###) further introduced the concept of PromptCast that extended language-based forecasting to other time series data domains like energy and temperature forecasting. However, the prompts used to describe time series are still based on fixed heuristic templates (e.g., similar to Figure 1  ###reference_### (b)).\nIn this paper, we hypothesize that the performance of language-based forecasting is related to the ways of using language sentences to describe numerical data.\nUnlike prior studies that have focused narrowly on fixed templates for prompting, our work aims to address this gap by exploring methods to develop more effective prompts, thereby potentially enhancing the performance of the language-based forecasting paradigm.\n###figure_2###"
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3. Method",
            "text": ""
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1. Problem Formulation",
            "text": "In this subsection, we formally define the problem that our proposed prompt mining framework aims to address: enhancing language-based human mobility forecasting through optimized prompt design.\nAs influenced by previous studies (Xue et al., 2022a  ###reference_b29###, b  ###reference_b30###), we simplify the forecasting task of interest as follows.\nGiven the historical customer visit records of a Point of Interest (POI)  over a span of  consecutive days, represented as , the objective is to predict the number of visits  for the subsequent day .\nNormally, different types of auxiliary information of  such as the area region information , the semantic information , the opening information (e.g., business opening time  and ending time ), or fine-grained hourly visits are often available, which can be used to assist the forecasting.\nFor the sake of clarity and simplification, we will omit the superscript  (indicative of the POI index) from this point onward.\nTemplate and Prompt: To leverage language models for the forecasting purpose, existing methods employ a predefined prompting template P to convert the numerical data (e.g.,  and ) into sentences (these sentences are referred as prompts) that can be directly processed by language models.\nThe template consists of placeholders for the actual values from the data, resulting in sentences that present the mobility information in a human-readable format.\nSpecifically, the template consists of two essential parts:\nthe history prompt template  that describes the historical values as the input sentences of the language models and the future prompt template  that defines the sentences for the description of future observations.\nIn this study, we focus on the design of P\n(especially the input parts  of language models)\nand aim to explore diverse prompts that are contextually relevant, coherent, and effective in guiding language models to produce accurate forecasts. Through the investigation of prompts, we seek to enhance the overall forecasting accuracy and reliability of the language-based human mobility forecasting approach."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2. Framework Overview",
            "text": "As illustrated in Figure 2  ###reference_###, the proposed prompt mining framework consists of three key stages: prompt initialization, prompt generation, and prompt refinement.\nPrompt Initialization: The mining process starts with prompt initialization. At this stage, we set the groundwork by creating a diverse pool of potential prompt templates manually. These templates can be used as supervision signals to mentor the following generation stage.\nPrompt Generation: In the prompt generation phase, we employ a language model  as the core engine to learn how to generate \u201cbetter\u201d prompts. An evaluator module  is specifically designed to indicate the quality of generated prompts in the training process of .\nPrompt Refinement: The final stage of our framework is prompt refinement. We introduce several mechanisms to further improve the quality of generated prompts from the previous generation step.\nBy combining these three stages, our prompt mining framework ensures the systematic evolution of prompts from their initial conception to refined and optimized forms.\nThe following subsections delve into each stage of the framework, providing comprehensive insights into the proposed methodology for providing better and more dynamic prompts for the language-based forecasting process.\n###table_1###"
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "3.3. Prompt Initialization",
            "text": "In our prompt mining framework, the initialization of prompts is a critical step to kickstart the process of generating high-quality forecasting prompts. The initial prompts serve as the foundation upon which subsequent iterations build, which also ensures the generated natural language has a certain directionality.\nIn a nutshell, the overarching objective of prompt mining is to use a designated language model  to automatically generate prompts from the original raw data, which is typically presented in numerical format.\nHowever, as the first attempt, the absence of well-established datasets containing diverse prompts for human mobility data, along with a lack of relevant pre-trained language models for mobility prompt generation, poses a unique challenge.\nGiven these considerations, we introduce a pragmatic approach. Instead of directly generating prompts from the raw numerical mobility data, we propose to leverage the fixed template (referred to as the initial template) used in previous work as the input of the prompt generation model  and  is trained to yield better prompts from the initially given input throughout the prompt mining process."
        },
        {
            "section_id": "3.3.1",
            "parent_section_id": "3.3",
            "section_name": "3.3.1. Initial Prompt Template",
            "text": "As exampled in Table 1  ###reference_###, we present a straightforward and uncomplicated template that functions as the initial template within our mining framework.\nAs aforementioned, this initial template serves as the foundation for transforming raw mobility data into the preliminary prompts denoted as , which are considered as the starting prompts of the entire prompt mining process.\nThus, given an input instance , the prompt generation process (elaborated upon in Section 3.4  ###reference_###) can be succinctly expressed as:\nwhere  represents the generated prompts in the natural language format for the specified input instance."
        },
        {
            "section_id": "3.3.2",
            "parent_section_id": "3.3",
            "section_name": "3.3.2. Templates Pool",
            "text": "Based on the initial template, the inputs of model  (i.e., ) are obtained.\nTo effectively train the model , a collection of pseudo labels is essential to supervise the training process.\nTo this end, we establish a pool of templates, as detailed in Appendix A  ###reference_###, Table 6  ###reference_###. These templates are crafted based on simple heuristics; for instance, Complex templates encompass more detailed information such as specific Points of Interest (POI) details and POI working hours, whereas lower quality templates are more simplistic. The pool consists of 12 lower quality templates and 6 Complex templates.\nThese templates support two main purposes: firstly, they are employed to train a classifier (refer to Section 3.4.1  ###reference_.SSS1###) capable of screening the quality (whether high or low) of a given prompt in the later prompt generation stage; secondly, they serve as pseudo labels during the training of .\nIt is worth noting that despite the discrepancy in the number of Simple and Complex templates, the generated training Simple and Complex prompts instances are equivalent in number and balanced.\nImportantly, during the training process of , it is noteworthy that these heuristic templates are utilized only as pseudo labels and not as ground truth labels.\nThis ensures that the model  generates dynamic prompts rather than replicating the exact prompts given in the template pool. The objective is to enable  to mine and discover prompts that are contextually sophisticated and better suited for human mobility forecasting.\n###table_2### This is a  Mobil in WI, Osseo. The human mobility of the past 3 days are:  0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 2, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0 people (per hour) came here from 00:00 to 24:00 (working time) on Mon. 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 2, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1 people (per hour) came here from from 00:00 to 24:00 (working time) on Tue. 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 3, 0, 0, 1, 0, 0 people (per hour) came here from 00:00 to 24:00 (working time) on Wed. How many people will visit this place tomorrow?\nOn Thu, there are 0, 1, 0, 1, 0, 0, 1, 2, 1, 0, 0, 1, 3, 0, 1, 2, 0, 1, 0, 1, 0, 0, 2, 0 people who will visit Mobil during working time.\nThis is a Mobil in WI, Osseo. The human mobility of the past 3 days are: 5 people came here during the first half of the work shift and 4 people came here during the latter half of the work shift on Mon. 4 people came here during the first half of the work shift and 8 people came here during the latter half of the work shift on Tue. 5 people came here during the first half of the work shift and 7 people came here during the latter half of the work shift on Wed. How many people will visit this place tomorrow?\nOn Thu, there will be 7 people to visit Mobil during the first half of the work shift and 10 people to visit Mobil during the latter half of the work shift. Therefore, there are 17 people will visit here.\nThis is a Mobil in WI, Osseo. From Mon to Wed, the human mobility during the first and second half working time are 5, 4, 4, 8, 5, 7. The entire working time is composed of the first half and the second half. Therefore, from Mon to Wed, the total human mobility are 5 + 4 = 9, 4 + 8 = 12, 5 + 7 = 12. How many people will visit this place tomorrow?\nOn Thu, there will be 7 people to visit Mobil during the first half of the work shift and 10 people to visit Mobil during the latter half of the work shift. Therefore, there are 17 people will visit here.\nThis is a Mobil in WI, Osseo. From Mon to Wed, the human mobility during the 4 different time segments are 1, 4, 3, 1; 0, 5, 1, 6; 0, 6, 1, 5. The entire working time is composed of the whole time segments. Therefore, from Mon to Wed, the total human mobility are 1 + 4 + 3 + 1 = 9; 0 + 5 + 1 + 6 = 12; 0 + 6 + 1 + 5 = 12. How many people will visit this place tomorrow?\nOn Thu, there will be 3, 5, 2, 7 people to visit Mobil during these 4 different time segments. Therefore, there are 17 people will visit Mobil on Thu."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "3.4. Prompt Generation",
            "text": "As illustrated in the middle module of Figure 2  ###reference_###, the prompt generation stage is the core part of the entire prompt mining process.\nIt functions based on the initial prompt as well as the heuristic template pool from the previous prompt initialization stage.\nThe prompt generation stage consists of two key components: the Prompt Quality Evaluator  and the generation model ."
        },
        {
            "section_id": "3.4.1",
            "parent_section_id": "3.4",
            "section_name": "3.4.1. Prompt Quality Evaluator",
            "text": "During the training process of the model, it is important to inform the model of the quality of the generated prompts. Instead of using the specialized module \u2013 the Prompt Quality Evaluator, we proceed by randomly selecting prompts without evaluation or feedback. This component typically plays a pivotal role in the prompt generation process by serving as a critical feedback mechanism to assess the quality and effectiveness of generated prompts, but in this case, prompts are indiscriminately selected. Based on the Simple/Complex templates in the template pool, we use a modest portion of (20%) available numerical data to generate prompts. Specifically, we randomly select a template from the pool to make prompts, and we make sure the total number of generated Complex prompts is the same as Simple prompts. Given the heuristics used to generate templates pool lack a concrete quantitative measure to gauge quality performance, a supplementary criterion is essential to discern the quality of generated prompts, though it is overlooked here. Essentially, the prompt generating is a process of information transmission, a translation from the domain of raw data into a descriptive language space. Inspired by the observation that the language with higher information entropy is more efficient in transmitting information under different language systems (Montemurro and Zanette, 2011; Liu et al., 2022), we typically introduce a special element to the Prompt Quality Evaluator \u2013 the Prompt Entropy, which is omitted in this approach. Thus, the ultimate prompt quality may not be systematically improved or optimized without feedback mechanisms."
        },
        {
            "section_id": "3.4.2",
            "parent_section_id": "3.4",
            "section_name": "3.4.2. Training of",
            "text": "As expressed in Equation (1  ###reference_###), during the training process of , the input prompts stem from the initial template\u2019s generated prompts.\nIn this backpropagation process, the quality evaluator  plays a pivotal role in determining which output instances contribute to the training loss computation for the parameter update in .\nThe decision is guided by the conditions outlined in Equation (3  ###reference_###), where exclusively high-quality prompts are retained, while low-quality prompts are discarded. This selection mechanism enforces the focus on generating high-quality prompts, driving the iterative process towards improved language generation performance.\nTo enhance \u2019s capacity to generate high-quality prompts, the Complex pool established during prompt initialization is utilized as pseudo labels. Conceptually, once tokenized, both the pseudo label prompt  and the generated prompt  can be represented as lists of tokens:  and .\nFurthermore, a novel loss function is introduced to actively guide  in generating high-quality prompts. The reciprocal of the associated prompt entropy is employed as the weight for the standard cross-entropy loss during training. In essence, this means that prompts with higher information entropy receive lower weights, resulting in smaller losses. This strategic approach accelerates model convergence and encourages a preference towards high-quality prompts during the training.\nConsequently, the loss function underpinning our prompt generation process is formulated as:\nThis concludes the generation stage. After training, the model  can be used to generate prompts from the initial template and the generated prompt is exemplified in Table 2  ###reference_### (the V1 part)."
        },
        {
            "section_id": "3.5",
            "parent_section_id": "3",
            "section_name": "3.5. Prompt Refinement",
            "text": "Building upon the above generation stage, wherein  is trained to generate prompts, the immediate prompts resulting from this stage are referred to as V1 prompts. In this section, our attention shifts to the refinement of the V1 prompts, with the aim of uncovering additional prompt variations."
        },
        {
            "section_id": "3.5.1",
            "parent_section_id": "3.5",
            "section_name": "3.5.1. Prompt Noise Reduction",
            "text": "The V1 prompts are designed to furnish an expanded array of information and finer-grained mobility data (e.g., including details such as hourly visit counts). However, the adoption of this strategy inevitably introduces a certain degree of noise into the generated prompts. This noise might manifest as extra characters or spacers placed between numbers.\nBased on the V1 prompts, we introduce a subsequent iteration denoted as V2 prompts. The essence of V2 lies in its adoption of an information integration strategy that seeks to mitigate noise while retaining the core semantic content inherent in the V1 prompts.\nSpecifically, considering the overarching forecasting target as the aggregate number of visits for the subsequent day  (same as the problem formulation in previous work (Xue et al., 2022a  ###reference_b29###, b  ###reference_b30###), V2 prompts reorganize human mobility data based on two distinct time periods. These divisions delineate the first and second halves of the day, effectively partitioning working hours at 12 PM, i.e., the diurnal partitioning.\nThis operational adjustment yields an updated set of prompts represented in the dedicated V2 section of Table 2  ###reference_###.\nImportantly, this refinement updates the prompt , which further leads to a corresponding modification of  (the prompt of the forecasting target)."
        },
        {
            "section_id": "3.5.2",
            "parent_section_id": "3.5",
            "section_name": "3.5.2. Chain of Thought Integration",
            "text": "Inspired by the recent strides made in harnessing chain of thought applications within language models for enhancing reasoning capabilities (Wei et al., 2022  ###reference_b23###), we extend our framework\u2019s refinement phase to incorporate a Chain of Thought (CoT) integration.\nTo this end, we propose the integration of a model  dedicated to generating a chain of thought, using the V2 prompts as input. In training or fine-tuning , we establish an initial format of the chain of thought as labels, effectively instructing  in its generation task.\nOur devised CoT structure is conceptually grounded in the V2 prompts. This structure imparts the model with the understanding that the sum of mobility data during the first and second halves of working hours equates to the total daily human mobility count.\nIt is important to note that, distinct from \u2019s training,  is trained using the standard cross-entropy loss, without employing prompt entropy. As depicted in Figure 2  ###reference_### (the green parts), the trained  generates a CoT, which is subsequently appended to the V2 prompts, leading to the formulation of the V3 prompts.\nTable 2  ###reference_### presents an illustrative example of V3 prompts.\nFrom the example, we can also notice that the  remains the same from V2 to V3 as the CoT is appended as the input of the language models when performing forecasting tasks.\nThe sentences highlighted in green represent the CoT generated by . V3 prompts effectively merge human mobility data, eliminate redundancy, and establish a coherent chain of thought characterized by a fixed logical sequence of prompt sentences (i.e., the sentences in V2).\nThis strategy augments the richness of valid information while concurrently attenuating potential noise. By introducing this CoT integration strategy, we enhance the sophistication of our prompt mining framework."
        },
        {
            "section_id": "3.5.3",
            "parent_section_id": "3.5",
            "section_name": "3.5.3. Segmentation with Information Gain",
            "text": "While the diurnal partitioning approach adopted in V2 and V3 effectively divides daily human mobility into two segments, this method may not fully capture the intricate patterns inherent in mobility behaviours. Such an approach might inadvertently result in the loss of crucial information, such as the peaks of the lunchtime rush around 12 PM.\nIn this phase of refinement, the focal challenge revolves around the effective segmentation of the given time series while minimizing the introduction of extraneous noise. The objective is to uncover a segmentation strategy that optimally captures temporal transitions in human activities and daily routines, ensuring accuracy while maintaining coherence.\nTo address this challenge, we draw upon an Information Gain-based Temporal Segmentation (IGTS) method (Sadri et al., 2017  ###reference_b18###)), which is an unsupervised segmentation technique to find the transition times in human activities and daily routines.\nIn the pursuit of refined prompts (denoted as V4 prompts), IGTS is employed.\nAssuming that the mobility series (e.g., the numerical numbers) in one day is a list of  and the goal is to divide it into  segments , with IGTS, this can be achieved by minimizing the information gain-based lost function :\nwhere  is the length of the -th segment (i.e., how many numbers) and  is the total length of data to be segmented.\nThis approach contrasts with the binary halves used in diurnal partitioning within V2 and V3. As showcased in Table 2  ###reference_###, the updated V4 prompts support multiple segments.\nConsidering the revisions to the segmentation in V4, both the CoT within  and the  are also modified accordingly."
        },
        {
            "section_id": "3.6",
            "parent_section_id": "3",
            "section_name": "3.6. Summary of Designed Prompt Variants",
            "text": "To provide a comprehensive comparative perspective on the four distinct prompt variants discovered through our prompt mining methodology, as illustrated in Table 2  ###reference_###, we present a summary of the key properties of 4 prompt variants:\n(1) V1: Generated directly by  which is trained with the prompt quality evaluator.\n(2) V2: Explores diurnal partitioning for segmentation based on V1, focusing on the first and second halves of the day, which aims to reduce noise while preserving semantic content.\n(3) V3: Integrates chain of thought (CoT) in  based on V2.\n(4) V4: Leverages Information Gain-based Temporal Segmentation (IGTS) to support detailed temporal segmentation beyond the diurnal partitioning in V2 and V3."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4. Experiments",
            "text": ""
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1. Source Data",
            "text": "To validate our prompt mining approach for language-based mobility forecasting, we follow the previous language-based human mobility forecasting studies (Xue et al., 2022a  ###reference_b29###, b  ###reference_b30###) and select SafeGraph111https://www.safegraph.com/ mobility pattern data accessed through Dewey research data platform222https://www.deweydata.io/ for our experiments.\nWe collect a total of 562,151 rows of raw weekly data of US POIs from 172 brand types.\nThe temporal span of the data ranges from 26th December 2022 to 2nd January 2023.\nEach row provides one week of visiting data (including both daily counting and hourly counting) of one POI.\nAuxiliary information such as the region of POI and the opening/closing hours are also available in the raw data."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2. Implementation Details",
            "text": "In our experiments, the implementation includes two phases: the prompt mining phase and the forecasting phase.\nFor the prompt mining phase,\nwe opted for the GPT-2 model (Radford et al., 2019  ###reference_b17###) architecture for both  and , despite the emergence of more advanced models like GPT-4 (OpenAI, 2023  ###reference_b15###) and Llama 2 (Touvron et al., 2023  ###reference_b21###). The choice was driven by accessibility and computational feasibility considerations, as the latter models pose challenges in terms of availability and resource requirements.\nThe maximum length of the prompt generated by the GPT-2 model is limited to 512 tokens.\n20% of the data was allocated and passed to the templates given in the heuristic pool for the training of  and .\nThe batch size and dropout rate are set as 5 and 0.1, respectively. A learning rate initially is set at  and early-stopping is adopted with a patience 3 epoch to avoid overfitting.\nFor the prompt quality evaluator, entropy analysis revealed that most generated prompts exhibited entropy values between 2 and 5. Setting a threshold  at 3.5 enabled effective classification of high-quality and low-quality prompts based on their information entropy.\nAs for the classifier in the evaluator, given that the task is binary classification, a simple yet effective logistic regression classifier is selected.\nIt uses L2 regularization and sets the reciprocal of the regularization strength as 1, which means that the strength is inversely proportional to the regularization. The model is fitted with the quasi-Newton as the optimization solver and a maximum iteration limit of 100.\nIn the forecasting phase, the total data is split into a training set (70%, for training numerical forecasting methods and fine-tuning language models), a validation set (10%), and a testing set (20%).\nThe raw data is transformed into sentences by the different variants of developed prompts to fine-tune language models for forecasting purposes.\nThe fine-tuning process of the language forecasting models utilizes the standard Trainer provided by HuggingFace.\nNo changes are made to the loss function or other aspects during the fine-tuning of language models in this phase.\nFor the forecasting setting, we observe the mobility data of the last 3 days and predict the mobility of the next day. From the hourly data perspective, the input length is 72 hours and the forecasting horizon is 24 hours.\nAll of the experiments are performed with PyTorch on a Linux server equipped with Nvidia V100 GPUs and only one GPU was utilized."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "4.3. Evaluation",
            "text": "The overall evaluation of different prompts is conducted based on the forecasting performance.\nFor language-based forecasting, following previous work (Xue et al., 2022a  ###reference_b29###, b  ###reference_b30###), we first need to extract the predicted numerical values from generated output sentences through string parsing.\nAfter extracting the predicted numerical values from the generated sentences, the evaluation of the proposed method can be carried out similarly to how traditional numerical-based forecasting methods are evaluated.\nWe consider two error measures: the Root Mean Squared Error (RMSE) and the Mean Absolute Error (MAE)."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "4.4. Baselines",
            "text": "In this subsection, we present the methods used for comparison in our energy load forecasting experiments. We categorize the baselines into two categories: numerical forecasting methods and language models.\nThe numerical baselines include the classic ARIMA, deep learning-based (Prophet (Taylor and Letham, 2018  ###reference_b20###), TimesNet (Wu et al., 2022  ###reference_b24###), LightTS (Zhang et al., 2022  ###reference_b35###), DLinear (Zeng et al., 2023  ###reference_b33###)), and Transformer (Vaswani et al., 2017  ###reference_b22###)-based models ( Reformer (Kitaev et al., 2019  ###reference_b8###), Informer (Zhou et al., 2021  ###reference_b37###), Autoformer (Xu et al., 2021  ###reference_b25###), Pyraformer (Liu et al., 2021  ###reference_b12###), Crossformer (Zhang and Yan, 2022  ###reference_b36###), PatchTST (Nie et al., 2022  ###reference_b14###)). Except for ARIMA and Prophet, all the rest of the numerical methods are based on the implementation provided by the Time Series Library (TSlib)333https://github.com/thuml/Time-Series-Library  ###reference_ry###..\nFor the language models, we select three language models with pre-trained weights from HuggingFace: Bart (Lewis et al., 2020  ###reference_b9###), Bigbird (Zaheer et al., 2020  ###reference_b32###), and Pegasus (Zhang et al., 2020  ###reference_b34###).\nFrom a recent benchmark study (Xue and Salim, 2023  ###reference_b28###), these 3 models have shown good performance in forecasting time series compared to other language models."
        },
        {
            "section_id": "4.5",
            "parent_section_id": "4",
            "section_name": "4.5. Comparison against Baselines",
            "text": "In this part of the experiment, we focus on investigating the performance of our mined V1 prompts alongside various baselines.\nThe results of these evaluations are presented in Table 3  ###reference_###.\nFor the numerical forecasting baselines, the inputs are the raw hourly visiting data in numbers.\nFor the language models, we also compare V1 against a basic prompt template (e.g., This POI is [STORE TYPE]. There were [HOURLY VISITING DATA] people came here to visit.) drawn from the previous language-based forecasting study (Xue and Salim, 2023  ###reference_b28###).\nAll methods reported in Table 3  ###reference_### predict hourly forecasting during the entire working day.\nIn addition to the daily forecasting (the sum of hourly predictions) performance, to make a more accurate comparison with the subsequent generated prompt V2 and V3 (where the diurnal partitioning is applied) later, we also report RMSE and MAE within the first and second-half of the working time. It allows better measurement of their predictive performance over different time periods.\nThe best and the second-best performers under each column are shown in red and blue.\nIn general, our V1 outperforms both numerical forecasting methods and the basic prompt without prompt mining process.\nWhile numerical models show competitive results in the second half, the Pegasus model with our V1 prompts consistently maintains a superior performance across different forecasting scenarios.\nFor the same language model, we can see that using V1 leads to better forecasting performance than using the basic prompt.\nMoreover, for language models, regardless of the prompt employed, both Pegasus and Bigbird showcase superior forecasting performance compared to Bart.\nThe above comparison results validate the\neffectiveness of our proposed prompt mining method that can contribute to more accurate forecasting."
        },
        {
            "section_id": "4.6",
            "parent_section_id": "4",
            "section_name": "4.6. Performance of Different Prompt Variants",
            "text": "To have a deeper understanding of our prompt mining approach and its impact on forecasting accuracy, we conduct a detailed analysis of the performance of different prompt variants.\nTable 4  ###reference_### presents the forecasting performance of the three language models using Prompt V1-V3.\nIn general, we can observe that V3 outperforms V1 and V2 in terms of the daily forecasting results no matter which model is used.\nFor the Bart model, V2 exhibits substantial improvements in accuracy compared to V1, with significant reductions in both RMSE and MAE. V3 also has a large reduction in daily forecast RMSE.\nIn the Bigbird case, V2 and V3 display a remarkable improvement against V1 for the first half day. Although V1 has a better performance in the second half day, V3 still remains the top performer under the daily forecast.\nSimilarly, the outcomes observed for the Pegasus language model are almost the same as the trends apparent in the Bigbird analysis.\nThis analysis of different prompt variants shows the efficacy of our mining method in enhancing mobility forecasting accuracy. The prompt refinements introduced in the prompt mining process, particularly for V3, contribute to improvements in the forecasting performance, which justifies the significance of our approach\u2019s prompt refinement phase."
        },
        {
            "section_id": "4.7",
            "parent_section_id": "4",
            "section_name": "4.7. Impact of Segments",
            "text": "###table_3### In this part of the experiment, we explore the impact of different segmenting mechanisms used in our prompt refinement stage.\nSpecifically, we investigate how different numbers of segments () in our V4 prompts influence forecasting performance.\nThe results of this experimentation are summarized in Table 5  ###reference_###, where we also provide the forecasting performance of V3 for easy comparison, which employs diurnal partitioning with 2 segments.\nDifferent from Table 3  ###reference_### and Table 4  ###reference_###, we calculate the average RMSE/MAE of each segment instead of the first/second half RMSE/MAE since we have settings with more than 2 segments for V4.\nWe also highlight the best and second-best results for each language model separately.\nUpon analyzing the results, it is evident that the performance of our V4 prompts is influenced by the number of segments .\nFor example, in the case of segment average performance, increasing the number of segments from 2 to 5 (V4) leads to a decreased error for both Bigbird and Pegasus.\nFor the daily forecasting performance, a similar trend can also be noticed for the Bart and Pegasus models.\nMoreover, the comparison with V3 prompts highlights that our refined V4 prompts generally perform favorably.\nIn conclusion, the results indicate that with a dynamic segmentation strategy offered in our V4 prompts, the language-based forecasting methods can be further improved. Additionally, we observe similar performance on different language models, which demonstrates the adaptability of our prompt mining approach."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5. Conclusion",
            "text": "In this study, we present a novel prompt mining framework for enhancing language-based mobility forecasting.\nWe introduce a multi-stage process with a core prompt generation stage based on prompt entropy and a refinement stage with the consideration of a chain of thought.\nOur mining pipeline generates and refines prompts for transforming human mobility data into sentences in order to leverage language models for mobility forecasting.\nThrough comprehensive experiments, we demonstrate the superiority of our refined prompts over traditional numerical forecasting methods and basic prompt structures. Our results also highlight the consistent performance improvement across different language models used for the forecasting phase.\nThe future directions of mobility prompt mining can include the integration of external data sources, such as weather and events, which could further provide more context and enhance forecasting capabilities. How to involve human feedback from domain experts in the prompt mining process would be another interesting future research topic."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Heuristic Prompt Template Pool",
            "text": "In this section, we show the details of our heuristic template pool (described in Section 3.3.2  ###reference_.SSS2###). As presented in Table 6  ###reference_###, this heuristic pool consists of both Simple templates and Complex templates.\nComplex templates, as opposed to their Simple counterparts, offer more comprehensive information, featuring complete sentences to describe the semantic details of Points of Interest (POIs). These templates are instrumental in generating training prompt instances to facilitate the training of .\nDuring the formation of the training set, these templates are randomly selected to create either Complex or Simple instances (prompts). To ensure a balanced dataset for training , the number of Complexinstances matches that of Simple instances within the formed training set."
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T1\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1. </span>The example of our initial prompt template using in the prompt initialization stage.</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S3.T1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T1.1.1.1.1\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.1.1.1.2.1\"><span class=\"ltx_text\" id=\"S3.T1.1.1.1.1.2.1.1\" style=\"font-size:90%;\">Initial Prompt</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.1.1.1.1.1\">\n<span class=\"ltx_text\" id=\"S3.T1.1.1.1.1.1.1.1\" style=\"font-size:90%;\">(</span><span class=\"ltx_text\" id=\"S3.T1.1.1.1.1.1.1.2\" style=\"font-size:90%;\">)</span>\n</td>\n</tr>\n</table>\n<span class=\"ltx_text\" id=\"S3.T1.1.1.1.2\" style=\"font-size:90%;\"></span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_b ltx_border_t\" id=\"S3.T1.1.1.2\" style=\"width:346.9pt;\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S3.T1.1.1.2.1\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.1.2.1.1.1\"><span class=\"ltx_text\" id=\"S3.T1.1.1.2.1.1.1.1\" style=\"font-size:90%;\">In Region WI, Osseo, what is the daily human mobility of Mobil Store from Mon to Wed?</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.2.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.1.2.1.2.1\"><span class=\"ltx_text\" id=\"S3.T1.1.1.2.1.2.1.1\" style=\"font-size:90%;\">[0,0,0,0,0,0,0,0,1,0,1,1,2,0,2,1,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,2,1,1,0,0,0,1,1,0,1,0,1,0,0,0,0,0,1,0,0,1,1,1,1,0,0,1,1,1,0,3,0,0,1,0,0].</span></td>\n</tr>\n</table>\n</td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 1. The example of our initial prompt template using in the prompt initialization stage."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T2\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2. </span>The examples of our 4 prompt variants. The auxiliary context, temporal information, mobility data, and chain of thought parts are shown in orange, blue, red, and green.</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S3.T2.8\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.2\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T2.1.1.2.1\">V1</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S3.T2.1.1.3\" style=\"width:346.9pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S3.T2.1.1.3.1\">This is a <span class=\"ltx_text\" id=\"S3.T2.1.1.3.1.1\" style=\"color:#FFA500;\"> Mobil in WI, Osseo</span>. The human mobility of the <span class=\"ltx_text\" id=\"S3.T2.1.1.3.1.2\" style=\"color:#0000FF;\">past 3 days</span> are: <span class=\"ltx_text\" id=\"S3.T2.1.1.3.1.3\" style=\"color:#FF0000;\"> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 2, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0</span> people (per hour) came here <span class=\"ltx_text\" id=\"S3.T2.1.1.3.1.4\" style=\"color:#FFA500;\">from 00:00 to 24:00 (working time)</span> on <span class=\"ltx_text\" id=\"S3.T2.1.1.3.1.5\" style=\"color:#0000FF;\">Mon</span>. <span class=\"ltx_text\" id=\"S3.T2.1.1.3.1.6\" style=\"color:#FF0000;\">0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 2, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1</span> people (per hour) came here from <span class=\"ltx_text\" id=\"S3.T2.1.1.3.1.7\" style=\"color:#FFA500;\">from 00:00 to 24:00 (working time)</span> on <span class=\"ltx_text\" id=\"S3.T2.1.1.3.1.8\" style=\"color:#0000FF;\">Tue</span>. <span class=\"ltx_text\" id=\"S3.T2.1.1.3.1.9\" style=\"color:#FF0000;\">0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 3, 0, 0, 1, 0, 0</span> people (per hour) came here <span class=\"ltx_text\" id=\"S3.T2.1.1.3.1.10\" style=\"color:#FFA500;\">from 00:00 to 24:00 (working time)</span> on <span class=\"ltx_text\" id=\"S3.T2.1.1.3.1.11\" style=\"color:#0000FF;\">Wed</span>. How many people will visit this place tomorrow?</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T2.2.2.1\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S3.T2.2.2.2\" style=\"width:346.9pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S3.T2.2.2.2.1\">On <span class=\"ltx_text\" id=\"S3.T2.2.2.2.1.1\" style=\"color:#0000FF;\">Thu</span>, there are <span class=\"ltx_text\" id=\"S3.T2.2.2.2.1.2\" style=\"color:#FF0000;\">0, 1, 0, 1, 0, 0, 1, 2, 1, 0, 0, 1, 3, 0, 1, 2, 0, 1, 0, 1, 0, 0, 2, 0</span> people who will visit <span class=\"ltx_text\" id=\"S3.T2.2.2.2.1.3\" style=\"color:#FFA500;\">Mobil</span> during working time.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S3.T2.3.3.2\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T2.3.3.2.1\">V2</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S3.T2.3.3.1\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\" id=\"S3.T2.3.3.3\" style=\"width:346.9pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S3.T2.3.3.3.1\">This is a <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.1\" style=\"color:#FFA500;\">Mobil in WI, Osseo</span>. The human mobility of the <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.2\" style=\"color:#0000FF;\">past 3 days</span> are: <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.3\" style=\"color:#FF0000;\">5</span> people came here during the <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.4\" style=\"color:#FFA500;\">first half of the work shift</span> and <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.5\" style=\"color:#FF0000;\">4</span> people came here during the <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.6\" style=\"color:#FFA500;\">latter half of the work shift</span> on <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.7\" style=\"color:#0000FF;\">Mon</span>. <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.8\" style=\"color:#FF0000;\">4</span> people came here during the <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.9\" style=\"color:#FFA500;\">first half of the work shift</span> and <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.10\" style=\"color:#FF0000;\">8</span> people came here during the <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.11\" style=\"color:#FFA500;\">latter half of the work shift</span> on <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.12\" style=\"color:#0000FF;\">Tue</span>. <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.13\" style=\"color:#FF0000;\">5</span> people came here during the <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.14\" style=\"color:#FFA500;\">first half of the work shift</span> and <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.15\" style=\"color:#FF0000;\">7</span> people came here during the <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.16\" style=\"color:#FFA500;\">latter half of the work shift</span> on <span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.17\" style=\"color:#0000FF;\">Wed</span>. How many people will visit this place tomorrow?</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T2.4.4.1\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S3.T2.4.4.2\" style=\"width:346.9pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S3.T2.4.4.2.1\">On <span class=\"ltx_text\" id=\"S3.T2.4.4.2.1.1\" style=\"color:#0000FF;\">Thu</span>, there will be <span class=\"ltx_text\" id=\"S3.T2.4.4.2.1.2\" style=\"color:#FF0000;\">7</span> people to visit Mobil during the <span class=\"ltx_text\" id=\"S3.T2.4.4.2.1.3\" style=\"color:#FFA500;\">first half of the work shift</span> and <span class=\"ltx_text\" id=\"S3.T2.4.4.2.1.4\" style=\"color:#FF0000;\">10</span> people to visit Mobil during the <span class=\"ltx_text\" id=\"S3.T2.4.4.2.1.5\" style=\"color:#FFA500;\">latter half of the work shift</span>. Therefore, there are <span class=\"ltx_text\" id=\"S3.T2.4.4.2.1.6\" style=\"color:#FF0000;\">17</span> people will visit here.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.5.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S3.T2.5.5.2\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T2.5.5.2.1\">V3</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S3.T2.5.5.1\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\" id=\"S3.T2.5.5.3\" style=\"width:346.9pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S3.T2.5.5.3.1\">This is a <span class=\"ltx_text\" id=\"S3.T2.5.5.3.1.1\" style=\"color:#FFA500;\">Mobil in WI, Osseo</span>. From <span class=\"ltx_text\" id=\"S3.T2.5.5.3.1.2\" style=\"color:#0000FF;\">Mon to Wed</span>, the human mobility during the <span class=\"ltx_text\" id=\"S3.T2.5.5.3.1.3\" style=\"color:#FFA500;\">first and second half working time</span> are <span class=\"ltx_text\" id=\"S3.T2.5.5.3.1.4\" style=\"color:#FF0000;\">5, 4, 4, 8, 5, 7</span>. <span class=\"ltx_text\" id=\"S3.T2.5.5.3.1.5\" style=\"color:#008000;\">The entire working time is composed of the first half and the second half. Therefore, from Mon to Wed, the total human mobility are 5 + 4 = 9, 4 + 8 = 12, 5 + 7 = 12.</span> How many people will visit this place tomorrow?</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T2.6.6.1\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S3.T2.6.6.2\" style=\"width:346.9pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S3.T2.6.6.2.1\">On <span class=\"ltx_text\" id=\"S3.T2.6.6.2.1.1\" style=\"color:#0000FF;\">Thu</span>, there will be <span class=\"ltx_text\" id=\"S3.T2.6.6.2.1.2\" style=\"color:#FF0000;\">7</span> people to visit <span class=\"ltx_text\" id=\"S3.T2.6.6.2.1.3\" style=\"color:#FFA500;\">Mobil</span> during the <span class=\"ltx_text\" id=\"S3.T2.6.6.2.1.4\" style=\"color:#FFA500;\">first half of the work shift</span> and <span class=\"ltx_text\" id=\"S3.T2.6.6.2.1.5\" style=\"color:#FF0000;\">10</span> people to visit <span class=\"ltx_text\" id=\"S3.T2.6.6.2.1.6\" style=\"color:#FFA500;\">Mobil</span> during the <span class=\"ltx_text\" id=\"S3.T2.6.6.2.1.7\" style=\"color:#FFA500;\">latter half of the work shift</span>. Therefore, there are <span class=\"ltx_text\" id=\"S3.T2.6.6.2.1.8\" style=\"color:#FF0000;\">17</span> people will visit here.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.7.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt\" id=\"S3.T2.7.7.2\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T2.7.7.2.1\">V4</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S3.T2.7.7.1\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\" id=\"S3.T2.7.7.3\" style=\"width:346.9pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S3.T2.7.7.3.1\">This is a <span class=\"ltx_text\" id=\"S3.T2.7.7.3.1.1\" style=\"color:#FFA500;\">Mobil in WI, Osseo</span>. From <span class=\"ltx_text\" id=\"S3.T2.7.7.3.1.2\" style=\"color:#0000FF;\">Mon to Wed</span>, the human mobility during the <span class=\"ltx_text\" id=\"S3.T2.7.7.3.1.3\" style=\"color:#FFA500;\">4 different time segments</span> are <span class=\"ltx_text\" id=\"S3.T2.7.7.3.1.4\" style=\"color:#FF0000;\">1, 4, 3, 1; 0, 5, 1, 6; 0, 6, 1, 5</span>. <span class=\"ltx_text\" id=\"S3.T2.7.7.3.1.5\" style=\"color:#008000;\">The entire working time is composed of the whole time segments. Therefore, from Mon to Wed, the total human mobility are 1 + 4 + 3 + 1 = 9; 0 + 5 + 1 + 6 = 12; 0 + 6 + 1 + 5 = 12.</span> How many people will visit this place tomorrow?</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T2.8.8.1\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_b ltx_border_t\" id=\"S3.T2.8.8.2\" style=\"width:346.9pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S3.T2.8.8.2.1\">On <span class=\"ltx_text\" id=\"S3.T2.8.8.2.1.1\" style=\"color:#0000FF;\">Thu</span>, there will be <span class=\"ltx_text\" id=\"S3.T2.8.8.2.1.2\" style=\"color:#FF0000;\">3, 5, 2, 7</span> people to visit <span class=\"ltx_text\" id=\"S3.T2.8.8.2.1.3\" style=\"color:#FFA500;\">Mobil</span> during these <span class=\"ltx_text\" id=\"S3.T2.8.8.2.1.4\" style=\"color:#FFA500;\">4 different time segments</span>. Therefore, there are <span class=\"ltx_text\" id=\"S3.T2.8.8.2.1.5\" style=\"color:#FF0000;\">17</span> people will visit <span class=\"ltx_text\" id=\"S3.T2.8.8.2.1.6\" style=\"color:#FFA500;\">Mobil</span> on <span class=\"ltx_text\" id=\"S3.T2.8.8.2.1.7\" style=\"color:#0000FF;\">Thu</span>.</p>\n</td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 2. The examples of our 4 prompt variants. The auxiliary context, temporal information, mobility data, and chain of thought parts are shown in orange, blue, red, and green."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T3\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3. </span>The results of numerical methods, using basic prompt and V1 generated by our prompt mining pipeline.</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.1.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.1.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\" id=\"S4.T3.1.1.1.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.1.1.3.1\" style=\"font-size:90%;\">1st Half</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\" id=\"S4.T3.1.1.1.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.1.1.4.1\" style=\"font-size:90%;\">2nd Half</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\" id=\"S4.T3.1.1.1.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.1.1.5.1\" style=\"font-size:90%;\">Daily Forecast</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.2.2\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.2.2.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.2.2.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.2.2.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.2.2.3.1\" style=\"font-size:90%;\">RMSE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.2.2.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.2.2.4.1\" style=\"font-size:90%;\">MAE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.2.2.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.2.2.5.1\" style=\"font-size:90%;\">RMSE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.2.2.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.2.2.6.1\" style=\"font-size:90%;\">MAE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.2.2.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.2.2.7.1\" style=\"font-size:90%;\">RMSE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.2.2.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.2.2.8.1\" style=\"font-size:90%;\">MAE</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.3.3\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T3.1.3.3.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T3.1.3.3.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.3.3.2.1\" style=\"font-size:90%;\">ARIMA</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.3.3.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.3.3.3.1\" style=\"font-size:90%;\">11.05</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.3.3.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.3.3.4.1\" style=\"font-size:90%;\">2.99</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.3.3.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.3.3.5.1\" style=\"font-size:90%;\">12.38</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.3.3.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.3.3.6.1\" style=\"font-size:90%;\">2.71</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.3.3.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.3.3.7.1\" style=\"font-size:90%;\">25.58</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.3.3.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.3.3.8.1\" style=\"font-size:90%;\">4.18</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.4.4\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.4.4.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.4.4.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.4.4.2.1\" style=\"font-size:90%;\">Prophet</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.4.4.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.4.4.3.1\" style=\"font-size:90%;\">92.69</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.4.4.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.4.4.4.1\" style=\"font-size:90%;\">35.49</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.4.4.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.4.4.5.1\" style=\"font-size:90%;\">9.25</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.4.4.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.4.4.6.1\" style=\"font-size:90%;\">3.02</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.4.4.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.4.4.7.1\" style=\"font-size:90%;color:#0000FF;\">10.76</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.4.4.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.4.4.8.1\" style=\"font-size:90%;\">3.89</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.5.5\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.5.5.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.5.5.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.5.5.2.1\" style=\"font-size:90%;\">Autoformer</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.5.5.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.5.5.3.1\" style=\"font-size:90%;\">25.53</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.5.5.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.5.5.4.1\" style=\"font-size:90%;\">4.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.5.5.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.5.5.5.1\" style=\"font-size:90%;\">10.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.5.5.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.5.5.6.1\" style=\"font-size:90%;\">3.79</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.5.5.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.5.5.7.1\" style=\"font-size:90%;\">35.02</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.5.5.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.5.5.8.1\" style=\"font-size:90%;\">8.31</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.6.6\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.6.6.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.6.6.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.6.6.2.1\" style=\"font-size:90%;\">Crossformer</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.6.6.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.6.6.3.1\" style=\"font-size:90%;\">24.77</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.6.6.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.6.6.4.1\" style=\"font-size:90%;\">3.69</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.6.6.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.6.6.5.1\" style=\"font-size:90%;\">9.81</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.6.6.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.6.6.6.1\" style=\"font-size:90%;\">3.05</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.6.6.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.6.6.7.1\" style=\"font-size:90%;\">33.68</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.6.6.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.6.6.8.1\" style=\"font-size:90%;\">6.42</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.7.7\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.7.7.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.7.7.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.7.7.2.1\" style=\"font-size:90%;\">DLinear</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.7.7.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.7.7.3.1\" style=\"font-size:90%;\">24.77</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.7.7.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.7.7.4.1\" style=\"font-size:90%;\">3.87</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.7.7.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.7.7.5.1\" style=\"font-size:90%;\">10.02</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.7.7.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.7.7.6.1\" style=\"font-size:90%;\">3.29</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.7.7.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.7.7.7.1\" style=\"font-size:90%;\">33.91</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.7.7.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.7.7.8.1\" style=\"font-size:90%;\">6.8</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.8.8\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.8.8.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.8.8.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.8.8.2.1\" style=\"font-size:90%;\">Informer</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.8.8.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.8.8.3.1\" style=\"font-size:90%;\">25.17</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.8.8.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.8.8.4.1\" style=\"font-size:90%;\">3.87</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.8.8.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.8.8.5.1\" style=\"font-size:90%;\">10.09</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.8.8.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.8.8.6.1\" style=\"font-size:90%;\">3.33</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.8.8.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.8.8.7.1\" style=\"font-size:90%;\">34.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.8.8.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.8.8.8.1\" style=\"font-size:90%;\">6.85</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.9.9\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.9.9.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.9.9.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.9.9.2.1\" style=\"font-size:90%;\">LightTS</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.9.9.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.9.9.3.1\" style=\"font-size:90%;\">24.47</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.9.9.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.9.9.4.1\" style=\"font-size:90%;\">4.03</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.9.9.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.9.9.5.1\" style=\"font-size:90%;\">9.97</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.9.9.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.9.9.6.1\" style=\"font-size:90%;\">3.44</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.9.9.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.9.9.7.1\" style=\"font-size:90%;\">33.51</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.9.9.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.9.9.8.1\" style=\"font-size:90%;\">7.04</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.10.10\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.10.10.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.10.10.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.10.10.2.1\" style=\"font-size:90%;\">PatchTST</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.10.10.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.10.10.3.1\" style=\"font-size:90%;\">24.36</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.10.10.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.10.10.4.1\" style=\"font-size:90%;\">3.69</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.10.10.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.10.10.5.1\" style=\"font-size:90%;\">9.98</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.10.10.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.10.10.6.1\" style=\"font-size:90%;\">3.08</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.10.10.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.10.10.7.1\" style=\"font-size:90%;\">33.42</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.10.10.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.10.10.8.1\" style=\"font-size:90%;\">6.39</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.11.11\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.11.11.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.11.11.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.11.11.2.1\" style=\"font-size:90%;\">Pyraformer</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.11.11.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.11.11.3.1\" style=\"font-size:90%;\">24.88</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.11.11.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.11.11.4.1\" style=\"font-size:90%;\">3.69</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.11.11.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.11.11.5.1\" style=\"font-size:90%;\">9.91</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.11.11.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.11.11.6.1\" style=\"font-size:90%;\">2.11</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.11.11.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.11.11.7.1\" style=\"font-size:90%;\">33.91</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.11.11.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.11.11.8.1\" style=\"font-size:90%;\">6.44</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.12.12\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.12.12.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.12.12.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.12.12.2.1\" style=\"font-size:90%;\">Reformer</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.12.12.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.12.12.3.1\" style=\"font-size:90%;\">25.08</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.12.12.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.12.12.4.1\" style=\"font-size:90%;\">3.85</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.12.12.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.12.12.5.1\" style=\"font-size:90%;\">10.02</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.12.12.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.12.12.6.1\" style=\"font-size:90%;\">3.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.12.12.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.12.12.7.1\" style=\"font-size:90%;\">34.24</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.12.12.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.12.12.8.1\" style=\"font-size:90%;\">6.7</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.13.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.13.13.1\" rowspan=\"-12\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.13.13.1.1\" style=\"font-size:90%;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S4.T3.1.13.13.1.1.1\" style=\"width:8.0pt;height:88pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:88.0pt;transform:translate(-39.99pt,-39.11pt) rotate(-90deg) ;\">\n<span class=\"ltx_p\" id=\"S4.T3.1.13.13.1.1.1.1\">Numerical Forecasting</span>\n</span></span></span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.13.13.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.13.13.2.1\" style=\"font-size:90%;\">TimesNet</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.13.13.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.13.13.3.1\" style=\"font-size:90%;\">24.94</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.13.13.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.13.13.4.1\" style=\"font-size:90%;\">3.61</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.13.13.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.13.13.5.1\" style=\"font-size:90%;\">10.15</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.13.13.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.13.13.6.1\" style=\"font-size:90%;\">3.15</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.13.13.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.13.13.7.1\" style=\"font-size:90%;\">34.21</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.13.13.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.13.13.8.1\" style=\"font-size:90%;\">6.4</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.14.14\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T3.1.14.14.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T3.1.14.14.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.14.14.2.1\" style=\"font-size:90%;\">Bart</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.1.14.14.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.14.14.3.1\" style=\"font-size:90%;\">57.46</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.14.14.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.14.14.4.1\" style=\"font-size:90%;\">15.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.1.14.14.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.14.14.5.1\" style=\"font-size:90%;\">58.78</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.14.14.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.14.14.6.1\" style=\"font-size:90%;\">56.43</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.1.14.14.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.14.14.7.1\" style=\"font-size:90%;\">94.54</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.1.14.14.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.14.14.8.1\" style=\"font-size:90%;\">65.05</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.15.15\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.15.15.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.15.15.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.15.15.2.1\" style=\"font-size:90%;\">Bigbird</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.15.15.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.15.15.3.1\" style=\"font-size:90%;\">13.3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.15.15.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.15.15.4.1\" style=\"font-size:90%;\">4.61</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.15.15.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.15.15.5.1\" style=\"font-size:90%;\">10.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.15.15.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.15.15.6.1\" style=\"font-size:90%;\">4.15</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.15.15.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.15.15.7.1\" style=\"font-size:90%;\">22.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.15.15.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.15.15.8.1\" style=\"font-size:90%;\">8.71</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.16.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.16.16.1\" rowspan=\"-3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.16.16.1.1\" style=\"font-size:90%;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S4.T3.1.16.16.1.1.1\" style=\"width:36.0pt;height:30.2pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:30.2pt;transform:translate(2.92pt,2.92pt) rotate(-90deg) ;\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S4.T3.1.16.16.1.1.1.1\">\n<span class=\"ltx_tr\" id=\"S4.T3.1.16.16.1.1.1.1.1\">\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.16.16.1.1.1.1.1.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\">Basic</span></span>\n<span class=\"ltx_tr\" id=\"S4.T3.1.16.16.1.1.1.1.2\">\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.16.16.1.1.1.1.2.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\">Prompt</span></span>\n</span>\n</span></span></span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.16.16.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.16.16.2.1\" style=\"font-size:90%;\">Pegasus</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.16.16.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.16.16.3.1\" style=\"font-size:90%;\">12.91</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.16.16.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.16.16.4.1\" style=\"font-size:90%;\">4.57</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.16.16.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.16.16.5.1\" style=\"font-size:90%;\">9.97</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.16.16.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.16.16.6.1\" style=\"font-size:90%;\">4.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.16.16.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.16.16.7.1\" style=\"font-size:90%;\">21.33</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.16.16.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.16.16.8.1\" style=\"font-size:90%;\">8.59</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.17.17\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T3.1.17.17.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T3.1.17.17.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.17.17.2.1\" style=\"font-size:90%;\">Bart</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.1.17.17.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.17.17.3.1\" style=\"font-size:90%;\">11.01</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.17.17.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.17.17.4.1\" style=\"font-size:90%;\">3.38</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.1.17.17.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.17.17.5.1\" style=\"font-size:90%;\">22.92</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.17.17.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.17.17.6.1\" style=\"font-size:90%;\">20.51</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.1.17.17.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.17.17.7.1\" style=\"font-size:90%;\">23.43</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.1.17.17.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.17.17.8.1\" style=\"font-size:90%;\">19.71</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.18.18\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.18.18.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.18.18.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.18.18.2.1\" style=\"font-size:90%;\">Bigbird</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.18.18.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.18.18.3.1\" style=\"font-size:90%;color:#0000FF;\">7.84</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.18.18.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.18.18.4.1\" style=\"font-size:90%;color:#0000FF;\">2.53</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.18.18.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.18.18.5.1\" style=\"font-size:90%;color:#0000FF;\">3.83</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.1.18.18.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.18.18.6.1\" style=\"font-size:90%;color:#0000FF;\">1.34</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.18.18.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.18.18.7.1\" style=\"font-size:90%;color:#0000FF;\">10.76</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.18.18.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.18.18.8.1\" style=\"font-size:90%;color:#0000FF;\">3.83</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.19.19\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T3.1.19.19.1\" rowspan=\"-3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.19.19.1.1\" style=\"font-size:90%;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S4.T3.1.19.19.1.1.1\" style=\"width:36.0pt;height:19.1pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:19.1pt;transform:translate(8.46pt,8.46pt) rotate(-90deg) ;\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S4.T3.1.19.19.1.1.1.1\">\n<span class=\"ltx_tr\" id=\"S4.T3.1.19.19.1.1.1.1.1\">\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.19.19.1.1.1.1.1.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\">Ours</span></span>\n<span class=\"ltx_tr\" id=\"S4.T3.1.19.19.1.1.1.1.2\">\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.19.19.1.1.1.1.2.1\" style=\"padding-left:3.1pt;padding-right:3.1pt;\">V1</span></span>\n</span>\n</span></span></span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T3.1.19.19.2\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.19.19.2.1\" style=\"font-size:90%;\">Pegasus</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T3.1.19.19.3\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.19.19.3.1\" style=\"font-size:90%;color:#FF0000;\">5.77</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S4.T3.1.19.19.4\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.19.19.4.1\" style=\"font-size:90%;color:#FF0000;\">2.42</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T3.1.19.19.5\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.19.19.5.1\" style=\"font-size:90%;color:#FF0000;\">3.58</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S4.T3.1.19.19.6\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.19.19.6.1\" style=\"font-size:90%;color:#FF0000;\">1.31</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T3.1.19.19.7\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.19.19.7.1\" style=\"font-size:90%;color:#FF0000;\">8.26</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T3.1.19.19.8\" style=\"padding-left:3.1pt;padding-right:3.1pt;\"><span class=\"ltx_text\" id=\"S4.T3.1.19.19.8.1\" style=\"font-size:90%;color:#FF0000;\">3.67</span></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 3. The results of numerical methods, using basic prompt and V1 generated by our prompt mining pipeline."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T4\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 4. </span>The results of different prompt variants.</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S4.T4.1.1.1.1\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"></th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T4.1.1.1.2\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\" id=\"S4.T4.1.1.1.3\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">1st Half</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\" id=\"S4.T4.1.1.1.4\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">2nd Half</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"2\" id=\"S4.T4.1.1.1.5\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">Daily Forecast</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.2.2\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row\" id=\"S4.T4.1.2.2.1\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r\" id=\"S4.T4.1.2.2.2\" rowspan=\"-2\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.2.2.2.1\">Prompt</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.1.2.2.3\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">RMSE</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S4.T4.1.2.2.4\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">MAE</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.1.2.2.5\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">RMSE</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S4.T4.1.2.2.6\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">MAE</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.1.2.2.7\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">RMSE</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.1.2.2.8\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">MAE</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.3.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T4.1.3.1.1\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T4.1.3.1.2\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">V1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.3.1.3\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">11.01</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.1.3.1.4\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">3.38</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.3.1.5\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">22.92</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.1.3.1.6\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">20.51</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.3.1.7\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">23.43</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.3.1.8\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">19.71</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.4.2\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.4.2.1\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.4.2.2\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">V2</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.4.2.3\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">3.75</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T4.1.4.2.4\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">1.08</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.4.2.5\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">4.71</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T4.1.4.2.6\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">1.61</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.4.2.7\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">8.79</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.4.2.8\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">2.82</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.5.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.5.3.1\" rowspan=\"-3\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.5.3.1.1\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S4.T4.1.5.3.1.1.1\" style=\"width:6.8pt;height:19.9pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:19.9pt;transform:translate(-6.53pt,-6.53pt) rotate(-90deg) ;\">\n<span class=\"ltx_p\" id=\"S4.T4.1.5.3.1.1.1.1\">Bart</span>\n</span></span></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.5.3.2\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">V3</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.5.3.3\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">3.19</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T4.1.5.3.4\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">1.08</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.5.3.5\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">4.48</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T4.1.5.3.6\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">1.62</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.5.3.7\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.5.3.7.1\" style=\"color:#0000FF;\">6.68</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.5.3.8\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">2.42</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.6.4\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T4.1.6.4.1\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T4.1.6.4.2\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">V1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.1.6.4.3\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">7.84</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.1.6.4.4\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">2.53</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.1.6.4.5\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.6.4.5.1\" style=\"color:#0000FF;\">3.83</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.1.6.4.6\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.6.4.6.1\" style=\"color:#0000FF;\">1.34</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.1.6.4.7\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">10.76</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.1.6.4.8\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">3.83</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.7.5\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.7.5.1\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.7.5.2\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">V2</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.7.5.3\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.7.5.3.1\" style=\"color:#FF0000;\">2.65</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T4.1.7.5.4\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">0.99</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.7.5.5\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">7.46</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T4.1.7.5.6\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">1.68</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.7.5.7\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">8.87</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.7.5.8\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">2.37</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.8.6\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.8.6.1\" rowspan=\"-3\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.8.6.1.1\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S4.T4.1.8.6.1.1.1\" style=\"width:8.9pt;height:32.7pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:32.7pt;transform:translate(-11.89pt,-10.92pt) rotate(-90deg) ;\">\n<span class=\"ltx_p\" id=\"S4.T4.1.8.6.1.1.1.1\">Bigbird</span>\n</span></span></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.8.6.2\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">V3</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.8.6.3\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.8.6.3.1\" style=\"color:#0000FF;\">2.78</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T4.1.8.6.4\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">1.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.8.6.5\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">4.47</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T4.1.8.6.6\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">1.59</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.8.6.7\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.8.6.7.1\" style=\"color:#FF0000;\">6.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.8.6.8\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">2.29</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.9.7\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T4.1.9.7.1\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T4.1.9.7.2\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">V1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.1.9.7.3\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">5.77</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.1.9.7.4\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">2.42</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.1.9.7.5\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.9.7.5.1\" style=\"color:#FF0000;\">3.58</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.1.9.7.6\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.9.7.6.1\" style=\"color:#FF0000;\">1.31</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.1.9.7.7\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">8.26</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.1.9.7.8\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">3.67</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.10.8\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.10.8.1\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.10.8.2\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">V2</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.10.8.3\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">2.97</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T4.1.10.8.4\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.10.8.4.1\" style=\"color:#FF0000;\">0.97</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.10.8.5\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">5.19</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T4.1.10.8.6\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">1.54</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.10.8.7\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">8.58</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.10.8.8\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.10.8.8.1\" style=\"color:#0000FF;\">2.21</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.11.9\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T4.1.11.9.1\" rowspan=\"-3\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.11.9.1.1\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S4.T4.1.11.9.1.1.1\" style=\"width:8.8pt;height:34.4pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:34.4pt;transform:translate(-12.82pt,-11.85pt) rotate(-90deg) ;\">\n<span class=\"ltx_p\" id=\"S4.T4.1.11.9.1.1.1.1\">Pegasus</span>\n</span></span></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T4.1.11.9.2\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">V3</th>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T4.1.11.9.3\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">3.65</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S4.T4.1.11.9.4\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.11.9.4.1\" style=\"color:#0000FF;\">0.98</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T4.1.11.9.5\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">4.19</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S4.T4.1.11.9.6\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">1.52</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T4.1.11.9.7\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">8.13</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T4.1.11.9.8\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><span class=\"ltx_text\" id=\"S4.T4.1.11.9.8.1\" style=\"color:#FF0000;\">2.20</span></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 4. The results of different prompt variants."
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T5\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 5. </span>Results of using different segments.</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T5.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T5.1.2.1.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.2.1.1.1\" style=\"font-size:90%;\">Language</span></td>\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"S4.T5.1.2.1.2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"S4.T5.1.2.1.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\" id=\"S4.T5.1.2.1.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.2.1.4.1\" style=\"font-size:90%;\">Segment Average</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\" id=\"S4.T5.1.2.1.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.2.1.5.1\" style=\"font-size:90%;\">Daily Forecast</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T5.1.1.2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.2.1\" style=\"font-size:90%;\">Model</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.1.3\" rowspan=\"-2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.3.1\" style=\"font-size:90%;\">Prompt</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.1.1\" rowspan=\"-2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.1.1\" style=\"font-size:90%;\"></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.1.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.4.1\" style=\"font-size:90%;\">RMSE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.1.1.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.5.1\" style=\"font-size:90%;\">MAE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.1.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.6.1\" style=\"font-size:90%;\">RMSE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.1.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.7.1\" style=\"font-size:90%;\">MAE</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.3.2\">\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"S4.T5.1.3.2.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.1.3.2.2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.3.2.2.1\" style=\"font-size:90%;\">V3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.1.3.2.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.3.2.3.1\" style=\"font-size:90%;\">default (2)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.3.2.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.3.2.4.1\" style=\"font-size:90%;\">3.84</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.1.3.2.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.3.2.5.1\" style=\"font-size:90%;\">1.35</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.3.2.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.3.2.6.1\" style=\"font-size:90%;color:#0000FF;\">6.68</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.3.2.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.3.2.7.1\" style=\"font-size:90%;\">2.42</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.4.3\">\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T5.1.4.3.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"S4.T5.1.4.3.2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.1.4.3.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.4.3.3.1\" style=\"font-size:90%;\">2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.4.3.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.4.3.4.1\" style=\"font-size:90%;\">8.49</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.1.4.3.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.4.3.5.1\" style=\"font-size:90%;\">2.06</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.4.3.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.4.3.6.1\" style=\"font-size:90%;\">12.67</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.4.3.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.4.3.7.1\" style=\"font-size:90%;\">2.51</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.5.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T5.1.5.4.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.5.4.1.1\" style=\"font-size:90%;\">Bart</span></td>\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T5.1.5.4.2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.5.4.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.5.4.3.1\" style=\"font-size:90%;\">3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.5.4.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.5.4.4.1\" style=\"font-size:90%;color:#0000FF;\">3.35</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.5.4.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.5.4.5.1\" style=\"font-size:90%;\">0.88</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.5.4.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.5.4.6.1\" style=\"font-size:90%;\">8.07</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.5.4.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.5.4.7.1\" style=\"font-size:90%;color:#FF0000;\">2.18</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.6.5\">\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T5.1.6.5.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T5.1.6.5.2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.6.5.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.6.5.3.1\" style=\"font-size:90%;\">4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.6.5.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.6.5.4.1\" style=\"font-size:90%;color:#FF0000;\">2.64</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.6.5.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.6.5.5.1\" style=\"font-size:90%;color:#FF0000;\">0.75</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.6.5.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.6.5.6.1\" style=\"font-size:90%;\">9.20</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.6.5.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.6.5.7.1\" style=\"font-size:90%;color:#0000FF;\">2.29</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.7.6\">\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T5.1.7.6.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.7.6.2\" rowspan=\"-4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.7.6.2.1\" style=\"font-size:90%;\">V4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.7.6.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.7.6.3.1\" style=\"font-size:90%;\">5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.7.6.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.7.6.4.1\" style=\"font-size:90%;\">5.54</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.7.6.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.7.6.5.1\" style=\"font-size:90%;color:#0000FF;\">0.77</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.7.6.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.7.6.6.1\" style=\"font-size:90%;color:#FF0000;\">5.04</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.7.6.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.7.6.7.1\" style=\"font-size:90%;\">2.50</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.8.7\">\n<td class=\"ltx_td ltx_border_r ltx_border_tt\" id=\"S4.T5.1.8.7.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.1.8.7.2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.8.7.2.1\" style=\"font-size:90%;\">V3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.1.8.7.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.8.7.3.1\" style=\"font-size:90%;\">default (2)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T5.1.8.7.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.8.7.4.1\" style=\"font-size:90%;\">3.63</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.1.8.7.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.8.7.5.1\" style=\"font-size:90%;\">1.30</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T5.1.8.7.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.8.7.6.1\" style=\"font-size:90%;color:#0000FF;\">6.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T5.1.8.7.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.8.7.7.1\" style=\"font-size:90%;color:#0000FF;\">2.29</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.9.8\">\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T5.1.9.8.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"S4.T5.1.9.8.2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.1.9.8.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.9.8.3.1\" style=\"font-size:90%;\">2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.9.8.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.9.8.4.1\" style=\"font-size:90%;\">19.44</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.1.9.8.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.9.8.5.1\" style=\"font-size:90%;\">2.02</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.9.8.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.9.8.6.1\" style=\"font-size:90%;\">11.20</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.9.8.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.9.8.7.1\" style=\"font-size:90%;\">2.32</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.10.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T5.1.10.9.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.10.9.1.1\" style=\"font-size:90%;\">Bigbird</span></td>\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T5.1.10.9.2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.10.9.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.10.9.3.1\" style=\"font-size:90%;\">3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.10.9.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.10.9.4.1\" style=\"font-size:90%;\">2.56</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.10.9.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.10.9.5.1\" style=\"font-size:90%;\">0.81</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.10.9.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.10.9.6.1\" style=\"font-size:90%;color:#FF0000;\">5.43</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.10.9.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.10.9.7.1\" style=\"font-size:90%;color:#FF0000;\">2.08</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.11.10\">\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T5.1.11.10.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T5.1.11.10.2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.11.10.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.11.10.3.1\" style=\"font-size:90%;\">4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.11.10.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.11.10.4.1\" style=\"font-size:90%;color:#0000FF;\">2.52</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.11.10.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.11.10.5.1\" style=\"font-size:90%;color:#0000FF;\">0.69</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.11.10.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.11.10.6.1\" style=\"font-size:90%;\">7.13</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.11.10.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.11.10.7.1\" style=\"font-size:90%;color:#0000FF;\">2.29</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.12.11\">\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T5.1.12.11.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.12.11.2\" rowspan=\"-4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.12.11.2.1\" style=\"font-size:90%;\">V4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.12.11.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.12.11.3.1\" style=\"font-size:90%;\">5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.12.11.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.12.11.4.1\" style=\"font-size:90%;color:#FF0000;\">1.81</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.12.11.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.12.11.5.1\" style=\"font-size:90%;color:#FF0000;\">0.59</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.12.11.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.12.11.6.1\" style=\"font-size:90%;\">7.39</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.12.11.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.12.11.7.1\" style=\"font-size:90%;\">2.42</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.13.12\">\n<td class=\"ltx_td ltx_border_r ltx_border_tt\" id=\"S4.T5.1.13.12.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.1.13.12.2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.13.12.2.1\" style=\"font-size:90%;\">V3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.1.13.12.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.13.12.3.1\" style=\"font-size:90%;\">default (2)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T5.1.13.12.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.13.12.4.1\" style=\"font-size:90%;\">3.92</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.1.13.12.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.13.12.5.1\" style=\"font-size:90%;\">1.25</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T5.1.13.12.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.13.12.6.1\" style=\"font-size:90%;\">8.13</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T5.1.13.12.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.13.12.7.1\" style=\"font-size:90%;\">2.20</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.14.13\">\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T5.1.14.13.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"S4.T5.1.14.13.2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.1.14.13.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.14.13.3.1\" style=\"font-size:90%;\">2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.14.13.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.14.13.4.1\" style=\"font-size:90%;\">9.04</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.1.14.13.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.14.13.5.1\" style=\"font-size:90%;\">1.98</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.14.13.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.14.13.6.1\" style=\"font-size:90%;\">11.22</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.14.13.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.14.13.7.1\" style=\"font-size:90%;\">2.24</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.15.14\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T5.1.15.14.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.15.14.1.1\" style=\"font-size:90%;\">Pegasus</span></td>\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T5.1.15.14.2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.15.14.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.15.14.3.1\" style=\"font-size:90%;\">3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.15.14.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.15.14.4.1\" style=\"font-size:90%;\">2.41</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.15.14.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.15.14.5.1\" style=\"font-size:90%;\">0.79</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.15.14.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.15.14.6.1\" style=\"font-size:90%;color:#0000FF;\">5.20</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.15.14.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.15.14.7.1\" style=\"font-size:90%;color:#FF0000;\">2.02</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.16.15\">\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T5.1.16.15.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T5.1.16.15.2\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.16.15.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.16.15.3.1\" style=\"font-size:90%;\">4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.16.15.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.16.15.4.1\" style=\"font-size:90%;color:#0000FF;\">2.27</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.16.15.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.16.15.5.1\" style=\"font-size:90%;color:#0000FF;\">0.67</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.16.15.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.16.15.6.1\" style=\"font-size:90%;color:#0000FF;\">5.20</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.16.15.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.16.15.7.1\" style=\"font-size:90%;color:#0000FF;\">2.17</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.17.16\">\n<td class=\"ltx_td ltx_border_b ltx_border_r\" id=\"S4.T5.1.17.16.1\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S4.T5.1.17.16.2\" rowspan=\"-4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.17.16.2.1\" style=\"font-size:90%;\">V4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S4.T5.1.17.16.3\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.17.16.3.1\" style=\"font-size:90%;\">5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T5.1.17.16.4\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.17.16.4.1\" style=\"font-size:90%;color:#FF0000;\">1.70</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S4.T5.1.17.16.5\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.17.16.5.1\" style=\"font-size:90%;color:#FF0000;\">0.57</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T5.1.17.16.6\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.17.16.6.1\" style=\"font-size:90%;color:#FF0000;\">5.03</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T5.1.17.16.7\" style=\"padding-left:2.7pt;padding-right:2.7pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.17.16.7.1\" style=\"font-size:90%;\">2.30</span></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 5. Results of using different segments."
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"A0.T6\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 6. </span>The heuristic template pool includes 12 <span class=\"ltx_text ltx_font_italic\" id=\"A0.T6.106.1\">Simple</span> templates and 6 <span class=\"ltx_text ltx_font_italic\" id=\"A0.T6.107.2\">Complex</span> templates.</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A0.T6.103\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A0.T6.103.104.1\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"A0.T6.103.104.1.1\"></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"A0.T6.103.104.1.2\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.103.104.1.2.1\"><span class=\"ltx_text\" id=\"A0.T6.103.104.1.2.1.1\" style=\"font-size:90%;\">Template</span></p>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A0.T6.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A0.T6.2.2.3\" rowspan=\"12\"><span class=\"ltx_text\" id=\"A0.T6.2.2.3.1\" style=\"font-size:90%;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"A0.T6.2.2.3.1.1\" style=\"width:8.0pt;height:26.5pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:26.5pt;transform:translate(-9.25pt,-8.38pt) rotate(-90deg) ;\">\n<span class=\"ltx_p\" id=\"A0.T6.2.2.3.1.1.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A0.T6.2.2.3.1.1.1.1\">Simple</span></span>\n</span></span></span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.2.2.2\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.2.2.2.2.2\"><span class=\"ltx_text\" id=\"A0.T6.2.2.2.2.2.1\" style=\"font-size:90%;\">A private store. Human mobility in past {</span><span class=\"ltx_text\" id=\"A0.T6.2.2.2.2.2.2\" style=\"font-size:90%;\">} days are: </span><span class=\"ltx_text\" id=\"A0.T6.2.2.2.2.2.3\" style=\"font-size:90%;\">. How many people will visit tomorrow?</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.4.4\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.4.4.2\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.4.4.2.2.2\"><span class=\"ltx_text\" id=\"A0.T6.4.4.2.2.2.1\" style=\"font-size:90%;\">A private store. There are </span><span class=\"ltx_text\" id=\"A0.T6.4.4.2.2.2.2\" style=\"font-size:90%;\"> came in the past {</span><span class=\"ltx_text\" id=\"A0.T6.4.4.2.2.2.3\" style=\"font-size:90%;\">} days, and how many people?</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.6.6\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.6.6.2\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.6.6.2.2.2\"><span class=\"ltx_text\" id=\"A0.T6.6.6.2.2.2.1\" style=\"font-size:90%;\">A private store. There are </span><span class=\"ltx_text\" id=\"A0.T6.6.6.2.2.2.2\" style=\"font-size:90%;\"> came in the past {</span><span class=\"ltx_text\" id=\"A0.T6.6.6.2.2.2.3\" style=\"font-size:90%;\">} days. How many?</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.13.13\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.13.13.7\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.13.13.7.7.7\"><span class=\"ltx_text\" id=\"A0.T6.13.13.7.7.7.1\" style=\"font-size:90%;\">This is a private store in {</span><span class=\"ltx_text\" id=\"A0.T6.13.13.7.7.7.2\" style=\"font-size:90%;\">}. The human mobility of the past {</span><span class=\"ltx_text\" id=\"A0.T6.13.13.7.7.7.3\" style=\"font-size:90%;\">} days are: {</span><span class=\"ltx_text\" id=\"A0.T6.13.13.7.7.7.4\" style=\"font-size:90%;\">} people (per hour) visited in {</span><span class=\"ltx_text\" id=\"A0.T6.13.13.7.7.7.5\" style=\"font-size:90%;\">} - {</span><span class=\"ltx_text\" id=\"A0.T6.13.13.7.7.7.6\" style=\"font-size:90%;\">} on {</span><span class=\"ltx_text\" id=\"A0.T6.13.13.7.7.7.7\" style=\"font-size:90%;\">}-th day. [Repeat for </span><span class=\"ltx_text\" id=\"A0.T6.13.13.7.7.7.8\" style=\"font-size:90%;\"> days]. How many people will visit this place tomorrow?</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.19.19\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.19.19.6\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.19.19.6.6.6\"><span class=\"ltx_text\" id=\"A0.T6.19.19.6.6.6.1\" style=\"font-size:90%;\">How many people will visit this private store tomorrow? If the human mobility of the past {</span><span class=\"ltx_text\" id=\"A0.T6.19.19.6.6.6.2\" style=\"font-size:90%;\">} days are: {</span><span class=\"ltx_text\" id=\"A0.T6.19.19.6.6.6.3\" style=\"font-size:90%;\">} people (per hour) visited in {</span><span class=\"ltx_text\" id=\"A0.T6.19.19.6.6.6.4\" style=\"font-size:90%;\">} - {</span><span class=\"ltx_text\" id=\"A0.T6.19.19.6.6.6.5\" style=\"font-size:90%;\">} on {</span><span class=\"ltx_text\" id=\"A0.T6.19.19.6.6.6.6\" style=\"font-size:90%;\">}-th day. [Repeat for </span><span class=\"ltx_text\" id=\"A0.T6.19.19.6.6.6.7\" style=\"font-size:90%;\"> days].</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.26.26\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.26.26.7\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.26.26.7.7.7\"><span class=\"ltx_text\" id=\"A0.T6.26.26.7.7.7.1\" style=\"font-size:90%;\">In {</span><span class=\"ltx_text\" id=\"A0.T6.26.26.7.7.7.2\" style=\"font-size:90%;\">}, there is a private store and the human mobility of the past {</span><span class=\"ltx_text\" id=\"A0.T6.26.26.7.7.7.3\" style=\"font-size:90%;\">} days are: {</span><span class=\"ltx_text\" id=\"A0.T6.26.26.7.7.7.4\" style=\"font-size:90%;\">} people (per hour) visited in {</span><span class=\"ltx_text\" id=\"A0.T6.26.26.7.7.7.5\" style=\"font-size:90%;\">} - {</span><span class=\"ltx_text\" id=\"A0.T6.26.26.7.7.7.6\" style=\"font-size:90%;\">} on {</span><span class=\"ltx_text\" id=\"A0.T6.26.26.7.7.7.7\" style=\"font-size:90%;\">}-th day. [Repeat for </span><span class=\"ltx_text\" id=\"A0.T6.26.26.7.7.7.8\" style=\"font-size:90%;\"> days]. How many people will visit this place on tomorrow?</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.29.29\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.29.29.3\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.29.29.3.3.3\"><span class=\"ltx_text\" id=\"A0.T6.29.29.3.3.3.1\" style=\"font-size:90%;\">{</span><span class=\"ltx_text\" id=\"A0.T6.29.29.3.3.3.2\" style=\"font-size:90%;\">}. Human mobility in past {</span><span class=\"ltx_text\" id=\"A0.T6.29.29.3.3.3.3\" style=\"font-size:90%;\">} days are: </span><span class=\"ltx_text\" id=\"A0.T6.29.29.3.3.3.4\" style=\"font-size:90%;\">. How many people will visit tomorrow?</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.32.32\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.32.32.3\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.32.32.3.3.3\"><span class=\"ltx_text\" id=\"A0.T6.32.32.3.3.3.1\" style=\"font-size:90%;\">{</span><span class=\"ltx_text\" id=\"A0.T6.32.32.3.3.3.2\" style=\"font-size:90%;\">}. There are </span><span class=\"ltx_text\" id=\"A0.T6.32.32.3.3.3.3\" style=\"font-size:90%;\"> came in the past {</span><span class=\"ltx_text\" id=\"A0.T6.32.32.3.3.3.4\" style=\"font-size:90%;\">} days, and how many people?</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.35.35\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.35.35.3\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.35.35.3.3.3\"><span class=\"ltx_text\" id=\"A0.T6.35.35.3.3.3.1\" style=\"font-size:90%;\">{</span><span class=\"ltx_text\" id=\"A0.T6.35.35.3.3.3.2\" style=\"font-size:90%;\">}. There are </span><span class=\"ltx_text\" id=\"A0.T6.35.35.3.3.3.3\" style=\"font-size:90%;\"> came in the past {</span><span class=\"ltx_text\" id=\"A0.T6.35.35.3.3.3.4\" style=\"font-size:90%;\">} days. How many?</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.43.43\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.43.43.8\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.43.43.8.8.8\"><span class=\"ltx_text\" id=\"A0.T6.43.43.8.8.8.1\" style=\"font-size:90%;\">This is a {</span><span class=\"ltx_text\" id=\"A0.T6.43.43.8.8.8.2\" style=\"font-size:90%;\">} in {</span><span class=\"ltx_text\" id=\"A0.T6.43.43.8.8.8.3\" style=\"font-size:90%;\">}. The human mobility of the past {</span><span class=\"ltx_text\" id=\"A0.T6.43.43.8.8.8.4\" style=\"font-size:90%;\">} days are: {</span><span class=\"ltx_text\" id=\"A0.T6.43.43.8.8.8.5\" style=\"font-size:90%;\">} people (per hour) visited in {</span><span class=\"ltx_text\" id=\"A0.T6.43.43.8.8.8.6\" style=\"font-size:90%;\">} - {</span><span class=\"ltx_text\" id=\"A0.T6.43.43.8.8.8.7\" style=\"font-size:90%;\">} on {</span><span class=\"ltx_text\" id=\"A0.T6.43.43.8.8.8.8\" style=\"font-size:90%;\">}-th day. [Repeat for </span><span class=\"ltx_text\" id=\"A0.T6.43.43.8.8.8.9\" style=\"font-size:90%;\"> days]. How many people will visit this place tomorrow?</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.50.50\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.50.50.7\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.50.50.7.7.7\"><span class=\"ltx_text\" id=\"A0.T6.50.50.7.7.7.1\" style=\"font-size:90%;\">How many people will visit {</span><span class=\"ltx_text\" id=\"A0.T6.50.50.7.7.7.2\" style=\"font-size:90%;\">} on tomorrow? If the human mobility of the past {</span><span class=\"ltx_text\" id=\"A0.T6.50.50.7.7.7.3\" style=\"font-size:90%;\">} days are: {</span><span class=\"ltx_text\" id=\"A0.T6.50.50.7.7.7.4\" style=\"font-size:90%;\">} people (per hour) visited in {</span><span class=\"ltx_text\" id=\"A0.T6.50.50.7.7.7.5\" style=\"font-size:90%;\">} - {</span><span class=\"ltx_text\" id=\"A0.T6.50.50.7.7.7.6\" style=\"font-size:90%;\">} on {</span><span class=\"ltx_text\" id=\"A0.T6.50.50.7.7.7.7\" style=\"font-size:90%;\">}-th day. [Repeat for </span><span class=\"ltx_text\" id=\"A0.T6.50.50.7.7.7.8\" style=\"font-size:90%;\"> days].</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.58.58\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.58.58.8\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.58.58.8.8.8\"><span class=\"ltx_text\" id=\"A0.T6.58.58.8.8.8.1\" style=\"font-size:90%;\">In {</span><span class=\"ltx_text\" id=\"A0.T6.58.58.8.8.8.2\" style=\"font-size:90%;\">}, there is a {</span><span class=\"ltx_text\" id=\"A0.T6.58.58.8.8.8.3\" style=\"font-size:90%;\">} and the human mobility of the past {</span><span class=\"ltx_text\" id=\"A0.T6.58.58.8.8.8.4\" style=\"font-size:90%;\">} days are: {</span><span class=\"ltx_text\" id=\"A0.T6.58.58.8.8.8.5\" style=\"font-size:90%;\">} people (per hour) visited in {</span><span class=\"ltx_text\" id=\"A0.T6.58.58.8.8.8.6\" style=\"font-size:90%;\">} - {</span><span class=\"ltx_text\" id=\"A0.T6.58.58.8.8.8.7\" style=\"font-size:90%;\">} on {</span><span class=\"ltx_text\" id=\"A0.T6.58.58.8.8.8.8\" style=\"font-size:90%;\">}-th day. [Repeat for </span><span class=\"ltx_text\" id=\"A0.T6.58.58.8.8.8.9\" style=\"font-size:90%;\"> days]. How many people will visit this place tomorrow?</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.65.65\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_tt\" id=\"A0.T6.65.65.8\" rowspan=\"6\"><span class=\"ltx_text\" id=\"A0.T6.65.65.8.1\" style=\"font-size:90%;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"A0.T6.65.65.8.1.1\" style=\"width:8.0pt;height:34.8pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:34.8pt;transform:translate(-13.38pt,-12.5pt) rotate(-90deg) ;\">\n<span class=\"ltx_p\" id=\"A0.T6.65.65.8.1.1.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A0.T6.65.65.8.1.1.1.1\">Complex</span></span>\n</span></span></span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\" id=\"A0.T6.65.65.7\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.65.65.7.7.7\"><span class=\"ltx_text\" id=\"A0.T6.65.65.7.7.7.1\" style=\"font-size:90%;\">This is a private store in {</span><span class=\"ltx_text\" id=\"A0.T6.65.65.7.7.7.2\" style=\"font-size:90%;\">}. The human mobility of the past {</span><span class=\"ltx_text\" id=\"A0.T6.65.65.7.7.7.3\" style=\"font-size:90%;\">} days are: {</span><span class=\"ltx_text\" id=\"A0.T6.65.65.7.7.7.4\" style=\"font-size:90%;\">} people (per hour) visited in {</span><span class=\"ltx_text\" id=\"A0.T6.65.65.7.7.7.5\" style=\"font-size:90%;\">} - {</span><span class=\"ltx_text\" id=\"A0.T6.65.65.7.7.7.6\" style=\"font-size:90%;\">} on {</span><span class=\"ltx_text\" id=\"A0.T6.65.65.7.7.7.7\" style=\"font-size:90%;\">}-th day. [Repeat for </span><span class=\"ltx_text\" id=\"A0.T6.65.65.7.7.7.8\" style=\"font-size:90%;\"> days]. How many people will visit this place tomorrow?</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.72.72\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.72.72.7\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.72.72.7.7.7\"><span class=\"ltx_text\" id=\"A0.T6.72.72.7.7.7.1\" style=\"font-size:90%;\">In {</span><span class=\"ltx_text\" id=\"A0.T6.72.72.7.7.7.2\" style=\"font-size:90%;\">}, how many people will visit this private store tomorrow? If the human mobility of the past {</span><span class=\"ltx_text\" id=\"A0.T6.72.72.7.7.7.3\" style=\"font-size:90%;\">} days are: {</span><span class=\"ltx_text\" id=\"A0.T6.72.72.7.7.7.4\" style=\"font-size:90%;\">} people (per hour) visited in {</span><span class=\"ltx_text\" id=\"A0.T6.72.72.7.7.7.5\" style=\"font-size:90%;\">} - {</span><span class=\"ltx_text\" id=\"A0.T6.72.72.7.7.7.6\" style=\"font-size:90%;\">} on {</span><span class=\"ltx_text\" id=\"A0.T6.72.72.7.7.7.7\" style=\"font-size:90%;\">}-th day. [Repeat for </span><span class=\"ltx_text\" id=\"A0.T6.72.72.7.7.7.8\" style=\"font-size:90%;\"> days].</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.79.79\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.79.79.7\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.79.79.7.7.7\"><span class=\"ltx_text\" id=\"A0.T6.79.79.7.7.7.1\" style=\"font-size:90%;\">In {</span><span class=\"ltx_text\" id=\"A0.T6.79.79.7.7.7.2\" style=\"font-size:90%;\">}, there is a private store and the human mobility of the past {</span><span class=\"ltx_text\" id=\"A0.T6.79.79.7.7.7.3\" style=\"font-size:90%;\">} days are: {</span><span class=\"ltx_text\" id=\"A0.T6.79.79.7.7.7.4\" style=\"font-size:90%;\">} people (per hour) visited in {</span><span class=\"ltx_text\" id=\"A0.T6.79.79.7.7.7.5\" style=\"font-size:90%;\">} - {</span><span class=\"ltx_text\" id=\"A0.T6.79.79.7.7.7.6\" style=\"font-size:90%;\">} on {</span><span class=\"ltx_text\" id=\"A0.T6.79.79.7.7.7.7\" style=\"font-size:90%;\">}-th day. [Repeat for </span><span class=\"ltx_text\" id=\"A0.T6.79.79.7.7.7.8\" style=\"font-size:90%;\"> days]. How many people will visit this place on tomorrow?</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.87.87\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.87.87.8\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.87.87.8.8.8\"><span class=\"ltx_text\" id=\"A0.T6.87.87.8.8.8.1\" style=\"font-size:90%;\">This is a {</span><span class=\"ltx_text\" id=\"A0.T6.87.87.8.8.8.2\" style=\"font-size:90%;\">} in {</span><span class=\"ltx_text\" id=\"A0.T6.87.87.8.8.8.3\" style=\"font-size:90%;\">}. The human mobility of the past {</span><span class=\"ltx_text\" id=\"A0.T6.87.87.8.8.8.4\" style=\"font-size:90%;\">} days are: {</span><span class=\"ltx_text\" id=\"A0.T6.87.87.8.8.8.5\" style=\"font-size:90%;\">} people (per hour) visited in {</span><span class=\"ltx_text\" id=\"A0.T6.87.87.8.8.8.6\" style=\"font-size:90%;\">} - {</span><span class=\"ltx_text\" id=\"A0.T6.87.87.8.8.8.7\" style=\"font-size:90%;\">} on {</span><span class=\"ltx_text\" id=\"A0.T6.87.87.8.8.8.8\" style=\"font-size:90%;\">}-th day. [Repeat for </span><span class=\"ltx_text\" id=\"A0.T6.87.87.8.8.8.9\" style=\"font-size:90%;\"> days]. How many people will visit this place tomorrow?</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.95.95\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A0.T6.95.95.8\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.95.95.8.8.8\"><span class=\"ltx_text\" id=\"A0.T6.95.95.8.8.8.1\" style=\"font-size:90%;\">In {</span><span class=\"ltx_text\" id=\"A0.T6.95.95.8.8.8.2\" style=\"font-size:90%;\">}, how many people will visit {</span><span class=\"ltx_text\" id=\"A0.T6.95.95.8.8.8.3\" style=\"font-size:90%;\">} on tomorrow? If the human mobility of the past {</span><span class=\"ltx_text\" id=\"A0.T6.95.95.8.8.8.4\" style=\"font-size:90%;\">} days are: {</span><span class=\"ltx_text\" id=\"A0.T6.95.95.8.8.8.5\" style=\"font-size:90%;\">} people (per hour) visited in {</span><span class=\"ltx_text\" id=\"A0.T6.95.95.8.8.8.6\" style=\"font-size:90%;\">} - {</span><span class=\"ltx_text\" id=\"A0.T6.95.95.8.8.8.7\" style=\"font-size:90%;\">} on {</span><span class=\"ltx_text\" id=\"A0.T6.95.95.8.8.8.8\" style=\"font-size:90%;\">}-th day. [Repeat for </span><span class=\"ltx_text\" id=\"A0.T6.95.95.8.8.8.9\" style=\"font-size:90%;\"> days].</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T6.103.103\">\n<td class=\"ltx_td ltx_align_justify ltx_border_b ltx_border_t\" id=\"A0.T6.103.103.8\" style=\"width:390.3pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"A0.T6.103.103.8.8.8\"><span class=\"ltx_text\" id=\"A0.T6.103.103.8.8.8.1\" style=\"font-size:90%;\">In {</span><span class=\"ltx_text\" id=\"A0.T6.103.103.8.8.8.2\" style=\"font-size:90%;\">}, there is a {</span><span class=\"ltx_text\" id=\"A0.T6.103.103.8.8.8.3\" style=\"font-size:90%;\">} and the human mobility of the past {</span><span class=\"ltx_text\" id=\"A0.T6.103.103.8.8.8.4\" style=\"font-size:90%;\">} days are: {</span><span class=\"ltx_text\" id=\"A0.T6.103.103.8.8.8.5\" style=\"font-size:90%;\">} people (per hour) visited in {</span><span class=\"ltx_text\" id=\"A0.T6.103.103.8.8.8.6\" style=\"font-size:90%;\">} - {</span><span class=\"ltx_text\" id=\"A0.T6.103.103.8.8.8.7\" style=\"font-size:90%;\">} on {</span><span class=\"ltx_text\" id=\"A0.T6.103.103.8.8.8.8\" style=\"font-size:90%;\">}-th day. [Repeat for </span><span class=\"ltx_text\" id=\"A0.T6.103.103.8.8.8.9\" style=\"font-size:90%;\"> days]. How many people will visit this place tomorrow?</span></p>\n</td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 6. The heuristic template pool includes 12 Simple templates and 6 Complex templates."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.03544v1_figure_1.png",
            "caption": "Figure 1. The conceptual comparison of: (a) numerical forecasting, (b) language-based forecasting with a fixed template, (c) our proposed prompt mining process."
        },
        "2": {
            "figure_path": "2403.03544v1_figure_2.png",
            "caption": "Figure 2. The illustration of our proposed prompt mining framework. It consists of 3 stages: prompt initialization, prompt generation, and prompt refinement."
        }
    },
    "references": [
        {
            "1": {
                "title": "Human mobility prediction based on individual and collective geographical preferences. In 13th international IEEE conference on intelligent transportation systems. IEEE, 312\u2013317.",
                "author": "Francesco Calabrese, Giusy Di Lorenzo, and Carlo Ratti. 2010.",
                "venue": "",
                "url": null
            }
        },
        {
            "2": {
                "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling.",
                "author": "Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014.",
                "venue": "arXiv preprint arXiv:1412.3555 (2014).",
                "url": null
            }
        },
        {
            "3": {
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers). Association for Computational Linguistics, 4171\u20134186.",
                "author": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.",
                "venue": "",
                "url": null
            }
        },
        {
            "4": {
                "title": "Deepmove: Predicting human mobility with attentional recurrent networks. In Proceedings of the 2018 world wide web conference. 1459\u20131468.",
                "author": "Jie Feng, Yong Li, Chao Zhang, Funing Sun, Fanchao Meng, Ang Guo, and Depeng Jin. 2018.",
                "venue": "",
                "url": null
            }
        },
        {
            "5": {
                "title": "Long Short-term Memory.",
                "author": "Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997.",
                "venue": "Neural computation 9, 8 (1997), 1735\u20131780.",
                "url": null
            }
        },
        {
            "6": {
                "title": "How do you go where? improving next location prediction by learning travel mode information using transformers. In Proceedings of the 30th International Conference on Advances in Geographic Information Systems. 1\u201310.",
                "author": "Ye Hong, Henry Martin, and Martin Raubal. 2022.",
                "venue": "",
                "url": null
            }
        },
        {
            "7": {
                "title": "Reformer: The Efficient Transformer. In International Conference on Learning Representations.",
                "author": "Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya. 2019.",
                "venue": "",
                "url": null
            }
        },
        {
            "8": {
                "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020. Association for Computational Linguistics, 7871\u20137880.",
                "author": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020.",
                "venue": "",
                "url": null
            }
        },
        {
            "9": {
                "title": "Entropy-based discrimination between translated Chinese and original Chinese using data mining techniques.",
                "author": "Kanglong Liu, Rongguang Ye, Liu Zhongzhu, and Rongye Ye. 2022.",
                "venue": "Plos one 17, 3 (2022), e0265633.",
                "url": null
            }
        },
        {
            "10": {
                "title": "Predicting the next location: A recurrent model with spatial and temporal contexts. In Thirtieth AAAI conference on artificial intelligence.",
                "author": "Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2016.",
                "venue": "",
                "url": null
            }
        },
        {
            "11": {
                "title": "Pyraformer: Low-complexity pyramidal attention for long-range time series modeling and forecasting. In International conference on learning representations.",
                "author": "Shizhan Liu, Hang Yu, Cong Liao, Jianguo Li, Weiyao Lin, Alex X Liu, and Schahram Dustdar. 2021.",
                "venue": "",
                "url": null
            }
        },
        {
            "12": {
                "title": "Universal entropy of word ordering across linguistic families.",
                "author": "Marcelo A Montemurro and Dami\u00e1n H Zanette. 2011.",
                "venue": "PLoS One 6, 5 (2011), e19875.",
                "url": null
            }
        },
        {
            "13": {
                "title": "A Time Series is Worth 64 Words: Long-term Forecasting with Transformers. In The Eleventh International Conference on Learning Representations.",
                "author": "Yuqi Nie, Nam H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. 2022.",
                "venue": "",
                "url": null
            }
        },
        {
            "14": {
                "title": "GPT-4 Technical Report.",
                "author": "OpenAI. 2023.",
                "venue": "",
                "url": null
            }
        },
        {
            "15": {
                "title": "A hybrid Markov-based model for human mobility prediction.",
                "author": "Yuanyuan Qiao, Zhongwei Si, Yanting Zhang, Fehmi Ben Abdesslem, Xinyu Zhang, and Jie Yang. 2018.",
                "venue": "Neurocomputing 278 (2018), 99\u2013109.",
                "url": null
            }
        },
        {
            "16": {
                "title": "Language models are unsupervised multitask learners.",
                "author": "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019.",
                "venue": "OpenAI blog 1, 8 (2019), 9.",
                "url": null
            }
        },
        {
            "17": {
                "title": "Information gain-based metric for recognizing transitions in human activities.",
                "author": "Amin Sadri, Yongli Ren, and Flora D Salim. 2017.",
                "venue": "Pervasive and Mobile Computing 38 (2017), 92\u2013109.",
                "url": null
            }
        },
        {
            "18": {
                "title": "Where to go next: Modeling long-and short-term user preferences for point-of-interest recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 214\u2013221.",
                "author": "Ke Sun, Tieyun Qian, Tong Chen, Yile Liang, Quoc Viet Hung Nguyen, and Hongzhi Yin. 2020.",
                "venue": "",
                "url": null
            }
        },
        {
            "19": {
                "title": "Forecasting at scale.",
                "author": "Sean J Taylor and Benjamin Letham. 2018.",
                "venue": "The American Statistician 72, 1 (2018), 37\u201345.",
                "url": null
            }
        },
        {
            "20": {
                "title": "Llama 2: Open foundation and fine-tuned chat models.",
                "author": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023.",
                "venue": "arXiv preprint arXiv:2307.09288 (2023).",
                "url": null
            }
        },
        {
            "21": {
                "title": "Attention is all you need.",
                "author": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017.",
                "venue": "Advances in neural information processing systems 30 (2017).",
                "url": null
            }
        },
        {
            "22": {
                "title": "Chain-of-thought prompting elicits reasoning in large language models.",
                "author": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022.",
                "venue": "Advances in Neural Information Processing Systems 35 (2022), 24824\u201324837.",
                "url": null
            }
        },
        {
            "23": {
                "title": "TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis. In The Eleventh International Conference on Learning Representations.",
                "author": "Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, and Mingsheng Long. 2022.",
                "venue": "",
                "url": null
            }
        },
        {
            "24": {
                "title": "Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting.",
                "author": "Jiehui Xu, Jianmin Wang, Mingsheng Long, et al. 2021.",
                "venue": "Advances in Neural Information Processing Systems 34 (2021).",
                "url": null
            }
        },
        {
            "25": {
                "title": "MobTCast: Leveraging auxiliary trajectory forecasting for human mobility prediction.",
                "author": "Hao Xue, Flora Salim, Yongli Ren, and Nuria Oliver. 2021.",
                "venue": "Advances in Neural Information Processing Systems 34 (2021), 30380\u201330391.",
                "url": null
            }
        },
        {
            "26": {
                "title": "TERMCast: Temporal relation modeling for effective urban flow forecasting. In Pacific-Asia Conference on Knowledge Discovery and Data Mining. Springer, 741\u2013753.",
                "author": "Hao Xue and Flora D Salim. 2021.",
                "venue": "",
                "url": null
            }
        },
        {
            "27": {
                "title": "Promptcast: A new prompt-based learning paradigm for time series forecasting.",
                "author": "Hao Xue and Flora D Salim. 2023.",
                "venue": "IEEE Transactions on Knowledge and Data Engineering (2023).",
                "url": null
            }
        },
        {
            "28": {
                "title": "Translating human mobility forecasting through natural language generation. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining. 1224\u20131233.",
                "author": "Hao Xue, Flora D Salim, Yongli Ren, and Charles LA Clarke. 2022a.",
                "venue": "",
                "url": null
            }
        },
        {
            "29": {
                "title": "Leveraging language foundation models for human mobility forecasting. In Proceedings of the 30th International Conference on Advances in Geographic Information Systems. 1\u20139.",
                "author": "Hao Xue, Bhanu Prakash Voutharoja, and Flora D Salim. 2022b.",
                "venue": "",
                "url": null
            }
        },
        {
            "30": {
                "title": "MTMGNN: Multi-time multi-graph neural network for metro passenger flow prediction.",
                "author": "Du Yin, Renhe Jiang, Jiewen Deng, Yongkang Li, Yi Xie, Zhongyi Wang, Yifan Zhou, Xuan Song, and Jedi S Shang. 2023.",
                "venue": "GeoInformatica 27, 1 (2023), 77\u2013105.",
                "url": null
            }
        },
        {
            "31": {
                "title": "Big bird: Transformers for longer sequences.",
                "author": "Manzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, et al. 2020.",
                "venue": "Advances in Neural Information Processing Systems 33 (2020), 17283\u201317297.",
                "url": null
            }
        },
        {
            "32": {
                "title": "Are transformers effective for time series forecasting?. In Proceedings of the AAAI conference on artificial intelligence, Vol. 37. 11121\u201311128.",
                "author": "Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. 2023.",
                "venue": "",
                "url": null
            }
        },
        {
            "33": {
                "title": "Pegasus: Pre-training with extracted gap-sentences for abstractive summarization. In International Conference on Machine Learning. PMLR, 11328\u201311339.",
                "author": "Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter Liu. 2020.",
                "venue": "",
                "url": null
            }
        },
        {
            "34": {
                "title": "Less is more: Fast multivariate time series forecasting with light sampling-oriented mlp structures.",
                "author": "Tianping Zhang, Yizhuo Zhang, Wei Cao, Jiang Bian, Xiaohan Yi, Shun Zheng, and Jian Li. 2022.",
                "venue": "arXiv preprint arXiv:2207.01186 (2022).",
                "url": null
            }
        },
        {
            "35": {
                "title": "Crossformer: Transformer utilizing cross-dimension dependency for multivariate time series forecasting. In The Eleventh International Conference on Learning Representations.",
                "author": "Yunhao Zhang and Junchi Yan. 2022.",
                "venue": "",
                "url": null
            }
        },
        {
            "36": {
                "title": "Informer: Beyond efficient transformer for long sequence time-series forecasting. In Proceedings of AAAI.",
                "author": "Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang. 2021.",
                "venue": "",
                "url": null
            }
        },
        {
            "37": {
                "title": "FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting. In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA (Proceedings of Machine Learning Research, Vol. 162). PMLR, 27268\u201327286.",
                "author": "Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin. 2022.",
                "venue": "",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.03544v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2.2"
        ],
        "methodology_sections": [
            "3.1",
            "3.2",
            "3.3",
            "3.3.1",
            "3.3.2",
            "3.4",
            "3.4.1",
            "3.4.2",
            "3.5",
            "3.5.1",
            "3.5.2",
            "3.5.3",
            "3.6"
        ],
        "main_experiment_and_results_sections": [
            "4.1",
            "4.2",
            "4.3",
            "4.4",
            "4.5",
            "4.6",
            "4.7"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4.6",
            "4.7"
        ]
    },
    "research_context": {
        "paper_id": "2403.03544v1",
        "paper_title": "Prompt Mining for Language-based Human Mobility Forecasting",
        "research_background": "### Paper's Motivation\nThe paper is motivated by the need for accurate human mobility forecasting, which is vital for several applications such as urban planning, transportation management, public health, and disaster response. Traditional statistical methods and recent advanced deep learning methods, particularly Transformer-based approaches, often exhibit limitations, such as failing to capture complex human behaviors or requiring overly complicated architectures. Emerging language-based forecasting approaches leveraging NLP and pre-trained language models offer a promising alternative, but face challenges in designing effective prompts to translate numerical mobility data into natural language. This paper aims to address these existing limitations by proposing a novel prompt mining framework designed to enhance the effectiveness of language-based mobility forecasting.\n\n### Research Problem\nThe central research problem addressed in this paper is the design of effective prompts for language-based human mobility forecasting. Especially, how to transform numerical mobility data and associated auxiliary information into sentences for language models in a way that accurately captures underlying mobility patterns. Existing methods using fixed, manually designed templates for prompt generation can lead to inaccuracies, suggesting the need for more sophisticated prompt generation and refinement processes.\n\n### Relevant Prior Work\n1. **Traditional Statistical Forecasting:**\n   - Calabrese et al. (2010)\n   - Qiao et al. (2018)\n\n2. **Deep Learning Forecasting Methods:**\n   - Feng et al. (2018)\n   - Sun et al. (2020)\n   - Yin et al. (2023)\n\n3. **Transformer-based Approaches:**\n   - Xue and Salim (2021)\n   - Hong et al. (2022)\n   - Xue et al. (2021)\n\n4. **Language-based Forecasting Approaches:**\n   - Xue et al. (2022a, 2022b)\n   - Xue and Salim (2023)\n\n5. **Language Models Used:**\n   - BERT (Devlin et al., 2019)\n\nThese references highlight the evolution from traditional numerical methods to more advanced, language-based approaches, showing a shift towards leveraging natural language processing technologies for more accurate and potentially less complex forecasting models. The referenced works also point out that while language models like BERT are proficient in understanding and generating human language, the effectiveness of such models in forecasting largely depends on how well numerical data is transformed into meaningful prompts.",
        "methodology": "The methodology section outlines a novel framework called \"Prompt Mining\" aimed at enhancing language-based human mobility forecasting by optimizing prompt design. Here's a breakdown of the key components and innovations of the proposed method:\n\n1. **Problem Definition**: \n   - The primary goal is to improve human mobility forecasting at Points of Interest (POIs) using optimized language-based prompts.\n   - The forecasting task involves predicting the number of visits to a POI for the subsequent day using historical customer visit records over consecutive days.\n\n2. **Auxiliary Information**: \n   - Various auxiliary information about the POI, such as area region information, semantic information, opening information (business opening and closing times), and fine-grained hourly visits, is often available to assist in the forecasting process.\n\n3. **Prompting Template**: \n   - A predefined prompting template \\( P \\) is employed to convert numerical data into readable sentences (prompts).\n   - The template includes placeholders for actual data values, creating sentences that present the mobility information in a human-readable format.\n\n4. **Components of the Template**:\n   - **History Prompt Template** \\( P_H \\): Describes the historical values as input sentences for the language models.\n   - **Future Prompt Template** \\( P_F \\): Defines sentences for describing future observations.\n\n5. **Optimization of Prompts**:\n   - The study focuses on the design of the prompting template \\( P \\), particularly the input components \\( P_H \\).\n   - The goal is to explore diverse, contextually relevant, coherent, and effective prompts that guide language models to produce accurate forecasts.\n\n6. **Objective**:\n   - By investigating and optimizing the prompts, the aim is to enhance the forecasting accuracy and reliability of language-based human mobility forecasting.\n\nThe innovation lies in the unique approach to leveraging language models for mobility forecasting by optimizing the design of prompting templates, transforming numerical data into contextually relevant sentences for improved predictive performance.",
        "main_experiment_and_results": "## Main Experiment Setup and Results\n\n### Datasets\nFor our experiments, we leverage mobility pattern data accessed through the Dewey research data platform, specifically collected from SafeGraph. The dataset encompasses a total of 562,151 rows of raw weekly data of US Points of Interest (POIs) from 172 different brand types. The temporal span of the data ranges from December 26, 2022, to January 2, 2023. Each data entry includes one week of visiting data for a specific POI, which encompasses both daily and hourly counting. Additionally, auxiliary information like the region of the POI and its opening/closing hours are also provided.\n\n### Baselines\nOur baseline setup follows prior language-based human mobility forecasting studies (Xue et al., 2022a, b) that ensure our approach is built on established methodologies and well-tested baselines from related studies in the field.\n\n### Evaluation Metrics\nThe performance of our forecasting approach is evaluated based on the accuracy of predictions regarding human mobility patterns. Specific metrics used to quantify performance include traditional accuracy metrics and other relevant industry-standard measures to ensure comprehensive evaluation.\n\n### Main Experimental Results\nTo summarize the results obtained through this setup, our prompt mining approach demonstrated significant improvements over the baselines from previous studies. The results are indicative of the effectiveness of integrating language-based prompts in forecasting human mobility, showing marked accuracy improvements. Specific results, including numerical metrics and comparative performance details, solidify the argument that language, when properly mined, can be a powerful feature for mobility pattern forecasting."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To have a deeper understanding of our prompt mining approach and its impact on forecasting accuracy.",
            "experiment_process": "The study analyzes the performance of different prompt variants (V1-V3) using three language models: Bart, Bigbird, and Pegasus. The performance is evaluated based on daily forecasting results, with specific metrics being RMSE and MAE, observed in terms of both the first half day and the second half day as well as overall daily performance.",
            "result_discussion": "V3 outperforms V1 and V2 in terms of forecasting accuracy for all models. For the Bart model, V2 shows substantial improvements over V1 with significant reductions in RMSE and MAE, while V3 exhibits a large reduction in daily forecast RMSE. In the Bigbird model, V2 and V3 show remarkable improvements over V1 for the first half day, with V3 being the top performer in daily forecasts despite V1 performing better in the second half day. In the Pegasus model, trends are similar to those observed in the Bigbird analysis. This analysis demonstrates the efficacy of the mining method in enhancing forecasting accuracy, particularly highlighting the significance of the prompt refinement phase.",
            "ablation_id": "2403.03544v1.No1"
        },
        {
            "research_objective": "To explore the impact of different segmenting mechanisms used in the prompt refinement stage on forecasting performance.",
            "experiment_process": "The experiment investigates how different numbers of segments in V4 prompts influence forecasting performance. The results are compared with V3, which employs diurnal partitioning with 2 segments. The evaluation metrics include average RMSE/MAE of each segment for settings with more than 2 segments and the best and second-best results for each language model (Bigbird, Pegasus, and Bart).",
            "result_discussion": "Increasing the number of segments from 2 to 5 in V4 leads to decreased error for both Bigbird and Pegasus in terms of segment average performance. A similar trend is observed for daily forecasting performance in Bart and Pegasus models. The refined V4 prompts generally perform favorably compared to V3 prompts, indicating that a dynamic segmentation strategy can further improve language-based forecasting methods. The consistent performance across different language models demonstrates the adaptability of the prompt mining approach.",
            "ablation_id": "2403.03544v1.No2"
        }
    ]
}