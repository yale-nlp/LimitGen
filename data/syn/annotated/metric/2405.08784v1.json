{
    "title": "Refinement of an Epilepsy Dictionary through Human Annotation of Health-related posts on Instagram",
    "abstract": "Objective \u2014\nTo (1) identify health-related terms used on social media posts that do not precisely match the health-related meaning of terms in a biomedical dictionary, (2) decide which terms need to be removed in order to improve the quality of the dictionary in the scope of biomedical text mining tasks, (3) evaluate the effect of removing imprecise terms on such tasks, and (4) discuss how human-centered annotation complements automated annotation in social media mining for biomedical purposes.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Social media data, such as text, hashtags, or images in posts, allow researchers to gain unprecedented access to study human cohorts. It is now possible to quantitatively measure very large populations for their individual or collective experiences, behaviors, perceptions, and emotions.\n\nSocial media is more than a source of information or a valuable communication tool for its users\u2014it is also a valuable resource of information about human health and well-being. It has been used to track and predict various public health issues, such as mental health disorders, adverse drug reaction (ADR), drug-drug interactions (DDI), and substance abuse.\n\nInstagram is one of the most popular social network services in the world; in 2021, Instagram reached more than 1 billion users worldwide. Through an application for smartphones or tablets, users can share photos and videos, often accompanied by long captions. Although most research on social media has been focused on data from Twitter or Facebook, Instagram has great potential for social media research given its increasing number of users. It has already shown its potential for large-scale social media analysis and monitoring of public health issues, such as DDI and ADR, uncovering behavioral pathology and associations between drugs and symptoms in depression. It can even be used as a tool for communication and support between patients and healthcare providers, and other health-related applications. For these reasons, the work described here is focused on data from Instagram, but our methodology and results are applicable to other social media from Twitter to Reddit.\n\nDespite the benefits of social media analysis for public health, social media research has not focused much on people with epilepsy (PWE), a chronic noncommunicable brain disorder and one of the most common neurological diseases. In the U.S., more than three million adults have epilepsy, and about 470,000 children were diagnosed with active epilepsy in 2015. Epilepsy-relevant Facebook pages and Twitter accounts play an essential role in providing information about drugs or correcting misconceptions or epilepsy stigma on online platforms. Furthermore, our team has shown that even small cohorts of epilepsy patients on Facebook can inform experts about relevant behaviors involved in rare outcomes, such as sudden death in epilepsy.\n\nTherefore, more research on PWE and their caregivers\u2019 online behaviors on social media, from epilepsy-specific online groups to general-purpose platforms, is needed\u2014especially to better understand their complex symptoms and medication schedules, including DDI and ADR. To support such a research agenda, it is essential to develop automated annotation pipelines to mine and detect biomedical signals from large-scale social media data in general. At the core of such pipelines is the construction of biomedical dictionaries to tag relevant terminology in social media posts. Typically these are produced from databases and named entity recognition tools that were developed for scientific discourse, such as papers with experimental evidence available on PubMed.\n\nHowever, it is unclear whether biomedical dictionaries built from scientific discourse and evidence are fit for the informal discourse and particularities of discussions on Instagram and other social media that are relevant for epilepsy (or other conditions of medical interest). To address that question, here we present a human-centered dictionary refinement methodology and analysis tailored to tag clinically relevant terminology for the study of epilepsy cohorts on Instagram. For comparison, OpenAI\u2019s GPT series models, as representatives of Large Language Model (LLMs), were also used as an alternative annotation process, though leading to worse results than human annotators in our analysis.\n\nIn addition to producing a focused biomedical dictionary for social media, our manual annotation effort demonstrates the importance of human annotation to improve the quality of cohort-specific social media analysis."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Data and Methods",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Dictionary Construction",
            "text": "Our dictionary includes terms related to drugs, allergens, medical terms, and natural products, including cannabis. We construct this dictionary following [15, 29]. We recall the details of that construction below.\n\nWe obtained these terms from a variety of existing medical ontologies and data sources. Drug, allergen, and food terms are retrieved from Drugbank (v.5.1.0) [30]. Medical terms including, but not limited to, disease symptoms and drug side effects are obtained from MedDRA (v.15) [31]. Natural products are retrieved from MedlinePlus [32] and TCMGeneDIT [33]. For cannabis, we manually added commonly referred terms and slang, such as \u2018Mary Jane\u2019 and \u2018420\u2019, to our dictionary, as detailed in [15]. In addition, epilepsy terms commonly used by patients on Internet forums were manually added using a C-value [34] tokenizer on the Epilepsy.com discussion forums. These epilepsy-related terms include mentions such as \u2018VNS\u2019 (i.e. Vagus Nerve Stimulator) and were validated by an epilepsy specialist and matched to MedDRA codes.\n\nWe distinguish dictionary terms into four categories: Allergens, Drugs, Medical Terms, and Natural Products. Allergens include food names, ingredients, and animals (e.g., Orange, Duck); Drugs include medicine and chemical compounds (e.g., Diazepam); Medical Terms include status and conditions of putative medical relevance, such as physical, psychological, or physiological features (e.g., Headache, Feeling hot); Natural Products consist of plants and their extracted elements (e.g., Rose).\n\nImportantly, synonyms are possible for each term. Therefore, all those are matched\u2014as child terms\u2014to a unique parent (preferred) term. For instance, Weed, Mary jane, 420, and Cannabis are all synonyms of the parent term Cannabis. The parent term is also included as a child term for completeness of synonym lists. Drug names are treated similarly, whereby we keep the chemical name as parent terms (e.g. Diazepam), and all known commercial names (as extracted from DrugBank [30]) as child terms (e.g. Valium). Some data sources of our dictionary already have term hierarchy, and we used it as the base of our parent term mapping (for example, the \u201cpreferred term\u201d in MedDRA is mapped to the parent term in our dictionary).\n\nTable 1 lists examples of the extracted posts, terms, and their parent term. After this collection and initial automatic curation procedure, our dictionary contains 176,278 terms, of which 105,345 are Drugs, 66,961 are Medical Terms, 2,797 are Allergens, and 1,175 are Natural Products."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Data Collection and Post Tagging",
            "text": "Since June 2016, the collection of Instagram data via the platform\u2019s API has been limited due to a company policy change. Here we use publicly available data from Instagram posts ranging from 2011 to early 2016 when they were collected and securely stored according to the platform\u2019s terms on our servers. The data is comprised of the entire timelines (all time-stamped public posts) of Instagram users who produced at least one post mentioning a hashtag with a drug name (or synonym) known to treat epilepsy. The drug names we used to retrieve timelines include carbamazepine, clobazam, diazepam, lacosamide, lamotrigine, levetiracetam, oxcarbazepine, as well as all their brand name synonyms (e.g., Valium). In addition, we added all user timelines that mentioned the epilepsy-associated hashtag \u2018#seizuremeds\u2019 which is commonly used among people with epilepsy (PWE) on discussion forums such as Epilepsy.com. This resulted in the collection of the entire timelines of a cohort of 9,890 users, comprising 8,496,124 posts. Duplicate posts from regrams were removed. In order to protect user privacy, we did not extract demographic information from the collected accounts. The caption field of all collected posts was subsequently tagged with the dictionary terms according to an automatic multi-word lexical matching pipeline, resulting in a total of 979,683 dictionary term matches on the more than 8 million Instagram posts in the dataset."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Results",
            "text": ""
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Human-centered Annotation",
            "text": "Automatic lexical matching with biomedical dictionaries built from scientific discourse and evidence is not necessarily contextually accurate when tagging social media posts. Indeed, dictionary terms used in social media discourse may refer to alternate meanings without any putative clinical relevance. For instance, the term \u2018hot\u2019 has multiple meanings depending on context, ranging from \u2018having a fever\u2019 to \u2018sexual appeal\u2019. Naturally, we are only interested in the potential clinical relevance of dictionary term usage. Therefore, we need to refine the dictionary terms to improve the accuracy of term matches in biomedical social media analytics.\n\nTo do this we designed and pursued a manual annotation workflow to identify the dictionary terms most likely to be irrelevant in the context of Instagram discourse related to epilepsy. Because it was unfeasible for our team to manually annotate over 8 million posts, a sample was randomly selected to provide a reasonable amount of posts for human annotators. This resulted in a set of 1,771 posts containing at least one matched term, for a total of 2,947 matches, associated with 466 unique parent terms.\n\nThe number and proportion of matches per dictionary category is:  = 874 (29.7%; 108 parent terms),  = 204 (6.9%; 64 parent terms),   = 1,647 (55.9%; 268 parent terms), and   = 222 (7.5%; 26 parent terms). Table 1  ###reference_### shows examples of posts and respective matched child terms (in red), their parent terms and categories. Each human annotator was given our annotation guidelines to understand the goal of the study and criteria to determine whether a matched term is used in the expected or correct sense (\u2018true-positive\u2019). Also, they were provided with instructions with examples to learn how to annotate through our annotation tool.\n\nThis sample was subsequently used in our annotation workflow which comprises two rounds (See Figure 1  ###reference_### & SI: Figure S1  ###reference_###): ###figure_1###.\n\nInitial annotation & guideline refinement. 292 posts with 499 dictionary matches were used to test the annotation workflow and to refine our annotation guidelines, establishing a standard for deciding whether a matched term was used as intended by the biomedical dictionary (true positive) in the context of the post. For instance, in the context of medical terms, if a matched term \u201cA\u201d is expressed as signifying a medical term, health condition, drug, food, or (potential) allergen (\u2018A\u2019), an annotator is instructed to label it as \u2018True.\u2019 Each sampled post was assigned to two annotators, with disagreements being collectively discussed to reach a consensus that triggered a revision to the guidelines.\n\nFull annotation review. Using the refined annotation guidelines obtained from the first step of the workflow (See Table 2  ###reference_###), all 1,771 posts in the sample and their 2,947 matches were reviewed independently by two annotators. Data scientists in training as well as epilepsy researchers participated in the annotation. They decided whether terms were appropriately matched (true-positive) or unclear to determine (e.g., a term with unclear meaning). Annotations were compared, achieving a good inter-rater reliability rating (Cohen\u2019s Kappa=0.634) [36  ###reference_b36###].\n\n###figure_2### An example of the interface used by annotators is provided in Figure S2  ###reference_### in SI. In this interface, each row displays a complete Instagram post with a dictionary term match highlighted in red. An annotator can review the context of each post and determine whether the meaning of the red-highlighted word is expressed with the intended use of the biomedical dictionary term, following the criteria provided in the guidelines. Notice that annotators are not shown the photos that accompany the post text on Instagram. They are only shown the text, which makes this a difficult task for human annotators and more so for LLMs used below."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Identifying Ambiguous Terms",
            "text": "After the full annotation review step of the human-centered annotation process, annotators considered and inferred the context of the post where the match occurred from text alone. In one case, from context, annotators infer that the dictionary term for Orange (as fruit it is in the allergen category) is actually used to mean the color orange. Similarly, in another post, rose was actually identified as a typo for ros\u00e9 (wine), thus assigned to an incorrect parent dictionary term. Focusing on each of the four term categories, the human-centered annotation revealed occurrences in various contexts: \n\nAllergen: These include Orange, Apple and Ginger which were frequently found to indicate a color, name (brand, pet, place, etc.), or toys, respectively.\n\nDrug: Since this drug brand name is frequently used as a metaphor on social media (unlike in the scientific literature), a discourse feature human annotators can easily infer (unlike most automatic methods).\n\nMedical term: This category showed broad meanings in which these terms were frequently used. For instance, Hot resolves to the Feeling hot parent term, which clinically means to be \u201chaving or feeling a relatively high temperature\u201d (fever). However, in the sampled posts, Hot often meant \u201csexually excited\u201d or \u201cnewly made\u201d\u2014another case of very distinct usage between social media and scientific discourse.\n\nNatural product: Examples include Rose, Rosa, and Daphne, where the inferred context often indicated one\u2019s name or color.\n\nThe next step is to identify which terms are most ambiguous and should be removed from the dictionary in order to refine and tailor it to epilepsy discourse on social media, our problem domain. The most concerning terms are naturally those that occur very frequently in our data. Table 4 lists the top 8 such child terms, as well as their respective parent terms. For instance, the terms Hot, Cold, and Euphoria are frequent matches in posts, but most of the time without any putative medical significance since they typically occur in contexts without any relationship to the intended meaning of the term in the biomedical dictionary.\n\nIn contrast, while the term Cannabis appears very frequently in our samples, it is most often used in relevant contexts. In Figure 2, we show two of the synonyms of Cannabis: 420 and weed.\n\nTo obtain a new refined dictionary, we established a criterion to remove terms that maximize this ambiguity and occur frequently enough in the human-annotated post sample. We first selected terms with a high ambiguity and frequency, subsequently ranking them by frequency. This resulted in the removal of 8 terms listed in Table 4: Hot, Cold, Euphoria, Valium, Death, Rose, Orange, and Ginger. Among the 8 terms, we found that most occurrences of Hot were not about feeling elevated temperature but about feeling excitement or describing something as popular. On the contrary, Cold was mostly used as a term about temperature, not about the illness known as the Common Cold. Likewise, the meaning of Euphoria was often not related to one\u2019s feeling of joy, since it was frequently used in club music-relevant contexts that may indicate a musical genre, a music album, or a brand.\n\nAs for Valium, if the word was mentioned with other terms related to drugs, it was easier to determine meaning. However, almost half of the posts that mentioned it did not provide enough context. In the remaining half, it was often used as a metaphor for something boring (e.g. example on the second row of table 3). Finally, Rose, Orange, and Ginger in the posts were frequently used as proper nouns, such as a person, an area, or a pet."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Impact of Removing Ambiguous Terms",
            "text": "After dictionary refinement, we evaluate the impact of term removal on the eigenvector-centrality of networks whose edge weights are obtained by tallying dictionary co-mentions in posts (their construction, especially how we dealt with parent terms and child terms, is detailed in SI Section B.1). These co-mention networks can be seen as associative knowledge structures that characterize the discourse of social media cohorts. The co-mention networks are built on the level of parent terms in the sense that each node is a parent term covering several synonyms in the dictionary. In such associative knowledge networks, removing terms from the dictionary potentially reduces the set of nodes that comprise them (each parent term is represented as a node and the term removal is done at the level of the child term). More importantly, removing terms also affects the edge weights between nodes, as co-mention counts are altered. Since the structure of connections is altered, all inferences one can make from these networks\u2014such as information retrieval, link prediction, community structure, shortest paths\u2014can be affected. We chose eigenvector centrality because it is a popular measurement of node importance that accounts for indirect influence between nodes on undirected graphs, thus allowing us to assess the network-level impact of term removal. Another popular node centrality is PageRank centrality. Although it is powerful on directed graphs, it is highly correlated with (or almost exactly the same as) node degree when applied to undirected networks. Therefore, since our co-mention networks are undirected, we choose eigenvector centrality rather than PageRank to assess the effect of removing terms. The top 20 terms ranked by eigenvector centrality, before and after dictionary refinement, are shown in Table 5. Top eigenvector centrality terms before the refinement include terms not particularly relevant to epilepsy, such as Cocoa or Tattoo. However, after dictionary refinement, not only do parent terms like Feeling hot disappear from the top, since their main child terms were no longer present in the dictionary, but we see that all the top 10 terms are associated with epilepsy, as attested by our epilepsy specialists. For instance, Depression, a clinical diagnosis often co-morbid with epilepsy, jumps from 9th (0.040) to the top-ranked centrality score term (0.599), closely followed by Anxiety. This suggests that our dictionary refinement improved the quality of the top eigenvector centrality terms, bringing epilepsy-related terms to a more central role in the knowledge network."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Comparing Social Media with Medical and Scientific Discourse",
            "text": "At the onset, the hypothesis behind our study is that while there is much discourse on general-purpose social media platforms that is of biomedical relevance, it is expressed differently than scientific discourse and unfolds simultaneously with many other contexts that are not relevant to health. Thus, human-centered dictionary refinement is needed to remove ambiguous terms in such platforms. \n\nTo emphasize this need, and how different general-purpose social media discourse is, we go beyond Instagram and deploy both the original and the refined version of our dictionary in other data sources: epilepsy-related abstracts from PubMed, epilepsy-related clinical trials from clinicaltrials.gov, Twitter (now named X) posts from users who have mentioned epilepsy related terms, and discussion forums from Epilepsy.com. Detailed descriptions of data harvesting and network construction of additional data sources are available in SI Appendix B under each data source section.\n\nThe first two additional data sources pertain to scientific discourse. Both Instagram and Twitter data sources represent epilepsy related users\u2019 speech on a general-purpose social media. The last data source is a form of social media that is focused on a single topic of medical relevance\u2014epilepsy, in this case.\n\nThis suggests that general-purpose social media platforms such as Instagram are much noisier for biomedical surveillance, and for epilepsy research in particular, since users tend to post about many distinct aspects of their lives. In contrast, in the Epilepsy Foundation (EF) forums users center discourse around their condition, which naturally makes it a rich resource for epilepsy research.\n\nThe same can be said for the chosen PubMed articles or Clinical Trials, where the scientific context is focused on epilepsy. Therefore, the impact of removing the same 8 terms from the knowledge networks of both the EF forums and the PubMed abstracts is much less pronounced in comparison to Instagram."
        },
        {
            "section_id": "3.5",
            "parent_section_id": "3",
            "section_name": "The disagreement between GPT-4 and human annotators is significant",
            "text": "Complementary to our human annotation efforts, we tested the feasibility of using a large language model instead of human annotators in the labeling process of our proposed dictionary refinement workflow. We assigned the same labeling task to OpenAI\u2019s latest and most advanced model, GPT-4 (version 1106 in 2023) and its predecessor GPT-3.5 via OpenAI\u2019s API, using the same guidelines we provided to human annotators.\n\nWe find significant disagreement between GPT-4 and the decisions of human annotators. We use OpenAI\u2019s API to ask OpenAI\u2019s GPT-3.5 (version gpt-3.5-turbo-1106) and GPT-4 (version gpt-4-1106-preview) to do the same labeling task as our human annotators. We converted the human annotation guidelines, initially designed for humans and presented to them in slides, into a text-based prompt for the AI, undergoing several rounds of refinement for optimization. For human annotators, the term matches to be annotated are highlighted in color, while for the LLM\u2019s task, these terms are marked with asterisks (*) on both sides. This method serves as a text-based alternative to visual highlighting, and is commonly used in prompting LLMs.\n\nFor each term tagged on a post, we query the LLM using two prompts: one system prompt based on the annotation guidelines, and one user prompt containing the entire text of the post with the highlighted term. The LLM was instructed to provide a response in json format, with both the decision label and justification for the classification. The model\u2019s response was then collected and parsed. For term matches that the LLM returned a different label than human annotators, we used the justification text generated by the model to suggest possible causes for the disagreement.\n\nFor each round of our prompt iteration, we used 200 tagged terms to test the performance. During those tests, GPT-3.5 consistently showed inferior performance compared to GPT-4, so we did not run a full-scale evaluation for GPT-3.5, choosing to focus on GPT-4 only. For the final full-scale test, we sent 1,500 term matches to GPT-4 (corresponding to 1,500 rows in the tables for human annotators), using our final version of the prompt.\n\nIn particular, GPT-4 tended to label correctly matched terms (\u201cTrue Positive\u201d in the annotation guideline and \u201cmatch\u201d for short in the following tables) as incorrectly matched (\u201cmismatch\u201d for short in the tables). In other words, it is more strict in designating a term as being used in a putatively clinically relevant way. As shown in Table 8, for the same set of 1,500 term matches, there are only 29 cases where the master annotator determined it as \u201cmismatch\u201d while the annotator 2 thought it was a \u201cmatch\u201d; in comparison, there are 285 cases where GPT-4 thought it was \u201cmismatch\u201d and the annotator 2 thought it was a \u201cmatch\u201d."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Discussion",
            "text": "In this paper, we show the importance of manual curation in developing a biomedical dictionary to study epilepsy-related discussions on social media. Despite its cultural importance and global reach, Instagram, the social media we study, has not been a focus of social media research. In general, most biomedical research on social media focuses on platforms with freely and easily accessible data, such as Twitter (now named X). \n\nVery few studies so far have analyzed the social media discourse of people with epilepsy and their caregivers [6  ###reference_b6###] using biomedical dictionaries. The use of dictionary-based methods to study biomedical discourse is not new. In general, they have been used for knowledge discovery and applied to large corpus of clinician-written notes and more recently extracted from electronic health records. Our goal here using human annotation is to refine the dictionary by removing inappropriate terms for social media data analysis.\n\nHuman annotation has been widely used to analyze and understand sentiments, behaviors, perceptions, languages, or relations of people in social media. Although automated annotation techniques can process data faster than human annotation, our results support prior literature showing human annotation is necessary when extracting term meaning from social media posts. Balancing between the speed of automated annotation and the reliability and validity of human annotation can lead to optimal results.\n\nWe identified what kinds of terms tend to mean differently than their biomedical meaning through human annotation and how often they have been used in social media posts. Proper nouns were one of the most common cases of misinterpretation, along with words used as metaphors. These results imply that future research on social media with biomedical dictionaries should be cautious about terms with multiple meanings for more precise analysis.\n\nAnother source of noise in term tagging on social media is the lack of context information. Annotators sometimes found it difficult to determine the true meaning of the words due to this lack of context. Machine-based methods may struggle to accurately tag terms in such ambiguous contexts. Our results show that dictionary refinement via human annotation has a significant impact on downstream data analysis and suggest the importance of this practice in ensuring accurate term tagging.\n\nWe found that the impact of the refined dictionary affected not only the terms removed but also had broader implications on the analysis, such as network analysis. It suggests potential network-based methods for identifying low-quality terms in the dictionary. These low-quality terms could either be ambiguous or inappropriate for inclusion. The structure and connections generated by these terms differ from the majority knowledge structure, indicating possible approaches for identifying them.\n\nWe also found that different data corpus benefits more from dictionary refinement than others, suggesting the need for dictionary refinement tailored to each individual research topic and data corpus. The Instagram posts' manual annotation suggests that a similar approach could be useful for refining dictionaries specific to other platforms like EF forums, PubMed abstracts, Clinical Trials, and Twitter. The variation in ambiguous terms across datasets could be due to the inherent differences in language usage and richness levels between social media, online health communities, and medical resources.\n\nIn Section 3, we have shown that GPT-4 could not replace human annotators in this task. GPT-4 often stayed within the narrow definitions of terms according to guidelines. Human annotators, however, could interpret terms in broader contexts and understand why certain terms were included or excluded, labeling them appropriately. GPT-3.5 exhibited more bias than GPT-4, further emphasizing the need for human involvement.\n\nEven with current LLMs, their operational costs prohibit large-scale applications. Nonetheless, the evolving field of LLM research holds potential for enhanced term tagging and dictionary refinement, potentially leading to better data coverage and improved analysis outcomes. In the future, hybrid approaches or more advanced LLMs could be used to refine dictionaries and analyze social media data with greater accuracy and efficiency."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "This research identified the terms in our dictionaries with higher frequencies in an epilepsy cohort on Instagram by using the human annotation method. On comparison, GPT series models cannot replace human annotation in the annotation process. We also identified which terms should be removed from our dictionary to obtain more epilepsy-relevant results from network analysis. Additionally, we identify the fundamental cause of incorrect term matches\u2014having different meanings that are often used\u2014and specific cases. Finally, through validation of the impact of the refined dictionary on eigenvector centrality analysis of the co-mention networks, we demonstrated the impacts and complementary role of the human annotation method to the automated annotation technique. Our results demonstrate that human-centered dictionary refinement should be performed when conducting social media mining of biomedical relevance, and epilepsy in particular. It remains to be determined if this approach is also necessary for analyzing other types of scientific or patient-centered textual resources. Our study has utilized a large number of terms in medical dictionaries and focused on Instagram, which may have significant potentials for large-scale social media analysis. Other social media studies on medical corpus have more focused on Twitter and Facebook, and most of them have selected a few specific medical terms in their analyses. Our results and implications may help future research in our research communities, including the areas of bioinformatics and health informatics, by improving analysis of medical topics on social media speeches. Ultimately, this research would contribute to developing knowledge graphs that more truthfully represent the underlying knowledge structure, which can be used for personalized information systems that can support PWE, PWEC. And the workflow could also be applied to other diseases and support other disease cohorts."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Acknowledgement",
            "text": "This work was partially funded by National Institutes of Health, National Library of Medicine Program, grant 01LM011945-01 (LMR, AM, XW, RBC, and WRM), a Fulbright Commission fellowship (LMR), the NSF-NRT grant 1735095 \u201cInterdisciplinary Training in Complex Networks and Systems\u201d (LMR, AM, XW and RBC), and Funda\u00e7\u00e3o para a Ci\u00eancia e a Tecnologia, grant PTDC-MEC-AND-30221-2017 (RBC)\nThe funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript."
        }
    ],
    "url": "http://arxiv.org/html/2405.08784v1",
    "segmentation": {
        "research_background_sections": [
            "1"
        ],
        "methodology_sections": [
            "2.1",
            "2.2"
        ],
        "main_experiment_and_results_sections": [
            "3.1",
            "3.2",
            "3.3"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "3.2",
            "3.3",
            "3.4"
        ]
    },
    "research_context": {
        "paper_id": "2405.08784v1",
        "paper_title": "Refinement of an Epilepsy Dictionary through Human Annotation of Health-related posts on Instagram",
        "research_background": "The paper is motivated by the increasing use and vast potential of social media data for public health research. With a specific focus on Instagram\u2014an immensely popular platform with over 1 billion users as of 2021\u2014the study aims to leverage this medium to gather detailed insights into the experiences and behaviors of people with epilepsy (PWE). While prior research has extensively exploited data from platforms like Twitter and Facebook, Instagram remains underutilized despite its rich data offerings.\n\nThe research problem addressed by this study centers on the inadequacy of existing biomedical dictionaries\u2014originally developed for scientific literature\u2014in capturing the informal and context-specific language used in social media posts relevant to epilepsy. The primary issue is that these dictionaries, when applied to social media, often result in false positives, i.e., clinically relevant terms being used in non-clinically relevant contexts. This leads to inaccurate biomedical knowledge extraction and potentially flawed inferences in automated annotation pipelines.\n\nThe related work highlights several key points:\n1. **Utilization of Social Media for Public Health**: Social media has been employed to track and predict health issues such as mental health disorders, adverse drug reactions (ADR), drug-drug interactions (DDI), and substance abuse.\n2. **Epilepsy on Social Media**: Specific platforms like Facebook and Twitter have been utilized to provide information and correct misconceptions about epilepsy, demonstrating their utility in capturing relevant patient behaviors and outcomes.\n3. **Challenges with Current Biomedical Dictionaries**: Dictionaries developed from scientific discourse often fail when applied to the informal language on social media, creating a need for a more tailored approach.\n\nThe paper builds on prior work by proposing a human-centered approach to refining biomedical dictionaries for epilepsy-specific research on Instagram. In doing so, it aims to address the gaps identified in leveraging social media data effectively to study PWE and ensure more accurate and relevant data annotation, thereby improving the quality of social media-based biomedical research.",
        "methodology": "## Refinement of an Epilepsy Dictionary through Human Annotation of Health-related Posts on Instagram\n\n### Methodology\n\n#### Dictionary Construction\nThe proposed method involves the construction and refinement of an epilepsy dictionary containing terms related to drugs, allergens, medical terms, and natural products, with an emphasis on including terms like cannabis. This dictionary was constructed following methodologies detailed in [15 ###reference_b15###, 29 ###reference_b29###] and was populated with terms sourced from various existing medical ontologies and data sources.\n\nKey sources include:\n- **Drugbank (v.5.1.0)** [30 ###reference_b30###] for drugs, allergens, and food-related terms.\n- **MedDRA (v.15)** [31 ###reference_b31###] for medical terms, including disease symptoms and drug side effects.\n- **MedlinePlus** [32 ###reference_b32###] and **TCMGeneDIT** [33 ###reference_b33###] for natural products.\n- **Cannabis-related terms** were manually added, including common slang such as \u2018Mary Jane\u2019 and \u2018420\u2019, referenced from [15 ###reference_b15###].\n\n#### Inclusion of Epilepsy Terms\nEpilepsy-specific terminology was manually curated by analyzing posts on the Epilepsy.com discussion forums using a C-value tokenizer [34 ###reference_b34###]. Terms such as \u2018VNS\u2019 (Vagus Nerve Stimulator) were identified, validated by an epilepsy specialist, and matched to MedDRA codes.\n\n#### Categorization\nDictionary terms were categorized into four specific groups:\n1. **Allergens**: Food names, ingredients, and animals (e.g., Orange, Duck).\n2. **Drugs**: Medications and chemical compounds (e.g., Diazepam).\n3. **Medical Terms**: Physical, psychological, or physiological conditions (e.g., Headache, Feeling hot).\n4. **Natural Products**: Plants and their extracts (e.g., Rose).\n\nEach term in the dictionary was matched as a child term to a unique parent (preferred) term to handle synonyms efficiently. For example, terms like Weed, Mary Jane, and Cannabis were all synonyms under the parent term Cannabis, with the parent term included as a child term for thorough synonym representation. Similarly, drug names retained their chemical name as the parent term (e.g., Diazepam) and included all known commercial names (e.g., Valium) as child terms, extracted from DrugBank [30 ###reference_b30###].\n\n#### Hierarchical Structure and Synonym Management\nThe dictionary leveraged existing term hierarchies from data sources (e.g., \u201cpreferred term\u201d in MedDRA) as the basis for parent term mapping. This hierarchical structure ensured that the most accurate and relevant terminology was retained and effectively organized.\n\n#### Handling Common Names and False-Positives\nTo mitigate false positives due to drug brand names overlapping with common English language terms (e.g., Nighttime, a synonym for Benadryl), the terms were cross-checked against their expected occurrence in the Brown Corpus [35 ###reference_b35###]. Highly common terms in daily language were ranked and removed from the dictionary.\n\n#### Outcome\nFollowing this rigorous collection and automatic curation process, the resultant dictionary encompassed a total of 176,278 terms, categorized as follows:\n- **Drugs**: 105,345 terms\n- **Medical Terms**: 66,961 terms\n- **Allergens**: 2,797 terms\n- **Natural Products**: 1,175 terms",
        "main_experiment_and_results": "**Main Experiment Setup and Results:**\n\n**Experiment Setup:**\nThe primary goal of the experiment is to refine an epilepsy-related dictionary to improve the accuracy of term matches in biomedical social media analytics, specifically on Instagram. The challenge addressed is that terms used in social media discourse may have alternate meanings not relevant to their clinical context. To achieve this, a manual annotation workflow was implemented to identify false positives among dictionary terms used in Instagram posts about epilepsy.\n\n**Datasets:**\n- The dataset comprises over 8 million Instagram posts initially, but due to the impracticality of manually annotating all, a sample was taken.\n- The sample includes 1,771 posts containing at least one matched term, resulting in 2,947 matches linked to 466 unique parent terms.\n- Breakdown of matches per dictionary category: \n  - 874 matches (29.7%; 108 parent terms)\n  - 204 matches (6.9%; 64 parent terms)\n  - 1,647 matches (55.9%; 268 parent terms)\n  - 222 matches (7.5%; 26 parent terms)\n\n**Annotation Workflow:**\n1. **Initial Annotation & Guideline Refinement:**\n   - A subset of 292 posts with 499 dictionary matches was used to test the annotation process and refine guidelines.\n   - The guidelines helped annotators decide if a matched term was used in its intended biomedical dictionary sense (true-positive) or not (false-positive).\n   - Each sampled post was assigned to two annotators for review, and discrepancies were discussed to revise the guidelines accordingly.\n\n2. **Full Annotation Review:**\n   - Using the refined guidelines, the remaining 1,771 posts and their 2,947 matches were reviewed by two annotators independently.\n   - Annotators included data scientists in training and epilepsy researchers.\n   - Annotations were categorized as true-positive, false-positive, or unclear.\n   - The process achieved good inter-rater reliability, indicated by a Cohen\u2019s Kappa of 0.634.\n\n**Evaluation Metrics:**\n- Inter-rater reliability was evaluated using Cohen\u2019s Kappa, with a result of 0.634, showcasing substantial agreement between annotators.\n\n**Main Experimental Results:**\n- The annotation workflow refined the original epilepsy-related dictionary by identifying terms that were frequently matched incorrectly in the context of Instagram posts.\n- This refinement aims to reduce false positive term matches in biomedical social media analytics.\n- The specific numbers showing the distribution of matches across various dictionary categories highlight the prevalence of false positives in social media discourse.\n\nOverall, this manual annotation workflow, involving both initial guideline refinement and full post review, provided a systematic approach to enhancing the contextual accuracy of biomedical dictionaries used in analyzing social media content."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To refine a biomedical dictionary by identifying and removing imprecise health-related terms used ambiguously in social media posts, particularly focusing on posts related to epilepsy on Instagram.",
            "experiment_process": "Following a full review of human-centered annotations, 839 false-positive term matches were found, representing 28.5% of cases. Annotators identified ambiguous terms such as 'Orange' (used for color), 'Rose' (typo for 'ros\u00e9'), and 'Valium' (used metaphorically). False-positive rates were calculated for four term categories: allergen (19%), drug (17%), medical term (35%), and natural product (30%). Terms with high false-positive rates were then plotted against their frequency, with the most problematic terms identified and slated for removal. A criterion based on maximizing false-positive rates and frequency was established, leading to the removal of 8 terms: Hot, Cold, Euphoria, Valium, Rose, Orange, Ginger, and Death.",
            "result_discussion": "Removing these terms significantly reduced the ambiguity in the dictionary, as evidenced by a drop in false-positive matches. Terms with high false-positive rates, such as 'Euphoria' and 'Hot', often lacked medical significance within the social media context. The refined dictionary improved the relevance of terms, presenting a more accurate mapping to epilepsy discourse.",
            "ablation_id": "2405.08784v1.No1"
        },
        {
            "research_objective": "To evaluate the impact of removing ambiguous terms on the eigenvector centrality of associative knowledge networks built from social media posts mentioning epilepsy.",
            "experiment_process": "Eigenvector centrality, which measures node importance based on indirect influence in undirected graphs, was chosen to quantify the impact of term removal. Co-mention networks of dictionary terms were created from social media posts. Top terms by eigenvector centrality were listed before and after the removal of ambiguous terms. A null model experiment was also conducted, where 8 frequent but less ambiguous terms were randomly removed 1,000 times to compare the impact with the removal of human-annotated ambiguous terms. Metric comparisons included common elements ratio (CER) and Fagin\u2019s generalized Kendall\u2019s distance.",
            "result_discussion": "Removing the 8 ambiguous terms led to a substantial shift in the network, with top centrality terms becoming more relevant to epilepsy (e.g., Depression and Anxiety). The refined dictionary had a greater impact on eigenvector centrality compared to random removals, indicating that human-analyzed ambiguous terms disrupt the biomedical knowledge network more significantly. The null model supported this finding, as random high-frequency term removal had less impact, affirming the significance of the refined dictionary.",
            "ablation_id": "2405.08784v1.No2"
        },
        {
            "research_objective": "To compare the discourse of general-purpose social media platforms like Instagram and Twitter with scientific and focused medical platforms regarding the impact of removing ambiguous terms.",
            "experiment_process": "Both original and refined dictionaries were applied to data from Instagram, Twitter, PubMed epilepsy-related abstracts, clinicaltrials.gov epilepsy clinical trials, and Epilepsy.com forums. The impact of term removal was assessed on the knowledge networks of each data source using Fagin's generalized Kendall\u2019s distance, quantifying changes in top terms ranked by eigenvector centrality after term removal. Data harvesting and network construction details were provided in supplementary sections.",
            "result_discussion": "General-purpose social media like Instagram and Twitter showed significant impact from term removal, indicating high noise levels in biomedical relevance. In contrast, scientific databases and specialized forums had minimal impact, suggesting more focused and relevant discourse. This highlights the necessity of human-centered annotation for refining biomedical dictionaries used in general-purpose social media mining.",
            "ablation_id": "2405.08784v1.No3"
        }
    ]
}