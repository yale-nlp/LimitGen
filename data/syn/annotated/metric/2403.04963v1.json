{
    "title": "An In-depth Evaluation of GPT-4 in Sentence Simplification with Error-based Human Assessment",
    "abstract": "Sentence simplification, which rewrites a sentence to be easier to read and understand, is a promising technique to help people with various reading difficulties. With the rise of advanced large language models (LLMs), evaluating their performance in sentence simplification has become imperative. Recent studies have used both automatic metrics and human evaluations to assess the simplification abilities of LLMs.\n\nHowever, the suitability of existing evaluation methodologies for LLMs remains in question. First, the suitability of current automatic metrics on LLMs\u2019 simplification evaluation is still uncertain. Second, current human evaluation approaches in sentence simplification often fall into two extremes: they are either too superficial, failing to offer a clear understanding of the models\u2019 performance, or overly detailed, making the annotation process complex and prone to inconsistency, which in turn affects the evaluation\u2019s reliability.\n\nTo address these problems, this study provides in-depth insights into LLMs\u2019 performance while ensuring the reliability of the evaluation. We design an error-based human annotation framework to assess the GPT-4\u2019s simplification capabilities. Results show that GPT-4 generally generates fewer erroneous simplification outputs compared to the current state-of-the-art. However, LLMs have their limitations, as seen in GPT-4\u2019s struggles with lexical paraphrasing.\n\nFurthermore, we conduct meta-evaluations on widely used automatic metrics using our human annotations. We find that while these metrics are effective for significant quality differences, they lack sufficient sensitivity to assess the overall high-quality simplification by GPT-4.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1. Introduction",
            "text": "Sentence simplification automatically rewrites sentences to make them easier to read and understand by modifying their wording and structures, without changing their meanings. It helps people with reading difficulties, such as non-native speakers (Paetzold, 2016), individuals with aphasia (Carroll et al., 1999), dyslexia (Rello et al., 2013b, a), or autism (Barbu et al., 2015). Previous studies often employed a sequence-to-sequence model, then have been enhanced by integrating various sub-modules into it (Zhang and Lapata, 2017; Zhao et al., 2018; Nishihara et al., 2019; Martin et al., 2020). Recent developments have seen the rise of large language models (LLMs). Notably, the ChatGPT families released by OpenAI demonstrate exceptional general and task-specific abilities (OpenAI, 2023; Wang et al., 2023; Liu et al., 2023), and sentence simplification is not an exception. Some studies (Feng et al., 2023; Kew et al., 2023) have begun to evaluate LLMs\u2019 performance in sentence simplification, including both automatic scoring and conventional human evaluations where annotators assess the levels of fluency, meaning preservation, and simplicity (Kriz et al., 2019; Jiang et al., 2020; Alva-Manchego et al., 2021; Maddela et al., 2021), or identify common edit operations (Alva-Manchego et al., 2017). However, these studies face limitations and challenges. Firstly, it is unclear whether the current automatic metrics are suitable for evaluating simplification abilities of LLMs. Although these metrics have demonstrated variable effectiveness across conventional systems (e.g., rule-based (Sulem et al., 2018b), statistical machine translation-based (Wubben et al., 2012; Xu et al., 2016), and sequence-to-sequence model-based simplification (Zhang and Lapata, 2017; Martin et al., 2020)) through their correlation with human evaluations (Alva-Manchego et al., 2021), their suitability for LLMs has yet to be explored, thereby their effectiveness in assessing LLMs\u2019 simplifications are uncertain. Secondly, given the general high performance of LLMs, conventional human evaluations may be too superficial to capture the subtle yet critical aspects of simplification quality. This lack of depth undermines the interpretability when evaluating on LLMs. Recently, Heineman et al. (Heineman et al., 2023) proposed a detailed human evaluation framework for LLMs, categorizing linguistically based success and failure types. However, their linguistics-based approach appears to be excessively intricate and complex, resulted in low consistency among annotators, thus raising concerns about the reliability of the evaluation. The trade-off between interpretability and reliability underscores the necessity for a more balanced approach. Our goal is to make a clear understanding of LLMs\u2019 performance on sentence simplification, and to reveal whether current automatic metrics are genuinely effective for evaluating LLMs\u2019 simplification ability. We design an error-based human evaluation framework to identify key failures in important aspects of sentence simplification, such as inadvertently increasing complexity or altering the original meaning. Our approach aligns closely with human intuition by focusing on outcome-based assessments rather than linguistic details. This straightforward approach makes the annotation easy without necessitating a background in linguistics. Additionally, we conduct a meta-evaluation of automatic evaluation metrics to examine their effectiveness in measuring the simplification abilities of LLMs by utilizing data from human evaluations. We applied our error-based human evaluation framework to evaluate the performance of GPT-4 in English sentence simplification, using prompt engineering on three representative datasets on sentence simplification: Turk (Xu et al., 2016), ASSET (Alva-Manchego et al., 2020), and Newsela (Xu et al., 2015). The results indicate that GPT-4 generally surpasses the previous state-of-the-art (SOTA) in performance; GPT-4 tends to generate fewer erroneous simplification outputs and better preserve the original meaning, while maintaining comparable levels of fluency and simplicity. However, LLMs have their limitations, as seen in GPT-4\u2019s struggles with lexical paraphrasing. The meta-evaluation results show that existing automatic metrics face difficulties in assessing simplification generated by GPT-4. That is, these metrics are able to differentiate significant quality differences but not sensitive enough for overall high-quality simplification outputs."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2. Related Work",
            "text": "Our study evaluates the performance of the advanced LLM, namely GPT-4, in sentence simplification by comparing it against the SOTA supervised simplification model. This section includes a review of current evaluations of LLMs in this domain, along with an overview of the SOTA supervised simplification models."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1. Evaluation of LLM-based Simplification",
            "text": "In sentence simplification, some studies attempted to assess the performance of LLMs. For example, Feng et al. (Feng et al., 2023) evaluated the performance of prompting ChatGPT and GPT-3.5, later Kew et al. (Kew et al., 2023) compared LLMs varying in size, architecture, pre-training methods, and with or without instruction tuning. Additionally, Heineman et al. (Heineman et al., 2023) proposed a detailed human evaluation framework for LLMs, categorizing 21 linguistically based success and failure types. Their findings indicate that OpenAI\u2019s LLMs generally surpass the previous SOTA supervised simplification models.\n\nHowever, these studies have three primary limitations. First, there has not been a comprehensive exploration into the capabilities of the most advanced ChatGPT model to date, i.e., GPT-4. Second, these studies do not adequately explore prompt variation, employing uniform prompts with few-shot examples across datasets without considering their unique features in simplification strategies. This may underutilize the potential of LLMs, which are known to be prompt-sensitive. Third, the human evaluations conducted are inadequate. Such evaluations are crucial, as automatic metrics often have blind spots and may not always be entirely reliable (He et al., 2023). Human evaluations in these studies often rely on shallow ratings or edit operation identifications to evaluate a narrow range of simplification outputs. These methods risk being superficial, overlooking intricate features. In contrast, Heineman et al.\u2019s linguistics-based approach (Heineman et al., 2023) appears to be excessively intricate and complex, resulting in low consistency among annotators, thus raising concerns about the reliability of the evaluations.\n\nOur study aims to bridge these gaps, significantly enhancing the utility of ChatGPT models through comprehensive prompt engineering processes, and incorporating elaborate human evaluations while ensuring reliability."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2. SOTA Supervised Simplification Models",
            "text": "Traditional NLP methods heavily relied on task-specific models, which involve adapting pre-trained language models for various downstream applications. In sentence simplification, Martin et al. (2022) introduced the MUSS model by fine-tuning BART with labeled sentence simplification datasets and/or mined paraphrases. Similarly, Sheang et al. (2021) fine-tuned T5, referred to as Control-T5 in this study, achieving state-of-the-art performance on two representative datasets: Turk and ASSET. These models leverage control tokens, initially introduced by ACCESS, to modulate attributes like length, lexical complexity, and syntactic complexity during simplification. This approach allows any sequence-to-sequence model to adjust these attributes by conditioning on simplification-specific tokens, facilitating strategies that aim to shorten sentences or reduce their lexical and syntactic complexity. Our study employs Control-T5 as a state-of-the-art model and compares it to GPT-4 in sentence simplification."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3. Datasets",
            "text": "In this study, we employed standard datasets for English sentence simplification, as detailed below. For replicating the SOTA supervised model, namely, Control-T5, we used the same training datasets as the original paper. Meanwhile, the evaluation datasets were used to assess the performance of our models."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1. Training Datasets",
            "text": "We utilized training sets from two datasets: WikiLarge (Zhang and Lapata, 2017 ###reference_b47###) and Newsela (Xu et al., 2015 ###reference_b44###; Zhang and Lapata, 2017 ###reference_b47###). WikiLarge consists of complex-simple sentence pairs automatically extracted from English Wikipedia and Simple English Wikipedia by sentence alignment. Introduced by Xu et al. (Xu et al., 2015 ###reference_b44###), Newsela originates from a collection of news articles accompanied by simplified versions written by professional editors. It was subsequently aligned from article-level to sentence-level, resulting in approximately complex-simple sentence pairs. In our study, we utilize the training split of the Newsela dataset made by Zhang and Lapata (Zhang and Lapata, 2017 ###reference_b47###)."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2. Evaluation Datasets",
            "text": "We used validation and test sets from the three standard datasets on English sentence simplification. These validation sets were used for prompt engineering on GPT-4. Table 1 shows the numbers of complex-simple sentence pairs in these sets. These datasets have distinctive features due to differences in simplification strategies as summarized below.\n\nTurk (Xu et al., 2016): This dataset comprises sentences from English Wikipedia, each paired with eight simplified references written by crowd-workers. It is created primarily focusing on lexical paraphrasing.\n\nASSET (Alva-Manchego et al., 2020): This dataset uses the same source sentences as the Turk dataset. It differs from Turk by aiming at rewriting sentences with more diverse transformations, i.e., paraphrasing, deleting phrases, and splitting a sentence, and provides simplified references written by crowd-workers.\n\nNewsela (Xu et al., 2015; Zhang and Lapata, 2017): This is the same Newsela dataset described in Section 3.1. We utilized its validation and test splits, totaling sentence pairs. After careful observation, we found that deletions of words, phrases, and clauses predominantly characterize the Newsela dataset."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4. Models",
            "text": "To enhance the performance of GPT-4 in sentence simplification, we undertook extensive prompt engineering effort. We also replicated the SOTA supervised model, Control-T5, for comparative analysis with GPT-4. Throughout our optimization efforts, we conducted various evaluations and analyses. Our meta-evaluation confirms alignment with human evaluation for the simplification tasks."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1. GPT-4 with Prompt Engineering",
            "text": "Scaling pre-trained language models, such as increasing model and data size, LLMs enhance their capacity for downstream tasks. Unlike earlier models that required fine-tuning, these LLMs can be effectively prompted with zero- or few-shot examples for task-solving."
        },
        {
            "section_id": "4.1.1",
            "parent_section_id": "4.1",
            "section_name": "4.1.1. Design",
            "text": "Aiming to optimize GPT-4\u2019s sentence simplification capabilities, we conducted prompt engineering based on three principal components:\n\nDataset-Specific Instructions: We tailored instructions to each dataset\u2019s unique features and objectives, as detailed in Section 3.2. For the Turk and ASSET datasets, we created instructions referring to the guidelines provided to the crowd-workers who composed the references. In the case of Newsela, where such guidelines are unavailable, we created instructions following the styles used for Turk and ASSET, with an emphasis on deletion. Refer to the Appendix A.1 for detailed instructions.\n\nVaried Number of Examples: We varied the number of examples to attach to the instructions: zero, one, and three.\n\nVaried Number of References: We experimented with single or multiple (namely, three) simplification references used in the examples. For Turk and ASSET, which are multi-reference datasets, we manually selected one high-quality reference from their multiple references. Newsela, which is basically a single-reference dataset, offers multiple simplification levels for the same source sentences. For this dataset, we extracted references targeting different simplicity levels of the same source sentence as multiple references.\n\nWe integrated these components into prompts, resulting in the creation of variations (Figure 1). These prompts were then applied to each validation set, excluding selected examples. Following this, we used the best prompts to generate simplification outputs from the respective test sets."
        },
        {
            "section_id": "4.1.2",
            "parent_section_id": "4.1",
            "section_name": "4.1.2. Effect of Prompt Engineering",
            "text": "Prompt engineering demonstrates its effectiveness. As shown in Table 2, across three validation sets, there is a significant performance difference between prompts with the highest and lowest scores, achieving top results for Turk, ASSET, and Newsela. Moreover, results reveal a direct alignment between the best prompt\u2019s instructional style and its respective dataset. These top-performing prompts all use a few-shot examples of three.\n\nThe optimal number of simplification references varies; Turk and ASSET show strong results with a single reference, whereas Newsela benefits from multiple references, likely due to the intricacies involved in ensuring meaning is preserved amidst deletions.\n\nOverall, prompt engineering notably enhances GPT-4\u2019s sentence simplification output."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2. Replicated Control-T5",
            "text": "We replicated the Control-T5 model (Sheang and Saggion, 2021). We started by fine-tuning the T5-base model (Raffel et al., 2020) with the WikiLarge dataset and then evaluated it on the ASSET and Turk\u2019s test sets. Unlike the original study, which did not train on or evaluate on Newsela, we incorporated this dataset. We employed Optuna (Akiba et al., 2019) for hyperparameter optimization, a method consistent with the approach used in the original study with the WikiLarge dataset. This optimization process focused on adjusting the batch size, the number of epochs, the learning rate, and the control token ratios. We refer the reader to Appendix A.2 for the optimal model configuration we achieved."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5. Human Evaluation",
            "text": "Automatic metrics provide a fast and cost-effective way for evaluating simplification but struggle to cover all the aspects; they are designed to capture only specific aspects such as the similarity between the output and a reference. Furthermore, the effectiveness of some automatic metrics has been challenged in previous studies (Sulem et al., 2018a  ###reference_b38###; Alva-Manchego et al., 2021  ###reference_b6###). Human evaluation, which is often viewed as the gold standard evaluation, may be a more reliable method to determine the quality of simplification.\nAs we discuss in detail in the following section, achieving a balance between interpretability and consistency among annotators is a challenge in sentence simplification. To address this challenge, we have crafted an error-based approach and made efforts in the annotation process such as mandating discussions among annotators to achieve consensus and implementing strict checks to ensure the quality of assessments.\nAs annotators, we used second-language learners with advanced English proficiency expecting that they are more sensitive to variations in textual difficulty based on their language-learning experiences.\nIn addition, given that second language learners stand to benefit significantly from sentence simplification applications, involving them as evaluators seems most appropriate.\nAll of our annotators were graduate students associated with our organization. The compensation rate for this task was set at   JPY (approximately $ USD) per sentence pair.\nFor quality control, annotators had to pass a qualification test before participating in the task. This qualification test comprises annotation guidelines and four complex-simple sentence pairs. Each pair contains various errors predefined by the author. All submissions to this test were manually reviewed. Three annotators were selected for this task based on their high accuracy in identifying errors, including specifying the error type, location, and rationale.\nSame with Task , we employed second-language learners with advanced English proficiency, who were graduate students associated with our organization.\nAnnotator candidates had to pass a qualification test before participating in the task. This qualification test comprises annotation guidelines and five complex-simple sentence pairs. Candidates were instructed to rate fluency, meaning preservation, and simplicity on each simplification output. Three annotators were selected based on their high inter-annotator agreement, demonstrated by the Intraclass Correlation Coefficient (ICC) (Shrout and Fleiss, 1979  ###reference_b37###) score of , indicating a substantial agreement.\nThe compensation rate for this task was set at   JPY (approximately $ USD) per sentence pair.\nWe assessed inner-annotator agreement through the overlapping rate of ratings across three annotators, as detailed in Table 4  ###reference_###. The overlapping rate was calculated by the proportion of identical ratings for a given simplification output.555We also tried Fleiss\u2019 kappa, Krippendorff\u2019s alpha, and ICC; however, they resulted in degenerate scores due to too-high agreements on mostly binary judgments. In the fluency dimension, both models demonstrate strong agreement, with overlapping rates between  and . In meaning preservation and simplicity, these dimensions exhibit comparably more variability in ratings, with a broader range of agreement. Annotators found it more subjective to assess meaning preservation and simplicity, as these aspects required direct comparison with the source sentences. Nevertheless, mid to high agreement levels were still achieved, showing the consistency of our annotation."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "5.1. Our approach: Error-based Human Evaluation",
            "text": ""
        },
        {
            "section_id": "5.1.1",
            "parent_section_id": "5.1",
            "section_name": "5.1.1. Challenge in Current Human Evaluation",
            "text": "Sentence simplification is expected to make the original sentence simpler while maintaining grammatical integrity and not losing important information. A common human assessment approach involves rating sentence-level automatic simplification outputs by comparing them to source sentences in three aspects: fluency, meaning preservation, and simplicity (Kriz et al., 2019  ###reference_b19###; Jiang et al., 2020  ###reference_b16###; Alva-Manchego et al., 2021  ###reference_b6###; Maddela et al., 2021  ###reference_b24###). However, sentence simplification involves various transformations, such as paraphrasing, deletion, and splitting, which affect both the lexical and structural aspects of a sentence. Sentence-level scores are difficult to interpret; they do not clearly indicate whether the transformations simplify or complicate the original sentence, maintain or alter the original meaning, or are necessary or unnecessary. Therefore, such evaluation approach falls short in comprehensively assessing the models\u2019 capabilities.\nThis inadequacy has led to a demand for more detailed and nuanced human assessment methods. Recently, the SALSA framework, introduced by Heineman et al. (Heineman et al., 2023  ###reference_b15###) aimed to provide clearer insights through comprehensive human evaluation, consider both the successes and failures of a simplification system. This framework categorizes transformations into  linguistically-grounded\nedit types across conceptual, syntactic, and lexical dimensions to facilitate detailed evaluation. However, due to the detailed categorization, it faces challenges in ensuring consistent interpretations across annotators. This inconsistency frequently leads to low inter-annotator agreement, thereby undermining the reliability of the evaluation. We argue that such extensive and fine-grained classifications are difficult for annotators to understand, particularly those without a linguistic background, making it challenging for them to keep consistency."
        },
        {
            "section_id": "5.1.2",
            "parent_section_id": "5.1",
            "section_name": "5.1.2. Error-based Human Evaluation",
            "text": "To overcome the trade-off between interpretability and consistency in evaluations, we design our error-based human evaluation framework. Our approach focuses on identifying and evaluating key failures generated by advanced LLMs in important aspects of sentence simplification. We aim to cover a broad range of potential failures while making the classification easy for annotators. Our approach reduces the categories to seven types while ensuring comprehensive coverage of common failures. In the study on sentence simplification evaluation of LLMs conducted by Kew et al. (Kew et al., 2023  ###reference_b17###), while the annotation of common failures is also incorporated, it is noteworthy that the types of failures addressed are very limited and they selected only a handful of output samples for annotation.\nWhile not intended for LLM-based simplification, a few previous studies have incorporated error analysis to assess their sequence-to-sequence simplification models (Kriz et al., 2019  ###reference_b19###; Cooper and Shardlow, 2020  ###reference_b9###; Maddela et al., 2021  ###reference_b24###).\nStarting from the error types established in these studies, we included ones that might also applicable in the outputs of advanced LLMs.\nSpecifically, we conducted a preliminary investigation on ChatGPT-3.5 simplification outputs on the ASSET dataset.444At the time of this investigation, GPT-4 was not publicly available.\nAs a result, we adopted errors of Altered Meaning, issues with Coreference, Repetition, and Hallucination, while omitted errors deemed unlikely, such as the ungrammatical error.\nAdditionally, we identified a new category of error based on our investigation: Lack of Simplicity.\nWe observed that ChatGPT-3.5 often opted for more complex expressions rather than simpler ones, which is counterproductive for sentence simplification. Recognizing this as a significant issue, we included it in our error types. We also refined the categories for altered meaning and lack of simplicity by looking into the specific types of changes they involve. Instead of listing numerous transformations like the SALSA framework (Heineman et al., 2023  ###reference_b15###), we classified these transformations into two simple categories based on their effects on the source sentence: lexical and structural changes. This categorization leads to four error types: Lack of Simplicity-Lexical, Lack of Simplicity-Structural, Altered Meaning-Lexical, and Altered Meaning-Structural.\nTable 3  ###reference_### summarizes the definition and examples of our target errors.\nOur approach is designed to align closely with human intuition by focusing on outcome-based assessments rather than linguistic details. Annotators evaluate whether the transformation simplifies and keeps the meaning of source components, preserves named entities accurately, and avoids repetition or irrelevant content. This methodology facilitates straightforward classification without necessitating a background in linguistics.\nThe simplified sentence uses more intricate lexical expression(s) to replace part(s) of the original sentence.\nFor Rowling, this scene is important because it shows Harry\u2019s bravery\u2026\nRowling considers the scene significant because it portrays Harry\u2019s courage\u2026\nThe simplified sentence modifies the grammatical structure, and it increases the difficulty of reading.\nThe other incorporated cities on the Palos Verdes Peninsula include\u2026\nOther cities on the Palos Verdes Peninsula include\u2026, which are also incorporated.\nSignificant deviation in the meaning of the original sentence due to lexical substitution(s).\nThe Britannica was primarily a Scottish enterprise.\nThe Britannica was mainly a Scottish endeavor.\nSignificant deviation in the meaning of the original sentence due to structural changes.\nGimnasia hired first famed Colombian trainer Francisco Maturana, and then Julio C\u00e9sar Falcioni.\nGimnasia hired two famous Colombian trainers, Francisco Maturana and Julio C\u00e9sar Falcioni.\nA named entity critical to understanding the main idea is replaced with a pronoun or a vague description.\nSea slugs dubbed sacoglossans are some of the most\u2026\nThese are some of the most\u2026\nUnnecessary duplication of sentence fragments\nThe report emphasizes the importance of sustainable practices.\nThe report emphasizes the importance, the significance, and the necessity of sustainable practices.\nInclusion of incorrect or unrelated information not present in the original sentence.\nIn a short video promoting the charity Equality Now, Joss Whedon confirmed that \u201dFray is not done, Fray is coming back.\nJoss Whedon confirmed in a short promotional video for the charity Equality Now that Fray will return, although the story is not yet finished."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "5.2. Annotation Process",
            "text": "###figure_2### We implemented our error-based human evaluation alongside the common evaluation on fluency, meaning preservation, and simplicity using a 1-3 Likert scale. The Potato Platform (Pei et al., 2022  ###reference_b32###) was utilized to establish our annotation environment for the execution of both tasks. The annotation interface for Task  is illustrated in Figure 2  ###reference_###.\nAnnotators select the error type, marking erroneous spans in the simplified sentence and, when applicable, the corresponding spans in the original (source) sentence. Note that the spans of different error types can overlap each other.\nEach annotator received individual training through a -hour tutorial, which covered guidelines and instructions on how to use the annotation platform. Our error-based human evaluations include guidelines that define and provide examples of each error type, as outlined in Table 3  ###reference_###. Additionally, detailed guidelines for Likert scale evaluation can be found in the Appendix B  ###reference_###.\nAs annotators, we used second-language learners with advanced English proficiency expecting that they are more sensitive to variations in textual difficulty based on their language-learning experiences.\nIn addition, given that second language learners stand to benefit significantly from sentence simplification applications, involving them as evaluators seems most appropriate.\nAll of our annotators were graduate students associated with our organization. The compensation rate for this task was set at   JPY (approximately $ USD) per sentence pair.\nFor quality control, annotators had to pass a qualification test before participating in the task. This qualification test comprises annotation guidelines and four complex-simple sentence pairs. Each pair contains various errors predefined by the author. All submissions to this test were manually reviewed. Three annotators were selected for this task based on their high accuracy in identifying errors, including specifying the error type, location, and rationale.\nSame with Task , we employed second-language learners with advanced English proficiency, who were graduate students associated with our organization.\nAnnotator candidates had to pass a qualification test before participating in the task. This qualification test comprises annotation guidelines and five complex-simple sentence pairs. Candidates were instructed to rate fluency, meaning preservation, and simplicity on each simplification output. Three annotators were selected based on their high inter-annotator agreement, demonstrated by the Intraclass Correlation Coefficient (ICC) (Shrout and Fleiss, 1979  ###reference_b37###  ###reference_b37###) score of , indicating a substantial agreement.\nThe compensation rate for this task was set at   JPY (approximately $ USD) per sentence pair.\nWe assessed inner-annotator agreement through the overlapping rate of ratings across three annotators, as detailed in Table 4  ###reference_###  ###reference_###. The overlapping rate was calculated by the proportion of identical ratings for a given simplification output.555We also tried Fleiss\u2019 kappa, Krippendorff\u2019s alpha, and ICC; however, they resulted in degenerate scores due to too-high agreements on mostly binary judgments. In the fluency dimension, both models demonstrate strong agreement, with overlapping rates between  and . In meaning preservation and simplicity, these dimensions exhibit comparably more variability in ratings, with a broader range of agreement. Annotators found it more subjective to assess meaning preservation and simplicity, as these aspects required direct comparison with the source sentences. Nevertheless, mid to high agreement levels were still achieved, showing the consistency of our annotation."
        },
        {
            "section_id": "5.2.1",
            "parent_section_id": "5.2",
            "section_name": "5.2.1. Task : Error Identification",
            "text": "Task  follows our error-based human evaluation detailed in Section 5.1  ###reference_###. We sampled  source sentences from Turk, ASSET, and Newsela test sets, along with simplification outputs generated by GPT-4 and Control-T5, resulting in a total of  complex-simple sentence pairs. The annotation period spanned from October  to February .\nAnnotators were instructed to identify and label errors within each sentence pair according to predefined guidelines. To overcome the trade-off between detailed granularity and annotator agreement, all annotators involved in this task participated in discussion sessions led by one of the authors. These sessions required annotators to share their individual labelings, which were then collectively reviewed during discussions until reaching the consensus.\nThere were eight discussion sessions, each lasting approximately three hours, for a total of  hours.\nAs annotators, we used second-language learners with advanced English proficiency expecting that they are more sensitive to variations in textual difficulty based on their language-learning experiences.\nIn addition, given that second language learners stand to benefit significantly from sentence simplification applications, involving them as evaluators seems most appropriate.\nAll of our annotators were graduate students associated with our organization. The compensation rate for this task was set at   JPY (approximately $ USD) per sentence pair.\nFor quality control, annotators had to pass a qualification test before participating in the task. This qualification test comprises annotation guidelines and four complex-simple sentence pairs. Each pair contains various errors predefined by the author. All submissions to this test were manually reviewed. Three annotators were selected for this task based on their high accuracy in identifying errors, including specifying the error type, location, and rationale."
        },
        {
            "section_id": "5.2.2",
            "parent_section_id": "5.2",
            "section_name": "5.2.2. Task : Likert Scale Rating",
            "text": "Following the convention of previous studies, we also include the rating approach on fluency, meaning preservation, and simplicity using a 1 to 3 Likert scale as Task . In this task, annotators evaluate all simplification outputs generated by GPT-4 and Control-T5 across three test sets, by comparing them with their corresponding source sentences. In particular, for the Newsela dataset, reference simplifications from the test set were also included. We assume that models trained or tuned on this dataset which is characterized by deletion, may produce shorter outputs, potentially impacting meaning preservation scores. To ensure fairness, we compare human evaluation of model-generated simplifications against that of Newsela reference simplifications for a more objective evaluation. The evaluation in Task  covered a total of  complex-simple sentence pairs.\nThe annotation period spanned from October  to February .\nTo address the challenge of annotator consistency, we implemented specific guidelines during the annotation phase. Annotators were advised to avoid neutral positions (\u20182\u2019 on our scale) unless faced with genuinely challenging decisions. This approach encouraged a tendency towards binary choices, i.e., \u20181\u2019 for simplification outputs that are disfluent, lose a lot of original meaning, or are not simpler, and \u20183\u2019 for simplification outputs that are fluent, preserve meaning, and are much simpler.\nTo ensure quality, one of the authors reviewed  pairs of sampled submissions from each annotator. If any issues were identified, such as an annotator rate inconsistently for sentence pairs with similar problems, they were required to revise and resubmit their annotations.\nSame with Task , we employed second-language learners with advanced English proficiency, who were graduate students associated with our organization.\nAnnotator candidates had to pass a qualification test before participating in the task. This qualification test comprises annotation guidelines and five complex-simple sentence pairs. Candidates were instructed to rate fluency, meaning preservation, and simplicity on each simplification output. Three annotators were selected based on their high inter-annotator agreement, demonstrated by the Intraclass Correlation Coefficient (ICC) (Shrout and Fleiss, 1979  ###reference_b37###  ###reference_b37###  ###reference_b37###) score of , indicating a substantial agreement.\nThe compensation rate for this task was set at   JPY (approximately $ USD) per sentence pair.\nWe assessed inner-annotator agreement through the overlapping rate of ratings across three annotators, as detailed in Table 4  ###reference_###  ###reference_###  ###reference_###. The overlapping rate was calculated by the proportion of identical ratings for a given simplification output.555We also tried Fleiss\u2019 kappa, Krippendorff\u2019s alpha, and ICC; however, they resulted in degenerate scores due to too-high agreements on mostly binary judgments. In the fluency dimension, both models demonstrate strong agreement, with overlapping rates between  and . In meaning preservation and simplicity, these dimensions exhibit comparably more variability in ratings, with a broader range of agreement. Annotators found it more subjective to assess meaning preservation and simplicity, as these aspects required direct comparison with the source sentences. Nevertheless, mid to high agreement levels were still achieved, showing the consistency of our annotation."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6. Annotation Result Analysis",
            "text": "Our comprehensive analysis of annotation data revealed that, overall, GPT-4 generates fewer erroneous simplification outputs compared to Control-T5, demonstrating higher ability in simplification. GPT-4 excels in maintaining the original meaning, whereas Control-T5 often falls short in this dimension. Nevertheless, GPT-4 is not without flaws; its most frequent mistake involves substituting lexical expressions with more complex ones.\nFr\u00e9d\u00e9ric Chopin\u2019s Opus 57 is a berceuse for solo piano.\nFr\u00e9d\u00e9ric Chopin wrote a piece called Opus 57 for solo piano.\nFr\u00e9d\u00e9ric Chopin\u2019s Opus 57 is a lullaby for a single piano.\nThe PAD called for the resignation of the governments of Thaksin Shinawatra, Samak Sundaravej, and Somchai Wongsawat, whom the PAD accused of being proxies for Thaksin.\nThe PAD called for the resignation of the governments of Thaksin Shinawatra, Samak Sundaravej, and Somchai Wongsawat. The PAD said that Thaksin was a friend of the PAD.\nThe PAD asked for the resignation of the governments of Thaksin Shinawatra, Samak Sundaravej and Somchai Wongsawat, whom the PAD accused of being representatives for Thaksin."
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "6.1. Analysis of Task 1: Error Identification",
            "text": "This section presents a comparative analysis of erroneous simplification outputs generated by GPT-4 and Control-T5, focusing on error quantification and type analysis.\nWe assessed erroneous simplification outputs across three datasets: Turk, ASSET, and Newsela, defining an erroneous output as one containing at least one error.\nOverall, Table 5  ###reference_### shows that GPT-4 with fewer errors than Control-T5 across all datasets. This performance difference underscores GPT-4\u2019s superior performance in simplification tasks.\nIn the following, we reveal characteristics of errors in GPT-4 and Control-T5 simplification outputs."
        },
        {
            "section_id": "6.1.1",
            "parent_section_id": "6.1",
            "section_name": "6.1.1. Error Co-occurrence",
            "text": "Multiple types of error may co-occur in a simplification output. Consider the following example where simplification was generated by Control-T5 model:\nCHICAGO \u2013 In less than two months, President Barack Obama is expected to choose the site for his library.\nCHICAGO \u2013 In less than two months, he will choose a new library.\nIn this example, Coreference and Altered Meaning-Lexical errors co-occur. The simplification process replaces President Barack Obama with he, leading to a coreference error. Additionally, the phrase the site for his library is oversimplified to a new library thus altering the original meaning.\nWe found that on average, GPT-4-generated erroneous simplification outputs contained  unique errors, while Control-T5-generated ones contained . This was calculated by dividing the sum of unique errors in each erroneous simplification output by the total number of these simplification outputs. This suggests that erroneous simplification outputs typically include just one error type on both Control-T5 and GPT-4."
        },
        {
            "section_id": "6.1.2",
            "parent_section_id": "6.1",
            "section_name": "6.1.2. Distribution of Same Errors",
            "text": "Section 6.1.1  ###reference_.SSS1### indicates that an erroneous simplification output contains a unique error type on average, then what is the distribution of the same error types in those simplification outputs?\nThe same type of error can occur multiple times within a single simplification output. Consider the following example where the simplification output was generated by GPT-4 model:\nIn 1990, she was the only female entertainer allowed to perform in Saudi Arabia.\nIn 1990, she was the sole woman performer permitted in Saudi Arabia.\nIn this example, Lack of Simplicity-Lexical error appears twice. The simplification uses more difficult words, sole and permitted, to replace only and allowed, respectively.\nWe plotted the label-wise distribution for both models, as illustrated in Figure 3  ###reference_###. This figure shows that in both models, each type of error occurs once in most of the erroneous simplification outputs, and only a small fraction of simplification outputs exhibit the same error type more than once. The maximum repetition of the same error type is capped at three.\n###figure_3###"
        },
        {
            "section_id": "6.1.3",
            "parent_section_id": "6.1",
            "section_name": "6.1.3. Characteristic Errors in Models",
            "text": "We quantitatively assessed the frequency of different error types in simplification outputs generated by GPT-4 and Control-T5. The results, presented in Table 6  ###reference_###, indicate differences in error tendencies between the two models.\nGPT-4\u2019s errors are predominantly from Lack of Simplicity-Lexical ( occurrences) and Altered Meaning-Lexical ( occurrences), showing its propensity to employ complex lexical expressions or misinterpret meanings through lexical choices.\nControl-T5, in contrast, displays a broader range of main error types, with notably higher frequencies in Altered Meaning-Lexical ( occurrences), Coreference ( occurrences), and Hallucination ( occurrences). This suggests difficulties with preserving original lexical meanings, ensuring referential clarity, and avoiding irrelevant information for Control-T5.\nOn both models, the occurrences of errors in lexical aspect (Lack of Simplicity-Lexical, Altered Meaning-Lexical, Coreference, Repetition) surpass the occurrences of errors in structural aspect (Lack of Simplicity-Structural, Altered Meaning-Structural) as a general tendency.\nFurther analysis on Newsela suggests dataset-specific challenges. In comparison to results on Turk and ASSET, Control-T5 generated significantly more Coreference errors than GPT-4. After a manual inspection, we found that a possible reason is the high occurrence of coreference within this dataset and Control-T5 tends to overfit during fine-tuning."
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "6.2. Likert Scale Rating",
            "text": "In this section, we compared model performances across various dimensions and datasets by averaging annotators\u2019 ratings summarized in Table 7  ###reference_###.\nAs a general tendency, GPT-4 again consistently outperforms Control-T5 across all datasets, indicating a preference among annotators for the GPT-4\u2019s simplification quality.\nFor fluency, both models demonstrate high fluency levels, indicated by the average ratings approach three. This suggests that both GPT-4 and Control-T5 generated grammatically correct simplifications without significant differences in fluency.\nIn terms of meaning preservation, GPT-4 outperforms Control-T5 across all three datasets: achieving scores of  versus  on Turk,  versus  on ASSET, and  versus  on Newsela. Conversely, for simplicity, GPT-4\u2019s ratings are slightly lower than those of Control-T5, though the disparities are less pronounced than those observed for meaning preservation:  versus  on Turk,  versus  on ASSET, and  versus  on Newsela. This contrast suggests that Control-T5 may be slightly better at generating simpler outputs but at the cost of losing a significant portion of the original meaning.\nOn the Newsela dataset, we observed that Control-T5 often simply deletes long segments of the source sentence, leaving only trivial changes to the remaining parts. Below is an example:\nObama said that children today still fail to meet their full potential, even if there are no mobs with bricks and bottles to ward young black women away from higher education.\nEven if there are no mobs with bricks and bottles to keep young black women from higher education.\nObama said that children aren\u2019t reaching their full potential, even when there are no threats stopping them from getting a better education.\nIn this example, Control-T5 removed the extensive segment preceding \u2018even if\u2026\u2019, resulting in the loss of significant information. In contrast, GPT-4 retained the majority of the information, resulting in higher scores on meaning preservation.\nThe last column of Table 7  ###reference_### shows average ratings for reference simplifications in the Newsela test set, which reveals that Newsela\u2019s references permit to sacrifice of meaning preservation for simplicity.\nControl-T5 might have adopted a deletion-heavy approach during its training on the Newsela dataset, even heavier than the deletion degree of the Newsela dataset itself. It adversely affects its ability to preserve the original sentence\u2019s meaning."
        },
        {
            "section_id": "6.3",
            "parent_section_id": "6",
            "section_name": "6.3. Discussion: Other Issues Resolved by LLM",
            "text": "Some Control-T5-generated simplification outputs are reported by our annotators to fail in meeting the satisfaction criteria. These cases include issues such as redundancy, lack of common sense, and inappropriate changes in focus, which were not noted with GPT-4\u2019s simplification outputs. This section provides an enumeration of such cases, alongside examples for each category.\nFr\u00e9d\u00e9ric Chopin\u2019s Opus 57 is a berceuse for solo piano.\nFr\u00e9d\u00e9ric Chopin wrote a piece called Opus 57 for solo piano.\nFr\u00e9d\u00e9ric Chopin\u2019s Opus 57 is a lullaby for a single piano.\nThe PAD called for the resignation of the governments of Thaksin Shinawatra, Samak Sundaravej, and Somchai Wongsawat, whom the PAD accused of being proxies for Thaksin.\nThe PAD called for the resignation of the governments of Thaksin Shinawatra, Samak Sundaravej, and Somchai Wongsawat. The PAD said that Thaksin was a friend of the PAD.\nThe PAD asked for the resignation of the governments of Thaksin Shinawatra, Samak Sundaravej and Somchai Wongsawat, whom the PAD accused of being representatives for Thaksin."
        },
        {
            "section_id": "6.3.1",
            "parent_section_id": "6.3",
            "section_name": "6.3.1. Redundancy",
            "text": "The simplifications introduced redundancies, failing to contribute meaningfully to the simplification of the sentence or to enhance clarity. In the example below,\nControl-T5 replaced \u2018biochemist\u2019 with \u2018biochemist and scientist\u2019, which seems redundant due to the overlapping parts in meanings. In contrast, GPT-4 avoided this issue.\nTheir granddaughter H\u00e9l\u00e8ne Langevin-Joliot is a professor of nuclear physics at the University of Paris, and their grandson Pierre Joliot, who was named after Pierre Curie, is a noted biochemist.\nTheir granddaughter H\u00e9l\u00e8ne Langevin-Joliot is a professor of nuclear physics at the University of Paris. Their grandson Pierre Joliot is also a well-known biochemist and scientist.\nTheir granddaughter, H\u00e9l\u00e8ne Langevin-Joliot, teaches nuclear physics at the University of Paris. Their grandson, Pierre Joliot, named after Pierre Curie, is a famous biochemist."
        },
        {
            "section_id": "6.3.2",
            "parent_section_id": "6.3",
            "section_name": "6.3.2. Lack of Common Sense",
            "text": "Simplifications that result in logical inconsistencies or nonsensical interpretations. In the example below, Control-T5 illogically suggested that Orton gave birth to his wife, indicating a lack of common sense. In contrast, GPT-4 avoided this issue by correctly suggesting that Orton and his wife welcomed a baby girl, aligning with human common sense understanding.\nOrton and his wife welcomed Alanna Marie Orton on July 12, 2008.\nOrton gave birth to his wife, Alanna Marie, on July 12, 2008.\nOrton and his wife had a baby girl named Alanna Marie Orton on July 12, 2008."
        },
        {
            "section_id": "6.3.3",
            "parent_section_id": "6.3",
            "section_name": "6.3.3. Change of Focus",
            "text": "Simplifications that inappropriately alter the original sentence\u2019s focus, leading to misleading interpretations or factual inaccuracies. In the first example below, Control-T5 shifted the focus from the type of piece Opus 57 is to the mere fact that Chopin composed it, while GPT-4 correctly kept the focus of the source sentence. In the second example, Control-T5 inaccurately replaced \u2018being proxies for Thaksin\u2019 with \u2018Thaksin was a friend of the PAD\u2019, changing the sentence\u2019s meaning substantially. Conversely, GPT-4 did not appear this kind of inference mistake.\nFr\u00e9d\u00e9ric Chopin\u2019s Opus 57 is a berceuse for solo piano.\nFr\u00e9d\u00e9ric Chopin wrote a piece called Opus 57 for solo piano.\nFr\u00e9d\u00e9ric Chopin\u2019s Opus 57 is a lullaby for a single piano.\nThe PAD called for the resignation of the governments of Thaksin Shinawatra, Samak Sundaravej, and Somchai Wongsawat, whom the PAD accused of being proxies for Thaksin.\nThe PAD called for the resignation of the governments of Thaksin Shinawatra, Samak Sundaravej, and Somchai Wongsawat. The PAD said that Thaksin was a friend of the PAD.\nThe PAD asked for the resignation of the governments of Thaksin Shinawatra, Samak Sundaravej and Somchai Wongsawat, whom the PAD accused of being representatives for Thaksin."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7. Meta-Evaluation of Automatic Evaluation Metrics",
            "text": "Due to the high cost and time requirements of human evaluation, automatic metrics are preferred as a means of obtaining faster and cheaper evaluation of simplification models. Previous studies have explored the extent of widely-used metrics in sentence simplification to assess the quality of outputs generated by neural systems (Sulem et al., 2018a; Alva-Manchego et al., 2021; Tanprasert and Kauchak, 2021). However, it remains uncertain whether these metrics are adequately sensitive and robust to differentiate the quality of simplification outputs generated by advanced LLMs, i.e., GPT-4, especially given the generally high performance. To fill this gap, we performed a meta-evaluation of commonly used automatic metrics in both sentence and corpus levels, utilizing our human evaluation data."
        },
        {
            "section_id": "7.1",
            "parent_section_id": "7",
            "section_name": "7.1. Automatic Metrics",
            "text": "In this section, we review evaluation metrics that have been widely used in sentence simplification, categorizing them based on their primary evaluation units into two types: sentence-level metrics, which evaluate individual sentences, and corpus-level metrics, which assess the system-wise quality of simplification outputs."
        },
        {
            "section_id": "7.1.1",
            "parent_section_id": "7.1",
            "section_name": "7.1.1. Sentence-level Metrics",
            "text": "LENS (Maddela et al., 2023) is a model-based evaluation metric that leverages RoBERTa (Liu et al., 2019) trained to predict human judgment scores, considering both the semantic similarity and the edits comparing the output to the source and reference sentences. Its values range from  to , where higher scores indicate better simplifications. BERTScore (Zhang et al., 2020) provides similarity scores (precision, recall, and f1) for each token in the candidate sentence against each token in the reference, leveraging BERT\u2019s (Devlin et al., 2019) contextual embeddings. We calculate LENS through the authors\u2019 GitHub implementation and BERTScore using the EASSE package (Alva-Manchego et al., 2019)."
        },
        {
            "section_id": "7.1.2",
            "parent_section_id": "7.1",
            "section_name": "7.1.2. Corpus-level Metrics",
            "text": "BLEU (Papineni et al., 2002) measures string similarity between references and outputs. Derived from the field of machine translation, it is designed to evaluate translation accuracy by comparing the match of n-grams between the candidate translations and reference translations. This metric has been employed to assess sentence simplification, treating the simplification process as a translation from complex to simple language. BLEU scores range from to , with higher scores indicating better quality.\n\nFKGL (Kincaid et al., 1975) evaluates readability by combining sentence and word lengths. Lower values indicate higher readability. The FKGL score starts from and has no upper bound.\n\nWe utilize the EASSE package (Alva-Manchego et al., 2019) to calculate these corpus-level metric scores."
        },
        {
            "section_id": "7.2",
            "parent_section_id": "7",
            "section_name": "7.2. Sentence-Level Results",
            "text": "To assess sentence-level metrics\u2019 ability to differentiate simplification quality, we explore the correlation between those metrics and human evaluations using the point-biserial correlation coefficient (Glass and Hopkins, 1995; Linacre, 2008), utilizing the scipy package (Virtanen et al., 2020) for calculation. This coefficient ranges from -1 to 1, where 0 indicates no correlation.\n\nOur analysis aims to assess the efficacy of sentence-level metrics in three aspects:\n\n1. Identification of the presence of errors.\n2. Distinction between high-quality and low-quality simplification overall.\n3. Distinction between high-quality and low-quality simplification within a specific dimension.\n\nGiven the data imbalance between sentences with and without errors, and between high-quality and low-quality simplification, we report our findings using both raw data and downsampled (DS) data to balance the number of class samples."
        },
        {
            "section_id": "7.2.1",
            "parent_section_id": "7.2",
            "section_name": "7.2.1. Identification of the presence of errors",
            "text": "For all simplification outputs in Task, each simplification output was classified as containing errors (labeled as) or no error (labeled as). We then computed the correlation coefficients between these labels and the metric scores. The results indicate that none of the metrics effectively identify erroneous simplifications, as evidenced by point-biserial correlation coefficients being near zero."
        },
        {
            "section_id": "7.2.2",
            "parent_section_id": "7.2",
            "section_name": "7.2.2. Distinction between high-quality and low-quality simplifications overall",
            "text": "We examined simplification outputs in Task . Each output was classified as high quality if it received a high rating from at least two out of three annotators across fluency, simplicity, and meaning preservation, and low quality otherwise. We computed the correlation coefficients between these classifications and the metric scores. As discussed, Newsela is different from other corpora for allowing significant meaning loss to prioritize simplicity. To reduce bias from this dataset, we also calculated the correlation after excluding Newsela, using only Turk and ASSET (denoted as \u2018T&A\u2019). For each evaluation, we further divided outputs based on the model (GPT-4 vs. Control-T5) to determine differences in metrics\u2019 capabilities. Results are summarized. For Control-T5 outputs, LENS exhibits some ability to distinguish quality, though with limited effectiveness overall. BERTScores indicate a stronger capability to distinguish quality, with correlations ranging from to , which decrease to when Newsela-derived outputs are removed. For GPT-4 outputs, neither BERTScores nor LENS effectively distinguish quality. These results suggest that while these metrics can detect significant quality variations, they fall short when overall quality is high. Thus, they may not be suitable for evaluating advanced LLMs like GPT-4. Visualization further illustrates this. For GPT-4, regardless of metric used, scores of high and low-quality outputs appear to blend, indicating lack of discriminative capability. In contrast, Control-T5 shows a clear difference, with both LENS and BERTScores giving lower scores to low-quality outputs and higher scores to high-quality ones. This differentiation is particularly pronounced in BERTScores. Note that most low-quality outputs stem from Newsela, making the distinction less apparent when excluding Newsela-derived simplifications."
        },
        {
            "section_id": "7.2.3",
            "parent_section_id": "7.2",
            "section_name": "7.2.3. Distinction between high-quality and low-quality simplifications within a specific dimension",
            "text": "We examined model-generated simplification outputs across individual dimensions. For each dimension, simplification outputs were classified as high quality if they received a high rating from at least two out of three annotators, and low quality otherwise. Based on our classification, on fluency, all the GPT4-generated simplification outputs are high quality, and only five out of Control-T5-generated simplification outputs are low quality. Given that GPT-4 and Control-T5 are rare to generate disfluent outputs, we focus on the dimensions of meaning preservation and simplicity. We then computed the correlation between these ratings and metrics scores.\n\nTable 10(a) indicates results for meaning preservation. Overall, BERTScores demonstrate a stronger correlation with human evaluations for meaning preservation compared to LENS scores. Upon dividing the data by model, BertScores show high correlations for Control-T5 simplification outputs. However, these correlations significantly drop upon the exclusion of simplification outputs derived from Newsela. For GPT-4 simplification outputs, both metrics reveal a negligible correlation. Human evaluation suggests that Control-T5 significantly underperforms in preserving meaning within the Newsela dataset compared to other datasets. While both metrics effectively differentiate substantial differences in meaning preservation, they struggle when overall meaning preservation is high.\n\nTable 10(b) shows results for simplicity, where neither metric correlates well with human evaluations, though LENS slightly outperforms BERTScores. Consequently, they may not be sufficiently sensitive to evaluate advanced LLMs like GPT-4 on meaning preservation and simplicity."
        },
        {
            "section_id": "7.3",
            "parent_section_id": "7",
            "section_name": "7.3. Corpus-level Results",
            "text": "Our human evaluations reveal GPT-4\u2019s simplification outputs are generally superior, evidenced by fewer errors, better meaning preservation, and comparable fluency and simplicity to those generated by Control-T5. The metrics\u2019 scores are detailed in Table 11, with the better scores emphasized in bold. To assess the statistical significance of the differences in corpus-level scores, we employed a randomization test (Fisher, 1935) against Control-T5. Better corpus-level scores are masked with an asterisk if statistically significant differences were confirmed.\n\nBLEU significantly favors Control-T5 on ASSET and Newsela, which does not match our human evaluations. Studies have demonstrated that BLEU is unsuitable for simplification tasks, as it tends to negatively correlate with simplicity, often penalizing simpler sentences, and gives high scores to sentences that are close or even identical to the input. Our findings further underscore the limitations of BLEU in evaluating sentence simplification. FKGL ranks Control-T5\u2019s outputs as easier to read compared to those from GPT-4 across all datasets. This aligns with our human evaluation; Control-T5 tends to generate simpler sentence expense of meaning preservation, thereby making the sentence easier to read. However, FKGL\u2019s focus solely on readability, without taking into account the quality of the content or the reference sentences, limits its effectiveness in a comprehensive quality analysis. Previous studies show FKGL is unsuitable for sentence simplification evaluation. Our findings further highlight its limitations in accurately evaluating corpus-level sentence simplification."
        },
        {
            "section_id": "7.4",
            "parent_section_id": "7",
            "section_name": "7.4. Summary of Findings",
            "text": "We summarize our findings on the meta-evaluation of existing evaluation metrics for sentence simplification, namely LENS, BERTScores, BLEU, and FKGL. Existing metrics are not capable of identifying the presence of errors in sentences. At sentence level, BERTScores are effective in differentiating the distinct difference between high-quality and low-quality simplification overall as well as on meaning preservation. However, they are not sensitive enough to evaluate the quality of simplification generated by GPT-4. On sentence-level simplicity, neither of the metrics is capable of differentiating high-quality and low-quality simplification."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "8. Conclusion",
            "text": "In this study, we conducted an in-depth human evaluation of the advanced LLM, specifically the performance of GPT-4, in sentence simplification. Our findings highlight that GPT-4 surpasses the supervised baseline model, Control-T5, by generating fewer erroneous simplification outputs and preserving the source sentence\u2019s meaning better. These results underscore the superiority of advanced LLMs in this task. Nevertheless, we observed limitations, notably in GPT-4\u2019s handling of lexical paraphrasing. Further, our meta-evaluation of sentence simplification\u2019s automatic metrics demonstrated their inadequacy in accurately assessing the quality of GPT-4-generated simplifications.\n\nOur investigation opens up multiple directions for future research. Future studies could investigate how to mitigate lexical paraphrasing issues. For example, it would be worthwhile to explore whether fine-tuning could help. Moreover, there\u2019s a need for more sensitive automatic metrics to properly evaluate the sentence-level quality of simplifications generated by LLMs."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Details of Models",
            "text": ""
        },
        {
            "section_id": "Appendix 2",
            "parent_section_id": null,
            "section_name": "Appendix B Annotation Guidelines for Task 2",
            "text": "Figure 6  ###reference_### shows guidelines provided to annotators in Task .\nAnnotators were required to understand these guidelines before starting the annotation process.\n###figure_6### ###figure_7### ###figure_8### ###figure_9###"
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T1\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S3.T1.8.1.1\" style=\"font-size:90%;\">Table 1</span>. </span><span class=\"ltx_text\" id=\"S3.T1.9.2\" style=\"font-size:90%;\">Number of complex-simple sentence pairs in the validation and test sets of each dataset</span></figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T1.6\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T1.6.7.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S3.T1.6.7.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.6.7.1.1.1\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.6.7.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.6.7.1.2.1\">Validation</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.6.7.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.6.7.1.3.1\">Test</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.2.2.3\">Turk</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.2.2.2\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T1.4.4.3\">ASSET</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.3.3.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.4.2\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T1.6.6.3\">Newsela</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.5.5.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.6.6.2\"></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 1. Number of complex-simple sentence pairs in the validation and test sets of each dataset"
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T2\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T2.5.1.1\" style=\"font-size:90%;\">Table 2</span>. </span><span class=\"ltx_text\" id=\"S4.T2.6.2\" style=\"font-size:90%;\">Prompt engineering impact on SARI scores</span></figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.3\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.3.4.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.3.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.4.1.1.1\">Valid Set</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.3.4.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.4.1.2.1\">SARI Diff.</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.3.4.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.4.1.3.1\">Best Prompts</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T2.1.1.2\">Turk</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T2.1.1.3\">Turk style + Few-shot + Single ref</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.2.2.2\">ASSET</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.2.1\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.2.2.3\">ASSET style + Few-shot + Single ref</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T2.3.3.2\">Newsela</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.3.3.1\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T2.3.3.3\">Newsela style + Few-shot + Multi refs</td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 2. Prompt engineering impact on SARI scores"
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T3\">\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 3. </span>Definitions and Examples of Errors</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T3.4\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T3.4.1.1\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.4.1.1.1\" style=\"width:56.9pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T3.4.1.1.1.1\" style=\"font-size:90%;\">Error</span></th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.4.1.1.2\" style=\"width:34.1pt;\"></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.4.1.1.3\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T3.4.1.1.3.1\" style=\"font-size:90%;\">Definition</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.4.1.1.4\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T3.4.1.1.4.1\" style=\"font-size:90%;\">Source</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.4.1.1.5\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T3.4.1.1.5.1\" style=\"font-size:90%;\">Simplification</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T3.4.2.1\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.2.1.1\" rowspan=\"2\" style=\"width:56.9pt;\"><span class=\"ltx_text ltx_align_top\" id=\"S5.T3.4.2.1.1.1\" style=\"font-size:90%;\">Lack of Simplicity</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.2.1.2\" style=\"width:34.1pt;\"><span class=\"ltx_text ltx_align_top\" id=\"S5.T3.4.2.1.2.1\" style=\"font-size:90%;\">Lexical</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.2.1.3\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.2.1.3.1\"><span class=\"ltx_text\" id=\"S5.T3.4.2.1.3.1.1\" style=\"font-size:90%;\">The simplified sentence uses more intricate lexical expression(s) to replace part(s) of the original sentence.</span></p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.2.1.4\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.2.1.4.1\"><span class=\"ltx_text\" id=\"S5.T3.4.2.1.4.1.1\" style=\"font-size:90%;\">For Rowling, this scene is </span><span class=\"ltx_text\" id=\"S5.T3.4.2.1.4.1.2\" style=\"font-size:90%;color:#FF0000;\">important</span><span class=\"ltx_text\" id=\"S5.T3.4.2.1.4.1.3\" style=\"font-size:90%;\"> because it </span><span class=\"ltx_text\" id=\"S5.T3.4.2.1.4.1.4\" style=\"font-size:90%;color:#FF0000;\">shows</span><span class=\"ltx_text\" id=\"S5.T3.4.2.1.4.1.5\" style=\"font-size:90%;\"> Harry\u2019s bravery\u2026</span></p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.2.1.5\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.2.1.5.1\"><span class=\"ltx_text\" id=\"S5.T3.4.2.1.5.1.1\" style=\"font-size:90%;\">Rowling considers the scene </span><span class=\"ltx_text\" id=\"S5.T3.4.2.1.5.1.2\" style=\"font-size:90%;color:#FF0000;\">significant</span><span class=\"ltx_text\" id=\"S5.T3.4.2.1.5.1.3\" style=\"font-size:90%;\"> because it </span><span class=\"ltx_text\" id=\"S5.T3.4.2.1.5.1.4\" style=\"font-size:90%;color:#FF0000;\">portrays</span><span class=\"ltx_text\" id=\"S5.T3.4.2.1.5.1.5\" style=\"font-size:90%;\"> Harry\u2019s courage\u2026</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.3.2\">\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.4.3.2.1\" style=\"width:34.1pt;\"><span class=\"ltx_text ltx_align_top\" id=\"S5.T3.4.3.2.1.1\" style=\"font-size:90%;\">Structural</span></td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.4.3.2.2\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.3.2.2.1\"><span class=\"ltx_text\" id=\"S5.T3.4.3.2.2.1.1\" style=\"font-size:90%;\">The simplified sentence modifies the grammatical structure, and it increases the difficulty of reading.</span></p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.4.3.2.3\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.3.2.3.1\"><span class=\"ltx_text\" id=\"S5.T3.4.3.2.3.1.1\" style=\"font-size:90%;color:#FF0000;\">The other incorporated cities</span><span class=\"ltx_text\" id=\"S5.T3.4.3.2.3.1.2\" style=\"font-size:90%;\"> on the Palos Verdes Peninsula include\u2026</span></p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.4.3.2.4\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.3.2.4.1\"><span class=\"ltx_text\" id=\"S5.T3.4.3.2.4.1.1\" style=\"font-size:90%;\">Other cities on the Palos Verdes Peninsula include\u2026, </span><span class=\"ltx_text\" id=\"S5.T3.4.3.2.4.1.2\" style=\"font-size:90%;color:#FF0000;\">which are also incorporated</span><span class=\"ltx_text\" id=\"S5.T3.4.3.2.4.1.3\" style=\"font-size:90%;\">.</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.4.3\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.4.3.1\" rowspan=\"2\" style=\"width:56.9pt;\"><span class=\"ltx_text ltx_align_top\" id=\"S5.T3.4.4.3.1.1\" style=\"font-size:90%;\">Altered Meaning</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.4.3.2\" style=\"width:34.1pt;\"><span class=\"ltx_text ltx_align_top\" id=\"S5.T3.4.4.3.2.1\" style=\"font-size:90%;\">Lexical</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.4.3.3\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.4.3.3.1\"><span class=\"ltx_text\" id=\"S5.T3.4.4.3.3.1.1\" style=\"font-size:90%;\">Significant deviation in the meaning of the original sentence due to lexical substitution(s).</span></p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.4.3.4\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.4.3.4.1\"><span class=\"ltx_text\" id=\"S5.T3.4.4.3.4.1.1\" style=\"font-size:90%;\">The Britannica was primarily a Scottish </span><span class=\"ltx_text\" id=\"S5.T3.4.4.3.4.1.2\" style=\"font-size:90%;color:#FF0000;\">enterprise</span><span class=\"ltx_text\" id=\"S5.T3.4.4.3.4.1.3\" style=\"font-size:90%;\">.</span></p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.4.3.5\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.4.3.5.1\"><span class=\"ltx_text\" id=\"S5.T3.4.4.3.5.1.1\" style=\"font-size:90%;\">The Britannica was mainly a Scottish </span><span class=\"ltx_text\" id=\"S5.T3.4.4.3.5.1.2\" style=\"font-size:90%;color:#FF0000;\">endeavor</span><span class=\"ltx_text\" id=\"S5.T3.4.4.3.5.1.3\" style=\"font-size:90%;\">.</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.5.4\">\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T3.4.5.4.1\" rowspan=\"4\" style=\"width:34.1pt;\"><span class=\"ltx_text ltx_align_top\" id=\"S5.T3.4.5.4.1.1\" style=\"font-size:90%;\">Structural</span></td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.4.5.4.2\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.5.4.2.1\"><span class=\"ltx_text\" id=\"S5.T3.4.5.4.2.1.1\" style=\"font-size:90%;\">Significant deviation in the meaning of the original sentence due to structural changes.</span></p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.4.5.4.3\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.5.4.3.1\"><span class=\"ltx_text\" id=\"S5.T3.4.5.4.3.1.1\" style=\"font-size:90%;\">Gimnasia hired </span><span class=\"ltx_text\" id=\"S5.T3.4.5.4.3.1.2\" style=\"font-size:90%;color:#FF0000;\">first famed Colombian trainer Francisco Maturana, and then Julio C\u00e9sar Falcioni</span><span class=\"ltx_text\" id=\"S5.T3.4.5.4.3.1.3\" style=\"font-size:90%;\">.</span></p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.4.5.4.4\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.5.4.4.1\"><span class=\"ltx_text\" id=\"S5.T3.4.5.4.4.1.1\" style=\"font-size:90%;\">Gimnasia hired </span><span class=\"ltx_text\" id=\"S5.T3.4.5.4.4.1.2\" style=\"font-size:90%;color:#FF0000;\">two famous Colombian trainers, Francisco Maturana and Julio C\u00e9sar Falcioni</span><span class=\"ltx_text\" id=\"S5.T3.4.5.4.4.1.3\" style=\"font-size:90%;\">.</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.6.5\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.6.5.1\" style=\"width:56.9pt;\"><span class=\"ltx_text ltx_align_top\" id=\"S5.T3.4.6.5.1.1\" style=\"font-size:90%;\">Coreference</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.6.5.2\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.6.5.2.1\"><span class=\"ltx_text\" id=\"S5.T3.4.6.5.2.1.1\" style=\"font-size:90%;\">A named entity critical to understanding the main idea is replaced with a pronoun or a vague description.</span></p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.6.5.3\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.6.5.3.1\"><span class=\"ltx_text\" id=\"S5.T3.4.6.5.3.1.1\" style=\"font-size:90%;color:#FF0000;\">Sea slugs dubbed sacoglossans</span><span class=\"ltx_text\" id=\"S5.T3.4.6.5.3.1.2\" style=\"font-size:90%;\"> are some of the most\u2026</span></p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.6.5.4\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.6.5.4.1\"><span class=\"ltx_text\" id=\"S5.T3.4.6.5.4.1.1\" style=\"font-size:90%;color:#FF0000;\">These</span><span class=\"ltx_text\" id=\"S5.T3.4.6.5.4.1.2\" style=\"font-size:90%;\"> are some of the most\u2026</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.7.6\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.7.6.1\" style=\"width:56.9pt;\"><span class=\"ltx_text ltx_align_top\" id=\"S5.T3.4.7.6.1.1\" style=\"font-size:90%;\">Repetition</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.7.6.2\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.7.6.2.1\"><span class=\"ltx_text\" id=\"S5.T3.4.7.6.2.1.1\" style=\"font-size:90%;\">Unnecessary duplication of sentence fragments</span></p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.7.6.3\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.7.6.3.1\"><span class=\"ltx_text\" id=\"S5.T3.4.7.6.3.1.1\" style=\"font-size:90%;\">The report emphasizes the </span><span class=\"ltx_text\" id=\"S5.T3.4.7.6.3.1.2\" style=\"font-size:90%;color:#FF0000;\">importance</span><span class=\"ltx_text\" id=\"S5.T3.4.7.6.3.1.3\" style=\"font-size:90%;\"> of sustainable practices.</span></p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.4.7.6.4\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.7.6.4.1\"><span class=\"ltx_text\" id=\"S5.T3.4.7.6.4.1.1\" style=\"font-size:90%;\">The report emphasizes the </span><span class=\"ltx_text\" id=\"S5.T3.4.7.6.4.1.2\" style=\"font-size:90%;color:#FF0000;\">importance, the significance, and the necessity</span><span class=\"ltx_text\" id=\"S5.T3.4.7.6.4.1.3\" style=\"font-size:90%;\"> of sustainable practices.</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.4.8.7\">\n<td class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_t\" id=\"S5.T3.4.8.7.1\" rowspan=\"6\" style=\"width:56.9pt;\"><span class=\"ltx_text ltx_align_top\" id=\"S5.T3.4.8.7.1.1\" style=\"font-size:90%;\">Hallucination</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_t\" id=\"S5.T3.4.8.7.2\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.8.7.2.1\"><span class=\"ltx_text\" id=\"S5.T3.4.8.7.2.1.1\" style=\"font-size:90%;\">Inclusion of incorrect or unrelated information not present in the original sentence.</span></p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_t\" id=\"S5.T3.4.8.7.3\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.8.7.3.1\"><span class=\"ltx_text\" id=\"S5.T3.4.8.7.3.1.1\" style=\"font-size:90%;\">In a short video promoting the charity Equality Now, Joss Whedon confirmed that \u201dFray is not done, Fray is coming back.</span></p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_t\" id=\"S5.T3.4.8.7.4\" style=\"width:85.4pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.4.8.7.4.1\"><span class=\"ltx_text\" id=\"S5.T3.4.8.7.4.1.1\" style=\"font-size:90%;\">Joss Whedon confirmed in a short promotional video for the charity Equality Now that Fray will return, </span><span class=\"ltx_text\" id=\"S5.T3.4.8.7.4.1.2\" style=\"font-size:90%;color:#FF0000;\">although the story is not yet finished</span><span class=\"ltx_text\" id=\"S5.T3.4.8.7.4.1.3\" style=\"font-size:90%;\">.</span></p>\n</td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 3. Definitions and Examples of Errors"
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T4\">\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 4. </span>Overlapping rate across three annotators (%)</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T4.21\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T4.21.22.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S5.T4.21.22.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S5.T4.21.22.1.2\"><span class=\"ltx_text\" id=\"S5.T4.21.22.1.2.1\" style=\"font-size:90%;\">Turk</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S5.T4.21.22.1.3\"><span class=\"ltx_text\" id=\"S5.T4.21.22.1.3.1\" style=\"font-size:90%;\">ASSET</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S5.T4.21.22.1.4\"><span class=\"ltx_text\" id=\"S5.T4.21.22.1.4.1\" style=\"font-size:90%;\">Newsela</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.21.23.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" id=\"S5.T4.21.23.2.1\"><span class=\"ltx_text\" id=\"S5.T4.21.23.2.1.1\" style=\"font-size:90%;\">Dimension</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.21.23.2.2\"><span class=\"ltx_text\" id=\"S5.T4.21.23.2.2.1\" style=\"font-size:90%;\">GPT-4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.21.23.2.3\"><span class=\"ltx_text\" id=\"S5.T4.21.23.2.3.1\" style=\"font-size:90%;\">T5</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.21.23.2.4\"><span class=\"ltx_text\" id=\"S5.T4.21.23.2.4.1\" style=\"font-size:90%;\">GPT-4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.21.23.2.5\"><span class=\"ltx_text\" id=\"S5.T4.21.23.2.5.1\" style=\"font-size:90%;\">T5</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.21.23.2.6\"><span class=\"ltx_text\" id=\"S5.T4.21.23.2.6.1\" style=\"font-size:90%;\">GPT-4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.21.23.2.7\"><span class=\"ltx_text\" id=\"S5.T4.21.23.2.7.1\" style=\"font-size:90%;\">T5</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.21.23.2.8\"><span class=\"ltx_text\" id=\"S5.T4.21.23.2.8.1\" style=\"font-size:90%;\">Reference</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T4.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T4.7.7.8\"><span class=\"ltx_text\" id=\"S5.T4.7.7.8.1\" style=\"font-size:90%;\">Fluency</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.4.4.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.5.5.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.6.6.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.7.7.7\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.14.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T4.14.14.8\"><span class=\"ltx_text\" id=\"S5.T4.14.14.8.1\" style=\"font-size:90%;\">Meaning Preservation</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.8.8.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.9.9.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.10.10.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.11.11.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.12.12.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.13.13.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.14.14.7\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.21.21\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T4.21.21.8\"><span class=\"ltx_text\" id=\"S5.T4.21.21.8.1\" style=\"font-size:90%;\">Simplicity</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.15.15.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.16.16.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.17.17.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.18.18.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.19.19.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.20.20.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.21.21.7\"></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 4. Overlapping rate across three annotators (%)"
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"S6.T5\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S6.T5.14.1.1\" style=\"font-size:90%;\">Table 5</span>. </span><span class=\"ltx_text\" id=\"S6.T5.15.2\" style=\"font-size:90%;\">Comparison of the number of erroneous simplification outputs generated by GPT-4 and Control-T5</span></figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S6.T5.12\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S6.T5.12.13.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S6.T5.12.13.1.1\">Test set</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T5.12.13.1.2\">GPT-4</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T5.12.13.1.3\">Control-T5</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S6.T5.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S6.T5.1.1.1\">Turk ( samples)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T5.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T5.3.3.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T5.4.4.1\">ASSET ( samples)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.5.5.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.6.6.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T5.7.7.1\">Newsela ( samples)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.8.8.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.9.9.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\" id=\"S6.T5.10.10.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.10.10.1.1\">Total</span> ( samples)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T5.11.11.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T5.12.12.3\"></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 5. Comparison of the number of erroneous simplification outputs generated by GPT-4 and Control-T5"
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"S6.T6\">\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 6. </span>Comparison of the number of each error type in GPT-4 and Control-T5 generated simplification outputs</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S6.T6.64\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S6.T6.64.65.1\">\n<td class=\"ltx_td ltx_border_tt\" id=\"S6.T6.64.65.1.1\"></td>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S6.T6.64.65.1.2\"><span class=\"ltx_text\" id=\"S6.T6.64.65.1.2.1\" style=\"font-size:90%;\">Turk</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S6.T6.64.65.1.3\"><span class=\"ltx_text\" id=\"S6.T6.64.65.1.3.1\" style=\"font-size:90%;\">ASSET</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S6.T6.64.65.1.4\"><span class=\"ltx_text\" id=\"S6.T6.64.65.1.4.1\" style=\"font-size:90%;\">Newsela</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S6.T6.64.65.1.5\"><span class=\"ltx_text\" id=\"S6.T6.64.65.1.5.1\" style=\"font-size:90%;\">Total</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T6.64.66.2\">\n<td class=\"ltx_td\" id=\"S6.T6.64.66.2.1\"></td>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T6.64.66.2.2\"><span class=\"ltx_text\" id=\"S6.T6.64.66.2.2.1\" style=\"font-size:90%;\">GPT-4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T6.64.66.2.3\"><span class=\"ltx_text\" id=\"S6.T6.64.66.2.3.1\" style=\"font-size:90%;\">T5</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T6.64.66.2.4\"><span class=\"ltx_text\" id=\"S6.T6.64.66.2.4.1\" style=\"font-size:90%;\">GPT-4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T6.64.66.2.5\"><span class=\"ltx_text\" id=\"S6.T6.64.66.2.5.1\" style=\"font-size:90%;\">T5</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T6.64.66.2.6\"><span class=\"ltx_text\" id=\"S6.T6.64.66.2.6.1\" style=\"font-size:90%;\">GPT-4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T6.64.66.2.7\"><span class=\"ltx_text\" id=\"S6.T6.64.66.2.7.1\" style=\"font-size:90%;\">T5</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T6.64.66.2.8\"><span class=\"ltx_text\" id=\"S6.T6.64.66.2.8.1\" style=\"font-size:90%;\">GPT-4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T6.64.66.2.9\"><span class=\"ltx_text\" id=\"S6.T6.64.66.2.9.1\" style=\"font-size:90%;\">T5</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T6.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S6.T6.8.8.9\"><span class=\"ltx_text\" id=\"S6.T6.8.8.9.1\" style=\"font-size:90%;\">Lack of Simplicity - Lexical</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T6.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T6.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T6.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T6.4.4.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T6.5.5.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T6.6.6.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T6.7.7.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T6.8.8.8\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T6.16.16\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T6.16.16.9\"><span class=\"ltx_text\" id=\"S6.T6.16.16.9.1\" style=\"font-size:90%;\">Lack of Simplicity - Structural</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.9.9.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.10.10.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.11.11.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.12.12.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.13.13.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.14.14.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.15.15.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.16.16.8\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T6.24.24\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T6.24.24.9\"><span class=\"ltx_text\" id=\"S6.T6.24.24.9.1\" style=\"font-size:90%;\">Altered Meaning - Structural</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.17.17.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.18.18.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.19.19.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.20.20.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.21.21.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.22.22.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.23.23.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.24.24.8\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T6.32.32\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T6.32.32.9\"><span class=\"ltx_text\" id=\"S6.T6.32.32.9.1\" style=\"font-size:90%;\">Altered Meaning - Lexical</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.25.25.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.26.26.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.27.27.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.28.28.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.29.29.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.30.30.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.31.31.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.32.32.8\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T6.40.40\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T6.40.40.9\"><span class=\"ltx_text\" id=\"S6.T6.40.40.9.1\" style=\"font-size:90%;\">Coreference</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.33.33.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.34.34.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.35.35.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.36.36.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.37.37.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.38.38.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.39.39.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.40.40.8\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T6.48.48\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T6.48.48.9\"><span class=\"ltx_text\" id=\"S6.T6.48.48.9.1\" style=\"font-size:90%;\">Repetition</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.41.41.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.42.42.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.43.43.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.44.44.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.45.45.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.46.46.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.47.47.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.48.48.8\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T6.56.56\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T6.56.56.9\"><span class=\"ltx_text\" id=\"S6.T6.56.56.9.1\" style=\"font-size:90%;\">Hallucination</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.49.49.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.50.50.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.51.51.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.52.52.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.53.53.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.54.54.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.55.55.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T6.56.56.8\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T6.64.64\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S6.T6.64.64.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T6.64.64.9.1\" style=\"font-size:90%;\">Total</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T6.57.57.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T6.58.58.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T6.59.59.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T6.60.60.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T6.61.61.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T6.62.62.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T6.63.63.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T6.64.64.8\"></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 6. Comparison of the number of each error type in GPT-4 and Control-T5 generated simplification outputs"
        },
        "7": {
            "table_html": "<figure class=\"ltx_table\" id=\"S6.T7\">\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 7. </span>Average Ratings</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S6.T7.28\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S6.T7.28.29.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S6.T7.28.29.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S6.T7.28.29.1.2\"><span class=\"ltx_text\" id=\"S6.T7.28.29.1.2.1\" style=\"font-size:90%;\">Turk</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S6.T7.28.29.1.3\"><span class=\"ltx_text\" id=\"S6.T7.28.29.1.3.1\" style=\"font-size:90%;\">ASSET</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S6.T7.28.29.1.4\"><span class=\"ltx_text\" id=\"S6.T7.28.29.1.4.1\" style=\"font-size:90%;\">Newsela</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T7.28.30.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" id=\"S6.T7.28.30.2.1\"><span class=\"ltx_text\" id=\"S6.T7.28.30.2.1.1\" style=\"font-size:90%;\">Dimension</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T7.28.30.2.2\"><span class=\"ltx_text\" id=\"S6.T7.28.30.2.2.1\" style=\"font-size:90%;\">GPT-4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T7.28.30.2.3\"><span class=\"ltx_text\" id=\"S6.T7.28.30.2.3.1\" style=\"font-size:90%;\">Control-T5</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T7.28.30.2.4\"><span class=\"ltx_text\" id=\"S6.T7.28.30.2.4.1\" style=\"font-size:90%;\">GPT-4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T7.28.30.2.5\"><span class=\"ltx_text\" id=\"S6.T7.28.30.2.5.1\" style=\"font-size:90%;\">Control-T5</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T7.28.30.2.6\"><span class=\"ltx_text\" id=\"S6.T7.28.30.2.6.1\" style=\"font-size:90%;\">GPT-4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T7.28.30.2.7\"><span class=\"ltx_text\" id=\"S6.T7.28.30.2.7.1\" style=\"font-size:90%;\">Control-T5</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T7.28.30.2.8\"><span class=\"ltx_text\" id=\"S6.T7.28.30.2.8.1\" style=\"font-size:90%;\">Reference</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S6.T7.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S6.T7.7.7.8\"><span class=\"ltx_text\" id=\"S6.T7.7.7.8.1\" style=\"font-size:90%;\">Fluency</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T7.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T7.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T7.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T7.4.4.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T7.5.5.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T7.6.6.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T7.7.7.7\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T7.14.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T7.14.14.8\"><span class=\"ltx_text\" id=\"S6.T7.14.14.8.1\" style=\"font-size:90%;\">Meaning Preservation</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T7.8.8.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T7.9.9.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T7.10.10.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T7.11.11.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T7.12.12.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T7.13.13.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T7.14.14.7\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T7.21.21\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T7.21.21.8\"><span class=\"ltx_text\" id=\"S6.T7.21.21.8.1\" style=\"font-size:90%;\">Simplicity</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T7.15.15.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T7.16.16.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T7.17.17.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T7.18.18.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T7.19.19.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T7.20.20.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T7.21.21.7\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T7.28.28\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\" id=\"S6.T7.28.28.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T7.28.28.8.1\" style=\"font-size:90%;\">Total</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T7.22.22.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T7.23.23.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T7.24.24.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T7.25.25.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T7.26.26.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T7.27.27.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S6.T7.28.28.7\"></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 7. Average Ratings"
        },
        "8": {
            "table_html": "<figure class=\"ltx_table\" id=\"S7.T8\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S7.T8.29.1.1\" style=\"font-size:90%;\">Table 8</span>. </span><span class=\"ltx_text\" id=\"S7.T8.30.2\" style=\"font-size:90%;\">Point-biserial correlation between the presence of errors and sentence-level metrics scores, with downsampling (DS) numbers provided.</span></figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S7.T8.27\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S7.T8.27.28.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S7.T8.27.28.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S7.T8.27.28.1.2\">All</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S7.T8.27.28.1.3\">GPT-4</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S7.T8.27.28.1.4\">Control-T5</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T8.3.3\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S7.T8.3.3.4\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T8.3.3.5\">Raw</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T8.1.1.1\">DS ()</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T8.3.3.6\">Raw</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T8.2.2.2\">DS ()</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T8.3.3.7\">Raw</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T8.3.3.3\">DS ()</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S7.T8.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S7.T8.9.9.7\">LENS</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T8.4.4.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T8.5.5.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T8.6.6.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T8.7.7.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T8.8.8.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T8.9.9.6\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T8.15.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T8.15.15.7\">BERT precision</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T8.10.10.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T8.11.11.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T8.12.12.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T8.13.13.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T8.14.14.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T8.15.15.6\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T8.21.21\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T8.21.21.7\">BERT recall</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T8.16.16.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T8.17.17.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T8.18.18.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T8.19.19.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T8.20.20.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T8.21.21.6\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T8.27.27\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S7.T8.27.27.7\">BERT f1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T8.22.22.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T8.23.23.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T8.24.24.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T8.25.25.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T8.26.26.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T8.27.27.6\"></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 8. Point-biserial correlation between the presence of errors and sentence-level metrics scores, with downsampling (DS) numbers provided."
        },
        "9": {
            "table_html": "<figure class=\"ltx_table\" id=\"S7.T9\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S7.T9.38.1.1\" style=\"font-size:90%;\">Table 9</span>. </span><span class=\"ltx_text\" id=\"S7.T9.39.2\" style=\"font-size:90%;\">Point-biserial correlation between the overall human ratings of simplification outputs and sentence-level metrics scores</span></figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S7.T9.36\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S7.T9.36.37.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S7.T9.36.37.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T9.36.37.1.2\">All</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T9.36.37.1.3\">GPT-4</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T9.36.37.1.4\">Control-T5</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T9.36.38.2\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S7.T9.36.38.2.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T9.36.38.2.2\">Raw</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T9.36.38.2.3\">DS (1515)</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T9.36.38.2.4\">T&amp;A</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T9.36.38.2.5\">Raw</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T9.36.38.2.6\">DS (271)</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T9.36.38.2.7\">T&amp;A</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T9.36.38.2.8\">Raw</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T9.36.38.2.9\">DS (551)</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T9.36.38.2.10\">T&amp;A</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S7.T9.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S7.T9.9.9.10\">LENS</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T9.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T9.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T9.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T9.4.4.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T9.5.5.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T9.6.6.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T9.7.7.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T9.8.8.8\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T9.9.9.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T9.18.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T9.18.18.10\">BERT precision</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.10.10.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.11.11.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.12.12.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.13.13.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.14.14.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.15.15.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.16.16.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.17.17.8\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.18.18.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T9.27.27\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T9.27.27.10\">BERT recall</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.19.19.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.20.20.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.21.21.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.22.22.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.23.23.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.24.24.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.25.25.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.26.26.8\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T9.27.27.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T9.36.36\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S7.T9.36.36.10\">BERT f1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T9.28.28.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T9.29.29.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T9.30.30.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T9.31.31.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T9.32.32.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T9.33.33.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T9.34.34.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T9.35.35.8\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T9.36.36.9\"></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 9. Point-biserial correlation between the overall human ratings of simplification outputs and sentence-level metrics scores"
        },
        "10": {
            "table_html": "<figure class=\"ltx_table\" id=\"S7.T10\">\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 10. </span>Point-biserial correlation between sentence-level metrics scores and human ratings in single dimension</figcaption><div class=\"ltx_flex_figure ltx_flex_table\">\n<div class=\"ltx_flex_cell ltx_flex_size_1\">\n<figure class=\"ltx_table ltx_flex_size_1 ltx_align_center\" id=\"S7.T10.st1\">\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">(a) </span>Meaning preservation</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S7.T10.st1.36\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S7.T10.st1.36.37.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S7.T10.st1.36.37.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T10.st1.36.37.1.2\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.37.1.2.1\" style=\"font-size:90%;\">All</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T10.st1.36.37.1.3\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.37.1.3.1\" style=\"font-size:90%;\">GPT-4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T10.st1.36.37.1.4\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.37.1.4.1\" style=\"font-size:90%;\">Control-T5</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st1.36.38.2\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S7.T10.st1.36.38.2.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.2\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.2.1\" style=\"font-size:90%;\">Raw</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.3\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.3.1\" style=\"font-size:90%;\">DS (1375)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.4\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.4.1\" style=\"font-size:90%;\">T&amp;A</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.5\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.5.1\" style=\"font-size:90%;\">Raw</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.6\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.6.1\" style=\"font-size:90%;\">DS (145)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.7\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.7.1\" style=\"font-size:90%;\">T&amp;A</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.8\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.8.1\" style=\"font-size:90%;\">Raw</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.9\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.9.1\" style=\"font-size:90%;\">DS (565)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.10\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.10.1\" style=\"font-size:90%;\">T&amp;A</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S7.T10.st1.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S7.T10.st1.9.9.10\"><span class=\"ltx_text\" id=\"S7.T10.st1.9.9.10.1\" style=\"font-size:90%;\">LENS</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.4.4.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.5.5.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.6.6.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.7.7.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.8.8.8\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.9.9.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st1.18.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T10.st1.18.18.10\"><span class=\"ltx_text\" id=\"S7.T10.st1.18.18.10.1\" style=\"font-size:90%;\">BERT precision</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.10.10.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.11.11.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.12.12.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.13.13.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.14.14.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.15.15.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.16.16.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.17.17.8\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.18.18.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st1.27.27\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T10.st1.27.27.10\"><span class=\"ltx_text\" id=\"S7.T10.st1.27.27.10.1\" style=\"font-size:90%;\">BERT recall</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.19.19.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.20.20.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.21.21.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.22.22.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.23.23.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.24.24.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.25.25.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.26.26.8\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.27.27.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st1.36.36\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S7.T10.st1.36.36.10\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.36.10.1\" style=\"font-size:90%;\">BERT f1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.28.28.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.29.29.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.30.30.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.31.31.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.32.32.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.33.33.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.34.34.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.35.35.8\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.36.36.9\"></td>\n</tr>\n</tbody>\n</table>\n</figure>\n</div>\n<div class=\"ltx_flex_break\"></div>\n<div class=\"ltx_flex_cell ltx_flex_size_1\">\n<figure class=\"ltx_table ltx_flex_size_1 ltx_align_center\" id=\"S7.T10.st2\">\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">(b) </span>Simplicity</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S7.T10.st2.36\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S7.T10.st2.36.37.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S7.T10.st2.36.37.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T10.st2.36.37.1.2\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.37.1.2.1\" style=\"font-size:90%;\">All</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T10.st2.36.37.1.3\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.37.1.3.1\" style=\"font-size:90%;\">GPT-4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T10.st2.36.37.1.4\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.37.1.4.1\" style=\"font-size:90%;\">Control-T5</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st2.36.38.2\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S7.T10.st2.36.38.2.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.2\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.2.1\" style=\"font-size:90%;\">Raw</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.3\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.3.1\" style=\"font-size:90%;\">DS (157)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.4\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.4.1\" style=\"font-size:90%;\">T&amp;A</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.5\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.5.1\" style=\"font-size:90%;\">Raw</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.6\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.6.1\" style=\"font-size:90%;\">DS (130)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.7\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.7.1\" style=\"font-size:90%;\">T&amp;A</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.8\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.8.1\" style=\"font-size:90%;\">Raw</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.9\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.9.1\" style=\"font-size:90%;\">DS (27)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.10\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.10.1\" style=\"font-size:90%;\">T&amp;A</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S7.T10.st2.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S7.T10.st2.9.9.10\"><span class=\"ltx_text\" id=\"S7.T10.st2.9.9.10.1\" style=\"font-size:90%;\">LENS</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.4.4.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.5.5.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.6.6.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.7.7.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.8.8.8\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.9.9.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st2.18.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T10.st2.18.18.10\"><span class=\"ltx_text\" id=\"S7.T10.st2.18.18.10.1\" style=\"font-size:90%;\">BERT precision</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.10.10.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.11.11.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.12.12.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.13.13.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.14.14.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.15.15.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.16.16.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.17.17.8\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.18.18.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st2.27.27\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T10.st2.27.27.10\"><span class=\"ltx_text\" id=\"S7.T10.st2.27.27.10.1\" style=\"font-size:90%;\">BERT recall</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.19.19.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.20.20.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.21.21.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.22.22.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.23.23.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.24.24.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.25.25.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.26.26.8\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.27.27.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st2.36.36\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S7.T10.st2.36.36.10\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.36.10.1\" style=\"font-size:90%;\">BERT f1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.28.28.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.29.29.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.30.30.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.31.31.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.32.32.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.33.33.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.34.34.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.35.35.8\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.36.36.9\"></td>\n</tr>\n</tbody>\n</table>\n</figure>\n</div>\n</div>\n</figure>",
            "capture": "Table 10. Point-biserial correlation between sentence-level metrics scores and human ratings in single dimension"
        },
        "11": {
            "table_html": "<figure class=\"ltx_table ltx_flex_size_1 ltx_align_center\" id=\"S7.T10.st1\">\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">(a) </span>Meaning preservation</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S7.T10.st1.36\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S7.T10.st1.36.37.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S7.T10.st1.36.37.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T10.st1.36.37.1.2\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.37.1.2.1\" style=\"font-size:90%;\">All</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T10.st1.36.37.1.3\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.37.1.3.1\" style=\"font-size:90%;\">GPT-4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T10.st1.36.37.1.4\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.37.1.4.1\" style=\"font-size:90%;\">Control-T5</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st1.36.38.2\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S7.T10.st1.36.38.2.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.2\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.2.1\" style=\"font-size:90%;\">Raw</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.3\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.3.1\" style=\"font-size:90%;\">DS (1375)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.4\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.4.1\" style=\"font-size:90%;\">T&amp;A</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.5\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.5.1\" style=\"font-size:90%;\">Raw</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.6\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.6.1\" style=\"font-size:90%;\">DS (145)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.7\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.7.1\" style=\"font-size:90%;\">T&amp;A</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.8\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.8.1\" style=\"font-size:90%;\">Raw</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.9\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.9.1\" style=\"font-size:90%;\">DS (565)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st1.36.38.2.10\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.38.2.10.1\" style=\"font-size:90%;\">T&amp;A</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S7.T10.st1.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S7.T10.st1.9.9.10\"><span class=\"ltx_text\" id=\"S7.T10.st1.9.9.10.1\" style=\"font-size:90%;\">LENS</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.4.4.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.5.5.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.6.6.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.7.7.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.8.8.8\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st1.9.9.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st1.18.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T10.st1.18.18.10\"><span class=\"ltx_text\" id=\"S7.T10.st1.18.18.10.1\" style=\"font-size:90%;\">BERT precision</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.10.10.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.11.11.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.12.12.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.13.13.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.14.14.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.15.15.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.16.16.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.17.17.8\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.18.18.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st1.27.27\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T10.st1.27.27.10\"><span class=\"ltx_text\" id=\"S7.T10.st1.27.27.10.1\" style=\"font-size:90%;\">BERT recall</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.19.19.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.20.20.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.21.21.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.22.22.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.23.23.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.24.24.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.25.25.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.26.26.8\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st1.27.27.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st1.36.36\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S7.T10.st1.36.36.10\"><span class=\"ltx_text\" id=\"S7.T10.st1.36.36.10.1\" style=\"font-size:90%;\">BERT f1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.28.28.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.29.29.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.30.30.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.31.31.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.32.32.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.33.33.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.34.34.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.35.35.8\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st1.36.36.9\"></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "(a) Meaning preservation"
        },
        "12": {
            "table_html": "<figure class=\"ltx_table ltx_flex_size_1 ltx_align_center\" id=\"S7.T10.st2\">\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">(b) </span>Simplicity</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S7.T10.st2.36\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S7.T10.st2.36.37.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S7.T10.st2.36.37.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T10.st2.36.37.1.2\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.37.1.2.1\" style=\"font-size:90%;\">All</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T10.st2.36.37.1.3\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.37.1.3.1\" style=\"font-size:90%;\">GPT-4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S7.T10.st2.36.37.1.4\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.37.1.4.1\" style=\"font-size:90%;\">Control-T5</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st2.36.38.2\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S7.T10.st2.36.38.2.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.2\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.2.1\" style=\"font-size:90%;\">Raw</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.3\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.3.1\" style=\"font-size:90%;\">DS (157)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.4\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.4.1\" style=\"font-size:90%;\">T&amp;A</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.5\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.5.1\" style=\"font-size:90%;\">Raw</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.6\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.6.1\" style=\"font-size:90%;\">DS (130)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.7\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.7.1\" style=\"font-size:90%;\">T&amp;A</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.8\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.8.1\" style=\"font-size:90%;\">Raw</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.9\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.9.1\" style=\"font-size:90%;\">DS (27)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S7.T10.st2.36.38.2.10\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.38.2.10.1\" style=\"font-size:90%;\">T&amp;A</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S7.T10.st2.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S7.T10.st2.9.9.10\"><span class=\"ltx_text\" id=\"S7.T10.st2.9.9.10.1\" style=\"font-size:90%;\">LENS</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.4.4.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.5.5.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.6.6.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.7.7.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.8.8.8\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S7.T10.st2.9.9.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st2.18.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T10.st2.18.18.10\"><span class=\"ltx_text\" id=\"S7.T10.st2.18.18.10.1\" style=\"font-size:90%;\">BERT precision</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.10.10.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.11.11.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.12.12.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.13.13.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.14.14.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.15.15.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.16.16.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.17.17.8\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.18.18.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st2.27.27\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T10.st2.27.27.10\"><span class=\"ltx_text\" id=\"S7.T10.st2.27.27.10.1\" style=\"font-size:90%;\">BERT recall</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.19.19.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.20.20.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.21.21.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.22.22.4\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.23.23.5\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.24.24.6\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.25.25.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.26.26.8\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S7.T10.st2.27.27.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T10.st2.36.36\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S7.T10.st2.36.36.10\"><span class=\"ltx_text\" id=\"S7.T10.st2.36.36.10.1\" style=\"font-size:90%;\">BERT f1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.28.28.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.29.29.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.30.30.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.31.31.4\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.32.32.5\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.33.33.6\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.34.34.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.35.35.8\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S7.T10.st2.36.36.9\"></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "(b) Simplicity"
        },
        "13": {
            "table_html": "<figure class=\"ltx_table\" id=\"S7.T11\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S7.T11.20.1.1\" style=\"font-size:90%;\">Table 11</span>. </span><span class=\"ltx_text\" id=\"S7.T11.21.2\" style=\"font-size:90%;\">Corpus-level metrics scores for different models</span></figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S7.T11.18\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S7.T11.18.19.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S7.T11.18.19.1.1\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S7.T11.18.19.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T11.18.19.1.2.1\">Model</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T11.18.19.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T11.18.19.1.3.1\">SARI</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T11.18.19.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T11.18.19.1.4.1\">BLEU</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S7.T11.18.19.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T11.18.19.1.5.1\">FKGL</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S7.T11.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S7.T11.3.3.4\">Turk</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S7.T11.3.3.5\">Control-T5</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S7.T11.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S7.T11.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S7.T11.3.3.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T11.6.6\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S7.T11.6.6.4\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T11.6.6.5\">GPT-4</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S7.T11.4.4.1\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S7.T11.5.5.2\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S7.T11.6.6.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T11.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S7.T11.9.9.4\">ASSET</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S7.T11.9.9.5\">Control-T5</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S7.T11.7.7.1\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S7.T11.8.8.2\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S7.T11.9.9.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T11.12.12\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S7.T11.12.12.4\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S7.T11.12.12.5\">GPT-4</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S7.T11.10.10.1\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S7.T11.11.11.2\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S7.T11.12.12.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T11.15.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S7.T11.15.15.4\">Newsela</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S7.T11.15.15.5\">Control-T5</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S7.T11.13.13.1\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S7.T11.14.14.2\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S7.T11.15.15.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T11.18.18\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_bb\" id=\"S7.T11.18.18.4\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S7.T11.18.18.5\">GPT-4</th>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S7.T11.16.16.1\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S7.T11.17.17.2\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S7.T11.18.18.3\"></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 11. Corpus-level metrics scores for different models"
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.04963v1_figure_1.png",
            "caption": "Figure 1. GPT-4 prompt engineering; the identified best prompt on the ASSET validation set is illustrated here."
        },
        "2": {
            "figure_path": "2403.04963v1_figure_2.png",
            "caption": "Figure 2. Annotation interface in error-based human assessment"
        },
        "3": {
            "figure_path": "2403.04963v1_figure_3.png",
            "caption": "Figure 3. Label-wise distribution: Each bar indicates the number of sentences containing a specific type of error, with error frequency ranging from 1111 to 3333."
        },
        "4": {
            "figure_path": "2403.04963v1_figure_4.png",
            "caption": "(a) GPT-4"
        },
        "5": {
            "figure_path": "2403.04963v1_figure_5.png",
            "caption": "(b) Control-T5"
        },
        "6": {
            "figure_path": "2403.04963v1_figure_6.png",
            "caption": "(a) Turk style + Few-shot + Single ref"
        },
        "7": {
            "figure_path": "2403.04963v1_figure_7.png",
            "caption": "(b) ASSET style + Few-shot + Single ref"
        },
        "8": {
            "figure_path": "2403.04963v1_figure_8.png",
            "caption": "(c) Newsela style + Few-shot + Multi refs"
        },
        "9": {
            "figure_path": "2403.04963v1_figure_9.png",
            "caption": "Figure 6. Annotation guidelines in Task 2222. We used the same examples as provided in (Kriz et al., 2019; Jiang et al., 2020)."
        }
    },
    "references": [
        {
            "1": {
                "title": "Optuna: A Next-Generation Hyperparameter Optimization Framework. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (Anchorage, AK, USA) (KDD \u201919). Association for Computing Machinery, New York, NY, USA, 2623\u20132631.",
                "author": "Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. 2019.",
                "venue": "https://doi.org/10.1145/3292500.3330701",
                "url": null
            }
        },
        {
            "2": {
                "title": "Learning How to Simplify From Explicit Labeling of Complex-Simplified Text Pairs. In Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers), Greg Kondrak and Taro Watanabe (Eds.). Asian Federation of Natural Language Processing, Taipei, Taiwan, 295\u2013305.",
                "author": "Fernando Alva-Manchego, Joachim Bingel, Gustavo Paetzold, Carolina Scarton, and Lucia Specia. 2017.",
                "venue": "https://aclanthology.org/I17-1030",
                "url": null
            }
        },
        {
            "3": {
                "title": "ASSET: A Dataset for Tuning and Evaluation of Sentence Simplification Models with Multiple Rewriting Transformations. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault (Eds.). Association for Computational Linguistics, Online, 4668\u20134679.",
                "author": "Fernando Alva-Manchego, Louis Martin, Antoine Bordes, Carolina Scarton, Beno\u00eet Sagot, and Lucia Specia. 2020.",
                "venue": "https://doi.org/10.18653/v1/2020.acl-main.424",
                "url": null
            }
        },
        {
            "4": {
                "title": "EASSE: Easier Automatic Sentence Simplification Evaluation. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations, Sebastian Pad\u00f3 and Ruihong Huang (Eds.). Association for Computational Linguistics, Hong Kong, China, 49\u201354.",
                "author": "Fernando Alva-Manchego, Louis Martin, Carolina Scarton, and Lucia Specia. 2019.",
                "venue": "https://doi.org/10.18653/v1/D19-3009",
                "url": null
            }
        },
        {
            "5": {
                "title": "The (Un)Suitability of Automatic Evaluation Metrics for Text Simplification.",
                "author": "Fernando Alva-Manchego, Carolina Scarton, and Lucia Specia. 2021.",
                "venue": "Computational Linguistics 47, 4 (Dec. 2021), 861\u2013889.",
                "url": null
            }
        },
        {
            "6": {
                "title": "Language technologies applied to document simplification for helping autistic people.",
                "author": "Eduard Barbu, M. Teresa Mart\u00edn-Valdivia, Eugenio Mart\u00ednez-C\u00e1mara, and L. Alfonso Ure\u00f1a-L\u00f3pez. 2015.",
                "venue": "Expert Systems with Applications 42, 12 (2015), 5076\u20135086.",
                "url": null
            }
        },
        {
            "7": {
                "title": "Simplifying Text for Language-Impaired Readers. In Ninth Conference of the European Chapter of the Association for Computational Linguistics, Henry S. Thompson and Alex Lascarides (Eds.). Association for Computational Linguistics, Bergen, Norway, 269\u2013270.",
                "author": "John Carroll, Guido Minnen, Darren Pearce, Yvonne Canning, Siobhan Devlin, and John Tait. 1999.",
                "venue": "https://aclanthology.org/E99-1042",
                "url": null
            }
        },
        {
            "8": {
                "title": "CombiNMT: An Exploration into Neural Text Simplification Models. In Proceedings of the Twelfth Language Resources and Evaluation Conference, Nicoletta Calzolari, Fr\u00e9d\u00e9ric B\u00e9chet, Philippe Blache, Khalid Choukri, Christopher Cieri, Thierry Declerck, Sara Goggi, Hitoshi Isahara, Bente Maegaard, Joseph Mariani, H\u00e9l\u00e8ne Mazo, Asuncion Moreno, Jan Odijk, and Stelios Piperidis (Eds.). European Language Resources Association, Marseille, France, 5588\u20135594.",
                "author": "Michael Cooper and Matthew Shardlow. 2020.",
                "venue": "https://aclanthology.org/2020.lrec-1.686",
                "url": null
            }
        },
        {
            "9": {
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association for Computational Linguistics, Minneapolis, Minnesota, 4171\u20134186.",
                "author": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.",
                "venue": "https://doi.org/10.18653/v1/N19-1423",
                "url": null
            }
        },
        {
            "10": {
                "title": "Sentence Simplification via Large Language Models.",
                "author": "Yutao Feng, Jipeng Qiang, Yun Li, Yunhao Yuan, and Yi Zhu. 2023.",
                "venue": "",
                "url": null
            }
        },
        {
            "11": {
                "title": "The Design of Experiments.",
                "author": "Ronald Aylmer Fisher. 1935.",
                "venue": "Oliver and Boyd, United Kingdom.",
                "url": null
            }
        },
        {
            "12": {
                "title": "Statistical Methods in Education and Psychology (3 ed.).",
                "author": "Gene V. Glass and Kenneth D. Hopkins. 1995.",
                "venue": "Allyn and Bacon.",
                "url": null
            }
        },
        {
            "13": {
                "title": "On the Blind Spots of Model-Based Evaluation Metrics for Text Generation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics, Toronto, Canada, 12067\u201312097.",
                "author": "Tianxing He, Jingyu Zhang, Tianle Wang, Sachin Kumar, Kyunghyun Cho, James Glass, and Yulia Tsvetkov. 2023.",
                "venue": "https://doi.org/10.18653/v1/2023.acl-long.674",
                "url": null
            }
        },
        {
            "14": {
                "title": "Dancing Between Success and Failure: Edit-level Simplification Evaluation using SALSA. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore, 3466\u20133495.",
                "author": "David Heineman, Yao Dou, Mounica Maddela, and Wei Xu. 2023.",
                "venue": "https://doi.org/10.18653/v1/2023.emnlp-main.211",
                "url": null
            }
        },
        {
            "15": {
                "title": "Neural CRF Model for Sentence Alignment in Text Simplification. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault (Eds.). Association for Computational Linguistics, Online, 7943\u20137960.",
                "author": "Chao Jiang, Mounica Maddela, Wuwei Lan, Yang Zhong, and Wei Xu. 2020.",
                "venue": "https://doi.org/10.18653/v1/2020.acl-main.709",
                "url": null
            }
        },
        {
            "16": {
                "title": "BLESS: Benchmarking Large Language Models on Sentence Simplification. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore, 13291\u201313309.",
                "author": "Tannon Kew, Alison Chi, Laura V\u00e1squez-Rodr\u00edguez, Sweta Agrawal, Dennis Aumiller, Fernando Alva-Manchego, and Matthew Shardlow. 2023.",
                "venue": "https://doi.org/10.18653/v1/2023.emnlp-main.821",
                "url": null
            }
        },
        {
            "17": {
                "title": "Derivation of new readability formulas (automated readability index, fog count and Flesch reading ease formula) for Navy enlisted personnel.",
                "author": "J. P. Kincaid, R. P. Fishburne, R. L. Rogers, and B. S. Chissom. 1975.",
                "venue": "Technical Report 8-75. Chief of Naval Technical Training: Naval Air Station Memphis.",
                "url": null
            }
        },
        {
            "18": {
                "title": "Complexity-Weighted Loss and Diverse Reranking for Sentence Simplification. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association for Computational Linguistics, Minneapolis, Minnesota, 3137\u20133147.",
                "author": "Reno Kriz, Jo\u00e3o Sedoc, Marianna Apidianaki, Carolina Zheng, Gaurav Kumar, Eleni Miltsakaki, and Chris Callison-Burch. 2019.",
                "venue": "https://doi.org/10.18653/v1/N19-1317",
                "url": null
            }
        },
        {
            "19": {
                "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault (Eds.). Association for Computational Linguistics, Online, 7871\u20137880.",
                "author": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020.",
                "venue": "https://doi.org/10.18653/v1/2020.acl-main.703",
                "url": null
            }
        },
        {
            "20": {
                "title": "The Expected Value of a Point-Biserial (or Similar) Correlation.",
                "author": "John Linacre. 2008.",
                "venue": "Rasch Measurement Transactions 22, 1 (2008), 1154.",
                "url": null
            }
        },
        {
            "21": {
                "title": "G-Eval: NLG Evaluation using Gpt-4 with Better Human Alignment. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore, 2511\u20132522.",
                "author": "Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. 2023.",
                "venue": "https://doi.org/10.18653/v1/2023.emnlp-main.153",
                "url": null
            }
        },
        {
            "22": {
                "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach.",
                "author": "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.",
                "venue": "",
                "url": null
            }
        },
        {
            "23": {
                "title": "Controllable Text Simplification with Explicit Paraphrasing. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-Tur, Iz Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou (Eds.). Association for Computational Linguistics, Online, 3536\u20133553.",
                "author": "Mounica Maddela, Fernando Alva-Manchego, and Wei Xu. 2021.",
                "venue": "https://doi.org/10.18653/v1/2021.naacl-main.277",
                "url": null
            }
        },
        {
            "24": {
                "title": "LENS: A Learnable Evaluation Metric for Text Simplification. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics, Toronto, Canada, 16383\u201316408.",
                "author": "Mounica Maddela, Yao Dou, David Heineman, and Wei Xu. 2023.",
                "venue": "https://doi.org/10.18653/v1/2023.acl-long.905",
                "url": null
            }
        },
        {
            "25": {
                "title": "Controllable Sentence Simplification. In Proceedings of the Twelfth Language Resources and Evaluation Conference, Nicoletta Calzolari, Fr\u00e9d\u00e9ric B\u00e9chet, Philippe Blache, Khalid Choukri, Christopher Cieri, Thierry Declerck, Sara Goggi, Hitoshi Isahara, Bente Maegaard, Joseph Mariani, H\u00e9l\u00e8ne Mazo, Asuncion Moreno, Jan Odijk, and Stelios Piperidis (Eds.). European Language Resources Association, Marseille, France, 4689\u20134698.",
                "author": "Louis Martin, \u00c9ric de la Clergerie, Beno\u00eet Sagot, and Antoine Bordes. 2020.",
                "venue": "https://aclanthology.org/2020.lrec-1.577",
                "url": null
            }
        },
        {
            "26": {
                "title": "MUSS: Multilingual Unsupervised Sentence Simplification by Mining Paraphrases. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, Nicoletta Calzolari, Fr\u00e9d\u00e9ric B\u00e9chet, Philippe Blache, Khalid Choukri, Christopher Cieri, Thierry Declerck, Sara Goggi, Hitoshi Isahara, Bente Maegaard, Joseph Mariani, H\u00e9l\u00e8ne Mazo, Jan Odijk, and Stelios Piperidis (Eds.). European Language Resources Association, Marseille, France, 1651\u20131664.",
                "author": "Louis Martin, Angela Fan, \u00c9ric de la Clergerie, Antoine Bordes, and Beno\u00eet Sagot. 2022.",
                "venue": "https://aclanthology.org/2022.lrec-1.176",
                "url": null
            }
        },
        {
            "27": {
                "title": "Controllable Text Simplification with Lexical Constraint Loss. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, Fernando Alva-Manchego, Eunsol Choi, and Daniel Khashabi (Eds.). Association for Computational Linguistics, Florence, Italy, 260\u2013266.",
                "author": "Daiki Nishihara, Tomoyuki Kajiwara, and Yuki Arase. 2019.",
                "venue": "https://doi.org/10.18653/v1/P19-2036",
                "url": null
            }
        },
        {
            "28": {
                "title": "GPT-4 Technical Report.",
                "author": "OpenAI. 2023.",
                "venue": "",
                "url": null
            }
        },
        {
            "29": {
                "title": "Lexical Simplification for Non-Native English Speakers.",
                "author": "Gustavo Henrique Paetzold. 2016.",
                "venue": "Ph.\u2009D. Dissertation. University of Sheffield.",
                "url": null
            }
        },
        {
            "30": {
                "title": "Bleu: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, Pierre Isabelle, Eugene Charniak, and Dekang Lin (Eds.). Association for Computational Linguistics, Philadelphia, Pennsylvania, USA, 311\u2013318.",
                "author": "Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.",
                "venue": "https://doi.org/10.3115/1073083.1073135",
                "url": null
            }
        },
        {
            "31": {
                "title": "POTATO: The Portable Text Annotation Tool. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Wanxiang Che and Ekaterina Shutova (Eds.). Association for Computational Linguistics, Abu Dhabi, UAE, 327\u2013337.",
                "author": "Jiaxin Pei, Aparna Ananthasubramaniam, Xingyao Wang, Naitian Zhou, Apostolos Dedeloudis, Jackson Sargent, and David Jurgens. 2022.",
                "venue": "https://doi.org/10.18653/v1/2022.emnlp-demos.33",
                "url": null
            }
        },
        {
            "32": {
                "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.",
                "author": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020.",
                "venue": "Journal of Machine Learning Research 21, 140 (2020), 1\u201367.",
                "url": null
            }
        },
        {
            "33": {
                "title": "Simplify or Help? Text Simplification Strategies for People with Dyslexia. In Proceedings of the 10th International Cross-Disciplinary Conference on Web Accessibility (Rio de Janeiro, Brazil) (W4A \u201913). Association for Computing Machinery, New York, NY, USA, Article 15, 10 pages.",
                "author": "Luz Rello, Ricardo Baeza-Yates, Stefan Bott, and Horacio Saggion. 2013a.",
                "venue": "https://doi.org/10.1145/2461121.2461126",
                "url": null
            }
        },
        {
            "34": {
                "title": "DysWebxia 2.0! More Accessible Text for People with Dyslexia. In Proceedings of the 10th International Cross-Disciplinary Conference on Web Accessibility (Rio de Janeiro, Brazil) (W4A \u201913). Association for Computing Machinery, New York, NY, USA, Article 25, 2 pages.",
                "author": "Luz Rello, Clara Bayarri, Azuki G\u00f2rriz, Ricardo Baeza-Yates, Saurabh Gupta, Gaurang Kanvinde, Horacio Saggion, Stefan Bott, Roberto Carlini, and Vasile Topac. 2013b.",
                "venue": "https://doi.org/10.1145/2461121.2461150",
                "url": null
            }
        },
        {
            "35": {
                "title": "Controllable Sentence Simplification with a Unified Text-to-Text Transfer Transformer. In Proceedings of the 14th International Conference on Natural Language Generation, Anya Belz, Angela Fan, Ehud Reiter, and Yaji Sripada (Eds.). Association for Computational Linguistics, Aberdeen, Scotland, UK, 341\u2013352.",
                "author": "Kim Cheng Sheang and Horacio Saggion. 2021.",
                "venue": "https://doi.org/10.18653/v1/2021.inlg-1.38",
                "url": null
            }
        },
        {
            "36": {
                "title": "Intraclass correlations: Uses in assessing rater reliability.",
                "author": "Patrick Shrout and Joseph Fleiss. 1979.",
                "venue": "Psychological bulletin 86 (03 1979), 420\u20138.",
                "url": null
            }
        },
        {
            "37": {
                "title": "BLEU is Not Suitable for the Evaluation of Text Simplification. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun\u2019ichi Tsujii (Eds.). Association for Computational Linguistics, Brussels, Belgium, 738\u2013744.",
                "author": "Elior Sulem, Omri Abend, and Ari Rappoport. 2018a.",
                "venue": "https://doi.org/10.18653/v1/D18-1081",
                "url": null
            }
        },
        {
            "38": {
                "title": "Simple and Effective Text Simplification Using Semantic and Neural Methods. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Iryna Gurevych and Yusuke Miyao (Eds.). Association for Computational Linguistics, Melbourne, Australia, 162\u2013173.",
                "author": "Elior Sulem, Omri Abend, and Ari Rappoport. 2018b.",
                "venue": "https://doi.org/10.18653/v1/P18-1016",
                "url": null
            }
        },
        {
            "39": {
                "title": "Flesch-Kincaid is Not a Text Simplification Evaluation Metric. In Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), Antoine Bosselut, Esin Durmus, Varun Prashant Gangal, Sebastian Gehrmann, Yacine Jernite, Laura Perez-Beltrachini, Samira Shaikh, and Wei Xu (Eds.). Association for Computational Linguistics, Online, 1\u201314.",
                "author": "Teerapaun Tanprasert and David Kauchak. 2021.",
                "venue": "https://doi.org/10.18653/v1/2021.gem-1.1",
                "url": null
            }
        },
        {
            "40": {
                "title": "SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python.",
                "author": "Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, St\u00e9fan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, C J Carey, \u0130lhan Polat, Yu Feng, Eric W. Moore, Jake VanderPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero,\nCharles R. Harris, Anne M. Archibald, Ant\u00f4nio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1.0 Contributors. 2020.",
                "venue": "Nature Methods 17 (2020), 261\u2013272.",
                "url": null
            }
        },
        {
            "41": {
                "title": "Document-Level Machine Translation with Large Language Models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore, 16646\u201316661.",
                "author": "Longyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui Zhang, Dian Yu, Shuming Shi, and Zhaopeng Tu. 2023.",
                "venue": "https://doi.org/10.18653/v1/2023.emnlp-main.1036",
                "url": null
            }
        },
        {
            "42": {
                "title": "Sentence Simplification by Monolingual Machine Translation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Haizhou Li, Chin-Yew Lin, Miles Osborne, Gary Geunbae Lee, and Jong C. Park (Eds.). Association for Computational Linguistics, Jeju Island, Korea, 1015\u20131024.",
                "author": "Sander Wubben, Antal van den Bosch, and Emiel Krahmer. 2012.",
                "venue": "https://aclanthology.org/P12-1107",
                "url": null
            }
        },
        {
            "43": {
                "title": "Problems in Current Text Simplification Research: New Data Can Help.",
                "author": "Wei Xu, Chris Callison-Burch, and Courtney Napoles. 2015.",
                "venue": "Transactions of the Association for Computational Linguistics 3 (2015), 283\u2013297.",
                "url": null
            }
        },
        {
            "44": {
                "title": "Optimizing Statistical Machine Translation for Text Simplification.",
                "author": "Wei Xu, Courtney Napoles, Ellie Pavlick, Quanze Chen, and Chris Callison-Burch. 2016.",
                "venue": "Transactions of the Association for Computational Linguistics 4 (2016), 401\u2013415.",
                "url": null
            }
        },
        {
            "45": {
                "title": "BERTScore: Evaluating Text Generation with BERT.",
                "author": "Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020.",
                "venue": "",
                "url": null
            }
        },
        {
            "46": {
                "title": "Sentence Simplification with Deep Reinforcement Learning. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, Martha Palmer, Rebecca Hwa, and Sebastian Riedel (Eds.). Association for Computational Linguistics, Copenhagen, Denmark, 584\u2013594.",
                "author": "Xingxing Zhang and Mirella Lapata. 2017.",
                "venue": "https://doi.org/10.18653/v1/D17-1062",
                "url": null
            }
        },
        {
            "47": {
                "title": "Integrating Transformer and Paraphrase Rules for Sentence Simplification. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun\u2019ichi Tsujii (Eds.). Association for Computational Linguistics, Brussels, Belgium, 3164\u20133173.",
                "author": "Sanqiang Zhao, Rui Meng, Daqing He, Andi Saptono, and Bambang Parmanto. 2018.",
                "venue": "https://doi.org/10.18653/v1/D18-1355",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.04963v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.1",
            "2.2"
        ],
        "methodology_sections": [
            "4",
            "4.1",
            "4.1.1",
            "4.1.2",
            "4.2"
        ],
        "main_experiment_and_results_sections": [
            "3",
            "3.1",
            "3.2",
            "5",
            "5.1",
            "5.1.2",
            "5.2",
            "5.2.1",
            "5.2.2",
            "6",
            "6.1",
            "6.1.1",
            "6.1.2",
            "6.1.3",
            "6.2",
            "6.3",
            "6.3.1",
            "6.3.2",
            "6.3.3",
            "7",
            "7.1",
            "7.1.1",
            "7.1.2",
            "7.2",
            "7.2.1",
            "7.2.2",
            "7.2.3",
            "7.3",
            "7.4"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4.1.1",
            "4.1.2",
            "5.1.2",
            "6.1.3",
            "7"
        ]
    },
    "research_context": {
        "paper_id": "2403.04963v1",
        "paper_title": "An In-depth Evaluation of GPT-4 in Sentence Simplification with Error-based Human Assessment",
        "research_background": "**Motivation:**\nThe motivation behind this paper is to gain a deeper understanding of large language models' (LLMs) performance in sentence simplification tasks, particularly focusing on GPT-4. Sentence simplification serves an important function by making text more accessible to various populations, such as non-native speakers, individuals with aphasia, dyslexia, or autism. Recent studies using LLMs have shown promising results, but there is uncertainty about the reliability of existing automatic metrics and human evaluation methods for assessing these models' simplifications. The paper aims to address these concerns by establishing a more effective evaluation framework.\n\n**Research Problem:**\nThe primary research problem is two-fold:\n1. Assessing whether current automatic metrics are genuinely effective for evaluating the sentence simplification abilities of LLMs like GPT-4.\n2. Developing a more reliable and interpretable human evaluation framework for sentence simplification that can capture subtle yet critical aspects of simplification quality that conventional methods and existing metrics might miss.\n\n**Relevant Prior Work:**\n1. **Sentence Simplification Techniques:**\n   - Sequence-to-sequence models (Zhang and Lapata, 2017; Zhao et al., 2018; Nishihara et al., 2019; Martin et al., 2020).\n   - Rule-based and statistical machine translation-based systems (Sulem et al., 2018b; Wubben et al., 2012; Xu et al., 2016).\n\n2. **Evaluation of LLMs in Simplification:**\n   - Studies evaluating LLM performance in sentence simplification through automatic scoring and conventional human evaluations (Feng et al., 2023; Kew et al., 2023).\n   - Conventional human evaluation metrics focusing on fluency, meaning preservation, and simplicity (Kriz et al., 2019; Jiang et al., 2020; Alva-Manchego et al., 2021; Maddela et al., 2021).\n\n3. **Challenges in Current Evaluation Methods:**\n   - Uncertainty around the suitability of existing automatic metrics for LLMs, despite their variable efficacy in traditional systems.\n   - The need for more depth in human evaluations to capture the nuanced quality of LLM-generated simplifications (Heineman et al., 2023).\n\n4. **Recent Advances in Human Evaluation:**\n   - Proposals for detailed human evaluation frameworks focusing on linguistically-based success and failure types (Heineman et al., 2023), though these can be overly intricate and lead to low consistency among annotators.\n\nBy building on these studies, the paper aims to enhance the evaluation methods for sentence simplification using LLMs like GPT-4, providing more reliable and interpretable assessments than existing metrics and evaluation frameworks.",
        "methodology": "The methodology section describes the proposed approach to enhancing the performance of the GPT-4 model in sentence simplification and compares it to the state-of-the-art supervised model, Control-T5.\n\n1. **Enhancement of GPT-4**: Significant effort was put into prompt engineering to improve GPT-4's ability to simplify sentences. This involved crafting the optimal prompts that guide the model to produce simpler versions of given sentences.\n\n2. **Comparative Analysis**: To provide a benchmark for GPT-4's performance, the state-of-the-art (SOTA) supervised model, Control-T5, was replicated. This allows for a direct comparison between the outputs of GPT-4 and Control-T5.\n\n3. **Performance Measurement**: The evaluation of sentence simplification quality is based on the SARI metric. SARI is a well-regarded, statistic-based metric that assesses a model by comparing its simplified outputs with both the original and reference sentences. SARI focuses on three key operations: adding, keeping, and deleting words, and computes separate scores for each. \n\n4. **Meta-evaluation**: Section 7 of the paper (though not provided in the excerpt) purportedly contains a meta-evaluation confirming that the SARI score correlates well with human evaluations. This affirms the reliability of SARI as an accurate measure of simplification quality.\n\nKey Innovations:\n- **Prompt Engineering for GPT-4**: The novel aspect here is the extensive effort in prompt engineering tailored specifically for optimizing GPT-4's performance in sentence simplification.\n- **Use of SARI Metric**: The methodology\u2019s focus on SARI scores for the systematic evaluation ensures a standardized and recognized assessment metric for simplification quality. \n\nIn essence, the methodology combines advanced model engineering with rigorous comparative analysis and evaluation metrics to improve and assess sentence simplification performance.",
        "main_experiment_and_results": "### Main Experiment Setup\n\n#### Datasets\n- **Training Datasets:** The same training datasets as employed in the original Control-T5 study.\n- **Evaluation Datasets:** Standard datasets for English sentence simplification to evaluate the models.\n\n#### Baselines\n- **Control-T5:** The state-of-the-art (SOTA) supervised model for sentence simplification, replicated for direct comparison.\n- **GPT-4:** Evaluated to compare its performance with the benchmark Control-T5 model.\n\n#### Evaluation Metrics\n- A combination of automatic metrics and human assessments was used to gauge performance:\n  - **Automatic Metrics:**\n    - **SARI:** Evaluates the quality of the simplified output by comparing it to human references.\n    - **BLEU:** Measures the precision of the generated sentences against reference sentences.\n  - **Human Assessment:** \n    - **Error-based Human Assessment:** A human evaluation technique to identify and assess errors in sentences simplified by the models.\n\n### Main Experimental Results\n\n- **Performance Comparison:**\n  - **GPT-4:** Showed superior performance on sentence simplification tasks, outperforming Control-T5 in both automatic metrics (SARI and BLEU) and human assessment.\n  - **Control-T5:** While effective, it lagged behind GPT-4 in terms of all measured aspects.\n\nSpecific numerical results and detailed human evaluation insights were not provided in the summary but the performance trend clearly favors GPT-4. The inclusion of error-based human assessment provided a robust and comprehensive evaluation of the simplification quality."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To optimize GPT-4\u2019s sentence simplification capabilities through prompt engineering.",
            "experiment_process": "We conducted prompt engineering based on three principal components: 1) Dataset-Specific Instructions: Instructions tailored to each dataset\u2019s unique features. For Turk and ASSET datasets, instructions were based on guidelines provided to crowd-workers. For Newsela dataset, instructions followed Turk and ASSET styles, emphasizing deletion. Detailed instructions are in Appendix A.1. 2) Varied Number of Examples: Zero, one, and three examples were attached to the instructions. 3) Varied Number of References: Single or multiple references (three) were used in the examples. For Turk and ASSET, one high-quality reference was manually selected, while for Newsela, multiple references were taken from different simplicity levels of the same source sentence. These components were integrated into prompts, resulting in various prompt configurations, which were then applied to each validation set. The highest SARI score prompts were designated as 'Best Prompts'. Detailed configurations are in Table 2 and Appendix A.1. Using the best prompts, simplification outputs were generated from the respective test sets.",
            "result_discussion": "Prompt engineering significantly improves GPT-4\u2019s sentence simplification performance. Prompts with the highest SARI scores across three validation sets (Turk, ASSET, Newsela) outperformed those with the lowest SARI scores. The best prompts aligned with the instructional style of the respective dataset and used three few-shot examples. The number of simplification references varied: Turk and ASSET performed better with a single reference, whereas Newsela benefited from multiple references due to the need for preserving meaning amidst deletions. Overall, prompt engineering led to significant increases in SARI scores.",
            "ablation_id": "2403.04963v1.No1"
        },
        {
            "research_objective": "To assess the effectiveness and interpretability of an error-based human evaluation framework for evaluating sentence simplification outputs of LLMs.",
            "experiment_process": "An error-based human evaluation framework was designed to evaluate key failures in sentence simplification by LLMs, encompassing seven types of errors: Lack of Simplicity (Lexical and Structural), Altered Meaning (Lexical and Structural), Coreference, Repetition, and Hallucination. The preliminary investigation on ChatGPT-3.5 simplification outputs on the ASSET dataset identified additional errors not commonly addressed in previous studies. Categories were refined to focus on outcome-based assessments. Annotators evaluated whether transformations simplified while preserving the meaning, accurately preserving named entities, and avoiding repetition or irrelevant content. This facilitated straightforward classification without requiring linguistic expertise. Errors and their types were exemplified and defined in Table 3.",
            "result_discussion": "The framework revealed differences in error tendencies between GPT-4 and Control-T5. GPT-4 predominantly showed errors in Lack of Simplicity-Lexical and Altered Meaning-Lexical, indicating a tendency to use complex expressions or misinterpret meanings lexically. Control-T5 exhibited a broader error range, particularly in Altered Meaning-Lexical, Coreference, and Hallucination, suggesting difficulties in preserving lexical meanings, referential clarity, and avoiding irrelevant information. Generally, both models had more lexical errors (Lack of Simplicity-Lexical, Altered Meaning-Lexical, Coreference, Repetition) than structural errors. In Newsela dataset, Control-T5 showed significantly more Coreference errors, possibly due to overfitting during fine-tuning.",
            "ablation_id": "2403.04963v1.No2"
        }
    ]
}