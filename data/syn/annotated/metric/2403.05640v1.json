{
    "title": "Generating Hard-Negative Out-of-Scope Data with ChatGPT for Intent Classification",
    "abstract": "Intent classifiers must be able to distinguish when a user\u2019s utterance does not belong to any supported intent to avoid producing incorrect and unrelated system responses. Although out-of-scope (OOS) detection for intent classifiers has been studied, previous work has not yet studied changes in classifier performance against hard-negative out-of-scope utterances (i.e., inputs that share common features with in-scope data, but are actually out-of-scope).\n\nWe present an automated technique to generate hard-negative OOS data using ChatGPT. We use our technique to build five new hard-negative OOS datasets and evaluate each against three benchmark intent classifiers. We show that classifiers struggle to correctly identify hard-negative OOS utterances more than general OOS utterances. Finally, we show that incorporating hard-negative OOS data for training improves model robustness when detecting hard-negative OOS data and general OOS data. Our technique, datasets, and evaluation address an important void in the field, offering a straightforward and inexpensive way to collect hard-negative OOS data and improve intent classifiers\u2019 robustness.\n\nKeywords: intent classification, out-of-scope, hard-negative data, data generation",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1.   Introduction",
            "text": "Task-oriented dialog systems rely on robust intent classification models to produce appropriate responses based on the user utterances. During deployment, the intent classifiers need to not only accurately classify the user utterances, but also must identify if user utterances do not belong to any supported intents. Brittle intent classifiers that fail to reliably distinguish OOS (out-of-scope) utterances from the INS (in-scope) utterances ultimately lead to poor user experiences, wasted time and resources, and potential safety concerns. Thus, it is imperative to develop techniques to ensure robustness against OOS utterances.\n\nWhen developing intent classifiers, developers typically begin by collecting and labelling a large amount of INS training data often acquired through crowd-sourcing. Collecting OOS datasets to improve the classifier\u2019s OOS detection capability is not a common practice. Currently, there is a dearth of large public OOS datasets, and the difficulty posed to intent classifiers has not been rigorously examined. General OOS datasets typically contain mostly samples that exhibit minimal similarity with the INS samples. While many models can distinguish such OOS samples and the INS samples during testing, using such OOS samples to evaluate models\u2019 OOS detection capabilities can produce misleading results.\n\nDuring deployment, the model may encounter OOS utterances that closely resemble the INS utterances but convey entirely different meanings. Due to the high similarity that those hard-negative out-of-scope utterances share with the INS data, the models are more susceptible to misclassifying them into a supported intent with high confidence. Therefore, collecting hard-negative OOS data is pivotal to ensure that the intent classifiers can reliably distinguish all OOS utterances, regardless of their resemblance to the INS samples.\n\nObtaining OOS data that sufficiently challenges the intent classifiers is difficult. Often, this is done through crowd-sourcing with platforms like Amazon Mechanical Turk. However, this approach is costly and time-consuming, and it requires careful verification to make sure that the samples are indeed out-of-scope and challenging. Furthermore, data collection via crowd-sourcing introduces quality control problems as the collected data are often error prone. In datasets containing a large number of intents, verifying each utterance to be irrelevant from all the intents poses significant difficulty for human crowd-sourcing workers. For example, the Clinc-150 dataset encompasses 150 intents; relying on the crowd-workers to verify all sentences to be OOS may be challenging and could lead to erroneous results.\n\nA cost-effective alternative is to generate hard-negative OOS data using Large Language Models such as ChatGPT. In comparison, the GPT-3.5 turbo API costs $0.0015 per 1K tokens in the prompt and $0.003 per 1K tokens for the output, a substantial potential savings. In this paper, we aim to investigate the following research questions: Can ChatGPT generate OOS utterances that do not fall into any of the system-supported INS intents? Do the generated hard-negative OOS utterances lead to high-confidence predictions from intent classifiers? Can the generated hard-negative OOS utterances be used in training to improve the intent classifiers\u2019 OOS detection ability and decrease the models\u2019 confidence on the supported intents when encountering OOS utterances?\n\nTo answer these questions, we select five large public datasets and introduce a method to generate 3,732 hard-negative OOS utterances \u2014 that is, utterances intended to closely resemble the in-scope data for a given intent. Our method works by analyzing important words that are likely to have the biggest influence on the intent classifiers\u2019 predictions for each intent from the INS training data. Then, the method prompts ChatGPT to generate OOS utterances that include specific important words for each intent. Since the generated OOS utterances contain the important words from supported intents, they are more likely to confuse the model and produce high confidence. In doing so, we can increase the rigor and challenge of a given dataset by partially automating the creation of hard negative inputs.\n\nWe evaluate the performance of three benchmark transformer models for intent classification on our generated datasets. The hard-negative OOS utterances produced using our method consistently resulted in high confidence (but incorrect) predictions across all five datasets. Notably, intent classifiers struggled to distinguish the hard-negative OOS utterances from the INS utterances. In particular for Clinc-150 and Banking77, model confidence scores are substantially higher for our generated hard-negative OOS datasets compared to the general OOS dataset.\n\nWe see various improvements in model performance when incorporating hard-negative OOS data in training. Our study shows that more attention must be given to curating hard-negative OOS datasets to enhance model robustness in deployment."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2.   Related Work",
            "text": "In this section, we discuss prior work related to data collection for intent classification tasks and ChatGPT\u2019s data generation capabilities."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1.   Hard-Negative Data",
            "text": "Several studies have highlighted the significance of using hard-negative samples during training to improve model robustness. For instance, Zhan et al. (2021) and Nguyen et al. (2023) used hard-negative examples during training to aid retrieval models to better discriminate between relevant and irrelevant documents. Hard-negatives can also facilitate contrastive learning for image classification (e.g., Kalantidis et al. (2020)) and image retrieval (e.g., Melekhov et al. (2016); Hughes et al. (2018)). However, the use of hard-negatives for intent classification remains understudied. In this paper, we use our generated hard-negative OOS datasets to improve model robustness for intent classification."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2.   Data Collection for Intent Classification",
            "text": "General Data Collection. Prior strategies for data collection for constructing training and evaluation data for intent classifiers include the use of crowd-sourcing to generate queries by either (1) paraphrasing input query prompts or (2) responding to scenarios with queries. This prior work includes Coucke et al. (2018); Larson et al. (2019b); Gupta et al. (2018); Liu et al. (2019a); Kang et al. (2018). Recently, prior work has investigated using large language models (LLMs) to generate this type of training data. This work includes Rosenbaum et al. (2022), who used AlexaTM, and Sahu et al. (2022), who used GPT-3, and Cegin et al. (2023), who used ChatGPT to generate paraphrases.\n\nOut-of-Scope and Challenging Data Collection. Most prior work on data collection for intent classification does not consider the production of OOS queries for evaluating a model\u2019s ability to distinguish between in- and out-of-scope inputs. Exceptions to this include Larson et al. (2019b), whose Clinc-150 dataset includes out-of-scope utterances that were generated via crowd-sourcing. Other work in this space includes Larson and Leach (2022a), whose out-of-scope data is constructed by sampling from other datasets, and Zhang et al. (2022), who constructed \u201cin-domain, out-of-scope\u201d splits of Clinc-150 and Banking77 where training data includes a set of intents from the original dataset, but evaluation data includes a set of intents that are in the same domain. Here, a domain is a semantically meaningful group of intents like \u201cbanking\u201d, \u201ctravel\u201d, etc. Similarly, Khosla and Gangadharaiah (2022) created challenging datasets for testing model robustness to \u201ccovariate shifted\u201d data. In that work, covariate shifted data means data that was generated from a different distribution with respect to some other original data distribution, but where both data distributions generate data for the same intent category. Considering the weather intent from Clinc-150, covariate shifted data includes data that was originally generated for the Snips or HWU64 datasets (i.e., the get_weather intent from Snips, and HWU64\u2019s weather_query intent). Other work that focuses on directly generating new challenge data includes techniques from Larson et al. (2019a), which prompted crowd workers to paraphrase only unique queries from a dataset, and Larson et al. (2020b), who prompted crowd workers to paraphrase seed phrases but constrained the crowd workers from using certain keywords that were found to be indicative of certain intents. The techniques from both of these works can be seen as ways to generate covariate shifted in-scope data."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "2.3.   Adversarial Examples",
            "text": "Our work on generating hard-negative data has similarities to prior work on generating adversarial examples. Motivated by adversarial example generation work in computer vision that applies \u201cimperceptible\u201d perturbations to images to provoke incorrect model classification (e.g., Goodfellow et al. (2015  ###reference_b14###)), prior work in natural language processing on adversarial example generation has revolved around perturbing texts using character-level alterations (e.g., Ebrahimi et al. (2018  ###reference_b9###); Gao et al. (2018  ###reference_b11###)) and word synonym and phrase replacement (e.g., Alzantot et al. (2018  ###reference_b1###); Ren et al. (2019  ###reference_b41###); Garg and Ramakrishnan (2020  ###reference_b12###)). Similar work in dialog data has been done by Peng et al. (2021  ###reference_b40###); Liu et al. (2021  ###reference_b33###); Sengupta et al. (2021  ###reference_b45###), where utterances are modified (e.g., by introducing typos, word synonyms, ASR errors, etc.) in order to test the robustness of models. The method we present in this paper can be seen as a way to generate adversarial examples to test the robustness of intent classification models, but differs in that we do not apply perturbations to existing samples."
        },
        {
            "section_id": "2.4",
            "parent_section_id": "2",
            "section_name": "2.4.   Data Collection and Annotation with ChatGPT",
            "text": "In a recent study, Cegin et al. (2023) showed that large language models such as ChatGPT can generate more lexically and syntactically diverse INS data by paraphrasing existing corpora. Cegin et al. (2023) also showed that ChatGPT can follow prompted restrictions and used ChatGPT in lieu of crowd-sourcing to generate \u201ctaboo\u201d paraphrases in the manner of Larson et al. (2020b), where certain words are avoided in paraphrases in order to promote diversity. However, Cegin et al. (2023) also observed several issues with open-sourced models such as Falcon-40b: duplicated outputs, erroneous outputs, and lack of instruction following.\n\nAnother study showed ChatGPT\u2019s performance varies for sentiment analysis on tweets depending on the topics. For tasks such as classifying the political affiliation of Twitter users, ChatGPT outperforms human crowd-source workers. ChatGPT\u2019s performance for text-annotation tasks has also been found to exceed that of crowd workers.\n\nSahu et al. (2022) prompted GPT-3 to generate labeled training data, and the generated data significantly improves the intent classifiers when the intents are distinct. Using ChatGPT to rephrase sentences, models trained with AugGPT outperform state-of-the-art text data augmentation methods to generate data for scarce intents in a few-shot learning setting."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3.   Methods",
            "text": "We introduce an automated method for generating hard-negative OOS utterances using ChatGPT\u2019s API. In this study, we generate 3,732 hard-negative OOS queries for five benchmark datasets. Our objective is to generate hard-negative OOS utterances by producing utterances that are likely to contain words that heavily influence the intent classifiers\u2019 predictions. The hard-negative OOS datasets are generated following these steps, which we discuss throughout this section. Example utterances produced with our approach are shown in Figure 2 ###reference_###. \n\nUse feature-mining to select keywords by analyzing the most frequently appearing words for each intent for every selected dataset. Select a combination of keywords from the keywords for an intent. Show ChatGPT the name of the intent and five in-scope utterances from. Prompt ChatGPT to generate questions (i.e., utterances) that must contain ... , and is not related to the intent. Prompt ChatGPT to verify that each of the generated questions is not related to the intent. Prompt ChatGPT to verify that each of the generated questions is not related to any of the intents in the entire dataset.\n\nIn this study, we select to be , to be , and to be . When the prompts include only one keyword, we noticed that the generated data shares less similarity to the INS data compared to when = . When prompts include three or more keywords, ChatGPT frequently struggles to include all the keywords or produce an OOS utterance. Larger and can be selected to generate more hard-negative OOS data."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1.   Feature-Mining Keywords",
            "text": "To ensure that the generated OOS queries resemble INS queries for each intent, we need to identify important keywords that are likely to influence the intent classifiers\u2019 prediction. Among our five selected datasets, we collect the most frequently occurring words in the INS training samples from each intent. We lemmatize all words using NLTK\u2019s WordNetLemmatizer to prevent getting multiple versions of the same word. In addition, we discard the stop words and tokens that contain less than three characters.\n\nWe have also explored alternative methods to identify keywords. For instance, using the Python ELI5 package, we determined the words with the highest weights after training an SVM classification model on each of the datasets. For larger datasets such as Clinc-150 and HWU64, training multi-class SVM on a substantial number of intents is time consuming. We utilized the LinearSVC from Scikit-Learn which is implemented as One-vs-All, resulting in a model requiring classifiers for intents.\n\nAfter removing stopwords and lemmatizing the tokens, we are not able to obtain at least five keywords for many intents. For example, 65 of 150 intents from Clinc-150 produced less than 5 keywords using the ELI5 method. Therefore, we use the original token frequency-based approach for keywords collection."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2.   Data Generation with ChatGPT",
            "text": "Recall that we prompt ChatGPT to produce hard-negative OOS samples. We use the GPT 3.5-turbo model through the chat completion API. (All experiments using ChatGPT were done June-August 2023.) For interaction with the API, we make use of three distinct \u201croles\u201d: (1) The \u201csystem\u201d role, which allows the developers to guide ChatGPT\u2019s behavior throughout the conversation. (2) The \u201cassistance\u201d role, which grants ChatGPT\u2019s API the access to previous conversations, enabling ChatGPT to recall previously generated hard-negative OOS utterances to avoid generating duplicates. ChatGPT can also retain the intent information, removing the need for us to repeatedly inform ChatGPT the intent in every prompt. (3) The \u201cuser\u201d role, which lets the developers to prompt questions for ChatGPT\u2019s API to answer. When generating hard-negative OOS utterances, we first set the role to \u201csystem\u201d and guide ChatGPT to answer with only the hard-negative sentence. This approach prevents the API from padding the responses with unnecessary tokens like \u201cSure, I\u2019d be happy to help.\u201d Next, we set the role to \u201cuser\u201d and show ChatGPT the name of each intent and five INS samples for that intent. This enables ChatGPT to understand the semantics of the intent, especially when the intent name alone does not provide sufficient context. Then, we use the \u201cassistance\u201d role to record the dialog between the developer and ChatGPT. Subsequently, we prompt ChatGPT to generate an utterance that must be unrelated to the intent (i.e., OOS) and must contain a combination of two keywords collected during feature-mining. Preliminary experiments revealed that ChatGPT will often output utterances with mostly the same tokens if prompted to generate multiple utterances at once. This process allows us to guide ChatGPT to produce an utterance that contains commonly used words associated with a given intent but that is not related to that intent \u2014 that is, a hard-negative OOS sample. Next, we discuss how we validate each such generated utterance is in fact OOS."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "3.3.   OOS Verification with ChatGPT",
            "text": "To ensure that the hard-negative OOS data does not contain any INS samples, we use a two-step verification method using ChatGPT. After ChatGPT generates every hard-negative OOS utterance, we immediately prompt ChatGPT to assess whether each utterance belongs to the intent that the utterance should not relate to. For example, after prompting ChatGPT to generate a question containing \u201chello\u201d and \u201cfrench\u201d that is not related to the translate intent, we subsequently prompt ChatGPT to determine whether the generated utterance is related to \u201ctranslate\u201d. If ChatGPT determines that the utterance is related to \u201ctranslate\u201d, then it is discarded. In the second step of verification, the remaining utterances are then checked to be OOS with respect to the entire dataset. To implement this step, we provide ChatGPT with the name of all INS intent categories using the \u201csystem\u201d role and prompt ChatGPT to verify if each utterance is OOS with the \u2018user\u2019 role. We note that ChatGPT occasionally mislabels a small portion of the utterances during this two-step verification process. However, since our goal is to generate hard negative OOS data, discarding such inadvertently mislabeled data is not critical. Finally, we manually check the hard-negative OOS datasets collected after the two-step verification stage to ensure the label accuracy. For utterances that do not clearly fall into the INS or OOS categories, we compare the utterance with the INS samples and discuss amongst the research team to conclude the correct label. We discard the utterances if no consensus is reached regarding label opinions."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4.   Evaluation",
            "text": "We design experiments to assess the level of difficulty that intent classifiers have when discerning between in-scope (INS) and hard-negative out-of-scope (OOS) data. As a baseline, we also measure models\u2019 abilities to discern INS data from \u201cgeneral\u201d (i.e., not hard-negative) OOS data. Additionally, we evaluate the improvements in models\u2019 OOS detection abilities after including hard-negative OOS and general OOS data in training. We hypothesize that the hard negative OOS data we generate with our approach will lead to performance decreases because the model will confuse these samples as being INS. We use INS data from Clinc-150, Banking77, ATIS, Snips, and HWU64. Different from the other four datasets, HWU64 consists of two intents General_Quirky and QA_Factoid that span a wide spectrum of semantics. We excluded these two \u201ccatch-all\u201d intents from HWU64 for training and testing to allow for sufficient samples that are considered OOS. We use our method to generate 3,732 hard-negative out-of-scope samples targeting intents from the five datasets listed above. Instead of hard-negative OOS data, the baseline approach uses \u201cgeneral\u201d OOS data. We use the Clinc-150 companion OOS data as this general OOS data, which consists of 1,000 test utterances. We then filtered out any utterances that belonged to any of the in-scope intents from the other four datasets. We split the INS data into training and testing. Each selected model is trained on the training data and evaluated with the INS testing data, the generated hard-negative OOS data, the general OOS data from Clinc-150. To examine whether hard-negative OOS data can be used during training to improve the models\u2019 OOS detection capability, we separated both hard-negative OOS data and general OOS data into 80% training and 20% testing splits and compared the models\u2019 confidence for the OOS datasets when we included hard-negative OOS, general OOS, and both OOS corpora in training."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1.   Data",
            "text": "We use INS data from Clinc-150 Larson et al. (2019b  ###reference_b31###  ###reference_b31###), Banking77 Casanueva et al. (2020  ###reference_b3###  ###reference_b3###), ATIS Hemphill et al. (1990  ###reference_b17###  ###reference_b17###); Hirschman et al. (1992  ###reference_b20###  ###reference_b20###, 1993  ###reference_b19###  ###reference_b19###); Dahl et al. (1994  ###reference_b6###  ###reference_b6###), Snips Coucke et al. (2018  ###reference_b5###  ###reference_b5###), and HWU64 Liu et al. (2019a  ###reference_b35###  ###reference_b35###). Different from the other four datasets, HWU64 consists of two intents General_Quirky and QA_Factoid that span a wide spectrum of semantics. We excluded these two \u201ccatch-all\u201d intents from HWU64 for training and testing to allow for sufficient samples that are considered OOS. We use our method to generate 3,732 hard-negative out-of-scope samples targeting intents from the five datasets listed above. Section 5.1  ###reference_###  ###reference_### discusses the generated data in detail. Instead of hard-negative OOS data, the baseline approach uses \u201cgeneral\u201d OOS data. We use the Clinc-150 companion OOS data as this general OOS data, which consists of 1,000 test utterances. We then filtered out any utterances that belonged to any of the in-scope intents from the other four datasets. We split the INS data into training and testing. Each selected model is trained on the training data and evaluated with the INS testing data, the generated hard-negative OOS data, the general OOS data from Clinc-150. To examine whether hard-negative OOS data can be used during training to improve the models\u2019 OOS detection capability, we separated both hard-negative OOS data and general OOS data into 80% training and 20% testing splits and compared the models\u2019 confidence for the OOS datasets when we included hard-negative OOS, general OOS, and both OOS corpora in training."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2.   Intent Classification Models",
            "text": "We use the following intent classifiers in our experiments:  \nBERT, a neural network that uses a transformer model to capture the context of each word and fine-tuned on the training data for NLP tasks Devlin et al. (2019). In this study, we use bert-base-uncased.  \nRoBERTa, a variant of BERT that provides better contextual representation of text Liu et al. (2019b).  \nDistilBERT, a lightweight variant of BERT that uses fewer parameters than BERT and processes texts faster Sanh et al. (2019).  \nWe used the Hugging Face implementations of these models Wolf et al. (2020).\n\nCommon approaches to dealing with OOS inputs involve the use of confidence scores to differentiate between INS and OOS inputs.  \nNormally, a desirable model is one that assigns higher confidence to INS inputs, and lower confidence to OOS inputs.  \nWe use two functions to produce the confidence scores when evaluating our hard-negative OOS datasets:  \n(1) Softmax, where we use the highest softmax confidence score for each prediction Hendrycks and Gimpel (2016).  \n(2) Energy, where we compute the energy score Liu et al. (2020) for each prediction using .444 We considered alternative values for and the results are similar for different .\n\nThese two methods are commonly used in prior work on out-of-distribution detection (e.g., Larson et al. (2022))."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "4.3.   Metrics",
            "text": "We consider several performance metrics to evaluate the quality of our hard-negative OOS datasets, assigning the INS predictions as the positive class and OOS predictions as the negative class:\n\n(1) AUPR, the Area Under the Precision and Recall Curve. A higher AUPR indicates a more robust model.\n\n(2) FPR95, the false positive rate at 95% recall. A lower FPR95 indicates a more robust model.\n\n(3) F1 score with confidence thresholds, the F1 score for a range of confidence thresholds from 0.5 to 0.95 for softmax confidence scores. Predictions with higher confidence score than the confidence threshold are considered as positive predictions. Higher F1 captures the classifier\u2019s ability to distinguish INS and OOS data at different confidence thresholds since most intent classifiers in deployment utilize a confidence threshold to determine whether an utterance is not understood."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5.   Results",
            "text": "This section discusses the results of our data generation and experiments: Section 5.1 ###reference_### discusses the results of generating hard-negative OOS with our method. Section 5.2 ###reference_### discusses results of experiments determining the effectiveness of hard-negative OOS data vis-\u00e0-vis general OOS data. Section 5.3 ###reference_### discusses results of experiments on determining the effectiveness of training with hard-negative OOS data."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "5.1.   Generation Results",
            "text": "In this study, we prompted ChatGPT to generate a total of 11,080 hard-negative OOS utterances from five different datasets. Roughly 74% (8,172 samples) of the generated hard-negative passed the first round of OOS verification. Then, 3,779 (34%) remained to be valid after the second round of OOS verification where each utterance is prompted to ChatGPT to determine whether it is related to any known in-scope intent of the dataset. Finally, when we manually examined the hard-negative OOS datasets after the two-step verification method, we found that 47 (1.2% of the hard-negative OOS after the two-step verification) are INS and mislabelled by ChatGPT, resulting in 3,732 valid hard-negative OOS samples. Examples of generated hard-negative data are shown in Table 1 ###reference_###. Precise counts of verified hard-negative OOS data for each dataset is shown in Table 2 ###reference_###."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "5.2.   Classifier Performance",
            "text": "We evaluate our five generated hard-negative OOS datasets with BERT, RoBERTa, and DistilBERT trained on only INS data. \n\nFor Banking77 and Clinc-150, the softmax and energy confidence scores for the INS predictions are substantially closer to the hard-negative OOS predictions than the general OOS predictions for all three models. For instance, when evaluated with BERT, Figure 3 (a) shows that the distribution of the softmax confidence scores for the hard-negative OOS is much closer to the INS data compared to the general OOS data. Figure 3 (b) demonstrates that the distribution of energy confidence scores for the INS data is also more similar to that of the hard-negative OOS data compared to the general OOS data. Figure 3 (c) displays the F1 score for the INS vs hard-negative OOS data is lower than that for the INS vs. general OOS data at all confidence thresholds, indicating the model is worse at distinguishing hard-negative OOS than general OOS from the INS data.\n\nRoBERTa and DistilBERT resulted in distributions of confidence scores comparable to BERT. Figure 4 displays the distribution of softmax confidence score for RoBERTa after training on the in-scope data from Clinc-150. During the evaluation for ATIS, Snips, and HWU64, all three models predict both hard-negative OOS data and general OOS data with a substantial number of high softmax confidence scores.\n\nThe FPR95 for both softmax and energy confidence for hard-negative OOS with INS are higher than those for general OOS with INS across all models and datasets, highlighting that the confidence scores can more effectively differentiate the INS data from the general OOS data than our hard-negative OOS data.\n\nOur results suggest that the hard-negative OOS utterances generated with our approach are, at minimum, as challenging as the general OOS dataset and frequently result in high-confidence, incorrect predictions from intent classifiers. Specifically for Clinc-150 and Banking77, the hard-negative OOS utterances are substantially more difficult to differentiate as be OOS in comparison to the general OOS utterances.\n\nTherefore, our proposed hard-negative OOS datasets and other hard-negative OOS datasets generated following our approach will challenge intent classifiers and scrutinize classifiers\u2019 robustness against such data."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "5.3.   Using Hard-Negative OOS in training",
            "text": "When we train transformer-based intent classifiers only on INS data (Section 5.2 ###reference_###), the models predicted high confidence for hard-negative OOS utterances and varying general OOS confidence across all five benchmark datasets. To determine if using hard-negative OOS in training can improve model robustness, we compare the model confidence after training BERT with (1) INS and general OOS data, (2) INS and hard-negative OOS data, (3) INS, general OOS, and hard-negative OOS data, using an 80/20 train test split for the datasets that are used in training.\n\nSince OOS data are included in training, we consider \u201coos\u201d to be a new label. We calculate the confidence score for each prediction by taking the highest softmax score for any in-scope intent. This confidence score indicates how confident the classifier models are in predicting that utterance belongs to a known intent and is in-scope.\n\nFor Clinc-150, Banking77, and ATIS, when the intent classifiers are trained on OOS data, the confidence scores for general OOS utterances drop substantially compared to models trained only on in-scope data, but the confidence score for hard-negative OOS utterances remains high. In comparison, when we add hard-negative OOS in the training corpora, the models produce low confidence predictions for both hard-negative OOS and OOS utterances. For Snips and HWU64, incorporating general OOS in training results in high confidence predictions for hard-negative OOS, and using hard-negative OOS in training results in high confidence predictions for the general OOS. In this case, incorporating only hard-negative OOS in training is not enough to ensure model robustness. When using both hard-negative OOS and general OOS in training, the model predicts OOS utterances with low confidence to be INS.\n\nThis result indicates that models trained solely with INS and general OOS data are still prone to predicting hard-negative OOS data with high confidence. When the generated hard-negative OOS datasets are incorporated in the training data, the models are much less likely to produce high confidence scores for hard-negative OOS utterances and display varying improvements for detecting general OOS utterances.\n\nAlthough our experiments demonstrate that training with both hard-negative OOS and general OOS greatly reduces confidence on OOS utterances, we note that there is no way to guarantee that every OOS intent can be covered. That is, in deployment, we cannot guarantee that the distribution of inputs will follow the OOS data generated with our approach. Nonetheless, our approach can be used to help improve model robustness and to improve benchmarking and data quality."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6.   Conclusion",
            "text": "We present a new approach to generating hard-negative OOS data using ChatGPT. After manually reviewing and verifying generated data, we show our approach can generate data that are OOS data with infrequent mislabels. Our evaluation shows that models trained only on INS data are brittle when tested against hard-negative OOS utterances generated with our approach and often result in overconfident but incorrect predictions. Our results indicate that the hard-negative OOS utterances are more challenging to differentiate from the INS utterances when compared to the general OOS utterances. Furthermore, we show that using hard-negative OOS data in training improves model robustness against hard-negative OOS utterances substantially and general OOS utterances to varying degrees. Models trained on general OOS data still struggle with hard-negative OOS utterances to a noticeable extent across all five datasets. Since collecting hard-negative OOS data with ChatGPT is substantially less costly than traditional crowd-sourcing methods, we hope that our technique and analysis will lead to more robust intent classifiers. All code used for generating and verifying hard-negative OOS data with ChatGPT, datasets generated and used, results, and additional figures are available at github.com/frank7li/Generating-Hard-Negative-Out-of-Scope-Data-with-ChatGPT-for-Intent-Classification."
        }
    ],
    "appendix": [],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T1\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T1.2\" style=\"width:400.0pt;height:207.9pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-22.2pt,11.5pt) scale(0.9,0.9) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.2.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.1.1.1.1.1\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.2.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.1.1.1.2.1\">Intent</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.2.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.1.1.1.3.1\">Keywords</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.2.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.1.1.1.4.1\">Hard-Negative OOS</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.2.1.2.1.1\">Clinc-150</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.2.1.2.1.2\">find_phone</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.2.1.2.1.3\">find, locate</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.2.1.2.1.4\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.2.1.2.1.4.1\">how do i <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.2.1.4.1.1\">find</span> and <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.2.1.4.1.2\">locate</span> a lost pet</em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.3.2.1\">Clinc-150</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.3.2.2\">change_language</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.3.2.3\">french, english</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.3.2.4\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.2.1.3.2.4.1\">are <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.3.2.4.1.1\">french</span> and <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.3.2.4.1.2\">english</span> official languages in canada</em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.4.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.4.3.1\">Clinc-150</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.4.3.2\">distance</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.4.3.3\">take, long</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.4.3.4\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.2.1.4.3.4.1\">does it <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.4.3.4.1.1\">take</span> <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.4.3.4.1.2\">long</span> to find a seat on the bus</em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.5.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.5.4.1\">Banking77</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.5.4.2\">exchange_rate</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.5.4.3\">foreign, know</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.5.4.4\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.2.1.5.4.4.1\">do you <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.5.4.4.1.1\">know</span> any <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.5.4.4.1.2\">foreign</span> exchange officers nearby</em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.6.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.6.5.1\">Banking77</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.6.5.2\">age_limit</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.6.5.3\">age, children</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.6.5.4\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.2.1.6.5.4.1\">what are <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.6.5.4.1.1\">age</span>-appropriate money lessons for <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.6.5.4.1.2\">children</span></em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.7.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.7.6.1\">Banking77</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.7.6.2\">card_arrival</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.7.6.3\">track, sent</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.7.6.4\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.2.1.7.6.4.1\">can i <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.7.6.4.1.1\">track</span> my <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.7.6.4.1.2\">sent</span> documents</em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.8.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.8.7.1\">HWU64</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.8.7.2\">iot_hue_lightchange</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.8.7.3\">color, change</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.8.7.4\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.2.1.8.7.4.1\">can temperature <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.8.7.4.1.1\">change</span> the <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.8.7.4.1.2\">color</span> of a blue flame</em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.9.8\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.9.8.1\">HWU64</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.9.8.2\">alarm_set</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.9.8.3\">wake, tomorrow</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.9.8.4\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.2.1.9.8.4.1\">what are some tips to <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.9.8.4.1.1\">wake</span> up refreshed <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.9.8.4.1.2\">tomorrow</span></em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.10.9\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.10.9.1\">HWU64</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.10.9.2\">iot_coffee</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.10.9.3\">make, machine</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.10.9.4\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.2.1.10.9.4.1\">how do i <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.10.9.4.1.1\">make</span> a homemade washing <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.10.9.4.1.2\">machine</span></em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.11.10\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.11.10.1\">ATIS</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.11.10.2\">flight_time</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.11.10.3\">time, open</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.11.10.4\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.2.1.11.10.4.1\">what <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.11.10.4.1.1\">time</span> does the golden gate bridge <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.11.10.4.1.2\">open</span></em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.12.11\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.12.11.1\">ATIS</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.12.11.2\">aircraft</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.12.11.3\">type, used</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.12.11.4\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.2.1.12.11.4.1\">what <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.12.11.4.1.1\">type</span> of currency is <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.12.11.4.1.2\">used</span> in boston</em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.13.12\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.13.12.1\">Snips</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.13.12.2\">BookRestaurant</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.13.12.3\">book, reservation</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.2.1.13.12.4\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.2.1.13.12.4.1\">can i <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.13.12.4.1.1\">book</span> a <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.13.12.4.1.2\">reservation</span> for the flight</em></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.1.14.13\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.2.1.14.13.1\">Snips</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.2.1.14.13.2\">GetWeather</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.2.1.14.13.3\">like, going</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.2.1.14.13.4\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T1.2.1.14.13.4.1\">what\u2019s the vibe <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.14.13.4.1.1\">like</span> <span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.2.1.14.13.4.1.2\">going</span> there</em></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T1.3.1.1\" style=\"font-size:90%;\">Table 1</span>: </span><span class=\"ltx_text\" id=\"S4.T1.4.2\" style=\"font-size:90%;\">Example hard-negative OOS data generated by ChatGPT across different intents and datasets.</span></figcaption>\n</figure>",
            "capture": "Table 1: Example hard-negative OOS data generated by ChatGPT across different intents and datasets."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T2\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T2.2\" style=\"width:140.1pt;height:103.9pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-7.8pt,5.8pt) scale(0.9,0.9) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.2.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T2.2.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.2.1.1.1.1.1\">Dataset</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"S4.T2.2.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.2.1.1.1.2.1\">Total</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"S4.T2.2.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.2.1.1.1.3.1\">Step 1</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"S4.T2.2.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.2.1.1.1.4.1\">Step 2</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"S4.T2.2.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.2.1.1.1.5.1\">Final</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.2.1.2.2.1\">Clinc-150</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.2.1.2.2.2\">6,000</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.2.1.2.2.3\">4,442</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.2.1.2.2.4\">2,278</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.2.1.2.2.5\">2,266</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.2.1.3.3.1\">Banking77</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.3.3.2\">1,440</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.3.3.3\">1,169</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.3.3.4\">742</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.3.3.5\">734</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.2.1.4.4.1\">ATIS</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.4.4.2\">640</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.4.4.3\">458</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.4.4.4\">226</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.4.4.5\">220</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.2.1.5.5.1\">Snips</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.5.5.2\">280</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.5.5.3\">200</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.5.5.4\">95</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.5.5.5\">90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.2.1.6.6.1\">HWU64</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.6.6.2\">2,720</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.6.6.3\">1,903</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.6.6.4\">438</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.2.1.6.6.5\">422</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\" id=\"S4.T2.2.1.7.7.1\">Overall</th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\" id=\"S4.T2.2.1.7.7.2\">11,080</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\" id=\"S4.T2.2.1.7.7.3\">8,172</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\" id=\"S4.T2.2.1.7.7.4\">3,779</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\" id=\"S4.T2.2.1.7.7.5\">3,732</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T2.3.1.1\" style=\"font-size:90%;\">Table 2</span>: </span><span class=\"ltx_text\" id=\"S4.T2.4.2\" style=\"font-size:90%;\">Results of prompting ChatGPT to generate hard-negative OOS utterances for each dataset. \u201cStep 1\u201d and \u201cStep 2\u201d show how many utterances remained valid after the ChatGPT OOS Verification.\nThe total count of valid hard-negative OOS utterances is displayed in the \u201cFinal\u201d column.</span></figcaption>\n</figure>",
            "capture": "Table 2: Results of prompting ChatGPT to generate hard-negative OOS utterances for each dataset. \u201cStep 1\u201d and \u201cStep 2\u201d show how many utterances remained valid after the ChatGPT OOS Verification.\nThe total count of valid hard-negative OOS utterances is displayed in the \u201cFinal\u201d column."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T3\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S5.T3.2\" style=\"width:412.7pt;height:374.2pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-22.9pt,20.8pt) scale(0.9,0.9) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S5.T3.2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S5.T3.2.1.1.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.1.1.1\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S5.T3.2.1.1.1.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.1.2.1\">AUROC</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S5.T3.2.1.1.1.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.1.3.1\">AUPR</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S5.T3.2.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.1.1.1.4.1\">FPR95</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.2.2\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.1.2.2.1\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T3.2.1.2.2.1.1\">General OOS</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.1.2.2.2\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T3.2.1.2.2.2.1\">HN OOS</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.1.2.2.3\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T3.2.1.2.2.3.1\">General OOS</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.1.2.2.4\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T3.2.1.2.2.4.1\">HN OOS</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.1.2.2.5\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T3.2.1.2.2.5.1\">General OOS</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.1.2.2.6\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T3.2.1.2.2.6.1\">HN OOS</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T3.2.1.3.1.1\">Clinc-150</th>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.2.1.3.1.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.3.1.2.1\">0.968</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.2.1.3.1.3\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.3.1.3.1\">0.914</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.2.1.3.1.4\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.3.1.4.1\">0.982</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.2.1.3.1.5\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.3.1.5.1\">0.914</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.2.1.3.1.6\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.3.1.6.1\">0.121</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T3.2.1.3.1.7\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.3.1.7.1\">0.326</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.2.1.4.2.1\">Banking77</th>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.4.2.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.4.2.2.1\">0.964</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.4.2.3\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.4.2.3.1\">0.810</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.4.2.4\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.4.2.4.1\">0.959</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.4.2.5\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.4.2.5.1\">0.826</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.4.2.6\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.4.2.6.1\">0.205</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.4.2.7\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.4.2.7.1\">0.639</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.2.1.5.3.1\">ATIS</th>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.5.3.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.5.3.2.1\">0.964</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.5.3.3\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.5.3.3.1\">0.953</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.5.3.4\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.5.3.4.1\">0.972</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.5.3.5\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.5.3.5.1\">0.989</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.5.3.6\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.5.3.6.1\">0.179</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.5.3.7\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.5.3.7.1\">0.245</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.2.1.6.4.1\">Snips</th>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.6.4.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.6.4.2.1\">0.956</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.6.4.3\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.6.4.3.1\">0.864</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.6.4.4\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.6.4.4.1\">0.982</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.6.4.5\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.6.4.5.1\">0.993</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.6.4.6\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.6.4.6.1\">0.223</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T3.2.1.6.4.7\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.6.4.7.1\">0.400</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.7.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T3.2.1.7.5.1\">HWU64</th>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T3.2.1.7.5.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.7.5.2.1\">0.921</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T3.2.1.7.5.3\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.7.5.3.1\">0.917</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T3.2.1.7.5.4\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.7.5.4.1\">0.971</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T3.2.1.7.5.5\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.7.5.5.1\">0.988</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T3.2.1.7.5.6\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.7.5.6.1\">0.392</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T3.2.1.7.5.7\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T3.2.1.7.5.7.1\">0.462</p>\n</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S5.T3.3.1.1\" style=\"font-size:90%;\">Table 3</span>: </span><span class=\"ltx_text\" id=\"S5.T3.4.2\" style=\"font-size:90%;\">Performance comparison between OOS data with the INS data of a BERT model evaluated via softmax confidence scores.</span></figcaption>\n</figure>",
            "capture": "Table 3: Performance comparison between OOS data with the INS data of a BERT model evaluated via softmax confidence scores."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T4\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S5.T4.2\" style=\"width:412.7pt;height:374.2pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-22.9pt,20.8pt) scale(0.9,0.9) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S5.T4.2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T4.2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S5.T4.2.1.1.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.1.1.1\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S5.T4.2.1.1.1.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.1.2.1\">INS</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S5.T4.2.1.1.1.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.1.3.1\">General OOS</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S5.T4.2.1.1.1.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.1.4.1\">Hard-Negative OOS</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S5.T4.2.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.1.1.1.5.1\">Both OOS</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.1.2.2\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.1.2.2.1\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T4.2.1.2.2.1.1\">General OOS</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.1.2.2.2\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T4.2.1.2.2.2.1\">HN OOS</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.1.2.2.3\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T4.2.1.2.2.3.1\">General OOS</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.1.2.2.4\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T4.2.1.2.2.4.1\">HN OOS</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.1.2.2.5\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T4.2.1.2.2.5.1\">General OOS</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.1.2.2.6\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T4.2.1.2.2.6.1\">HN OOS</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.1.2.2.7\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T4.2.1.2.2.7.1\">General OOS</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S5.T4.2.1.2.2.8\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S5.T4.2.1.2.2.8.1\">HN OOS</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T4.2.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T4.2.1.3.1.1\">Clinc-150</th>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T4.2.1.3.1.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.3.1.2.1\">0.968</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T4.2.1.3.1.3\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.3.1.3.1\">0.914</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T4.2.1.3.1.4\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.3.1.4.1\">0.989</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T4.2.1.3.1.5\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.3.1.5.1\">0.916</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T4.2.1.3.1.6\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.3.1.6.1\">0.981</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T4.2.1.3.1.7\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.3.1.7.1\">0.988</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T4.2.1.3.1.8\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.3.1.8.1\">0.984</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T4.2.1.3.1.9\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.3.1.9.1\">0.990</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T4.2.1.4.2.1\">Banking77</th>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.4.2.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.4.2.2.1\">0.964</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.4.2.3\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.4.2.3.1\">0.810</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.4.2.4\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.4.2.4.1\">0.997</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.4.2.5\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.4.2.5.1\">0.874</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.4.2.6\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.4.2.6.1\">0.989</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.4.2.7\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.4.2.7.1\">0.996</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.4.2.8\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.4.2.8.1\">0.996</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.4.2.9\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.4.2.9.1\">0.992</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T4.2.1.5.3.1\">ATIS</th>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.5.3.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.5.3.2.1\">0.964</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.5.3.3\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.5.3.3.1\">0.953</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.5.3.4\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.5.3.4.1\">0.998</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.5.3.5\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.5.3.5.1\">0.974</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.5.3.6\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.5.3.6.1\">0.996</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.5.3.7\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.5.3.7.1\">0.996</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.5.3.8\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.5.3.8.1\">1.000</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.5.3.9\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.5.3.9.1\">1.000</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.1.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T4.2.1.6.4.1\">Snips</th>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.6.4.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.6.4.2.1\">0.956</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.6.4.3\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.6.4.3.1\">0.864</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.6.4.4\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.6.4.4.1\">0.999</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.6.4.5\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.6.4.5.1\">0.919</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.6.4.6\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.6.4.6.1\">0.968</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.6.4.7\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.6.4.7.1\">0.999</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.6.4.8\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.6.4.8.1\">0.998</p>\n</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"S5.T4.2.1.6.4.9\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.6.4.9.1\">0.993</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.1.7.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T4.2.1.7.5.1\">HWU64</th>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T4.2.1.7.5.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.7.5.2.1\">0.921</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T4.2.1.7.5.3\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.7.5.3.1\">0.917</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T4.2.1.7.5.4\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.7.5.4.1\">0.965</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T4.2.1.7.5.5\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.7.5.5.1\">0.927</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T4.2.1.7.5.6\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.7.5.6.1\">0.924</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T4.2.1.7.5.7\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.7.5.7.1\">0.985</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T4.2.1.7.5.8\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.7.5.8.1\">0.961</p>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"S5.T4.2.1.7.5.9\">\n<p class=\"ltx_p ltx_align_top\" id=\"S5.T4.2.1.7.5.9.1\">0.986</p>\n</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S5.T4.3.1.1\" style=\"font-size:90%;\">Table 4</span>: </span><span class=\"ltx_text\" id=\"S5.T4.4.2\" style=\"font-size:90%;\">The AUROC of the OOS data with the INS data of a BERT model. If the AUROC is closer to 1, then the model is less likely to classify an OOS utterance as INS. We compare how using general OOS, hard-negative OOS, and both OOS datasets in training improves the model\u2019s OOS detection capability.</span></figcaption>\n</figure>",
            "capture": "Table 4: The AUROC of the OOS data with the INS data of a BERT model. If the AUROC is closer to 1, then the model is less likely to classify an OOS utterance as INS. We compare how using general OOS, hard-negative OOS, and both OOS datasets in training improves the model\u2019s OOS detection capability."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.05640v1_figure_1.png",
            "caption": "Figure 1: Example exchanges between a user (blue,\nright side) and a task-driven dialog system for personal\nfinance (grey, left side). The system correctly identifies the user\u2019s utterance as in-scope in \\\u20ddraisebox{0.5pt}{1}, and correctly identifies the user\u2019s utterance as out-of-scope and gives a valid response in \\\u20ddraisebox{0.5pt}{2}. In \\\u20ddraisebox{0.5pt}{3}, the system incorrectly identifies the hard-negative OOS user utterance as in-scope and provides an incorrect response."
        },
        "2": {
            "figure_path": "2403.05640v1_figure_2.png",
            "caption": "Figure 2: An overview of the hard-negative OOS generation process, including examples. The third generated utterance is filtered out during the two-step OOS verification."
        },
        "3": {
            "figure_path": "2403.05640v1_figure_3.png",
            "caption": "Figure 3: Results for Banking77 evaluated with BERT. (a) shows the distribution of softmax confidence scores. (b) shows the distribution of energy confidence scores.\n(c) shows the F1 score of softmax confidence score for hard-negative OOS and general OOS with in-scope at different confidence thresholds."
        },
        "4": {
            "figure_path": "2403.05640v1_figure_4.png",
            "caption": "Figure 4: Distribution of softmax confidence scores for Clinc-150 evaluated with RoBERTa."
        }
    },
    "references": [
        {
            "1": {
                "title": "Generating natural\nlanguage adversarial examples.",
                "author": "Moustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani Srivastava,\nand Kai-Wei Chang. 2018.",
                "venue": "In Proceedings of the 2018 Conference on Empirical Methods in\nNatural Language Processing (EMNLP).",
                "url": "https://doi.org/10.18653/v1/D18-1316"
            }
        },
        {
            "2": {
                "title": "NLTK: The natural\nlanguage toolkit.",
                "author": "Steven Bird and Edward Loper. 2004.",
                "venue": "In Proceedings of the ACL Interactive Poster and\nDemonstration Sessions.",
                "url": "https://aclanthology.org/P04-3031"
            }
        },
        {
            "3": {
                "title": "Efficient\nintent detection with dual sentence encoders.",
                "author": "I\u00f1igo Casanueva, Tadas Tem\u010dinas, Daniela Gerz, Matthew Henderson, and\nIvan Vuli\u0107. 2020.",
                "venue": "In Proceedings of the 2nd Workshop on Natural Language\nProcessing for Conversational AI.",
                "url": "https://doi.org/10.18653/v1/2020.nlp4convai-1.5"
            }
        },
        {
            "4": {
                "title": "ChatGPT\nto replace crowdsourcing of paraphrases for intent classification: Higher\ndiversity and comparable model robustness.",
                "author": "Jan Cegin, Jakub Simko, and Peter Brusilovsky. 2023.",
                "venue": "In Proceedings of the 2023 Conference on Empirical Methods in\nNatural Language Processing (EMNLP).",
                "url": "https://doi.org/10.18653/v1/2023.emnlp-main.117"
            }
        },
        {
            "5": {
                "title": "Snips voice platform:\nan embedded spoken language understanding system for private-by-design voice\ninterfaces.",
                "author": "Alice Coucke, Alaa Saade, Adrien Ball, Th\u00e9odore Bluche, Alexandre Caulier,\nDavid Leroy, Cl\u00e9ment Doumouro, Thibault Gisselbrecht, Francesco\nCaltagirone, Thibaut Lavril, et al. 2018.",
                "venue": "arXiv preprint arXiv:1805.10190.",
                "url": "https://arxiv.org/pdf/1805.10190.pdf"
            }
        },
        {
            "6": {
                "title": "Expanding the scope of the\nATIS task: The ATIS-3 corpus.",
                "author": "Deborah A. Dahl, Madeleine Bates, Michael Brown, William Fisher, Kate\nHunicke-Smith, David Pallett, Christine Pao, Alexander Rudnicky, and\nElizabeth Shriberg. 1994.",
                "venue": "In Human Language Technology: Proceedings of a Workshop\nheld at Plainsboro, New Jersey, March 8-11, 1994.",
                "url": "https://aclanthology.org/H94-1010"
            }
        },
        {
            "7": {
                "title": "AugGPT: Leveraging\nchatGPT for text data augmentation.",
                "author": "Haixing Dai, Zhengliang Liu, Wenxiong Liao, Xiaoke Hugna, Yihan Cao, Zihao Wu,\nLin Zhao, shaochen Xu, Wei Liu, Ninghao Liu, Sheng Li, Dajiang Zhu, Hongmin\nCai, Lichao Sun, Quanzheng Li, Dinggang Shen, Tianming Liu, and Xiang Li.\n2023.",
                "venue": "arXiv preprint arXiv:2302.13007.",
                "url": "https://arxiv.org/pdf/2302.13007.pdf"
            }
        },
        {
            "8": {
                "title": "BERT: Pre-training of\ndeep bidirectional transformers for language understanding.",
                "author": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.",
                "venue": "In Proceedings of the 2019 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language\nTechnologies (NAACL-HLT).",
                "url": "https://doi.org/10.18653/v1/N19-1423"
            }
        },
        {
            "9": {
                "title": "HotFlip: White-box\nadversarial examples for text classification.",
                "author": "Javid Ebrahimi, Anyi Rao, Daniel Lowd, and Dejing Dou. 2018.",
                "venue": "In Proceedings of the 56th Annual Meeting of the Association\nfor Computational Linguistics (ACL).",
                "url": "https://doi.org/10.18653/v1/P18-2006"
            }
        },
        {
            "10": {
                "title": "Exploring the\nlimits of out-of-distribution detection.",
                "author": "Stanislav Fort, Jie Ren, and Balaji Lakshminarayanan. 2021.",
                "venue": "Advances in Neural Information Processing Systems,\n34:7068\u20137081.",
                "url": "https://openreview.net/pdf?id=j5NrN8ffXC"
            }
        },
        {
            "11": {
                "title": "Black-box generation\nof adversarial text sequences to evade deep learning classifiers.",
                "author": "Ji Gao, Jack Lanchantin, Mary Lou Soffa, and Yanjun Qi. 2018.",
                "venue": "In 2018 IEEE Security and Privacy Workshops (SPW).",
                "url": "https://doi.org/10.1109/SPW.2018.00016"
            }
        },
        {
            "12": {
                "title": "BAE:\nBERT-based adversarial examples for text classification.",
                "author": "Siddhant Garg and Goutham Ramakrishnan. 2020.",
                "venue": "In Proceedings of the 2020 Conference on Empirical Methods in\nNatural Language Processing (EMNLP).",
                "url": "https://doi.org/10.18653/v1/2020.emnlp-main.498"
            }
        },
        {
            "13": {
                "title": "ChatGPT\noutperforms crowd-workers for text-annotation tasks.",
                "author": "Fabrizio Gilardi, Meysam Alizadeh, and Ma\u00ebl Kubli. 2023.",
                "venue": "Proceedings of the National Academy of Sciences, 120(30).",
                "url": "https://www.pnas.org/doi/10.1073/pnas.2305016120"
            }
        },
        {
            "14": {
                "title": "Explaining and\nharnessing adversarial examples.",
                "author": "Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015.",
                "venue": "In Proceedings of the International Conference on Learning\nRepresentations (ICLR).",
                "url": "https://arxiv.org/pdf/1412.6572.pdf"
            }
        },
        {
            "15": {
                "title": "Semantic parsing for\ntask oriented dialog using hierarchical representations.",
                "author": "Sonal Gupta, Rushin Shah, Mrinal Mohit, Anuj Kumar, and Mike Lewis. 2018.",
                "venue": "In Proceedings of the 2018 Conference on Empirical Methods in\nNatural Language Processing (EMNLP).",
                "url": "https://doi.org/10.18653/v1/D18-1300"
            }
        },
        {
            "16": {
                "title": "If in a crowdsourced\ndata annotation pipeline, a GPT-4.",
                "author": "Zeyu He, Huang Chieh-Yang, Chien-Kuang Cornelia Ding, Shaurya Rohatgi, and\nTing-Hao \u2019Kenneth\u2019 Huang. 2024.",
                "venue": "arXiv preprint arXiv:2402.16795.",
                "url": "https://arxiv.org/pdf/2402.16795.pdf"
            }
        },
        {
            "17": {
                "title": "The ATIS spoken language\nsystems pilot corpus.",
                "author": "Charles T. Hemphill, John J. Godfrey, and George R. Doddington. 1990.",
                "venue": "In Speech and Natural Language: Proceedings of a Workshop Held\nat Hidden Valley, Pennsylvania, June 24-27,1990.",
                "url": "https://aclanthology.org/H90-1021"
            }
        },
        {
            "18": {
                "title": "A baseline for\ndetecting misclassified and out-of-distribution examples in neural networks.",
                "author": "Dan Hendrycks and Kevin Gimpel. 2016.",
                "venue": "In Proceedings of International Conference on Learning\nRepresentations (ICLR).",
                "url": "https://arxiv.org/pdf/1610.02136.pdf"
            }
        },
        {
            "19": {
                "title": "Multi-site data collection\nand evaluation in spoken language understanding.",
                "author": "L. Hirschman, M. Bates, D. Dahl, W. Fisher, J. Garofolo, D. Pallett,\nK. Hunicke-Smith, P. Price, A. Rudnicky, and E. Tzoukermann. 1993.",
                "venue": "In Human Language Technology: Proceedings of a Workshop\nHeld at Plainsboro, New Jersey, March 21-24, 1993.",
                "url": "https://aclanthology.org/H93-1004"
            }
        },
        {
            "20": {
                "title": "Multi-site data collection\nfor a spoken language corpus.",
                "author": "Lynette Hirschman, Madeleine Bates, Deborah Dahl, William Fisher, John\nGarofolo, and Kate Hunicke-Smith. 1992.",
                "venue": "In Speech and Natural Language: Proceedings of a Workshop Held\nat Harriman, New York, February 23-26, 1992.",
                "url": "https://aclanthology.org/H92-1003"
            }
        },
        {
            "21": {
                "title": "Mining hard negative\nsamples for sar-optical image matching using generative adversarial\nnetworks.",
                "author": "Lloyd Haydn Hughes, Michael Schmitt, and Xiao Xiang Zhu. 2018.",
                "venue": "Remote Sensing, 10(10).",
                "url": "https://doi.org/10.3390/rs10101552"
            }
        },
        {
            "22": {
                "title": "Hard negative mixing for contrastive learning.",
                "author": "Yannis Kalantidis, Mert Bulent Sariyildiz, Noe Pion, Philippe Weinzaepfel, and\nDiane Larlus. 2020.",
                "venue": "Advances in Neural Information Processing Systems,\n33:21798\u201321809.",
                "url": "https://proceedings.neurips.cc/paper/2020/file/f7cade80b7cc92b991cf4d2806d6bd78-Paper.pdf"
            }
        },
        {
            "23": {
                "title": "Data collection for\ndialogue system: A startup perspective.",
                "author": "Yiping Kang, Yunqi Zhang, Jonathan K. Kummerfeld, Lingjia Tang, and Jason Mars.\n2018.",
                "venue": "In Proceedings of the 2018 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language\nTechnologies, Volume 3 (Industry Papers).",
                "url": "https://doi.org/10.18653/v1/N18-3005"
            }
        },
        {
            "24": {
                "title": "Benchmarking the\ncovariate shift robustness of open-world intent classification approaches.",
                "author": "Sopan Khosla and Rashmi Gangadharaiah. 2022.",
                "venue": "In Proceedings of the 2nd Conference of the Asia-Pacific\nChapter of the Association for Computational Linguistics and the 12th\nInternational Joint Conference on Natural Language Processing (AACL-IJCNLP).",
                "url": "https://aclanthology.org/2022.aacl-short.3"
            }
        },
        {
            "25": {
                "title": "Quantifying\nand avoiding unfair qualification labour in crowdsourcing.",
                "author": "Jonathan K. Kummerfeld. 2021.",
                "venue": "In Proceedings of the 59th Annual Meeting of the Association\nfor Computational Linguistics and the 11th International Joint Conference on\nNatural Language Processing (ACL-IJCNLP).",
                "url": "https://doi.org/10.18653/v1/2021.acl-short.44"
            }
        },
        {
            "26": {
                "title": "Inconsistencies in crowdsourced slot-filling annotations: A typology and\nidentification methods.",
                "author": "Stefan Larson, Adrian Cheung, Anish Mahendran, Kevin Leach, and Jonathan K.\nKummerfeld. 2020a.",
                "venue": "In Proceedings of the 28th International Conference on\nComputational Linguistics (COLING).",
                "url": "https://doi.org/10.18653/v1/2020.coling-main.442"
            }
        },
        {
            "27": {
                "title": "Redwood: Using\ncollision detection to grow a large-scale intent classification dataset.",
                "author": "Stefan Larson and Kevin Leach. 2022a.",
                "venue": "In Proceedings of the 23rd Annual Meeting of the Special\nInterest Group on Discourse and Dialogue (SIGDIAL).",
                "url": "https://doi.org/10.18653/v1/2022.sigdial-1.45"
            }
        },
        {
            "28": {
                "title": "A survey on intent\nclassification and slot-filling datasets for task-oriented dialog.",
                "author": "Stefan Larson and Kevin Leach. 2022b.",
                "venue": "arXiv preprint arXiv:2207.13211.",
                "url": "https://arxiv.org/pdf/2207.13211.pdf"
            }
        },
        {
            "29": {
                "title": "Evaluating out-of-distribution performance on document image classifiers.",
                "author": "Stefan Larson, Gordon Lim, Yutong Ai, David Kuang, and Kevin Leach. 2022.",
                "venue": "In Proceedings of the Thirty-sixth Conference on Neural\nInformation Processing Systems Datasets and Bench marks Track.",
                "url": "https://papers.nips.cc/paper_files/paper/2022/file/4c0986bd04d747745beba3752bdf4d9d-Paper-Datasets_and_Benchmarks.pdf"
            }
        },
        {
            "30": {
                "title": "Outlier detection for\nimproved data quality and diversity in dialog systems.",
                "author": "Stefan Larson, Anish Mahendran, Andrew Lee, Jonathan K. Kummerfeld, Parker\nHill, Michael A. Laurenzano, Johann Hauswald, Lingjia Tang, and Jason Mars.\n2019a.",
                "venue": "In Proceedings of the 2019 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language\nTechnologies (NAACL-HLT).",
                "url": "https://doi.org/10.18653/v1/N19-1051"
            }
        },
        {
            "31": {
                "title": "An evaluation dataset\nfor intent classification and out-of-scope prediction.",
                "author": "Stefan Larson, Anish Mahendran, Joseph J. Peper, Christopher Clarke, Andrew\nLee, Parker Hill, Jonathan K. Kummerfeld, Kevin Leach, Michael A. Laurenzano,\nLingjia Tang, and Jason Mars. 2019b.",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in\nNatural Language Processing and the 9th International Joint Conference on\nNatural Language Processing (EMNLP-IJCNLP).",
                "url": "https://doi.org/10.18653/v1/D19-1131"
            }
        },
        {
            "32": {
                "title": "Iterative\nfeature mining for constraint-based data collection to increase data\ndiversity and model robustness.",
                "author": "Stefan Larson, Anthony Zheng, Anish Mahendran, Rishi Tekriwal, Adrian Cheung,\nEric Guldan, Kevin Leach, and Jonathan K Kummerfeld. 2020b.",
                "venue": "In Proceedings of the 2020 Conference on Empirical Methods in\nNatural Language Processing (EMNLP).",
                "url": "https://aclanthology.org/2020.emnlp-main.650.pdf"
            }
        },
        {
            "33": {
                "title": "Robustness\ntesting of language understanding in task-oriented dialog.",
                "author": "Jiexi Liu, Ryuichi Takanobu, Jiaxin Wen, Dazhen Wan, Hongguang Li, Weiran Nie,\nCheng Li, Wei Peng, and Minlie Huang. 2021.",
                "venue": "In Proceedings of the 59th Annual Meeting of the Association\nfor Computational Linguistics and the 11th International Joint Conference on\nNatural Language Processing (ACL-IJCNLP).",
                "url": "https://doi.org/10.18653/v1/2021.acl-long.192"
            }
        },
        {
            "34": {
                "title": "Energy-based out-of-distribution detection.",
                "author": "Weitang Liu, Xiaoyun Wang, John Owens, and Yixuan Li. 2020.",
                "venue": "In Proceedings of the 34th Conference on Neural Information\nProcessing Systems (NeurIPS).",
                "url": "https://proceedings.neurips.cc/paper/2020/file/f5496252609c43eb8a3d147ab9b9c006-Paper.pdf"
            }
        },
        {
            "35": {
                "title": "Benchmarking natural\nlanguage understanding services for building conversational agents.",
                "author": "Xingkun Liu, Arash Eshghi, Pawel Swietojanski, and Verena Rieser.\n2019a.",
                "venue": "In Proceedings of the Tenth International Workshop on Spoken\nDialog Systems Technology (IWSDS).",
                "url": "https://arxiv.org/pdf/1903.05566.pdf"
            }
        },
        {
            "36": {
                "title": "RoBERTa: A robustly\noptimized BERT pretraining approach.",
                "author": "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer\nLevy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019b.",
                "venue": "arXiv preprint arXiv:1907.11692.",
                "url": "https://arxiv.org/pdf/1907.11692.pdf"
            }
        },
        {
            "37": {
                "title": "Siamese network features for image matching.",
                "author": "Iaroslav Melekhov, Juho Kannala, and Esa Rahtu. 2016.",
                "venue": "In Proceedings of the International Conference on Pattern\nRecognition (ICPR).",
                "url": "https://users.aalto.fi/~kannalj1/publications/icpr2016.pdf"
            }
        },
        {
            "38": {
                "title": "Passage-based\nBM25 hard negatives: A simple and effective negative sampling strategy for\ndense retrieval.",
                "author": "Thanh-Do Nguyen, Chi Minh Bui, Thi-Hai-Yen Vuong, and Xuan-Hieu Phan. 2023.",
                "venue": "In Proceedings of the 37th Pacific Asia Conference on Language,\nInformation and Computation.",
                "url": "https://aclanthology.org/2023.paclic-1.59"
            }
        },
        {
            "39": {
                "title": "Scikit-learn: Machine learning in Python.",
                "author": "Fabian Pedregosa, Ga\u00ebl Varoquaux, Alexandre Gramfort, Vincent Michel,\nBertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron\nWeiss, Vincent Dubourg, et al. 2011.",
                "venue": "Journal of Machine Learning Research, 12(Oct):2825\u20132830.",
                "url": "https://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf"
            }
        },
        {
            "40": {
                "title": "RADDLE: An\nevaluation benchmark and analysis platform for robust task-oriented dialog\nsystems.",
                "author": "Baolin Peng, Chunyuan Li, Zhu Zhang, Chenguang Zhu, Jinchao Li, and Jianfeng\nGao. 2021.",
                "venue": "In Proceedings of the 59th Annual Meeting of the Association\nfor Computational Linguistics and the 11th International Joint Conference on\nNatural Language Processing (ACL-IJCNLP).",
                "url": "https://doi.org/10.18653/v1/2021.acl-long.341"
            }
        },
        {
            "41": {
                "title": "Generating natural\nlanguage adversarial examples through probability weighted word saliency.",
                "author": "Shuhuai Ren, Yihe Deng, Kun He, and Wanxiang Che. 2019.",
                "venue": "In Proceedings of the 57th Annual Meeting of the Association\nfor Computational Linguistics (ACL).",
                "url": "https://doi.org/10.18653/v1/P19-1103"
            }
        },
        {
            "42": {
                "title": "LINGUIST:\nLanguage model instruction tuning to generate annotated utterances for intent\nclassification and slot tagging.",
                "author": "Andy Rosenbaum, Saleh Soltan, Wael Hamza, Yannick Versley, and Markus Boese.\n2022.",
                "venue": "In Proceedings of the 29th International Conference on\nComputational Linguistics (COLING).",
                "url": "https://aclanthology.org/2022.coling-1.18"
            }
        },
        {
            "43": {
                "title": "Data\naugmentation for intent classification with off-the-shelf large language\nmodels.",
                "author": "Gaurav Sahu, Pau Rodriguez, Issam Laradji, Parmida Atighehchian, David Vazquez,\nand Dzmitry Bahdanau. 2022.",
                "venue": "In Proceedings of the 4th Workshop on NLP for Conversational\nAI.",
                "url": "https://doi.org/10.18653/v1/2022.nlp4convai-1.5"
            }
        },
        {
            "44": {
                "title": "DistilBERT, a\ndistilled version of BERT: smaller, faster, cheaper and lighter.",
                "author": "Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019.",
                "venue": "arXiv preprint arXiv:1910.01108.",
                "url": "https://arxiv.org/pdf/1910.01108.pdf"
            }
        },
        {
            "45": {
                "title": "On the\nrobustness of intent classification and slot labeling in goal-oriented dialog\nsystems to real-world noise.",
                "author": "Sailik Sengupta, Jason Krone, and Saab Mansour. 2021.",
                "venue": "In Proceedings of the 3rd Workshop on Natural Language\nProcessing for Conversational AI.",
                "url": "https://doi.org/10.18653/v1/2021.nlp4convai-1.7"
            }
        },
        {
            "46": {
                "title": "No oops, you\nwon\u2019t do it again: mechanisms for self-correction in crowdsourcing.",
                "author": "Nihar Shah and Dengyong Zhou. 2016.",
                "venue": "In Proceedings of the 33rd International Conference on Machine\nLearning (ICML).",
                "url": "https://proceedings.mlr.press/v48/shaha16.pdf"
            }
        },
        {
            "47": {
                "title": "ChatGPT-4 outperforms\nexperts and crowd workers in annotating political twitter messages with\nzero-shot learning.",
                "author": "Petter T\u00f6rnberg. 2023.",
                "venue": "arXiv preprint arXiv:2304.06588.",
                "url": "https://arxiv.org/pdf/2304.06588.pdf"
            }
        },
        {
            "48": {
                "title": "Transformers:\nState-of-the-art natural language processing.",
                "author": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,\nAnthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe\nDavison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien\nPlu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,\nand Alexander Rush. 2020.",
                "venue": "In Proceedings of the 2020 Conference on Empirical Methods in\nNatural Language Processing: System Demonstrations.",
                "url": "https://doi.org/10.18653/v1/2020.emnlp-demos.6"
            }
        },
        {
            "49": {
                "title": "Optimizing dense\nretrieval model training with hard negatives.",
                "author": "Jingtao Zhan, Jiaxin Mao, Yiqun Liu, Jiafeng Guo, Min Zhang, and Shaoping Ma.\n2021.",
                "venue": "In Proceedings of the 44th International ACM SIGIR Conference\non Research and Development in Information Retrieval.",
                "url": "https://arxiv.org/pdf/2104.08051.pdf"
            }
        },
        {
            "50": {
                "title": "Are\npre-trained transformers robust in intent classification? a missing\ningredient in evaluation of out-of-scope intent detection.",
                "author": "Jianguo Zhang, Kazuma Hashimoto, Yao Wan, Zhiwei Liu, Ye Liu, Caiming Xiong,\nand Philip Yu. 2022.",
                "venue": "In Proceedings of the 4th Workshop on NLP for Conversational\nAI.",
                "url": "https://doi.org/10.18653/v1/2022.nlp4convai-1.2"
            }
        },
        {
            "51": {
                "title": "Can ChatGPT\nreproduce human-generated labels? a study of social computing tasks.",
                "author": "Yiming Zhu, Peixian Zhang, Ehsan-Ul Haq, Pan Hui, and Gareth Tyson. 2023.",
                "venue": "arXiv preprint arXiv:2304.10145.",
                "url": "https://arxiv.org/pdf/2304.10145.pdf"
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.05640v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.1",
            "2.2",
            "2.3",
            "2.4"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.2",
            "4.3",
            "5",
            "5.1",
            "5.2",
            "5.3"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4",
            "5.2",
            "5.3"
        ]
    },
    "research_context": {
        "paper_id": "2403.05640v1",
        "paper_title": "Generating Hard-Negative Out-of-Scope Data with ChatGPT for Intent Classification",
        "research_background": "### Paper's Motivation\n\nThe motivation behind this paper is to develop robust intent classification models for task-oriented dialog systems. Such systems need to accurately classify user utterances and identify out-of-scope (OOS) utterances that do not belong to any predefined intents. Ensuring that the intent classifiers can distinguish OOS utterances is crucial because failure to do so can result in poor user experiences, wastage of time and resources, and potential safety concerns. The paper addresses the challenge of developing techniques to ensure robustness against OOS utterances, especially those that closely resemble in-scope (INS) utterances but convey different meanings\u2014termed as hard-negative OOS utterances.\n\n### Research Problem\n\nThe primary research problem addressed in this paper is twofold:\n1. The lack of robust techniques and large public datasets needed to improve the OOS detection capabilities of intent classifiers.\n2. The difficulty of generating hard-negative OOS data that closely resemble in-scope samples but are challenging for the intent classifiers to correctly identify as OOS.\n\nThe paper aims to answer the following research questions:\n- Can ChatGPT generate OOS utterances that do not fall into any of the system-supported INS intents?\n- Do the generated hard-negative OOS utterances lead to high-confidence predictions from intent classifiers?\n- Can the generated hard-negative OOS utterances be used in training to improve the intent classifiers\u2019 OOS detection ability and decrease the models\u2019 confidence on the supported intents when encountering OOS utterances?\n\n### Relevant Prior Work\n\nThe related work in this area includes efforts in collecting and labeling INS training data through crowd-sourcing, as noted by Kang et al. (2018) and Larson and Leach (2022b). However, the collection of OOS datasets to enhance classifiers\u2019 OOS detection abilities is less common, as seen in Larson et al. (2019b). The existing general OOS datasets contain samples with minimal similarity to the INS samples, which does not rigorously test the models' OOS detection capabilities during real-world deployment.\n\nCrowd-sourcing has been used for OOS data collection, but it is costly, time-consuming, and prone to errors, as highlighted by Shah and Zhou (2016) and Larson et al. (2020a). Issues related to verifying large-scale OOS data are exacerbated in datasets with numerous intents, such as Clinc-150, making it impractical for human workers to verify relevancy accurately (Larson et al. (2019b)).\n\nA cost-effective alternative proposed involves generating hard-negative OOS data using large language models like ChatGPT. Previous crowd-sourcing costs (e.g., $0.20 per three paraphrases, according to Larson et al. (2019b)) and best-practice wage rates (Kummerfeld, 2021) suggest significant cost savings could be achieved using language model APIs, with GPT-3.5-turbo costing only $0.0015 per 1K tokens in the prompt and $0.003 per 1K tokens for the output.",
        "methodology": "In this study, we introduce an automated method aimed at generating hard-negative out-of-scope (OOS) utterances utilizing ChatGPT's API. Specifically, we generate a total of 3,732 hard-negative OOS queries across five benchmark datasets. Our primary goal is to create OOS utterances that include words which significantly influence intent classifiers' predictions, thereby producing more challenging negative examples.\n\n#### Steps for Generating Hard-Negative OOS Datasets:\n\n1. **Feature Mining for Keywords**: Begin with analyzing the most frequently occurring words within each intent for the selected datasets. This enables the identification of a set of keywords for each intent.\n\n2. **Keyword Selection**: Choose a combination of these keywords for each intent to use in the prompt.\n\n3. **Providing Context to ChatGPT**: Present ChatGPT with the name of the intent along with five in-scope (INS) utterances.\n\n4. **Generating Utterances**: Prompt ChatGPT to generate questions (or utterances) that must contain the selected keywords but should not be related to the given intent.\n\n5. **Verification of Generated Questions**: Ensure that ChatGPT confirms that each generated question is unrelated to the given intent.\n\n6. **Cross-Intent Verification**: Lastly, prompt ChatGPT to ensure that the generated questions are not related to any intents across the entire dataset.\n\nThis methodology leverages the natural language generation capabilities of ChatGPT to build robust hard-negative examples. This enriched data can potentially make intent classification systems more accurate by better discerning between in-scope and out-of-scope queries.",
        "main_experiment_and_results": "### Main Experiment Setup and Results:\n\n**Goal**:\nThe main objective of this experiment is to measure how well intent classifiers can distinguish between in-scope (INS) data and hard-negative out-of-scope (OOS) data generated using ChatGPT.\n\n**Datasets**:\n- **In-Scope (INS) Data**: Derived from five publicly available datasets:\n  - Clinc-150 (Larson et al., 2019b)\n  - Banking77 (Casanueva et al., 2020)\n  - ATIS (Hemphill et al., 1990; Hirschman et al., 1992, 1993; Dahl et al., 1994)\n  - Snips (Coucke et al., 2018)\n  - HWU64 (Liu et al., 2019a)\n  - Note: For HWU64, the intents \"General_Quirky\" and \"QA_Factoid\" were excluded to better identify OOS intents.\n\n- **Hard-Negative OOS Data**: 3,732 samples generated to target the intents of the five INS datasets.\n- **General OOS Data**: From Clinc-150's companion OOS dataset, consisting of 1,000 test utterances. These were filtered to remove any overlapping intents with the INS datasets.\n\n**Baselines**:\n- Models are tested on their ability to distinguish INS data from \"general\" (non-hard-negative) OOS data as a baseline comparison.\n\n**Training and Testing**:\n- The datasets are split into training and testing partitions.\n- Models are trained on INS training data and evaluated on:\n  1. INS testing data\n  2. Generated hard-negative OOS data\n  3. General OOS data from Clinc-150\n\n**Hypothesis**:\nIt is hypothesized that models will face performance decreases when hard-negative OOS data is included because these samples are confusingly similar to INS data.\n\n**Evaluation Metrics**:\n- Models\u2019 confidence in correctly identifying OOS instances.\n- The ability of models to discriminate between INS and OOS under different training conditions.\n\n### Main Experimental Results:\n(Specific numerical results are not provided in the text, but generally, the results would encompass measurements of model performance across the different conditions outlined above, such as accuracy, precision, recall, F1 score, and possibly other metrics relevant to intent classification and OOS detection capabilities.)\n\nBy including both types of OOS data in training and observing changes in the model's detection performance, the study aims to validate the hypothesis that using hard-negative OOS data can improve the robustness of intent classifiers."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "The goal of this ablation study is to assess the difficulty that intent classifiers have when discerning between in-scope (INS) and hard-negative out-of-scope (OOS) data, and to evaluate the improvements in the models' OOS detection abilities after including hard-negative OOS and general OOS data in training.",
            "experiment_process": "The study uses INS data from five datasets: Clinc-150, Banking77, ATIS, Snips, and HWU64. Hard-negative OOS samples are generated using ChatGPT, resulting in 3,732 samples. A baseline is established using general OOS data, specifically the Clinc-150 companion OOS data. The data is split into training and testing sets. Three models, BERT, RoBERTa, and DistilBERT, are trained on INS data and then evaluated on INS testing data, the generated hard-negative OOS data, and the general OOS data. The study also examines whether incorporating hard-negative OOS data during training can improve OOS detection capabilities, with further training splits and model evaluations configured accordingly.",
            "result_discussion": "The results show that classifiers struggle more to correctly identify hard-negative OOS utterances than general OOS utterances. Specifically, confidence scores for hard-negative OOS predictions are closer to those for INS data than general OOS predictions. AUROC scores are lower, and FPR95 scores are higher for hard-negative OOS vs. INS than for general OOS vs. INS, indicating a significant overlap in confidence scores between INS data and hard-negative OOS data. The findings suggest that the hard-negative OOS data generated are at least as challenging as general OOS data and frequently result in high-confidence incorrect predictions from intent classifiers.",
            "ablation_id": "2403.05640v1.No1"
        },
        {
            "research_objective": "To determine if including hard-negative OOS data in training improves model robustness against both hard-negative OOS and general OOS utterances.",
            "experiment_process": "Transformer-based intent classifiers (BERT, RoBERTa, DistilBERT) are trained under three conditions: (1) on INS and general OOS data, (2) on INS and hard-negative OOS data, and (3) on INS, general OOS, and hard-negative OOS data. The datasets are split in an 80/20 ratio for training and testing. The confidence scores for each prediction are evaluated using the highest softmax score for any in-scope intent, representing the confidence in predicting that an utterance belongs to a known intent. The AUROC of the softmax confidence scores is measured for INS, general OOS, and hard-negative OOS data.",
            "result_discussion": "Models trained with general OOS data show a substantial drop in confidence scores for general OOS utterances but still maintain high confidence for hard-negative OOS utterances. Incorporating hard-negative OOS data in training results in low confidence for both types of OOS utterances, improving robustness. However, for Snips and HWU64 datasets, training with only hard-negative OOS is insufficient, highlighting the need to use both hard-negative OOS and general OOS for comprehensive model robustness. The study indicates that while training with both types of OOS data improves detection, it cannot cover every possible OOS intent, but it enhances overall model robustness and benchmarking.",
            "ablation_id": "2403.05640v1.No2"
        }
    ]
}