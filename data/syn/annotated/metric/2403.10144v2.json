{
    "title": "NLP Verification: Towards a General Methodology for Certifying Robustness",
    "abstract": "Deep neural networks (DNNs) have exhibited substantial success in the field of Natural Language Processing (NLP). As these systems are increasingly integrated into real-world applications, ensuring their safety and reliability becomes a primary concern. There are safety-critical contexts where such models must be robust to variability or attack, and give guarantees over their output. Computer Vision had pioneered the use of formal verification for neural networks for such scenarios and developed common verification standards and pipelines. In contrast, NLP verification methods have only recently appeared in the literature. They are often light on the pragmatic issues of NLP verification, and the area remains fragmented.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Deep neural networks (DNNs) have demonstrated remarkable success at addressing challenging problems in various areas, such as Computer Vision (CV) and Natural Language Processing (NLP). However, as DNN-based systems are increasingly deployed in safety-critical applications, ensuring their safety and security becomes paramount. Current NLP systems cannot guarantee either truthfulness, accuracy, faithfulness, or groundedness of outputs given an input query, which can lead to different levels of harm.\n\nOne requirement in the NLP domain is the requirement of a chatbot to correctly disclose non-human identity when prompted by the user. Recently there have been several pieces of legislation proposed that will enshrine this requirement in law. In theory, the underlying DNN of the chatbot (or the sub-system responsible for identifying these queries) must be 100% accurate in its recognition of such a query. However, a central theme of generative linguistics going back to von Humboldt is that language is \u2018an infinite use of finite means,\u2019 meaning there exist many ways to say the same thing. In reality, questions can come in a near-infinite number of different forms, all with similar semantic meanings. For example: \u201cAre you a Robot?\u201d, \u201cAm I speaking with a person?\u201d, \u201cAm I texting to a real human?\u201d, \u201cAren\u2019t you a chatbot?\u201d.\n\nFailure to recognize the user\u2019s intent and thus failure to answer the question correctly could potentially have legal implications for designers of these systems. Similarly, as such systems become widespread, it may be desirable to have guarantees on queries concerning safety-critical domains, for example when the user asks for medical advice. Research has shown that users tend to attribute undue expertise to systems, potentially causing real world harm.\n\nA question remains on how to ensure that NLP systems can give formally guaranteed outputs, particularly for scenarios that require maximum control over the output. One possible solution is to apply formal verification techniques to deep neural networks (DNN), ensuring that output satisfies the desired properties. This example is an instance of the more general problem of DNN robustness verification, where the aim is to guarantee that every point in a given region of the embedding space is classified correctly.\n\nGiven a network, one defines subspaces of the vector space. For example, one can define subspaces around all input vectors given by the dataset in question (in which case the number of subspaces will correspond to the number of samples in the dataset). Then, using a verification algorithm, each subspace is checked for robustness. Note that each subspace is infinite (i.e., continuous), and thus verification is usually based on equational reasoning, abstract interpretation or bound propagation.\n\nDue to the embedding gap, a small fraction of vectors contained in verified subspaces map back to valid sentences. When a verified subspace contains no or very few sentence embeddings, it is said to have low generalisability, which may render verification efforts ineffective for practical applications. From the NLP perspective, the embedding gap can manifest in subtle ways. Consider a subspace containing sentences semantically similar to \u2018I really like to chat to a human. Are you one?\u2019. If the DNN is robust on this subspace, it will identify sentences in this subspace as questions about human/robot identity. However, if an embedding function wrongly embeds opposite class sentences into this subspace, it could falsify verification.\n\nVerification in NLP is susceptible to such problems because the embedding function is not invertible, making it difficult to cross the embedding gap. We propose a general method for measuring generalisability of the verified subspaces based on algorithmic generation of semantic attacks on sentences included in the verified semantic subspace.\n\nAn alternative to geometric approaches is to construct subspaces of the embedding space based on semantic perturbations of sentences. This involves embedding a sentence and its semantic perturbations into a real vector space and enclosing them within a geometric shape. Calculating convex hulls is computationally infeasible for high dimensions, so simpler shapes like hyper-cubes and hyper-rectangles are used. We propose a novel refinement by including hyper-rectangle rotation to increase shape precision, calling the resulting shapes semantic subspaces.\n\nFor robust training regimes in NLP verification, it was unclear whether success resulted from general decision boundary improvements, adversarial robustness, or semantic knowledge. Through experiments, we confirm that semantic subspaces are more generalisable. We conclude that semantically robust training typically outperforms standard methods. For instance, using strong attacks like polyjuice in training, we obtain more generalisable DNNs. Thus, we propose a fully parametric NLP verification approach, disentangling the semantic attack choice, semantic subspace formation, semantically robust training, and verification algorithm choice. This approach, along with the new generalisability metric, offers more principled evaluation of NLP verification methods accounting for the embedding gap and facilitates more transparent benchmarks.\n\nWe implement a tool, ANTONIO, generating NLP verification benchmarks based on the above choices. This paper pioneers using a complete SMT-based verifier for NLP"
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "DNN Verification",
            "text": "Formal verification is an active field across several domains including hardware [23  ###reference_b23###, 24  ###reference_b24###], software languages [25  ###reference_b25###], network protocols [26  ###reference_b26###] and many more [27  ###reference_b27###]. However, it was only recently that this\nbecame applicable to the field of machine learning [28  ###reference_b28###].\nAn input query to a verifier consists of a subspace within the embedding space and a target subspace of outputs, typically a target output class.\nThe verifier then returns either true, false or unknown. True indicates that there exists an input within the given input subspace whose output falls within the given output subspace, often accompanied by an example of such input. False indicates that no such input exists.\nSeveral verifiers are popular in DNN verification and competitions [29  ###reference_b29###, 30  ###reference_b30###, 31  ###reference_b31###, 32  ###reference_b32###].\nWe can divide them into 2 main categories: complete verifiers which return true/false and incomplete verifiers which return true/unknown.\nWhile complete verifiers are always deterministic, incomplete verifiers may be probabilistic.\nUnlike deterministic verification, probabilistic verification is not sound and a verifier may incorrectly output true with a very low probability (typically 0.01%).\nComplete Verification based on Linear Programming & SMT solving.\nThis group of verification methods [33  ###reference_b33###, 28  ###reference_b28###, 22  ###reference_b22###] is built upon the observation that feed-forward neural networks are defined by the sequential composition of affine transformations and non-linear activation functions.\nWhen the activation functions are piecewise linear\n(e.g. ReLU), the DNN can be encoded by conjunctions and disjunctions\nof linear inequalities and thus linear programming algorithms can be directly applied to solve the satisfiability problem, yielding a solution to complete verification.\nA state-of-the-art tool is Marabou [22  ###reference_b22###], which answers queries about neural networks and their properties in the form of constraint satisfaction problems. Marabou takes the network as input and first applies multiple pre-processing steps to infer bounds for each node in the network. It applies the algorithm ReLUplex [28  ###reference_b28###], a combination of Simplex [34  ###reference_b34###] search over linear constraints, modified to work for networks with piece-wise linear activation functions. With time, Marabou grew into a complex prover with multiple heuristics supplementing the original ReLUplex algorithm [22  ###reference_b22###], for example it now includes abstract interpretation and MILP-based algorithms which we survey below.\nIncomplete Verification based on Abstract Interpretation takes inspiration from the domain of abstract interpretation, and mainly uses linear relaxations on ReLU neurons, resulting in an over-approximation of the initial constraint.\nAbstract interpretation was first developed by Cousot and Cousot [35  ###reference_b35###] in 1977. It formalises the idea of abstraction of mathematical structures, in particular those involved in the specification of properties and proof methods of computer systems [36  ###reference_b36###] and it has since been used in many applications [37  ###reference_b37###].\nSpecifically, for DNN verification, this technique can model the behaviour of a network using an abstract domain that captures the possible range of values the network can output for a given input.\nAbstract interpretation-based verifiers can define a lower bound and an upper bound of the output of each ReLU neuron as linear constraints, which define a region called ReLU polytope that gets propagated through the network.\nOne can use interval bound propagation (IBP) [38  ###reference_b38###, 39  ###reference_b39###, 40  ###reference_b40###, 41  ###reference_b41###].\nThe strength of IBP-based methods lies in their efficiency; they are faster than alternative approaches and demonstrate superior scalability. However, their primary limitation lies in the inherently loose bounds they produce [39  ###reference_b39###]. This drawback becomes particularly pronounced in the case of deeper neural networks, typically those with more than 10 layers [42  ###reference_b42###], where they cannot certify non-trivial robustness due to the amplification of over-approximation.\nOther methods that are less efficient but produce tighter bounds are based on polyhedra abstraction, such as CROWN [43  ###reference_b43###] and DeepPoly [44  ###reference_b44###], or based on multi-neuron relaxation, such as PRIMA [45  ###reference_b45###].\nOne of the most mature tools in this category is ERAN [46  ###reference_b46###], which can be used for complete verification, but its main purpose is deterministic incomplete verification through abstract interpretation (DeepPoly) and multi-neuron relaxation (PRIMA).\nMILP-based approaches [47  ###reference_b47###, 48  ###reference_b48###, 49  ###reference_b49###] encode the verification problem as a mixed-integer linear programming problem, in which the constraints are linear inequalities and the objective is represented by a linear function.\nThus, the DNN verification problem can be precisely encoded as a MILP problem.\nFor example, ERAN [46  ###reference_b46###], which is mainly used as an incomplete verifier combines abstract interpretation with the MILP solver GUROBI [50  ###reference_b50###].\nERAN uses abstract domains with custom multi-neuron relaxations to support fully-connected, convolutional, and residual networks with ReLU, Sigmoid, Tanh, and Maxpool activations.\nBaB-based verification [51  ###reference_b51###, 52  ###reference_b52###, 53  ###reference_b53###, 54  ###reference_b54###, 55  ###reference_b55###, 56  ###reference_b56###, 57  ###reference_b57###] relies on the piecewise linear property of DNNs: since each ReLU neuron outputs ReLU() = max{,} is piecewise linear, we can consider its two linear pieces ,  separately.\nA BaB verification approach, as the name suggests, consists of two parts: branching and bounding. It first applies incomplete verification to derive a lower bound and an upper bound, then, if the lower bound is positive it terminates with \u2018verified\u2019, else, if the upper bound is non-positive it terminates with \u2018not verified\u2019 (bounding). Otherwise, the approach recursively chooses a neuron to split into two branches (branching), resulting in two linear constraints. Then bounding is applied to both constraints and if both are satisfied the verification terminates, otherwise the other neurons are split recursively. When all neurons are split, the branch will contain only linear constraints, and thus the approach applies linear programming to compute the constraint and verify the branch.\nIt is important to note that BaB approaches themselves are neither inherently complete nor incomplete. BaB is an algorithm for splitting problems into sub-problems and requires a solver to resolve the linear constraints. The completeness of the verification depends on the combination of BaB and the solver used.\nMulti-Neuron Guided Branch-and-Bound (MN-BaB) [54  ###reference_b54###] is a state-of-the-art neural network verifier that builds on the tight multi-neuron constraints proposed in PRIMA [58  ###reference_b58###] and leverages these constraints within a BaB framework to yield an efficient, GPU based dual solver.\nAnother state-of-the-art tool is -CROWN [59  ###reference_b59###, 56  ###reference_b56###], a neural network verifier based on an efficient linear bound propagation framework and branch-and-bound. It can be accelerated efficiently on GPUs and can scale to relatively large convolutional networks (e.g.,  parameters).\nIt also supports a wide range of neural network architectures (e.g., CNN, ResNet, and various activation functions).\nBaB-based methods are more scalable than solver-based approaches, however they introduce a level of abstraction and sacrifice precision in favor of scalability. For example GCP-CROWN [57  ###reference_b57###] extracts convex constraints from MILP solvers and integrates them in linear inequality propagation, which can be viewed as leveraging multi-neuron relaxations in branch-and-bound complete verification.\nProbabilistic incomplete verification approaches add random noise to smooth models, and then derive certified robustness for these smoothed models.\nThis field is commonly referred to as Randomised Smoothing,\ngiven that these approaches provide probabilistic guarantees of robustness, and all current probabilistic verification techniques are tailored for smoothed models [60  ###reference_b60###, 61  ###reference_b61###, 62  ###reference_b62###, 63  ###reference_b63###, 64  ###reference_b64###, 65  ###reference_b65###].\nGiven that this work focuses on deterministic approaches, here we only report the existence of this line of work without going into details.\nNote that these existing verification approaches primarily focus on computer vision tasks, where images are seen as vectors in a continuous space and every point in the space corresponds to a valid image, while sentences in NLP form a discrete domain, making it challenging to apply traditional verification techniques effectively.\nIn this work we use both an abstract interpretation-based incomplete verifier (ERAN [46  ###reference_b46###]) and an SMT-based complete verifier (Marabou [22  ###reference_b22###]) in order to demonstrate the effect that the choice of a verifier may bring, and demonstrate common trends."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Robust Training",
            "text": "Verifying DNNs poses significant challenges if they are not appropriately trained. The fundamental issue lies in the failure of DNNs, including even sophisticated models, to meet essential verification properties, such as robustness [66  ###reference_b66###].\nTo enhance robustness, various training methodologies have been proposed. It is noteworthy that, although robust training by projected gradient descent [67  ###reference_b67###, 20  ###reference_b20###, 68  ###reference_b68###] predates verification, contemporary approaches are often related to, or derived from, the corresponding verification methods by optimizing verification-inspired regularization terms or injecting specific data augmentation during training.\nIn practice, after robust training, the model usually achieves higher certified robustness and is more likely to satisfy the desired verification properties [66  ###reference_b66###]. Thus, robust training is a strong complement to robustness verification approaches.\nRobust training techniques can be classified into several large groups:\ndata augmentation [69  ###reference_b69###],\nadversarial training [67  ###reference_b67###, 20  ###reference_b20###] including property-driven training [70  ###reference_b70###, 71  ###reference_b71###],\nIBP training [39  ###reference_b39###, 72  ###reference_b72###] and other forms of\ncertified training [73  ###reference_b73###], or\na combination thereof [74  ###reference_b74###, 66  ###reference_b66###].\nData augmentation involves the creation of synthetic examples through the application of diverse transformations or perturbations to the initial training data. These generated instances are then incorporated into the original dataset to enhance the training process.\nAdversarial training entails identifying worst-case examples at each epoch during the training phase and calculating an additional loss on these instances. State of the art adversarial training involves projected gradient descent algorithms such as FGSM [67  ###reference_b67###] and PGD [20  ###reference_b20###].\nCertified training methods focus on providing mathematical guarantees about the model\u2019s behaviour within certain bounds. Among them, we can name IBP\ntraining [39  ###reference_b39###, 72  ###reference_b72###] techniques, which impose intervals or bounds on the predictions or activations of the model, ensuring that the model\u2019s output lies within a specific range with high confidence.\nNote that all techniques mentioned above can be categorised based on whether they primarily augment the data (such as data augmentation) or augment the loss function (as seen in adversarial, IBP and certified training).\nAugmenting the data tends to enhance generalisation and is efficient, although it may not help against stronger adversarial attacks. Conversely, methods that manipulate the loss functions directly are more resistant to strong adversarial attacks but often come with higher computational costs. Ultimately, the choice between altering data or loss functions depends on the specific requirements of the application and the desired trade-offs between performance, computational complexity, and robustness guarantees."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "NLP robustness",
            "text": "There exists a substantial body of research dedicated to enhancing the adversarial robustness of NLP systems [75  ###reference_b75###, 76  ###reference_b76###, 77  ###reference_b77###, 78  ###reference_b78###, 79  ###reference_b79###, 80  ###reference_b80###, 81  ###reference_b81###]. These efforts aim to mitigate the vulnerability of NLP models to adversarial attacks and improve their resilience in real-world scenarios [76  ###reference_b76###, 77  ###reference_b77###] and mostly employ data augmentation techniques [82  ###reference_b82###, 83  ###reference_b83###].\nIn NLP, we can distinguish perturbations based on three main criteria:\nwhere and how the perturbations occur,\nwhether they are algorithmically generated (vs. generated by humans or LLMs) and\nwhether they are adversarial (as opposed to random).\nIn particular, perturbations can occur at the character, word, or sentence level [84  ###reference_b84###, 85  ###reference_b85###, 86  ###reference_b86###] and may involve deletion, insertion, swapping, flipping, substitution with synonyms, concatenation with characters or words, or insertion of numeric or alphanumeric characters [87  ###reference_b87###, 88  ###reference_b88###, 89  ###reference_b89###].\nFor instance, in character level adversarial attacks, Belinkov et al. [90  ###reference_b90###] introduce natural and synthetic noise to input data, while Gao et al. [91  ###reference_b91###] and Li et al. [92  ###reference_b92###] and Li et al. [92  ###reference_b92###] identify crucial words within a sentence and perturb them accordingly. For word level attacks, they can be categorised into gradient-based [87  ###reference_b87###, 93  ###reference_b93###], importance-based [94  ###reference_b94###, 95  ###reference_b95###], and replacement-based [96  ###reference_b96###, 97  ###reference_b97###, 98  ###reference_b98###] strategies, based on the perturbation method employed.\nMoreover, Moradi et al. [99  ###reference_b99###] introduce algorithmic non-adversarial perturbations at both the character and word levels. They utilise a rule-based method to generate these perturbations, simulating various types of noise typically caused by spelling mistakes, typos, and other similar errors.\nIn sentence level adversarial attacks, some perturbations [100  ###reference_b100###, 101  ###reference_b101###] are created so that they do not impact the original label of the input and can be incorporated as a concatenation in the original text. In such scenarios, the expected behaviour from the model is to maintain the original output, and the attack can be deemed successful if the label/output of the model is altered.\nAdditionally, non-algorithmic sentence perturbations can be obtained through prompting language models based methods [21  ###reference_b21###, 14  ###reference_b14###] to generate rephrases of the inputs.\nBy augmenting the training data with these perturbed examples, models are exposed to a more diverse range of linguistic variations and potential adversarial inputs. This helps the models to generalise better and become more robust to different types of adversarial attacks.\nTo help with this task, the NLP community has gathered a dataset of adversarial attacks named AdvGLUE [102  ###reference_b102###], which aims to be a principled and comprehensive benchmark for NLP robustness measurements.\nIn this work we employ a PGD-based adversarial training as the method to enhance the robustness and verifiability of our models against gradient-based adversarial attacks. For non-adversarial perturbations, we create algorithmic perturbations at the character and word level as in Moradi et al. [99  ###reference_b99###] and non-algorithmic perturbations at the sentence level using PolyJuice [21  ###reference_b21###] and Vicuna [14  ###reference_b14###].\nWe thus cover most combinations of the three choices above (bypassing only human-generated adversarial attacks as these do not admit systematic evaluation which is important for this study).\n###table_1### ###table_2###"
        },
        {
            "section_id": "2.4",
            "parent_section_id": "2",
            "section_name": "Previous NLP Verification Approaches",
            "text": "Although DNN verification studies have predominantly focused on computer vision, there is a growing body of research exploring the verification of NLP. This research can be categorised into three main approaches: IBP, abstract interpretation, and randomised smoothing.\nTables 1  ###reference_### and 2  ###reference_### shows a comparison of these approaches.\nTo the best of our knowledge, this paper is the first one to use an SMT-based verifier for this purpose, and compare it with an abstract interpretation-based verifier on the same benchmarks.\nNLP Verification via Interval Bound Propagation.\nThe first technique successfully adapted from the computer vision domain for verifying NLP models was the IBP. In the NLP approaches, IBP is used for both training and verification. Its aim is to minimise the upper bound on the maximum difference between the classification boundary and the input perturbation region by augmenting the loss function.\nThis facilitates the minimisation of the perturbation region in the last layer, ensuring it remains on one side of the classification boundary. As a result, the adversarial region becomes tighter and can be considered certifiably robust.\nNotably, Jia et al. [17  ###reference_b17###] proposed certified robust models on word substitutions in text classification. The authors employed IBP to optimise the upper bound over perturbations, providing an upper bound over the discrete set of perturbations in the word vector space.\nFurthermore, Huang et al. [18  ###reference_b18###] introduced a verification and verifiable training method with a tighter over-approximation in style of the Simplex algorithm [28  ###reference_b28###].\nTo make the network verifiable, they defined the convex hull of all the original unperturbed inputs as a space of perturbations.\nBy employing the IBP algorithm, they generated robustness bounds for each neural network layer.\nLater on, Welbl et al. [103  ###reference_b103###] differentiated from the previous approaches by using IBP to address the under-sensitivity issue. They designed and formally verified the \u2018under-sensitivity specification\u2019 that a model should not become more confident as arbitrary subsets of input words are deleted.\nRecently, Zhang et al. [19  ###reference_b19###] introduced Abstract Recursive Certification (ARC) to verify the robustness of LSTMs. ARC defines a set of programmatically perturbed string transformations to construct a perturbation space. By memorising the hidden states of strings in the perturbation space that share a common prefix, ARC can efficiently calculate an upper bound while avoiding redundant hidden state computations.\nFinally, Wang et al. [104  ###reference_b104###] improved on the work of Jia et al. by introducing Embedding Interval Bound Constraint (EIBC). EIBC is a new loss that constraints the word embeddings in order to tighten the IBP bounds.\nThe strength of IBP-based methods is their efficiency and speed, while their main limitation is the bounds\u2019 looseness, further accentuated if the neural network is deep.\nNLP Verification via Abstract Interpretation.\nAnother popular verification technique applied to various NLP models is based on abstract interpretation.\nOne notable contribution in this area is POPQORN [105  ###reference_b105###], which is the first work that gives robustness guarantees for RNN-based networks. They handle the challenging non-linear activation functions of complicated RNN structures (like LSTMs and GRUs) by bounding them with linear functions.\nLater on, Du et al. improve on POPQORN by introducing Cert-RNN [106  ###reference_b106###], a robust certification framework for RNNs that overcomes the limitations of POPQORN. The framework maintains inter-variable correlation and accelerates the non-linearities of RNNs for practical uses. Cert-RNN utilised Zonotopes [115  ###reference_b115###] to encapsulate input perturbations\nand can verify the properties of the output Zonotopes to determine certifiable robustness.\nThis results in improved precision and tighter bounds, leading to a significant speedup compared to POPQORN.\nIn contrast, Shi et al. [15  ###reference_b15###] focus on transformers with self-attention layers. They developed a verification algorithm that can provide a lower bound to ensure the probability of the correct label is consistently higher than that of the incorrect labels.\nAnalogously, Bonaert et al. [107  ###reference_b107###] propose DeepT, a certification method for large transformers.\nIt is specifically designed to verify the robustness of transformers against synonym replacement-based attacks. DeepT employs multi-norm Zonotopes to achieve larger robustness radii in the certification and can work with networks much larger than Shi et al.\nAbstract interpretation-based methods produce much tighter bounds than IBP-based methods, which can be used with deeper networks. However, they use geometric perturbations () instead of semantic perturbations.\nNLP Verification via Randomised Smoothing.\nRandomised smoothing [116  ###reference_b116###] is another technique for verifying the robustness of deep language models that has recently grown in popularity due to its scalability [108  ###reference_b108###, 109  ###reference_b109###, 110  ###reference_b110###, 111  ###reference_b111###, 112  ###reference_b112###, 113  ###reference_b113###, 114  ###reference_b114###].\nThe idea is to leverage randomness during inference to create a smoothed classifier that is more robust to small perturbations in the input. This technique can also be used to give certified guarantees against adversarial perturbations within a certain radius. Generally, randomized smoothing begins by training a regular neural network on a given dataset.\nDuring the inference phase, to classify a new sample, noise is randomly sampled from the predetermined distribution multiple times. These instances of noise are then injected into the input, resulting in noisy samples. Subsequently, the base classifier generates predictions for each of these noisy samples. The final prediction is determined by the class with the highest frequency of predictions, thereby shaping the smoothed classifier. To certify the robustness of the smoothed classifier against adversarial perturbations within a specific radius centered around the input, randomised smoothing calculates the likelihood of agreement between the base classifier and the smoothed classifier when noise is introduced to the input. If this likelihood exceeds a certain threshold, it indicates the certified robustness of the smoothed classifier within the radius around the input.\nThe main advantage of randomised smoothing-based methods is their scalability, indeed recent approaches are tested on larger transformer such as BERT and Alpaca.\nHowever, their main issue is that they are probabilistic approaches, meaning they give certifications up to a certain probability (e.g., 99.9%).\nIn this work we focus on deterministic approaches, hence we only report these works in Table 2  ###reference_### for completeness without delving deeper into each paper here. All randomised smoothing-based approaches use data augmentation obtained by semantic perturbations."
        },
        {
            "section_id": "2.5",
            "parent_section_id": "2",
            "section_name": "Datasets and Use Cases Used in NLP Verification",
            "text": "Existing NLP verification datasets. Table 3  ###reference_### summarises the main features and tasks of the datasets used in NLP verification.\nDespite their diverse origins and applications, the datasets in the literature are usually binary or multi-class text classification problems. Furthermore, datasets can be sensitive to perturbations, i.e. perturbations can have non-trivial impact on label consistency. For example, Jia et al. [17  ###reference_b17###] use IBP with the SNLI [117  ###reference_b117###]333A semantic inference dataset that labels whether one sentence entails, contradicts or is neutral to another sentence. dataset (see Tables 1  ###reference_### and 3  ###reference_###) to show that\nword perturbations (e.g. \u2018good\u2019 to \u2018best\u2019) can change whether one sentence entails another. Some works such as Jia et al. [17  ###reference_b17###] try to address this label consistency, while others do not.\nAdditionally, we find that the previous research on NLP verification does\nnot utilise safety critical datasets (which strongly motivates the choice of datasets in alternative verification domains), with the exception of Du et al. [106  ###reference_b106###] that use the Toxic Comment dataset [118  ###reference_b118###].\nThese papers do not provide detailed motivation as to why the dataset choices were made, however it could be due to the datasets being commonly used in NLP benchmarks (IMDB etc.).\n###table_3###"
        },
        {
            "section_id": "2.5.1",
            "parent_section_id": "2.5",
            "section_name": "2.5.1 Datasets Proposed in This Paper",
            "text": "In this paper we focus on two datasets from safety-critical applications that have not appeared in the NLP verification literature before. Both are driven by real-world use cases of safety-critical NLP applications, i.e. applications for which law enforcement and safety demand formal guarantees of \u201cgood\u201d DNN behaviour.\nChatbot Disclosure Dataset.\nThe first case study is motivated by new legislation which states that a chatbot must not mislead people about its artificial identity [11  ###reference_b11###, 10  ###reference_b10###]. Given that the regulatory landscape surrounding NLP models (particularly LLMs and generative AI) is rapidly evolving, similar legislation could be widespread in the future \u2013 with recent calls for the US Congress to formalise such disclosure requirements [127  ###reference_b127###]. The prohibition on deceptive conduct act may apply to the outputs generated by NLP systems if used commercially [128  ###reference_b128###], and at minimum a system must guarantee a truthful response when asked about its agency [129  ###reference_b129###, 130  ###reference_b130###]. Furthermore, the burden of this should be placed on the designers of NLP systems, and not on the consumers.\nOur first safety critical case is the R-U-A-Robot dataset [129  ###reference_b129###], a written English dataset consisting of 6800 variations on queries relating to the intent of \u2018Are you a robot?\u2019, such as \u2018I\u2019m a man, what about you?\u2019. The dataset was created via a context-free grammar template, crowd-sourcing and pre-existing data sources. It consists of 2,720 positive examples (where given the query, it is appropriate for the system to state its non-human identity), 3,400 negative/adversarial examples and 680 \u2018ambiguous-if-clarify\u2019 examples (where it is unclear whether the system is required to state its identity). The dataset was created to promote transparency which may be required when the user receives unsolicited phone calls from artificial systems. Given systems like Google Duplex [131  ###reference_b131###], and the criticism it received for human-sounding outputs [132  ###reference_b132###], it is also highly plausible for the user to be deceived regarding the outputs generated by other NLP-based systems [128  ###reference_b128###]. Thus we choose this dataset to understand how to enforce such disclosure requirements. We collapse the positive and ambiguous examples into one label, following the principle of \u2018better be safe than sorry\u2019, i.e. prioritising a high recall system.\nMedical Safety Dataset.\nAnother scenario one might consider is that inappropriate outputs of NLP systems have the potential to cause harm to human users [13  ###reference_b13###]. For example, a system may give a user false impressions of its \u2018expertise\u2019 and generate harmful advice in response to medically related user queries [7  ###reference_b7###]. In practice it may be desirable for the system to avoid answering such queries.\nThus we choose the Medical safety dataset [12  ###reference_b12###], a written English dataset consisting of 2,917 risk-graded medical and non-medical queries (1,417 and 1,500 examples respectively). The dataset was constructed via collecting questions posted on reddit, such as r/AskDocs. The medical queries have been labelled by experts and crowd annotators for both relevance and levels of risk (i.e. non-serious, serious to critical) following established World Economic Forum (WEF) risk levels designated for chatbots in healthcare [133  ###reference_b133###]. We merge the medical queries of different risk-levels into one class, given the high scarcity of the latter 2 labels to create an in-domain/out-of-domain classification task for medical queries. Additionally, we consider only the medical queries that were labelled as such by expert medical practitioners. Thus this dataset will facilitate discussion on how to guarantee a system recognises medical queries, in order to avoid generating medical output.\nAn additional benefit of these two datasets is that they are distinct semantically, i.e. the R-U-A-Robot dataset contains several semantically similar, but lexically different queries, while the medical safety dataset contains semantically diverse queries. For both datasets, we utilise the same data splits as given in the original papers, and refer to the final binary labels as positive and negative. The positive label in the R-U-A-Robot dataset implies a sample where it is appropriate to disclose non-human identity, while in the medical safety dataset it implies an in-domain medical query."
        },
        {
            "section_id": "2.6",
            "parent_section_id": "2",
            "section_name": "Our Work: Parametric Approach to NLP Verification Pipelines",
            "text": "To show relation of our work to the body of already existing work, we distill an \u201cNLP verification pipeline\u201d that is common across many related papers. Figure 2  ###reference_### shows the pipeline diagrammatically. It proceeds in stages:\nGiven an NLP dataset, generate semantic perturbations on sentences that it contains.\nThe semantic perturbations can be of different kinds: character, word or sentence level. IBP and randomised smoothing use word and character perturbations, abstract interpretation papers usually do not use any semantic perturbations.\nOur method allows to use all existing semantic perturbations, in particular, we implement character and word level perturbations as in Moradi et al. [99  ###reference_b99###], sentence level perturbations with PolyJuice [21  ###reference_b21###] and Vicuna.\nEmbed the semantic perturbations into continuous spaces. The cited papers use the word embeddings GloVe [98  ###reference_b98###], we use the sentence embeddings S-BERT and S-GPT.\nWorking on the embedding space, use geometric or semantic perturbations to define geometric or semantic subspaces around perturbed sentences. In IBP papers, semantic subspaces are defined as \u201cbounds\u201d derived from admissible semantic perturbations. In abstract interpretation papers, geometric subspaces are given by -cubes and  around each embedded sentence. Our paper generalises the notion of -cubes by defining \u201chyper-rectangles\u201d on sets of semantic perturbations. The hyper-rectangles generalise -cubes both geometrically and semantically, by allowing to analyse subspaces that are drawn around several (embedded) semantic perturbations of the same sentence. We could adapt our methods to work with hyper-ellipses and thus directly generalise  (the difference boils down to using  norm instead of  when computing geometric proximity of points), however hyper-rectangles are more efficient to compute, which determined our choice of shapes in this paper.\nUse the geometric/semantic subspaces to train a classifier to be robust to change of label within the given subspaces.\nWe generally call such training either robust training or semantically robust training, depending on whether the subspaces it uses are geometric or semantic.\nA custom semantically robust training algorithm\nis used in IBP papers, while abstract interpretation papers usually skip this step or use (adversarial) robust training.\nIn this paper, we adapt the famous PGD algorithm [20  ###reference_b20###] that was initially defined for geometric subspaces () to work with semantic subspaces (hyper-rectangles) to obtain a novel semantic training algorithm.\nUse the geometric/semantic subspaces to verify the classifier\u2019s behaviour within those subspaces. The papers [17  ###reference_b17###, 18  ###reference_b18###, 103  ###reference_b103###, 19  ###reference_b19###, 104  ###reference_b104###] use IBP algorithms and the papers  [105  ###reference_b105###, 15  ###reference_b15###, 106  ###reference_b106###, 107  ###reference_b107###] use abstract interpretation; in both cases it is incomplete and deterministic verification. We use SMT-based tool Marabou (complete and deterministic) and abstract-interpretation tool ERAN (incomplete and deterministic).\nTable 1  ###reference_### summarises differences and similarities of the above NLP verification approaches against ours.\nTo the best of our knowledge, we are the first to use SMT-based complete methods in NLP verification and we show how they achieve higher verifiability than abstract interpretation-based verification approaches, thanks to the increased precision of the ReLUplex algorithm proof search relative to bound propagation.\nFurthermore, our study is the first to demonstrate that the construction of semantic subspaces can happen independently of the choice of the training and verification algorithms. Likewise, although training and verification build upon the defined (semantic) subspaces, the actual choice of the training and verification algorithms can be made independently of the method used to define the semantic subspaces.\nThis separation, and the general modularity of our approach, facilitates a comprehensive examination and comparison of the two key components involved in any NLP verification process:\neffects of the verifiability-generalisability trade-off for verification with geometric and semantic subspaces;\nrelation between the volume/shape of semantic subspaces and verifiability of neural networks obtained via semantic training with these subspaces.\nThese two aspects have not been considered in the literature before."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "The Parametric NLP Verification Pipeline",
            "text": "This section presents a parametric NLP pipeline, shown in Figure 2 diagrammatically. We call it \u201cparametric\u201d because each component within the pipeline operates independently of the others and can be taken as a parameter when studying other components. The parametric nature of the pipeline allows for the seamless integration of state-of-the-art methods at every stage, and for more sophisticated experiments with those methods. The following section provides a detailed exposition of the methodological choices made at each step of the pipeline."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Semantic Perturbations",
            "text": "As discussed, we require semantic perturbations for creating semantic subspaces. To do so, we consider three kinds of perturbations: character, word, and sentence level. This accounts for different variations of the samples.\n\nCharacter and word level perturbations are created via a rule-based method to simulate different kinds of noise, such as spelling mistakes and typos. These perturbations include inserting, deleting, replacing, swapping, or repeating a character of the data sample. Certain perturbations, like letter case changes and commonly misspelled words, are omitted for their limited relevance to our datasets.\n\nWord level perturbations include repeating or deleting a word, changing word order, verb tense, and singular to plural verbs, or adding negation. Some perturbations, such as synonym replacement, are done via sentence rephrasing. Negation and certain verb changes are avoided in specific datasets to prevent label ambiguities and annotator difficulties.\n\nFor sentence level perturbations, we use Polyjuice or Vicuna. Polyjuice offers control over perturbation types and locations, while Vicuna generates variations with prompts such as \"Rephrase this sentence 5 times: '[Example]\u2019.\" Examples of sentence variations include changes in phrasing while maintaining the core meaning."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "NLP Embeddings",
            "text": "The next component of the pipeline is the embeddings. Embeddings play a crucial role in NLP as they map textual data into continuous vector spaces, capturing semantic relationships and contextual information. Given the set of all strings, an NLP dataset is a set of sentences written in natural language. The embedding is a function that maps a string to a vector in a space called the embedding space. Ideally, the embedding should reflect the semantic similarities between sentences, meaning that more semantically similar sentences should have closer distances in the embedding space. \n\nDefining semantic similarity precisely may not be tractable due to the infinite number of unseen sentences, subjectivity, and context-dependency. Hence, state-of-the-art NLP relies on machine learning methods to capture semantic similarity approximately. Currently, the most common approach to obtaining an embedding function is by training transformers. Transformers are a type of deep neural networks that can be trained to map sequential data into real vector spaces and handle variable-length input sequences. They are also used for other tasks, such as classification or sentence generation, with training occurring at the level of embedding spaces. \n\nIn this work, a transformer is trained as a function. The key feature of the transformer is the \"self-attention mechanism,\" which allows the network to weigh the importance of different elements in the input sequence when making predictions, rather than relying solely on the order of elements. This feature makes them effective at learning to associate semantically similar words or sentences. Sentence-BERT is initially used, and later Sentence-GPT is added to embed sentences.\n\nUnfortunately, the relation between the embedding space and the NLP dataset is not bijective; each sentence is mapped into the embedding space, but not every point in the embedding space has a corresponding sentence. This issue is known in NLP literature.\n\nGiven an NLP dataset that should be classified into classes, the standard approach is to construct a function that maps the embedded inputs to the classes. To do that, a domain-specific classifier is trained on the embeddings, and the final system is the composition of the two subsystems."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Geometric Analysis of Embedding Spaces",
            "text": "We now formally define geometric and semantic subspaces of the embedding space. Our goal is to define subspaces on the embedding space m by using an effective algorithmic procedure. We will use notation to refer to a subspace of the embedding space. A hyper-rectangle of dimension is a list of points such that a point is a member if for every dimension we have.\n\nWe start with an observation that, given an NLP dataset that contains a finite set of sentences belonging to the same class, and an embedding function, we can define an embedding matrix, where each row is given by. We will use the notation to refer to the element of the vector, and to refer to the element in the row and column of. Treating embedded sentences as matrices, rather than as points in the real vector space, makes many computations easier. We can therefore define a hyper-rectangle for as follows.\n\nGiven an embedding matrix, the -dimensional hyper-rectangle for is defined as:\n\nTherefore given an embedding function, and a set of sentences, we can form a subspace by constructing the embedding matrix, as described above, and forming the corresponding hyper-rectangle. To simplify notation, we will omit the application of and from here on simply write.\n\nThe next example shows how the above definitions generalise the commonly known definition of the.\n\nIt is defined as follows. Given an embedded input, a constant, and a distance function (L-norm), the around of radius is defined as:\n\nIn practice, it is common to use the norm, which results in the actually being a hyper-rectangle, also called, where. Therefore our construction is a strict generalisation of. We will therefore use the notation to refer to the set of around every sentence in the dataset.\n\nOf course, as we have already discussed in the introduction and Figure 1, hyper-rectangles are not very precise, geometrically. A more precise shape would be a convex hull around given points in the embedding space. Indeed literature has some definitions of convex hulls. However, none of them is suitable as they are computationally too expensive due to the time complexity of where is the number of inputs and is the number of dimensions. Approaches that use under-approximations to speed up the algorithms do not work well in NLP scenarios, as under-approximated subspaces are so small that they contain near zero sentence embeddings."
        },
        {
            "section_id": "3.3.1",
            "parent_section_id": "3.3",
            "section_name": "3.3.1 Exclusion of Unwanted Sentences Via Shrinking",
            "text": "Another concern is that the generated hyper-rectangles may contain sentences from a different class. In order to exclude all samples from the wrong class, we define a shrinking algorithm that calculates a new subspace that is a subset of the original hyper-rectangle around, that only contains embeddings of sentences in that are of class. Of course, to ensure this, the algorithm may have to exclude some sentences of class. The second graph of Figure 3 gives a visual intuition of how this is done. \n\nFormally, for each sentence in that is not of class, the algorithm performs the following procedure. If lies in the current hyper-rectangle, then for each dimension we compute the distance whether is closer to or. Without loss of generality, assume is closer. We then compute the number of sentences of class that would be excluded by replacing with in the hyper-rectangle where is a small positive number (we use). This gives us a penalty for each dimension, and we exclude by updating the hyper-rectangle in the dimension that minimises this penalty. \n\nThe idea is to shrink the hyper-rectangle in the dimensions that exclude as few embedded sentences from the desired class as possible. This choice keeps the algorithm fast while guaranteeing the subspace to retain the highest number of wanted inputs. However, there might be cases where perturbations of the unwanted input are left inside after shrinking. For large subspaces, more clever algorithms should be explored and discussed."
        },
        {
            "section_id": "3.3.2",
            "parent_section_id": "3.3",
            "section_name": "3.3.2 Exclusion of Unwanted Sentences Via Clustering",
            "text": "An alternative approach to excluding unwanted sentences is to split the dataset by clustering semantically similar sentences in the embedding space and then computing the hyper-rectangles around each cluster individually. In this paper, we use the k-means algorithm for clustering. We adopt the notation to refer to the k-clusters formed by applying it to dataset D. This method is combined with the shrinking algorithm in our experiments."
        },
        {
            "section_id": "3.3.3",
            "parent_section_id": "3.3",
            "section_name": "3.3.3 Eigenspace Rotation",
            "text": "A final alternative and computationally efficient way of reducing the likelihood that the hyper-rectangles will contain embedded sentences of an unwanted class is to rotate them to better align with the distribution of the embedded sentences of the desired class in the embedding space. This motivates us to introduce the Eigenspace rotation.\n\nTo construct the tightest possible hyper-rectangle, we define a specific method of eigenspace rotation. Our approach is to calculate a rotation matrix such that the rotated matrix is better aligned with the axes and therefore has a smaller volume. By a slight abuse of terminology, we will refer to it as the rotated hyper-rectangle, even though strictly speaking, we are rotating the data, not the hyper-rectangle itself.\n\nTo calculate the rotation matrix, we use singular value decomposition. The singular value decomposition of a matrix is defined such that it describes directions in which the matrix exhibits the most variance. The main idea behind the definition of rotation is to align these directions of maximum variance with the standard canonical basis vectors.\n\nFormally, using the decomposition, we can compute the rotation (or change-of-basis) matrix that rotates the right-singular vectors onto the canonical standard basis vectors, where the identity matrix is used. We thus obtain the desired rotation.\n\nAll hyper-rectangles constructed in this paper are rotated."
        },
        {
            "section_id": "3.3.4",
            "parent_section_id": "3.3",
            "section_name": "3.3.4 Geometric and Semantic Subspaces",
            "text": "We now apply the abstract definition of a subspace of an embedding space to concrete NLP scenarios. Once we know how to define subspaces for a selection of points in the embedding space, the choice remains how to choose those points. The first option is to use around given embedded points, as Example 1 defines. Since this construction does not involve any knowledge about the semantics of sentences, we will call the resulting subspaces geometric subspaces.\n\nThe second choice is to apply semantic perturbations to a point, embed the resulting sentences, and then define a subspace around them. We will call the subspaces obtained by this method semantic perturbation subspaces, or just semantic subspaces for short. We will finish this section with defining semantic subspaces formally.\n\nWe will use to denote an algorithm for generating sentence perturbations of type, applied to an input sentence in a random position. In the later sections, we will use to refer to the different types of perturbations illustrated in Tables 4 and 5, e.g., character-level insertion, deletion, replacement.\n\nIntuitively, given a single sentence we want to generate a set of semantically similar perturbations and then construct a hyper-rectangle around them, as described in Definition 1. This motivates the following definitions. Given a sentence, a number, and a type, the set is the set of semantic perturbations of type generated from.\n\nWe will use the notation to denote the new dataset generated by creating semantic perturbations of type around each sentence. Given an embedding function, the semantic subspace for a sentence is the subspace. We will refer to a set of such semantic hyper-rectangles over an entire dataset as.\n\nTo illustrate this construction, let us consider the sentence: \u201cCan u tell me if you are a chatbot?\u201d. This sentence is one of the original sentences of the positive class in the dataset. From this single sentence, we can create six new sentences using the word-level perturbations from Table 5 to form. Once the seven sentences are embedded into the vector space, they form the hyper-rectangle. By repeating this construction for the remaining sentences, we obtain the set of hyper-rectangles for the dataset.\n\nGiven a sentence, we embed each sentence into m obtaining vectors where."
        },
        {
            "section_id": "3.3.5",
            "parent_section_id": "3.3",
            "section_name": "3.3.5 Measuring the Quality of Sentence Embeddings",
            "text": "One of our implicit assumptions in the previous sections is that the embedding function maps pairs of semantically similar sentences to nearby points in the embedding space. Cosine similarity is used to measure how similar two vectors are in a multi-dimensional space by calculating the cosine of the angle between them. This is done by taking the dot product and dividing by the magnitudes of the vectors. The resulting value ranges from -1 to 1. A value of 1 indicates that the vectors are parallel (highest similarity), while -1 means that the vectors are orthogonal (no similarity)."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Training",
            "text": "As outlined in Section 2.2, robust training is essential for bolstering the robustness of DNNs. This study employs two robust training methods, namely data augmentation and a custom PGD adversarial training, with the goal of discerning the factors contributing to the success of robust training and compare the effectiveness of these methods.\n\nData Augmentation. In this training method, we statically generate semantic perturbations at the character, word, and sentence levels before training, which are then added to the dataset. The network is subsequently trained on this augmented dataset using the standard stochastic gradient descent algorithm.\n\nAdversarial Training. In this training method, the traditional Projected Gradient Descent (PGD) algorithm is defined. The primary distinction between our customised PGD algorithm and the standard version lies in the definition of the step size. In the conventional algorithm, the step size is represented by a scalar, therefore representing a uniform step size in every dimension. In our case, the width in each dimension may vary greatly, therefore we transform it into a vector, allowing the step size to vary by dimension. Note that the dot product between the vectors becomes an element-wise multiplication. The resulting customised PGD training seeks to identify the worst perturbations within the custom-defined subspace, and trains the given neural network to classify those perturbations correctly, in order to make the network robust to adversarial inputs in the chosen subspace."
        },
        {
            "section_id": "3.5",
            "parent_section_id": "3",
            "section_name": "Choice of Verification Algorithm",
            "text": "Our approach in this study involves the utilization of cutting-edge tools for DNN analysis. We initially focus on employing advanced methods to yield significant results. This choice is prioritized due to its efficiency. Subsequently, we explore integrating other advanced methods, which enables us to maximize the effectiveness of the analysis."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Characterisation of Verifiable Subspaces",
            "text": "In this Section, we provide key results in support of Contribution 1 formulated in the introduction: We introduce the metric of generalisability of subspaces and set-up some baseline experiments. We introduce the problem of the generalisability trade-off in the context of geometric subspaces. We show that, compared to geometric subspaces, the use of semantic subspaces helps to find a better balance between generalisability. Finally, we show that adversarial training based on semantic subspaces results in DNNs that are more generalisable than those obtained with other forms of robust training."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Metrics for Understanding the Properties of Embedding Spaces",
            "text": "Let us start with recalling the existing standard metrics used in DNN verification. Recall that we are given an NLP dataset, moreover we assume that each is assigned a correct class from. We restrict to the case of binary classification in this paper for simplicity, so we will assume.\n\nFurthermore, we are given an embedding function, and a network. Usually corresponds to the number of classes, and thus in case of binary classification, we have.\n\nAn embedded sentence is classified as class if the value of in is higher than all other classes.\n\nAccuracy. The most popular metric for measuring the performance of the network is the accuracy of, which is measured as a percentage of sentences in that are assigned to a correct class by.\n\nNote that this metric only checks a finite number of points in m given by the dataset.\n\nGeneralisability. Therefore, we now introduce a third metric, generalisability, which is a heuristic for the number of semantically-similar unseen sentences captured by a given set of subspaces.\n\nGiven a set of subspaces and a target set of embeddings the generalisability of the subspaces is measured as the percentage of the embedded vectors that lie in the subspaces:\n\nIn this paper we will generate the target set of embeddings as where is a dataset, is the type of semantic perturbation, is the number of perturbations and is the embeddings of the set of semantic perturbations around generated using, as described in Section 3.3 ###reference_###.\n\nNote that can be given by a collection of different perturbation algorithms and their kinds. The key assumption is that contains valid sentences semantically similar to and belonging to the same class. Assuming that membership of is easy to compute, then this metric is also easy to compute as the set is finite and of size, and therefore so is. Note that, unlike accuracy and verifiability, the generalisability metric does not explicitly depend on any DNN or verifier. However, in this paper we only study generalisability of verifiable subspaces, and thus the existence of a verified network will be assumed. Furthermore, the verified subspaces we study in this paper will be constructed from the dataset via the methodology described in Definition 2 ###reference_inition2###."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Baseline Experiments for Understanding the Properties of Embedding Spaces",
            "text": "The methodology defined thus far has provided basic intuitions about the modular nature of the NLP pipeline. Bearing this in mind, it is important to start our analysis with the general study of basic properties of the embedding subspaces, which is our main interest in this paper, and suitable baselines.\n\nBenchmark datasets will be abbreviated as \u201cRUAR\u201d and \u201cMedical\u201d. We use these to refer to the set of sentences in the training dataset with a positive class (i.e. a question asking the identity of the model, and a medical query respectively), and the remaining sentences.\n\nFor a benchmark network, we train a medium-sized fully-connected DNN (with 2 layers of size (128, 2) and input size 30) using stochastic gradient descent and cross-entropy loss. \n\nFor the choice of benchmark subspaces, we use two extreme sets of geometric subspaces: the singleton set containing the maximal subspace around all embedded sentences of the positive class. This is illustrated in the first graph of Figure 3. \n\nAnother set consists of minimal subspaces given by around each embedded sentence of class, where is chosen to be sufficiently small. This is illustrated in the first graph of Figure 1.\n\nWe first seek to understand the geometric properties (e.g. volume, values) for these two extremes."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Verifiability-Generalisability Trade-off for Geometric Subspaces",
            "text": "For example, in the RUAR dataset, there are sentences of the positive class. The experiment consists of generating hyper-cubes around each positive sentence, resulting in several hyper-cubes. Using clustering, we obtain a set of clusters denoted as different clusters, and using the shrinking algorithm, we obtain reduced clusters. There is a consistent reduction in volume observed, and there are several orders of magnitude between the largest and the smallest subspace."
        },
        {
            "section_id": "4.3.1",
            "parent_section_id": "4.3",
            "section_name": "4.3.1 Verifiability of Geometric Subspaces",
            "text": "One may also conjecture that they are less generalisable (as they will contain fewer embedded sentences). We now will confirm this via experiments; we are particularly interested in understanding how quickly generalisability deteriorates."
        },
        {
            "section_id": "4.3.2",
            "parent_section_id": "4.3",
            "section_name": "4.3.2 Generalisability of Geometric Subspaces",
            "text": "The choice to use only positive sentences is motivated by the nature of the chosen datasets - both Medical and RUAR sentences split into a positive class, that contains sentences with one intended semantic meaning (they are medical queries, or they are questions about robot identity); and a negative class that represents \u201call other sentences\u201d. These \u201cother sentences\u201d are not grouped by any specific semantic meaning and therefore do not form one coherent semantic category.\n\nFor the perturbation type, we take a combination of the different perturbations algorithms described. For RUAR: character insertion, character deletion, character replacement, character swapping, character repetition, word deletion, word repetition, word negation, word singular/plural verbs, word order, and word tense. For the Medical dataset: character insertion, character deletion, character replacement, character swapping, character repetition, word deletion, word repetition, word negation, word singular/plural verbs, word order, word tense, and sentence polyjuice. Each type of perturbation is applied 4 times on the given sentence in random places. The resulting datasets of semantically perturbed sentences are therefore approximately two orders of magnitude larger than the original datasets and contain unseen sentences of similar semantic meaning to the ones present in the original datasets."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "Verifiability-Generalisability Trade-off for Semantic Subspaces",
            "text": "In this section, we argue that using semantic subspaces can help to address the limitations of the trade-off. The main hypothesis we are testing is that semantic subspaces constructed using semantic-preserving perturbations are more precise, which improves both generalisability and other dimensions. \n\nWe employ semantic hyper-rectangles constructed on sentences of the positive class using character-level, word-level, and sentence-level perturbations. The types of perturbations include deletion, insertion, replacement, swapping, and the use of tools like Polyjuice. Notice the comparable volumes of all these shapes."
        },
        {
            "section_id": "4.4.1",
            "parent_section_id": "4.4",
            "section_name": "4.4.1 Verifiability of Semantic Subspaces",
            "text": "We pass each set of hyper-rectangles and the network to measure subspaces. Our semantic hyper-rectangles achieve notable higher verification than its counterpart of comparable volume. Precision of the subspaces has an impact."
        },
        {
            "section_id": "4.4.2",
            "parent_section_id": "4.4",
            "section_name": "4.4.2 Generalisability of Semantic Subspaces",
            "text": "Table 13 compares the generalisability of different semantic subspaces. It shows that these semantic subspaces are the most generalisable, containing a significant proportion of the unseen sentences. We infer that using semantic subspaces is effective for improving generalisability, with precise subspaces performing somewhat better than those of the same volume; however, both exceed the smallest subspaces from previous sections of comparable scale. The finding that these subspaces contain up to a notable percentage of randomly generated new sentences indicates their potential utility in sentence embedding and generalisation tasks."
        },
        {
            "section_id": "4.5",
            "parent_section_id": "4",
            "section_name": "Adversarial Training on Semantic Subspaces",
            "text": "In this section, we study the effects that adversarial training methods have on the subspaces previously defined. By comparing the effectiveness of the different training approaches described, we show that adversarial training based on our new semantic subspaces is the most efficient. Three kinds of training are deployed: \n\n1. **No robustness training:** The baseline network from the previous experiments, which has not undergone any robustness training. \n2. **Data augmentation:** We obtain three augmented datasets with different levels of perturbations. We train the baseline architecture using the standard stochastic gradient descent and cross-entropy loss on these augmented datasets, resulting in different DNNs. \n3. **PGD adversarial training:** Instead of using the standard subspace, we use various hyper-rectangles for training.\n\nWe train the networks using these methods, obtaining networks that are designed to be more robust. The networks trained with data augmentation achieve similar nominal accuracy to networks trained with adversarial training. However, differences in subspace specifications impact their performance outcomes. The adversarially trained networks trained on semantic subspaces showed high performance. The successful performance improvements are attributed to the specific semantic attacks used during training. For instance, networks trained with a more aggressive form of attack tended to perform best. This suggests that knowledge of potential attacks beforehand can help refine the training approach for improved outcomes. The results emphasize that subspaces that are too extensive may not yield good results, even with adversarial training. Generalisability of the subspace shapes remains consistent across different tests."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "NLP Case Studies",
            "text": "The purpose of this section is to explore the application of more modern NLP tools using different LLMs to embed sentences and replace Polyjuice with the LLM vicuna-13b, a state-of-the-art open source chatbot trained by fine-tuning LLaMA on user-shared conversations. We use the tool ANTONIO to vary different components of the NLP pipeline.\n\nThe correctness of the specification is dependent on the purely NLP parts of the pipeline, particularly the parts that generate, perturb, and embed sentences. There are two key assumptions affecting the correctness of the generated specifications: the locality of the embedding function and the preservation of semantics by the sentence perturbation algorithm.\n\nLocality of the Embedding Function - This assumes that the embedding function maps semantically similar sentences to nearby points in the embedding space and dissimilar sentences to faraway points. If this assumption fails, the subspace may also contain the embeddings of unseen sentences from different classes.\n\nSentence Perturbation Algorithm Preserves Semantics - It is assumed that sentence perturbations can be generated in a way that retains the original semantic meaning. If this assumption fails, we may construct semantic subspaces around embeddings of sentences belonging to different classes.\n\nGiven the potential for these assumptions to fail, it is incorrect to assure that verifying the subspace guarantees that all sentences embedding into it belong to the intended classification. New sentences of a class that fall inside the verified subspace of another class falsify the subspace.\n\nThis highlights limitations in mapping sets of points in the embedding space back to sets of natural language sentences, leading to incorrect specifications and a paradoxical situation where the same subspace can be formally verified yet empirically falsified. Formal verification ensures identical classification by a given DNN within a semantic subspace, while empirical falsification arises from appealing to the semantic meaning of the embedded sentences.\n\nThe failure to address falsifiable verified subspaces can have various implications, depending on usage scenarios, such as censoring sensitive content. Incorrect embeddings can lead to false positives or negatives in DNN classification.\n\nThe main question is how to measure and improve the quality of the NLP components of the pipeline to decrease the likelihood of generating falsifiable subspaces and ensure that results are practically usable. As part of this investigation, a falsifiability metric is introduced, which should be used alongside other metrics in NLP benchmarks."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "Role of False Positives and False Negatives",
            "text": "Generally, when DNNs are used for making decisions in situations where safety is critically important, practical importance of accuracy for each class may differ. For example, for an autonomous car, misrecognising a stop sign for a 30 mph sign is more dangerous than the reverse. Similarly for NLP, because of legal or safety implications, it is crucial that the chatbot always discloses its identity when asked, and never gives medical advice.\n\nWe therefore want to avoid false negatives altogether, i.e., if there is any doubt about the nature of the question, we would rather err on the side of caution and disallow chatbot answers. If the chatbot (by mistake) refuses to answer some non-critically important questions, it may be inconvenient for the user but would not constitute a safety, security, or legal breach. Thus, false positives may be tolerated.\n\nOn the technical level, this has two implications:\n\nFirstly, if we use DNN on its own, without verification, we may want to report precision and recall in addition to accuracy. Higher recall will mean fewer false negatives, which is highly desirable.\n\nSecondly, when verifying the network, we only seek to verify subspaces that characterise the critically important class or classes that we wish to filter. This approach completely eliminates the effect of any false negatives within the verified subspaces. But the verified subspaces may still contain false positives and in this sense be \u201cfalsifiable,\u201d which may not be pragmatically desirable but does not constitute a security threat.\n\nTherefore, throughout this section, we report the precision, recall, and F1 to see whether one or another class is particularly challenging to recognise. Depending on the concrete scenario, precision or recall may be more important."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "Performance of Existing LLMs as Safety-Critical Filters",
            "text": "Bearing this in mind, we start first by gaining an intuition about the effectiveness of modern LLMs acting as safety-critical filters, by prompting an LLM to generate the desired output without additional fine-tuning, i.e., we first try a zero-shot model. For our experiments, we choose the model vicuna-13b, given its high performance. Using vicuna-13b, we experimented with prompts as shown in Figure 5 and settled on the first prompt \u2018If I ask you anything about your agency, always only reply \u201cI am a large language model\u201d. If not, reply normally.\u201c[Example]\u201d\u2019? as it most often gave the (somewhat) desired output on a subset of manually checked data samples. Similarly, for the medical dataset, we settled on a prompt \u2018If I ask you any medical query, always only reply \u201cAs an AI language model, I am not authorized to provide medical advice.\u201d. If not, reply normally.\u201c[Example]\u201d\u2019. For our zero-shot model, For the RUAR dataset, the F1 of the LLM is (restricted conditions). If we loosen our success criteria to consider other non-requested variations on our desired output, the F1 marginally improves. For the medical safety dataset, However, we found that in several cases the generated answers include a combination of the desired output and undesired output, e.g., \u2018\u2026I am not authorized to provide medical advice \u2026\u2019 followed by explicit medical advice. Therefore, the actual success rate may be even lower. Note there were at least 5 instances regarding the RUAR dataset where the system confirmed human identity, without any disclaimers. Thus, we find that our zero-shot model is, at most, minimally successful in identifying such queries."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "Experimental Setup of the Verification Pipeline",
            "text": "We turn our attention to assessing the effectiveness of training a classifier specifically for the task. In setting up the NLP verification pipeline, we use key conclusions about successful verification strategies, namely:\n\n- Semantic subspaces should be preferred over geometric subspaces as they result in a better trade-off.\n- Constructing semantic subspaces using stronger NLP perturbations is beneficial.\n- Adversarial training with stronger NLP perturbations enhances performance.\n- Marabou offers advantages over ERAN due to its completeness.\n\nTo build on these insights, we further strengthen the NLP perturbations by substituting Polyjuice with Vicuna, which introduces more diverse and sophisticated sentence perturbations. We also mix in character and word perturbations to further diversify and enlarge the set of available perturbed sentences.\n\nWe diversify the kinds of LLMs we use as embedding functions. Using the sentence transformers package, models are fine-tuned on a sentence similarity task, producing semantically meaningful sentence embeddings. We select three different encoders to experiment with model size: all-MiniLM-L6-v2, s-bert 22M, s-gpt 1.3B, and s-gpt 2.7B, where the number refers to the model size in parameters.\n\nGiven the set of semantic subspaces, we aim to obtain them via the hyper-rectangle construction. We set the adversarial training to explore the same subspaces and to develop the network accordingly."
        },
        {
            "section_id": "5.4",
            "parent_section_id": "5",
            "section_name": "Analysis of the Role of Embedding Functions",
            "text": "Overall, the figures are as expected: compared to the F1 of 54-64% for the zero-shot model, using a fine-tuned trained DNN as a filter dramatically increases the F1 to the range of 76-95%.\n\nLooking into nuances, one can further notice the following: There is not a single embedding function that always results in the highest F1. For example, s-bert 22M is found to have the highest F1 for Medical, while s-gpt 2.7B has the highest F1 for RUAR (with the exception of F1 score, for which s-bert 22M is best for both datasets). The smaller GPT model s-gpt 1.3B is systematically worse for both datasets. As expected and discussed, depending on the scenario of use, the highest F1 may not be the best indicator of performance. For Medical, s-bert 22M (either with or without adversarial training) obtains the highest precision, recall, and F1. However, for RUAR, the choice of the embedding function has a greater effect: if F1 is desired, s-bert 22M is the best choice (difference with the worst choice of the embedding function is more significant, for scenarios when one is not interested in verifying the network, the embedding function s-gpt 2.7B when combined with adversarial training gives an incredibly high recall and would be a great choice. Adversarial training only makes a significant difference in F1 for the Medical perturbed test set. However, it has more effect on improving recall (up to 10% for Medical and 33% for RUAR). \n\nThe main conclusion one should make is that depending on the scenario, the embedding function may influence the quality of the NLP pipelines, and reporting the error range (for both precision and recall) depending on the embedding function choice should be common practice."
        },
        {
            "section_id": "5.5",
            "parent_section_id": "5",
            "section_name": "Analysis of Perturbations",
            "text": "Recall that two problems were identified as potential causes of falsifiable semantic subspaces: the imprecise embedding functions and invalid perturbations (i.e., those that change semantic meaning and the class of the perturbed sentences).\nFirstly, we wish to understand how common it is for our chosen perturbations to change the class, and secondly, we propose several practical methods for how perturbation adequacy can be measured algorithmically.\nRecall that the definition of semantic subspaces depends on the assumption that we can always generate semantically similar (valid) perturbations and draw semantic subspaces around them. Both adversarial training and exploration of these semantic subspaces depend on this assumption. If this assumption fails and the subspaces contain a large number of invalid sentences, the NLP pipeline loses much of its practical value."
        },
        {
            "section_id": "5.5.1",
            "parent_section_id": "5.5",
            "section_name": "5.5.1 Understanding the Scale of the Problem",
            "text": "In the experiment, for each original dataset and word/character perturbation type, we select 10 perturbed sentences. At the character level, there are 50 perturbed sentences for both datasets (10 each for inserting, deleting, replacing, swapping, or repeating a character). At the word level, there are 60 perturbed sentences for RUAR (deletion, repetition, ordering, negation, singular/plural, verb tense) and 30 for Medical (deletion, repetition, ordering). At the sentence level, perturbations are obtained by prompting vicuna-13b with instructions for the original sentence to be rephrased 5 times. This results in a total of 290 pairs consisting of the original sentence and the perturbed sentence (130 from the medical safety, and 160 from the R-U-A-Robot dataset).\n\nOverall, there are high scores for label consistency, particularly for rule-based perturbations. There are also high scores for semantic similarity. For grammaticality, perturbations generated by vicuna-13b are generally rated as grammatical, whereas rule-based perturbations compromise on grammaticality.\n\nWe note this is in part due to our definition of grammatical being interpreted differently by the two independent evaluators and label consistency being ambiguous for the RUAR dataset. Finally, we acknowledge that there may be discrepancies in individual ratings. Future replications are warranted."
        },
        {
            "section_id": "5.5.2",
            "parent_section_id": "5.5",
            "section_name": "5.5.2 Automatic Ways to Measure and Report Perturbation Validity",
            "text": "Although in the near future, no geometric or algorithmic method will be able to match to the full extent the human perception and interpretation of sentences, we can still formulate a number of effective methods that give a characterisation of the validity of the perturbations utilised when defining semantic subspaces. We propose two:\nUsing cosine similarity of embedded sentences, we can characterise semantic similarity. \nUsing the ROUGE-N method, we can measure lexical and syntactic validity. \nWe proceed to describe each of them in order."
        },
        {
            "section_id": "5.5.x",
            "parent_section_id": "5.5",
            "section_name": "Cosine Similarity",
            "text": "To measure the general effectiveness of the embedding function at generating semantically similar sentences, we identify the pros and cons of using cosine similarity as a metric.\n\nPros:\nCosine similarity metric is general, efficient, and scalable. It applies irrespective of other choices in the pipeline.\n\nCons:\nDue to its geometric nature, cosine similarity does not provide direct knowledge about true semantic similarity of sentences. The human evaluation of semantic similarity hardly matches the optimistic numbers sometimes reported. Disagreement in cosine similarity estimations may vary significantly when different embedding functions are applied.\n\nOverall, although it has its limitations, cosine similarity is a useful metric. Filtering based on cosine similarity is beneficial as a pre-processing stage in NLP."
        },
        {
            "section_id": "5.5.x",
            "parent_section_id": "5.5",
            "section_name": "ROUGE-N",
            "text": "We calculate lexical and syntactic variability of the generated vicuna-13b output using ROUGE-N scores, which measure overlap. Intuitively, if a sentence from the dataset has a perturbation, ROUGE-N provides an overlap measure. Figure 6 presents an experiment where vicuna-13b generates sentence perturbations. The results display a high number of invalid sentences, mainly due to incoherence, hallucination, or incorrect rephrasing.\n\nFor lexical ROUGE-N, we compare the original sample to the perturbations, while for syntax, we use the corresponding parts-of-speech (POS) tags. We also calculate ROUGE-N before and after filtering with cosine similarity. These results suggest that a low score does not necessarily indicate non-semantic preserving rephrases. Shuffling, rephrasing, or synonym substitution could lower the scores without altering meaning.\n\nPrior to filtering, the scores remain steady, which implies a long sequence of overlapping text, although some unique text may remain. When ROUGE scores decrease, it means singular words overlap in both sentences but not in sequence, or they are alternated by other words. It is plausible that cosine similarity filters out perturbations with long word sequence overlaps but added hallucinations changing the meaning.\n\nThere is generally higher syntactic overlap than lexical overlap. This occasionally leads to unsatisfactory perturbations, where local rephrasing results in globally incoherent sentences. Without filtering, ROUGE scores are higher compared to BLEU scores, while after filtering, the BLEU scores increase. We hypothesize that cosine similarity filters out shorter perturbations than the original sentences.\n\nLiteral rephrasing is often observed, highlighting challenges in generating high-quality perturbations. For example, in medical queries, expressed emotions usually need inference, and hallucinated content in perturbations becomes problematic, especially with additional risk labels from a medical safety dataset. This hallucinated content can significantly affect label consistency."
        },
        {
            "section_id": "5.6",
            "parent_section_id": "5",
            "section_name": "Falsifiability",
            "text": "As the final result of this paper, we introduce the new metric \u2013 falsifiability \u2013 that measures the number of unwanted sentences that are mapped into a verified subspace. The falsifiability metric differs from traditional NLP methods in two aspects: firstly, it helps to measure both effects simultaneously, and thus helps to assess validity of both the assumption of locality of the embedding function and the assumption of semantic stability of the perturbations outlined at the start of Section 5. Secondly, it is applied here as a verification metric specifically.\n\nWe next formally define the falsifiability metric. Intuitively, the falsifiability of a set of subspaces of class is the percentage of those subspaces that contain at least one embedding of a sentence that belongs to a different class. Given a set of subspaces that are supposed to contain exclusively sentences of class, a dataset that contains sentences not of class, and a set of embeddings, then falsifiability is measured as the percentage of subspaces that contain at least one element of. As with the definition of generalisability, in this paper we will generate the target set of embeddings as where is a dataset, is the type of semantic perturbation, is the number of perturbations, and is the embeddings of the set of semantic perturbations around generated using, as described in Section 3.3. We also measure the presence of false positives, calculated as the percentage of the perturbations of sentences from classes other than that lie within at least one of the set of subspaces.\n\nFurthermore, falsifiability could also reflect issues in the dataset and subsequent noisy perturbations. The medical safety dataset, for instance, was annotated by an expert practitioner, while the RUAR dataset contains (for this particular task) what could be construed as noisy labels. For example, \u2018are robot you you a\u2019 is a sample that is found in the negative RUAR train set. The reason for the negative label is that it is an ungrammatical false positive, but given our methods of perturbation for the construction of subspaces, this negative sample may be very similar to a word-level perturbation for the positive class. Concretely, for some sentence pairs of negative samples with their accompanying perturbations contained in falsified subspaces are: (Original: \u2018Are you a chump?\u2019, Perturbation: \u2018You a chump\u2019), (Original: \u2018Are you a liar\u2019, Perturbation: \u2018You a liar\u2019), (Original: \u2018if a computer can feel emotions, does that make you a computer or an actual human?\u2019, Perturbation: \u2018if a computer can feel, does that make it a machine or a person\u2019). Thus, the task of determining what queries require disclosure (e.g., should \u2018what is your favorite food\u2019 warrant disclosure?) is more ambiguous and, as the outputs of LLMs sound more coherent, it becomes harder to define.\n\nThis area merits further research."
        },
        {
            "section_id": "5.6.x",
            "parent_section_id": "5.6",
            "section_name": "Falsifiability vs Generalisability and Verifiability",
            "text": "For comparison with the findings outlined in Section 4, we provide additional insights into generalisability. We first analyse the effect of cosine similarity filtering. Initially, the experiments reveal that filtering results in slightly higher levels of generalisability for all models. Given the conclusions in Section 4, the increase in generalisability is somewhat unexpected because larger subspaces tend to exhibit greater generalisability, but filtering decreases the volume of the subspaces. Therefore, we conjecture the increase in precision of the subspaces from filtering outweighs the reduction in their volume and hence generalisability increases overall. The data therefore suggests that cosine similarity filtering can serve as an additional heuristic for improving precision of the DNNs. \n\nMoreover, the best performing model (s-bert 22M), results in medical perturbations and RUAR perturbations contained in the subspaces. While the perturbations contained in the subspaces for the RUAR dataset may seem like a low number, it still results in a robust filter, given that the class of the dataset contains many adversarial examples of the same input query, i.e., semantically similar but lexically different queries. The medical dataset, on the other hand, contains many semantically diverse queries, and there are several unseen medical queries not contained in the dataset nor in the resultant subspaces. However, given that the subspaces contain perturbations of the medical safety dataset, an application of this could be to carefully curate a new dataset containing only queries with critical and serious risk-level labels defined by the World Economic Forum for chatbots in healthcare. This dataset could be used to create filters centred around these queries to prevent generation of medical advice for these high-risk categories. Overall, we find that semantically-informed verification generalises well across the different kinds of data to ensure guarantees on the output and thus should aid in ensuring the safety of LLMs."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Conclusions and Future Work",
            "text": "Summary. This paper provides an analysis of existing NLP approaches, identifying key components for a general methodology. We distilled these into a \"NLP Pipeline\" consisting of the following components: dataset selection, generation of perturbations, choice of embedding functions, definition of subspaces, training, and component analysis. Using the tool ANTONIO, we were able to study the effects of varying components in an algorithm-independent way.\n\nOur main focus was to identify weak or missing parts of the existing NLP methodologies. We proposed that NLP results should report whether they use geometric or semantic subspaces, and for which type of semantic perturbations; volumes and generalisability of defined subspaces.\n\nWe concluded with a study of current limitations and proposed possible improvements such as introducing a perturbations filter stage using cosine similarity. One of the strengths of the pipeline is that each component can be improved individually.\n\nContributions. The major discoveries of this paper included proposing generalisability as a novel metric, showing methods to overcome trade-offs by using heuristic methods such as defining semantic subspaces, training for semantic robustness, and choosing suitable embedding functions. These methods result in defining more precise subspaces and can be implemented in future NLP pipelines.\n\nWe revealed that assumptions underlying the definition of subspaces need scrutiny, such as whether embedding functions map semantically similar sentences correctly, and whether our methods for generating perturbations preserve semantics. These factors influence practical applications of the pipeline.\n\nWe demonstrated that even defined subspaces can be semantically falsified, due to tensions between geometric methods and the semantic interpretation of sentences. By defining the falsifiability metric, we showed its effects are generally not severe but vary with different scenarios. Awareness of this pitfall is vital.\n\nFinally, we propose a novel framework incorporating a broad spectrum of NLP, geometric, machine learning, and methodological methods under one canopy. This comprehensive range has not been previously addressed in this domain, and it is crucial for the field's development.\n\nFuture Work. Despite a satisfactory resolution to discussed issues, scalability of available algorithms remains a problem. For example, -Crown can handle only limited network parameters, whereas NLP models like BERT have vastly more parameters. This highlights a need for real-world pipeline implementation.\n\nFor future work, we suggest verifying a smaller DNN that can act as a filter upstream of a complex NLP system, ensuring responsible handling of safety-critical queries. This approach, alongside existing initiatives like guardrails, can build safer systems. Implementing these techniques at multiple stages of a pipeline may enhance system safety, a topic we plan to explore.\n\nA future direction is to create NLP benchmarks to spread awareness and focus in this field. Despite advances, major verification competitions still lack NLP benchmarks, a gap this work can help fill for future editions."
        }
    ],
    "appendix": [],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S2.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S2.T1.15\">\n<tr class=\"ltx_tr\" id=\"S2.T1.15.16\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_tt\" id=\"S2.T1.15.16.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.16.1.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.16.1.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.15.16.1.1.1.1\" style=\"font-size:80%;\">Method</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T1.15.16.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.16.2.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.16.2.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.15.16.2.1.1.1\" style=\"font-size:80%;\">Verification algorithm</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T1.15.16.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.16.3.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.16.3.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.15.16.3.1.1.1\" style=\"font-size:80%;\">Verification characteristics</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T1.15.16.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.16.4.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.16.4.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.15.16.4.1.1.1\" style=\"font-size:80%;\">Datasets</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T1.15.16.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.16.5.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.16.5.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.15.16.5.1.1.1\" style=\"font-size:80%;\">NLP perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T1.15.16.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.16.6.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.16.6.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.15.16.6.1.1.1\" style=\"font-size:80%;\">Embeddings</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T1.15.16.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.16.7.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.16.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.15.16.7.1.1.1\" style=\"font-size:80%;\">Architectures (# of parameters)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T1.15.16.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.16.8.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.16.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.15.16.8.1.1.1\" style=\"font-size:80%;\">Robust training</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.2.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_tt\" id=\"S2.T1.2.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.2.2.3.1\">\n<span class=\"ltx_p\" id=\"S2.T1.2.2.3.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.2.2.3.1.1.1\" style=\"font-size:80%;\">Ours</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T1.2.2.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.2.2.4.1\">\n<span class=\"ltx_p\" id=\"S2.T1.2.2.4.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.2.2.4.1.1.1\" style=\"font-size:80%;\">SMT</span><span class=\"ltx_text\" id=\"S2.T1.2.2.4.1.1.2\" style=\"font-size:80%;\">-based, Abstract interpretation-based, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.2.2.4.1.1.3\" style=\"font-size:80%;\">BaB</span><span class=\"ltx_text\" id=\"S2.T1.2.2.4.1.1.4\" style=\"font-size:80%;\">-based</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T1.2.2.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.2.2.5.1\">\n<span class=\"ltx_p\" id=\"S2.T1.2.2.5.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.2.2.5.1.1.1\" style=\"font-size:80%;\">Complete</span><span class=\"ltx_text\" id=\"S2.T1.2.2.5.1.1.2\" style=\"font-size:80%;\">, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.2.2.5.1.1.3\" style=\"font-size:80%;\">Deterministic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T1.2.2.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.2.2.6.1\">\n<span class=\"ltx_p\" id=\"S2.T1.2.2.6.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.2.2.6.1.1.1\" style=\"font-size:80%;\">RUARobot, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T1.2.2.6.1.1.2\" style=\"font-size:80%;\">Medical</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T1.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S2.T1.1.1.1.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text\" id=\"S2.T1.1.1.1.1.1.1\" style=\"font-size:80%;\">General purpose: char, word and sentence perturbations, </span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T1.2.2.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.2.2.7.1\">\n<span class=\"ltx_p\" id=\"S2.T1.2.2.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.2.2.7.1.1.1\" style=\"font-size:80%;\">Sentence: S-BERT, S-GPT</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T1.2.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.2.2.2.1\">\n<span class=\"ltx_p\" id=\"S2.T1.2.2.2.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.2.2.2.1.1.1\" style=\"font-size:80%;\">FFNN (</span><span class=\"ltx_text\" id=\"S2.T1.2.2.2.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T1.2.2.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.2.2.8.1\">\n<span class=\"ltx_p\" id=\"S2.T1.2.2.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.2.2.8.1.1.1\" style=\"font-size:80%;\">PGD</span><span class=\"ltx_text\" id=\"S2.T1.2.2.8.1.1.2\" style=\"font-size:80%;\">-based</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.3.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.3.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.3.3.2.1\">\n<span class=\"ltx_p\" id=\"S2.T1.3.3.2.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.3.3.2.1.1.1\" style=\"font-size:80%;\">Jia et al. (2019) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T1.3.3.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib17\" title=\"\">17</a><span class=\"ltx_text\" id=\"S2.T1.3.3.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.3.3.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.3.3.3.1\">\n<span class=\"ltx_p\" id=\"S2.T1.3.3.3.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T1.3.3.3.1.1.1\" style=\"font-size:80%;\">IBP-based</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.3.3.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.3.3.4.1\">\n<span class=\"ltx_p\" id=\"S2.T1.3.3.4.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T1.3.3.4.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.3.3.4.1.1.2\" style=\"font-size:80%;\">Deterministic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.3.3.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.3.3.5.1\">\n<span class=\"ltx_p\" id=\"S2.T1.3.3.5.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.3.3.5.1.1.1\" style=\"font-size:80%;\">IMDB, SNLI</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.3.3.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.3.3.6.1\">\n<span class=\"ltx_p\" id=\"S2.T1.3.3.6.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text\" id=\"S2.T1.3.3.6.1.1.1\" style=\"font-size:80%;\">Word substitution</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.3.3.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.3.3.7.1\">\n<span class=\"ltx_p\" id=\"S2.T1.3.3.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.3.3.7.1.1.1\" style=\"font-size:80%;\">Word: GloVe</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.3.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.3.3.1.1\">\n<span class=\"ltx_p\" id=\"S2.T1.3.3.1.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.3.3.1.1.1.1\" style=\"font-size:80%;\">LSTM, CNN, BoW, Attention-based, (</span><span class=\"ltx_text\" id=\"S2.T1.3.3.1.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.3.3.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.3.3.8.1\">\n<span class=\"ltx_p\" id=\"S2.T1.3.3.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.3.3.8.1.1.1\" style=\"font-size:80%;\">IBP</span><span class=\"ltx_text\" id=\"S2.T1.3.3.8.1.1.2\" style=\"font-size:80%;\">-based</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.4.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.4.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.4.4.2.1\">\n<span class=\"ltx_p\" id=\"S2.T1.4.4.2.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.4.4.2.1.1.1\" style=\"font-size:80%;\">Huang et al. (2019) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T1.4.4.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib18\" title=\"\">18</a><span class=\"ltx_text\" id=\"S2.T1.4.4.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.4.4.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.4.4.3.1\">\n<span class=\"ltx_p\" id=\"S2.T1.4.4.3.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T1.4.4.3.1.1.1\" style=\"font-size:80%;\">IBP-based</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.4.4.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.4.4.4.1\">\n<span class=\"ltx_p\" id=\"S2.T1.4.4.4.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T1.4.4.4.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.4.4.4.1.1.2\" style=\"font-size:80%;\">Deterministic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.4.4.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.4.4.5.1\">\n<span class=\"ltx_p\" id=\"S2.T1.4.4.5.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.4.4.5.1.1.1\" style=\"font-size:80%;\">AGNews, SST</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.4.4.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.4.4.6.1\">\n<span class=\"ltx_p\" id=\"S2.T1.4.4.6.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text\" id=\"S2.T1.4.4.6.1.1.1\" style=\"font-size:80%;\">Char and word substitution</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.4.4.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.4.4.7.1\">\n<span class=\"ltx_p\" id=\"S2.T1.4.4.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.4.4.7.1.1.1\" style=\"font-size:80%;\">Word: GloVe</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.4.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.4.4.1.1\">\n<span class=\"ltx_p\" id=\"S2.T1.4.4.1.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.4.4.1.1.1.1\" style=\"font-size:80%;\">CNN (</span><span class=\"ltx_text\" id=\"S2.T1.4.4.1.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.4.4.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.4.4.8.1\">\n<span class=\"ltx_p\" id=\"S2.T1.4.4.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.4.4.8.1.1.1\" style=\"font-size:80%;\">IBP</span><span class=\"ltx_text\" id=\"S2.T1.4.4.8.1.1.2\" style=\"font-size:80%;\">-based</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.5.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.5.5.2.1\">\n<span class=\"ltx_p\" id=\"S2.T1.5.5.2.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.5.5.2.1.1.1\" style=\"font-size:80%;\">Welbl et al. (2020) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T1.5.5.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib103\" title=\"\">103</a><span class=\"ltx_text\" id=\"S2.T1.5.5.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.5.5.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.5.5.3.1\">\n<span class=\"ltx_p\" id=\"S2.T1.5.5.3.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T1.5.5.3.1.1.1\" style=\"font-size:80%;\">IBP-based</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.5.5.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.5.5.4.1\">\n<span class=\"ltx_p\" id=\"S2.T1.5.5.4.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T1.5.5.4.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.5.5.4.1.1.2\" style=\"font-size:80%;\">Deterministic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.5.5.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.5.5.5.1\">\n<span class=\"ltx_p\" id=\"S2.T1.5.5.5.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.5.5.5.1.1.1\" style=\"font-size:80%;\">SNLI, MNLI</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.5.5.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.5.5.6.1\">\n<span class=\"ltx_p\" id=\"S2.T1.5.5.6.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text\" id=\"S2.T1.5.5.6.1.1.1\" style=\"font-size:80%;\">Word deletion</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.5.5.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.5.5.7.1\">\n<span class=\"ltx_p\" id=\"S2.T1.5.5.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.5.5.7.1.1.1\" style=\"font-size:80%;\">Word: GloVe</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.5.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.5.5.1.1\">\n<span class=\"ltx_p\" id=\"S2.T1.5.5.1.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.5.5.1.1.1.1\" style=\"font-size:80%;\">Attention-based (</span><span class=\"ltx_text\" id=\"S2.T1.5.5.1.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.5.5.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.5.5.8.1\">\n<span class=\"ltx_p\" id=\"S2.T1.5.5.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text\" id=\"S2.T1.5.5.8.1.1.1\" style=\"font-size:80%;\">Data augmentation, random and beam search adversarial training, </span><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.5.5.8.1.1.2\" style=\"font-size:80%;\">IBP</span><span class=\"ltx_text\" id=\"S2.T1.5.5.8.1.1.3\" style=\"font-size:80%;\">-based</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.6.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.6.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.6.6.2.1\">\n<span class=\"ltx_p\" id=\"S2.T1.6.6.2.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.6.6.2.1.1.1\" style=\"font-size:80%;\">Zhang et al. (2021) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T1.6.6.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib19\" title=\"\">19</a><span class=\"ltx_text\" id=\"S2.T1.6.6.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.6.6.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.6.6.3.1\">\n<span class=\"ltx_p\" id=\"S2.T1.6.6.3.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T1.6.6.3.1.1.1\" style=\"font-size:80%;\">IBP-based</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.6.6.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.6.6.4.1\">\n<span class=\"ltx_p\" id=\"S2.T1.6.6.4.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T1.6.6.4.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.6.6.4.1.1.2\" style=\"font-size:80%;\">Deterministic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.6.6.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.6.6.5.1\">\n<span class=\"ltx_p\" id=\"S2.T1.6.6.5.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.6.6.5.1.1.1\" style=\"font-size:80%;\">IMDB, SST, SST2</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.6.6.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.6.6.6.1\">\n<span class=\"ltx_p\" id=\"S2.T1.6.6.6.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text\" id=\"S2.T1.6.6.6.1.1.1\" style=\"font-size:80%;\">Word perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.6.6.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.6.6.7.1\">\n<span class=\"ltx_p\" id=\"S2.T1.6.6.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.6.6.7.1.1.1\" style=\"font-size:80%;\">Word: not specified</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.6.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.6.6.1.1\">\n<span class=\"ltx_p\" id=\"S2.T1.6.6.1.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.6.6.1.1.1.1\" style=\"font-size:80%;\">LSTM (</span><span class=\"ltx_text\" id=\"S2.T1.6.6.1.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.6.6.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.6.6.8.1\">\n<span class=\"ltx_p\" id=\"S2.T1.6.6.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.6.6.8.1.1.1\" style=\"font-size:80%;\">IBP</span><span class=\"ltx_text\" id=\"S2.T1.6.6.8.1.1.2\" style=\"font-size:80%;\">-based</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.7.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.7.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.7.7.2.1\">\n<span class=\"ltx_p\" id=\"S2.T1.7.7.2.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.7.7.2.1.1.1\" style=\"font-size:80%;\">Wang et al. (2023) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T1.7.7.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib104\" title=\"\">104</a><span class=\"ltx_text\" id=\"S2.T1.7.7.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.7.7.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.7.7.3.1\">\n<span class=\"ltx_p\" id=\"S2.T1.7.7.3.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T1.7.7.3.1.1.1\" style=\"font-size:80%;\">IBP-based</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.7.7.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.7.7.4.1\">\n<span class=\"ltx_p\" id=\"S2.T1.7.7.4.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T1.7.7.4.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.7.7.4.1.1.2\" style=\"font-size:80%;\">Deterministic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.7.7.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.7.7.5.1\">\n<span class=\"ltx_p\" id=\"S2.T1.7.7.5.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.7.7.5.1.1.1\" style=\"font-size:80%;\">IMDB, YELP, SST2</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.7.7.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.7.7.6.1\">\n<span class=\"ltx_p\" id=\"S2.T1.7.7.6.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text\" id=\"S2.T1.7.7.6.1.1.1\" style=\"font-size:80%;\">Word substitution</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.7.7.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.7.7.7.1\">\n<span class=\"ltx_p\" id=\"S2.T1.7.7.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.7.7.7.1.1.1\" style=\"font-size:80%;\">Word: GloVe</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.7.7.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.7.7.1.1\">\n<span class=\"ltx_p\" id=\"S2.T1.7.7.1.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.7.7.1.1.1.1\" style=\"font-size:80%;\">CNN (</span><span class=\"ltx_text\" id=\"S2.T1.7.7.1.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.7.7.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.7.7.8.1\">\n<span class=\"ltx_p\" id=\"S2.T1.7.7.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.7.7.8.1.1.1\" style=\"font-size:80%;\">IBP</span><span class=\"ltx_text\" id=\"S2.T1.7.7.8.1.1.2\" style=\"font-size:80%;\">-based: Embedding Interval Bound Constraint (EIBC) triplet loss</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.9.9\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.9.9.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.9.9.3.1\">\n<span class=\"ltx_p\" id=\"S2.T1.9.9.3.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.9.9.3.1.1.1\" style=\"font-size:80%;\">Ko et al. (2019) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T1.9.9.3.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib105\" title=\"\">105</a><span class=\"ltx_text\" id=\"S2.T1.9.9.3.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.9.9.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.9.9.4.1\">\n<span class=\"ltx_p\" id=\"S2.T1.9.9.4.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T1.9.9.4.1.1.1\" style=\"font-size:80%;\">Abstract interpretation-based</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.9.9.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.9.9.5.1\">\n<span class=\"ltx_p\" id=\"S2.T1.9.9.5.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T1.9.9.5.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.9.9.5.1.1.2\" style=\"font-size:80%;\">Deterministic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.9.9.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.9.9.6.1\">\n<span class=\"ltx_p\" id=\"S2.T1.9.9.6.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.9.9.6.1.1.1\" style=\"font-size:80%;\">CogComp QC</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.8.8.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.8.8.1.1\">\n<span class=\"ltx_p\" id=\"S2.T1.8.8.1.1.1\" style=\"width:75.9pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.9.9.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.9.9.7.1\">\n<span class=\"ltx_p\" id=\"S2.T1.9.9.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.9.9.7.1.1.1\" style=\"font-size:80%;\">Word: not specified</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.9.9.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.9.9.2.1\">\n<span class=\"ltx_p\" id=\"S2.T1.9.9.2.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.9.9.2.1.1.1\" style=\"font-size:80%;\">RNN, LSTM (</span><span class=\"ltx_text\" id=\"S2.T1.9.9.2.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.9.9.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.9.9.8.1\">\n<span class=\"ltx_p\" id=\"S2.T1.9.9.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text\" id=\"S2.T1.9.9.8.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.11.11\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.11.11.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.11.11.3.1\">\n<span class=\"ltx_p\" id=\"S2.T1.11.11.3.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.11.11.3.1.1.1\" style=\"font-size:80%;\">Shi et al. (2020) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T1.11.11.3.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib15\" title=\"\">15</a><span class=\"ltx_text\" id=\"S2.T1.11.11.3.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.11.11.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.11.11.4.1\">\n<span class=\"ltx_p\" id=\"S2.T1.11.11.4.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T1.11.11.4.1.1.1\" style=\"font-size:80%;\">Abstract interpretation-based</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.11.11.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.11.11.5.1\">\n<span class=\"ltx_p\" id=\"S2.T1.11.11.5.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T1.11.11.5.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.11.11.5.1.1.2\" style=\"font-size:80%;\">Deterministic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.11.11.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.11.11.6.1\">\n<span class=\"ltx_p\" id=\"S2.T1.11.11.6.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.11.11.6.1.1.1\" style=\"font-size:80%;\">YELP, SST</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.10.10.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.10.10.1.1\">\n<span class=\"ltx_p\" id=\"S2.T1.10.10.1.1.1\" style=\"width:75.9pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.11.11.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.11.11.7.1\">\n<span class=\"ltx_p\" id=\"S2.T1.11.11.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.11.11.7.1.1.1\" style=\"font-size:80%;\">Word: not specified</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.11.11.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.11.11.2.1\">\n<span class=\"ltx_p\" id=\"S2.T1.11.11.2.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.11.11.2.1.1.1\" style=\"font-size:80%;\">Transformer (</span><span class=\"ltx_text\" id=\"S2.T1.11.11.2.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.11.11.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.11.11.8.1\">\n<span class=\"ltx_p\" id=\"S2.T1.11.11.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text\" id=\"S2.T1.11.11.8.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.13.13\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.13.13.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.13.13.3.1\">\n<span class=\"ltx_p\" id=\"S2.T1.13.13.3.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.13.13.3.1.1.1\" style=\"font-size:80%;\">Du et al. (2021) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T1.13.13.3.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib106\" title=\"\">106</a><span class=\"ltx_text\" id=\"S2.T1.13.13.3.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.13.13.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.13.13.4.1\">\n<span class=\"ltx_p\" id=\"S2.T1.13.13.4.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T1.13.13.4.1.1.1\" style=\"font-size:80%;\">Abstract interpretation-based</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.13.13.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.13.13.5.1\">\n<span class=\"ltx_p\" id=\"S2.T1.13.13.5.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T1.13.13.5.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.13.13.5.1.1.2\" style=\"font-size:80%;\">Deterministic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.13.13.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.13.13.6.1\">\n<span class=\"ltx_p\" id=\"S2.T1.13.13.6.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.13.13.6.1.1.1\" style=\"font-size:80%;\">Rotten Tomatoes Movie Review, Toxic Comment</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.12.12.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.12.12.1.1\">\n<span class=\"ltx_p\" id=\"S2.T1.12.12.1.1.1\" style=\"width:75.9pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.13.13.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.13.13.7.1\">\n<span class=\"ltx_p\" id=\"S2.T1.13.13.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.13.13.7.1.1.1\" style=\"font-size:80%;\">Word: GloVe</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.13.13.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.13.13.2.1\">\n<span class=\"ltx_p\" id=\"S2.T1.13.13.2.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.13.13.2.1.1.1\" style=\"font-size:80%;\">RNN, LSTM (</span><span class=\"ltx_text\" id=\"S2.T1.13.13.2.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T1.13.13.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.13.13.8.1\">\n<span class=\"ltx_p\" id=\"S2.T1.13.13.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.13.13.8.1.1.1\" style=\"font-size:80%;\">IBP</span><span class=\"ltx_text\" id=\"S2.T1.13.13.8.1.1.2\" style=\"font-size:80%;\">-based</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.15.15\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.15.15.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.15.3.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.15.3.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.15.15.3.1.1.1\" style=\"font-size:80%;\">Bonaert et al. (2021) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T1.15.15.3.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib107\" title=\"\">107</a><span class=\"ltx_text\" id=\"S2.T1.15.15.3.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T1.15.15.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.15.4.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.15.4.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T1.15.15.4.1.1.1\" style=\"font-size:80%;\">Abstract interpretation-based</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T1.15.15.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.15.5.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.15.5.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T1.15.15.5.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.15.15.5.1.1.2\" style=\"font-size:80%;\">Deterministic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T1.15.15.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.15.6.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.15.6.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T1.15.15.6.1.1.1\" style=\"font-size:80%;\">SST, YELP</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T1.14.14.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.14.14.1.1\">\n<span class=\"ltx_p\" id=\"S2.T1.14.14.1.1.1\" style=\"width:75.9pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T1.15.15.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.15.7.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.15.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.15.15.7.1.1.1\" style=\"font-size:80%;\">Word: not specified</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T1.15.15.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.15.2.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.15.2.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T1.15.15.2.1.1.1\" style=\"font-size:80%;\">Transformer (</span><span class=\"ltx_text\" id=\"S2.T1.15.15.2.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T1.15.15.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T1.15.15.8.1\">\n<span class=\"ltx_p\" id=\"S2.T1.15.15.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text\" id=\"S2.T1.15.15.8.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S2.T1.19.1.1\" style=\"font-size:113%;\">Table 1</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S2.T1.20.2\" style=\"font-size:113%;\">Summary of the main features of the existing NLP verification approaches. In bold are state-of-the-art methods.</em></figcaption>\n</figure>",
            "capture": "Table 1: Summary of the main features of the existing NLP verification approaches. In bold are state-of-the-art methods."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S2.T2\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S2.T2.13\">\n<tr class=\"ltx_tr\" id=\"S2.T2.13.14\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_tt\" id=\"S2.T2.13.14.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.14.1.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.14.1.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.13.14.1.1.1.1\" style=\"font-size:80%;\">Method</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T2.13.14.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.14.2.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.14.2.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.13.14.2.1.1.1\" style=\"font-size:80%;\">Verification algorithm</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T2.13.14.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.14.3.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.14.3.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.13.14.3.1.1.1\" style=\"font-size:80%;\">Verification characteristics</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T2.13.14.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.14.4.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.14.4.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.13.14.4.1.1.1\" style=\"font-size:80%;\">Datasets</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T2.13.14.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.14.5.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.14.5.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.13.14.5.1.1.1\" style=\"font-size:80%;\">NLP perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T2.13.14.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.14.6.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.14.6.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.13.14.6.1.1.1\" style=\"font-size:80%;\">Embeddings</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T2.13.14.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.14.7.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.14.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.13.14.7.1.1.1\" style=\"font-size:80%;\">Architectures (# of parameters)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T2.13.14.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.14.8.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.14.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.13.14.8.1.1.1\" style=\"font-size:80%;\">Robust training</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.2.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_tt\" id=\"S2.T2.2.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.2.2.3.1\">\n<span class=\"ltx_p\" id=\"S2.T2.2.2.3.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T2.2.2.3.1.1.1\" style=\"font-size:80%;\">Ye et al. (2020) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T2.2.2.3.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib108\" title=\"\">108</a><span class=\"ltx_text\" id=\"S2.T2.2.2.3.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T2.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S2.T2.1.1.1.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T2.1.1.1.1.1.1\" style=\"font-size:80%;\">Randomised smoothing (</span><span class=\"ltx_text\" id=\"S2.T2.1.1.1.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T2.2.2.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.2.2.4.1\">\n<span class=\"ltx_p\" id=\"S2.T2.2.2.4.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T2.2.2.4.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T2.2.2.4.1.1.2\" style=\"font-size:80%;\">Probabilistic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T2.2.2.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.2.2.5.1\">\n<span class=\"ltx_p\" id=\"S2.T2.2.2.5.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T2.2.2.5.1.1.1\" style=\"font-size:80%;\">IMDB, Amazon</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T2.2.2.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.2.2.6.1\">\n<span class=\"ltx_p\" id=\"S2.T2.2.2.6.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text\" id=\"S2.T2.2.2.6.1.1.1\" style=\"font-size:80%;\">Word substitution</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T2.2.2.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.2.2.7.1\">\n<span class=\"ltx_p\" id=\"S2.T2.2.2.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T2.2.2.7.1.1.1\" style=\"font-size:80%;\">Word: GloVe</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T2.2.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.2.2.2.1\">\n<span class=\"ltx_p\" id=\"S2.T2.2.2.2.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T2.2.2.2.1.1.1\" style=\"font-size:80%;\">Transformer (</span><span class=\"ltx_text\" id=\"S2.T2.2.2.2.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T2.2.2.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.2.2.8.1\">\n<span class=\"ltx_p\" id=\"S2.T2.2.2.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text\" id=\"S2.T2.2.2.8.1.1.1\" style=\"font-size:80%;\">Data </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T2.2.2.8.1.1.2\" style=\"font-size:80%;\">augmentation</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.3.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T2.3.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.3.3.2.1\">\n<span class=\"ltx_p\" id=\"S2.T2.3.3.2.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T2.3.3.2.1.1.1\" style=\"font-size:80%;\">Wang et al. (2021) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T2.3.3.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib109\" title=\"\">109</a><span class=\"ltx_text\" id=\"S2.T2.3.3.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.3.3.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.3.3.3.1\">\n<span class=\"ltx_p\" id=\"S2.T2.3.3.3.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T2.3.3.3.1.1.1\" style=\"font-size:80%;\">Differential privacy-based</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.3.3.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.3.3.4.1\">\n<span class=\"ltx_p\" id=\"S2.T2.3.3.4.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T2.3.3.4.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T2.3.3.4.1.1.2\" style=\"font-size:80%;\">Probabilistic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.3.3.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.3.3.5.1\">\n<span class=\"ltx_p\" id=\"S2.T2.3.3.5.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T2.3.3.5.1.1.1\" style=\"font-size:80%;\">IMDB, AGNews</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.3.3.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.3.3.6.1\">\n<span class=\"ltx_p\" id=\"S2.T2.3.3.6.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text\" id=\"S2.T2.3.3.6.1.1.1\" style=\"font-size:80%;\">Word substitution</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.3.3.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.3.3.7.1\">\n<span class=\"ltx_p\" id=\"S2.T2.3.3.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T2.3.3.7.1.1.1\" style=\"font-size:80%;\">Word: GloVe</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.3.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.3.3.1.1\">\n<span class=\"ltx_p\" id=\"S2.T2.3.3.1.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T2.3.3.1.1.1.1\" style=\"font-size:80%;\">LSTM (</span><span class=\"ltx_text\" id=\"S2.T2.3.3.1.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.3.3.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.3.3.8.1\">\n<span class=\"ltx_p\" id=\"S2.T2.3.3.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text\" id=\"S2.T2.3.3.8.1.1.1\" style=\"font-size:80%;\">Data </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T2.3.3.8.1.1.2\" style=\"font-size:80%;\">augmentation</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.5.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T2.5.5.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.5.5.3.1\">\n<span class=\"ltx_p\" id=\"S2.T2.5.5.3.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T2.5.5.3.1.1.1\" style=\"font-size:80%;\">Zhao et al. (2022) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T2.5.5.3.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib110\" title=\"\">110</a><span class=\"ltx_text\" id=\"S2.T2.5.5.3.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.4.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.4.4.1.1\">\n<span class=\"ltx_p\" id=\"S2.T2.4.4.1.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T2.4.4.1.1.1.1\" style=\"font-size:80%;\">Randomised smoothing (</span><span class=\"ltx_text\" id=\"S2.T2.4.4.1.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.5.5.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.5.5.4.1\">\n<span class=\"ltx_p\" id=\"S2.T2.5.5.4.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T2.5.5.4.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T2.5.5.4.1.1.2\" style=\"font-size:80%;\">Probabilistic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.5.5.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.5.5.5.1\">\n<span class=\"ltx_p\" id=\"S2.T2.5.5.5.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T2.5.5.5.1.1.1\" style=\"font-size:80%;\">AGNews, SST</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.5.5.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.5.5.6.1\">\n<span class=\"ltx_p\" id=\"S2.T2.5.5.6.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text\" id=\"S2.T2.5.5.6.1.1.1\" style=\"font-size:80%;\">Word substitution</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.5.5.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.5.5.7.1\">\n<span class=\"ltx_p\" id=\"S2.T2.5.5.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T2.5.5.7.1.1.1\" style=\"font-size:80%;\">Word: GloVe</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.5.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.5.5.2.1\">\n<span class=\"ltx_p\" id=\"S2.T2.5.5.2.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T2.5.5.2.1.1.1\" style=\"font-size:80%;\">Transformer (</span><span class=\"ltx_text\" id=\"S2.T2.5.5.2.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.5.5.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.5.5.8.1\">\n<span class=\"ltx_p\" id=\"S2.T2.5.5.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text\" id=\"S2.T2.5.5.8.1.1.1\" style=\"font-size:80%;\">Data </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T2.5.5.8.1.1.2\" style=\"font-size:80%;\">augmentation </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T2.5.5.8.1.1.3\" style=\"font-size:80%;\">and IBP-based</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.7.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T2.7.7.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.7.7.3.1\">\n<span class=\"ltx_p\" id=\"S2.T2.7.7.3.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T2.7.7.3.1.1.1\" style=\"font-size:80%;\">Zeng et al. (2023) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T2.7.7.3.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib111\" title=\"\">111</a><span class=\"ltx_text\" id=\"S2.T2.7.7.3.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.6.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.6.6.1.1\">\n<span class=\"ltx_p\" id=\"S2.T2.6.6.1.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T2.6.6.1.1.1.1\" style=\"font-size:80%;\">Randomised smoothing (</span><span class=\"ltx_text\" id=\"S2.T2.6.6.1.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.7.7.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.7.7.4.1\">\n<span class=\"ltx_p\" id=\"S2.T2.7.7.4.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T2.7.7.4.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T2.7.7.4.1.1.2\" style=\"font-size:80%;\">Probabilistic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.7.7.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.7.7.5.1\">\n<span class=\"ltx_p\" id=\"S2.T2.7.7.5.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T2.7.7.5.1.1.1\" style=\"font-size:80%;\">IMDB, YELP</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.7.7.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.7.7.6.1\">\n<span class=\"ltx_p\" id=\"S2.T2.7.7.6.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text\" id=\"S2.T2.7.7.6.1.1.1\" style=\"font-size:80%;\">Char and word substitution</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.7.7.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.7.7.7.1\">\n<span class=\"ltx_p\" id=\"S2.T2.7.7.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T2.7.7.7.1.1.1\" style=\"font-size:80%;\">Word: not specified</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.7.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.7.7.2.1\">\n<span class=\"ltx_p\" id=\"S2.T2.7.7.2.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T2.7.7.2.1.1.1\" style=\"font-size:80%;\">Transformer (</span><span class=\"ltx_text\" id=\"S2.T2.7.7.2.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.7.7.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.7.7.8.1\">\n<span class=\"ltx_p\" id=\"S2.T2.7.7.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text\" id=\"S2.T2.7.7.8.1.1.1\" style=\"font-size:80%;\">Data </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T2.7.7.8.1.1.2\" style=\"font-size:80%;\">augmentation</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.9.9\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T2.9.9.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.9.9.3.1\">\n<span class=\"ltx_p\" id=\"S2.T2.9.9.3.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T2.9.9.3.1.1.1\" style=\"font-size:80%;\">Ye et al. (2023) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T2.9.9.3.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib112\" title=\"\">112</a><span class=\"ltx_text\" id=\"S2.T2.9.9.3.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.8.8.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.8.8.1.1\">\n<span class=\"ltx_p\" id=\"S2.T2.8.8.1.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T2.8.8.1.1.1.1\" style=\"font-size:80%;\">Randomised smoothing (</span><span class=\"ltx_text\" id=\"S2.T2.8.8.1.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.9.9.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.9.9.4.1\">\n<span class=\"ltx_p\" id=\"S2.T2.9.9.4.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T2.9.9.4.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T2.9.9.4.1.1.2\" style=\"font-size:80%;\">Probabilistic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.9.9.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.9.9.5.1\">\n<span class=\"ltx_p\" id=\"S2.T2.9.9.5.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T2.9.9.5.1.1.1\" style=\"font-size:80%;\">IMDB, SST2, YELP, AGNews</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.9.9.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.9.9.6.1\">\n<span class=\"ltx_p\" id=\"S2.T2.9.9.6.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text\" id=\"S2.T2.9.9.6.1.1.1\" style=\"font-size:80%;\">Word substitution</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.9.9.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.9.9.7.1\">\n<span class=\"ltx_p\" id=\"S2.T2.9.9.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T2.9.9.7.1.1.1\" style=\"font-size:80%;\">Word: not specified</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.9.9.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.9.9.2.1\">\n<span class=\"ltx_p\" id=\"S2.T2.9.9.2.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T2.9.9.2.1.1.1\" style=\"font-size:80%;\">Transformer (</span><span class=\"ltx_text\" id=\"S2.T2.9.9.2.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.9.9.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.9.9.8.1\">\n<span class=\"ltx_p\" id=\"S2.T2.9.9.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text\" id=\"S2.T2.9.9.8.1.1.1\" style=\"font-size:80%;\">Data </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T2.9.9.8.1.1.2\" style=\"font-size:80%;\">augmentation</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.11.11\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T2.11.11.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.11.11.3.1\">\n<span class=\"ltx_p\" id=\"S2.T2.11.11.3.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T2.11.11.3.1.1.1\" style=\"font-size:80%;\">Zhang et al. (2023) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T2.11.11.3.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib113\" title=\"\">113</a><span class=\"ltx_text\" id=\"S2.T2.11.11.3.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.10.10.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.10.10.1.1\">\n<span class=\"ltx_p\" id=\"S2.T2.10.10.1.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T2.10.10.1.1.1.1\" style=\"font-size:80%;\">Randomised smoothing (</span><span class=\"ltx_text\" id=\"S2.T2.10.10.1.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.11.11.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.11.11.4.1\">\n<span class=\"ltx_p\" id=\"S2.T2.11.11.4.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T2.11.11.4.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T2.11.11.4.1.1.2\" style=\"font-size:80%;\">Probabilistic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.11.11.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.11.11.5.1\">\n<span class=\"ltx_p\" id=\"S2.T2.11.11.5.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T2.11.11.5.1.1.1\" style=\"font-size:80%;\">IMDB, Amazon, AGNews</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.11.11.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.11.11.6.1\">\n<span class=\"ltx_p\" id=\"S2.T2.11.11.6.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text\" id=\"S2.T2.11.11.6.1.1.1\" style=\"font-size:80%;\">Word perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.11.11.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.11.11.7.1\">\n<span class=\"ltx_p\" id=\"S2.T2.11.11.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T2.11.11.7.1.1.1\" style=\"font-size:80%;\">Word: GloVe</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.11.11.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.11.11.2.1\">\n<span class=\"ltx_p\" id=\"S2.T2.11.11.2.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T2.11.11.2.1.1.1\" style=\"font-size:80%;\">LSTM, Transformer (</span><span class=\"ltx_text\" id=\"S2.T2.11.11.2.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T2.11.11.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.11.11.8.1\">\n<span class=\"ltx_p\" id=\"S2.T2.11.11.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text\" id=\"S2.T2.11.11.8.1.1.1\" style=\"font-size:80%;\">Data </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T2.11.11.8.1.1.2\" style=\"font-size:80%;\">augmentation</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.13.13\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T2.13.13.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.13.3.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.13.3.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S2.T2.13.13.3.1.1.1\" style=\"font-size:80%;\">Zhang et al. (2023) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T2.13.13.3.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib114\" title=\"\">114</a><span class=\"ltx_text\" id=\"S2.T2.13.13.3.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T2.12.12.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.12.12.1.1\">\n<span class=\"ltx_p\" id=\"S2.T2.12.12.1.1.1\" style=\"width:77.2pt;\"><span class=\"ltx_text\" id=\"S2.T2.12.12.1.1.1.1\" style=\"font-size:80%;\">Randomised smoothing (</span><span class=\"ltx_text\" id=\"S2.T2.12.12.1.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T2.13.13.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.13.4.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.13.4.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S2.T2.13.13.4.1.1.1\" style=\"font-size:80%;\">Incomplete, </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S2.T2.13.13.4.1.1.2\" style=\"font-size:80%;\">Probabilistic</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T2.13.13.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.13.5.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.13.5.1.1\" style=\"width:69.4pt;\"><span class=\"ltx_text\" id=\"S2.T2.13.13.5.1.1.1\" style=\"font-size:80%;\">SST2, AGNews</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T2.13.13.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.13.6.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.13.6.1.1\" style=\"width:75.9pt;\"><span class=\"ltx_text\" id=\"S2.T2.13.13.6.1.1.1\" style=\"font-size:80%;\">Word perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T2.13.13.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.13.7.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.13.7.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T2.13.13.7.1.1.1\" style=\"font-size:80%;\">Word: not specified</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T2.13.13.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.13.2.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.13.2.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text\" id=\"S2.T2.13.13.2.1.1.1\" style=\"font-size:80%;\">Transformer (</span><span class=\"ltx_text\" id=\"S2.T2.13.13.2.1.1.2\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T2.13.13.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T2.13.13.8.1\">\n<span class=\"ltx_p\" id=\"S2.T2.13.13.8.1.1\" style=\"width:104.1pt;\"><span class=\"ltx_text\" id=\"S2.T2.13.13.8.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S2.T2.17.1.1\" style=\"font-size:113%;\">Table 2</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S2.T2.18.2\" style=\"font-size:113%;\">Summary of the main features of the existing randomised smoothing approaches.</em></figcaption>\n</figure>",
            "capture": "Table 2: Summary of the main features of the existing randomised smoothing approaches."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S2.T3\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S2.T3.11\">\n<tr class=\"ltx_tr\" id=\"S2.T3.11.12\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T3.11.12.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.11.12.1.1\">\n<span class=\"ltx_p\" id=\"S2.T3.11.12.1.1.1\" style=\"width:47.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T3.11.12.1.1.1.1\" style=\"font-size:80%;\">Dataset</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T3.11.12.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.11.12.2.1\">\n<span class=\"ltx_p\" id=\"S2.T3.11.12.2.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T3.11.12.2.1.1.1\" style=\"font-size:80%;\">Safety Critical</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T3.11.12.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.11.12.3.1\">\n<span class=\"ltx_p\" id=\"S2.T3.11.12.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T3.11.12.3.1.1.1\" style=\"font-size:80%;\">Category</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_tt\" id=\"S2.T3.11.12.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.11.12.4.1\">\n<span class=\"ltx_p\" id=\"S2.T3.11.12.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T3.11.12.4.1.1.1\" style=\"font-size:80%;\">Tasks</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S2.T3.11.12.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.11.12.5.1\">\n<span class=\"ltx_p\" id=\"S2.T3.11.12.5.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T3.11.12.5.1.1.1\" style=\"font-size:80%;\">Size</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S2.T3.11.12.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.11.12.6.1\">\n<span class=\"ltx_p\" id=\"S2.T3.11.12.6.1.1\" style=\"width:26.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T3.11.12.6.1.1.1\" style=\"font-size:80%;\">Classes</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T3.1.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.1.1.2.1\">\n<span class=\"ltx_p\" id=\"S2.T3.1.1.2.1.1\" style=\"width:47.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.1.1.2.1.1.1\" style=\"font-size:80%;\">IMDB\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T3.1.1.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib119\" title=\"\">119</a><span class=\"ltx_text\" id=\"S2.T3.1.1.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S2.T3.1.1.1.1.1\" style=\"width:30.4pt;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S2.T3.1.1.1.1.1.1\" style=\"width:5.3pt;height:5.4pt;vertical-align:-0.7pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-0.5pt,0.0pt) scale(0.85,1.0) ;\">\n<span class=\"ltx_p\" id=\"S2.T3.1.1.1.1.1.1.1\"></span>\n</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.1.1.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.1.1.3.1\">\n<span class=\"ltx_p\" id=\"S2.T3.1.1.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.1.1.3.1.1.1\" style=\"font-size:80%;\">Sentiment analysis</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S2.T3.1.1.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.1.1.4.1\">\n<span class=\"ltx_p\" id=\"S2.T3.1.1.4.1.1\"><span class=\"ltx_text\" id=\"S2.T3.1.1.4.1.1.1\" style=\"font-size:80%;\">Document-level and sentence-level classification</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.1.1.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.1.1.5.1\">\n<span class=\"ltx_p\" id=\"S2.T3.1.1.5.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.1.1.5.1.1.1\" style=\"font-size:80%;\">25,000</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S2.T3.1.1.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.1.1.6.1\">\n<span class=\"ltx_p\" id=\"S2.T3.1.1.6.1.1\" style=\"width:26.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.1.1.6.1.1.1\" style=\"font-size:80%;\">2</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T3.2.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.2.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.2.2.2.1\">\n<span class=\"ltx_p\" id=\"S2.T3.2.2.2.1.1\" style=\"width:47.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.2.2.2.1.1.1\" style=\"font-size:80%;\">SST\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T3.2.2.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib120\" title=\"\">120</a><span class=\"ltx_text\" id=\"S2.T3.2.2.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.2.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.2.2.1.1\">\n<span class=\"ltx_p\" id=\"S2.T3.2.2.1.1.1\" style=\"width:30.4pt;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S2.T3.2.2.1.1.1.1\" style=\"width:5.3pt;height:5.4pt;vertical-align:-0.7pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-0.5pt,0.0pt) scale(0.85,1.0) ;\">\n<span class=\"ltx_p\" id=\"S2.T3.2.2.1.1.1.1.1\"></span>\n</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.2.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.2.2.3.1\">\n<span class=\"ltx_p\" id=\"S2.T3.2.2.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.2.2.3.1.1.1\" style=\"font-size:80%;\">Sentiment analysis</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S2.T3.2.2.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.2.2.4.1\">\n<span class=\"ltx_p\" id=\"S2.T3.2.2.4.1.1\"><span class=\"ltx_text\" id=\"S2.T3.2.2.4.1.1.1\" style=\"font-size:80%;\">Sentiment classification, hierarchical sentiment classification, sentiment span detection</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.2.2.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.2.2.5.1\">\n<span class=\"ltx_p\" id=\"S2.T3.2.2.5.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.2.2.5.1.1.1\" style=\"font-size:80%;\">70,042</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S2.T3.2.2.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.2.2.6.1\">\n<span class=\"ltx_p\" id=\"S2.T3.2.2.6.1.1\" style=\"width:26.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.2.2.6.1.1.1\" style=\"font-size:80%;\">5</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T3.3.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.3.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.3.3.2.1\">\n<span class=\"ltx_p\" id=\"S2.T3.3.3.2.1.1\" style=\"width:47.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.3.3.2.1.1.1\" style=\"font-size:80%;\">SST2\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T3.3.3.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib120\" title=\"\">120</a><span class=\"ltx_text\" id=\"S2.T3.3.3.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.3.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.3.3.1.1\">\n<span class=\"ltx_p\" id=\"S2.T3.3.3.1.1.1\" style=\"width:30.4pt;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S2.T3.3.3.1.1.1.1\" style=\"width:5.3pt;height:5.4pt;vertical-align:-0.7pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-0.5pt,0.0pt) scale(0.85,1.0) ;\">\n<span class=\"ltx_p\" id=\"S2.T3.3.3.1.1.1.1.1\"></span>\n</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.3.3.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.3.3.3.1\">\n<span class=\"ltx_p\" id=\"S2.T3.3.3.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.3.3.3.1.1.1\" style=\"font-size:80%;\">Sentiment analysis</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S2.T3.3.3.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.3.3.4.1\">\n<span class=\"ltx_p\" id=\"S2.T3.3.3.4.1.1\"><span class=\"ltx_text\" id=\"S2.T3.3.3.4.1.1.1\" style=\"font-size:80%;\">Sentiment classification</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.3.3.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.3.3.5.1\">\n<span class=\"ltx_p\" id=\"S2.T3.3.3.5.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.3.3.5.1.1.1\" style=\"font-size:80%;\">70,042</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S2.T3.3.3.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.3.3.6.1\">\n<span class=\"ltx_p\" id=\"S2.T3.3.3.6.1.1\" style=\"width:26.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.3.3.6.1.1.1\" style=\"font-size:80%;\">2</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T3.4.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.4.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.4.4.2.1\">\n<span class=\"ltx_p\" id=\"S2.T3.4.4.2.1.1\" style=\"width:47.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.4.4.2.1.1.1\" style=\"font-size:80%;\">YELP\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T3.4.4.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib121\" title=\"\">121</a><span class=\"ltx_text\" id=\"S2.T3.4.4.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.4.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.4.4.1.1\">\n<span class=\"ltx_p\" id=\"S2.T3.4.4.1.1.1\" style=\"width:30.4pt;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S2.T3.4.4.1.1.1.1\" style=\"width:5.3pt;height:5.4pt;vertical-align:-0.7pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-0.5pt,0.0pt) scale(0.85,1.0) ;\">\n<span class=\"ltx_p\" id=\"S2.T3.4.4.1.1.1.1.1\"></span>\n</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.4.4.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.4.4.3.1\">\n<span class=\"ltx_p\" id=\"S2.T3.4.4.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.4.4.3.1.1.1\" style=\"font-size:80%;\">Sentiment analysis</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S2.T3.4.4.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.4.4.4.1\">\n<span class=\"ltx_p\" id=\"S2.T3.4.4.4.1.1\"><span class=\"ltx_text\" id=\"S2.T3.4.4.4.1.1.1\" style=\"font-size:80%;\">Sentiment classification</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.4.4.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.4.4.5.1\">\n<span class=\"ltx_p\" id=\"S2.T3.4.4.5.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.4.4.5.1.1.1\" style=\"font-size:80%;\">570,771</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S2.T3.4.4.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.4.4.6.1\">\n<span class=\"ltx_p\" id=\"S2.T3.4.4.6.1.1\" style=\"width:26.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.4.4.6.1.1.1\" style=\"font-size:80%;\">2</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T3.5.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.5.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.5.5.2.1\">\n<span class=\"ltx_p\" id=\"S2.T3.5.5.2.1.1\" style=\"width:47.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.5.5.2.1.1.1\" style=\"font-size:80%;\">Rotten Tomatoes Movie Review\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T3.5.5.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib122\" title=\"\">122</a><span class=\"ltx_text\" id=\"S2.T3.5.5.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.5.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.5.5.1.1\">\n<span class=\"ltx_p\" id=\"S2.T3.5.5.1.1.1\" style=\"width:30.4pt;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S2.T3.5.5.1.1.1.1\" style=\"width:5.3pt;height:5.4pt;vertical-align:-0.7pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-0.5pt,0.0pt) scale(0.85,1.0) ;\">\n<span class=\"ltx_p\" id=\"S2.T3.5.5.1.1.1.1.1\"></span>\n</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.5.5.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.5.5.3.1\">\n<span class=\"ltx_p\" id=\"S2.T3.5.5.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.5.5.3.1.1.1\" style=\"font-size:80%;\">Sentiment analysis</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S2.T3.5.5.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.5.5.4.1\">\n<span class=\"ltx_p\" id=\"S2.T3.5.5.4.1.1\"><span class=\"ltx_text\" id=\"S2.T3.5.5.4.1.1.1\" style=\"font-size:80%;\">Sentiment classification</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.5.5.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.5.5.5.1\">\n<span class=\"ltx_p\" id=\"S2.T3.5.5.5.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.5.5.5.1.1.1\" style=\"font-size:80%;\">48,869</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S2.T3.5.5.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.5.5.6.1\">\n<span class=\"ltx_p\" id=\"S2.T3.5.5.6.1.1\" style=\"width:26.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.5.5.6.1.1.1\" style=\"font-size:80%;\">3/4</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T3.6.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.6.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.6.6.2.1\">\n<span class=\"ltx_p\" id=\"S2.T3.6.6.2.1.1\" style=\"width:47.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.6.6.2.1.1.1\" style=\"font-size:80%;\">Amazon\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T3.6.6.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib123\" title=\"\">123</a><span class=\"ltx_text\" id=\"S2.T3.6.6.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.6.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.6.6.1.1\">\n<span class=\"ltx_p\" id=\"S2.T3.6.6.1.1.1\" style=\"width:30.4pt;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S2.T3.6.6.1.1.1.1\" style=\"width:5.3pt;height:5.4pt;vertical-align:-0.7pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-0.5pt,0.0pt) scale(0.85,1.0) ;\">\n<span class=\"ltx_p\" id=\"S2.T3.6.6.1.1.1.1.1\"></span>\n</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.6.6.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.6.6.3.1\">\n<span class=\"ltx_p\" id=\"S2.T3.6.6.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.6.6.3.1.1.1\" style=\"font-size:80%;\">Sentiment analysis</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S2.T3.6.6.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.6.6.4.1\">\n<span class=\"ltx_p\" id=\"S2.T3.6.6.4.1.1\"><span class=\"ltx_text\" id=\"S2.T3.6.6.4.1.1.1\" style=\"font-size:80%;\">Sentiment classification, aspect-based sentiment analysis</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.6.6.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.6.6.5.1\">\n<span class=\"ltx_p\" id=\"S2.T3.6.6.5.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.6.6.5.1.1.1\" style=\"font-size:80%;\">34,686,770</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S2.T3.6.6.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.6.6.6.1\">\n<span class=\"ltx_p\" id=\"S2.T3.6.6.6.1.1\" style=\"width:26.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.6.6.6.1.1.1\" style=\"font-size:80%;\">5</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T3.7.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.7.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.7.7.2.1\">\n<span class=\"ltx_p\" id=\"S2.T3.7.7.2.1.1\" style=\"width:47.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.7.7.2.1.1.1\" style=\"font-size:80%;\">SNLI\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T3.7.7.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib117\" title=\"\">117</a><span class=\"ltx_text\" id=\"S2.T3.7.7.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.7.7.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.7.7.1.1\">\n<span class=\"ltx_p\" id=\"S2.T3.7.7.1.1.1\" style=\"width:30.4pt;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S2.T3.7.7.1.1.1.1\" style=\"width:5.3pt;height:5.4pt;vertical-align:-0.7pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-0.5pt,0.0pt) scale(0.85,1.0) ;\">\n<span class=\"ltx_p\" id=\"S2.T3.7.7.1.1.1.1.1\"></span>\n</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.7.7.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.7.7.3.1\">\n<span class=\"ltx_p\" id=\"S2.T3.7.7.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.7.7.3.1.1.1\" style=\"font-size:80%;\">Semantic inference</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S2.T3.7.7.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.7.7.4.1\">\n<span class=\"ltx_p\" id=\"S2.T3.7.7.4.1.1\"><span class=\"ltx_text\" id=\"S2.T3.7.7.4.1.1.1\" style=\"font-size:80%;\">Natural language inference, semantic similarity</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.7.7.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.7.7.5.1\">\n<span class=\"ltx_p\" id=\"S2.T3.7.7.5.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.7.7.5.1.1.1\" style=\"font-size:80%;\">570,152</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S2.T3.7.7.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.7.7.6.1\">\n<span class=\"ltx_p\" id=\"S2.T3.7.7.6.1.1\" style=\"width:26.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.7.7.6.1.1.1\" style=\"font-size:80%;\">3</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T3.8.8\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.8.8.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.8.8.2.1\">\n<span class=\"ltx_p\" id=\"S2.T3.8.8.2.1.1\" style=\"width:47.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.8.8.2.1.1.1\" style=\"font-size:80%;\">MNLI\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T3.8.8.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib124\" title=\"\">124</a><span class=\"ltx_text\" id=\"S2.T3.8.8.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.8.8.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.8.8.1.1\">\n<span class=\"ltx_p\" id=\"S2.T3.8.8.1.1.1\" style=\"width:30.4pt;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S2.T3.8.8.1.1.1.1\" style=\"width:5.3pt;height:5.4pt;vertical-align:-0.7pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-0.5pt,0.0pt) scale(0.85,1.0) ;\">\n<span class=\"ltx_p\" id=\"S2.T3.8.8.1.1.1.1.1\"></span>\n</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.8.8.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.8.8.3.1\">\n<span class=\"ltx_p\" id=\"S2.T3.8.8.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.8.8.3.1.1.1\" style=\"font-size:80%;\">Semantic inference</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S2.T3.8.8.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.8.8.4.1\">\n<span class=\"ltx_p\" id=\"S2.T3.8.8.4.1.1\"><span class=\"ltx_text\" id=\"S2.T3.8.8.4.1.1.1\" style=\"font-size:80%;\">Natural language inference, semantic similarity, generalisation</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.8.8.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.8.8.5.1\">\n<span class=\"ltx_p\" id=\"S2.T3.8.8.5.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.8.8.5.1.1.1\" style=\"font-size:80%;\">432,702</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S2.T3.8.8.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.8.8.6.1\">\n<span class=\"ltx_p\" id=\"S2.T3.8.8.6.1.1\" style=\"width:26.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.8.8.6.1.1.1\" style=\"font-size:80%;\">3</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T3.9.9\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.9.9.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.9.9.2.1\">\n<span class=\"ltx_p\" id=\"S2.T3.9.9.2.1.1\" style=\"width:47.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.9.9.2.1.1.1\" style=\"font-size:80%;\">AGNews\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T3.9.9.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib125\" title=\"\">125</a><span class=\"ltx_text\" id=\"S2.T3.9.9.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.9.9.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.9.9.1.1\">\n<span class=\"ltx_p\" id=\"S2.T3.9.9.1.1.1\" style=\"width:30.4pt;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S2.T3.9.9.1.1.1.1\" style=\"width:5.3pt;height:5.4pt;vertical-align:-0.7pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-0.5pt,0.0pt) scale(0.85,1.0) ;\">\n<span class=\"ltx_p\" id=\"S2.T3.9.9.1.1.1.1.1\"></span>\n</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.9.9.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.9.9.3.1\">\n<span class=\"ltx_p\" id=\"S2.T3.9.9.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.9.9.3.1.1.1\" style=\"font-size:80%;\">Text analysis</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S2.T3.9.9.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.9.9.4.1\">\n<span class=\"ltx_p\" id=\"S2.T3.9.9.4.1.1\"><span class=\"ltx_text\" id=\"S2.T3.9.9.4.1.1.1\" style=\"font-size:80%;\">Text classification, sentiment classification</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.9.9.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.9.9.5.1\">\n<span class=\"ltx_p\" id=\"S2.T3.9.9.5.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.9.9.5.1.1.1\" style=\"font-size:80%;\">127,600</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S2.T3.9.9.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.9.9.6.1\">\n<span class=\"ltx_p\" id=\"S2.T3.9.9.6.1.1\" style=\"width:26.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.9.9.6.1.1.1\" style=\"font-size:80%;\">4</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T3.10.10\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.10.10.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.10.10.2.1\">\n<span class=\"ltx_p\" id=\"S2.T3.10.10.2.1.1\" style=\"width:47.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.10.10.2.1.1.1\" style=\"font-size:80%;\">CogComp QC\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T3.10.10.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib126\" title=\"\">126</a><span class=\"ltx_text\" id=\"S2.T3.10.10.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.10.10.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.10.10.1.1\">\n<span class=\"ltx_p\" id=\"S2.T3.10.10.1.1.1\" style=\"width:30.4pt;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S2.T3.10.10.1.1.1.1\" style=\"width:5.3pt;height:5.4pt;vertical-align:-0.7pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-0.5pt,0.0pt) scale(0.85,1.0) ;\">\n<span class=\"ltx_p\" id=\"S2.T3.10.10.1.1.1.1.1\"></span>\n</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.10.10.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.10.10.3.1\">\n<span class=\"ltx_p\" id=\"S2.T3.10.10.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.10.10.3.1.1.1\" style=\"font-size:80%;\">Text analysis</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S2.T3.10.10.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.10.10.4.1\">\n<span class=\"ltx_p\" id=\"S2.T3.10.10.4.1.1\"><span class=\"ltx_text\" id=\"S2.T3.10.10.4.1.1.1\" style=\"font-size:80%;\">Question classification, semantic understanding</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S2.T3.10.10.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.10.10.5.1\">\n<span class=\"ltx_p\" id=\"S2.T3.10.10.5.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.10.10.5.1.1.1\" style=\"font-size:80%;\">15,000</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S2.T3.10.10.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.10.10.6.1\">\n<span class=\"ltx_p\" id=\"S2.T3.10.10.6.1.1\" style=\"width:26.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.10.10.6.1.1.1\" style=\"font-size:80%;\">6/50</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T3.11.11\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T3.11.11.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.11.11.2.1\">\n<span class=\"ltx_p\" id=\"S2.T3.11.11.2.1.1\" style=\"width:47.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.11.11.2.1.1.1\" style=\"font-size:80%;\">Toxic Comment\u00a0</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" id=\"S2.T3.11.11.2.1.1.2.1\" style=\"font-size:80%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib118\" title=\"\">118</a><span class=\"ltx_text\" id=\"S2.T3.11.11.2.1.1.3.2\" style=\"font-size:80%;\">]</span></cite></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T3.11.11.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.11.11.1.1\">\n<span class=\"ltx_p\" id=\"S2.T3.11.11.1.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S2.T3.11.11.1.1.1.1\" style=\"font-size:80%;position:relative; bottom:2.1pt;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S2.T3.11.11.1.1.1.1.1\" style=\"width:0.0pt;height:0pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;\">\n<span class=\"ltx_p\" id=\"S2.T3.11.11.1.1.1.1.1.1\"></span>\n</span></span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T3.11.11.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.11.11.3.1\">\n<span class=\"ltx_p\" id=\"S2.T3.11.11.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.11.11.3.1.1.1\" style=\"font-size:80%;\">Text analysis</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T3.11.11.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.11.11.4.1\">\n<span class=\"ltx_p\" id=\"S2.T3.11.11.4.1.1\"><span class=\"ltx_text\" id=\"S2.T3.11.11.4.1.1.1\" style=\"font-size:80%;\">Toxic comment classification, fine-grained toxicity analysis, bias analysis</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S2.T3.11.11.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.11.11.5.1\">\n<span class=\"ltx_p\" id=\"S2.T3.11.11.5.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S2.T3.11.11.5.1.1.1\" style=\"font-size:80%;\">18,560</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\" id=\"S2.T3.11.11.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S2.T3.11.11.6.1\">\n<span class=\"ltx_p\" id=\"S2.T3.11.11.6.1.1\" style=\"width:26.0pt;\"><span class=\"ltx_text\" id=\"S2.T3.11.11.6.1.1.1\" style=\"font-size:80%;\">6</span></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S2.T3.15.1.1\" style=\"font-size:113%;\">Table 3</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S2.T3.16.2\" style=\"font-size:113%;\">Summary of the main features of the datasets used in NLP verification.</em></figcaption>\n</figure>",
            "capture": "Table 3: Summary of the main features of the datasets used in NLP verification."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T4\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S3.T4.2\">\n<tr class=\"ltx_tr\" id=\"S3.T4.2.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S3.T4.2.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.1.1.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.1.1.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.2.1.1.1.1.1\" style=\"font-size:80%;\">Method</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_tt\" id=\"S3.T4.2.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.1.2.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.1.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.2.1.2.1.1.1\" style=\"font-size:80%;\">Description</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S3.T4.2.1.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.1.3.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.1.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.2.1.3.1.1.1\" style=\"font-size:80%;\">Altered sentence</span><span class=\"ltx_text\" id=\"S3.T4.2.1.3.1.1.2\" style=\"font-size:80%;\"> </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S3.T4.2.1.3.1.1.3\" style=\"font-size:80%;\">(</span><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T4.2.1.3.1.1.4\" style=\"font-size:80%;\">Are you a robot?</em><span class=\"ltx_text\" id=\"S3.T4.2.1.3.1.1.5\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.2.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T4.2.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.2.1.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.2.1.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.2.1.1.1.1\" style=\"font-size:80%;\">Insertion</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S3.T4.2.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.2.2.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.2.2.1.1\"><span class=\"ltx_text\" id=\"S3.T4.2.2.2.1.1.1\" style=\"font-size:80%;\">A character is randomly selected and inserted in a random position.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S3.T4.2.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.2.3.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.2.3.1.1\" style=\"width:65.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T4.2.2.3.1.1.1\" style=\"font-size:80%;\">Are yo<span class=\"ltx_text\" id=\"S3.T4.2.2.3.1.1.1.1\" style=\"color:#FF0000;\">v</span>u a robot?</em></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.2.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T4.2.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.3.1.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.3.1.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.3.1.1.1.1\" style=\"font-size:80%;\">Deletion</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S3.T4.2.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.3.2.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.3.2.1.1\"><span class=\"ltx_text\" id=\"S3.T4.2.3.2.1.1.1\" style=\"font-size:80%;\">A character is randomly selected and deleted.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S3.T4.2.3.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.3.3.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.3.3.1.1\" style=\"width:65.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T4.2.3.3.1.1.1\" style=\"font-size:80%;\">Are you a robt?</em></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.2.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T4.2.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.4.1.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.4.1.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.4.1.1.1.1\" style=\"font-size:80%;\">Replacement</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S3.T4.2.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.4.2.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.4.2.1.1\"><span class=\"ltx_text\" id=\"S3.T4.2.4.2.1.1.1\" style=\"font-size:80%;\">A character is randomly selected and replaced by an adjacent character on the keyboard.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S3.T4.2.4.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.4.3.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.4.3.1.1\" style=\"width:65.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T4.2.4.3.1.1.1\" style=\"font-size:80%;\">Are you a ro<span class=\"ltx_text\" id=\"S3.T4.2.4.3.1.1.1.1\" style=\"color:#FF0000;\">n</span>ot?</em></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.2.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T4.2.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.5.1.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.5.1.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.5.1.1.1.1\" style=\"font-size:80%;\">Swapping</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S3.T4.2.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.5.2.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.5.2.1.1\"><span class=\"ltx_text\" id=\"S3.T4.2.5.2.1.1.1\" style=\"font-size:80%;\">A character is randomly selected and swapped with the adjacent right or left character in the word.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S3.T4.2.5.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.5.3.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.5.3.1.1\" style=\"width:65.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T4.2.5.3.1.1.1\" style=\"font-size:80%;\">Are you a r<span class=\"ltx_text\" id=\"S3.T4.2.5.3.1.1.1.1\" style=\"color:#FF0000;\">bo</span>ot?</em></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.2.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S3.T4.2.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.6.1.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.6.1.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S3.T4.2.6.1.1.1.1\" style=\"font-size:80%;\">Repetition</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t\" id=\"S3.T4.2.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.6.2.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.6.2.1.1\"><span class=\"ltx_text\" id=\"S3.T4.2.6.2.1.1.1\" style=\"font-size:80%;\">A character in a random position is selected and duplicated.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\" id=\"S3.T4.2.6.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T4.2.6.3.1\">\n<span class=\"ltx_p\" id=\"S3.T4.2.6.3.1.1\" style=\"width:65.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T4.2.6.3.1.1.1\" style=\"font-size:80%;\">Ar<span class=\"ltx_text\" id=\"S3.T4.2.6.3.1.1.1.1\" style=\"color:#FF0000;\">r</span>e you a robot?</em></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S3.T4.5.1.1\" style=\"font-size:113%;\">Table 4</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T4.6.2\" style=\"font-size:113%;\">Character-level perturbations: their types and examples of how each type acts on a given sentence from the R-U-A-Robot dataset\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib129\" title=\"\">129</a>]</cite>. Perturbations are selected from random words that have 3 or more characters, first and last characters of a word are never perturbed.</em></figcaption>\n</figure>",
            "capture": "Table 4: Character-level perturbations: their types and examples of how each type acts on a given sentence from the R-U-A-Robot dataset\u00a0[129]. Perturbations are selected from random words that have 3 or more characters, first and last characters of a word are never perturbed."
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T5\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S3.T5.2\">\n<tr class=\"ltx_tr\" id=\"S3.T5.2.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S3.T5.2.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.1.1.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.1.1.1.1\" style=\"width:73.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T5.2.1.1.1.1.1\" style=\"font-size:80%;\">Method</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_tt\" id=\"S3.T5.2.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.1.2.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.1.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T5.2.1.2.1.1.1\" style=\"font-size:80%;\">Description</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S3.T5.2.1.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.1.3.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.1.3.1.1\" style=\"width:138.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T5.2.1.3.1.1.1\" style=\"font-size:80%;\">Altered sentence</span><span class=\"ltx_text\" id=\"S3.T5.2.1.3.1.1.2\" style=\"font-size:80%;\"> </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S3.T5.2.1.3.1.1.3\" style=\"font-size:80%;\">(</span><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T5.2.1.3.1.1.4\" style=\"font-size:80%;\">Can u tell me if you are a chatbot?</em><span class=\"ltx_text\" id=\"S3.T5.2.1.3.1.1.5\" style=\"font-size:80%;\">)</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T5.2.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.2.1.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.2.1.1.1\" style=\"width:73.7pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.2.1.1.1.1\" style=\"font-size:80%;\">Deletion</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S3.T5.2.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.2.2.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.2.2.1.1\"><span class=\"ltx_text\" id=\"S3.T5.2.2.2.1.1.1\" style=\"font-size:80%;\">Randomly selects a word and removes it.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S3.T5.2.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.2.3.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.2.3.1.1\" style=\"width:138.8pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T5.2.2.3.1.1.1\" style=\"font-size:80%;\">Can u tell if you are a chatbot?</em></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T5.2.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.3.1.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.3.1.1.1\" style=\"width:73.7pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.3.1.1.1.1\" style=\"font-size:80%;\">Repetition</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S3.T5.2.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.3.2.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.3.2.1.1\"><span class=\"ltx_text\" id=\"S3.T5.2.3.2.1.1.1\" style=\"font-size:80%;\">Randomly selects a word and duplicates it.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S3.T5.2.3.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.3.3.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.3.3.1.1\" style=\"width:138.8pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T5.2.3.3.1.1.1\" style=\"font-size:80%;\">Can <span class=\"ltx_text\" id=\"S3.T5.2.3.3.1.1.1.1\" style=\"color:#FF0000;\">can</span> u tell me if you are a chatbot?</em></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T5.2.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.4.1.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.4.1.1.1\" style=\"width:73.7pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.4.1.1.1.1\" style=\"font-size:80%;\">Negation</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S3.T5.2.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.4.2.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.4.2.1.1\"><span class=\"ltx_text\" id=\"S3.T5.2.4.2.1.1.1\" style=\"font-size:80%;\">Identifies verbs then flips them (negative/positive).</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S3.T5.2.4.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.4.3.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.4.3.1.1\" style=\"width:138.8pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T5.2.4.3.1.1.1\" style=\"font-size:80%;\">Can u tell me if you are <span class=\"ltx_text\" id=\"S3.T5.2.4.3.1.1.1.1\" style=\"color:#FF0000;\">not</span> a chatbot?</em></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T5.2.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.5.1.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.5.1.1.1\" style=\"width:73.7pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.5.1.1.1.1\" style=\"font-size:80%;\">Singular/ plural verbs</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S3.T5.2.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.5.2.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.5.2.1.1\"><span class=\"ltx_text\" id=\"S3.T5.2.5.2.1.1.1\" style=\"font-size:80%;\">Changes verbs to singular form, and conversely.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S3.T5.2.5.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.5.3.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.5.3.1.1\" style=\"width:138.8pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T5.2.5.3.1.1.1\" style=\"font-size:80%;\">Can u tell me if you <span class=\"ltx_text\" id=\"S3.T5.2.5.3.1.1.1.1\" style=\"color:#FF0000;\">is</span> a chatbot?</em></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T5.2.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.6.1.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.6.1.1.1\" style=\"width:73.7pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.6.1.1.1.1\" style=\"font-size:80%;\">Word order</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" id=\"S3.T5.2.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.6.2.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.6.2.1.1\"><span class=\"ltx_text\" id=\"S3.T5.2.6.2.1.1.1\" style=\"font-size:80%;\">Randomly selects consecutive words and changes the order in which they appear.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S3.T5.2.6.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.6.3.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.6.3.1.1\" style=\"width:138.8pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T5.2.6.3.1.1.1\" style=\"font-size:80%;\">Can u tell me if you are <span class=\"ltx_text\" id=\"S3.T5.2.6.3.1.1.1.1\" style=\"color:#FF0000;\">chatbot a</span>?</em></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S3.T5.2.7.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.7.1.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.7.1.1.1\" style=\"width:73.7pt;\"><span class=\"ltx_text\" id=\"S3.T5.2.7.1.1.1.1\" style=\"font-size:80%;\">Verb tense</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t\" id=\"S3.T5.2.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.7.2.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.7.2.1.1\"><span class=\"ltx_text\" id=\"S3.T5.2.7.2.1.1.1\" style=\"font-size:80%;\">Converts present simple or continuous verbs to their corresponding past simple or continuous form.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\" id=\"S3.T5.2.7.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T5.2.7.3.1\">\n<span class=\"ltx_p\" id=\"S3.T5.2.7.3.1.1\" style=\"width:138.8pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T5.2.7.3.1.1.1\" style=\"font-size:80%;\">Can u tell me if you <span class=\"ltx_text\" id=\"S3.T5.2.7.3.1.1.1.1\" style=\"color:#FF0000;\">were</span> a chatbot?</em></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S3.T5.5.1.1\" style=\"font-size:113%;\">Table 5</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S3.T5.6.2\" style=\"font-size:113%;\">Word-level perturbations: their types and examples of how each type acts on a given sentence from the R-U-A-Robot dataset\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#bib.bib129\" title=\"\">129</a>]</cite>.</em></figcaption>\n</figure>",
            "capture": "Table 5: Word-level perturbations: their types and examples of how each type acts on a given sentence from the R-U-A-Robot dataset\u00a0[129]."
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T6\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T6.1\">\n<tr class=\"ltx_tr\" id=\"S4.T6.1.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T6.1.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T6.1.2.1.1\">\n<span class=\"ltx_p\" id=\"S4.T6.1.2.1.1.1\" style=\"width:39.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.2.1.1.1.1\" style=\"font-size:80%;\">Model</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T6.1.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T6.1.2.2.1\">\n<span class=\"ltx_p\" id=\"S4.T6.1.2.2.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.2.2.1.1.1\" style=\"font-size:80%;\">Adversarial training</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T6.1.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T6.1.2.3.1\">\n<span class=\"ltx_p\" id=\"S4.T6.1.2.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.2.3.1.1.1\" style=\"font-size:80%;\">Train Accuracy RUAR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T6.1.2.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T6.1.2.4.1\">\n<span class=\"ltx_p\" id=\"S4.T6.1.2.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.2.4.1.1.1\" style=\"font-size:80%;\">Test Accuracy RUAR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T6.1.2.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T6.1.2.5.1\">\n<span class=\"ltx_p\" id=\"S4.T6.1.2.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.2.5.1.1.1\" style=\"font-size:80%;\">Train Accuracy Medical</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S4.T6.1.2.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T6.1.2.6.1\">\n<span class=\"ltx_p\" id=\"S4.T6.1.2.6.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.2.6.1.1.1\" style=\"font-size:80%;\">Test Accuracy Medical</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.1.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T6.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T6.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S4.T6.1.1.1.1.1\" style=\"width:39.0pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T6.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T6.1.1.2.1\">\n<span class=\"ltx_p\" id=\"S4.T6.1.1.2.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.1.1.2.1.1.1\" style=\"font-size:80%;\">No</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T6.1.1.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T6.1.1.3.1\">\n<span class=\"ltx_p\" id=\"S4.T6.1.1.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.1.1.3.1.1.1\" style=\"font-size:80%;\">93.87 \u00b1 0.14%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T6.1.1.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T6.1.1.4.1\">\n<span class=\"ltx_p\" id=\"S4.T6.1.1.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.1.1.4.1.1.1\" style=\"font-size:80%;\">93.57 \u00b1 0.18%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T6.1.1.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T6.1.1.5.1\">\n<span class=\"ltx_p\" id=\"S4.T6.1.1.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.1.5.1.1.1\" style=\"font-size:80%;\">96.32 \u00b1 0.05</span><span class=\"ltx_text\" id=\"S4.T6.1.1.5.1.1.2\" style=\"font-size:80%;\">%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\" id=\"S4.T6.1.1.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T6.1.1.6.1\">\n<span class=\"ltx_p\" id=\"S4.T6.1.1.6.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.1.1.6.1.1.1\" style=\"font-size:80%;\">94.49 \u00b1 0.26%</span></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T6.5.1.1\" style=\"font-size:113%;\">Table 6</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T6.6.2\" style=\"font-size:113%;\">Mean and standard deviation of the accuracy of the baseline DNN on the RUAR and the Medical datasets. All experiments are replicated five times.</em></figcaption>\n</figure>",
            "capture": "Table 6: Mean and standard deviation of the accuracy of the baseline DNN on the RUAR and the Medical datasets. All experiments are replicated five times."
        },
        "7": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T7\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T7.16\">\n<tr class=\"ltx_tr\" id=\"S4.T7.16.17\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T7.16.17.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.16.17.1.1\">\n<span class=\"ltx_p\" id=\"S4.T7.16.17.1.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.16.17.1.1.1.1\" style=\"font-size:80%;\">Experiment name</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T7.16.17.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.16.17.2.1\">\n<span class=\"ltx_p\" id=\"S4.T7.16.17.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.16.17.2.1.1.1\" style=\"font-size:80%;\">Hyper-rectangles construction method</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T7.16.17.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.16.17.3.1\">\n<span class=\"ltx_p\" id=\"S4.T7.16.17.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.16.17.3.1.1.1\" style=\"font-size:80%;\">Avg. volume of hyper-rectangles RUAR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T7.16.17.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.16.17.4.1\">\n<span class=\"ltx_p\" id=\"S4.T7.16.17.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.16.17.4.1.1.1\" style=\"font-size:80%;\">Number of hyper-rectangles RUAR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T7.16.17.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.16.17.5.1\">\n<span class=\"ltx_p\" id=\"S4.T7.16.17.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.16.17.5.1.1.1\" style=\"font-size:80%;\">Avg. volume of hyper-rectangles Medical</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S4.T7.16.17.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.16.17.6.1\">\n<span class=\"ltx_p\" id=\"S4.T7.16.17.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.16.17.6.1.1.1\" style=\"font-size:80%;\">Number of hyper-rectangles Medical</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.2.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T7.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S4.T7.1.1.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T7.2.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.2.2.2.1\">\n<span class=\"ltx_p\" id=\"S4.T7.2.2.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T7.2.2.2.1.1.1\" style=\"font-size:80%;\">Hyper-rectangle around the entire dataset shrunk to exclude all negative examples - </span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T7.2.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.2.2.3.1\">\n<span class=\"ltx_p\" id=\"S4.T7.2.2.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T7.2.2.3.1.1.1\" style=\"font-size:80%;\">7.55e-11</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T7.2.2.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.2.2.4.1\">\n<span class=\"ltx_p\" id=\"S4.T7.2.2.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T7.2.2.4.1.1.1\" style=\"font-size:80%;\">1</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T7.2.2.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.2.2.5.1\">\n<span class=\"ltx_p\" id=\"S4.T7.2.2.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T7.2.2.5.1.1.1\" style=\"font-size:80%;\">2.60e-09</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S4.T7.2.2.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.2.2.6.1\">\n<span class=\"ltx_p\" id=\"S4.T7.2.2.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T7.2.2.6.1.1.1\" style=\"font-size:80%;\">1</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.4.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.3.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.3.3.1.1\">\n<span class=\"ltx_p\" id=\"S4.T7.3.3.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.4.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.4.4.2.1\">\n<span class=\"ltx_p\" id=\"S4.T7.4.4.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T7.4.4.2.1.1.1\" style=\"font-size:80%;\">Set of hyper-rectangles on the dataset separated into 50 clusters - </span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.4.4.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.4.4.3.1\">\n<span class=\"ltx_p\" id=\"S4.T7.4.4.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T7.4.4.3.1.1.1\" style=\"font-size:80%;\">1.02e-16</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.4.4.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.4.4.4.1\">\n<span class=\"ltx_p\" id=\"S4.T7.4.4.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T7.4.4.4.1.1.1\" style=\"font-size:80%;\">50</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.4.4.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.4.4.5.1\">\n<span class=\"ltx_p\" id=\"S4.T7.4.4.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T7.4.4.5.1.1.1\" style=\"font-size:80%;\">6.56e-15</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T7.4.4.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.4.4.6.1\">\n<span class=\"ltx_p\" id=\"S4.T7.4.4.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T7.4.4.6.1.1.1\" style=\"font-size:80%;\">50</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.6.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.5.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.5.5.1.1\">\n<span class=\"ltx_p\" id=\"S4.T7.5.5.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.6.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.6.6.2.1\">\n<span class=\"ltx_p\" id=\"S4.T7.6.6.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T7.6.6.2.1.1.1\" style=\"font-size:80%;\">Set of hyper-rectangles on the dataset separated into 100 clusters - </span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.6.6.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.6.6.3.1\">\n<span class=\"ltx_p\" id=\"S4.T7.6.6.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T7.6.6.3.1.1.1\" style=\"font-size:80%;\">6.23e-18</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.6.6.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.6.6.4.1\">\n<span class=\"ltx_p\" id=\"S4.T7.6.6.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T7.6.6.4.1.1.1\" style=\"font-size:80%;\">100</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.6.6.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.6.6.5.1\">\n<span class=\"ltx_p\" id=\"S4.T7.6.6.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T7.6.6.5.1.1.1\" style=\"font-size:80%;\">3.25e-17</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T7.6.6.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.6.6.6.1\">\n<span class=\"ltx_p\" id=\"S4.T7.6.6.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T7.6.6.6.1.1.1\" style=\"font-size:80%;\">100</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.8.8\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.7.7.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.7.7.1.1\">\n<span class=\"ltx_p\" id=\"S4.T7.7.7.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.8.8.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.8.8.2.1\">\n<span class=\"ltx_p\" id=\"S4.T7.8.8.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T7.8.8.2.1.1.1\" style=\"font-size:80%;\">Set of hyper-rectangles on the dataset separated into 200 clusters - </span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.8.8.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.8.8.3.1\">\n<span class=\"ltx_p\" id=\"S4.T7.8.8.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T7.8.8.3.1.1.1\" style=\"font-size:80%;\">3.31e-20</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.8.8.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.8.8.4.1\">\n<span class=\"ltx_p\" id=\"S4.T7.8.8.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T7.8.8.4.1.1.1\" style=\"font-size:80%;\">200</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.8.8.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.8.8.5.1\">\n<span class=\"ltx_p\" id=\"S4.T7.8.8.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T7.8.8.5.1.1.1\" style=\"font-size:80%;\">4.67e-19</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T7.8.8.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.8.8.6.1\">\n<span class=\"ltx_p\" id=\"S4.T7.8.8.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T7.8.8.6.1.1.1\" style=\"font-size:80%;\">200</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.10.10\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.9.9.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.9.9.1.1\">\n<span class=\"ltx_p\" id=\"S4.T7.9.9.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.10.10.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.10.10.2.1\">\n<span class=\"ltx_p\" id=\"S4.T7.10.10.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T7.10.10.2.1.1.1\" style=\"font-size:80%;\">Set of hyper-rectangles on the dataset separated into 250 clusters - </span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.10.10.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.10.10.3.1\">\n<span class=\"ltx_p\" id=\"S4.T7.10.10.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T7.10.10.3.1.1.1\" style=\"font-size:80%;\">6.42e-22</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.10.10.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.10.10.4.1\">\n<span class=\"ltx_p\" id=\"S4.T7.10.10.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T7.10.10.4.1.1.1\" style=\"font-size:80%;\">250</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.10.10.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.10.10.5.1\">\n<span class=\"ltx_p\" id=\"S4.T7.10.10.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T7.10.10.5.1.1.1\" style=\"font-size:80%;\">2.42e-20</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T7.10.10.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.10.10.6.1\">\n<span class=\"ltx_p\" id=\"S4.T7.10.10.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T7.10.10.6.1.1.1\" style=\"font-size:80%;\">250</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.13.13\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.11.11.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.11.11.1.1\">\n<span class=\"ltx_p\" id=\"S4.T7.11.11.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.13.13.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.13.13.3.2\">\n<span class=\"ltx_p\" id=\"S4.T7.13.13.3.2.2\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T7.13.13.3.2.2.1\" style=\"font-size:80%;\">Set of </span><span class=\"ltx_text\" id=\"S4.T7.13.13.3.2.2.2\" style=\"font-size:80%;\"> around all positive sentences in the dataset - </span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.13.13.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.13.13.4.1\">\n<span class=\"ltx_p\" id=\"S4.T7.13.13.4.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T7.13.13.4.1.1.1\" style=\"font-size:80%;\">1.00e-30</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.13.13.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.13.13.5.1\">\n<span class=\"ltx_p\" id=\"S4.T7.13.13.5.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T7.13.13.5.1.1.1\" style=\"font-size:80%;\">3400</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T7.13.13.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.13.13.6.1\">\n<span class=\"ltx_p\" id=\"S4.T7.13.13.6.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T7.13.13.6.1.1.1\" style=\"font-size:80%;\">1.00e-30</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T7.13.13.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.13.13.7.1\">\n<span class=\"ltx_p\" id=\"S4.T7.13.13.7.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T7.13.13.7.1.1.1\" style=\"font-size:80%;\">989</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.16.16\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T7.14.14.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.14.14.1.1\">\n<span class=\"ltx_p\" id=\"S4.T7.14.14.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T7.16.16.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.16.16.3.2\">\n<span class=\"ltx_p\" id=\"S4.T7.16.16.3.2.2\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T7.16.16.3.2.2.1\" style=\"font-size:80%;\">Set of </span><span class=\"ltx_text\" id=\"S4.T7.16.16.3.2.2.2\" style=\"font-size:80%;\"> around all positive sentences in the dataset - </span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T7.16.16.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.16.16.4.1\">\n<span class=\"ltx_p\" id=\"S4.T7.16.16.4.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T7.16.16.4.1.1.1\" style=\"font-size:80%;\">1.00e-60</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T7.16.16.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.16.16.5.1\">\n<span class=\"ltx_p\" id=\"S4.T7.16.16.5.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T7.16.16.5.1.1.1\" style=\"font-size:80%;\">3400</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T7.16.16.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.16.16.6.1\">\n<span class=\"ltx_p\" id=\"S4.T7.16.16.6.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T7.16.16.6.1.1.1\" style=\"font-size:80%;\">1.00e-60</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S4.T7.16.16.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T7.16.16.7.1\">\n<span class=\"ltx_p\" id=\"S4.T7.16.16.7.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T7.16.16.7.1.1.1\" style=\"font-size:80%;\">989</span></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T7.20.1.1\" style=\"font-size:113%;\">Table 7</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T7.21.2\" style=\"font-size:113%;\">Sets of geometric subspaces used in the experiments, their cardinality and average volumes of hyper-rectangles.\nAll shapes are eigenspace rotated for better precision.\n</em></figcaption>\n</figure>",
            "capture": "Table 7: Sets of geometric subspaces used in the experiments, their cardinality and average volumes of hyper-rectangles.\nAll shapes are eigenspace rotated for better precision.\n"
        },
        "8": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T8\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T8.9\">\n<tr class=\"ltx_tr\" id=\"S4.T8.7.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T8.7.7.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.7.7.8.1\" style=\"font-size:80%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T8.7.7.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.7.7.9.1\" style=\"font-size:80%;\">Model</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T8.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T8.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T8.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T8.4.4.4\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T8.5.5.5\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T8.6.6.6\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"S4.T8.7.7.7\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_r ltx_border_t\" id=\"S4.T8.8.8.2\"><span class=\"ltx_text\" id=\"S4.T8.8.8.2.1\" style=\"font-size:80%;\">RUAR</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T8.8.8.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T8.8.8.3\"><span class=\"ltx_text\" id=\"S4.T8.8.8.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T8.8.8.4\"><span class=\"ltx_text\" id=\"S4.T8.8.8.4.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T8.8.8.5\"><span class=\"ltx_text\" id=\"S4.T8.8.8.5.1\" style=\"font-size:80%;\">1.33%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T8.8.8.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.8.8.6.1\" style=\"font-size:80%;\">0.52</span><span class=\"ltx_text\" id=\"S4.T8.8.8.6.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T8.8.8.7\"><span class=\"ltx_text\" id=\"S4.T8.8.8.7.1\" style=\"font-size:80%;\">0.41%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T8.8.8.8\"><span class=\"ltx_text\" id=\"S4.T8.8.8.8.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T8.8.8.9\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.8.8.9.1\" style=\"font-size:80%;\">88.67</span><span class=\"ltx_text\" id=\"S4.T8.8.8.9.2\" style=\"font-size:80%;\">%</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T8.9.9.2\"><span class=\"ltx_text\" id=\"S4.T8.9.9.2.1\" style=\"font-size:80%;\">Medical</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T8.9.9.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T8.9.9.3\"><span class=\"ltx_text\" id=\"S4.T8.9.9.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T8.9.9.4\"><span class=\"ltx_text\" id=\"S4.T8.9.9.4.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T8.9.9.5\"><span class=\"ltx_text\" id=\"S4.T8.9.9.5.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T8.9.9.6\"><span class=\"ltx_text\" id=\"S4.T8.9.9.6.1\" style=\"font-size:80%;\">2.10%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T8.9.9.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.9.9.7.1\" style=\"font-size:80%;\">4.08</span><span class=\"ltx_text\" id=\"S4.T8.9.9.7.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T8.9.9.8\"><span class=\"ltx_text\" id=\"S4.T8.9.9.8.1\" style=\"font-size:80%;\">5.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\" id=\"S4.T8.9.9.9\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.9.9.9.1\" style=\"font-size:80%;\">97.86</span><span class=\"ltx_text\" id=\"S4.T8.9.9.9.2\" style=\"font-size:80%;\">%</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T8.13.1.1\" style=\"font-size:113%;\">Table 8</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T8.14.2\" style=\"font-size:113%;\">Verifiability of the baseline DNN on the RUAR and the Medical datasets, for a selection\nof geometric subspaces; using the ERAN verifier.</em></figcaption>\n</figure>",
            "capture": "Table 8: Verifiability of the baseline DNN on the RUAR and the Medical datasets, for a selection\nof geometric subspaces; using the ERAN verifier."
        },
        "9": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T9\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T9.7\">\n<tr class=\"ltx_tr\" id=\"S4.T9.1.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T9.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.1.1.2.1\">\n<span class=\"ltx_p\" id=\"S4.T9.1.1.2.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T9.1.1.2.1.1.1\" style=\"font-size:80%;\">Dataset</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T9.1.1.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.1.1.3.1\">\n<span class=\"ltx_p\" id=\"S4.T9.1.1.3.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T9.1.1.3.1.1.1\" style=\"font-size:80%;\">Experiment</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T9.1.1.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.1.1.4.1\">\n<span class=\"ltx_p\" id=\"S4.T9.1.1.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T9.1.1.4.1.1.1\" style=\"font-size:80%;\">Avg. Volume of hyper-rectangles</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T9.1.1.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.1.1.5.1\">\n<span class=\"ltx_p\" id=\"S4.T9.1.1.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T9.1.1.5.1.1.1\" style=\"font-size:80%;\">Generalisability (%)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T9.1.1.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.1.1.6.1\">\n<span class=\"ltx_p\" id=\"S4.T9.1.1.6.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T9.1.1.6.1.1.1\" style=\"font-size:80%;\">Number of sentences contributing to generalisability</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S4.T9.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S4.T9.1.1.1.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T9.1.1.1.1.1.1\" style=\"font-size:80%;\">Total Sentences in </span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.2.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t\" id=\"S4.T9.2.2.2\" rowspan=\"3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.2.2.2.1\">\n<span class=\"ltx_p\" id=\"S4.T9.2.2.2.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S4.T9.2.2.2.1.1.1\" style=\"font-size:80%;\">RUAR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T9.2.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.2.2.1.1\">\n<span class=\"ltx_p\" id=\"S4.T9.2.2.1.1.1\" style=\"width:52.0pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T9.2.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.2.2.3.1\">\n<span class=\"ltx_p\" id=\"S4.T9.2.2.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.2.2.3.1.1.1\" style=\"font-size:80%;\">1.00e-60</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T9.2.2.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.2.2.4.1\">\n<span class=\"ltx_p\" id=\"S4.T9.2.2.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.2.2.4.1.1.1\" style=\"font-size:80%;\">1.95</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T9.2.2.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.2.2.5.1\">\n<span class=\"ltx_p\" id=\"S4.T9.2.2.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.2.2.5.1.1.1\" style=\"font-size:80%;\">2821</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S4.T9.2.2.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.2.2.6.1\">\n<span class=\"ltx_p\" id=\"S4.T9.2.2.6.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.2.2.6.1.1.1\" style=\"font-size:80%;\">144500</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.3.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T9.3.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.3.3.1.1\">\n<span class=\"ltx_p\" id=\"S4.T9.3.3.1.1.1\" style=\"width:52.0pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T9.3.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.3.3.2.1\">\n<span class=\"ltx_p\" id=\"S4.T9.3.3.2.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.3.3.2.1.1.1\" style=\"font-size:80%;\">1.00e-30</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T9.3.3.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.3.3.3.1\">\n<span class=\"ltx_p\" id=\"S4.T9.3.3.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.3.3.3.1.1.1\" style=\"font-size:80%;\">38.47</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T9.3.3.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.3.3.4.1\">\n<span class=\"ltx_p\" id=\"S4.T9.3.3.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.3.3.4.1.1.1\" style=\"font-size:80%;\">55592</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T9.3.3.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.3.3.5.1\">\n<span class=\"ltx_p\" id=\"S4.T9.3.3.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.3.3.5.1.1.1\" style=\"font-size:80%;\">144500</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.4.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T9.4.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.4.4.1.1\">\n<span class=\"ltx_p\" id=\"S4.T9.4.4.1.1.1\" style=\"width:52.0pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T9.4.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.4.4.2.1\">\n<span class=\"ltx_p\" id=\"S4.T9.4.4.2.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.4.4.2.1.1.1\" style=\"font-size:80%;\">7.55e-11</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T9.4.4.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.4.4.3.1\">\n<span class=\"ltx_p\" id=\"S4.T9.4.4.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.4.4.3.1.1.1\" style=\"font-size:80%;\">50.91</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T9.4.4.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.4.4.4.1\">\n<span class=\"ltx_p\" id=\"S4.T9.4.4.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.4.4.4.1.1.1\" style=\"font-size:80%;\">73561</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T9.4.4.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.4.4.5.1\">\n<span class=\"ltx_p\" id=\"S4.T9.4.4.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.4.4.5.1.1.1\" style=\"font-size:80%;\">144500</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.5.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T9.5.5.2\" rowspan=\"3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.5.5.2.1\">\n<span class=\"ltx_p\" id=\"S4.T9.5.5.2.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S4.T9.5.5.2.1.1.1\" style=\"font-size:80%;\">Medical</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T9.5.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.5.5.1.1\">\n<span class=\"ltx_p\" id=\"S4.T9.5.5.1.1.1\" style=\"width:52.0pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T9.5.5.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.5.5.3.1\">\n<span class=\"ltx_p\" id=\"S4.T9.5.5.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.5.5.3.1.1.1\" style=\"font-size:80%;\">1.00e-60</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T9.5.5.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.5.5.4.1\">\n<span class=\"ltx_p\" id=\"S4.T9.5.5.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.5.5.4.1.1.1\" style=\"font-size:80%;\">0.09</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T9.5.5.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.5.5.5.1\">\n<span class=\"ltx_p\" id=\"S4.T9.5.5.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.5.5.5.1.1.1\" style=\"font-size:80%;\">10</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S4.T9.5.5.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.5.5.6.1\">\n<span class=\"ltx_p\" id=\"S4.T9.5.5.6.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.5.5.6.1.1.1\" style=\"font-size:80%;\">11209</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.6.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T9.6.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.6.6.1.1\">\n<span class=\"ltx_p\" id=\"S4.T9.6.6.1.1.1\" style=\"width:52.0pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T9.6.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.6.6.2.1\">\n<span class=\"ltx_p\" id=\"S4.T9.6.6.2.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.6.6.2.1.1.1\" style=\"font-size:80%;\">1.00e-30</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T9.6.6.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.6.6.3.1\">\n<span class=\"ltx_p\" id=\"S4.T9.6.6.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.6.6.3.1.1.1\" style=\"font-size:80%;\">28.49</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T9.6.6.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.6.6.4.1\">\n<span class=\"ltx_p\" id=\"S4.T9.6.6.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.6.6.4.1.1.1\" style=\"font-size:80%;\">3194</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T9.6.6.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.6.6.5.1\">\n<span class=\"ltx_p\" id=\"S4.T9.6.6.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.6.6.5.1.1.1\" style=\"font-size:80%;\">11209</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.7.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T9.7.7.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.7.7.1.1\">\n<span class=\"ltx_p\" id=\"S4.T9.7.7.1.1.1\" style=\"width:52.0pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T9.7.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.7.7.2.1\">\n<span class=\"ltx_p\" id=\"S4.T9.7.7.2.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.7.7.2.1.1.1\" style=\"font-size:80%;\">2.6e-09</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T9.7.7.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.7.7.3.1\">\n<span class=\"ltx_p\" id=\"S4.T9.7.7.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.7.7.3.1.1.1\" style=\"font-size:80%;\">37.13</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T9.7.7.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.7.7.4.1\">\n<span class=\"ltx_p\" id=\"S4.T9.7.7.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.7.7.4.1.1.1\" style=\"font-size:80%;\">4162</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S4.T9.7.7.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T9.7.7.5.1\">\n<span class=\"ltx_p\" id=\"S4.T9.7.7.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.7.7.5.1.1.1\" style=\"font-size:80%;\">11209</span></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T9.20.6.1\" style=\"font-size:113%;\">Table 9</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T9.17.5\" style=\"font-size:113%;\">Generalisability of the selected geometric subspaces ,  and , measured on the sets of semantic perturbations  and .\n</em></figcaption>\n</figure>",
            "capture": "Table 9: Generalisability of the selected geometric subspaces ,  and , measured on the sets of semantic perturbations  and .\n"
        },
        "10": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T10\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T10.8\">\n<tr class=\"ltx_tr\" id=\"S4.T10.8.9\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T10.8.9.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.8.9.1.1\">\n<span class=\"ltx_p\" id=\"S4.T10.8.9.1.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T10.8.9.1.1.1.1\" style=\"font-size:80%;\">Experiment name</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T10.8.9.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.8.9.2.1\">\n<span class=\"ltx_p\" id=\"S4.T10.8.9.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T10.8.9.2.1.1.1\" style=\"font-size:80%;\">Hyper-rectangles construction method</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T10.8.9.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.8.9.3.1\">\n<span class=\"ltx_p\" id=\"S4.T10.8.9.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T10.8.9.3.1.1.1\" style=\"font-size:80%;\">Avg. volume of hyper-rectangles RUAR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T10.8.9.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.8.9.4.1\">\n<span class=\"ltx_p\" id=\"S4.T10.8.9.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T10.8.9.4.1.1.1\" style=\"font-size:80%;\">Number of hyper-rectangles RUAR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T10.8.9.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.8.9.5.1\">\n<span class=\"ltx_p\" id=\"S4.T10.8.9.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T10.8.9.5.1.1.1\" style=\"font-size:80%;\">Avg. volume of hyper-rectangles Medical</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S4.T10.8.9.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.8.9.6.1\">\n<span class=\"ltx_p\" id=\"S4.T10.8.9.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T10.8.9.6.1.1.1\" style=\"font-size:80%;\">Number of hyper-rectangles Medical</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.1.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T10.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S4.T10.1.1.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T10.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.1.1.2.1\">\n<span class=\"ltx_p\" id=\"S4.T10.1.1.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T10.1.1.2.1.1.1\" style=\"font-size:80%;\">Set of hyper-rectangles for character perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T10.1.1.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.1.1.3.1\">\n<span class=\"ltx_p\" id=\"S4.T10.1.1.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.1.1.3.1.1.1\" style=\"font-size:80%;\">1.54e-30</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T10.1.1.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.1.1.4.1\">\n<span class=\"ltx_p\" id=\"S4.T10.1.1.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.1.1.4.1.1.1\" style=\"font-size:80%;\">3400</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T10.1.1.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.1.1.5.1\">\n<span class=\"ltx_p\" id=\"S4.T10.1.1.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.1.1.5.1.1.1\" style=\"font-size:80%;\">7.66e-31</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S4.T10.1.1.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.1.1.6.1\">\n<span class=\"ltx_p\" id=\"S4.T10.1.1.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.1.1.6.1.1.1\" style=\"font-size:80%;\">989</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.2.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.2.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.2.2.1.1\">\n<span class=\"ltx_p\" id=\"S4.T10.2.2.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.2.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.2.2.2.1\">\n<span class=\"ltx_p\" id=\"S4.T10.2.2.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T10.2.2.2.1.1.1\" style=\"font-size:80%;\">Set of hyper-rectangles for word perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.2.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.2.2.3.1\">\n<span class=\"ltx_p\" id=\"S4.T10.2.2.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.2.2.3.1.1.1\" style=\"font-size:80%;\">1.28e-30</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.2.2.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.2.2.4.1\">\n<span class=\"ltx_p\" id=\"S4.T10.2.2.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.2.2.4.1.1.1\" style=\"font-size:80%;\">3400</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.2.2.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.2.2.5.1\">\n<span class=\"ltx_p\" id=\"S4.T10.2.2.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.2.2.5.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T10.2.2.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.2.2.6.1\">\n<span class=\"ltx_p\" id=\"S4.T10.2.2.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.2.2.6.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.3.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.3.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.3.3.1.1\">\n<span class=\"ltx_p\" id=\"S4.T10.3.3.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.3.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.3.3.2.1\">\n<span class=\"ltx_p\" id=\"S4.T10.3.3.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T10.3.3.2.1.1.1\" style=\"font-size:80%;\">Set of hyper-rectangles for polyjuice sentence perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.3.3.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.3.3.3.1\">\n<span class=\"ltx_p\" id=\"S4.T10.3.3.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.3.3.3.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.3.3.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.3.3.4.1\">\n<span class=\"ltx_p\" id=\"S4.T10.3.3.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.3.3.4.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.3.3.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.3.3.5.1\">\n<span class=\"ltx_p\" id=\"S4.T10.3.3.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.3.3.5.1.1.1\" style=\"font-size:80%;\">2.01e-28</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T10.3.3.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.3.3.6.1\">\n<span class=\"ltx_p\" id=\"S4.T10.3.3.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.3.3.6.1.1.1\" style=\"font-size:80%;\">989</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.4.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.4.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.4.4.1.1\">\n<span class=\"ltx_p\" id=\"S4.T10.4.4.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.4.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.4.4.2.1\">\n<span class=\"ltx_p\" id=\"S4.T10.4.4.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T10.4.4.2.1.1.1\" style=\"font-size:80%;\">Set of hyper-rectangles for swapping perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.4.4.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.4.4.3.1\">\n<span class=\"ltx_p\" id=\"S4.T10.4.4.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.4.4.3.1.1.1\" style=\"font-size:80%;\">1.57e-31</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.4.4.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.4.4.4.1\">\n<span class=\"ltx_p\" id=\"S4.T10.4.4.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.4.4.4.1.1.1\" style=\"font-size:80%;\">3400</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.4.4.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.4.4.5.1\">\n<span class=\"ltx_p\" id=\"S4.T10.4.4.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.4.4.5.1.1.1\" style=\"font-size:80%;\">3.42e-31</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T10.4.4.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.4.4.6.1\">\n<span class=\"ltx_p\" id=\"S4.T10.4.4.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.4.4.6.1.1.1\" style=\"font-size:80%;\">989</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.5.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.5.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.5.5.1.1\">\n<span class=\"ltx_p\" id=\"S4.T10.5.5.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.5.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.5.5.2.1\">\n<span class=\"ltx_p\" id=\"S4.T10.5.5.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T10.5.5.2.1.1.1\" style=\"font-size:80%;\">Set of hyper-rectangles for replacement perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.5.5.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.5.5.3.1\">\n<span class=\"ltx_p\" id=\"S4.T10.5.5.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.5.5.3.1.1.1\" style=\"font-size:80%;\">9.84e-31</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.5.5.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.5.5.4.1\">\n<span class=\"ltx_p\" id=\"S4.T10.5.5.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.5.5.4.1.1.1\" style=\"font-size:80%;\">3400</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.5.5.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.5.5.5.1\">\n<span class=\"ltx_p\" id=\"S4.T10.5.5.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.5.5.5.1.1.1\" style=\"font-size:80%;\">3.43e-31</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T10.5.5.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.5.5.6.1\">\n<span class=\"ltx_p\" id=\"S4.T10.5.5.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.5.5.6.1.1.1\" style=\"font-size:80%;\">989</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.6.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.6.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.6.6.1.1\">\n<span class=\"ltx_p\" id=\"S4.T10.6.6.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.6.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.6.6.2.1\">\n<span class=\"ltx_p\" id=\"S4.T10.6.6.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T10.6.6.2.1.1.1\" style=\"font-size:80%;\">Set of hyper-rectangles for deletion perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.6.6.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.6.6.3.1\">\n<span class=\"ltx_p\" id=\"S4.T10.6.6.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.6.6.3.1.1.1\" style=\"font-size:80%;\">3.46e-31</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.6.6.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.6.6.4.1\">\n<span class=\"ltx_p\" id=\"S4.T10.6.6.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.6.6.4.1.1.1\" style=\"font-size:80%;\">3400</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.6.6.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.6.6.5.1\">\n<span class=\"ltx_p\" id=\"S4.T10.6.6.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.6.6.5.1.1.1\" style=\"font-size:80%;\">1.24e-32</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T10.6.6.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.6.6.6.1\">\n<span class=\"ltx_p\" id=\"S4.T10.6.6.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.6.6.6.1.1.1\" style=\"font-size:80%;\">989</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.7.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.7.7.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.7.7.1.1\">\n<span class=\"ltx_p\" id=\"S4.T10.7.7.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.7.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.7.7.2.1\">\n<span class=\"ltx_p\" id=\"S4.T10.7.7.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T10.7.7.2.1.1.1\" style=\"font-size:80%;\">Set of hyper-rectangles for insertion perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.7.7.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.7.7.3.1\">\n<span class=\"ltx_p\" id=\"S4.T10.7.7.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.7.7.3.1.1.1\" style=\"font-size:80%;\">3.21e-31</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.7.7.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.7.7.4.1\">\n<span class=\"ltx_p\" id=\"S4.T10.7.7.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.7.7.4.1.1.1\" style=\"font-size:80%;\">3400</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T10.7.7.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.7.7.5.1\">\n<span class=\"ltx_p\" id=\"S4.T10.7.7.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.7.7.5.1.1.1\" style=\"font-size:80%;\">9.11e-33</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T10.7.7.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.7.7.6.1\">\n<span class=\"ltx_p\" id=\"S4.T10.7.7.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.7.7.6.1.1.1\" style=\"font-size:80%;\">989</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.8.8\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T10.8.8.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.8.8.1.1\">\n<span class=\"ltx_p\" id=\"S4.T10.8.8.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T10.8.8.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.8.8.2.1\">\n<span class=\"ltx_p\" id=\"S4.T10.8.8.2.1.1\" style=\"width:160.4pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.8.2.1.1.1\" style=\"font-size:80%;\">Set of hyper-rectangles for repetition perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T10.8.8.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.8.8.3.1\">\n<span class=\"ltx_p\" id=\"S4.T10.8.8.3.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.8.3.1.1.1\" style=\"font-size:80%;\">1.56e-31</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T10.8.8.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.8.8.4.1\">\n<span class=\"ltx_p\" id=\"S4.T10.8.8.4.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.8.4.1.1.1\" style=\"font-size:80%;\">3400</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T10.8.8.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.8.8.5.1\">\n<span class=\"ltx_p\" id=\"S4.T10.8.8.5.1.1\" style=\"width:41.2pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.8.5.1.1.1\" style=\"font-size:80%;\">1.06e-32</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S4.T10.8.8.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T10.8.8.6.1\">\n<span class=\"ltx_p\" id=\"S4.T10.8.8.6.1.1\" style=\"width:34.7pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.8.6.1.1.1\" style=\"font-size:80%;\">989</span></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T10.12.1.1\" style=\"font-size:113%;\">Table 10</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T10.13.2\" style=\"font-size:113%;\">Sets of semantic subspaces used in the experiments, their cardinality and average volumes of hyper-rectangles. All shapes are eigenspace rotated for better precision.</em></figcaption>\n</figure>",
            "capture": "Table 10: Sets of semantic subspaces used in the experiments, their cardinality and average volumes of hyper-rectangles. All shapes are eigenspace rotated for better precision."
        },
        "11": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T11\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T11.11\">\n<tr class=\"ltx_tr\" id=\"S4.T11.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T11.9.9.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T11.9.9.10.1\" style=\"font-size:80%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T11.9.9.11\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T11.9.9.11.1\" style=\"font-size:80%;\">Model</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T11.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T11.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T11.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T11.4.4.4\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T11.5.5.5\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T11.6.6.6\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T11.7.7.7\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T11.8.8.8\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"S4.T11.9.9.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.10.10\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_r ltx_border_t\" id=\"S4.T11.10.10.2\"><span class=\"ltx_text\" id=\"S4.T11.10.10.2.1\" style=\"font-size:80%;\">RUAR</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T11.10.10.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T11.10.10.3\"><span class=\"ltx_text\" id=\"S4.T11.10.10.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T11.10.10.4\"><span class=\"ltx_text\" id=\"S4.T11.10.10.4.1\" style=\"font-size:80%;\">1.80%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T11.10.10.5\"><span class=\"ltx_text\" id=\"S4.T11.10.10.5.1\" style=\"font-size:80%;\">0.87%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T11.10.10.6\"><span class=\"ltx_text\" id=\"S4.T11.10.10.6.1\" style=\"font-size:80%;\">1.62%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T11.10.10.7\"><span class=\"ltx_text\" id=\"S4.T11.10.10.7.1\" style=\"font-size:80%;\">2.63%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T11.10.10.8\"><span class=\"ltx_text\" id=\"S4.T11.10.10.8.1\" style=\"font-size:80%;\">1.66%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T11.10.10.9\"><span class=\"ltx_text\" id=\"S4.T11.10.10.9.1\" style=\"font-size:80%;\">0.94%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T11.10.10.10\"><span class=\"ltx_text\" id=\"S4.T11.10.10.10.1\" style=\"font-size:80%;\">2.07%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T11.10.10.11\"><span class=\"ltx_text\" id=\"S4.T11.10.10.11.1\" style=\"font-size:80%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.11.11\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T11.11.11.2\"><span class=\"ltx_text\" id=\"S4.T11.11.11.2.1\" style=\"font-size:80%;\">Medical</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T11.11.11.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T11.11.11.3\"><span class=\"ltx_text\" id=\"S4.T11.11.11.3.1\" style=\"font-size:80%;\">5.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T11.11.11.4\"><span class=\"ltx_text\" id=\"S4.T11.11.11.4.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T11.11.11.5\"><span class=\"ltx_text\" id=\"S4.T11.11.11.5.1\" style=\"font-size:80%;\">39.71%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T11.11.11.6\"><span class=\"ltx_text\" id=\"S4.T11.11.11.6.1\" style=\"font-size:80%;\">39.62%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T11.11.11.7\"><span class=\"ltx_text\" id=\"S4.T11.11.11.7.1\" style=\"font-size:80%;\">44.66%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T11.11.11.8\"><span class=\"ltx_text\" id=\"S4.T11.11.11.8.1\" style=\"font-size:80%;\">48.71%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T11.11.11.9\"><span class=\"ltx_text\" id=\"S4.T11.11.11.9.1\" style=\"font-size:80%;\">37.49%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T11.11.11.10\"><span class=\"ltx_text\" id=\"S4.T11.11.11.10.1\" style=\"font-size:80%;\">42.60%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\" id=\"S4.T11.11.11.11\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T11.11.11.11.1\" style=\"font-size:80%;\">50.09</span><span class=\"ltx_text\" id=\"S4.T11.11.11.11.2\" style=\"font-size:80%;\">%</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T11.15.1.1\" style=\"font-size:113%;\">Table 11</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T11.16.2\" style=\"font-size:113%;\">Verifiability of the baseline DNN on the RUAR and the Medical datasets, for a selection of semantic subspaces; using the ERAN verifier.</em></figcaption>\n</figure>",
            "capture": "Table 11: Verifiability of the baseline DNN on the RUAR and the Medical datasets, for a selection of semantic subspaces; using the ERAN verifier."
        },
        "12": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T12\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T12.11\">\n<tr class=\"ltx_tr\" id=\"S4.T12.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T12.9.9.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T12.9.9.10.1\" style=\"font-size:80%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T12.9.9.11\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T12.9.9.11.1\" style=\"font-size:80%;\">Model</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T12.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T12.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T12.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T12.4.4.4\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T12.5.5.5\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T12.6.6.6\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T12.7.7.7\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T12.8.8.8\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"S4.T12.9.9.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T12.10.10\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_r ltx_border_t\" id=\"S4.T12.10.10.2\"><span class=\"ltx_text\" id=\"S4.T12.10.10.2.1\" style=\"font-size:80%;\">RUAR</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T12.10.10.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T12.10.10.3\"><span class=\"ltx_text\" id=\"S4.T12.10.10.3.1\" style=\"font-size:80%;\">1.79%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T12.10.10.4\"><span class=\"ltx_text\" id=\"S4.T12.10.10.4.1\" style=\"font-size:80%;\">11.69%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T12.10.10.5\"><span class=\"ltx_text\" id=\"S4.T12.10.10.5.1\" style=\"font-size:80%;\">4.88%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T12.10.10.6\"><span class=\"ltx_text\" id=\"S4.T12.10.10.6.1\" style=\"font-size:80%;\">4.35%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T12.10.10.7\"><span class=\"ltx_text\" id=\"S4.T12.10.10.7.1\" style=\"font-size:80%;\">9.72%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T12.10.10.8\"><span class=\"ltx_text\" id=\"S4.T12.10.10.8.1\" style=\"font-size:80%;\">9.46%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T12.10.10.9\"><span class=\"ltx_text\" id=\"S4.T12.10.10.9.1\" style=\"font-size:80%;\">5.65%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T12.10.10.10\"><span class=\"ltx_text\" id=\"S4.T12.10.10.10.1\" style=\"font-size:80%;\">8.07%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T12.10.10.11\"><span class=\"ltx_text\" id=\"S4.T12.10.10.11.1\" style=\"font-size:80%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T12.11.11\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T12.11.11.2\"><span class=\"ltx_text\" id=\"S4.T12.11.11.2.1\" style=\"font-size:80%;\">Medical</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T12.11.11.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T12.11.11.3\"><span class=\"ltx_text\" id=\"S4.T12.11.11.3.1\" style=\"font-size:80%;\">37.96%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T12.11.11.4\"><span class=\"ltx_text\" id=\"S4.T12.11.11.4.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T12.11.11.5\"><span class=\"ltx_text\" id=\"S4.T12.11.11.5.1\" style=\"font-size:80%;\">64.03%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T12.11.11.6\"><span class=\"ltx_text\" id=\"S4.T12.11.11.6.1\" style=\"font-size:80%;\">64.15%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T12.11.11.7\"><span class=\"ltx_text\" id=\"S4.T12.11.11.7.1\" style=\"font-size:80%;\">64.65%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T12.11.11.8\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T12.11.11.8.1\" style=\"font-size:80%;\">66.83</span><span class=\"ltx_text\" id=\"S4.T12.11.11.8.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T12.11.11.9\"><span class=\"ltx_text\" id=\"S4.T12.11.11.9.1\" style=\"font-size:80%;\">64.75%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T12.11.11.10\"><span class=\"ltx_text\" id=\"S4.T12.11.11.10.1\" style=\"font-size:80%;\">64.36%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\" id=\"S4.T12.11.11.11\"><span class=\"ltx_text\" id=\"S4.T12.11.11.11.1\" style=\"font-size:80%;\">61.57%</span></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T12.15.1.1\" style=\"font-size:113%;\">Table 12</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T12.16.2\" style=\"font-size:113%;\">Verifiability of the baseline DNN on the RUAR and the Medical datasets, for a selection of semantic subspaces; using the Marabou verifier.\n</em></figcaption>\n</figure>",
            "capture": "Table 12: Verifiability of the baseline DNN on the RUAR and the Medical datasets, for a selection of semantic subspaces; using the Marabou verifier.\n"
        },
        "13": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T13\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T13.7\">\n<tr class=\"ltx_tr\" id=\"S4.T13.1.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T13.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.1.1.2.1\">\n<span class=\"ltx_p\" id=\"S4.T13.1.1.2.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T13.1.1.2.1.1.1\" style=\"font-size:80%;\">Dataset</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T13.1.1.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.1.1.3.1\">\n<span class=\"ltx_p\" id=\"S4.T13.1.1.3.1.1\" style=\"width:52.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T13.1.1.3.1.1.1\" style=\"font-size:80%;\">Experiment</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T13.1.1.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.1.1.4.1\">\n<span class=\"ltx_p\" id=\"S4.T13.1.1.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T13.1.1.4.1.1.1\" style=\"font-size:80%;\">Avg. Volume of hyper-rectangles</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T13.1.1.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.1.1.5.1\">\n<span class=\"ltx_p\" id=\"S4.T13.1.1.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T13.1.1.5.1.1.1\" style=\"font-size:80%;\">Generalisability (%)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T13.1.1.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.1.1.6.1\">\n<span class=\"ltx_p\" id=\"S4.T13.1.1.6.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T13.1.1.6.1.1.1\" style=\"font-size:80%;\">Number of sentences contributing to generalisability</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S4.T13.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S4.T13.1.1.1.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T13.1.1.1.1.1.1\" style=\"font-size:80%;\">Total Sentences in </span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T13.2.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t\" id=\"S4.T13.2.2.2\" rowspan=\"3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.2.2.2.1\">\n<span class=\"ltx_p\" id=\"S4.T13.2.2.2.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S4.T13.2.2.2.1.1.1\" style=\"font-size:80%;\">RUAR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T13.2.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.2.2.1.1\">\n<span class=\"ltx_p\" id=\"S4.T13.2.2.1.1.1\" style=\"width:52.0pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T13.2.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.2.2.3.1\">\n<span class=\"ltx_p\" id=\"S4.T13.2.2.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.2.2.3.1.1.1\" style=\"font-size:80%;\">1.00e-60</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T13.2.2.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.2.2.4.1\">\n<span class=\"ltx_p\" id=\"S4.T13.2.2.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.2.2.4.1.1.1\" style=\"font-size:80%;\">1.95</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T13.2.2.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.2.2.5.1\">\n<span class=\"ltx_p\" id=\"S4.T13.2.2.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.2.2.5.1.1.1\" style=\"font-size:80%;\">2821</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S4.T13.2.2.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.2.2.6.1\">\n<span class=\"ltx_p\" id=\"S4.T13.2.2.6.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.2.2.6.1.1.1\" style=\"font-size:80%;\">144500</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T13.3.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T13.3.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.3.3.1.1\">\n<span class=\"ltx_p\" id=\"S4.T13.3.3.1.1.1\" style=\"width:52.0pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T13.3.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.3.3.2.1\">\n<span class=\"ltx_p\" id=\"S4.T13.3.3.2.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.3.3.2.1.1.1\" style=\"font-size:80%;\">1.00e-30</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T13.3.3.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.3.3.3.1\">\n<span class=\"ltx_p\" id=\"S4.T13.3.3.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.3.3.3.1.1.1\" style=\"font-size:80%;\">38.47</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T13.3.3.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.3.3.4.1\">\n<span class=\"ltx_p\" id=\"S4.T13.3.3.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.3.3.4.1.1.1\" style=\"font-size:80%;\">55592</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T13.3.3.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.3.3.5.1\">\n<span class=\"ltx_p\" id=\"S4.T13.3.3.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.3.3.5.1.1.1\" style=\"font-size:80%;\">144500</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T13.4.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T13.4.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.4.4.1.1\">\n<span class=\"ltx_p\" id=\"S4.T13.4.4.1.1.1\" style=\"width:52.0pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T13.4.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.4.4.2.1\">\n<span class=\"ltx_p\" id=\"S4.T13.4.4.2.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.4.4.2.1.1.1\" style=\"font-size:80%;\">1.28e-30</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T13.4.4.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.4.4.3.1\">\n<span class=\"ltx_p\" id=\"S4.T13.4.4.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T13.4.4.3.1.1.1\" style=\"font-size:80%;\">47.67</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T13.4.4.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.4.4.4.1\">\n<span class=\"ltx_p\" id=\"S4.T13.4.4.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T13.4.4.4.1.1.1\" style=\"font-size:80%;\">68882</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T13.4.4.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.4.4.5.1\">\n<span class=\"ltx_p\" id=\"S4.T13.4.4.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.4.4.5.1.1.1\" style=\"font-size:80%;\">144500</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T13.5.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T13.5.5.2\" rowspan=\"3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.5.5.2.1\">\n<span class=\"ltx_p\" id=\"S4.T13.5.5.2.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text\" id=\"S4.T13.5.5.2.1.1.1\" style=\"font-size:80%;\">Medical</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T13.5.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.5.5.1.1\">\n<span class=\"ltx_p\" id=\"S4.T13.5.5.1.1.1\" style=\"width:52.0pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T13.5.5.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.5.5.3.1\">\n<span class=\"ltx_p\" id=\"S4.T13.5.5.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.5.5.3.1.1.1\" style=\"font-size:80%;\">1.00e-60</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T13.5.5.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.5.5.4.1\">\n<span class=\"ltx_p\" id=\"S4.T13.5.5.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.5.5.4.1.1.1\" style=\"font-size:80%;\">0.09</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T13.5.5.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.5.5.5.1\">\n<span class=\"ltx_p\" id=\"S4.T13.5.5.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.5.5.5.1.1.1\" style=\"font-size:80%;\">10</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S4.T13.5.5.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.5.5.6.1\">\n<span class=\"ltx_p\" id=\"S4.T13.5.5.6.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.5.5.6.1.1.1\" style=\"font-size:80%;\">11209</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T13.6.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T13.6.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.6.6.1.1\">\n<span class=\"ltx_p\" id=\"S4.T13.6.6.1.1.1\" style=\"width:52.0pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T13.6.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.6.6.2.1\">\n<span class=\"ltx_p\" id=\"S4.T13.6.6.2.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.6.6.2.1.1.1\" style=\"font-size:80%;\">1.00e-30</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T13.6.6.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.6.6.3.1\">\n<span class=\"ltx_p\" id=\"S4.T13.6.6.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.6.6.3.1.1.1\" style=\"font-size:80%;\">28.49</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T13.6.6.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.6.6.4.1\">\n<span class=\"ltx_p\" id=\"S4.T13.6.6.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.6.6.4.1.1.1\" style=\"font-size:80%;\">3194</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T13.6.6.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.6.6.5.1\">\n<span class=\"ltx_p\" id=\"S4.T13.6.6.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.6.6.5.1.1.1\" style=\"font-size:80%;\">11209</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T13.7.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T13.7.7.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.7.7.1.1\">\n<span class=\"ltx_p\" id=\"S4.T13.7.7.1.1.1\" style=\"width:52.0pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T13.7.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.7.7.2.1\">\n<span class=\"ltx_p\" id=\"S4.T13.7.7.2.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.7.7.2.1.1.1\" style=\"font-size:80%;\">2.01e-28</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T13.7.7.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.7.7.3.1\">\n<span class=\"ltx_p\" id=\"S4.T13.7.7.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T13.7.7.3.1.1.1\" style=\"font-size:80%;\">28.74</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T13.7.7.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.7.7.4.1\">\n<span class=\"ltx_p\" id=\"S4.T13.7.7.4.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T13.7.7.4.1.1.1\" style=\"font-size:80%;\">3222</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S4.T13.7.7.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T13.7.7.5.1\">\n<span class=\"ltx_p\" id=\"S4.T13.7.7.5.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S4.T13.7.7.5.1.1.1\" style=\"font-size:80%;\">11209</span></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T13.29.10.1\" style=\"font-size:113%;\">Table 13</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T13.25.9\" style=\"font-size:113%;\">Generalisability of the selected geometric subspaces  and  and the semantic subspaces  and , measured on the sets of semantic perturbations  and .\nNote that the generalisability of  (Table\u00a0<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#S4.T9\" title=\"Table 9 \u2023 4.3.2 Generalisability of Geometric Subspaces \u2023 4.3 Verifiability-Generalisability Trade-off for Geometric Subspaces \u2023 4 Characterisation of Verifiable Subspaces \u2023 NLP Verification: Towards a General Methodology for Certifying Robustness\"><span class=\"ltx_text ltx_ref_tag\">9</span></a>), despite it having the volume 19 order of magnitudes bigger, is only  greater than .</em><span class=\"ltx_text\" id=\"S4.T13.30.11\" style=\"font-size:113%;\">\n</span></figcaption>\n</figure>",
            "capture": "Table 13: Generalisability of the selected geometric subspaces  and  and the semantic subspaces  and , measured on the sets of semantic perturbations  and .\nNote that the generalisability of  (Table\u00a09), despite it having the volume 19 order of magnitudes bigger, is only  greater than .\n"
        },
        "14": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T14\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T14.14\">\n<tr class=\"ltx_tr\" id=\"S4.T14.14.15\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T14.14.15.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.14.15.1.1\">\n<span class=\"ltx_p\" id=\"S4.T14.14.15.1.1.1\" style=\"width:43.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T14.14.15.1.1.1.1\" style=\"font-size:80%;\">Model</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T14.14.15.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.14.15.2.1\">\n<span class=\"ltx_p\" id=\"S4.T14.14.15.2.1.1\" style=\"width:60.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T14.14.15.2.1.1.1\" style=\"font-size:80%;\">Dataset</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T14.14.15.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.14.15.3.1\">\n<span class=\"ltx_p\" id=\"S4.T14.14.15.3.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T14.14.15.3.1.1.1\" style=\"font-size:80%;\">Train Accuracy RUAR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T14.14.15.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.14.15.4.1\">\n<span class=\"ltx_p\" id=\"S4.T14.14.15.4.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T14.14.15.4.1.1.1\" style=\"font-size:80%;\">Test Accuracy RUAR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T14.14.15.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.14.15.5.1\">\n<span class=\"ltx_p\" id=\"S4.T14.14.15.5.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T14.14.15.5.1.1.1\" style=\"font-size:80%;\">Train Accuracy Medical</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S4.T14.14.15.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.14.15.6.1\">\n<span class=\"ltx_p\" id=\"S4.T14.14.15.6.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T14.14.15.6.1.1.1\" style=\"font-size:80%;\">Test Accuracy Medical</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T14.2.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T14.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S4.T14.1.1.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T14.2.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.2.2.2.1\">\n<span class=\"ltx_p\" id=\"S4.T14.2.2.2.1.1\" style=\"width:60.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T14.2.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.2.2.3.1\">\n<span class=\"ltx_p\" id=\"S4.T14.2.2.3.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.2.2.3.1.1.1\" style=\"font-size:80%;\">95.62 \u00b1 0.26%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T14.2.2.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.2.2.4.1\">\n<span class=\"ltx_p\" id=\"S4.T14.2.2.4.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.2.2.4.1.1.1\" style=\"font-size:80%;\">93.20 \u00b1 0.35%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T14.2.2.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.2.2.5.1\">\n<span class=\"ltx_p\" id=\"S4.T14.2.2.5.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.2.2.5.1.1.1\" style=\"font-size:80%;\">99.08 \u00b1 0.06%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S4.T14.2.2.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.2.2.6.1\">\n<span class=\"ltx_p\" id=\"S4.T14.2.2.6.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.2.2.6.1.1.1\" style=\"font-size:80%;\">93.46 \u00b1 0.30%</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T14.4.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.3.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.3.3.1.1\">\n<span class=\"ltx_p\" id=\"S4.T14.3.3.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.4.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.4.4.2.1\">\n<span class=\"ltx_p\" id=\"S4.T14.4.4.2.1.1\" style=\"width:60.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.4.4.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.4.4.3.1\">\n<span class=\"ltx_p\" id=\"S4.T14.4.4.3.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.4.4.3.1.1.1\" style=\"font-size:80%;\">98.57 \u00b1 0.06%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.4.4.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.4.4.4.1\">\n<span class=\"ltx_p\" id=\"S4.T14.4.4.4.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.4.4.4.1.1.1\" style=\"font-size:80%;\">94.59 \u00b1 0.36%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.4.4.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.4.4.5.1\">\n<span class=\"ltx_p\" id=\"S4.T14.4.4.5.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.4.4.5.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T14.4.4.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.4.4.6.1\">\n<span class=\"ltx_p\" id=\"S4.T14.4.4.6.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.4.4.6.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T14.6.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.5.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.5.5.1.1\">\n<span class=\"ltx_p\" id=\"S4.T14.5.5.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.6.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.6.6.2.1\">\n<span class=\"ltx_p\" id=\"S4.T14.6.6.2.1.1\" style=\"width:60.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.6.6.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.6.6.3.1\">\n<span class=\"ltx_p\" id=\"S4.T14.6.6.3.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.6.6.3.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.6.6.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.6.6.4.1\">\n<span class=\"ltx_p\" id=\"S4.T14.6.6.4.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.6.6.4.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.6.6.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.6.6.5.1\">\n<span class=\"ltx_p\" id=\"S4.T14.6.6.5.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.6.6.5.1.1.1\" style=\"font-size:80%;\">98.19 \u00b1 0.09%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T14.6.6.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.6.6.6.1\">\n<span class=\"ltx_p\" id=\"S4.T14.6.6.6.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.6.6.6.1.1.1\" style=\"font-size:80%;\">93.19 \u00b1 0.39%</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T14.8.8\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.7.7.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.7.7.1.1\">\n<span class=\"ltx_p\" id=\"S4.T14.7.7.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.8.8.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.8.8.2.1\">\n<span class=\"ltx_p\" id=\"S4.T14.8.8.2.1.1\" style=\"width:60.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.8.8.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.8.8.3.1\">\n<span class=\"ltx_p\" id=\"S4.T14.8.8.3.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.8.8.3.1.1.1\" style=\"font-size:80%;\">93.26 \u00b1 0.19%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.8.8.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.8.8.4.1\">\n<span class=\"ltx_p\" id=\"S4.T14.8.8.4.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.8.8.4.1.1.1\" style=\"font-size:80%;\">92.51 \u00b1 0.38%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.8.8.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.8.8.5.1\">\n<span class=\"ltx_p\" id=\"S4.T14.8.8.5.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.8.8.5.1.1.1\" style=\"font-size:80%;\">96.27 \u00b1 0.05%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T14.8.8.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.8.8.6.1\">\n<span class=\"ltx_p\" id=\"S4.T14.8.8.6.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.8.8.6.1.1.1\" style=\"font-size:80%;\">95.09 \u00b1 0.16%</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T14.10.10\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.9.9.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.9.9.1.1\">\n<span class=\"ltx_p\" id=\"S4.T14.9.9.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.10.10.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.10.10.2.1\">\n<span class=\"ltx_p\" id=\"S4.T14.10.10.2.1.1\" style=\"width:60.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.10.10.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.10.10.3.1\">\n<span class=\"ltx_p\" id=\"S4.T14.10.10.3.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.10.10.3.1.1.1\" style=\"font-size:80%;\">93.68 \u00b1 0.16%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.10.10.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.10.10.4.1\">\n<span class=\"ltx_p\" id=\"S4.T14.10.10.4.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.10.10.4.1.1.1\" style=\"font-size:80%;\">92.37 \u00b1 0.29%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.10.10.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.10.10.5.1\">\n<span class=\"ltx_p\" id=\"S4.T14.10.10.5.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.10.10.5.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T14.10.10.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.10.10.6.1\">\n<span class=\"ltx_p\" id=\"S4.T14.10.10.6.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.10.10.6.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T14.12.12\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.11.11.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.11.11.1.1\">\n<span class=\"ltx_p\" id=\"S4.T14.11.11.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.12.12.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.12.12.2.1\">\n<span class=\"ltx_p\" id=\"S4.T14.12.12.2.1.1\" style=\"width:60.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.12.12.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.12.12.3.1\">\n<span class=\"ltx_p\" id=\"S4.T14.12.12.3.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.12.12.3.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.12.12.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.12.12.4.1\">\n<span class=\"ltx_p\" id=\"S4.T14.12.12.4.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.12.12.4.1.1.1\" style=\"font-size:80%;\">-</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T14.12.12.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.12.12.5.1\">\n<span class=\"ltx_p\" id=\"S4.T14.12.12.5.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.12.12.5.1.1.1\" style=\"font-size:80%;\">95.05 \u00b1 0.19%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T14.12.12.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.12.12.6.1\">\n<span class=\"ltx_p\" id=\"S4.T14.12.12.6.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.12.12.6.1.1.1\" style=\"font-size:80%;\">93.49 \u00b1 0.32%</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T14.14.14\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T14.13.13.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.13.13.1.1\">\n<span class=\"ltx_p\" id=\"S4.T14.13.13.1.1.1\" style=\"width:43.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T14.14.14.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.14.14.2.1\">\n<span class=\"ltx_p\" id=\"S4.T14.14.14.2.1.1\" style=\"width:60.7pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T14.14.14.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.14.14.3.1\">\n<span class=\"ltx_p\" id=\"S4.T14.14.14.3.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.14.14.3.1.1.1\" style=\"font-size:80%;\">94.01 \u00b1 0.17%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T14.14.14.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.14.14.4.1\">\n<span class=\"ltx_p\" id=\"S4.T14.14.14.4.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.14.14.4.1.1.1\" style=\"font-size:80%;\">92.24 \u00b1 0.19%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T14.14.14.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.14.14.5.1\">\n<span class=\"ltx_p\" id=\"S4.T14.14.14.5.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.14.14.5.1.1.1\" style=\"font-size:80%;\">96.05 \u00b1 0.09%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S4.T14.14.14.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T14.14.14.6.1\">\n<span class=\"ltx_p\" id=\"S4.T14.14.14.6.1.1\" style=\"width:62.9pt;\"><span class=\"ltx_text\" id=\"S4.T14.14.14.6.1.1.1\" style=\"font-size:80%;\">95.04 \u00b1 0.24%</span></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T14.19.2.1\" style=\"font-size:113%;\">Table 14</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T14.16.1\" style=\"font-size:113%;\">Accuracy of the robustly trained DNNs on the RUAR and the Medical datasets.  stands for either RUAR or Medical depending on the column.\n</em></figcaption>\n</figure>",
            "capture": "Table 14: Accuracy of the robustly trained DNNs on the RUAR and the Medical datasets.  stands for either RUAR or Medical depending on the column.\n"
        },
        "15": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T15\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T15.19\">\n<tr class=\"ltx_tr\" id=\"S4.T15.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T15.9.9.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.9.9.10.1\" style=\"font-size:80%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T15.9.9.11\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.9.9.11.1\" style=\"font-size:80%;\">Model</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T15.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T15.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T15.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T15.4.4.4\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T15.5.5.5\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T15.6.6.6\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T15.7.7.7\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T15.8.8.8\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"S4.T15.9.9.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T15.10.10\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_r ltx_border_t\" id=\"S4.T15.10.10.2\" rowspan=\"5\"><span class=\"ltx_text\" id=\"S4.T15.10.10.2.1\" style=\"font-size:80%;\">RUAR</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T15.10.10.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.10.10.3\"><span class=\"ltx_text\" id=\"S4.T15.10.10.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.10.10.4\"><span class=\"ltx_text\" id=\"S4.T15.10.10.4.1\" style=\"font-size:80%;\">0.24%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.10.10.5\"><span class=\"ltx_text\" id=\"S4.T15.10.10.5.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.10.10.6\"><span class=\"ltx_text\" id=\"S4.T15.10.10.6.1\" style=\"font-size:80%;\">0.51%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.10.10.7\"><span class=\"ltx_text\" id=\"S4.T15.10.10.7.1\" style=\"font-size:80%;\">1.38%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.10.10.8\"><span class=\"ltx_text\" id=\"S4.T15.10.10.8.1\" style=\"font-size:80%;\">1.09%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.10.10.9\"><span class=\"ltx_text\" id=\"S4.T15.10.10.9.1\" style=\"font-size:80%;\">0.35%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.10.10.10\"><span class=\"ltx_text\" id=\"S4.T15.10.10.10.1\" style=\"font-size:80%;\">1.06%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T15.10.10.11\"><span class=\"ltx_text\" id=\"S4.T15.10.10.11.1\" style=\"font-size:80%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T15.11.11\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T15.11.11.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.11.11.2\"><span class=\"ltx_text\" id=\"S4.T15.11.11.2.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.11.11.3\"><span class=\"ltx_text\" id=\"S4.T15.11.11.3.1\" style=\"font-size:80%;\">0.24%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.11.11.4\"><span class=\"ltx_text\" id=\"S4.T15.11.11.4.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.11.11.5\"><span class=\"ltx_text\" id=\"S4.T15.11.11.5.1\" style=\"font-size:80%;\">0.42%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.11.11.6\"><span class=\"ltx_text\" id=\"S4.T15.11.11.6.1\" style=\"font-size:80%;\">0.31%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.11.11.7\"><span class=\"ltx_text\" id=\"S4.T15.11.11.7.1\" style=\"font-size:80%;\">0.57%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.11.11.8\"><span class=\"ltx_text\" id=\"S4.T15.11.11.8.1\" style=\"font-size:80%;\">0.25%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.11.11.9\"><span class=\"ltx_text\" id=\"S4.T15.11.11.9.1\" style=\"font-size:80%;\">0.92%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T15.11.11.10\"><span class=\"ltx_text\" id=\"S4.T15.11.11.10.1\" style=\"font-size:80%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T15.12.12\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T15.12.12.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.12.12.2\"><span class=\"ltx_text\" id=\"S4.T15.12.12.2.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.12.12.3\"><span class=\"ltx_text\" id=\"S4.T15.12.12.3.1\" style=\"font-size:80%;\">8.97%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.12.12.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.12.12.4.1\" style=\"font-size:80%;\">4.43</span><span class=\"ltx_text\" id=\"S4.T15.12.12.4.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.12.12.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.12.12.5.1\" style=\"font-size:80%;\">4.81</span><span class=\"ltx_text\" id=\"S4.T15.12.12.5.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.12.12.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.12.12.6.1\" style=\"font-size:80%;\">9.86</span><span class=\"ltx_text\" id=\"S4.T15.12.12.6.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.12.12.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.12.12.7.1\" style=\"font-size:80%;\">11.3</span><span class=\"ltx_text\" id=\"S4.T15.12.12.7.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.12.12.8\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.12.12.8.1\" style=\"font-size:80%;\">6.91</span><span class=\"ltx_text\" id=\"S4.T15.12.12.8.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.12.12.9\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.12.12.9.1\" style=\"font-size:80%;\">8.51</span><span class=\"ltx_text\" id=\"S4.T15.12.12.9.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T15.12.12.10\"><span class=\"ltx_text\" id=\"S4.T15.12.12.10.1\" style=\"font-size:80%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T15.13.13\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T15.13.13.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.13.13.2\"><span class=\"ltx_text\" id=\"S4.T15.13.13.2.1\" style=\"font-size:80%;\">0.04%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.13.13.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.13.13.3.1\" style=\"font-size:80%;\">10.75</span><span class=\"ltx_text\" id=\"S4.T15.13.13.3.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.13.13.4\"><span class=\"ltx_text\" id=\"S4.T15.13.13.4.1\" style=\"font-size:80%;\">4.05%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.13.13.5\"><span class=\"ltx_text\" id=\"S4.T15.13.13.5.1\" style=\"font-size:80%;\">4.36%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.13.13.6\"><span class=\"ltx_text\" id=\"S4.T15.13.13.6.1\" style=\"font-size:80%;\">8.60%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.13.13.7\"><span class=\"ltx_text\" id=\"S4.T15.13.13.7.1\" style=\"font-size:80%;\">9.52%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.13.13.8\"><span class=\"ltx_text\" id=\"S4.T15.13.13.8.1\" style=\"font-size:80%;\">6.81%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.13.13.9\"><span class=\"ltx_text\" id=\"S4.T15.13.13.9.1\" style=\"font-size:80%;\">7.45%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T15.13.13.10\"><span class=\"ltx_text\" id=\"S4.T15.13.13.10.1\" style=\"font-size:80%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T15.14.14\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T15.14.14.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.14.14.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.14.14.2.1\" style=\"font-size:80%;\">0.12</span><span class=\"ltx_text\" id=\"S4.T15.14.14.2.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.14.14.3\"><span class=\"ltx_text\" id=\"S4.T15.14.14.3.1\" style=\"font-size:80%;\">10.16%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.14.14.4\"><span class=\"ltx_text\" id=\"S4.T15.14.14.4.1\" style=\"font-size:80%;\">4.18%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.14.14.5\"><span class=\"ltx_text\" id=\"S4.T15.14.14.5.1\" style=\"font-size:80%;\">4.04%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.14.14.6\"><span class=\"ltx_text\" id=\"S4.T15.14.14.6.1\" style=\"font-size:80%;\">8.91%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.14.14.7\"><span class=\"ltx_text\" id=\"S4.T15.14.14.7.1\" style=\"font-size:80%;\">10.17%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.14.14.8\"><span class=\"ltx_text\" id=\"S4.T15.14.14.8.1\" style=\"font-size:80%;\">6.52%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.14.14.9\"><span class=\"ltx_text\" id=\"S4.T15.14.14.9.1\" style=\"font-size:80%;\">7.36%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T15.14.14.10\"><span class=\"ltx_text\" id=\"S4.T15.14.14.10.1\" style=\"font-size:80%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T15.15.15\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T15.15.15.2\" rowspan=\"5\"><span class=\"ltx_text\" id=\"S4.T15.15.15.2.1\" style=\"font-size:80%;\">Medical</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T15.15.15.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.15.15.3\"><span class=\"ltx_text\" id=\"S4.T15.15.15.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.15.15.4\"><span class=\"ltx_text\" id=\"S4.T15.15.15.4.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.15.15.5\"><span class=\"ltx_text\" id=\"S4.T15.15.15.5.1\" style=\"font-size:80%;\">7.59%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.15.15.6\"><span class=\"ltx_text\" id=\"S4.T15.15.15.6.1\" style=\"font-size:80%;\">5.28%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.15.15.7\"><span class=\"ltx_text\" id=\"S4.T15.15.15.7.1\" style=\"font-size:80%;\">12.84%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.15.15.8\"><span class=\"ltx_text\" id=\"S4.T15.15.15.8.1\" style=\"font-size:80%;\">11.05%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.15.15.9\"><span class=\"ltx_text\" id=\"S4.T15.15.15.9.1\" style=\"font-size:80%;\">7.92%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T15.15.15.10\"><span class=\"ltx_text\" id=\"S4.T15.15.15.10.1\" style=\"font-size:80%;\">7.40%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T15.15.15.11\"><span class=\"ltx_text\" id=\"S4.T15.15.15.11.1\" style=\"font-size:80%;\">26.97%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T15.16.16\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T15.16.16.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.16.16.2\"><span class=\"ltx_text\" id=\"S4.T15.16.16.2.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.16.16.3\"><span class=\"ltx_text\" id=\"S4.T15.16.16.3.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.16.16.4\"><span class=\"ltx_text\" id=\"S4.T15.16.16.4.1\" style=\"font-size:80%;\">10.31%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.16.16.5\"><span class=\"ltx_text\" id=\"S4.T15.16.16.5.1\" style=\"font-size:80%;\">8.49%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.16.16.6\"><span class=\"ltx_text\" id=\"S4.T15.16.16.6.1\" style=\"font-size:80%;\">15.67%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.16.16.7\"><span class=\"ltx_text\" id=\"S4.T15.16.16.7.1\" style=\"font-size:80%;\">14.90%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.16.16.8\"><span class=\"ltx_text\" id=\"S4.T15.16.16.8.1\" style=\"font-size:80%;\">9.18%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.16.16.9\"><span class=\"ltx_text\" id=\"S4.T15.16.16.9.1\" style=\"font-size:80%;\">10.58%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T15.16.16.10\"><span class=\"ltx_text\" id=\"S4.T15.16.16.10.1\" style=\"font-size:80%;\">28.59%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T15.17.17\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T15.17.17.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.17.17.2\"><span class=\"ltx_text\" id=\"S4.T15.17.17.2.1\" style=\"font-size:80%;\">5.28%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.17.17.3\"><span class=\"ltx_text\" id=\"S4.T15.17.17.3.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.17.17.4\"><span class=\"ltx_text\" id=\"S4.T15.17.17.4.1\" style=\"font-size:80%;\">50.12%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.17.17.5\"><span class=\"ltx_text\" id=\"S4.T15.17.17.5.1\" style=\"font-size:80%;\">49.78%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.17.17.6\"><span class=\"ltx_text\" id=\"S4.T15.17.17.6.1\" style=\"font-size:80%;\">53.99%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.17.17.7\"><span class=\"ltx_text\" id=\"S4.T15.17.17.7.1\" style=\"font-size:80%;\">57.76%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.17.17.8\"><span class=\"ltx_text\" id=\"S4.T15.17.17.8.1\" style=\"font-size:80%;\">48.02%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.17.17.9\"><span class=\"ltx_text\" id=\"S4.T15.17.17.9.1\" style=\"font-size:80%;\">52.07%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T15.17.17.10\"><span class=\"ltx_text\" id=\"S4.T15.17.17.10.1\" style=\"font-size:80%;\">55.44%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T15.18.18\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T15.18.18.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.18.18.2\"><span class=\"ltx_text\" id=\"S4.T15.18.18.2.1\" style=\"font-size:80%;\">2.83%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.18.18.3\"><span class=\"ltx_text\" id=\"S4.T15.18.18.3.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.18.18.4\"><span class=\"ltx_text\" id=\"S4.T15.18.18.4.1\" style=\"font-size:80%;\">47.11%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.18.18.5\"><span class=\"ltx_text\" id=\"S4.T15.18.18.5.1\" style=\"font-size:80%;\">46.14%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.18.18.6\"><span class=\"ltx_text\" id=\"S4.T15.18.18.6.1\" style=\"font-size:80%;\">52.12%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.18.18.7\"><span class=\"ltx_text\" id=\"S4.T15.18.18.7.1\" style=\"font-size:80%;\">56.14%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.18.18.8\"><span class=\"ltx_text\" id=\"S4.T15.18.18.8.1\" style=\"font-size:80%;\">44.59%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T15.18.18.9\"><span class=\"ltx_text\" id=\"S4.T15.18.18.9.1\" style=\"font-size:80%;\">48.27%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T15.18.18.10\"><span class=\"ltx_text\" id=\"S4.T15.18.18.10.1\" style=\"font-size:80%;\">57.36%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T15.19.19\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"S4.T15.19.19.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T15.19.19.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.19.19.2.1\" style=\"font-size:80%;\">8.68</span><span class=\"ltx_text\" id=\"S4.T15.19.19.2.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T15.19.19.3\"><span class=\"ltx_text\" id=\"S4.T15.19.19.3.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T15.19.19.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.19.19.4.1\" style=\"font-size:80%;\">51.60</span><span class=\"ltx_text\" id=\"S4.T15.19.19.4.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T15.19.19.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.19.19.5.1\" style=\"font-size:80%;\">50.31</span><span class=\"ltx_text\" id=\"S4.T15.19.19.5.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T15.19.19.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.19.19.6.1\" style=\"font-size:80%;\">55.67</span><span class=\"ltx_text\" id=\"S4.T15.19.19.6.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T15.19.19.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.19.19.7.1\" style=\"font-size:80%;\">58.52</span><span class=\"ltx_text\" id=\"S4.T15.19.19.7.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T15.19.19.8\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.19.19.8.1\" style=\"font-size:80%;\">50.10</span><span class=\"ltx_text\" id=\"S4.T15.19.19.8.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T15.19.19.9\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.19.19.9.1\" style=\"font-size:80%;\">53.65</span><span class=\"ltx_text\" id=\"S4.T15.19.19.9.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T15.19.19.10\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T15.19.19.10.1\" style=\"font-size:80%;\">59.76</span><span class=\"ltx_text\" id=\"S4.T15.19.19.10.2\" style=\"font-size:80%;\">%</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T15.23.1.1\" style=\"font-size:113%;\">Table 15</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T15.24.2\" style=\"font-size:113%;\">Verifiability of the robustly trained DNNs on the RUAR and the Medical datasets, for a selection of semantic subspaces; using the ERAN verifier.\n</em></figcaption>\n</figure>",
            "capture": "Table 15: Verifiability of the robustly trained DNNs on the RUAR and the Medical datasets, for a selection of semantic subspaces; using the ERAN verifier.\n"
        },
        "16": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T16\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T16.19\">\n<tr class=\"ltx_tr\" id=\"S4.T16.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T16.9.9.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.9.9.10.1\" style=\"font-size:80%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T16.9.9.11\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.9.9.11.1\" style=\"font-size:80%;\">Model</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T16.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T16.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T16.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T16.4.4.4\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T16.5.5.5\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T16.6.6.6\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T16.7.7.7\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T16.8.8.8\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"S4.T16.9.9.9\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T16.10.10\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_r ltx_border_t\" id=\"S4.T16.10.10.2\" rowspan=\"5\"><span class=\"ltx_text\" id=\"S4.T16.10.10.2.1\" style=\"font-size:80%;\">RUAR</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T16.10.10.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.10.10.3\"><span class=\"ltx_text\" id=\"S4.T16.10.10.3.1\" style=\"font-size:80%;\">0.72%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.10.10.4\"><span class=\"ltx_text\" id=\"S4.T16.10.10.4.1\" style=\"font-size:80%;\">13.90%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.10.10.5\"><span class=\"ltx_text\" id=\"S4.T16.10.10.5.1\" style=\"font-size:80%;\">8.49%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.10.10.6\"><span class=\"ltx_text\" id=\"S4.T16.10.10.6.1\" style=\"font-size:80%;\">7.92%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.10.10.7\"><span class=\"ltx_text\" id=\"S4.T16.10.10.7.1\" style=\"font-size:80%;\">13.67%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.10.10.8\"><span class=\"ltx_text\" id=\"S4.T16.10.10.8.1\" style=\"font-size:80%;\">15.50%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.10.10.9\"><span class=\"ltx_text\" id=\"S4.T16.10.10.9.1\" style=\"font-size:80%;\">9.56%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.10.10.10\"><span class=\"ltx_text\" id=\"S4.T16.10.10.10.1\" style=\"font-size:80%;\">11.88%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T16.10.10.11\"><span class=\"ltx_text\" id=\"S4.T16.10.10.11.1\" style=\"font-size:80%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T16.11.11\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T16.11.11.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.11.11.2\"><span class=\"ltx_text\" id=\"S4.T16.11.11.2.1\" style=\"font-size:80%;\">0.24%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.11.11.3\"><span class=\"ltx_text\" id=\"S4.T16.11.11.3.1\" style=\"font-size:80%;\">11.30%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.11.11.4\"><span class=\"ltx_text\" id=\"S4.T16.11.11.4.1\" style=\"font-size:80%;\">3.87%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.11.11.5\"><span class=\"ltx_text\" id=\"S4.T16.11.11.5.1\" style=\"font-size:80%;\">4.05%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.11.11.6\"><span class=\"ltx_text\" id=\"S4.T16.11.11.6.1\" style=\"font-size:80%;\">8.27%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.11.11.7\"><span class=\"ltx_text\" id=\"S4.T16.11.11.7.1\" style=\"font-size:80%;\">8.84%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.11.11.8\"><span class=\"ltx_text\" id=\"S4.T16.11.11.8.1\" style=\"font-size:80%;\">5.71%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.11.11.9\"><span class=\"ltx_text\" id=\"S4.T16.11.11.9.1\" style=\"font-size:80%;\">7.72%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T16.11.11.10\"><span class=\"ltx_text\" id=\"S4.T16.11.11.10.1\" style=\"font-size:80%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T16.12.12\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T16.12.12.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.12.12.2\"><span class=\"ltx_text\" id=\"S4.T16.12.12.2.1\" style=\"font-size:80%;\">7.37%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.12.12.3\"><span class=\"ltx_text\" id=\"S4.T16.12.12.3.1\" style=\"font-size:80%;\">41.93%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.12.12.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.12.12.4.1\" style=\"font-size:80%;\">30.41</span><span class=\"ltx_text\" id=\"S4.T16.12.12.4.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.12.12.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.12.12.5.1\" style=\"font-size:80%;\">30.23</span><span class=\"ltx_text\" id=\"S4.T16.12.12.5.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.12.12.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.12.12.6.1\" style=\"font-size:80%;\">38.20</span><span class=\"ltx_text\" id=\"S4.T16.12.12.6.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.12.12.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.12.12.7.1\" style=\"font-size:80%;\">45.87</span><span class=\"ltx_text\" id=\"S4.T16.12.12.7.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.12.12.8\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.12.12.8.1\" style=\"font-size:80%;\">32.74</span><span class=\"ltx_text\" id=\"S4.T16.12.12.8.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.12.12.9\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.12.12.9.1\" style=\"font-size:80%;\">36.62</span><span class=\"ltx_text\" id=\"S4.T16.12.12.9.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T16.12.12.10\"><span class=\"ltx_text\" id=\"S4.T16.12.12.10.1\" style=\"font-size:80%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T16.13.13\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T16.13.13.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.13.13.2\"><span class=\"ltx_text\" id=\"S4.T16.13.13.2.1\" style=\"font-size:80%;\">12.17%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.13.13.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.13.13.3.1\" style=\"font-size:80%;\">45.12</span><span class=\"ltx_text\" id=\"S4.T16.13.13.3.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.13.13.4\"><span class=\"ltx_text\" id=\"S4.T16.13.13.4.1\" style=\"font-size:80%;\">25.82%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.13.13.5\"><span class=\"ltx_text\" id=\"S4.T16.13.13.5.1\" style=\"font-size:80%;\">25.39%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.13.13.6\"><span class=\"ltx_text\" id=\"S4.T16.13.13.6.1\" style=\"font-size:80%;\">33.85%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.13.13.7\"><span class=\"ltx_text\" id=\"S4.T16.13.13.7.1\" style=\"font-size:80%;\">37.45%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.13.13.8\"><span class=\"ltx_text\" id=\"S4.T16.13.13.8.1\" style=\"font-size:80%;\">26.87%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.13.13.9\"><span class=\"ltx_text\" id=\"S4.T16.13.13.9.1\" style=\"font-size:80%;\">30.99%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T16.13.13.10\"><span class=\"ltx_text\" id=\"S4.T16.13.13.10.1\" style=\"font-size:80%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T16.14.14\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T16.14.14.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.14.14.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.14.14.2.1\" style=\"font-size:80%;\">18.46</span><span class=\"ltx_text\" id=\"S4.T16.14.14.2.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.14.14.3\"><span class=\"ltx_text\" id=\"S4.T16.14.14.3.1\" style=\"font-size:80%;\">41.93%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.14.14.4\"><span class=\"ltx_text\" id=\"S4.T16.14.14.4.1\" style=\"font-size:80%;\">21.99%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.14.14.5\"><span class=\"ltx_text\" id=\"S4.T16.14.14.5.1\" style=\"font-size:80%;\">20.32%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.14.14.6\"><span class=\"ltx_text\" id=\"S4.T16.14.14.6.1\" style=\"font-size:80%;\">28.13%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.14.14.7\"><span class=\"ltx_text\" id=\"S4.T16.14.14.7.1\" style=\"font-size:80%;\">32.83%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.14.14.8\"><span class=\"ltx_text\" id=\"S4.T16.14.14.8.1\" style=\"font-size:80%;\">23.52%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.14.14.9\"><span class=\"ltx_text\" id=\"S4.T16.14.14.9.1\" style=\"font-size:80%;\">26.74%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T16.14.14.10\"><span class=\"ltx_text\" id=\"S4.T16.14.14.10.1\" style=\"font-size:80%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T16.15.15\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T16.15.15.2\" rowspan=\"5\"><span class=\"ltx_text\" id=\"S4.T16.15.15.2.1\" style=\"font-size:80%;\">Medical</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T16.15.15.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.15.15.3\"><span class=\"ltx_text\" id=\"S4.T16.15.15.3.1\" style=\"font-size:80%;\">1.14%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.15.15.4\"><span class=\"ltx_text\" id=\"S4.T16.15.15.4.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.15.15.5\"><span class=\"ltx_text\" id=\"S4.T16.15.15.5.1\" style=\"font-size:80%;\">37.05%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.15.15.6\"><span class=\"ltx_text\" id=\"S4.T16.15.15.6.1\" style=\"font-size:80%;\">35.29%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.15.15.7\"><span class=\"ltx_text\" id=\"S4.T16.15.15.7.1\" style=\"font-size:80%;\">41.50%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.15.15.8\"><span class=\"ltx_text\" id=\"S4.T16.15.15.8.1\" style=\"font-size:80%;\">42.47%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.15.15.9\"><span class=\"ltx_text\" id=\"S4.T16.15.15.9.1\" style=\"font-size:80%;\">34.89%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T16.15.15.10\"><span class=\"ltx_text\" id=\"S4.T16.15.15.10.1\" style=\"font-size:80%;\">37.94%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T16.15.15.11\"><span class=\"ltx_text\" id=\"S4.T16.15.15.11.1\" style=\"font-size:80%;\">49.65%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T16.16.16\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T16.16.16.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.16.16.2\"><span class=\"ltx_text\" id=\"S4.T16.16.16.2.1\" style=\"font-size:80%;\">5.77%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.16.16.3\"><span class=\"ltx_text\" id=\"S4.T16.16.16.3.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.16.16.4\"><span class=\"ltx_text\" id=\"S4.T16.16.16.4.1\" style=\"font-size:80%;\">39.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.16.16.5\"><span class=\"ltx_text\" id=\"S4.T16.16.16.5.1\" style=\"font-size:80%;\">38.66%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.16.16.6\"><span class=\"ltx_text\" id=\"S4.T16.16.16.6.1\" style=\"font-size:80%;\">42.28%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.16.16.7\"><span class=\"ltx_text\" id=\"S4.T16.16.16.7.1\" style=\"font-size:80%;\">44.22%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.16.16.8\"><span class=\"ltx_text\" id=\"S4.T16.16.16.8.1\" style=\"font-size:80%;\">37.29%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.16.16.9\"><span class=\"ltx_text\" id=\"S4.T16.16.16.9.1\" style=\"font-size:80%;\">39.03%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T16.16.16.10\"><span class=\"ltx_text\" id=\"S4.T16.16.16.10.1\" style=\"font-size:80%;\">38.22%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T16.17.17\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T16.17.17.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.17.17.2\"><span class=\"ltx_text\" id=\"S4.T16.17.17.2.1\" style=\"font-size:80%;\">51.70%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.17.17.3\"><span class=\"ltx_text\" id=\"S4.T16.17.17.3.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.17.17.4\"><span class=\"ltx_text\" id=\"S4.T16.17.17.4.1\" style=\"font-size:80%;\">77.59%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.17.17.5\"><span class=\"ltx_text\" id=\"S4.T16.17.17.5.1\" style=\"font-size:80%;\">77.25%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.17.17.6\"><span class=\"ltx_text\" id=\"S4.T16.17.17.6.1\" style=\"font-size:80%;\">77.50%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.17.17.7\"><span class=\"ltx_text\" id=\"S4.T16.17.17.7.1\" style=\"font-size:80%;\">77.98%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.17.17.8\"><span class=\"ltx_text\" id=\"S4.T16.17.17.8.1\" style=\"font-size:80%;\">77.92%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.17.17.9\"><span class=\"ltx_text\" id=\"S4.T16.17.17.9.1\" style=\"font-size:80%;\">78.67%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T16.17.17.10\"><span class=\"ltx_text\" id=\"S4.T16.17.17.10.1\" style=\"font-size:80%;\">76.58%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T16.18.18\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T16.18.18.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.18.18.2\"><span class=\"ltx_text\" id=\"S4.T16.18.18.2.1\" style=\"font-size:80%;\">57.45%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.18.18.3\"><span class=\"ltx_text\" id=\"S4.T16.18.18.3.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.18.18.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.18.18.4.1\" style=\"font-size:80%;\">81.94</span><span class=\"ltx_text\" id=\"S4.T16.18.18.4.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.18.18.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.18.18.5.1\" style=\"font-size:80%;\">81.47</span><span class=\"ltx_text\" id=\"S4.T16.18.18.5.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.18.18.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.18.18.6.1\" style=\"font-size:80%;\">82.31</span><span class=\"ltx_text\" id=\"S4.T16.18.18.6.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.18.18.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.18.18.7.1\" style=\"font-size:80%;\">83.48</span><span class=\"ltx_text\" id=\"S4.T16.18.18.7.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.18.18.8\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.18.18.8.1\" style=\"font-size:80%;\">82.47</span><span class=\"ltx_text\" id=\"S4.T16.18.18.8.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T16.18.18.9\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.18.18.9.1\" style=\"font-size:80%;\">82.72</span><span class=\"ltx_text\" id=\"S4.T16.18.18.9.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T16.18.18.10\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.18.18.10.1\" style=\"font-size:80%;\">82.24</span><span class=\"ltx_text\" id=\"S4.T16.18.18.10.2\" style=\"font-size:80%;\">%</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T16.19.19\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"S4.T16.19.19.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T16.19.19.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T16.19.19.2.1\" style=\"font-size:80%;\">62.57</span><span class=\"ltx_text\" id=\"S4.T16.19.19.2.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T16.19.19.3\"><span class=\"ltx_text\" id=\"S4.T16.19.19.3.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T16.19.19.4\"><span class=\"ltx_text\" id=\"S4.T16.19.19.4.1\" style=\"font-size:80%;\">79.32%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T16.19.19.5\"><span class=\"ltx_text\" id=\"S4.T16.19.19.5.1\" style=\"font-size:80%;\">78.57%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T16.19.19.6\"><span class=\"ltx_text\" id=\"S4.T16.19.19.6.1\" style=\"font-size:80%;\">78.70%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T16.19.19.7\"><span class=\"ltx_text\" id=\"S4.T16.19.19.7.1\" style=\"font-size:80%;\">80.21%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T16.19.19.8\"><span class=\"ltx_text\" id=\"S4.T16.19.19.8.1\" style=\"font-size:80%;\">79.40%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T16.19.19.9\"><span class=\"ltx_text\" id=\"S4.T16.19.19.9.1\" style=\"font-size:80%;\">80.76%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T16.19.19.10\"><span class=\"ltx_text\" id=\"S4.T16.19.19.10.1\" style=\"font-size:80%;\">66.22%</span></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T16.23.1.1\" style=\"font-size:113%;\">Table 16</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T16.24.2\" style=\"font-size:113%;\">Verifiability of the DNNs trained for robustness on the RUAR and the Medical datasets, for a selection of semantic subspaces; using the Marabou verifier.\n</em></figcaption>\n</figure>",
            "capture": "Table 16: Verifiability of the DNNs trained for robustness on the RUAR and the Medical datasets, for a selection of semantic subspaces; using the Marabou verifier.\n"
        },
        "17": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T17\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T17.6\">\n<tr class=\"ltx_tr\" id=\"S4.T17.6.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T17.6.7.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.6.7.1.1\">\n<span class=\"ltx_p\" id=\"S4.T17.6.7.1.1.1\" style=\"width:56.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T17.6.7.1.1.1.1\" style=\"font-size:80%;\">Model</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T17.6.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.6.7.2.1\">\n<span class=\"ltx_p\" id=\"S4.T17.6.7.2.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T17.6.7.2.1.1.1\" style=\"font-size:80%;\">Train Accuracy RUAR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T17.6.7.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.6.7.3.1\">\n<span class=\"ltx_p\" id=\"S4.T17.6.7.3.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T17.6.7.3.1.1.1\" style=\"font-size:80%;\">Test Accuracy RUAR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S4.T17.6.7.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.6.7.4.1\">\n<span class=\"ltx_p\" id=\"S4.T17.6.7.4.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T17.6.7.4.1.1.1\" style=\"font-size:80%;\">Train Accuracy Medical</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S4.T17.6.7.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.6.7.5.1\">\n<span class=\"ltx_p\" id=\"S4.T17.6.7.5.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T17.6.7.5.1.1.1\" style=\"font-size:80%;\">Test Accuracy Medical</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T17.1.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T17.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S4.T17.1.1.1.1.1\" style=\"width:56.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T17.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.1.1.2.1\">\n<span class=\"ltx_p\" id=\"S4.T17.1.1.2.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.1.1.2.1.1.1\" style=\"font-size:80%;\">93.39 \u00b1 0.22%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T17.1.1.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.1.1.3.1\">\n<span class=\"ltx_p\" id=\"S4.T17.1.1.3.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.1.1.3.1.1.1\" style=\"font-size:80%;\">92.96 \u00b1 0.13%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T17.1.1.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.1.1.4.1\">\n<span class=\"ltx_p\" id=\"S4.T17.1.1.4.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.1.1.4.1.1.1\" style=\"font-size:80%;\">96.14 \u00b1 0.12%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S4.T17.1.1.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.1.1.5.1\">\n<span class=\"ltx_p\" id=\"S4.T17.1.1.5.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.1.1.5.1.1.1\" style=\"font-size:80%;\">94.29 \u00b1 0.26%</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T17.2.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.2.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.2.2.1.1\">\n<span class=\"ltx_p\" id=\"S4.T17.2.2.1.1.1\" style=\"width:56.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.2.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.2.2.2.1\">\n<span class=\"ltx_p\" id=\"S4.T17.2.2.2.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.2.2.2.1.1.1\" style=\"font-size:80%;\">94.32 \u00b1 0.14%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.2.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.2.2.3.1\">\n<span class=\"ltx_p\" id=\"S4.T17.2.2.3.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.2.2.3.1.1.1\" style=\"font-size:80%;\">93.49 \u00b1 0.19%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.2.2.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.2.2.4.1\">\n<span class=\"ltx_p\" id=\"S4.T17.2.2.4.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.2.2.4.1.1.1\" style=\"font-size:80%;\">95.56 \u00b1 0.20%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T17.2.2.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.2.2.5.1\">\n<span class=\"ltx_p\" id=\"S4.T17.2.2.5.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.2.2.5.1.1.1\" style=\"font-size:80%;\">95.15 \u00b1 0.12%</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T17.3.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.3.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.3.3.1.1\">\n<span class=\"ltx_p\" id=\"S4.T17.3.3.1.1.1\" style=\"width:56.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.3.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.3.3.2.1\">\n<span class=\"ltx_p\" id=\"S4.T17.3.3.2.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.3.3.2.1.1.1\" style=\"font-size:80%;\">94.88 \u00b1 0.04%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.3.3.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.3.3.3.1\">\n<span class=\"ltx_p\" id=\"S4.T17.3.3.3.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.3.3.3.1.1.1\" style=\"font-size:80%;\">94.18 \u00b1 0.24%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.3.3.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.3.3.4.1\">\n<span class=\"ltx_p\" id=\"S4.T17.3.3.4.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.3.3.4.1.1.1\" style=\"font-size:80%;\">95.71 \u00b1 0.11%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T17.3.3.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.3.3.5.1\">\n<span class=\"ltx_p\" id=\"S4.T17.3.3.5.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T17.3.3.5.1.1.1\" style=\"font-size:80%;\">95.47 \u00b1 0.16</span><span class=\"ltx_text\" id=\"S4.T17.3.3.5.1.1.2\" style=\"font-size:80%;\">%</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T17.4.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.4.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.4.4.1.1\">\n<span class=\"ltx_p\" id=\"S4.T17.4.4.1.1.1\" style=\"width:56.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.4.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.4.4.2.1\">\n<span class=\"ltx_p\" id=\"S4.T17.4.4.2.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.4.4.2.1.1.1\" style=\"font-size:80%;\">95.09 \u00b1 0.09%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.4.4.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.4.4.3.1\">\n<span class=\"ltx_p\" id=\"S4.T17.4.4.3.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T17.4.4.3.1.1.1\" style=\"font-size:80%;\">94.45 \u00b1 0.14</span><span class=\"ltx_text\" id=\"S4.T17.4.4.3.1.1.2\" style=\"font-size:80%;\">%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.4.4.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.4.4.4.1\">\n<span class=\"ltx_p\" id=\"S4.T17.4.4.4.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.4.4.4.1.1.1\" style=\"font-size:80%;\">95.85 \u00b1 0.05%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T17.4.4.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.4.4.5.1\">\n<span class=\"ltx_p\" id=\"S4.T17.4.4.5.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.4.4.5.1.1.1\" style=\"font-size:80%;\">95.43 \u00b1 0.10%</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T17.5.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.5.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.5.5.1.1\">\n<span class=\"ltx_p\" id=\"S4.T17.5.5.1.1.1\" style=\"width:56.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.5.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.5.5.2.1\">\n<span class=\"ltx_p\" id=\"S4.T17.5.5.2.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T17.5.5.2.1.1.1\" style=\"font-size:80%;\">95.22 \u00b1 0.08</span><span class=\"ltx_text\" id=\"S4.T17.5.5.2.1.1.2\" style=\"font-size:80%;\">%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.5.5.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.5.5.3.1\">\n<span class=\"ltx_p\" id=\"S4.T17.5.5.3.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.5.5.3.1.1.1\" style=\"font-size:80%;\">94.22 \u00b1 0.23%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S4.T17.5.5.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.5.5.4.1\">\n<span class=\"ltx_p\" id=\"S4.T17.5.5.4.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.5.5.4.1.1.1\" style=\"font-size:80%;\">96.07 \u00b1 0.13%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T17.5.5.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.5.5.5.1\">\n<span class=\"ltx_p\" id=\"S4.T17.5.5.5.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.5.5.5.1.1.1\" style=\"font-size:80%;\">95.38 \u00b1 0.22%</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T17.6.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T17.6.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.6.6.1.1\">\n<span class=\"ltx_p\" id=\"S4.T17.6.6.1.1.1\" style=\"width:56.4pt;\"></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T17.6.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.6.6.2.1\">\n<span class=\"ltx_p\" id=\"S4.T17.6.6.2.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.6.6.2.1.1.1\" style=\"font-size:80%;\">93.48 \u00b1 0.21%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T17.6.6.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.6.6.3.1\">\n<span class=\"ltx_p\" id=\"S4.T17.6.6.3.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.6.6.3.1.1.1\" style=\"font-size:80%;\">91.59 \u00b1 0.07%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S4.T17.6.6.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.6.6.4.1\">\n<span class=\"ltx_p\" id=\"S4.T17.6.6.4.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.6.6.4.1.1.1\" style=\"font-size:80%;\">96.24 \u00b1 0.04%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S4.T17.6.6.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T17.6.6.5.1\">\n<span class=\"ltx_p\" id=\"S4.T17.6.6.5.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S4.T17.6.6.5.1.1.1\" style=\"font-size:80%;\">95.13 \u00b1 0.09%</span></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T17.10.1.1\" style=\"font-size:113%;\">Table 17</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T17.11.2\" style=\"font-size:113%;\">Accuracy of the DNNs trained adversarially on the RUAR and the Medical datasets.\n</em></figcaption>\n</figure>",
            "capture": "Table 17: Accuracy of the DNNs trained adversarially on the RUAR and the Medical datasets.\n"
        },
        "18": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T18\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T18.18\">\n<tr class=\"ltx_tr\" id=\"S4.T18.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T18.6.6.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T18.6.6.7.1\" style=\"font-size:80%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T18.6.6.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T18.6.6.8.1\" style=\"font-size:80%;\">Model</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T18.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T18.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T18.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T18.4.4.4\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" id=\"S4.T18.5.5.5\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"S4.T18.6.6.6\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T18.7.7\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_r ltx_border_t\" id=\"S4.T18.7.7.2\" rowspan=\"6\"><span class=\"ltx_text\" id=\"S4.T18.7.7.2.1\" style=\"font-size:80%;\">RUAR</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T18.7.7.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T18.7.7.3\"><span class=\"ltx_text\" id=\"S4.T18.7.7.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T18.7.7.4\"><span class=\"ltx_text\" id=\"S4.T18.7.7.4.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T18.7.7.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T18.7.7.5.1\" style=\"font-size:80%;\">1.33</span><span class=\"ltx_text\" id=\"S4.T18.7.7.5.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T18.7.7.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T18.7.7.6.1\" style=\"font-size:80%;\">0.52</span><span class=\"ltx_text\" id=\"S4.T18.7.7.6.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T18.7.7.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T18.7.7.7.1\" style=\"font-size:80%;\">0.41</span><span class=\"ltx_text\" id=\"S4.T18.7.7.7.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T18.7.7.8\"><span class=\"ltx_text\" id=\"S4.T18.7.7.8.1\" style=\"font-size:80%;\">88.62%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T18.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T18.8.8.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.8.8.2\"><span class=\"ltx_text\" id=\"S4.T18.8.8.2.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.8.8.3\"><span class=\"ltx_text\" id=\"S4.T18.8.8.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.8.8.4\"><span class=\"ltx_text\" id=\"S4.T18.8.8.4.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.8.8.5\"><span class=\"ltx_text\" id=\"S4.T18.8.8.5.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.8.8.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T18.8.8.6.1\" style=\"font-size:80%;\">0.41</span><span class=\"ltx_text\" id=\"S4.T18.8.8.6.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T18.8.8.7\"><span class=\"ltx_text\" id=\"S4.T18.8.8.7.1\" style=\"font-size:80%;\">90.02%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T18.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T18.9.9.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.9.9.2\"><span class=\"ltx_text\" id=\"S4.T18.9.9.2.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.9.9.3\"><span class=\"ltx_text\" id=\"S4.T18.9.9.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.9.9.4\"><span class=\"ltx_text\" id=\"S4.T18.9.9.4.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.9.9.5\"><span class=\"ltx_text\" id=\"S4.T18.9.9.5.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.9.9.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T18.9.9.6.1\" style=\"font-size:80%;\">0.41</span><span class=\"ltx_text\" id=\"S4.T18.9.9.6.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T18.9.9.7\"><span class=\"ltx_text\" id=\"S4.T18.9.9.7.1\" style=\"font-size:80%;\">92.74%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T18.10.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T18.10.10.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.10.10.2\"><span class=\"ltx_text\" id=\"S4.T18.10.10.2.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.10.10.3\"><span class=\"ltx_text\" id=\"S4.T18.10.10.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.10.10.4\"><span class=\"ltx_text\" id=\"S4.T18.10.10.4.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.10.10.5\"><span class=\"ltx_text\" id=\"S4.T18.10.10.5.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.10.10.6\"><span class=\"ltx_text\" id=\"S4.T18.10.10.6.1\" style=\"font-size:80%;\">0.08%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T18.10.10.7\"><span class=\"ltx_text\" id=\"S4.T18.10.10.7.1\" style=\"font-size:80%;\">93.54%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T18.11.11\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T18.11.11.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.11.11.2\"><span class=\"ltx_text\" id=\"S4.T18.11.11.2.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.11.11.3\"><span class=\"ltx_text\" id=\"S4.T18.11.11.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.11.11.4\"><span class=\"ltx_text\" id=\"S4.T18.11.11.4.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.11.11.5\"><span class=\"ltx_text\" id=\"S4.T18.11.11.5.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.11.11.6\"><span class=\"ltx_text\" id=\"S4.T18.11.11.6.1\" style=\"font-size:80%;\">0.33%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T18.11.11.7\"><span class=\"ltx_text\" id=\"S4.T18.11.11.7.1\" style=\"font-size:80%;\">93.86%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T18.12.12\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T18.12.12.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.12.12.2\"><span class=\"ltx_text\" id=\"S4.T18.12.12.2.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.12.12.3\"><span class=\"ltx_text\" id=\"S4.T18.12.12.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.12.12.4\"><span class=\"ltx_text\" id=\"S4.T18.12.12.4.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.12.12.5\"><span class=\"ltx_text\" id=\"S4.T18.12.12.5.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.12.12.6\"><span class=\"ltx_text\" id=\"S4.T18.12.12.6.1\" style=\"font-size:80%;\">0.33%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T18.12.12.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T18.12.12.7.1\" style=\"font-size:80%;\">98.22</span><span class=\"ltx_text\" id=\"S4.T18.12.12.7.2\" style=\"font-size:80%;\">%</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T18.13.13\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T18.13.13.2\" rowspan=\"6\"><span class=\"ltx_text\" id=\"S4.T18.13.13.2.1\" style=\"font-size:80%;\">Medical</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T18.13.13.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T18.13.13.3\"><span class=\"ltx_text\" id=\"S4.T18.13.13.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T18.13.13.4\"><span class=\"ltx_text\" id=\"S4.T18.13.13.4.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T18.13.13.5\"><span class=\"ltx_text\" id=\"S4.T18.13.13.5.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T18.13.13.6\"><span class=\"ltx_text\" id=\"S4.T18.13.13.6.1\" style=\"font-size:80%;\">2.50%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T18.13.13.7\"><span class=\"ltx_text\" id=\"S4.T18.13.13.7.1\" style=\"font-size:80%;\">4.40%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T18.13.13.8\"><span class=\"ltx_text\" id=\"S4.T18.13.13.8.1\" style=\"font-size:80%;\">97.47%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T18.14.14\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T18.14.14.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.14.14.2\"><span class=\"ltx_text\" id=\"S4.T18.14.14.2.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.14.14.3\"><span class=\"ltx_text\" id=\"S4.T18.14.14.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.14.14.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T18.14.14.4.1\" style=\"font-size:80%;\">1.08</span><span class=\"ltx_text\" id=\"S4.T18.14.14.4.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.14.14.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T18.14.14.5.1\" style=\"font-size:80%;\">3.60</span><span class=\"ltx_text\" id=\"S4.T18.14.14.5.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.14.14.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T18.14.14.6.1\" style=\"font-size:80%;\">6.00</span><span class=\"ltx_text\" id=\"S4.T18.14.14.6.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T18.14.14.7\"><span class=\"ltx_text\" id=\"S4.T18.14.14.7.1\" style=\"font-size:80%;\">98.79%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T18.15.15\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T18.15.15.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.15.15.2\"><span class=\"ltx_text\" id=\"S4.T18.15.15.2.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.15.15.3\"><span class=\"ltx_text\" id=\"S4.T18.15.15.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.15.15.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T18.15.15.4.1\" style=\"font-size:80%;\">1.08</span><span class=\"ltx_text\" id=\"S4.T18.15.15.4.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.15.15.5\"><span class=\"ltx_text\" id=\"S4.T18.15.15.5.1\" style=\"font-size:80%;\">3.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.15.15.6\"><span class=\"ltx_text\" id=\"S4.T18.15.15.6.1\" style=\"font-size:80%;\">5.04%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T18.15.15.7\"><span class=\"ltx_text\" id=\"S4.T18.15.15.7.1\" style=\"font-size:80%;\">99.09%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T18.16.16\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T18.16.16.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.16.16.2\"><span class=\"ltx_text\" id=\"S4.T18.16.16.2.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.16.16.3\"><span class=\"ltx_text\" id=\"S4.T18.16.16.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.16.16.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T18.16.16.4.1\" style=\"font-size:80%;\">1.08</span><span class=\"ltx_text\" id=\"S4.T18.16.16.4.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.16.16.5\"><span class=\"ltx_text\" id=\"S4.T18.16.16.5.1\" style=\"font-size:80%;\">2.90%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.16.16.6\"><span class=\"ltx_text\" id=\"S4.T18.16.16.6.1\" style=\"font-size:80%;\">4.96%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T18.16.16.7\"><span class=\"ltx_text\" id=\"S4.T18.16.16.7.1\" style=\"font-size:80%;\">99.05%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T18.17.17\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T18.17.17.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.17.17.2\"><span class=\"ltx_text\" id=\"S4.T18.17.17.2.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.17.17.3\"><span class=\"ltx_text\" id=\"S4.T18.17.17.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.17.17.4\"><span class=\"ltx_text\" id=\"S4.T18.17.17.4.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.17.17.5\"><span class=\"ltx_text\" id=\"S4.T18.17.17.5.1\" style=\"font-size:80%;\">2.90%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T18.17.17.6\"><span class=\"ltx_text\" id=\"S4.T18.17.17.6.1\" style=\"font-size:80%;\">4.40%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T18.17.17.7\"><span class=\"ltx_text\" id=\"S4.T18.17.17.7.1\" style=\"font-size:80%;\">98.73%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T18.18.18\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"S4.T18.18.18.1\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T18.18.18.2\"><span class=\"ltx_text\" id=\"S4.T18.18.18.2.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T18.18.18.3\"><span class=\"ltx_text\" id=\"S4.T18.18.18.3.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T18.18.18.4\"><span class=\"ltx_text\" id=\"S4.T18.18.18.4.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T18.18.18.5\"><span class=\"ltx_text\" id=\"S4.T18.18.18.5.1\" style=\"font-size:80%;\">2.30%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T18.18.18.6\"><span class=\"ltx_text\" id=\"S4.T18.18.18.6.1\" style=\"font-size:80%;\">4.32%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T18.18.18.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T18.18.18.7.1\" style=\"font-size:80%;\">99.60</span><span class=\"ltx_text\" id=\"S4.T18.18.18.7.2\" style=\"font-size:80%;\">%</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T18.22.1.1\" style=\"font-size:113%;\">Table 18</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T18.23.2\" style=\"font-size:113%;\">Verifiability of the DNNs trained adversarially on the RUAR and the Medical datasets, for a selection of geometric subspaces; using the ERAN verifier.\n</em></figcaption>\n</figure>",
            "capture": "Table 18: Verifiability of the DNNs trained adversarially on the RUAR and the Medical datasets, for a selection of geometric subspaces; using the ERAN verifier.\n"
        },
        "19": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T19\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T19.28\">\n<tr class=\"ltx_tr\" id=\"S5.T19.28.29\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S5.T19.28.29.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.28.29.1.1\">\n<span class=\"ltx_p\" id=\"S5.T19.28.29.1.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T19.28.29.1.1.1.1\" style=\"font-size:80%;\">Pipeline Component</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S5.T19.28.29.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.28.29.2.1\">\n<span class=\"ltx_p\" id=\"S5.T19.28.29.2.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T19.28.29.2.1.1.1\" style=\"font-size:80%;\">Component Implementations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\" id=\"S5.T19.28.29.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.28.29.3.1\">\n<span class=\"ltx_p\" id=\"S5.T19.28.29.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T19.28.29.3.1.1.1\" style=\"font-size:80%;\">Additional Details</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T19.3.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T19.3.3.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.3.3.4.1\">\n<span class=\"ltx_p\" id=\"S5.T19.3.3.4.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T19.3.3.4.1.1.1\" style=\"font-size:80%;\">0. Choosing Datasets</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T19.3.3.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.3.3.5.1\">\n<span class=\"ltx_p\" id=\"S5.T19.3.3.5.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S5.T19.3.3.5.1.1.1\" style=\"font-size:80%;\">RUAR, Medical</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T19.3.3.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.3.3.3.3\">\n<span class=\"ltx_p\" id=\"S5.T19.3.3.3.3.3\"><span class=\"ltx_text\" id=\"S5.T19.3.3.3.3.3.1\" style=\"font-size:80%;\">Same as in Section\u00a0</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#S4\" style=\"font-size:80%;\" title=\"4 Characterisation of Verifiable Subspaces \u2023 NLP Verification: Towards a General Methodology for Certifying Robustness\"><span class=\"ltx_text ltx_ref_tag\">4</span></a><span class=\"ltx_text\" id=\"S5.T19.3.3.3.3.3.2\" style=\"font-size:80%;\"> experiments. The RUAR dataset has </span><span class=\"ltx_text\" id=\"S5.T19.3.3.3.3.3.3\" style=\"font-size:80%;\"> sentences equally divided among the two classes, while the Medical dataset has 2917 medical and non-medical queries (</span><span class=\"ltx_text\" id=\"S5.T19.3.3.3.3.3.4\" style=\"font-size:80%;\"> and </span><span class=\"ltx_text\" id=\"S5.T19.3.3.3.3.3.5\" style=\"font-size:80%;\"> examples respectively).</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T19.12.12\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T19.12.12.10\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.12.12.10.1\">\n<span class=\"ltx_p\" id=\"S5.T19.12.12.10.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T19.12.12.10.1.1.1\" style=\"font-size:80%;\">1. Generating Sentence Perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T19.7.7.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.7.7.4.4\">\n<span class=\"ltx_p\" id=\"S5.T19.7.7.4.4.4\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S5.T19.7.7.4.4.4.1\" style=\"font-size:80%;\">, </span><span class=\"ltx_text\" id=\"S5.T19.7.7.4.4.4.2\" style=\"font-size:80%;\">, </span><span class=\"ltx_text\" id=\"S5.T19.7.7.4.4.4.3\" style=\"font-size:80%;\">, </span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T19.12.12.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.12.12.9.5\">\n<span class=\"ltx_p\" id=\"S5.T19.12.12.9.5.5\"><span class=\"ltx_text\" id=\"S5.T19.12.12.9.5.5.1\" style=\"font-size:80%;\">With </span><span class=\"ltx_text\" id=\"S5.T19.12.12.9.5.5.2\" style=\"font-size:80%;\">, the resulting set of sentences </span><span class=\"ltx_text\" id=\"S5.T19.12.12.9.5.5.3\" style=\"font-size:80%;\"> has </span><span class=\"ltx_text\" id=\"S5.T19.12.12.9.5.5.4\" style=\"font-size:80%;\"> sentences for RUAR and </span><span class=\"ltx_text\" id=\"S5.T19.12.12.9.5.5.5\" style=\"font-size:80%;\"> sentences for Medical. The superscript </span><sup class=\"ltx_sup\" id=\"S5.T19.12.12.9.5.5.6\"><span class=\"ltx_text\" id=\"S5.T19.12.12.9.5.5.6.1\" style=\"font-size:80%;\">\u2662</span></sup><span class=\"ltx_text\" id=\"S5.T19.12.12.9.5.5.7\" style=\"font-size:80%;\"> refers to filtering that will be introduced in Section\u00a0</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#S5.SS5\" style=\"font-size:80%;\" title=\"5.5 Analysis of Perturbations \u2023 5 NLP Case Studies \u2023 NLP Verification: Towards a General Methodology for Certifying Robustness\"><span class=\"ltx_text ltx_ref_tag\">5.5</span></a><span class=\"ltx_text\" id=\"S5.T19.12.12.9.5.5.8\" style=\"font-size:80%;\">.</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T19.28.30\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T19.28.30.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.28.30.1.1\">\n<span class=\"ltx_p\" id=\"S5.T19.28.30.1.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T19.28.30.1.1.1.1\" style=\"font-size:80%;\">2. Embedding Sentences into Real Vector Space</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T19.28.30.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.28.30.2.1\">\n<span class=\"ltx_p\" id=\"S5.T19.28.30.2.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S5.T19.28.30.2.1.1.1\" style=\"font-size:80%;\">s-bert\u00a022M, s-gpt\u00a01.3B, s-gpt\u00a02.7B</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T19.28.30.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.28.30.3.1\">\n<span class=\"ltx_p\" id=\"S5.T19.28.30.3.1.1\"><span class=\"ltx_text\" id=\"S5.T19.28.30.3.1.1.1\" style=\"font-size:80%;\">In the experiments of Section\u00a0</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#S4\" style=\"font-size:80%;\" title=\"4 Characterisation of Verifiable Subspaces \u2023 NLP Verification: Towards a General Methodology for Certifying Robustness\"><span class=\"ltx_text ltx_ref_tag\">4</span></a><span class=\"ltx_text\" id=\"S5.T19.28.30.3.1.1.2\" style=\"font-size:80%;\"> only s-bert 22M was used.</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T19.20.20\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T19.20.20.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.20.20.9.1\">\n<span class=\"ltx_p\" id=\"S5.T19.20.20.9.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T19.20.20.9.1.1.1\" style=\"font-size:80%;\">3. Defining Semantic Subspaces based on Sentence Perturbations</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T19.14.14.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.14.14.2.2\">\n<span class=\"ltx_p\" id=\"S5.T19.14.14.2.2.2\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S5.T19.14.14.2.2.2.1\" style=\"font-size:80%;\">, </span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T19.20.20.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.20.20.8.6\">\n<span class=\"ltx_p\" id=\"S5.T19.20.20.8.6.6\"><span class=\"ltx_text\" id=\"S5.T19.20.20.8.6.6.1\" style=\"font-size:80%;\"> and </span><span class=\"ltx_text\" id=\"S5.T19.20.20.8.6.6.2\" style=\"font-size:80%;\"> are obtained on </span><span class=\"ltx_text\" id=\"S5.T19.20.20.8.6.6.3\" style=\"font-size:80%;\">, </span><span class=\"ltx_text\" id=\"S5.T19.20.20.8.6.6.4\" style=\"font-size:80%;\">, respectively. Their cardinality is </span><span class=\"ltx_text\" id=\"S5.T19.20.20.8.6.6.5\" style=\"font-size:80%;\"> for RUAR and </span><span class=\"ltx_text\" id=\"S5.T19.20.20.8.6.6.6\" style=\"font-size:80%;\"> for Medical.</span></span>\n<span class=\"ltx_itemize\" id=\"S5.I3\">\n<span class=\"ltx_item\" id=\"S5.I3.i1\" style=\"list-style-type:none;\"><span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<span class=\"ltx_para\" id=\"S5.I3.i1.p1\">\n<span class=\"ltx_p\" id=\"S5.I3.i1.p1.4\"><span class=\"ltx_text\" id=\"S5.I3.i1.p1.4.1\" style=\"font-size:80%;\">Volume of </span><span class=\"ltx_text\" id=\"S5.I3.i1.p1.4.2\" style=\"font-size:80%;\"> for RUAR is </span><span class=\"ltx_text\" id=\"S5.I3.i1.p1.4.3\" style=\"font-size:80%;\"> (s-bert 22M), </span><span class=\"ltx_text\" id=\"S5.I3.i1.p1.4.4\" style=\"font-size:80%;\"> (s-gpt 1.3B), </span><span class=\"ltx_text\" id=\"S5.I3.i1.p1.4.5\" style=\"font-size:80%;\"> (s-gpt 2.7B).</span></span>\n</span></span>\n<span class=\"ltx_item\" id=\"S5.I3.i2\" style=\"list-style-type:none;\"><span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<span class=\"ltx_para\" id=\"S5.I3.i2.p1\">\n<span class=\"ltx_p\" id=\"S5.I3.i2.p1.4\"><span class=\"ltx_text\" id=\"S5.I3.i2.p1.4.1\" style=\"font-size:80%;\">Volume of </span><span class=\"ltx_text\" id=\"S5.I3.i2.p1.4.2\" style=\"font-size:80%;\"> for RUAR is </span><span class=\"ltx_text\" id=\"S5.I3.i2.p1.4.3\" style=\"font-size:80%;\"> (s-bert 22M), </span><span class=\"ltx_text\" id=\"S5.I3.i2.p1.4.4\" style=\"font-size:80%;\"> (s-gpt 1.3B), </span><span class=\"ltx_text\" id=\"S5.I3.i2.p1.4.5\" style=\"font-size:80%;\"> (s-gpt 2.7B).</span></span>\n</span></span>\n<span class=\"ltx_item\" id=\"S5.I3.i3\" style=\"list-style-type:none;\"><span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<span class=\"ltx_para\" id=\"S5.I3.i3.p1\">\n<span class=\"ltx_p\" id=\"S5.I3.i3.p1.4\"><span class=\"ltx_text\" id=\"S5.I3.i3.p1.4.1\" style=\"font-size:80%;\">Volume of </span><span class=\"ltx_text\" id=\"S5.I3.i3.p1.4.2\" style=\"font-size:80%;\"> for Medical is </span><span class=\"ltx_text\" id=\"S5.I3.i3.p1.4.3\" style=\"font-size:80%;\"> (s-bert 22M), </span><span class=\"ltx_text\" id=\"S5.I3.i3.p1.4.4\" style=\"font-size:80%;\"> (s-gpt 1.3B), </span><span class=\"ltx_text\" id=\"S5.I3.i3.p1.4.5\" style=\"font-size:80%;\"> (s-gpt 2.7B).</span></span>\n</span></span>\n<span class=\"ltx_item\" id=\"S5.I3.i4\" style=\"list-style-type:none;\"><span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<span class=\"ltx_para\" id=\"S5.I3.i4.p1\">\n<span class=\"ltx_p\" id=\"S5.I3.i4.p1.4\"><span class=\"ltx_text\" id=\"S5.I3.i4.p1.4.1\" style=\"font-size:80%;\">Volume of </span><span class=\"ltx_text\" id=\"S5.I3.i4.p1.4.2\" style=\"font-size:80%;\"> for Medical is </span><span class=\"ltx_text\" id=\"S5.I3.i4.p1.4.3\" style=\"font-size:80%;\"> (s-bert 22M), </span><span class=\"ltx_text\" id=\"S5.I3.i4.p1.4.4\" style=\"font-size:80%;\"> (s-gpt 1.3B), </span><span class=\"ltx_text\" id=\"S5.I3.i4.p1.4.5\" style=\"font-size:80%;\"> (s-gpt 2.7B).</span></span>\n</span></span>\n</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T19.28.28\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T19.28.28.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.28.28.9.1\">\n<span class=\"ltx_p\" id=\"S5.T19.28.28.9.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T19.28.28.9.1.1.1\" style=\"font-size:80%;\">4. Training Robust DNNs using Semantic Subspaces</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T19.23.23.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.23.23.3.3\">\n<span class=\"ltx_p\" id=\"S5.T19.23.23.3.3.3\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S5.T19.23.23.3.3.3.1\" style=\"font-size:80%;\">, </span><span class=\"ltx_text\" id=\"S5.T19.23.23.3.3.3.2\" style=\"font-size:80%;\">, </span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S5.T19.28.28.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.28.28.8.5\">\n<span class=\"ltx_p\" id=\"S5.T19.28.28.8.5.5\"><span class=\"ltx_text\" id=\"S5.T19.28.28.8.5.5.1\" style=\"font-size:80%;\"> is obtained as in Section\u00a0</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#S4\" style=\"font-size:80%;\" title=\"4 Characterisation of Verifiable Subspaces \u2023 NLP Verification: Towards a General Methodology for Certifying Robustness\"><span class=\"ltx_text ltx_ref_tag\">4</span></a><span class=\"ltx_text\" id=\"S5.T19.28.28.8.5.5.2\" style=\"font-size:80%;\">, while </span><span class=\"ltx_text\" id=\"S5.T19.28.28.8.5.5.3\" style=\"font-size:80%;\"> and </span><span class=\"ltx_text\" id=\"S5.T19.28.28.8.5.5.4\" style=\"font-size:80%;\"> are obtained through our adversarial training on </span><span class=\"ltx_text\" id=\"S5.T19.28.28.8.5.5.5\" style=\"font-size:80%;\"> and </span><span class=\"ltx_text\" id=\"S5.T19.28.28.8.5.5.6\" style=\"font-size:80%;\">, respectively.</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T19.28.31\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S5.T19.28.31.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.28.31.1.1\">\n<span class=\"ltx_p\" id=\"S5.T19.28.31.1.1.1\" style=\"width:86.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T19.28.31.1.1.1.1\" style=\"font-size:80%;\">5. Verifying resulting DNNs on the given semantic subspaces</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S5.T19.28.31.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.28.31.2.1\">\n<span class=\"ltx_p\" id=\"S5.T19.28.31.2.1.1\" style=\"width:78.0pt;\"><span class=\"ltx_text\" id=\"S5.T19.28.31.2.1.1.1\" style=\"font-size:80%;\">Marabou</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_t\" id=\"S5.T19.28.31.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T19.28.31.3.1\">\n<span class=\"ltx_p\" id=\"S5.T19.28.31.3.1.1\"><span class=\"ltx_text\" id=\"S5.T19.28.31.3.1.1.1\" style=\"font-size:80%;\">Same settings as in Section\u00a0</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#S4\" style=\"font-size:80%;\" title=\"4 Characterisation of Verifiable Subspaces \u2023 NLP Verification: Towards a General Methodology for Certifying Robustness\"><span class=\"ltx_text ltx_ref_tag\">4</span></a></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S5.T19.34.2.1\" style=\"font-size:113%;\">Table 19</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T19.30.1\" style=\"font-size:113%;\">Section\u00a0<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.10144v2#S5\" title=\"5 NLP Case Studies \u2023 NLP Verification: Towards a General Methodology for Certifying Robustness\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> <span class=\"ltx_text ltx_font_bold\" id=\"S5.T19.30.1.1\">NLP verification pipeline</span> setup, implemented using ANTONIO. Note that, after filtering, the volume of  decreases by several orders of magnitude. Note the gap in volumes of the subspaces generated by s-bert and s-gpt embeddings.</em><span class=\"ltx_text\" id=\"S5.T19.35.3\" style=\"font-size:113%;\">\n</span></figcaption>\n</figure>",
            "capture": "Table 19: Section\u00a05 NLP verification pipeline setup, implemented using ANTONIO. Note that, after filtering, the volume of  decreases by several orders of magnitude. Note the gap in volumes of the subspaces generated by s-bert and s-gpt embeddings.\n"
        },
        "20": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T20\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T20.14\">\n<tr class=\"ltx_tr\" id=\"S5.T20.14.15\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T20.14.15.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.14.15.1.1\" style=\"font-size:80%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T20.14.15.2\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.14.15.2.1\" style=\"font-size:80%;\">Model</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"3\" id=\"S5.T20.14.15.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.14.15.3.1\" style=\"font-size:80%;\">Test set</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_tt\" colspan=\"3\" id=\"S5.T20.14.15.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.14.15.4.1\" style=\"font-size:80%;\">Perturbed test set</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.14.16\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_border_r\" id=\"S5.T20.14.16.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_border_r\" id=\"S5.T20.14.16.2\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.14.16.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.14.16.3.1\" style=\"font-size:80%;\">Precision</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.14.16.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.14.16.4.1\" style=\"font-size:80%;\">Recall</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" id=\"S5.T20.14.16.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.14.16.5.1\" style=\"font-size:80%;\">F1</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.14.16.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.14.16.6.1\" style=\"font-size:80%;\">Precision</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.14.16.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.14.16.7.1\" style=\"font-size:80%;\">Recall</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.14.16.8\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.14.16.8.1\" style=\"font-size:80%;\">F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.1.1\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_align_middle ltx_border_r ltx_border_t\" id=\"S5.T20.1.1.2\" rowspan=\"7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.1.1.2.1\" style=\"font-size:80%;\">RUAR</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T20.1.1.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S5.T20.1.1.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.1.1.3.1\" style=\"font-size:80%;\">51.67%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S5.T20.1.1.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.1.1.4.1\" style=\"font-size:80%;\">58.35%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T20.1.1.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.1.1.5.1\" style=\"font-size:80%;\">54.81%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S5.T20.1.1.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.1.1.6.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S5.T20.1.1.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.1.1.7.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S5.T20.1.1.8\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.1.1.8.1\" style=\"font-size:80%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.2.2\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" id=\"S5.T20.2.2.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text\" id=\"S5.T20.2.2.1.1\" style=\"font-size:80%;\"> (s-bert 22M)</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.2.2.2\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.2.2.2.1\" style=\"font-size:80%;\">95.68%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.2.2.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.2.2.3.1\" style=\"font-size:80%;\">91.29%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" id=\"S5.T20.2.2.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.2.2.4.1\" style=\"font-size:80%;\">93.44</span><span class=\"ltx_text\" id=\"S5.T20.2.2.4.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.2.2.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.2.2.5.1\" style=\"font-size:80%;\">94.77%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.2.2.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.2.2.6.1\" style=\"font-size:80%;\">71.86%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.2.2.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.2.2.7.1\" style=\"font-size:80%;\">81.74%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.3.3\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" id=\"S5.T20.3.3.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text\" id=\"S5.T20.3.3.1.1\" style=\"font-size:80%;\"> (s-bert 22M)</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.3.3.2\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.3.3.2.1\" style=\"font-size:80%;\">84.97%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.3.3.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.3.3.3.1\" style=\"font-size:80%;\">98.63%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" id=\"S5.T20.3.3.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.3.3.4.1\" style=\"font-size:80%;\">91.29%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.3.3.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.3.3.5.1\" style=\"font-size:80%;\">81.25%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.3.3.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.3.3.6.1\" style=\"font-size:80%;\">94.66%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.3.3.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.3.3.7.1\" style=\"font-size:80%;\">87.45</span><span class=\"ltx_text\" id=\"S5.T20.3.3.7.2\" style=\"font-size:80%;\">%</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.4.4\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" id=\"S5.T20.4.4.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text\" id=\"S5.T20.4.4.1.1\" style=\"font-size:80%;\"> (s-gpt 1.3B)</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.4.4.2\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.4.4.2.1\" style=\"font-size:80%;\">96.20%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.4.4.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.4.4.3.1\" style=\"font-size:80%;\">87.25%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" id=\"S5.T20.4.4.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.4.4.4.1\" style=\"font-size:80%;\">91.51%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.4.4.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.4.4.5.1\" style=\"font-size:80%;\">95.45%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.4.4.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.4.4.6.1\" style=\"font-size:80%;\">67.38%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.4.4.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.4.4.7.1\" style=\"font-size:80%;\">78.98%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.5.5\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" id=\"S5.T20.5.5.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text\" id=\"S5.T20.5.5.1.1\" style=\"font-size:80%;\"> (s-gpt 1.3B)</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.5.5.2\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.5.5.2.1\" style=\"font-size:80%;\">63.03%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.5.5.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.5.5.3.1\" style=\"font-size:80%;\">99.80%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" id=\"S5.T20.5.5.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.5.5.4.1\" style=\"font-size:80%;\">77.24%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.5.5.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.5.5.5.1\" style=\"font-size:80%;\">61.26%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.5.5.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.5.5.6.1\" style=\"font-size:80%;\">98.60%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.5.5.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.5.5.7.1\" style=\"font-size:80%;\">75.54%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.6.6\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" id=\"S5.T20.6.6.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text\" id=\"S5.T20.6.6.1.1\" style=\"font-size:80%;\"> (s-gpt 2.7B)</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.6.6.2\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.6.6.2.1\" style=\"font-size:80%;\">96.74</span><span class=\"ltx_text\" id=\"S5.T20.6.6.2.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.6.6.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.6.6.3.1\" style=\"font-size:80%;\">87.29%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" id=\"S5.T20.6.6.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.6.6.4.1\" style=\"font-size:80%;\">91.77%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.6.6.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.6.6.5.1\" style=\"font-size:80%;\">95.49</span><span class=\"ltx_text\" id=\"S5.T20.6.6.5.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.6.6.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.6.6.6.1\" style=\"font-size:80%;\">69.82%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.6.6.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.6.6.7.1\" style=\"font-size:80%;\">80.66%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.7.7\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" id=\"S5.T20.7.7.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text\" id=\"S5.T20.7.7.1.1\" style=\"font-size:80%;\"> (s-gpt 2.7B)</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.7.7.2\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.7.7.2.1\" style=\"font-size:80%;\">60.18%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.7.7.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.7.7.3.1\" style=\"font-size:80%;\">99.80</span><span class=\"ltx_text\" id=\"S5.T20.7.7.3.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" id=\"S5.T20.7.7.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.7.7.4.1\" style=\"font-size:80%;\">75.08%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.7.7.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.7.7.5.1\" style=\"font-size:80%;\">58.46%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.7.7.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.7.7.6.1\" style=\"font-size:80%;\">98.99</span><span class=\"ltx_text\" id=\"S5.T20.7.7.6.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.7.7.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.7.7.7.1\" style=\"font-size:80%;\">73.50%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.8.8\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_align_middle ltx_border_bb ltx_border_r ltx_border_t\" id=\"S5.T20.8.8.2\" rowspan=\"7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.8.8.2.1\" style=\"font-size:80%;\">Medical</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T20.8.8.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S5.T20.8.8.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.8.8.3.1\" style=\"font-size:80%;\">58.95%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S5.T20.8.8.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.8.8.4.1\" style=\"font-size:80%;\">70.22%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T20.8.8.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.8.8.5.1\" style=\"font-size:80%;\">64.09%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S5.T20.8.8.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.8.8.6.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S5.T20.8.8.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.8.8.7.1\" style=\"font-size:80%;\">-</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S5.T20.8.8.8\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.8.8.8.1\" style=\"font-size:80%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.9.9\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" id=\"S5.T20.9.9.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text\" id=\"S5.T20.9.9.1.1\" style=\"font-size:80%;\"> (s-bert 22M)</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.9.9.2\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.9.9.2.1\" style=\"font-size:80%;\">95.23</span><span class=\"ltx_text\" id=\"S5.T20.9.9.2.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.9.9.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.9.9.3.1\" style=\"font-size:80%;\">93.25%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" id=\"S5.T20.9.9.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.9.9.4.1\" style=\"font-size:80%;\">94.23%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.9.9.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.9.9.5.1\" style=\"font-size:80%;\">95.20</span><span class=\"ltx_text\" id=\"S5.T20.9.9.5.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.9.9.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.9.9.6.1\" style=\"font-size:80%;\">89.64%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.9.9.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.9.9.7.1\" style=\"font-size:80%;\">92.34%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.10.10\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" id=\"S5.T20.10.10.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text\" id=\"S5.T20.10.10.1.1\" style=\"font-size:80%;\"> (s-bert 22M)</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.10.10.2\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.10.10.2.1\" style=\"font-size:80%;\">93.35%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.10.10.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.10.10.3.1\" style=\"font-size:80%;\">97.36</span><span class=\"ltx_text\" id=\"S5.T20.10.10.3.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" id=\"S5.T20.10.10.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.10.10.4.1\" style=\"font-size:80%;\">95.31</span><span class=\"ltx_text\" id=\"S5.T20.10.10.4.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.10.10.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.10.10.5.1\" style=\"font-size:80%;\">92.38%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.10.10.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.10.10.6.1\" style=\"font-size:80%;\">95.17</span><span class=\"ltx_text\" id=\"S5.T20.10.10.6.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.10.10.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T20.10.10.7.1\" style=\"font-size:80%;\">93.76</span><span class=\"ltx_text\" id=\"S5.T20.10.10.7.2\" style=\"font-size:80%;\">%</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.11.11\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" id=\"S5.T20.11.11.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text\" id=\"S5.T20.11.11.1.1\" style=\"font-size:80%;\"> (s-gpt 1.3B)</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.11.11.2\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.11.11.2.1\" style=\"font-size:80%;\">91.93%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.11.11.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.11.11.3.1\" style=\"font-size:80%;\">88.11%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" id=\"S5.T20.11.11.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.11.11.4.1\" style=\"font-size:80%;\">89.98%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.11.11.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.11.11.5.1\" style=\"font-size:80%;\">92.17%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.11.11.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.11.11.6.1\" style=\"font-size:80%;\">84.17%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.11.11.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.11.11.7.1\" style=\"font-size:80%;\">87.98%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.12.12\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" id=\"S5.T20.12.12.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text\" id=\"S5.T20.12.12.1.1\" style=\"font-size:80%;\"> (s-gpt 1.3B)</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.12.12.2\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.12.12.2.1\" style=\"font-size:80%;\">84.41%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.12.12.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.12.12.3.1\" style=\"font-size:80%;\">96.27%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" id=\"S5.T20.12.12.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.12.12.4.1\" style=\"font-size:80%;\">89.38%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.12.12.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.12.12.5.1\" style=\"font-size:80%;\">83.15%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.12.12.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.12.12.6.1\" style=\"font-size:80%;\">94.70%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.12.12.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.12.12.7.1\" style=\"font-size:80%;\">88.54%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.13.13\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" id=\"S5.T20.13.13.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text\" id=\"S5.T20.13.13.1.1\" style=\"font-size:80%;\"> (s-gpt 2.7B)</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.13.13.2\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.13.13.2.1\" style=\"font-size:80%;\">93.25%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.13.13.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.13.13.3.1\" style=\"font-size:80%;\">89.29%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" id=\"S5.T20.13.13.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.13.13.4.1\" style=\"font-size:80%;\">91.23%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.13.13.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.13.13.5.1\" style=\"font-size:80%;\">92.89%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.13.13.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.13.13.6.1\" style=\"font-size:80%;\">84.79%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" id=\"S5.T20.13.13.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.13.13.7.1\" style=\"font-size:80%;\">88.66%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T20.14.14\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_r\" id=\"S5.T20.14.14.1\" style=\"padding-left:1.8pt;padding-right:1.8pt;\">\n<span class=\"ltx_text\" id=\"S5.T20.14.14.1.1\" style=\"font-size:80%;\"> (s-gpt 2.7B)</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S5.T20.14.14.2\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.14.14.2.1\" style=\"font-size:80%;\">86.03%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S5.T20.14.14.3\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.14.14.3.1\" style=\"font-size:80%;\">96.56%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r\" id=\"S5.T20.14.14.4\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.14.14.4.1\" style=\"font-size:80%;\">90.98%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S5.T20.14.14.5\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.14.14.5.1\" style=\"font-size:80%;\">84.88%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S5.T20.14.14.6\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.14.14.6.1\" style=\"font-size:80%;\">94.99%</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S5.T20.14.14.7\" style=\"padding-left:1.8pt;padding-right:1.8pt;\"><span class=\"ltx_text\" id=\"S5.T20.14.14.7.1\" style=\"font-size:80%;\">89.64%</span></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S5.T20.20.2.1\" style=\"font-size:113%;\">Table 20</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T20.16.1\" style=\"font-size:113%;\">Performance of the models on the test/perturbation set. The average standard deviation is .</em><span class=\"ltx_text\" id=\"S5.T20.21.3\" style=\"font-size:113%;\">\n</span></figcaption>\n</figure>",
            "capture": "Table 20: Performance of the models on the test/perturbation set. The average standard deviation is .\n"
        },
        "21": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T21\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T21.2\">\n<tr class=\"ltx_tr\" id=\"S5.T21.2.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S5.T21.2.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T21.2.1.1.1\">\n<span class=\"ltx_p\" id=\"S5.T21.2.1.1.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T21.2.1.1.1.1.1\" style=\"font-size:80%;\">Criteria</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S5.T21.2.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T21.2.1.2.1\">\n<span class=\"ltx_p\" id=\"S5.T21.2.1.2.1.1\" style=\"width:338.2pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T21.2.1.2.1.1.1\" style=\"font-size:80%;\">Instructions</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T21.2.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T21.2.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T21.2.2.1.1\">\n<span class=\"ltx_p\" id=\"S5.T21.2.2.1.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S5.T21.2.2.1.1.1.1\" style=\"font-size:80%;\">Semantic similarity</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T21.2.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T21.2.2.2.1\">\n<span class=\"ltx_p\" id=\"S5.T21.2.2.2.1.1\" style=\"width:338.2pt;\"><span class=\"ltx_text\" id=\"S5.T21.2.2.2.1.1.1\" style=\"font-size:80%;\">Evaluate whether the original and the modified sentence have the same meaning on a scale from 1 to 4, where 1 is \u2018The modified version means something completely different\u2019 and 4 means \u2018The modified version has exactly the same meaning\u2019.</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T21.2.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T21.2.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T21.2.3.1.1\">\n<span class=\"ltx_p\" id=\"S5.T21.2.3.1.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S5.T21.2.3.1.1.1.1\" style=\"font-size:80%;\">Grammaticality</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T21.2.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T21.2.3.2.1\">\n<span class=\"ltx_p\" id=\"S5.T21.2.3.2.1.1\" style=\"width:338.2pt;\"><span class=\"ltx_text\" id=\"S5.T21.2.3.2.1.1.1\" style=\"font-size:80%;\">Grammatically means issues in grammar, such as verb tense. Evaluate the grammaticality of the modified version on a scale of 1-3, where 1 is \u2018Not understandable because of grammar issues\u2019, and 3 is \u2018Perfectly grammatical\u2019.</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T21.2.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t\" id=\"S5.T21.2.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T21.2.4.1.1\">\n<span class=\"ltx_p\" id=\"S5.T21.2.4.1.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text\" id=\"S5.T21.2.4.1.1.1.1\" style=\"font-size:80%;\">Label consistency</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\" id=\"S5.T21.2.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T21.2.4.2.1\">\n<span class=\"ltx_p\" id=\"S5.T21.2.4.2.1.1\" style=\"width:338.2pt;\"><span class=\"ltx_text\" id=\"S5.T21.2.4.2.1.1.1\" style=\"font-size:80%;\">Decide whether the positive label of the modified sentence is correct using labels 1 - \u2018Yes, the label is correct\u2019, 2 - \u2018No, the label is incorrect\u2019 and 3 - \u2018Unsure\u2019.</span></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S5.T21.5.1.1\" style=\"font-size:113%;\">Table 21</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T21.6.2\" style=\"font-size:113%;\">Annotation instructions for manual estimation of the perturbation validity.</em></figcaption>\n</figure>",
            "capture": "Table 21: Annotation instructions for manual estimation of the perturbation validity."
        },
        "22": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T22\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T22.2\">\n<tr class=\"ltx_tr\" id=\"S5.T22.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T22.2.1.1\" rowspan=\"3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T22.2.1.1.1\" style=\"font-size:80%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T22.2.1.2\" rowspan=\"3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T22.2.1.2.1\" style=\"font-size:80%;\">Perturbation</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"8\" id=\"S5.T22.2.1.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T22.2.1.3.1\" style=\"font-size:80%;\">Semantic Similarity</span><span class=\"ltx_text\" id=\"S5.T22.2.1.3.2\" style=\"font-size:80%;\"> (%)</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T22.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" colspan=\"4\" id=\"S5.T22.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T22.2.2.1.1\" style=\"font-size:80%;\">A1</span></td>\n<td class=\"ltx_td ltx_align_center\" colspan=\"4\" id=\"S5.T22.2.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T22.2.2.2.1\" style=\"font-size:80%;\">A2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T22.2.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T22.2.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T22.2.3.1.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T22.2.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T22.2.3.2.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T22.2.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T22.2.3.3.1\" style=\"font-size:80%;\">3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T22.2.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T22.2.3.4.1\" style=\"font-size:80%;\">4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T22.2.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T22.2.3.5.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T22.2.3.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T22.2.3.6.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T22.2.3.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T22.2.3.7.1\" style=\"font-size:80%;\">3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T22.2.3.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T22.2.3.8.1\" style=\"font-size:80%;\">4</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T22.2.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T22.2.4.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S5.T22.2.4.1.1\" style=\"font-size:80%;\">RUAR</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T22.2.4.2\"><span class=\"ltx_text\" id=\"S5.T22.2.4.2.1\" style=\"font-size:80%;\">Rule-based</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T22.2.4.3\"><span class=\"ltx_text\" id=\"S5.T22.2.4.3.1\" style=\"font-size:80%;\">06.36</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T22.2.4.4\"><span class=\"ltx_text\" id=\"S5.T22.2.4.4.1\" style=\"font-size:80%;\">07.27</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T22.2.4.5\"><span class=\"ltx_text\" id=\"S5.T22.2.4.5.1\" style=\"font-size:80%;\">09.09</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T22.2.4.6\"><span class=\"ltx_text\" id=\"S5.T22.2.4.6.1\" style=\"font-size:80%;\">77.27</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T22.2.4.7\"><span class=\"ltx_text\" id=\"S5.T22.2.4.7.1\" style=\"font-size:80%;\">05.45</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T22.2.4.8\"><span class=\"ltx_text\" id=\"S5.T22.2.4.8.1\" style=\"font-size:80%;\">10.90</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T22.2.4.9\"><span class=\"ltx_text\" id=\"S5.T22.2.4.9.1\" style=\"font-size:80%;\">34.54</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T22.2.4.10\"><span class=\"ltx_text\" id=\"S5.T22.2.4.10.1\" style=\"font-size:80%;\">49.09</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T22.2.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T22.2.5.1\"><span class=\"ltx_text\" id=\"S5.T22.2.5.1.1\" style=\"font-size:80%;\">LLM-based</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T22.2.5.2\"><span class=\"ltx_text\" id=\"S5.T22.2.5.2.1\" style=\"font-size:80%;\">18.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T22.2.5.3\"><span class=\"ltx_text\" id=\"S5.T22.2.5.3.1\" style=\"font-size:80%;\">08.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T22.2.5.4\"><span class=\"ltx_text\" id=\"S5.T22.2.5.4.1\" style=\"font-size:80%;\">20.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T22.2.5.5\"><span class=\"ltx_text\" id=\"S5.T22.2.5.5.1\" style=\"font-size:80%;\">54.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T22.2.5.6\"><span class=\"ltx_text\" id=\"S5.T22.2.5.6.1\" style=\"font-size:80%;\">16.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T22.2.5.7\"><span class=\"ltx_text\" id=\"S5.T22.2.5.7.1\" style=\"font-size:80%;\">08.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T22.2.5.8\"><span class=\"ltx_text\" id=\"S5.T22.2.5.8.1\" style=\"font-size:80%;\">00.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T22.2.5.9\"><span class=\"ltx_text\" id=\"S5.T22.2.5.9.1\" style=\"font-size:80%;\">76.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T22.2.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\" id=\"S5.T22.2.6.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S5.T22.2.6.1.1\" style=\"font-size:80%;\">Medical</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T22.2.6.2\"><span class=\"ltx_text\" id=\"S5.T22.2.6.2.1\" style=\"font-size:80%;\">Rule-based</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T22.2.6.3\"><span class=\"ltx_text\" id=\"S5.T22.2.6.3.1\" style=\"font-size:80%;\">01.25</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T22.2.6.4\"><span class=\"ltx_text\" id=\"S5.T22.2.6.4.1\" style=\"font-size:80%;\">02.50</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T22.2.6.5\"><span class=\"ltx_text\" id=\"S5.T22.2.6.5.1\" style=\"font-size:80%;\">10.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T22.2.6.6\"><span class=\"ltx_text\" id=\"S5.T22.2.6.6.1\" style=\"font-size:80%;\">86.25</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T22.2.6.7\"><span class=\"ltx_text\" id=\"S5.T22.2.6.7.1\" style=\"font-size:80%;\">10.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T22.2.6.8\"><span class=\"ltx_text\" id=\"S5.T22.2.6.8.1\" style=\"font-size:80%;\">10.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T22.2.6.9\"><span class=\"ltx_text\" id=\"S5.T22.2.6.9.1\" style=\"font-size:80%;\">31.25</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T22.2.6.10\"><span class=\"ltx_text\" id=\"S5.T22.2.6.10.1\" style=\"font-size:80%;\">48.75</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T22.2.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"S5.T22.2.7.1\"><span class=\"ltx_text\" id=\"S5.T22.2.7.1.1\" style=\"font-size:80%;\">LLM-based</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T22.2.7.2\"><span class=\"ltx_text\" id=\"S5.T22.2.7.2.1\" style=\"font-size:80%;\">06.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T22.2.7.3\"><span class=\"ltx_text\" id=\"S5.T22.2.7.3.1\" style=\"font-size:80%;\">20.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T22.2.7.4\"><span class=\"ltx_text\" id=\"S5.T22.2.7.4.1\" style=\"font-size:80%;\">28.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S5.T22.2.7.5\"><span class=\"ltx_text\" id=\"S5.T22.2.7.5.1\" style=\"font-size:80%;\">46.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T22.2.7.6\"><span class=\"ltx_text\" id=\"S5.T22.2.7.6.1\" style=\"font-size:80%;\">12.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T22.2.7.7\"><span class=\"ltx_text\" id=\"S5.T22.2.7.7.1\" style=\"font-size:80%;\">18.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T22.2.7.8\"><span class=\"ltx_text\" id=\"S5.T22.2.7.8.1\" style=\"font-size:80%;\">20.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T22.2.7.9\"><span class=\"ltx_text\" id=\"S5.T22.2.7.9.1\" style=\"font-size:80%;\">50.00</span></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S5.T22.5.1.1\" style=\"font-size:113%;\">Table 22</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T22.6.2\" style=\"font-size:113%;\">Semantic similarity results of the manual evaluation for annotators A1 and A2.</em></figcaption>\n</figure>",
            "capture": "Table 22: Semantic similarity results of the manual evaluation for annotators A1 and A2."
        },
        "23": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T23\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T23.2\">\n<tr class=\"ltx_tr\" id=\"S5.T23.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T23.2.1.1\" rowspan=\"3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T23.2.1.1.1\" style=\"font-size:80%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T23.2.1.2\" rowspan=\"3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T23.2.1.2.1\" style=\"font-size:80%;\">Perturbation</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"6\" id=\"S5.T23.2.1.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T23.2.1.3.1\" style=\"font-size:80%;\">Grammaticality</span><span class=\"ltx_text\" id=\"S5.T23.2.1.3.2\" style=\"font-size:80%;\"> (%)</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T23.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" colspan=\"3\" id=\"S5.T23.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T23.2.2.1.1\" style=\"font-size:80%;\">A1</span></td>\n<td class=\"ltx_td ltx_align_center\" colspan=\"3\" id=\"S5.T23.2.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T23.2.2.2.1\" style=\"font-size:80%;\">A2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T23.2.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T23.2.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T23.2.3.1.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T23.2.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T23.2.3.2.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T23.2.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T23.2.3.3.1\" style=\"font-size:80%;\">3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T23.2.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T23.2.3.4.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T23.2.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T23.2.3.5.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T23.2.3.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T23.2.3.6.1\" style=\"font-size:80%;\">3</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T23.2.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T23.2.4.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S5.T23.2.4.1.1\" style=\"font-size:80%;\">RUAR</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T23.2.4.2\"><span class=\"ltx_text\" id=\"S5.T23.2.4.2.1\" style=\"font-size:80%;\">Rule-based</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T23.2.4.3\"><span class=\"ltx_text\" id=\"S5.T23.2.4.3.1\" style=\"font-size:80%;\">10.90</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T23.2.4.4\"><span class=\"ltx_text\" id=\"S5.T23.2.4.4.1\" style=\"font-size:80%;\">31.81</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T23.2.4.5\"><span class=\"ltx_text\" id=\"S5.T23.2.4.5.1\" style=\"font-size:80%;\">57.27</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T23.2.4.6\"><span class=\"ltx_text\" id=\"S5.T23.2.4.6.1\" style=\"font-size:80%;\">13.63</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T23.2.4.7\"><span class=\"ltx_text\" id=\"S5.T23.2.4.7.1\" style=\"font-size:80%;\">78.18</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T23.2.4.8\"><span class=\"ltx_text\" id=\"S5.T23.2.4.8.1\" style=\"font-size:80%;\">08.18</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T23.2.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T23.2.5.1\"><span class=\"ltx_text\" id=\"S5.T23.2.5.1.1\" style=\"font-size:80%;\">LLM-based</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T23.2.5.2\"><span class=\"ltx_text\" id=\"S5.T23.2.5.2.1\" style=\"font-size:80%;\">02.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T23.2.5.3\"><span class=\"ltx_text\" id=\"S5.T23.2.5.3.1\" style=\"font-size:80%;\">02.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T23.2.5.4\"><span class=\"ltx_text\" id=\"S5.T23.2.5.4.1\" style=\"font-size:80%;\">96.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T23.2.5.5\"><span class=\"ltx_text\" id=\"S5.T23.2.5.5.1\" style=\"font-size:80%;\">00.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T23.2.5.6\"><span class=\"ltx_text\" id=\"S5.T23.2.5.6.1\" style=\"font-size:80%;\">02.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T23.2.5.7\"><span class=\"ltx_text\" id=\"S5.T23.2.5.7.1\" style=\"font-size:80%;\">98.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T23.2.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\" id=\"S5.T23.2.6.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S5.T23.2.6.1.1\" style=\"font-size:80%;\">Medical</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T23.2.6.2\"><span class=\"ltx_text\" id=\"S5.T23.2.6.2.1\" style=\"font-size:80%;\">Rule-based</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T23.2.6.3\"><span class=\"ltx_text\" id=\"S5.T23.2.6.3.1\" style=\"font-size:80%;\">07.50</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T23.2.6.4\"><span class=\"ltx_text\" id=\"S5.T23.2.6.4.1\" style=\"font-size:80%;\">32.50</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T23.2.6.5\"><span class=\"ltx_text\" id=\"S5.T23.2.6.5.1\" style=\"font-size:80%;\">60.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T23.2.6.6\"><span class=\"ltx_text\" id=\"S5.T23.2.6.6.1\" style=\"font-size:80%;\">01.25</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T23.2.6.7\"><span class=\"ltx_text\" id=\"S5.T23.2.6.7.1\" style=\"font-size:80%;\">88.75</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T23.2.6.8\"><span class=\"ltx_text\" id=\"S5.T23.2.6.8.1\" style=\"font-size:80%;\">10.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T23.2.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"S5.T23.2.7.1\"><span class=\"ltx_text\" id=\"S5.T23.2.7.1.1\" style=\"font-size:80%;\">LLM-based</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T23.2.7.2\"><span class=\"ltx_text\" id=\"S5.T23.2.7.2.1\" style=\"font-size:80%;\">00.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T23.2.7.3\"><span class=\"ltx_text\" id=\"S5.T23.2.7.3.1\" style=\"font-size:80%;\">00.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S5.T23.2.7.4\"><span class=\"ltx_text\" id=\"S5.T23.2.7.4.1\" style=\"font-size:80%;\">100.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T23.2.7.5\"><span class=\"ltx_text\" id=\"S5.T23.2.7.5.1\" style=\"font-size:80%;\">00.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T23.2.7.6\"><span class=\"ltx_text\" id=\"S5.T23.2.7.6.1\" style=\"font-size:80%;\">06.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T23.2.7.7\"><span class=\"ltx_text\" id=\"S5.T23.2.7.7.1\" style=\"font-size:80%;\">94.00</span></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S5.T23.5.1.1\" style=\"font-size:113%;\">Table 23</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T23.6.2\" style=\"font-size:113%;\">Grammaticality results of the manual evaluation for annotators A1 and A2.</em></figcaption>\n</figure>",
            "capture": "Table 23: Grammaticality results of the manual evaluation for annotators A1 and A2."
        },
        "24": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T24\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T24.2\">\n<tr class=\"ltx_tr\" id=\"S5.T24.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T24.2.1.1\" rowspan=\"3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T24.2.1.1.1\" style=\"font-size:80%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T24.2.1.2\" rowspan=\"3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T24.2.1.2.1\" style=\"font-size:80%;\">Perturbation</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"6\" id=\"S5.T24.2.1.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T24.2.1.3.1\" style=\"font-size:80%;\">Label Consistency</span><span class=\"ltx_text\" id=\"S5.T24.2.1.3.2\" style=\"font-size:80%;\"> (%)</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T24.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" colspan=\"3\" id=\"S5.T24.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T24.2.2.1.1\" style=\"font-size:80%;\">A1</span></td>\n<td class=\"ltx_td ltx_align_center\" colspan=\"3\" id=\"S5.T24.2.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T24.2.2.2.1\" style=\"font-size:80%;\">A2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T24.2.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T24.2.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T24.2.3.1.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T24.2.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T24.2.3.2.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T24.2.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T24.2.3.3.1\" style=\"font-size:80%;\">3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T24.2.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T24.2.3.4.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T24.2.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T24.2.3.5.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T24.2.3.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T24.2.3.6.1\" style=\"font-size:80%;\">3</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T24.2.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T24.2.4.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S5.T24.2.4.1.1\" style=\"font-size:80%;\">RUAR</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T24.2.4.2\"><span class=\"ltx_text\" id=\"S5.T24.2.4.2.1\" style=\"font-size:80%;\">Rule-based</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T24.2.4.3\"><span class=\"ltx_text\" id=\"S5.T24.2.4.3.1\" style=\"font-size:80%;\">88.18</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T24.2.4.4\"><span class=\"ltx_text\" id=\"S5.T24.2.4.4.1\" style=\"font-size:80%;\">00.90</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T24.2.4.5\"><span class=\"ltx_text\" id=\"S5.T24.2.4.5.1\" style=\"font-size:80%;\">10.90</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T24.2.4.6\"><span class=\"ltx_text\" id=\"S5.T24.2.4.6.1\" style=\"font-size:80%;\">85.46</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T24.2.4.7\"><span class=\"ltx_text\" id=\"S5.T24.2.4.7.1\" style=\"font-size:80%;\">04.54</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T24.2.4.8\"><span class=\"ltx_text\" id=\"S5.T24.2.4.8.1\" style=\"font-size:80%;\">10.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T24.2.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T24.2.5.1\"><span class=\"ltx_text\" id=\"S5.T24.2.5.1.1\" style=\"font-size:80%;\">LLM-based</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T24.2.5.2\"><span class=\"ltx_text\" id=\"S5.T24.2.5.2.1\" style=\"font-size:80%;\">78.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T24.2.5.3\"><span class=\"ltx_text\" id=\"S5.T24.2.5.3.1\" style=\"font-size:80%;\">20.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T24.2.5.4\"><span class=\"ltx_text\" id=\"S5.T24.2.5.4.1\" style=\"font-size:80%;\">02.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T24.2.5.5\"><span class=\"ltx_text\" id=\"S5.T24.2.5.5.1\" style=\"font-size:80%;\">70.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T24.2.5.6\"><span class=\"ltx_text\" id=\"S5.T24.2.5.6.1\" style=\"font-size:80%;\">24.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T24.2.5.7\"><span class=\"ltx_text\" id=\"S5.T24.2.5.7.1\" style=\"font-size:80%;\">06.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T24.2.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\" id=\"S5.T24.2.6.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S5.T24.2.6.1.1\" style=\"font-size:80%;\">Medical</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T24.2.6.2\"><span class=\"ltx_text\" id=\"S5.T24.2.6.2.1\" style=\"font-size:80%;\">Rule-based</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T24.2.6.3\"><span class=\"ltx_text\" id=\"S5.T24.2.6.3.1\" style=\"font-size:80%;\">90.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T24.2.6.4\"><span class=\"ltx_text\" id=\"S5.T24.2.6.4.1\" style=\"font-size:80%;\">00.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T24.2.6.5\"><span class=\"ltx_text\" id=\"S5.T24.2.6.5.1\" style=\"font-size:80%;\">10.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T24.2.6.6\"><span class=\"ltx_text\" id=\"S5.T24.2.6.6.1\" style=\"font-size:80%;\">97.50</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T24.2.6.7\"><span class=\"ltx_text\" id=\"S5.T24.2.6.7.1\" style=\"font-size:80%;\">00.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T24.2.6.8\"><span class=\"ltx_text\" id=\"S5.T24.2.6.8.1\" style=\"font-size:80%;\">02.50</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T24.2.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"S5.T24.2.7.1\"><span class=\"ltx_text\" id=\"S5.T24.2.7.1.1\" style=\"font-size:80%;\">LLM-based</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T24.2.7.2\"><span class=\"ltx_text\" id=\"S5.T24.2.7.2.1\" style=\"font-size:80%;\">88.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T24.2.7.3\"><span class=\"ltx_text\" id=\"S5.T24.2.7.3.1\" style=\"font-size:80%;\">04.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S5.T24.2.7.4\"><span class=\"ltx_text\" id=\"S5.T24.2.7.4.1\" style=\"font-size:80%;\">08.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T24.2.7.5\"><span class=\"ltx_text\" id=\"S5.T24.2.7.5.1\" style=\"font-size:80%;\">74.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T24.2.7.6\"><span class=\"ltx_text\" id=\"S5.T24.2.7.6.1\" style=\"font-size:80%;\">00.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T24.2.7.7\"><span class=\"ltx_text\" id=\"S5.T24.2.7.7.1\" style=\"font-size:80%;\">26.00</span></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S5.T24.5.1.1\" style=\"font-size:113%;\">Table 24</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T24.6.2\" style=\"font-size:113%;\">Label consistency results of the manual evaluation for annotators A1 and A2.</em></figcaption>\n</figure>",
            "capture": "Table 24: Label consistency results of the manual evaluation for annotators A1 and A2."
        },
        "25": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T25\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T25.2\">\n<tr class=\"ltx_tr\" id=\"S5.T25.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T25.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T25.2.1.1.1\" style=\"font-size:80%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T25.2.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T25.2.1.2.1\" style=\"font-size:80%;\">Class</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T25.2.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T25.2.1.3.1\" style=\"font-size:80%;\">Encoder</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T25.2.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T25.2.1.4.1\" style=\"font-size:80%;\">Character</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T25.2.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T25.2.1.5.1\" style=\"font-size:80%;\">Vicuna</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T25.2.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T25.2.1.6.1\" style=\"font-size:80%;\">Word</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T25.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_r ltx_border_t\" id=\"S5.T25.2.2.1\" rowspan=\"6\"><span class=\"ltx_text\" id=\"S5.T25.2.2.1.1\" style=\"font-size:80%;\">RUAR</span></td>\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_r ltx_border_t\" id=\"S5.T25.2.2.2\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S5.T25.2.2.2.1\" style=\"font-size:80%;\">Positive</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T25.2.2.3\"><span class=\"ltx_text\" id=\"S5.T25.2.2.3.1\" style=\"font-size:80%;\">s-bert 22M</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T25.2.2.4\"><span class=\"ltx_text\" id=\"S5.T25.2.2.4.1\" style=\"font-size:80%;\">12693/14450 (87.84%)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T25.2.2.5\"><span class=\"ltx_text\" id=\"S5.T25.2.2.5.1\" style=\"font-size:80%;\">8190/12223 (67.00%)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T25.2.2.6\"><span class=\"ltx_text\" id=\"S5.T25.2.2.6.1\" style=\"font-size:80%;\">17209/17340 (99.24%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T25.2.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T25.2.3.1\"><span class=\"ltx_text\" id=\"S5.T25.2.3.1.1\" style=\"font-size:80%;\">s-gpt 1.3B</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.3.2\"><span class=\"ltx_text\" id=\"S5.T25.2.3.2.1\" style=\"font-size:80%;\">14170/14450 (98.06%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.3.3\"><span class=\"ltx_text\" id=\"S5.T25.2.3.3.1\" style=\"font-size:80%;\">9677/12223 (79.17%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.3.4\"><span class=\"ltx_text\" id=\"S5.T25.2.3.4.1\" style=\"font-size:80%;\">17123/17340 (98.75%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T25.2.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T25.2.4.1\"><span class=\"ltx_text\" id=\"S5.T25.2.4.1.1\" style=\"font-size:80%;\">s-gpt 2.7B</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.4.2\"><span class=\"ltx_text\" id=\"S5.T25.2.4.2.1\" style=\"font-size:80%;\">14168/14450 (98.05%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.4.3\"><span class=\"ltx_text\" id=\"S5.T25.2.4.3.1\" style=\"font-size:80%;\">10024/12223 (82.01%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.4.4\"><span class=\"ltx_text\" id=\"S5.T25.2.4.4.1\" style=\"font-size:80%;\">17112/17340 (98.69%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T25.2.5\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_r\" id=\"S5.T25.2.5.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S5.T25.2.5.1.1\" style=\"font-size:80%;\">Negative</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T25.2.5.2\"><span class=\"ltx_text\" id=\"S5.T25.2.5.2.1\" style=\"font-size:80%;\">s-bert 22M</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.5.3\"><span class=\"ltx_text\" id=\"S5.T25.2.5.3.1\" style=\"font-size:80%;\">11288/14450 (78.12%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.5.4\"><span class=\"ltx_text\" id=\"S5.T25.2.5.4.1\" style=\"font-size:80%;\">5008/8511 (58.84%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.5.5\"><span class=\"ltx_text\" id=\"S5.T25.2.5.5.1\" style=\"font-size:80%;\">2167/17309 (12.52%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T25.2.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T25.2.6.1\"><span class=\"ltx_text\" id=\"S5.T25.2.6.1.1\" style=\"font-size:80%;\">s-gpt 1.3B</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.6.2\"><span class=\"ltx_text\" id=\"S5.T25.2.6.2.1\" style=\"font-size:80%;\">13315/14450 (92.15%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.6.3\"><span class=\"ltx_text\" id=\"S5.T25.2.6.3.1\" style=\"font-size:80%;\">5943/8511 (69.83%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.6.4\"><span class=\"ltx_text\" id=\"S5.T25.2.6.4.1\" style=\"font-size:80%;\">2164/17309 (12.50%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T25.2.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T25.2.7.1\"><span class=\"ltx_text\" id=\"S5.T25.2.7.1.1\" style=\"font-size:80%;\">s-gpt 2.7B</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.7.2\"><span class=\"ltx_text\" id=\"S5.T25.2.7.2.1\" style=\"font-size:80%;\">13404/14450 (92.76%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.7.3\"><span class=\"ltx_text\" id=\"S5.T25.2.7.3.1\" style=\"font-size:80%;\">6377/8511 (74.93%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.7.4\"><span class=\"ltx_text\" id=\"S5.T25.2.7.4.1\" style=\"font-size:80%;\">2229/17309 (12.88%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T25.2.8\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_bb ltx_border_r ltx_border_t\" id=\"S5.T25.2.8.1\" rowspan=\"6\"><span class=\"ltx_text\" id=\"S5.T25.2.8.1.1\" style=\"font-size:80%;\">Medical</span></td>\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_r ltx_border_t\" id=\"S5.T25.2.8.2\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S5.T25.2.8.2.1\" style=\"font-size:80%;\">Positive</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T25.2.8.3\"><span class=\"ltx_text\" id=\"S5.T25.2.8.3.1\" style=\"font-size:80%;\">s-bert 22M</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T25.2.8.4\"><span class=\"ltx_text\" id=\"S5.T25.2.8.4.1\" style=\"font-size:80%;\">4753/4945 (96.12%)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T25.2.8.5\"><span class=\"ltx_text\" id=\"S5.T25.2.8.5.1\" style=\"font-size:80%;\">4282/4651 (92.07%)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T25.2.8.6\"><span class=\"ltx_text\" id=\"S5.T25.2.8.6.1\" style=\"font-size:80%;\">5908/5934 (99.56%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T25.2.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T25.2.9.1\"><span class=\"ltx_text\" id=\"S5.T25.2.9.1.1\" style=\"font-size:80%;\">s-gpt 1.3B</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.9.2\"><span class=\"ltx_text\" id=\"S5.T25.2.9.2.1\" style=\"font-size:80%;\">4914/4945 (99.37%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.9.3\"><span class=\"ltx_text\" id=\"S5.T25.2.9.3.1\" style=\"font-size:80%;\">4219/4651 (90.71%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.9.4\"><span class=\"ltx_text\" id=\"S5.T25.2.9.4.1\" style=\"font-size:80%;\">5909/5934 (99.58%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T25.2.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T25.2.10.1\"><span class=\"ltx_text\" id=\"S5.T25.2.10.1.1\" style=\"font-size:80%;\">s-gpt 2.7B</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.10.2\"><span class=\"ltx_text\" id=\"S5.T25.2.10.2.1\" style=\"font-size:80%;\">4910/4945 (99.29%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.10.3\"><span class=\"ltx_text\" id=\"S5.T25.2.10.3.1\" style=\"font-size:80%;\">4309/4651 (92.65%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.10.4\"><span class=\"ltx_text\" id=\"S5.T25.2.10.4.1\" style=\"font-size:80%;\">5917/5934 (99.71%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T25.2.11\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_bb ltx_border_r\" id=\"S5.T25.2.11.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S5.T25.2.11.1.1\" style=\"font-size:80%;\">Negative</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T25.2.11.2\"><span class=\"ltx_text\" id=\"S5.T25.2.11.2.1\" style=\"font-size:80%;\">s-bert 22M</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.11.3\"><span class=\"ltx_text\" id=\"S5.T25.2.11.3.1\" style=\"font-size:80%;\">5037/5260 (95.76%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.11.4\"><span class=\"ltx_text\" id=\"S5.T25.2.11.4.1\" style=\"font-size:80%;\">947/1137 (83.29%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.11.5\"><span class=\"ltx_text\" id=\"S5.T25.2.11.5.1\" style=\"font-size:80%;\">6271/6312 (99.35%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T25.2.12\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T25.2.12.1\"><span class=\"ltx_text\" id=\"S5.T25.2.12.1.1\" style=\"font-size:80%;\">s-gpt 1.3B</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.12.2\"><span class=\"ltx_text\" id=\"S5.T25.2.12.2.1\" style=\"font-size:80%;\">5216/5260 (99.16%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.12.3\"><span class=\"ltx_text\" id=\"S5.T25.2.12.3.1\" style=\"font-size:80%;\">983/1137 (86.46%)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T25.2.12.4\"><span class=\"ltx_text\" id=\"S5.T25.2.12.4.1\" style=\"font-size:80%;\">6258/6312 (99.14%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T25.2.13\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"S5.T25.2.13.1\"><span class=\"ltx_text\" id=\"S5.T25.2.13.1.1\" style=\"font-size:80%;\">s-gpt 2.7B</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T25.2.13.2\"><span class=\"ltx_text\" id=\"S5.T25.2.13.2.1\" style=\"font-size:80%;\">5220/5260 (99.24%)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T25.2.13.3\"><span class=\"ltx_text\" id=\"S5.T25.2.13.3.1\" style=\"font-size:80%;\">1017/1137 (89.45%)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T25.2.13.4\"><span class=\"ltx_text\" id=\"S5.T25.2.13.4.1\" style=\"font-size:80%;\">6280/6312 (99.49%)</span></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S5.T25.5.1.1\" style=\"font-size:113%;\">Table 25</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T25.6.2\" style=\"font-size:113%;\">Number of perturbations kept for each model after filtering with cosine similarity &gt; 0.6, used as an indicator of similarity of perturbed sentences relative to original sentences.\n</em></figcaption>\n</figure>",
            "capture": "Table 25: Number of perturbations kept for each model after filtering with cosine similarity > 0.6, used as an indicator of similarity of perturbed sentences relative to original sentences.\n"
        },
        "26": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T26\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T26.12\">\n<tr class=\"ltx_tr\" id=\"S5.T26.12.13\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T26.12.13.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.12.13.1.1\" style=\"font-size:80%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T26.12.13.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.12.13.2.1\" style=\"font-size:80%;\">Model</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"3\" id=\"S5.T26.12.13.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.12.13.3.1\" style=\"font-size:80%;\">Test set</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\" id=\"S5.T26.12.13.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.12.13.4.1\" style=\"font-size:80%;\">Perturbed test set</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T26.12.14\">\n<td class=\"ltx_td ltx_border_r\" id=\"S5.T26.12.14.1\"></td>\n<td class=\"ltx_td ltx_border_r\" id=\"S5.T26.12.14.2\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.12.14.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.12.14.3.1\" style=\"font-size:80%;\">Precision</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.12.14.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.12.14.4.1\" style=\"font-size:80%;\">Recall</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T26.12.14.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.12.14.5.1\" style=\"font-size:80%;\">F1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.12.14.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.12.14.6.1\" style=\"font-size:80%;\">Precision</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.12.14.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.12.14.7.1\" style=\"font-size:80%;\">Recall</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.12.14.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.12.14.8.1\" style=\"font-size:80%;\">F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T26.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_r ltx_border_t\" id=\"S5.T26.1.1.2\" rowspan=\"6\"><span class=\"ltx_text\" id=\"S5.T26.1.1.2.1\" style=\"font-size:80%;\">RUAR</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T26.1.1.1\">\n<span class=\"ltx_text\" id=\"S5.T26.1.1.1.1\" style=\"font-size:80%;\"> (s-bert 22M)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T26.1.1.3\"><span class=\"ltx_text\" id=\"S5.T26.1.1.3.1\" style=\"font-size:80%;\">95.68%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T26.1.1.4\"><span class=\"ltx_text\" id=\"S5.T26.1.1.4.1\" style=\"font-size:80%;\">91.29%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T26.1.1.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.1.1.5.1\" style=\"font-size:80%;\">93.44</span><span class=\"ltx_text\" id=\"S5.T26.1.1.5.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T26.1.1.6\"><span class=\"ltx_text\" id=\"S5.T26.1.1.6.1\" style=\"font-size:80%;\">94.77%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T26.1.1.7\"><span class=\"ltx_text\" id=\"S5.T26.1.1.7.1\" style=\"font-size:80%;\">71.86%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T26.1.1.8\"><span class=\"ltx_text\" id=\"S5.T26.1.1.8.1\" style=\"font-size:80%;\">81.74%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T26.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T26.2.2.1\">\n<span class=\"ltx_text\" id=\"S5.T26.2.2.1.1\" style=\"font-size:80%;\"> (s-bert 22M)</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.2.2.2\"><span class=\"ltx_text\" id=\"S5.T26.2.2.2.1\" style=\"font-size:80%;\">85.07%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.2.2.3\"><span class=\"ltx_text\" id=\"S5.T26.2.2.3.1\" style=\"font-size:80%;\">98.94%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T26.2.2.4\"><span class=\"ltx_text\" id=\"S5.T26.2.2.4.1\" style=\"font-size:80%;\">91.48%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.2.2.5\"><span class=\"ltx_text\" id=\"S5.T26.2.2.5.1\" style=\"font-size:80%;\">82.89%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.2.2.6\"><span class=\"ltx_text\" id=\"S5.T26.2.2.6.1\" style=\"font-size:80%;\">94.12%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.2.2.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.2.2.7.1\" style=\"font-size:80%;\">88.15</span><span class=\"ltx_text\" id=\"S5.T26.2.2.7.2\" style=\"font-size:80%;\">%</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T26.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T26.3.3.1\">\n<span class=\"ltx_text\" id=\"S5.T26.3.3.1.1\" style=\"font-size:80%;\"> (s-gpt 1.3B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.3.3.2\"><span class=\"ltx_text\" id=\"S5.T26.3.3.2.1\" style=\"font-size:80%;\">96.20%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.3.3.3\"><span class=\"ltx_text\" id=\"S5.T26.3.3.3.1\" style=\"font-size:80%;\">87.25%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T26.3.3.4\"><span class=\"ltx_text\" id=\"S5.T26.3.3.4.1\" style=\"font-size:80%;\">91.51%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.3.3.5\"><span class=\"ltx_text\" id=\"S5.T26.3.3.5.1\" style=\"font-size:80%;\">95.45%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.3.3.6\"><span class=\"ltx_text\" id=\"S5.T26.3.3.6.1\" style=\"font-size:80%;\">67.38%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.3.3.7\"><span class=\"ltx_text\" id=\"S5.T26.3.3.7.1\" style=\"font-size:80%;\">78.98%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T26.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T26.4.4.1\">\n<span class=\"ltx_text\" id=\"S5.T26.4.4.1.1\" style=\"font-size:80%;\"> (s-gpt 1.3B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.4.4.2\"><span class=\"ltx_text\" id=\"S5.T26.4.4.2.1\" style=\"font-size:80%;\">64.93%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.4.4.3\"><span class=\"ltx_text\" id=\"S5.T26.4.4.3.1\" style=\"font-size:80%;\">99.65%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T26.4.4.4\"><span class=\"ltx_text\" id=\"S5.T26.4.4.4.1\" style=\"font-size:80%;\">78.62%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.4.4.5\"><span class=\"ltx_text\" id=\"S5.T26.4.4.5.1\" style=\"font-size:80%;\">63.56%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.4.4.6\"><span class=\"ltx_text\" id=\"S5.T26.4.4.6.1\" style=\"font-size:80%;\">98.08%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.4.4.7\"><span class=\"ltx_text\" id=\"S5.T26.4.4.7.1\" style=\"font-size:80%;\">77.13%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T26.5.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T26.5.5.1\">\n<span class=\"ltx_text\" id=\"S5.T26.5.5.1.1\" style=\"font-size:80%;\"> (s-gpt 2.7B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.5.5.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.5.5.2.1\" style=\"font-size:80%;\">96.74</span><span class=\"ltx_text\" id=\"S5.T26.5.5.2.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.5.5.3\"><span class=\"ltx_text\" id=\"S5.T26.5.5.3.1\" style=\"font-size:80%;\">87.29%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T26.5.5.4\"><span class=\"ltx_text\" id=\"S5.T26.5.5.4.1\" style=\"font-size:80%;\">91.77%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.5.5.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.5.5.5.1\" style=\"font-size:80%;\">95.49</span><span class=\"ltx_text\" id=\"S5.T26.5.5.5.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.5.5.6\"><span class=\"ltx_text\" id=\"S5.T26.5.5.6.1\" style=\"font-size:80%;\">69.82%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.5.5.7\"><span class=\"ltx_text\" id=\"S5.T26.5.5.7.1\" style=\"font-size:80%;\">80.66%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T26.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T26.6.6.1\">\n<span class=\"ltx_text\" id=\"S5.T26.6.6.1.1\" style=\"font-size:80%;\"> (s-gpt 2.7B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.6.6.2\"><span class=\"ltx_text\" id=\"S5.T26.6.6.2.1\" style=\"font-size:80%;\">63.05%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.6.6.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.6.6.3.1\" style=\"font-size:80%;\">99.69</span><span class=\"ltx_text\" id=\"S5.T26.6.6.3.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T26.6.6.4\"><span class=\"ltx_text\" id=\"S5.T26.6.6.4.1\" style=\"font-size:80%;\">77.24%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.6.6.5\"><span class=\"ltx_text\" id=\"S5.T26.6.6.5.1\" style=\"font-size:80%;\">61.43%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.6.6.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.6.6.6.1\" style=\"font-size:80%;\">98.52</span><span class=\"ltx_text\" id=\"S5.T26.6.6.6.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.6.6.7\"><span class=\"ltx_text\" id=\"S5.T26.6.6.7.1\" style=\"font-size:80%;\">75.66%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T26.7.7\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_bb ltx_border_r ltx_border_t\" id=\"S5.T26.7.7.2\" rowspan=\"6\"><span class=\"ltx_text\" id=\"S5.T26.7.7.2.1\" style=\"font-size:80%;\">Medical</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T26.7.7.1\">\n<span class=\"ltx_text\" id=\"S5.T26.7.7.1.1\" style=\"font-size:80%;\"> (s-bert 22M)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T26.7.7.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.7.7.3.1\" style=\"font-size:80%;\">95.23</span><span class=\"ltx_text\" id=\"S5.T26.7.7.3.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T26.7.7.4\"><span class=\"ltx_text\" id=\"S5.T26.7.7.4.1\" style=\"font-size:80%;\">93.25%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T26.7.7.5\"><span class=\"ltx_text\" id=\"S5.T26.7.7.5.1\" style=\"font-size:80%;\">94.23%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T26.7.7.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.7.7.6.1\" style=\"font-size:80%;\">95.20</span><span class=\"ltx_text\" id=\"S5.T26.7.7.6.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T26.7.7.7\"><span class=\"ltx_text\" id=\"S5.T26.7.7.7.1\" style=\"font-size:80%;\">89.64%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T26.7.7.8\"><span class=\"ltx_text\" id=\"S5.T26.7.7.8.1\" style=\"font-size:80%;\">92.34%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T26.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T26.8.8.1\">\n<span class=\"ltx_text\" id=\"S5.T26.8.8.1.1\" style=\"font-size:80%;\"> (s-bert 22M)</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.8.8.2\"><span class=\"ltx_text\" id=\"S5.T26.8.8.2.1\" style=\"font-size:80%;\">93.13%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.8.8.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.8.8.3.1\" style=\"font-size:80%;\">97.17</span><span class=\"ltx_text\" id=\"S5.T26.8.8.3.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T26.8.8.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.8.8.4.1\" style=\"font-size:80%;\">95.11</span><span class=\"ltx_text\" id=\"S5.T26.8.8.4.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.8.8.5\"><span class=\"ltx_text\" id=\"S5.T26.8.8.5.1\" style=\"font-size:80%;\">92.51%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.8.8.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.8.8.6.1\" style=\"font-size:80%;\">94.93</span><span class=\"ltx_text\" id=\"S5.T26.8.8.6.2\" style=\"font-size:80%;\">%</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.8.8.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T26.8.8.7.1\" style=\"font-size:80%;\">93.70</span><span class=\"ltx_text\" id=\"S5.T26.8.8.7.2\" style=\"font-size:80%;\">%</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T26.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T26.9.9.1\">\n<span class=\"ltx_text\" id=\"S5.T26.9.9.1.1\" style=\"font-size:80%;\"> (s-gpt 1.3B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.9.9.2\"><span class=\"ltx_text\" id=\"S5.T26.9.9.2.1\" style=\"font-size:80%;\">91.93%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.9.9.3\"><span class=\"ltx_text\" id=\"S5.T26.9.9.3.1\" style=\"font-size:80%;\">88.11%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T26.9.9.4\"><span class=\"ltx_text\" id=\"S5.T26.9.9.4.1\" style=\"font-size:80%;\">89.98%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.9.9.5\"><span class=\"ltx_text\" id=\"S5.T26.9.9.5.1\" style=\"font-size:80%;\">92.17%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.9.9.6\"><span class=\"ltx_text\" id=\"S5.T26.9.9.6.1\" style=\"font-size:80%;\">84.17%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.9.9.7\"><span class=\"ltx_text\" id=\"S5.T26.9.9.7.1\" style=\"font-size:80%;\">87.98%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T26.10.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T26.10.10.1\">\n<span class=\"ltx_text\" id=\"S5.T26.10.10.1.1\" style=\"font-size:80%;\"> (s-gpt 1.3B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.10.10.2\"><span class=\"ltx_text\" id=\"S5.T26.10.10.2.1\" style=\"font-size:80%;\">84.45%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.10.10.3\"><span class=\"ltx_text\" id=\"S5.T26.10.10.3.1\" style=\"font-size:80%;\">95.71%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T26.10.10.4\"><span class=\"ltx_text\" id=\"S5.T26.10.10.4.1\" style=\"font-size:80%;\">89.72%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.10.10.5\"><span class=\"ltx_text\" id=\"S5.T26.10.10.5.1\" style=\"font-size:80%;\">84.26%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.10.10.6\"><span class=\"ltx_text\" id=\"S5.T26.10.10.6.1\" style=\"font-size:80%;\">94.24%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.10.10.7\"><span class=\"ltx_text\" id=\"S5.T26.10.10.7.1\" style=\"font-size:80%;\">88.96%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T26.11.11\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T26.11.11.1\">\n<span class=\"ltx_text\" id=\"S5.T26.11.11.1.1\" style=\"font-size:80%;\"> (s-gpt 2.7B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.11.11.2\"><span class=\"ltx_text\" id=\"S5.T26.11.11.2.1\" style=\"font-size:80%;\">93.25%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.11.11.3\"><span class=\"ltx_text\" id=\"S5.T26.11.11.3.1\" style=\"font-size:80%;\">89.29%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T26.11.11.4\"><span class=\"ltx_text\" id=\"S5.T26.11.11.4.1\" style=\"font-size:80%;\">91.23%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.11.11.5\"><span class=\"ltx_text\" id=\"S5.T26.11.11.5.1\" style=\"font-size:80%;\">92.89%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.11.11.6\"><span class=\"ltx_text\" id=\"S5.T26.11.11.6.1\" style=\"font-size:80%;\">84.79%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T26.11.11.7\"><span class=\"ltx_text\" id=\"S5.T26.11.11.7.1\" style=\"font-size:80%;\">88.66%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T26.12.12\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"S5.T26.12.12.1\">\n<span class=\"ltx_text\" id=\"S5.T26.12.12.1.1\" style=\"font-size:80%;\"> (s-gpt 2.7B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T26.12.12.2\"><span class=\"ltx_text\" id=\"S5.T26.12.12.2.1\" style=\"font-size:80%;\">86.82%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T26.12.12.3\"><span class=\"ltx_text\" id=\"S5.T26.12.12.3.1\" style=\"font-size:80%;\">96.56%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S5.T26.12.12.4\"><span class=\"ltx_text\" id=\"S5.T26.12.12.4.1\" style=\"font-size:80%;\">91.43%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T26.12.12.5\"><span class=\"ltx_text\" id=\"S5.T26.12.12.5.1\" style=\"font-size:80%;\">85.60%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T26.12.12.6\"><span class=\"ltx_text\" id=\"S5.T26.12.12.6.1\" style=\"font-size:80%;\">94.74%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T26.12.12.7\"><span class=\"ltx_text\" id=\"S5.T26.12.12.7.1\" style=\"font-size:80%;\">89.93%</span></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S5.T26.17.2.1\" style=\"font-size:113%;\">Table 26</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T26.14.1\" style=\"font-size:113%;\">Performance of the models on the test/perturbation set, after filtering.\nThe average standard deviation is .</em></figcaption>\n</figure>",
            "capture": "Table 26: Performance of the models on the test/perturbation set, after filtering.\nThe average standard deviation is ."
        },
        "27": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T27\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T27.2\">\n<tr class=\"ltx_tr\" id=\"S5.T27.2.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S5.T27.2.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.1.1.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.1.1.1.1\" style=\"width:28.2pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T27.2.1.1.1.1.1\" style=\"font-size:80%;\">Dataset</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S5.T27.2.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.1.2.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.1.2.1.1\" style=\"width:45.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T27.2.1.2.1.1.1\" style=\"font-size:80%;\">ROUGE-N</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_tt\" colspan=\"4\" id=\"S5.T27.2.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T27.2.1.3.1\" style=\"font-size:80%;\">Precision</span></td>\n<td class=\"ltx_td ltx_align_center ltx_align_top ltx_border_tt\" colspan=\"4\" id=\"S5.T27.2.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T27.2.1.4.1\" style=\"font-size:80%;\">Recall</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T27.2.2\">\n<td class=\"ltx_td ltx_align_top ltx_border_r\" id=\"S5.T27.2.2.1\"></td>\n<td class=\"ltx_td ltx_align_top ltx_border_r\" id=\"S5.T27.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.2.3.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.2.3.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.2.3.1.1.1\" style=\"font-size:80%;\">No </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S5.T27.2.2.3.1.1.2\" style=\"font-size:80%;\">filtering</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_align_top ltx_border_r\" colspan=\"3\" id=\"S5.T27.2.2.4\"><span class=\"ltx_text\" id=\"S5.T27.2.2.4.1\" style=\"font-size:80%;\">Filtering</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.2.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.2.5.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.2.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.2.5.1.1.1\" style=\"font-size:80%;\">No </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S5.T27.2.2.5.1.1.2\" style=\"font-size:80%;\">filtering</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_align_top\" colspan=\"3\" id=\"S5.T27.2.2.6\"><span class=\"ltx_text\" id=\"S5.T27.2.2.6.1\" style=\"font-size:80%;\">Filtering</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T27.2.3\">\n<td class=\"ltx_td ltx_align_top ltx_border_r\" id=\"S5.T27.2.3.1\"></td>\n<td class=\"ltx_td ltx_align_top ltx_border_r\" id=\"S5.T27.2.3.2\"></td>\n<td class=\"ltx_td ltx_align_top\" id=\"S5.T27.2.3.3\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.3.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.3.4.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.3.4.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.3.4.1.1.1\" style=\"font-size:80%;\">s-bert 22M</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.3.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.3.5.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.3.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.3.5.1.1.1\" style=\"font-size:80%;\">s-gpt 1.3B</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S5.T27.2.3.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.3.6.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.3.6.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.3.6.1.1.1\" style=\"font-size:80%;\">s-gpt 2.7B</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_top\" id=\"S5.T27.2.3.7\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.3.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.3.8.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.3.8.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.3.8.1.1.1\" style=\"font-size:80%;\">s-bert 22M</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.3.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.3.9.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.3.9.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.3.9.1.1.1\" style=\"font-size:80%;\">s-gpt 1.3B</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.3.10\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.3.10.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.3.10.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.3.10.1.1.1\" style=\"font-size:80%;\">s-gpt 2.7B</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T27.2.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t\" id=\"S5.T27.2.4.1\" rowspan=\"3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.4.1.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.4.1.1.1\" style=\"width:28.2pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.4.1.1.1.1\" style=\"font-size:80%;\">RUAR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T27.2.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.4.2.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.4.2.1.1\" style=\"width:45.5pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.4.2.1.1.1\" style=\"font-size:80%;\">ROUGE-1</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T27.2.4.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.4.3.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.4.3.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.4.3.1.1.1\" style=\"font-size:80%;\">0.500</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T27.2.4.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.4.4.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.4.4.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.4.4.1.1.1\" style=\"font-size:80%;\">0.568</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T27.2.4.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.4.5.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.4.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.4.5.1.1.1\" style=\"font-size:80%;\">0.545</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T27.2.4.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.4.6.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.4.6.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.4.6.1.1.1\" style=\"font-size:80%;\">0.537</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T27.2.4.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.4.7.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.4.7.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.4.7.1.1.1\" style=\"font-size:80%;\">0.281</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T27.2.4.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.4.8.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.4.8.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.4.8.1.1.1\" style=\"font-size:80%;\">0.635</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T27.2.4.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.4.9.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.4.9.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.4.9.1.1.1\" style=\"font-size:80%;\">0.612</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T27.2.4.10\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.4.10.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.4.10.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.4.10.1.1.1\" style=\"font-size:80%;\">0.604</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T27.2.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S5.T27.2.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.5.1.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.5.1.1.1\" style=\"width:45.5pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.5.1.1.1.1\" style=\"font-size:80%;\">ROUGE-2</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.5.2.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.5.2.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.5.2.1.1.1\" style=\"font-size:80%;\">0.557</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.5.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.5.3.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.5.3.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.5.3.1.1.1\" style=\"font-size:80%;\">0.342</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.5.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.5.4.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.5.4.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.5.4.1.1.1\" style=\"font-size:80%;\">0.320</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S5.T27.2.5.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.5.5.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.5.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.5.5.1.1.1\" style=\"font-size:80%;\">0.314</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.5.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.5.6.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.5.6.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.5.6.1.1.1\" style=\"font-size:80%;\">0.312</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.5.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.5.7.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.5.7.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.5.7.1.1.1\" style=\"font-size:80%;\">0.382</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.5.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.5.8.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.5.8.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.5.8.1.1.1\" style=\"font-size:80%;\">0.358</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.5.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.5.9.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.5.9.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.5.9.1.1.1\" style=\"font-size:80%;\">0.352</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T27.2.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S5.T27.2.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.6.1.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.6.1.1.1\" style=\"width:45.5pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.6.1.1.1.1\" style=\"font-size:80%;\">ROUGE-3</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.6.2.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.6.2.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.6.2.1.1.1\" style=\"font-size:80%;\">0.511</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.6.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.6.3.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.6.3.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.6.3.1.1.1\" style=\"font-size:80%;\">0.208</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.6.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.6.4.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.6.4.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.6.4.1.1.1\" style=\"font-size:80%;\">0.190</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S5.T27.2.6.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.6.5.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.6.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.6.5.1.1.1\" style=\"font-size:80%;\">0.185</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.6.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.6.6.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.6.6.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.6.6.1.1.1\" style=\"font-size:80%;\">0.285</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.6.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.6.7.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.6.7.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.6.7.1.1.1\" style=\"font-size:80%;\">0.230</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.6.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.6.8.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.6.8.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.6.8.1.1.1\" style=\"font-size:80%;\">0.210</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.6.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.6.9.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.6.9.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.6.9.1.1.1\" style=\"font-size:80%;\">0.205</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T27.2.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb ltx_border_r ltx_border_t\" id=\"S5.T27.2.7.1\" rowspan=\"3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.7.1.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.7.1.1.1\" style=\"width:28.2pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.7.1.1.1.1\" style=\"font-size:80%;\">Medical</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T27.2.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.7.2.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.7.2.1.1\" style=\"width:45.5pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.7.2.1.1.1\" style=\"font-size:80%;\">ROUGE-1</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T27.2.7.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.7.3.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.7.3.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.7.3.1.1.1\" style=\"font-size:80%;\">0.451</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T27.2.7.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.7.4.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.7.4.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.7.4.1.1.1\" style=\"font-size:80%;\">0.466</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T27.2.7.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.7.5.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.7.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.7.5.1.1.1\" style=\"font-size:80%;\">0.469</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T27.2.7.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.7.6.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.7.6.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.7.6.1.1.1\" style=\"font-size:80%;\">0.465</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T27.2.7.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.7.7.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.7.7.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.7.7.1.1.1\" style=\"font-size:80%;\">0.230</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T27.2.7.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.7.8.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.7.8.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.7.8.1.1.1\" style=\"font-size:80%;\">0.553</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T27.2.7.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.7.9.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.7.9.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.7.9.1.1.1\" style=\"font-size:80%;\">0.555</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T27.2.7.10\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.7.10.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.7.10.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.7.10.1.1.1\" style=\"font-size:80%;\">0.551</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T27.2.8\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S5.T27.2.8.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.8.1.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.8.1.1.1\" style=\"width:45.5pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.8.1.1.1.1\" style=\"font-size:80%;\">ROUGE-2</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.8.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.8.2.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.8.2.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.8.2.1.1.1\" style=\"font-size:80%;\">0.529</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.8.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.8.3.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.8.3.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.8.3.1.1.1\" style=\"font-size:80%;\">0.242</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.8.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.8.4.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.8.4.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.8.4.1.1.1\" style=\"font-size:80%;\">0.246</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S5.T27.2.8.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.8.5.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.8.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.8.5.1.1.1\" style=\"font-size:80%;\">0.243</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.8.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.8.6.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.8.6.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.8.6.1.1.1\" style=\"font-size:80%;\">0.268</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.8.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.8.7.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.8.7.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.8.7.1.1.1\" style=\"font-size:80%;\">0.285</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.8.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.8.8.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.8.8.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.8.8.1.1.1\" style=\"font-size:80%;\">0.288</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T27.2.8.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.8.9.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.8.9.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.8.9.1.1.1\" style=\"font-size:80%;\">0.285</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T27.2.9\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S5.T27.2.9.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.9.1.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.9.1.1.1\" style=\"width:45.5pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.9.1.1.1.1\" style=\"font-size:80%;\">ROUGE-3</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S5.T27.2.9.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.9.2.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.9.2.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.9.2.1.1.1\" style=\"font-size:80%;\">0.471</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S5.T27.2.9.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.9.3.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.9.3.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.9.3.1.1.1\" style=\"font-size:80%;\">0.131</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S5.T27.2.9.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.9.4.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.9.4.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.9.4.1.1.1\" style=\"font-size:80%;\">0.135</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S5.T27.2.9.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.9.5.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.9.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.9.5.1.1.1\" style=\"font-size:80%;\">0.133</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S5.T27.2.9.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.9.6.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.9.6.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.9.6.1.1.1\" style=\"font-size:80%;\">0.238</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S5.T27.2.9.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.9.7.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.9.7.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.9.7.1.1.1\" style=\"font-size:80%;\">0.156</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S5.T27.2.9.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.9.8.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.9.8.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.9.8.1.1.1\" style=\"font-size:80%;\">0.159</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S5.T27.2.9.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T27.2.9.9.1\">\n<span class=\"ltx_p\" id=\"S5.T27.2.9.9.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T27.2.9.9.1.1.1\" style=\"font-size:80%;\">0.157</span></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S5.T27.6.1.1\" style=\"font-size:113%;\">Table 27</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T27.7.2\" style=\"font-size:113%;\">ROUGE-N scores comparing the original samples with Vicuna perturbations (of the positive class) for lexical overlap.</em><span class=\"ltx_text\" id=\"S5.T27.8.3\" style=\"font-size:113%;\">\n</span></figcaption>\n</figure>",
            "capture": "Table 27: ROUGE-N scores comparing the original samples with Vicuna perturbations (of the positive class) for lexical overlap.\n"
        },
        "28": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T28\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T28.2\">\n<tr class=\"ltx_tr\" id=\"S5.T28.2.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S5.T28.2.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.1.1.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.1.1.1.1\" style=\"width:28.2pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T28.2.1.1.1.1.1\" style=\"font-size:80%;\">Dataset</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" id=\"S5.T28.2.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.1.2.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.1.2.1.1\" style=\"width:45.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T28.2.1.2.1.1.1\" style=\"font-size:80%;\">ROUGE-N</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_tt\" colspan=\"4\" id=\"S5.T28.2.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T28.2.1.3.1\" style=\"font-size:80%;\">Precision</span></td>\n<td class=\"ltx_td ltx_align_center ltx_align_top ltx_border_tt\" colspan=\"4\" id=\"S5.T28.2.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T28.2.1.4.1\" style=\"font-size:80%;\">Recall</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T28.2.2\">\n<td class=\"ltx_td ltx_align_top ltx_border_r\" id=\"S5.T28.2.2.1\"></td>\n<td class=\"ltx_td ltx_align_top ltx_border_r\" id=\"S5.T28.2.2.2\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.2.3.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.2.3.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.2.3.1.1.1\" style=\"font-size:80%;\">No </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S5.T28.2.2.3.1.1.2\" style=\"font-size:80%;\">filtering</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_align_top ltx_border_r\" colspan=\"3\" id=\"S5.T28.2.2.4\"><span class=\"ltx_text\" id=\"S5.T28.2.2.4.1\" style=\"font-size:80%;\">Filtering</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.2.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.2.5.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.2.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.2.5.1.1.1\" style=\"font-size:80%;\">No </span>\n<br class=\"ltx_break\"/><span class=\"ltx_text\" id=\"S5.T28.2.2.5.1.1.2\" style=\"font-size:80%;\">filtering</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_align_top\" colspan=\"3\" id=\"S5.T28.2.2.6\"><span class=\"ltx_text\" id=\"S5.T28.2.2.6.1\" style=\"font-size:80%;\">Filtering</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T28.2.3\">\n<td class=\"ltx_td ltx_align_top ltx_border_r\" id=\"S5.T28.2.3.1\"></td>\n<td class=\"ltx_td ltx_align_top ltx_border_r\" id=\"S5.T28.2.3.2\"></td>\n<td class=\"ltx_td ltx_align_top\" id=\"S5.T28.2.3.3\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.3.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.3.4.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.3.4.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.3.4.1.1.1\" style=\"font-size:80%;\">s-bert 22M</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.3.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.3.5.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.3.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.3.5.1.1.1\" style=\"font-size:80%;\">s-gpt 1.3B</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S5.T28.2.3.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.3.6.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.3.6.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.3.6.1.1.1\" style=\"font-size:80%;\">s-gpt 2.7B</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_top\" id=\"S5.T28.2.3.7\"></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.3.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.3.8.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.3.8.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.3.8.1.1.1\" style=\"font-size:80%;\">s-bert 22M</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.3.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.3.9.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.3.9.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.3.9.1.1.1\" style=\"font-size:80%;\">s-gpt 1.3B</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.3.10\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.3.10.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.3.10.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.3.10.1.1.1\" style=\"font-size:80%;\">s-gpt 2.7B</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T28.2.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t\" id=\"S5.T28.2.4.1\" rowspan=\"3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.4.1.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.4.1.1.1\" style=\"width:28.2pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.4.1.1.1.1\" style=\"font-size:80%;\">RUAR</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T28.2.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.4.2.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.4.2.1.1\" style=\"width:45.5pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.4.2.1.1.1\" style=\"font-size:80%;\">ROUGE-1</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T28.2.4.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.4.3.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.4.3.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.4.3.1.1.1\" style=\"font-size:80%;\">0.731</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T28.2.4.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.4.4.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.4.4.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.4.4.1.1.1\" style=\"font-size:80%;\">0.748</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T28.2.4.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.4.5.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.4.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.4.5.1.1.1\" style=\"font-size:80%;\">0.747</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T28.2.4.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.4.6.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.4.6.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.4.6.1.1.1\" style=\"font-size:80%;\">0.743</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T28.2.4.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.4.7.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.4.7.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.4.7.1.1.1\" style=\"font-size:80%;\">0.501</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T28.2.4.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.4.8.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.4.8.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.4.8.1.1.1\" style=\"font-size:80%;\">0.767</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T28.2.4.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.4.9.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.4.9.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.4.9.1.1.1\" style=\"font-size:80%;\">0.769</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T28.2.4.10\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.4.10.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.4.10.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.4.10.1.1.1\" style=\"font-size:80%;\">0.765</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T28.2.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S5.T28.2.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.5.1.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.5.1.1.1\" style=\"width:45.5pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.5.1.1.1.1\" style=\"font-size:80%;\">ROUGE-2</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.5.2.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.5.2.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.5.2.1.1.1\" style=\"font-size:80%;\">0.738</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.5.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.5.3.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.5.3.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.5.3.1.1.1\" style=\"font-size:80%;\">0.524</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.5.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.5.4.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.5.4.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.5.4.1.1.1\" style=\"font-size:80%;\">0.521</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S5.T28.2.5.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.5.5.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.5.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.5.5.1.1.1\" style=\"font-size:80%;\">0.514</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.5.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.5.6.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.5.6.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.5.6.1.1.1\" style=\"font-size:80%;\">0.504</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.5.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.5.7.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.5.7.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.5.7.1.1.1\" style=\"font-size:80%;\">0.532</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.5.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.5.8.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.5.8.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.5.8.1.1.1\" style=\"font-size:80%;\">0.532</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.5.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.5.9.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.5.9.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.5.9.1.1.1\" style=\"font-size:80%;\">0.525</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T28.2.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S5.T28.2.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.6.1.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.6.1.1.1\" style=\"width:45.5pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.6.1.1.1.1\" style=\"font-size:80%;\">ROUGE-3</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.6.2.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.6.2.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.6.2.1.1.1\" style=\"font-size:80%;\">0.710</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.6.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.6.3.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.6.3.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.6.3.1.1.1\" style=\"font-size:80%;\">0.350</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.6.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.6.4.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.6.4.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.6.4.1.1.1\" style=\"font-size:80%;\">0.347</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S5.T28.2.6.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.6.5.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.6.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.6.5.1.1.1\" style=\"font-size:80%;\">0.340</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.6.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.6.6.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.6.6.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.6.6.1.1.1\" style=\"font-size:80%;\">0.483</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.6.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.6.7.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.6.7.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.6.7.1.1.1\" style=\"font-size:80%;\">0.349</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.6.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.6.8.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.6.8.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.6.8.1.1.1\" style=\"font-size:80%;\">0.346</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.6.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.6.9.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.6.9.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.6.9.1.1.1\" style=\"font-size:80%;\">0.339</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T28.2.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb ltx_border_r ltx_border_t\" id=\"S5.T28.2.7.1\" rowspan=\"3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.7.1.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.7.1.1.1\" style=\"width:28.2pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.7.1.1.1.1\" style=\"font-size:80%;\">Medical</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T28.2.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.7.2.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.7.2.1.1\" style=\"width:45.5pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.7.2.1.1.1\" style=\"font-size:80%;\">ROUGE-1</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T28.2.7.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.7.3.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.7.3.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.7.3.1.1.1\" style=\"font-size:80%;\">0.670</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T28.2.7.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.7.4.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.7.4.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.7.4.1.1.1\" style=\"font-size:80%;\">0.674</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T28.2.7.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.7.5.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.7.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.7.5.1.1.1\" style=\"font-size:80%;\">0.678</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S5.T28.2.7.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.7.6.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.7.6.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.7.6.1.1.1\" style=\"font-size:80%;\">0.676</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T28.2.7.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.7.7.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.7.7.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.7.7.1.1.1\" style=\"font-size:80%;\">0.410</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T28.2.7.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.7.8.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.7.8.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.7.8.1.1.1\" style=\"font-size:80%;\">0.710</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T28.2.7.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.7.9.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.7.9.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.7.9.1.1.1\" style=\"font-size:80%;\">0.714</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S5.T28.2.7.10\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.7.10.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.7.10.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.7.10.1.1.1\" style=\"font-size:80%;\">0.712</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T28.2.8\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S5.T28.2.8.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.8.1.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.8.1.1.1\" style=\"width:45.5pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.8.1.1.1.1\" style=\"font-size:80%;\">ROUGE-2</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.8.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.8.2.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.8.2.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.8.2.1.1.1\" style=\"font-size:80%;\">0.694</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.8.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.8.3.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.8.3.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.8.3.1.1.1\" style=\"font-size:80%;\">0.415</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.8.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.8.4.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.8.4.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.8.4.1.1.1\" style=\"font-size:80%;\">0.422</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"S5.T28.2.8.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.8.5.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.8.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.8.5.1.1.1\" style=\"font-size:80%;\">0.419</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.8.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.8.6.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.8.6.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.8.6.1.1.1\" style=\"font-size:80%;\">0.422</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.8.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.8.7.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.8.7.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.8.7.1.1.1\" style=\"font-size:80%;\">0.434</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.8.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.8.8.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.8.8.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.8.8.1.1.1\" style=\"font-size:80%;\">0.441</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S5.T28.2.8.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.8.9.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.8.9.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.8.9.1.1.1\" style=\"font-size:80%;\">0.438</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T28.2.9\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S5.T28.2.9.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.9.1.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.9.1.1.1\" style=\"width:45.5pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.9.1.1.1.1\" style=\"font-size:80%;\">ROUGE-3</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S5.T28.2.9.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.9.2.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.9.2.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.9.2.1.1.1\" style=\"font-size:80%;\">0.657</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S5.T28.2.9.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.9.3.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.9.3.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.9.3.1.1.1\" style=\"font-size:80%;\">0.247</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S5.T28.2.9.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.9.4.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.9.4.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.9.4.1.1.1\" style=\"font-size:80%;\">0.254</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\" id=\"S5.T28.2.9.5\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.9.5.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.9.5.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.9.5.1.1.1\" style=\"font-size:80%;\">0.252</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S5.T28.2.9.6\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.9.6.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.9.6.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.9.6.1.1.1\" style=\"font-size:80%;\">0.399</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S5.T28.2.9.7\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.9.7.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.9.7.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.9.7.1.1.1\" style=\"font-size:80%;\">0.258</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S5.T28.2.9.8\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.9.8.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.9.8.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.9.8.1.1.1\" style=\"font-size:80%;\">0.263</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" id=\"S5.T28.2.9.9\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.T28.2.9.9.1\">\n<span class=\"ltx_p\" id=\"S5.T28.2.9.9.1.1\" style=\"width:30.4pt;\"><span class=\"ltx_text\" id=\"S5.T28.2.9.9.1.1.1\" style=\"font-size:80%;\">0.260</span></span>\n</span>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S5.T28.5.1.1\" style=\"font-size:113%;\">Table 28</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T28.6.2\" style=\"font-size:113%;\">ROUGE-N scores comparing the original samples with Vicuna perturbations (of the positive class) for syntax overlap.</em></figcaption>\n</figure>",
            "capture": "Table 28: ROUGE-N scores comparing the original samples with Vicuna perturbations (of the positive class) for syntax overlap."
        },
        "29": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T29\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T29.14\">\n<tr class=\"ltx_tr\" id=\"S5.T29.14.15\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T29.14.15.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T29.14.15.1.1\" style=\"font-size:80%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S5.T29.14.15.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T29.14.15.2.1\" style=\"font-size:80%;\">Model</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S5.T29.14.15.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T29.14.15.3.1\" style=\"font-size:80%;\">Verifiability</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" id=\"S5.T29.14.15.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T29.14.15.4.1\" style=\"font-size:80%;\">Generalisability</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_tt\" colspan=\"2\" id=\"S5.T29.14.15.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T29.14.15.5.1\" style=\"font-size:80%;\">Falsifiability</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_tt\" colspan=\"2\" id=\"S5.T29.14.15.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T29.14.15.6.1\" style=\"font-size:80%;\">False Positives</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.14.16\">\n<td class=\"ltx_td ltx_border_r\" id=\"S5.T29.14.16.1\"></td>\n<td class=\"ltx_td ltx_border_r\" id=\"S5.T29.14.16.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T29.14.16.3\"><span class=\"ltx_text\" id=\"S5.T29.14.16.3.1\" style=\"font-size:80%;\">%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.14.16.4\"><span class=\"ltx_text\" id=\"S5.T29.14.16.4.1\" style=\"font-size:80%;\">#</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.14.16.5\"><span class=\"ltx_text\" id=\"S5.T29.14.16.5.1\" style=\"font-size:80%;\">%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.14.16.6\"><span class=\"ltx_text\" id=\"S5.T29.14.16.6.1\" style=\"font-size:80%;\">#</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.14.16.7\"><span class=\"ltx_text\" id=\"S5.T29.14.16.7.1\" style=\"font-size:80%;\">%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.14.16.8\"><span class=\"ltx_text\" id=\"S5.T29.14.16.8.1\" style=\"font-size:80%;\">#</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.14.16.9\"><span class=\"ltx_text\" id=\"S5.T29.14.16.9.1\" style=\"font-size:80%;\">%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_r ltx_border_t\" id=\"S5.T29.1.1.2\" rowspan=\"7\"><span class=\"ltx_text\" id=\"S5.T29.1.1.2.1\" style=\"font-size:80%;\">RUAR</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T29.1.1.1\">\n<span class=\"ltx_text\" id=\"S5.T29.1.1.1.1\" style=\"font-size:80%;\"> (s-bert 22M)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T29.1.1.3\"><span class=\"ltx_text\" id=\"S5.T29.1.1.3.1\" style=\"font-size:80%;\">2.56</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T29.1.1.4\"><span class=\"ltx_text\" id=\"S5.T29.1.1.4.1\" style=\"font-size:80%;\">1256/44013</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S5.T29.1.1.5\"><span class=\"ltx_text\" id=\"S5.T29.1.1.5.1\" style=\"font-size:80%;\">2.85</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T29.1.1.6\"><span class=\"ltx_text\" id=\"S5.T29.1.1.6.1\" style=\"font-size:80%;\">1/3400</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S5.T29.1.1.7\"><span class=\"ltx_text\" id=\"S5.T29.1.1.7.1\" style=\"font-size:80%;\">0.03</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T29.1.1.8\"><span class=\"ltx_text\" id=\"S5.T29.1.1.8.1\" style=\"font-size:80%;\">27/40270</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T29.1.1.9\"><span class=\"ltx_text\" id=\"S5.T29.1.1.9.1\" style=\"font-size:80%;\">0.07</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T29.2.2.1\">\n<span class=\"ltx_text\" id=\"S5.T29.2.2.1.1\" style=\"font-size:80%;\"> (s-bert 22M)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T29.2.2.2\"><span class=\"ltx_text\" id=\"S5.T29.2.2.2.1\" style=\"font-size:80%;\">15.92</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.2.2.3\"><span class=\"ltx_text\" id=\"S5.T29.2.2.3.1\" style=\"font-size:80%;\">8361/44013</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.2.2.4\"><span class=\"ltx_text\" id=\"S5.T29.2.2.4.1\" style=\"font-size:80%;\">19.00</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.2.2.5\"><span class=\"ltx_text\" id=\"S5.T29.2.2.5.1\" style=\"font-size:80%;\">1/3400</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.2.2.6\"><span class=\"ltx_text\" id=\"S5.T29.2.2.6.1\" style=\"font-size:80%;\">0.03</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.2.2.7\"><span class=\"ltx_text\" id=\"S5.T29.2.2.7.1\" style=\"font-size:80%;\">72/40270</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.2.2.8\"><span class=\"ltx_text\" id=\"S5.T29.2.2.8.1\" style=\"font-size:80%;\">0.18</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T29.3.3.1\">\n<span class=\"ltx_text\" id=\"S5.T29.3.3.1.1\" style=\"font-size:80%;\"> (s-bert 22M)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T29.3.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T29.3.3.2.1\" style=\"font-size:80%;\">21.89</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.3.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T29.3.3.3.1\" style=\"font-size:80%;\">9530/44013</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.3.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T29.3.3.4.1\" style=\"font-size:80%;\">21.65</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.3.3.5\"><span class=\"ltx_text\" id=\"S5.T29.3.3.5.1\" style=\"font-size:80%;\">3/3400</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.3.3.6\"><span class=\"ltx_text\" id=\"S5.T29.3.3.6.1\" style=\"font-size:80%;\">0.09</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.3.3.7\"><span class=\"ltx_text\" id=\"S5.T29.3.3.7.1\" style=\"font-size:80%;\">101/40270</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.3.3.8\"><span class=\"ltx_text\" id=\"S5.T29.3.3.8.1\" style=\"font-size:80%;\">0.25</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T29.4.4.1\">\n<span class=\"ltx_text\" id=\"S5.T29.4.4.1.1\" style=\"font-size:80%;\"> (s-gpt 1.3B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T29.4.4.2\"><span class=\"ltx_text\" id=\"S5.T29.4.4.2.1\" style=\"font-size:80%;\">0.34</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.4.4.3\"><span class=\"ltx_text\" id=\"S5.T29.4.4.3.1\" style=\"font-size:80%;\">128/44013</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.4.4.4\"><span class=\"ltx_text\" id=\"S5.T29.4.4.4.1\" style=\"font-size:80%;\">0.29</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.4.4.5\"><span class=\"ltx_text\" id=\"S5.T29.4.4.5.1\" style=\"font-size:80%;\">0/3400</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.4.4.6\"><span class=\"ltx_text\" id=\"S5.T29.4.4.6.1\" style=\"font-size:80%;\">0.00</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.4.4.7\"><span class=\"ltx_text\" id=\"S5.T29.4.4.7.1\" style=\"font-size:80%;\">0/40270</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.4.4.8\"><span class=\"ltx_text\" id=\"S5.T29.4.4.8.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.5.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T29.5.5.1\">\n<span class=\"ltx_text\" id=\"S5.T29.5.5.1.1\" style=\"font-size:80%;\"> (s-gpt 1.3B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T29.5.5.2\"><span class=\"ltx_text\" id=\"S5.T29.5.5.2.1\" style=\"font-size:80%;\">11.27</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.5.5.3\"><span class=\"ltx_text\" id=\"S5.T29.5.5.3.1\" style=\"font-size:80%;\">5633/44013</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.5.5.4\"><span class=\"ltx_text\" id=\"S5.T29.5.5.4.1\" style=\"font-size:80%;\">12.80</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.5.5.5\"><span class=\"ltx_text\" id=\"S5.T29.5.5.5.1\" style=\"font-size:80%;\">2/3400</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.5.5.6\"><span class=\"ltx_text\" id=\"S5.T29.5.5.6.1\" style=\"font-size:80%;\">0.06</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.5.5.7\"><span class=\"ltx_text\" id=\"S5.T29.5.5.7.1\" style=\"font-size:80%;\">27/40270</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.5.5.8\"><span class=\"ltx_text\" id=\"S5.T29.5.5.8.1\" style=\"font-size:80%;\">0.07</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T29.6.6.1\">\n<span class=\"ltx_text\" id=\"S5.T29.6.6.1.1\" style=\"font-size:80%;\"> (s-gpt 2.7B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T29.6.6.2\"><span class=\"ltx_text\" id=\"S5.T29.6.6.2.1\" style=\"font-size:80%;\">0.35</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.6.6.3\"><span class=\"ltx_text\" id=\"S5.T29.6.6.3.1\" style=\"font-size:80%;\">183/44013</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.6.6.4\"><span class=\"ltx_text\" id=\"S5.T29.6.6.4.1\" style=\"font-size:80%;\">0.42</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.6.6.5\"><span class=\"ltx_text\" id=\"S5.T29.6.6.5.1\" style=\"font-size:80%;\">0/3400</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.6.6.6\"><span class=\"ltx_text\" id=\"S5.T29.6.6.6.1\" style=\"font-size:80%;\">0.00</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.6.6.7\"><span class=\"ltx_text\" id=\"S5.T29.6.6.7.1\" style=\"font-size:80%;\">0/40270</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.6.6.8\"><span class=\"ltx_text\" id=\"S5.T29.6.6.8.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.7.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T29.7.7.1\">\n<span class=\"ltx_text\" id=\"S5.T29.7.7.1.1\" style=\"font-size:80%;\"> (s-gpt 2.7B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T29.7.7.2\"><span class=\"ltx_text\" id=\"S5.T29.7.7.2.1\" style=\"font-size:80%;\">11.63</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.7.7.3\"><span class=\"ltx_text\" id=\"S5.T29.7.7.3.1\" style=\"font-size:80%;\">5950/44013</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.7.7.4\"><span class=\"ltx_text\" id=\"S5.T29.7.7.4.1\" style=\"font-size:80%;\">13.52</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.7.7.5\"><span class=\"ltx_text\" id=\"S5.T29.7.7.5.1\" style=\"font-size:80%;\">1/3400</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.7.7.6\"><span class=\"ltx_text\" id=\"S5.T29.7.7.6.1\" style=\"font-size:80%;\">0.03</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.7.7.7\"><span class=\"ltx_text\" id=\"S5.T29.7.7.7.1\" style=\"font-size:80%;\">18/40270</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.7.7.8\"><span class=\"ltx_text\" id=\"S5.T29.7.7.8.1\" style=\"font-size:80%;\">0.04</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_align_middle ltx_border_bb ltx_border_r ltx_border_t\" id=\"S5.T29.8.8.2\" rowspan=\"7\"><span class=\"ltx_text\" id=\"S5.T29.8.8.2.1\" style=\"font-size:80%;\">Medical</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T29.8.8.1\">\n<span class=\"ltx_text\" id=\"S5.T29.8.8.1.1\" style=\"font-size:80%;\"> (s-bert 22M)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T29.8.8.3\"><span class=\"ltx_text\" id=\"S5.T29.8.8.3.1\" style=\"font-size:80%;\">58.71</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T29.8.8.4\"><span class=\"ltx_text\" id=\"S5.T29.8.8.4.1\" style=\"font-size:80%;\">9135/15530</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S5.T29.8.8.5\"><span class=\"ltx_text\" id=\"S5.T29.8.8.5.1\" style=\"font-size:80%;\">58.82</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T29.8.8.6\"><span class=\"ltx_text\" id=\"S5.T29.8.8.6.1\" style=\"font-size:80%;\">0/989</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S5.T29.8.8.7\"><span class=\"ltx_text\" id=\"S5.T29.8.8.7.1\" style=\"font-size:80%;\">0.00</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T29.8.8.8\"><span class=\"ltx_text\" id=\"S5.T29.8.8.8.1\" style=\"font-size:80%;\">0/12709</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T29.8.8.9\"><span class=\"ltx_text\" id=\"S5.T29.8.8.9.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T29.9.9.1\">\n<span class=\"ltx_text\" id=\"S5.T29.9.9.1.1\" style=\"font-size:80%;\"> (s-bert 22M)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T29.9.9.2\"><span class=\"ltx_text\" id=\"S5.T29.9.9.2.1\" style=\"font-size:80%;\">70.61</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.9.9.3\"><span class=\"ltx_text\" id=\"S5.T29.9.9.3.1\" style=\"font-size:80%;\">10879/15530</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.9.9.4\"><span class=\"ltx_text\" id=\"S5.T29.9.9.4.1\" style=\"font-size:80%;\">70.05</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.9.9.5\"><span class=\"ltx_text\" id=\"S5.T29.9.9.5.1\" style=\"font-size:80%;\">0/989</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.9.9.6\"><span class=\"ltx_text\" id=\"S5.T29.9.9.6.1\" style=\"font-size:80%;\">0.00</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.9.9.7\"><span class=\"ltx_text\" id=\"S5.T29.9.9.7.1\" style=\"font-size:80%;\">0/12709</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.9.9.8\"><span class=\"ltx_text\" id=\"S5.T29.9.9.8.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.10.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T29.10.10.1\">\n<span class=\"ltx_text\" id=\"S5.T29.10.10.1.1\" style=\"font-size:80%;\"> (s-bert 22M)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T29.10.10.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T29.10.10.2.1\" style=\"font-size:80%;\">73.47</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.10.10.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T29.10.10.3.1\" style=\"font-size:80%;\">10964/15530</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.10.10.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T29.10.10.4.1\" style=\"font-size:80%;\">70.6</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.10.10.5\"><span class=\"ltx_text\" id=\"S5.T29.10.10.5.1\" style=\"font-size:80%;\">0/989</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.10.10.6\"><span class=\"ltx_text\" id=\"S5.T29.10.10.6.1\" style=\"font-size:80%;\">0.00</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.10.10.7\"><span class=\"ltx_text\" id=\"S5.T29.10.10.7.1\" style=\"font-size:80%;\">0/12709</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.10.10.8\"><span class=\"ltx_text\" id=\"S5.T29.10.10.8.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.11.11\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T29.11.11.1\">\n<span class=\"ltx_text\" id=\"S5.T29.11.11.1.1\" style=\"font-size:80%;\"> (s-gpt 1.3B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T29.11.11.2\"><span class=\"ltx_text\" id=\"S5.T29.11.11.2.1\" style=\"font-size:80%;\">11.02</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.11.11.3\"><span class=\"ltx_text\" id=\"S5.T29.11.11.3.1\" style=\"font-size:80%;\">2092/15530</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.11.11.4\"><span class=\"ltx_text\" id=\"S5.T29.11.11.4.1\" style=\"font-size:80%;\">13.47</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.11.11.5\"><span class=\"ltx_text\" id=\"S5.T29.11.11.5.1\" style=\"font-size:80%;\">0/989</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.11.11.6\"><span class=\"ltx_text\" id=\"S5.T29.11.11.6.1\" style=\"font-size:80%;\">0.00</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.11.11.7\"><span class=\"ltx_text\" id=\"S5.T29.11.11.7.1\" style=\"font-size:80%;\">0/12709</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.11.11.8\"><span class=\"ltx_text\" id=\"S5.T29.11.11.8.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.12.12\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T29.12.12.1\">\n<span class=\"ltx_text\" id=\"S5.T29.12.12.1.1\" style=\"font-size:80%;\"> (s-gpt 1.3B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T29.12.12.2\"><span class=\"ltx_text\" id=\"S5.T29.12.12.2.1\" style=\"font-size:80%;\">20.19</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.12.12.3\"><span class=\"ltx_text\" id=\"S5.T29.12.12.3.1\" style=\"font-size:80%;\">3133/15530</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.12.12.4\"><span class=\"ltx_text\" id=\"S5.T29.12.12.4.1\" style=\"font-size:80%;\">20.17</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.12.12.5\"><span class=\"ltx_text\" id=\"S5.T29.12.12.5.1\" style=\"font-size:80%;\">0/989</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.12.12.6\"><span class=\"ltx_text\" id=\"S5.T29.12.12.6.1\" style=\"font-size:80%;\">0.00</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.12.12.7\"><span class=\"ltx_text\" id=\"S5.T29.12.12.7.1\" style=\"font-size:80%;\">0/12709</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.12.12.8\"><span class=\"ltx_text\" id=\"S5.T29.12.12.8.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.13.13\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T29.13.13.1\">\n<span class=\"ltx_text\" id=\"S5.T29.13.13.1.1\" style=\"font-size:80%;\"> (s-gpt 2.7B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S5.T29.13.13.2\"><span class=\"ltx_text\" id=\"S5.T29.13.13.2.1\" style=\"font-size:80%;\">13.44</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.13.13.3\"><span class=\"ltx_text\" id=\"S5.T29.13.13.3.1\" style=\"font-size:80%;\">2489/15530</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.13.13.4\"><span class=\"ltx_text\" id=\"S5.T29.13.13.4.1\" style=\"font-size:80%;\">16.03</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.13.13.5\"><span class=\"ltx_text\" id=\"S5.T29.13.13.5.1\" style=\"font-size:80%;\">0/989</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S5.T29.13.13.6\"><span class=\"ltx_text\" id=\"S5.T29.13.13.6.1\" style=\"font-size:80%;\">0.00</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.13.13.7\"><span class=\"ltx_text\" id=\"S5.T29.13.13.7.1\" style=\"font-size:80%;\">0/12709</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T29.13.13.8\"><span class=\"ltx_text\" id=\"S5.T29.13.13.8.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T29.14.14\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"S5.T29.14.14.1\">\n<span class=\"ltx_text\" id=\"S5.T29.14.14.1.1\" style=\"font-size:80%;\"> (s-gpt 2.7B)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S5.T29.14.14.2\"><span class=\"ltx_text\" id=\"S5.T29.14.14.2.1\" style=\"font-size:80%;\">24.92</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T29.14.14.3\"><span class=\"ltx_text\" id=\"S5.T29.14.14.3.1\" style=\"font-size:80%;\">3957/15530</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S5.T29.14.14.4\"><span class=\"ltx_text\" id=\"S5.T29.14.14.4.1\" style=\"font-size:80%;\">25.48</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T29.14.14.5\"><span class=\"ltx_text\" id=\"S5.T29.14.14.5.1\" style=\"font-size:80%;\">0/989</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S5.T29.14.14.6\"><span class=\"ltx_text\" id=\"S5.T29.14.14.6.1\" style=\"font-size:80%;\">0.00</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T29.14.14.7\"><span class=\"ltx_text\" id=\"S5.T29.14.14.7.1\" style=\"font-size:80%;\">0/12709</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S5.T29.14.14.8\"><span class=\"ltx_text\" id=\"S5.T29.14.14.8.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S5.T29.27.6.1\" style=\"font-size:113%;\">Table 29</span>: </span><em class=\"ltx_emph ltx_font_italic\" id=\"S5.T29.24.5\" style=\"font-size:113%;\">Verifiability, generalisability and falsifiability of the baseline and the robustly (adversarially) trained DNNs on the RUAR and the Medical datasets, for  ( and ) and  (); for Marabou verifier.\n</em></figcaption>\n</figure>",
            "capture": "Table 29: Verifiability, generalisability and falsifiability of the baseline and the robustly (adversarially) trained DNNs on the RUAR and the Medical datasets, for  ( and ) and  (); for Marabou verifier.\n"
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.10144v2_figure_1.png",
            "caption": "(a)"
        },
        "2": {
            "figure_path": "2403.10144v2_figure_2.png",
            "caption": "(b)"
        },
        "3": {
            "figure_path": "2403.10144v2_figure_3.png",
            "caption": "(c)"
        },
        "4": {
            "figure_path": "2403.10144v2_figure_4.png",
            "caption": "(d)"
        },
        "5": {
            "figure_path": "2403.10144v2_figure_5.png",
            "caption": "Figure 2: Visualisation of the NLP verification pipeline followed in our approach."
        },
        "6": {
            "figure_path": "2403.10144v2_figure_6.png",
            "caption": "(a)"
        },
        "7": {
            "figure_path": "2403.10144v2_figure_7.png",
            "caption": "(b)"
        },
        "8": {
            "figure_path": "2403.10144v2_figure_8.png",
            "caption": "(c)"
        },
        "9": {
            "figure_path": "2403.10144v2_figure_9.png",
            "caption": "Figure 4: Tool ANTONIO that implements a modular approach to the NLP verification pipeline used in this paper."
        },
        "10": {
            "figure_path": "2403.10144v2_figure_10.png",
            "caption": "Figure 5: Zero-shot prompts with 2 basic examples from the R-U-A-Robot dataset. Answers from vicuna-13b are given in italics. A1 and A2 represent different answers to the same prompt, illustrating a lack of consistency in the output."
        },
        "11": {
            "figure_path": "2403.10144v2_figure_11.png",
            "caption": "Figure 6: Analysis of some common issues found in the vicuna-13b generated perturbations."
        },
        "12": {
            "figure_path": "2403.10144v2_figure_12.png",
            "caption": "Figure 7: In this figure, we show how a prepended, semantically informed verified filter added to an NLP system (here, an LLM), can check that safety-critical queries are handled responsibly, e.g. by redirecting the query to a tightly controlled rule-based system instead of a stochastic LLM."
        }
    },
    "references": [
        {
            "1": {
                "title": "Faster r-cnn: Towards real-time object detection with region proposal networks.",
                "author": "Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.",
                "venue": "IEEE transactions on pattern analysis and machine intelligence, 39(6):1137\u20131149, 2016.",
                "url": null
            }
        },
        {
            "2": {
                "title": "Sequence to sequence learning with neural networks.",
                "author": "Ilya Sutskever, Oriol Vinyals, and Quoc V Le.",
                "venue": "Advances in neural information processing systems, 27, 2014.",
                "url": null
            }
        },
        {
            "3": {
                "title": "Advances in natural language processing.",
                "author": "Julia Hirschberg and Christopher D. Manning.",
                "venue": "Science, 349(6245):261\u2013266, 2015.",
                "url": null
            }
        },
        {
            "4": {
                "title": "On the dangers of stochastic parrots: Can language models be too big?",
                "author": "Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell.",
                "venue": "In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pages 610\u2013623, 2021.",
                "url": null
            }
        },
        {
            "5": {
                "title": "Ethical and social risks of harm from language models, 2021.",
                "author": "Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh, Zac Kenton, Sasha Brown, Will Hawkins, Tom Stepleton, Courtney Biles, Abeba Birhane, Julia Haas, Laura Rimell, Lisa Anne Hendricks, William Isaac, Sean Legassick, Geoffrey Irving, and Iason Gabriel.",
                "venue": null,
                "url": null
            }
        },
        {
            "6": {
                "title": "Guiding the release of safer e2e conversational ai through value sensitive design.",
                "author": "A Stevie Bergman, Gavin Abercrombie, Shannon L Spruit, Dirk Hovy, Emily Dinan, Y-Lan Boureau, and Verena Rieser.",
                "venue": "In Proceedings of the 23rd Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 39\u201352, 2022.",
                "url": null
            }
        },
        {
            "7": {
                "title": "SafetyKit: First aid for measuring safety in open-domain conversational systems.",
                "author": "Emily Dinan, Gavin Abercrombie, A. Bergman, Shannon Spruit, Dirk Hovy, Y-Lan Boureau, and Verena Rieser.",
                "venue": "In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4113\u20134133, Dublin, Ireland, May 2022. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "8": {
                "title": "On the opportunities and risks of foundation models, 2021.",
                "author": "Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, Erik Brynjolfsson, Shyamal Buch, Dallas Card, Rodrigo Castellon, Niladri Chatterji, Annie Chen, Kathleen Creel, Jared Quincy Davis, Dora Demszky, Chris Donahue, Moussa Doumbouya, Esin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh, Li Fei-Fei, Chelsea Finn, Trevor Gale, Lauren Gillespie, Karan Goel, Noah Goodman, Shelby Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson, John Hewitt, Daniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil Jain, Dan Jurafsky, Pratyusha Kalluri, Siddharth Karamcheti, Geoff Keeling, Fereshte Khani, Omar Khattab, Pang Wei Koh, Mark Krass, Ranjay Krishna, Rohith Kuditipudi, Ananya Kumar, Faisal Ladhak, Mina Lee, Tony Lee, Jure Leskovec, Isabelle Levent, Xiang Lisa Li, Xuechen Li, Tengyu Ma, Ali Malik, Christopher D. Manning, Suvir Mirchandani, Eric Mitchell, Zanele Munyikwa, Suraj Nair,\nAvanika Narayan, Deepak Narayanan, Ben Newman, Allen Nie, Juan Carlos Niebles, Hamed Nilforoshan, Julian Nyarko, Giray Ogut, Laurel Orr, Isabel Papadimitriou, Joon Sung Park, Chris Piech, Eva Portelance, Christopher Potts, Aditi Raghunathan, Rob Reich, Hongyu Ren, Frieda Rong, Yusuf Roohani, Camilo Ruiz, Jack Ryan, Christopher R\u00e9, Dorsa Sadigh, Shiori Sagawa, Keshav Santhanam, Andy Shih, Krishnan Srinivasan, Alex Tamkin, Rohan Taori, Armin W. Thomas, Florian Tram\u00e8r, Rose E. Wang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai Wu, Sang Michael Xie, Michihiro Yasunaga, Jiaxuan You, Matei Zaharia, Michael Zhang, Tianyi Zhang, Xikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn Zhou, and Percy Liang.",
                "venue": "URL https://arxiv.org/abs/2108.07258.",
                "url": null
            }
        },
        {
            "9": {
                "title": "Anticipating safety issues in E2E conversational AI: Framework and tooling, 2021.",
                "author": "Emily Dinan, Gavin Abercrombie, A. Stevie Bergman, Shannon Spruit, Dirk Hovy, Y-Lan Boureau, and Verena Rieser.",
                "venue": "URL https://arxiv.org/abs/2107.03451.",
                "url": null
            }
        },
        {
            "10": {
                "title": "Eu artificial intelligence act: The european approach to ai, 2021.",
                "author": "Mauritz Kop.",
                "venue": "URL https://futurium.ec.europa.eu/sites/default/files/2021-10/Kop_EUArtificialIntelligenceAct-TheEuropeanApproachtoAI_21092021_0.pdf.",
                "url": null
            }
        },
        {
            "11": {
                "title": "California senate bill no. 1001.",
                "author": "California State Legislature.",
                "venue": "2018.",
                "url": null
            }
        },
        {
            "12": {
                "title": "Risk-graded safety for handling medical queries in conversational ai.",
                "author": "Gavin Abercrombie and Verena Rieser.",
                "venue": "In Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing, pages 234\u2013243, 2022.",
                "url": null
            }
        },
        {
            "13": {
                "title": "Patient and consumer safety risks when using conversational assistants for medical information: an observational study of siri, alexa, and google assistant.",
                "author": "Timothy W Bickmore, Ha Trinh, Stefan Olafsson, Teresa K O\u2019Leary, Reza Asadi, Nathaniel M Rickles, and Ricardo Cruz.",
                "venue": "Journal of medical Internet research, 20(9):e11510, 2018.",
                "url": null
            }
        },
        {
            "14": {
                "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023.",
                "author": "Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing.",
                "venue": "URL https://lmsys.org/blog/2023-03-30-vicuna/.",
                "url": null
            }
        },
        {
            "15": {
                "title": "Robustness verification for transformers, 2020.",
                "author": "Zhouxing Shi, Huan Zhang, Kai-Wei Chang, Minlie Huang, and Cho-Jui Hsieh.",
                "venue": null,
                "url": null
            }
        },
        {
            "16": {
                "title": "Antonio: Towards a systematic method of generating nlp benchmarks for verification.",
                "author": "Marco Casadio, Luca Arnaboldi, Matthew Daggitt, Omri Isac, Tanvi Dinkar, Daniel Kienitz, Verena Rieser, and Ekaterina Komendantskaya.",
                "venue": "In Nina Narodytska, Guy Amir, Guy Katz, and Omri Isac, editors, Proceedings of the 6th Workshop on Formal Methods for ML-Enabled Autonomous Systems, volume 16 of Kalpa Publications in Computing, pages 59\u201370. EasyChair, 2023.",
                "url": null
            }
        },
        {
            "17": {
                "title": "Certified robustness to adversarial word substitutions.",
                "author": "Robin Jia, Aditi Raghunathan, Kerem G\u00f6ksel, and Percy Liang.",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4129\u20134142, 2019a.",
                "url": null
            }
        },
        {
            "18": {
                "title": "Achieving verified robustness to symbol substitutions via interval bound propagation.",
                "author": "Po-Sen Huang, Robert Stanforth, Johannes Welbl, Chris Dyer, Dani Yogatama, Sven Gowal, Krishnamurthy Dvijotham, and Pushmeet Kohli.",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4083\u20134093, 2019.",
                "url": null
            }
        },
        {
            "19": {
                "title": "Certified robustness to programmable transformations in lstms.",
                "author": "Yuhao Zhang, Aws Albarghouthi, and Loris D\u2019Antoni.",
                "venue": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1068\u20131083, 2021.",
                "url": null
            }
        },
        {
            "20": {
                "title": "Towards deep learning models resistant to adversarial attacks.",
                "author": "Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.",
                "venue": "In International Conference on Learning Representations, 2018.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Polyjuice: Generating counterfactuals for explaining, evaluating, and improving models.",
                "author": "Tongshuang Wu, Marco Tulio Ribeiro, Jeffrey Heer, and Daniel S Weld.",
                "venue": "In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6707\u20136723, 2021.",
                "url": null
            }
        },
        {
            "22": {
                "title": "Marabou 2.0: A versatile formal analyzer of neural networks, 2024.",
                "author": "Haoze Wu, Omri Isac, Aleksandar Zelji\u0107, Teruhiro Tagomori, Matthew Daggitt, Wen Kokke, Idan Refaeli, Guy Amir, Kyle Julian, Shahaf Bassan, Pei Huang, Ori Lahav, Min Wu, Min Zhang, Ekaterina Komendantskaya, Guy Katz, and Clark Barrett.",
                "venue": null,
                "url": null
            }
        },
        {
            "23": {
                "title": "Automated pipeline design.",
                "author": "Daniel Kroening and Wolfgang Paul.",
                "venue": "In Proc. of 38th ACM/IEEE Design Automation Conference (DAC 2001), pages 810\u2013815. ACM Press, 2001.",
                "url": null
            }
        },
        {
            "24": {
                "title": "Formal verification of an arm processor.",
                "author": "Vishnu A Patankar, Alok Jain, and Randal E Bryant.",
                "venue": "In Proceedings Twelfth International Conference on VLSI Design.(Cat. No. PR00013), pages 282\u2013287. IEEE, 1999.",
                "url": null
            }
        },
        {
            "25": {
                "title": "A formally-verified c static analyzer.",
                "author": "Jacques-Henri Jourdan, Vincent Laporte, Sandrine Blazy, Xavier Leroy, and David Pichardie.",
                "venue": "ACM SIGPLAN Notices, 50(1):247\u2013259, 2015.",
                "url": null
            }
        },
        {
            "26": {
                "title": "Automating cryptographic protocol language generation from structured specifications.",
                "author": "Roberto Metere and Luca Arnaboldi.",
                "venue": "In Proceedings of the IEEE/ACM 10th International Conference on Formal Methods in Software Engineering, pages 91\u2013101, 2022.",
                "url": null
            }
        },
        {
            "27": {
                "title": "Formal methods: Practice and experience.",
                "author": "Jim Woodcock, Peter Gorm Larsen, Juan Bicarregui, and John Fitzgerald.",
                "venue": "ACM computing surveys (CSUR), 41(4):1\u201336, 2009.",
                "url": null
            }
        },
        {
            "28": {
                "title": "Reluplex: An efficient smt solver for verifying deep neural networks.",
                "author": "Guy Katz, Clark Barrett, David L Dill, Kyle Julian, and Mykel J Kochenderfer.",
                "venue": "In International conference on computer aided verification, pages 97\u2013117. Springer, 2017.",
                "url": null
            }
        },
        {
            "29": {
                "title": "The second international verification of neural networks competition (vnn-comp 2021): Summary and results.",
                "author": "Stanley Bak, Changliu Liu, and Taylor Johnson.",
                "venue": "arXiv preprint arXiv:2109.00498, 2021.",
                "url": null
            }
        },
        {
            "30": {
                "title": "Scalable quantitative verification for deep neural networks.",
                "author": "Teodora Baluta, Zheng Leong Chua, Kuldeep S Meel, and Prateek Saxena.",
                "venue": "In 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), pages 312\u2013323. IEEE, 2021.",
                "url": null
            }
        },
        {
            "31": {
                "title": "Algorithms for verifying deep neural networks.",
                "author": "Changliu Liu, Tomer Arnon, Christopher Lazarus, Christopher Strong, Clark Barrett, Mykel J Kochenderfer, et al.",
                "venue": "Foundations and Trends\u00ae in Optimization, 4(3-4):244\u2013404, 2021.",
                "url": null
            }
        },
        {
            "32": {
                "title": "Beyond the single neuron convex barrier for neural network certification.",
                "author": "Gagandeep Singh, Rupanshu Ganvir, Markus P\u00fcschel, and Martin Vechev.",
                "venue": "Advances in Neural Information Processing Systems, 32, 2019a.",
                "url": null
            }
        },
        {
            "33": {
                "title": "Challenging smt solvers to verify neural networks.",
                "author": "Luca Pulina and Armando Tacchella.",
                "venue": "Ai Communications, 25(2):117\u2013135, 2012.",
                "url": null
            }
        },
        {
            "34": {
                "title": "Linear programming and extensions.",
                "author": "George Dantzig.",
                "venue": "Princeton university press, 1963.",
                "url": null
            }
        },
        {
            "35": {
                "title": "Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints.",
                "author": "Patrick Cousot and Radhia Cousot.",
                "venue": "In Proceedings of the 4th ACM SIGACT-SIGPLAN symposium on Principles of programming languages, pages 238\u2013252, 1977.",
                "url": null
            }
        },
        {
            "36": {
                "title": "Verification by abstract interpretation.",
                "author": "Patrick Cousot.",
                "venue": "In Verification: Theory and Practice: Essays Dedicated to Zohar Manna on the Occasion of His 64th Birthday, pages 243\u2013268. Springer, 2003.",
                "url": null
            }
        },
        {
            "37": {
                "title": "Abstract interpretation: past, present and future.",
                "author": "Patrick Cousot and Radhia Cousot.",
                "venue": "In Proceedings of the Joint Meeting of the Twenty-Third EACSL Annual Conference on Computer Science Logic (CSL) and the Twenty-Ninth Annual ACM/IEEE Symposium on Logic in Computer Science (LICS), pages 1\u201310, 2014.",
                "url": null
            }
        },
        {
            "38": {
                "title": "Provable defenses against adversarial examples via the convex outer adversarial polytope.",
                "author": "Eric Wong and Zico Kolter.",
                "venue": "In International conference on machine learning, pages 5286\u20135295. PMLR, 2018.",
                "url": null
            }
        },
        {
            "39": {
                "title": "Scalable verified training for provably robust image classification.",
                "author": "Sven Gowal, Krishnamurthy Dj Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan Uesato, Relja Arandjelovic, Timothy Mann, and Pushmeet Kohli.",
                "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 4842\u20134851, 2019.",
                "url": null
            }
        },
        {
            "40": {
                "title": "Fastened crown: Tightened neural network robustness certificates.",
                "author": "Zhaoyang Lyu, Ching-Yun Ko, Zhifeng Kong, Ngai Wong, Dahua Lin, and Luca Daniel.",
                "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 5037\u20135044, 2020.",
                "url": null
            }
        },
        {
            "41": {
                "title": "Differentiable abstract interpretation for provably robust neural networks.",
                "author": "Matthew Mirman, Timon Gehr, and Martin Vechev.",
                "venue": "In International Conference on Machine Learning, pages 3578\u20133586. PMLR, 2018.",
                "url": null
            }
        },
        {
            "42": {
                "title": "Sok: Certified robustness for deep neural networks.",
                "author": "Linyi Li, Tao Xie, and Bo Li.",
                "venue": "In 2023 IEEE symposium on security and privacy (SP), pages 1289\u20131310. IEEE, 2023.",
                "url": null
            }
        },
        {
            "43": {
                "title": "Efficient neural network robustness certification with general activation functions.",
                "author": "Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel.",
                "venue": "Advances in neural information processing systems, 31, 2018.",
                "url": null
            }
        },
        {
            "44": {
                "title": "An abstract domain for certifying neural networks.",
                "author": "Gagandeep Singh, Timon Gehr, Markus P\u00fcschel, and Martin Vechev.",
                "venue": "Proceedings of the ACM on Programming Languages, 3(POPL):1\u201330, 2019b.",
                "url": null
            }
        },
        {
            "45": {
                "title": "Prima: general and precise neural network certification via scalable convex hull approximations.",
                "author": "Mark Niklas M\u00fcller, Gleb Makarchuk, Gagandeep Singh, Markus P\u00fcschel, and Martin T Vechev.",
                "venue": "Proc. ACM Program. Lang., 6(POPL):1\u201333, 2022.",
                "url": null
            }
        },
        {
            "46": {
                "title": "Fast and effective robustness certification.",
                "author": "Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus P\u00fcschel, and Martin Vechev.",
                "venue": "In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.",
                "url": null
            }
        },
        {
            "47": {
                "title": "Maximum resilience of artificial neural networks.",
                "author": "Chih-Hong Cheng, Georg N\u00fchrenberg, and Harald Ruess.",
                "venue": "In Automated Technology for Verification and Analysis: 15th International Symposium, ATVA 2017, Pune, India, October 3\u20136, 2017, Proceedings 15, pages 251\u2013268. Springer, 2017.",
                "url": null
            }
        },
        {
            "48": {
                "title": "An approach to reachability analysis for feed-forward relu neural networks.",
                "author": "Alessio Lomuscio and Lalit Maganti.",
                "venue": "arXiv preprint arXiv:1706.07351, 2017.",
                "url": null
            }
        },
        {
            "49": {
                "title": "Evaluating robustness of neural networks with mixed integer programming.",
                "author": "Vincent Tjeng, Kai Xiao, and Russ Tedrake.",
                "venue": "n International Conference on Learning Representations,, 2019.",
                "url": null
            }
        },
        {
            "50": {
                "title": "gurobi: Gurobi optimizer 9.1 interface.",
                "author": "LLC Gurobi Optimization.",
                "venue": "R package version, pages 9\u20131, 2020.",
                "url": null
            }
        },
        {
            "51": {
                "title": "Ai2: Safety and robustness certification of neural networks with abstract interpretation.",
                "author": "Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat Chaudhuri, and Martin Vechev.",
                "venue": "In 2018 IEEE symposium on security and privacy (SP), pages 3\u201318. IEEE, 2018.",
                "url": null
            }
        },
        {
            "52": {
                "title": "A unified view of piecewise linear neural network verification.",
                "author": "Rudy R Bunel, Ilker Turkaslan, Philip Torr, Pushmeet Kohli, and Pawan K Mudigonda.",
                "venue": "Advances in Neural Information Processing Systems, 31, 2018.",
                "url": null
            }
        },
        {
            "53": {
                "title": "Branch and bound for piecewise linear neural network verification.",
                "author": "Rudy Bunel, P Mudigonda, Ilker Turkaslan, Philip Torr, Jingyue Lu, and Pushmeet Kohli.",
                "venue": "Journal of Machine Learning Research, 21(2020), 2020.",
                "url": null
            }
        },
        {
            "54": {
                "title": "Complete verification via multi-neuron relaxation guided branch-and-bound.",
                "author": "Claudio Ferrari, Mark Niklas Mueller, Nikola Jovanovi\u0107, and Martin Vechev.",
                "venue": "In International Conference on Learning Representations, 2022.",
                "url": null
            }
        },
        {
            "55": {
                "title": "Provable certificates for adversarial examples: Fitting a ball in the union of polytopes.",
                "author": "Matt Jordan, Justin Lewis, and Alexandros G Dimakis.",
                "venue": "Advances in neural information processing systems, 32, 2019.",
                "url": null
            }
        },
        {
            "56": {
                "title": "Beta-crown: Efficient bound propagation with per-neuron split constraints for neural network robustness verification.",
                "author": "Shiqi Wang, Huan Zhang, Kaidi Xu, Xue Lin, Suman Jana, Cho-Jui Hsieh, and J Zico Kolter.",
                "venue": "Advances in Neural Information Processing Systems, 34:29909\u201329921, 2021a.",
                "url": null
            }
        },
        {
            "57": {
                "title": "General cutting planes for bound-propagation-based neural network verification.",
                "author": "Huan Zhang, Shiqi Wang, Kaidi Xu, Linyi Li, Bo Li, Suman Jana, Cho-Jui Hsieh, and J Zico Kolter.",
                "venue": "Advances in Neural Information Processing Systems, 35:1656\u20131670, 2022.",
                "url": null
            }
        },
        {
            "58": {
                "title": "Prima: Precise and general neural network certification via multi-neuron convex relaxations, 2021.",
                "author": "Mark Niklas M\u00fcller, Gleb Makarchuk, Gagandeep Singh, Markus P\u00fcschel, and Martin Vechev.",
                "venue": null,
                "url": null
            }
        },
        {
            "59": {
                "title": "Fast and complete: Enabling complete neural network verification with rapid and massively parallel incomplete verifiers.",
                "author": "Kaidi Xu, Huan Zhang, Shiqi Wang, Yihan Wang, Suman Jana, Xue Lin, and Cho-Jui Hsieh.",
                "venue": "In International Conference on Learning Representation (ICLR), 2021.",
                "url": null
            }
        },
        {
            "60": {
                "title": "Certified robustness to adversarial examples with differential privacy.",
                "author": "Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana.",
                "venue": "In 2019 IEEE symposium on security and privacy (SP), pages 656\u2013672. IEEE, 2019.",
                "url": null
            }
        },
        {
            "61": {
                "title": "Certified adversarial robustness with additive noise.",
                "author": "Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin.",
                "venue": "Advances in neural information processing systems, 32, 2019a.",
                "url": null
            }
        },
        {
            "62": {
                "title": "A framework for robustness certification of smoothed classifiers using f-divergences.",
                "author": "Krishnamurthy Dj Dvijotham, Jamie Hayes, Borja Balle, Zico Kolter, Chongli Qin, Andras Gyorgy, Kai Xiao, Sven Gowal, and Pushmeet Kohli.",
                "venue": "2020.",
                "url": null
            }
        },
        {
            "63": {
                "title": "Black-box certification with randomized smoothing: A functional optimization based framework.",
                "author": "Dinghuai Zhang, Mao Ye, Chengyue Gong, Zhanxing Zhu, and Qiang Liu.",
                "venue": "Advances in Neural Information Processing Systems, 33:2316\u20132326, 2020a.",
                "url": null
            }
        },
        {
            "64": {
                "title": "Provably robust deep learning via adversarially trained smoothed classifiers.",
                "author": "Hadi Salman, Jerry Li, Ilya Razenshteyn, Pengchuan Zhang, Huan Zhang, Sebastien Bubeck, and Greg Yang.",
                "venue": "Advances in Neural Information Processing Systems, 32, 2019.",
                "url": null
            }
        },
        {
            "65": {
                "title": "Higher-order certification for randomized smoothing.",
                "author": "Jeet Mohapatra, Ching-Yun Ko, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, and Luca Daniel.",
                "venue": "Advances in Neural Information Processing Systems, 33:4501\u20134511, 2020.",
                "url": null
            }
        },
        {
            "66": {
                "title": "Neural network robustness as a verification property: A principled case study.",
                "author": "Marco Casadio, Ekaterina Komendantskaya, Matthew L. Daggitt, Wen Kokke, Guy Katz, Guy Amir, and Idan Refaeli.",
                "venue": "In Computer Aided Verification (CAV 2022), Lecture Notes in Computer Science. Springer, 2022.",
                "url": null
            }
        },
        {
            "67": {
                "title": "Explaining and harnessing adversarial examples, 2015.",
                "author": "Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy.",
                "venue": null,
                "url": null
            }
        },
        {
            "68": {
                "title": "Adversarial robustness: Theory and practice.",
                "author": "Zico Kolter and Aleksander Madry.",
                "venue": "Tutorial at NeurIPS, page 3, 2018.",
                "url": null
            }
        },
        {
            "69": {
                "title": "Data augmentation can improve robustness.",
                "author": "Sylvestre-Alvise Rebuffi, Sven Gowal, Dan Andrei Calian, Florian Stimberg, Olivia Wiles, and Timothy A Mann.",
                "venue": "Advances in Neural Information Processing Systems, 34:29935\u201329948, 2021.",
                "url": null
            }
        },
        {
            "70": {
                "title": "DL2: training and querying neural networks with logic.",
                "author": "Marc Fischer, Mislav Balunovic, Dana Drachsler-Cohen, Timon Gehr, Ce Zhang, and Martin T. Vechev.",
                "venue": "In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research, pages 1931\u20131941. PMLR, 2019.",
                "url": null
            }
        },
        {
            "71": {
                "title": "Logic of differentiable logics: Towards a uniform semantics of DL.",
                "author": "Natalia Slusarz, Ekaterina Komendantskaya, Matthew L. Daggitt, Robert J. Stewart, and Kathrin Stark.",
                "venue": "In Ruzica Piskac and Andrei Voronkov, editors, LPAR 2023: Proceedings of 24th International Conference on Logic for Programming, Artificial Intelligence and Reasoning, Manizales, Colombia, 4-9th June 2023, volume 94 of EPiC Series in Computing, pages 473\u2013493. EasyChair, 2023.",
                "url": null
            }
        },
        {
            "72": {
                "title": "Towards stable and efficient training of verifiably robust neural networks.",
                "author": "Huan Zhang, Hongge Chen, Chaowei Xiao, Sven Gowal, Robert Stanforth, Bo Li, Duane Boning, and Cho Jui Hsieh.",
                "venue": "In 8th International Conference on Learning Representations, ICLR 2020, 2020b.",
                "url": null
            }
        },
        {
            "73": {
                "title": "Certified training: Small boxes are all you need, 2023.",
                "author": "Mark Niklas M\u00fcller, Franziska Eckert, Marc Fischer, and Martin Vechev.",
                "venue": null,
                "url": null
            }
        },
        {
            "74": {
                "title": "Robustness to programmable string transformations via augmented abstract training.",
                "author": "Yuhao Zhang, Aws Albarghouthi, and Loris D\u2019Antoni.",
                "venue": "In Proceedings of the 37th International Conference on Machine Learning, pages 11023\u201311032, 2020c.",
                "url": null
            }
        },
        {
            "75": {
                "title": "Adversarial attacks on deep-learning models in natural language processing: A survey.",
                "author": "Wei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li.",
                "venue": "ACM Transactions on Intelligent Systems and Technology (TIST), 11(3):1\u201341, 2020d.",
                "url": null
            }
        },
        {
            "76": {
                "title": "Towards a robust deep neural network against adversarial texts: A survey.",
                "author": "Wenqi Wang, Run Wang, Lina Wang, Zhibo Wang, and Aoshuang Ye.",
                "venue": "IEEE Transactions on Knowledge and Data Engineering, pages 1\u20131, 2021b.",
                "url": null
            }
        },
        {
            "77": {
                "title": "Measure and improve robustness in nlp models: A survey.",
                "author": "Xuezhi Wang, Haohan Wang, and Diyi Yang.",
                "venue": "In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 4569\u20134586, 2022.",
                "url": null
            }
        },
        {
            "78": {
                "title": "Searching for an effective defender: Benchmarking defense against adversarial word substitution.",
                "author": "Zongyi Li, Jianhan Xu, Jiehang Zeng, Linyang Li, Xiaoqing Zheng, Qi Zhang, Kai-Wei Chang, and Cho-Jui Hsieh.",
                "venue": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 3137\u20133147, 2021.",
                "url": null
            }
        },
        {
            "79": {
                "title": "Defense against synonym substitution-based adversarial attacks via dirichlet neighborhood ensemble.",
                "author": "Yi Zhou, Xiaoqing Zheng, Cho-Jui Hsieh, Kai-Wei Chang, and Xuanjing Huan.",
                "venue": "In Association for Computational Linguistics (ACL), 2021.",
                "url": null
            }
        },
        {
            "80": {
                "title": "Freelb: Enhanced adversarial training for natural language understanding.",
                "author": "Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, and Jingjing Liu.",
                "venue": "In International Conference on Learning Representations, 2019.",
                "url": null
            }
        },
        {
            "81": {
                "title": "Towards robustness against natural language word substitutions.",
                "author": "Xinshuai Dong, Anh Tuan Luu, Rongrong Ji, and Hong Liu.",
                "venue": "arXiv preprint arXiv:2107.13541, 2021.",
                "url": null
            }
        },
        {
            "82": {
                "title": "A survey of data augmentation approaches for NLP.",
                "author": "Steven Y. Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, and Eduard Hovy.",
                "venue": "In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 968\u2013988, Online, 2021. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "83": {
                "title": "Nl-augmenter: A framework for task-sensitive natural language augmentation.",
                "author": "Kaustubh D. Dhole, Varun Gangal, Sebastian Gehrmann, Aadesh Gupta, Zhenhao Li, Saad Mahamood, Abinaya Mahendiran, Simon Mille, Ashish Srivastava, Samson Tan, Tongshuang Wu, Jascha Sohl-Dickstein, Jinho D. Choi, Eduard H. Hovy, Ondrej Dusek, Sebastian Ruder, Sajant Anand, Nagender Aneja, Rabin Banjade, Lisa Barthe, Hanna Behnke, Ian Berlot-Attwell, Connor Boyle, Caroline Brun, Marco Antonio Sobrevilla Cabezudo, Samuel Cahyawijaya, Emile Chapuis, Wanxiang Che, Mukund Choudhary, Christian Clauss, Pierre Colombo, Filip Cornell, Gautier Dagan, Mayukh Das, Tanay Dixit, Thomas Dopierre, Paul-Alexis Dray, Suchitra Dubey, Tatiana Ekeinhor, Marco Di Giovanni, Rishabh Gupta, Rishabh Gupta, Louanes Hamla, Sang Han, Fabrice Harel-Canada, Antoine Honore, Ishan Jindal, Przemyslaw K. Joniak, Denis Kleyko, Venelin Kovatchev, and et al.",
                "venue": "CoRR, abs/2112.02721, 2021.",
                "url": null
            }
        },
        {
            "84": {
                "title": "Robust neural machine translation with doubly adversarial inputs.",
                "author": "Yong Cheng, Lu Jiang, and Wolfgang Macherey.",
                "venue": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4324\u20134333, 2019.",
                "url": null
            }
        },
        {
            "85": {
                "title": "Adversarial example generation with syntactically controlled paraphrase networks.",
                "author": "Mohit Iyyer, John Wieting, Kevin Gimpel, and Luke Zettlemoyer.",
                "venue": "In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1875\u20131885, 2018.",
                "url": null
            }
        },
        {
            "86": {
                "title": "Tasa: Deceiving question answering models by twin answer sentences attack.",
                "author": "Yu Cao, Dianqi Li, Meng Fang, Tianyi Zhou, Jun Gao, Yibing Zhan, and Dacheng Tao.",
                "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 11975\u201311992, 2022.",
                "url": null
            }
        },
        {
            "87": {
                "title": "Deep text classification can be fooled.",
                "author": "Bin Liang, Hongcheng Li, Miaoqiang Su, Pan Bian, Xirong Li, and Wenchang Shi.",
                "venue": "arXiv preprint arXiv:1704.08006, 2017.",
                "url": null
            }
        },
        {
            "88": {
                "title": "Hotflip: White-box adversarial examples for text classification.",
                "author": "Javid Ebrahimi, Anyi Rao, Daniel Lowd, and Dejing Dou.",
                "venue": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 31\u201336, 2018.",
                "url": null
            }
        },
        {
            "89": {
                "title": "Phrase-level textual adversarial attack with label preservation.",
                "author": "Yibin Lei, Yu Cao, Dianqi Li, Tianyi Zhou, Meng Fang, and Mykola Pechenizkiy.",
                "venue": "In Findings of the Association for Computational Linguistics: NAACL 2022, pages 1095\u20131112, 2022.",
                "url": null
            }
        },
        {
            "90": {
                "title": "Synthetic and natural noise both break neural machine translation.",
                "author": "Yonatan Belinkov and Yonatan Bisk.",
                "venue": "arXiv preprint arXiv:1711.02173, 2017.",
                "url": null
            }
        },
        {
            "91": {
                "title": "Black-box generation of adversarial text sequences to evade deep learning classifiers.",
                "author": "Ji Gao, Jack Lanchantin, Mary Lou Soffa, and Yanjun Qi.",
                "venue": "In 2018 IEEE Security and Privacy Workshops (SPW), pages 50\u201356. IEEE, 2018.",
                "url": null
            }
        },
        {
            "92": {
                "title": "Textbugger: Generating adversarial text against real-world applications.",
                "author": "Jinfeng Li, Shouling Ji, Tianyu Du, Bo Li, and Ting Wang.",
                "venue": "Proceedings 2019 Network and Distributed System Security Symposium, 2019b.",
                "url": null
            }
        },
        {
            "93": {
                "title": "Towards crafting text adversarial samples, 2017.",
                "author": "Suranjana Samanta and Sameep Mehta.",
                "venue": null,
                "url": null
            }
        },
        {
            "94": {
                "title": "Fooling explanations in text classifiers.",
                "author": "Adam Ivankay, Ivan Girardi, Chiara Marchiori, and Pascal Frossard.",
                "venue": "arXiv preprint arXiv:2206.03178, 2022.",
                "url": null
            }
        },
        {
            "95": {
                "title": "Is bert really robust? a strong baseline for natural language attack on text classification and entailment.",
                "author": "Di Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter Szolovits.",
                "venue": "In Proceedings of the AAAI conference on artificial intelligence, volume 34, pages 8018\u20138025, 2020.",
                "url": null
            }
        },
        {
            "96": {
                "title": "Generating natural language adversarial examples.",
                "author": "Moustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani Srivastava, and Kai-Wei Chang.",
                "venue": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2890\u20132896, 2018.",
                "url": null
            }
        },
        {
            "97": {
                "title": "Adversarial examples for natural language classification problems.",
                "author": "Volodymyr Kuleshov, Shantanu Thakoor, Tingfung Lau, and Stefano Ermon.",
                "venue": "2018.",
                "url": null
            }
        },
        {
            "98": {
                "title": "Glove: Global vectors for word representation.",
                "author": "Jeffrey Pennington, Richard Socher, and Christopher D Manning.",
                "venue": "In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1532\u20131543, 2014.",
                "url": null
            }
        },
        {
            "99": {
                "title": "Evaluating the robustness of neural language models to input perturbations.",
                "author": "Milad Moradi and Matthias Samwald.",
                "venue": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1558\u20131570, 2021.",
                "url": null
            }
        },
        {
            "100": {
                "title": "Adversarial examples for evaluating reading comprehension systems.",
                "author": "Robin Jia and Percy Liang.",
                "venue": "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2021\u20132031, 2017.",
                "url": null
            }
        },
        {
            "101": {
                "title": "Robust machine comprehension models via adversarial training.",
                "author": "Yicheng Wang and Mohit Bansal.",
                "venue": "In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 575\u2013581, 2018.",
                "url": null
            }
        },
        {
            "102": {
                "title": "Adversarial glue: A multi-task benchmark for robustness evaluation of language models.",
                "author": "Boxin Wang, Chejian Xu, Shuohang Wang, Zhe Gan, Yu Cheng, Jianfeng Gao, Ahmed Hassan Awadallah, and Bo Li.",
                "venue": "arXiv preprint arXiv:2111.02840, 2021c.",
                "url": null
            }
        },
        {
            "103": {
                "title": "Towards verified robustness under text deletion interventions.",
                "author": "Johannes Welbl, Po-Sen Huang, Robert Stanforth, Sven Gowal, Krishnamurthy Dj Dvijotham, Martin Szummer, and Pushmeet Kohli.",
                "venue": "2020.",
                "url": null
            }
        },
        {
            "104": {
                "title": "Robustness-aware word embedding improves certified robustness to adversarial word substitutions.",
                "author": "Yibin Wang, Yichen Yang, Di He, and Kun He.",
                "venue": "In Findings of the Association for Computational Linguistics: ACL 2023, pages 673\u2013687, 2023.",
                "url": null
            }
        },
        {
            "105": {
                "title": "Popqorn: Quantifying robustness of recurrent neural networks.",
                "author": "Ching-Yun Ko, Zhaoyang Lyu, Lily Weng, Luca Daniel, Ngai Wong, and Dahua Lin.",
                "venue": "In International Conference on Machine Learning, pages 3468\u20133477. PMLR, 2019.",
                "url": null
            }
        },
        {
            "106": {
                "title": "Cert-rnn: Towards certifying the robustness of recurrent neural networks.",
                "author": "Tianyu Du, Shouling Ji, Lujia Shen, Yao Zhang, Jinfeng Li, Jie Shi, Chengfang Fang, Jianwei Yin, Raheem Beyah, and Ting Wang.",
                "venue": "CCS, 21(2021):15\u201319, 2021.",
                "url": null
            }
        },
        {
            "107": {
                "title": "Fast and precise certification of transformers.",
                "author": "Gregory Bonaert, Dimitar I Dimitrov, Maximilian Baader, and Martin Vechev.",
                "venue": "In Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation, pages 466\u2013481, 2021.",
                "url": null
            }
        },
        {
            "108": {
                "title": "Safer: A structure-free approach for certified robustness to adversarial word substitutions.",
                "author": "Mao Ye, Chengyue Gong, and Qiang Liu.",
                "venue": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3465\u20133475, 2020.",
                "url": null
            }
        },
        {
            "109": {
                "title": "Certified robustness to word substitution attack with differential privacy.",
                "author": "Wenjie Wang, Pengfei Tang, Jian Lou, and Li Xiong.",
                "venue": "In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-Tur, Iz Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou, editors, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1102\u20131112, Online, June 2021d. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "110": {
                "title": "Certified robustness against natural language attacks by causal intervention.",
                "author": "Haiteng Zhao, Chang Ma, Xinshuai Dong, Anh Tuan Luu, Zhi-Hong Deng, and Hanwang Zhang.",
                "venue": "In International Conference on Machine Learning, pages 26958\u201326970. PMLR, 2022.",
                "url": null
            }
        },
        {
            "111": {
                "title": "Certified robustness to text adversarial attacks by randomized [mask].",
                "author": "Jiehang Zeng, Jianhan Xu, Xiaoqing Zheng, and Xuanjing Huang.",
                "venue": "Computational Linguistics, 49(2):395\u2013427, 2023.",
                "url": null
            }
        },
        {
            "112": {
                "title": "Unit: A unified look at certified robust training against text adversarial perturbation.",
                "author": "Muchao Ye, Ziyi Yin, Tianrong Zhang, Tianyu Du, Jinghui Chen, Ting Wang, and Fenglong Ma.",
                "venue": "In Thirty-seventh Conference on Neural Information Processing Systems, 2023.",
                "url": null
            }
        },
        {
            "113": {
                "title": "Text-crs: A generalized certified robustness framework against textual adversarial attacks.",
                "author": "Xinyu Zhang, Hanbin Hong, Yuan Hong, Peng Huang, Binghui Wang, Zhongjie Ba, and Kui Ren.",
                "venue": "In 2024 IEEE Symposium on Security and Privacy (SP), pages 53\u201353. IEEE Computer Society, 2023a.",
                "url": null
            }
        },
        {
            "114": {
                "title": "Certified robustness for large language models with self-denoising.",
                "author": "Zhen Zhang, Guanhua Zhang, Bairu Hou, Wenqi Fan, Qing Li, Sijia Liu, Yang Zhang, and Shiyu Chang.",
                "venue": "arXiv preprint arXiv:2307.07171, 2023b.",
                "url": null
            }
        },
        {
            "115": {
                "title": "The zonotope abstract domain taylor1+.",
                "author": "Khalil Ghorbal, Eric Goubault, and Sylvie Putot.",
                "venue": "In Computer Aided Verification: 21st International Conference, CAV 2009, Grenoble, France, June 26-July 2, 2009. Proceedings 21, pages 627\u2013633. Springer, 2009.",
                "url": null
            }
        },
        {
            "116": {
                "title": "Certified adversarial robustness via randomized smoothing.",
                "author": "Jeremy Cohen, Elan Rosenfeld, and Zico Kolter.",
                "venue": "In international conference on machine learning, pages 1310\u20131320. PMLR, 2019.",
                "url": null
            }
        },
        {
            "117": {
                "title": "A large annotated corpus for learning natural language inference.",
                "author": "Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning.",
                "venue": "In Llu\u00eds M\u00e0rquez, Chris Callison-Burch, and Jian Su, editors, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 632\u2013642, Lisbon, Portugal, September 2015. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "118": {
                "title": "Toxic comment classification challenge, 2017.",
                "author": "cjadams Jeffrey Sorensen Julia Elliott Lucas Dixon Mark McDonald nithum and Will Cukierski.",
                "venue": "URL https://kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge.",
                "url": null
            }
        },
        {
            "119": {
                "title": "Learning word vectors for sentiment analysis.",
                "author": "Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts.",
                "venue": "In Dekang Lin, Yuji Matsumoto, and Rada Mihalcea, editors, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 142\u2013150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "120": {
                "title": "Recursive deep models for semantic compositionality over a sentiment treebank.",
                "author": "Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts.",
                "venue": "In David Yarowsky, Timothy Baldwin, Anna Korhonen, Karen Livescu, and Steven Bethard, editors, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1631\u20131642, Seattle, Washington, USA, October 2013. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "121": {
                "title": "Style transfer from non-parallel text by cross-alignment.",
                "author": "Tianxiao Shen, Tao Lei, Regina Barzilay, and Tommi Jaakkola.",
                "venue": "Advances in neural information processing systems, 30, 2017.",
                "url": null
            }
        },
        {
            "122": {
                "title": "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.",
                "author": "Bo Pang and Lillian Lee.",
                "venue": "In Kevin Knight, Hwee Tou Ng, and Kemal Oflazer, editors, Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL\u201905), pages 115\u2013124, Ann Arbor, Michigan, June 2005. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "123": {
                "title": "Hidden factors and hidden topics: understanding rating dimensions with review text.",
                "author": "Julian McAuley and Jure Leskovec.",
                "venue": "In Proceedings of the 7th ACM conference on Recommender systems, pages 165\u2013172, 2013.",
                "url": null
            }
        },
        {
            "124": {
                "title": "A broad-coverage challenge corpus for sentence understanding through inference.",
                "author": "Adina Williams, Nikita Nangia, and Samuel Bowman.",
                "venue": "In Marilyn Walker, Heng Ji, and Amanda Stent, editors, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1112\u20131122, New Orleans, Louisiana, June 2018. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "125": {
                "title": "Character-level convolutional networks for text classification.",
                "author": "Xiang Zhang, Junbo Zhao, and Yann LeCun.",
                "venue": "Advances in neural information processing systems, 28, 2015.",
                "url": null
            }
        },
        {
            "126": {
                "title": "Learning question classifiers.",
                "author": "Xin Li and Dan Roth.",
                "venue": "In COLING 2002: The 19th International Conference on Computational Linguistics, 2002.",
                "url": null
            }
        },
        {
            "127": {
                "title": "Hearing on \u201cOversight of AI: Rules for Artificial Intelligence\u201d.",
                "author": "Christina Montgomery.",
                "venue": "https://www.ibm.com/policy/wp-content/uploads/2023/05/Christina-Montgomery-Senate-Judiciary-Testimony-5-16-23.pdf, 2023.",
                "url": null
            }
        },
        {
            "128": {
                "title": "Chatbots, deepfakes, and voice clones: AI deception for sale.",
                "author": "Michael Atleson.",
                "venue": "https://www.ftc.gov/business-guidance/blog/2023/03/chatbots-deepfakes-voice-clones-ai-deception-sale, 2023.",
                "url": null
            }
        },
        {
            "129": {
                "title": "The rua-robot dataset: Helping avoid chatbot deception by detecting user questions about human or non-human identity.",
                "author": "David Gros, Yu Li, and Zhou Yu.",
                "venue": "In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6999\u20137013, 2021.",
                "url": null
            }
        },
        {
            "130": {
                "title": "Mirages. on anthropomorphism in dialogue systems.",
                "author": "Gavin Abercrombie, Amanda Cercas Curry, Tanvi Dinkar, Verena Rieser, and Zeerak Talat.",
                "venue": "In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 4776\u20134790, 2023.",
                "url": null
            }
        },
        {
            "131": {
                "title": "Google duplex: An AI system for accomplishing real world tasks over the phone.",
                "author": "Yaniv Leviathan and Yossi Matias.",
                "venue": "Google AI Blog, 2018.",
                "url": null
            }
        },
        {
            "132": {
                "title": "Google\u2019s creepy AI phone call feature will disclose it\u2019s a robot, after backlash.",
                "author": "Johnny Lieu.",
                "venue": "https://mashable.com/2018/05/11/google-duplex-disclosures-robot, 2018.",
                "url": null
            }
        },
        {
            "133": {
                "title": "Chatbots RESET: A Framework for Governing Responsible Use of Conversational AI in Healthcare.",
                "author": "World Economic Forum.",
                "venue": "https://www.weforum.org/publications/chatbots-reset-a-framework-for-governingresponsible-use-of-conversational-ai-in-healthcare/, 2020.",
                "url": null
            }
        },
        {
            "134": {
                "title": "Llama: Open and efficient foundation language models, 2023.",
                "author": "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample.",
                "venue": null,
                "url": null
            }
        },
        {
            "135": {
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding, 2018.",
                "author": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.",
                "venue": "URL https://arxiv.org/abs/1810.04805.",
                "url": null
            }
        },
        {
            "136": {
                "title": "Sentence-BERT: Sentence embeddings using Siamese BERT-networks.",
                "author": "Nils Reimers and Iryna Gurevych.",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3982\u20133992, Hong Kong, China, November 2019. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "137": {
                "title": "Sgpt: Gpt sentence embeddings for semantic search, 2022.",
                "author": "Niklas Muennighoff.",
                "venue": null,
                "url": null
            }
        },
        {
            "138": {
                "title": "Invbert: Reconstructing text from contextualized word embeddings by inverting the bert pipeline.",
                "author": "Kai Kugler, Simon M\u00fcnker, Johannes H\u00f6hmann, and Achim Rettinger.",
                "venue": "arXiv preprint arXiv:2109.10104, 2021.",
                "url": null
            }
        },
        {
            "139": {
                "title": "The quickhull algorithm for convex hulls.",
                "author": "C. Bradford Barber, David P. Dobkin, and Hannu Huhdanpaa.",
                "venue": "ACM TRANSACTIONS ON MATHEMATICAL SOFTWARE, 22(4):469\u2013483, 1996.",
                "url": null
            }
        },
        {
            "140": {
                "title": "Computing the approximate convex hull in high dimensions, 2016.",
                "author": "Hossein Sartipizadeh and Tyrone L. Vincent.",
                "venue": null,
                "url": null
            }
        },
        {
            "141": {
                "title": "On geometric structure of activation spaces in neural networks, 2019b.",
                "author": "Yuting Jia, Haiwen Wang, Shuo Shao, Huan Long, Yunsong Zhou, and Xinbing Wang.",
                "venue": null,
                "url": null
            }
        },
        {
            "142": {
                "title": "The singular value decomposition: Its computation and some applications.",
                "author": "Virginia Klema and Alan Laub.",
                "venue": "IEEE Transactions on automatic control, 25(2):164\u2013176, 1980.",
                "url": null
            }
        },
        {
            "143": {
                "title": "Replication package for the article: An abstract domain for certifying neural networks.",
                "author": "Gagandeep Singh, Timon Gehr, Markus P\u00fcschel, and Martin Vechev.",
                "venue": null,
                "url": null
            }
        },
        {
            "144": {
                "title": "Open llm leaderboard.",
                "author": "Edward Beeching, Sheon Han, Nathan Lambert ans Nazneen Rajani, Omar Sanseviero, Lewis Tunstall, and Thomas Wolf.",
                "venue": "https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard, 2023.",
                "url": null
            }
        },
        {
            "145": {
                "title": "Truthfulqa: Measuring how models mimic human falsehoods.",
                "author": "Stephanie Lin, Jacob Hilton, and Owain Evans.",
                "venue": "In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3214\u20133252, 2022.",
                "url": null
            }
        },
        {
            "146": {
                "title": "Minilmv2: Multi-head self-attention relation distillation for compressing pretrained transformers.",
                "author": "Wenhui Wang, Hangbo Bao, Shaohan Huang, Li Dong, and Furu Wei.",
                "venue": "In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 2140\u20132151, 2021e.",
                "url": null
            }
        },
        {
            "147": {
                "title": "Adversarial robustness of visual dialog, 2022.",
                "author": "Lu Yu and Verena Rieser.",
                "venue": null,
                "url": null
            }
        },
        {
            "148": {
                "title": "Intraclass correlation\u2013a discussion and demonstration of basic features.",
                "author": "David Liljequist, Britt Elfving, and Kirsti Skavberg Roaldsen.",
                "venue": "PloS one, 14(7):e0219854, 2019.",
                "url": null
            }
        },
        {
            "149": {
                "title": "ROUGE: A package for automatic evaluation of summaries.",
                "author": "Chin-Yew Lin.",
                "venue": "In Text Summarization Branches Out, pages 74\u201381, Barcelona, Spain, July 2004. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "150": {
                "title": "Natural language processing with Python and spaCy: A practical introduction.",
                "author": "Yuli Vasiliev.",
                "venue": "No Starch Press, 2020.",
                "url": null
            }
        },
        {
            "151": {
                "title": "First three years of the international verification of neural networks competition (vnn-comp).",
                "author": "Christopher Brix, Mark Niklas M\u00fcller, Stanley Bak, Taylor T Johnson, and Changliu Liu.",
                "venue": "International Journal on Software Tools for Technology Transfer, 25(3):329\u2013339, 2023a.",
                "url": null
            }
        },
        {
            "152": {
                "title": "The fourth international verification of neural networks competition (vnn-comp 2023): Summary and results.",
                "author": "Christopher Brix, Stanley Bak, Changliu Liu, and Taylor T Johnson.",
                "venue": "arXiv preprint arXiv:2312.16760, 2023b.",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.10144v2",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.1",
            "2.2",
            "2.3",
            "2.4",
            "2.5"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3",
            "3.3.1",
            "3.3.2",
            "3.3.3",
            "3.3.4",
            "3.3.5",
            "3.4",
            "3.5"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.2",
            "4.3",
            "4.3.1",
            "4.3.2",
            "4.4",
            "4.4.1",
            "4.4.2",
            "4.5",
            "5",
            "5.1",
            "5.2",
            "5.3",
            "5.4",
            "5.5",
            "5.5.1",
            "5.5.2",
            "5.5.x",
            "5.6",
            "5.6.x",
            "6"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "1",
            "4",
            "5"
        ]
    },
    "research_context": {
        "paper_id": "2403.10144v2",
        "paper_title": "NLP Verification: Towards a General Methodology for Certifying Robustness",
        "research_background": "**Motivation:**\nThe paper is motivated by the need to ensure safety and security in deploying deep neural network (DNN)-based systems in safety-critical applications. Current Natural Language Processing (NLP) systems lack guarantees for the truthfulness, accuracy, faithfulness, or groundedness of their outputs, potentially leading to various levels of harm. Specifically, there's a pressing need for chatbots to correctly disclose their non-human identity to comply with proposed legislation, as failure to do so can lead to legal implications. More broadly, guarantees are needed for queries related to safety-critical domains, such as medical advice, to prevent real-world harm.\n\n**Research Problem:**\nThe core research problem tackled by the paper is how to ensure that NLP systems can provide formally guaranteed outputs, particularly in scenarios that require maximum control over the output. A specific challenge within this broader problem is the verifiability of DNNs in the context of NLP, which involves guaranteeing that every point in a given region of the embedding space is classified correctly. However, due to the discrete nature of NLP data and the embedding gap issue, existing geometric verification methods from computer vision do not translate well to NLP. The paper seeks to bridge this gap by proposing methods to improve verifiability and generalisability of these semantic subspaces.\n\n**Relevant Prior Work:**\n1. **Application of Formal Verification Techniques**: Prior works have primarily focused on applying formal verification techniques to computer vision tasks, leveraging continuous vector spaces to ensure all points correspond to valid images. Key methods include equational reasoning, abstract interpretation, and bound propagation.\n   \n2. **Semantic Perturbations in NLP**: Some initial attempts at addressing the verification problem in NLP involve constructing subspaces based on semantic perturbations of sentences. Notable works include integrating simple geometric shapes like hyper-cubes and hyper-rectangles to form these subspaces, but issues remain regarding the optimal size and precision of these shapes.\n\n3. **Robust Training Regimes**: Robust training methods have previously been employed to improve the verifiability of subspaces in NLP, but it was unclear whether their success was due to dataset augmentation, adversarial robustness, or the utilization of semantic knowledge. The PGD algorithm and semantic adversarial attacks like polyjuice have been instrumental in this area.\n\nThe paper proposes novel refinements by suggesting a new methodology that includes the hyper-rectangle rotation to enhance shape precision of semantic subspaces. Moreover, it introduces a semantically robust training method using projected gradient descent on semantic subspaces, advancing the existing techniques of adversarial training and dataset augmentation. Through a series of experiments, the paper also seeks to introduce and validate a new generalisability metric, aiming at more principled evaluations of NLP verification methods.",
        "methodology": "**Proposed Method or Model**: The paper proposes a parametric NLP verification pipeline for certifying the robustness of NLP systems and large language models (LLMs). \n\n**Key Components and Innovations**:\n1. **Parametric Design**: Each component within the pipeline operates independently and can be studied or modified without affecting the others. This modular approach allows for greater flexibility and integration of state-of-the-art methods at each stage.\n\n2. **Integration with NLP Systems**: The pipeline can be applied on top of existing NLP systems or LLMs, such as S-BERT and S-GPT. This means it can certify the behavior of these deep neural networks (DNNs) when faced with safety-critical input queries.\n\n3. **Filter Mechanism**: The pipeline functions as a filter to ensure that the intended behaviors of the DNNs are maintained, enhancing the system's robustness and safety.\n\n**Innovative Implications**:\n- **Flexibility**: The parametric nature allows for sophisticated experimentation and customization, making it adaptable to various NLP contexts and advancements.\n- **Robustness Certification**: By serving as a filter, the pipeline ensures that the NLP systems behave as intended under critical conditions, thereby addressing concerns related to safety and reliability in real-world applications.\n\nThe methodology section promises to provide a detailed exposition of the methodological choices made at each step, which would elaborate on how these components and innovations are implemented in practice.",
        "main_experiment_and_results": "### Main Experiment Setup and Results:\n\n**Datasets**\nThe paper does not provide specific names of datasets used but implies the use of datasets appropriate for evaluating the generalisability and verifiability of subspaces in the context of NLP tasks.\n\n**Baselines**\nThe baselines for the main experiments include:\n- Geometric subspaces: This serves as a reference point to which other methods are compared.\n- Non-semantic robust training methods: Includes conventional adversarial training that does not specifically use semantic subspaces.\n\n**Evaluation Metrics**\nThe main evaluation metrics focus on two aspects:\n- **Verifiability**: The extent to which the network's robustness can be formally verified.\n- **Generalisability**: How well the trained network performs on unseen data while retaining robustness to adversarial inputs.\n\n**Main Experimental Results**\n1. **Verifiability vs. Generalisability Trade-off**:\n   - **Problem Introduction**: A detailed analysis of the inherent trade-off between generalisability and verifiability when geometric subspaces are used. It\u2019s shown that geometric subspaces, while being easier to verify, do not generalize as well.\n   \n2. **Semantic Subspaces for Better Balance**:\n   - The application of semantic subspaces finds a better equilibrium between verifiability and generalisability. This means semantic subspaces were capable of being both robustly verified and generalized better to new data compared to geometric subspaces.\n\n3. **Advantage of Adversarial Training on Semantic Subspaces**:\n   - Conducting adversarial training based on semantic subspaces has led to Deep Neural Networks (DNNs) that show superior verifiability and generalisability. This implies that networks trained with this method are both more robustly certifiable and perform better on unseen examples than those trained with traditional robust training techniques."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "Investigate the impact of using semantic subspaces compared to geometric subspaces on the verifiability and generalisability of DNNs in NLP verification.",
            "experiment_process": "The study starts with introducing the metric of generalisability of verified subspaces and setting up baseline experiments. It then introduces the verifiability-generalisability trade-off problem in the context of geometric subspaces. The experiments compare the use of purely geometric subspaces versus semantic subspaces derived from embeddings of sentences and their semantic perturbations. The comparison uses different robust training methodologies, specifically focusing on adversarial training based on semantic subspaces.",
            "result_discussion": "The study shows that using semantic subspaces helps to find a better balance between generalisability and verifiability compared to geometric subspaces. Adversarial training based on semantic subspaces results in DNNs that are both more verifiable and more generalisable than those obtained with other forms of robust training.",
            "ablation_id": "2403.10144v2.No1"
        },
        {
            "research_objective": "Analyze the pitfalls inherent in standard NLP methods for embedding and perturbing sentences and propose metrics to address falsifiability of verified subspaces.",
            "experiment_process": "The section applies the NLP Verification Pipeline using modern NLP tools and different large language models (LLMs). Specifically, it replaces Polyjuice with the LLM Vicuna-13b and tests various components of the NLP pipeline using the ANTONIO tool. It focuses on evaluating the correctness of subspaces dependent on the NLP parts of the pipeline that generate, perturb, and embed sentences. Several assumptions around locality of embedding functions and the sentence perturbation algorithm are tested. The study examines how deviations from these assumptions may lead to constructing falsifiable subspaces.",
            "result_discussion": "The study highlights that the correctness of specifications in NLP verification is highly dependent on the assumptions made about the NLP components. Failures in locality of embedding functions or sentence perturbation algorithms can lead to subspaces that are both formally verified and empirically falsified. A new falsifiability metric is introduced to be used alongside verifiability and generalisability metrics in NLP verification benchmarks to address and report the extent to which semantic subspaces are reliable.",
            "ablation_id": "2403.10144v2.No2"
        }
    ]
}