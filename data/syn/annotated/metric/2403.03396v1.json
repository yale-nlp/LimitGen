{
    "title": "Japanese-English Sentence Translation Exercises Dataset for Automatic Grading",
    "abstract": "This paper proposes the task of automatic assessment of Sentence Translation Exercises (STEs), that have been used in the early stage of L2 language learning. We formalize the task as grading student responses for each rubric criterion pre-specified by the educators. We then create a dataset for STE between Japanese and English including 21 questions, along with a total of student responses (on average). The answer responses were collected from students and crowd workers. Using this dataset, we demonstrate the performance of baselines including finetuned BERT and GPT models with few-shot in-context learning. Experimental results show that the baseline model with finetuned BERT was able to classify correct responses with approximately 90%, but only less than 80% for incorrect responses. Furthermore, the GPT models with few-shot learning show poorer results than finetuned BERT, indicating that our newly proposed task presents a challenging issue, even for the state-of-the-art large language models.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Sentence translation exercises (STEs) are often utilized as educational tools in the early stages of L2 language learning, particularly between language pairs that are linguistically distant from each other Cook (2010  ###reference_b5###); Butzkamm and Caldwell (2009  ###reference_b3###). Figure 1  ###reference_### shows an example of STE. Here, a learner translates a short sentence in their native language (L1) into the language they are learning (L2), and these translations are graded following analytic criteria within the grading rubric such as E3 and G4, which correspond to specific grammar items or expressions. ###figure_1### This format facilitates the recognition of similarities and differences between the native language and the target language, which is especially effective in helping learners acquire basic grammar and expressions in the early stages of their language learning, thus enhancing their understanding of the desired modes of expression Cook (2010  ###reference_b5###). The questions in these exercises are brief and repeatable tests that efficiently help learners practice specific grammatical items, basic vocabulary, and idioms at a certain proficiency level and learn the nuances of expression between L1 and L2. Teachers can also use these exercises as assessment tools to evaluate whether learners have mastered specific grammar items or a vocabulary level. However, because the responses to these exercises are descriptive, they pose a significant burden on educators in the form of manual grading and feedback. Such a limitation restricts the frequency of these exercises despite the importance of repetitive training in language acquisition  Larsen-Freeman (2012  ###reference_b21###). Therefore, automating the correction and feedback for translation exercises has the potential to significantly transform the educational environment in language learning. Therefore, we aim to automate the grading of L1-to-L2 STEs. Tasks that are closely associated with this challenge include Grammatical Error Correction (GEC), which evaluates the grammatical correctness of written sentences, and machine translation. STEs, however, are substantially different from these tasks in that they are usually operationalized with explicit learning objectives and closely reflect educators\u2019 intentions (\u00a72.1  ###reference_###). STEs not only clarify the learning objectives of a particular question but also allow for a more detailed learning analysis based on the performance of each evaluation item. The motivation for incorporating educators\u2019 intentions is also supported by studies that have found that the sole use of the GEC system does not elicit effective learner engagement Koltovskaia (2020  ###reference_b18###); Ranalli (2021  ###reference_b25###). To achieve our goal, we perform three tasks: (1) question formulation, (2) dataset creation, and (3) evaluation of baseline systems for our task. To the best of our knowledge, this is the first attempt at an automated STE grading for educational purposes. Therefore, we first formulate the question. An important aspect of this formulation is to ensure that the established framework reflects the educators\u2019 evaluation criteria. Consequently, we formulate our task as a classification of scores on each evaluation item according to the predefined rubrics. We then develop the dataset for this task. The questions and the rubric were created by English education experts, and answer scripts were collected from secondary education classrooms and through crowdsourcing. Finally, we evaluate the performance of the conventional automated scoring model typically used for short answer scoring (SAS), as well as the latest generative language models with few-shot learning. Experimental results showed that the baseline model using finetuned BERT successfully classified approximately 90% of correct responses, but only less than 80% of incorrect responses. Furthermore, GPT models with few-shot learning showed poorer results than the BERT model, indicating that even with a state-of-the-art LLM, our proposed new task remains difficult and challenging. Error analysis of the few-shot models revealed their lack of comprehension regarding the grading task. The contributions of this study are the following: We formulate the automated grading of sentence translation exercises as a new task, referencing the actual operation of STEs in educational settings. We construct a dataset for the automated STE grading in accordance with this task design, which includes a total of 21 questions and responses, and demonstrate the feasibility of the task. We establish baseline performances for the task, showing potential for advancement."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Automatic scoring of sentence translation exercises",
            "text": "For a given STE, let  denote the set of analytic criteria. For the input response text , the model outputs an analytic score  for a given analytic criterion , where 2, 1, and 0 represent \u201ccorrect,\u201d \u201cpartially correct,\u201d and \u201cincorrect,\u201d respectively."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Sentence translation exercises",
            "text": "Sentence translation exercises (STEs) are a language learning tool where a learner translates a sentence in L1 into a target L2. Studies have shown that the use of L1 in L2 education promotes an understanding of differences and similarities between the two languages Butzkamm and Caldwell (2009); Cook (2010), reduces incomprehension, and enhances learning focus Scott and De la Fuente (2008). Language translation has also been effective in improving students\u2019 four skills (speaking, writing, reading, listening) and promoting learning and communication skills Yasar Yuzlu and Dikilitas (2022). Because of these benefits, STEs are widely used in educational settings, particularly among beginners in language learning.\n\nFigure 1 shows an overview of an STE. A learner\u2019s translated response is assessed using a grading rubric meticulously designed by educators to evaluate the learner\u2019s L2 ability, such as vocabulary and grammatical understanding. Such a rubric contains multiple analytic criteria aligned with the specific pedagogical objectives that an educator intends to assess in the question. This aspect characterizes STE evaluation and distinguishes them from typical GEC tasks, which assess the overall correctness of the grammar. Evaluation based on the analytic scoring criteria highlights the degree to which the learning objectives are achieved. \n\nTo this end, some degree of constraint is imposed on the question design and answer choices, limiting the freedom of translation. However, if translation variations are observed, all possible expressions are accounted for. These restrictions in translation practice, as discussed in Cook (2010), prevent learners from easily avoiding knowledge gaps and direct their attention to L2 aspects that they may find challenging. Therefore, these constraints can be useful in focusing students\u2019 attention on specific language abilities. In addition, the evaluation of translated sentences in educational settings is also different from that of general translations in that the former involves pedagogical objectives such as the acquisition of specific language knowledge."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Task formulation",
            "text": "The purpose of assessing the STE task is to determine how well students\u2019 responses achieve the learning objectives defined by the instructors. To effectively do so, instructors use a carefully constructed scoring rubric. Each STE question targets several learning objectives and evaluates other fundamental grammatical items (e.g., number, tense, etc.); therefore, a scoring rubric contains multiple independent analytical criteria to evaluate specific items. These criteria serve as the basis for grading each student\u2019s response, with a corresponding analytic score assigned to each grading item (see Table 1). The automatic scoring of analytic criteria was formulated by Mizumoto et al. (2019) as an analytic score prediction task for reading comprehension questions. Therefore, this study also considers the analytic score prediction for the automatic scoring of STE. For a given STE, let denote the set of analytic criteria. For the input response text, the model outputs an analytic score for a given analytic criterion, where 2, 1, and 0 represent \u201ccorrect,\u201d \u201cpartially correct,\u201d and \u201cincorrect,\u201d respectively."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Sentence translation exercise (STEs) dataset",
            "text": "To implement the automatic STE scoring, we introduce an STE dataset. This dataset currently comprises 21 Japanese-to-English STE questions with detailed rubrics and annotated student responses. These questions and the scoring rubrics were created by specialists in the design of English learning materials. The questions were constructed to cover all the major grammar topics in several well-known English textbooks used in Japanese high schools. Table 1 shows an example of a rubric, which contains 17 analytic criteria: three for grammar (labeled as \u201cG\u201d), seven for vocabulary and expression (labeled as \u201cE\u201d), and seven for word order (labeled as \u201cO\u201d). Each analytic criterion is evaluated on a three-point scale: 2 (correct), 1 (partially correct), and 0 (incorrect); the rubric lists the typical expressions for each scale. Essentially, STEs are designed such that they limit variations in correct responses from the outset. In practical settings, however, educators may adjust the grading rubric by incorporating variations in correct responses, previously unidentified during the rubric\u2019s initial creation, to accurately evaluate the student responses. To replicate this process, we initially create the analytic criteria, followed by the collection of student responses as described in the following subsection. Subsequently, we refine the rubric by reviewing the collected responses, to preempt any challenges that may arise during the grading procedure. In the following sections, we will discuss in detail the methods used to gather responses, as well as the annotation process, and statistically analyze the whole dataset. Mizumoto et al. (2019) also annotated specific substrings within responses that contribute to an analytic score. These substrings are called justification cues because they serve as the rationale for the analytic scores. We also annotated justification cues in our dataset to enhance the interpretability of analytic scores. For example, in Figure 1, the phrase \u201cbefore I saw\u201d was annotated as a justification cue and was assigned an analytic score of \u201c.\u201d We then used the F-score to calculate agreement for justification cues. Regarding agreement for justification cues, the F-score was 0.92, signifying a high level of agreement among the annotators. This suggests that different annotators can consistently identify the same phrase as a justification cue for an analytic score. Table 2 shows the dataset statistics. We annotated a total of 3,498 responses for 21 questions, including 196 analytic criteria. For the pilot question, ranging from Q1 to Q7, scoring included 1 (partially correct) whereas the other questions followed a binary scoring of 2 (correct) and 0 (incorrect). Additionally, the number of instances with a grade of 0 was relatively fewer than those with a grade of 2. This distribution was similar to the one observed in the pilot question and others. Therefore, we conclude that we have successfully gathered crowdsourcing workers whose English ability is equivalent to that of original high school students and that these workers have attempted to answer those questions correctly."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Collecting student responses",
            "text": "Ideally, student responses are compiled within classrooms and other practical learning environments. However, the number of responses that can be collected from actual classrooms is often limited, and the collecting process is time-consuming. Therefore, we constructed our dataset through a combined approach involving high school students and crowdsourcing workers to collect responses for response collection. In this approach, we conducted a pilot data collection in which responses were obtained from high school students. Then, we analyzed these responses with English education experts and created the criteria for gathering crowdsourcing workers whose English abilities are equivalent to those of the high school students (see Appendix A for details regarding the recruitment criteria). Finally, we hired workers who met the criteria and allowed them to answer the questions, thus collecting a sufficient amount of responses. To maintain quality, we manually reviewed the collected responses and excluded those that significantly deviated from the expected responses. As a result, we obtained an average of 167 responses per question. The following section will present the statistics of the dataset."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Annotation:",
            "text": "As explained in Section 2.2, the scoring task for STEs involves grading on a three-class classification for each analytic criterion. Annotators are also asked to identify the specific phrase of the response that serves as a grading clue (referred to as justification cues). We annotated both types of information in each response. We hired professional graders to annotate those responses. As demonstrated in Figure 1, the annotators assigned an analytic score to the responses based on each analytic criterion. Mizumoto et al. (2019) also annotated specific substrings within responses that contribute to an analytic score. These substrings are called justification cues because they serve as the rationale for the analytic scores. We also annotated justification cues in our dataset to enhance the interpretability of analytic scores. For example, in Figure 1, the phrase \u201cbefore I saw\u201d was annotated as a justification cue and was assigned an analytic score of \u201c.\u201d To measure the quality of the annotations, we randomly selected 10 out of the 21 questions and asked a different annotator to annotate 20 responses for each question. Regarding agreement for justification cues, the F-score was 0.92, signifying a high level of agreement among the annotators. This suggests that different annotators can consistently identify the same phrase as a justification cue for an analytic score. Table 2 shows the dataset statistics. We annotated a total of 3,498 responses for 21 questions, including 196 analytic criteria. For the pilot question, ranging from Q1 to Q7, scoring included 1 (partially correct) whereas the other questions followed a binary scoring of 2 (correct) and 0 (incorrect). Additionally, the number of instances with a grade of 0 was relatively fewer than those with a grade of 2. This distribution was similar to the one observed in the pilot question and others. Therefore, we conclude that we have successfully gathered crowdsourcing workers whose English ability is equivalent to that of original high school students and that these workers have attempted to answer those questions correctly."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Method",
            "text": "We employ a BERT Devlin et al. (2019  ###reference_b7###)-based classification model and the GPT models OpenAI (2023  ###reference_b24###) with in-context learning as a baseline for our task formulation.\nThis section discusses these baseline models in detail.\nFirst, the response text sequence , with a prepended CLS token, is input into BERT, obtaining the intermediate representation  as follows:\nIn our task, a justification cue that indicates the rationale behind its score is provided for each response.\nBy utilizing this justification cue to train a model, we expect that the model will grade faithfully according to the rubric.\nTherefore, following  Mizumoto et al. (2019  ###reference_b22###), we use these justification cues as supervisory signals to train the model\u2019s attention layer.\nHere, we perform pooling on the BERT-encoded representations using a Bi-LSTM and attention mechanism.\nThe sequence obtained from  by excluding  is input into the Bi-LSTM, yielding .\nThen we calculate the weighted sum as follows:\nwhere  is the weight of the -th word relative to the scoring rubric , calculated by the attention mechanism shown in Equation (4.1  ###reference_###).\nwhere  and  are learnable parameters. Finally, the evaluation value  for item  is obtained by the following formula:\nwhere  and  are the learnable parameters.\nThe analytic scoring model is trained to minimize the negative log-likelihood  for each analytic score.\nwhere  is the label (evaluation value) of the ground truth for scoring rubric .\nIn addition, as discussed in the Section 3.2  ###reference_###, the dataset contains the justification cues  for each analytic criterion for the response, where\n is the indicator of whether the -th token in the response is the justification cue for the score of the analytic criterion .\nWhen the gold justification cue includes  tokens, the sum of  is . Therefore, as a gold signal for , we use  divided by  during the training process.\nFollowing Mizumoto et al. (2019  ###reference_b22###), we use the MSE-based loss function to achieve supervised training of the attentions with justification cues.\nThus, the overall loss  is expressed as:"
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Finetuned BERT model",
            "text": "We employ BERT, which is widely used in various NLP tasks, including SAS, as a baseline for this task.\nThis model is finetuened for each scoring item in the rubric using the training data.\nFirst, the response text sequence , with a prepended CLS token, is input into BERT, obtaining the intermediate representation  as follows:\nIn our task, a justification cue that indicates the rationale behind its score is provided for each response.\nBy utilizing this justification cue to train a model, we expect that the model will grade faithfully according to the rubric.\nTherefore, following  Mizumoto et al. (2019  ###reference_b22###  ###reference_b22###), we use these justification cues as supervisory signals to train the model\u2019s attention layer.\nHere, we perform pooling on the BERT-encoded representations using a Bi-LSTM and attention mechanism.\nThe sequence obtained from  by excluding  is input into the Bi-LSTM, yielding .\nThen we calculate the weighted sum as follows:\nwhere  is the weight of the -th word relative to the scoring rubric , calculated by the attention mechanism shown in Equation (4.1  ###reference_###  ###reference_###).\nwhere  and  are learnable parameters. Finally, the evaluation value  for item  is obtained by the following formula:\nwhere  and  are the learnable parameters.\nThe analytic scoring model is trained to minimize the negative log-likelihood  for each analytic score.\nwhere  is the label (evaluation value) of the ground truth for scoring rubric .\nIn addition, as discussed in the Section 3.2  ###reference_###  ###reference_###, the dataset contains the justification cues  for each analytic criterion for the response, where\n is the indicator of whether the -th token in the response is the justification cue for the score of the analytic criterion .\nWhen the gold justification cue includes  tokens, the sum of  is . Therefore, as a gold signal for , we use  divided by  during the training process.\nFollowing Mizumoto et al. (2019  ###reference_b22###  ###reference_b22###), we use the MSE-based loss function to achieve supervised training of the attentions with justification cues.\nThus, the overall loss  is expressed as:"
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "GPT models with in-context learning",
            "text": "We evaluate the GPT-3.5 and GPT-4 models in the setting of few-shot in-context learning Brown et al. (2020  ###reference_b1###), which significantly minimizes the cost of building a scoring model specific to each grading item as well as the training examples required for finetuning.\nFurthermore, the GPT series demonstrates superior performance in tasks such as translation and summarization, among other tasks Gladkoff et al. (2023  ###reference_b13###); Helwan et al. (2023  ###reference_b15###).\nTherefore, we can expect the proficiency in grammatical knowledge required for automatic grading of STEs.\n###figure_2### Figure 2  ###reference_### shows the input template for the GPT models.\nThe input can be segmented into two parts.\nThe first part is a prompt that includes a task instruction, a description of the output format, an L1 sentence for translation, a focused single analytic criterion, and the scoring examples corresponding to that criterion.\nThe analytic criterion is a (literal) textual representation of a rubric item described in a single row in Table 1  ###reference_###.\nFor each score label, we provide a few-shot examples to illustrate the analytic criterion and its scoring (output examples) for in-context learning.\nThe second part is a student response.\nThe model leverages these two inputs to generate a score label for the specified criterion and identify the substring of the student response that justifies the evaluation.\nIn the GPT models, we treat the grading of each analytic criterion within a prompt as an independent grading task, thus the GPT models output a score for each analytic criterion independently.\nMore details of the input prompt can be found in Table 5  ###reference_### in the appendix."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "In the experiment, we investigate the feasibility of our task formulation for STEs using the BERT model and the state-of-the-art large language models, GPT-4 and GPT-3.5.\nWe also investigate the impact of the number of in-context examples on the scoring performance.\nAs discussed in Section 5.2  ###reference_###, the models showed notably lower performance in grading incorrect responses than in grading correct responses.\nThis discrepancy may be due to the difference in the number of variations between correct and incorrect responses.\nAs shown in Figure 1  ###reference_###, the variation of acceptable correct responses is limited; meanwhile, the variation of incorrect responses shows considerable latitude, potentially encompassing any type of response besides the correct ones.\nConsequently, although the training data covered the majority of variations in correct responses, they cannot cover all potential incorrect responses.\nAdditionally, the GPT models significantly struggled in grading such incorrect responses, especially with fewer examples than the BERT models.\nTable 4  ###reference_### shows a grading error made by GPT-3.5, in which the model significantly failed to recognize an incorrect response.\nSuch grading errors constitute the majority of inaccurate predictions by GPT-3.5.\nWe hypothesized that these inaccuracies are due to the specialized prompt and response format of STEs, including scores, detailed rubrics, and justification cues.\nHence, during pretraining, GPTs are not exposed to such a task, despite the extensive corpora collected from the Web.\nUtilizing GPT-3.5 for few-shot in-context learning is expected to be more suitable for classroom applications than fine-tuning the model with a substantial amount of training data.\nHowever, our observations suggest that this application of GPT-3.5 is inadequate for grading STEs.\nTo investigate the appropriate number of in-context examples, we evaluate performance by varying the number of examples provided in the prompt.\nFigure 3  ###reference_### illustrates the -score of GPT-3.5 for each label as the number of in-context examples is varied between one, two, five, and 10.\nFrom the result, we can clearly see that the grading performance hardly changed even when the number of in-context examples was increased to more than two.\nAs a reason for this, in grading for correct responses, it is considered that our task design inherently results in a very limited number of patterns corresponding to correct expressions. Therefore, increasing the number of instruction samples may not significantly influence the accuracy for correct responses.\nIn the grading of incorrect responses, a considerable number of instances are labeled as incorrect due to the absence of expressions equivalent to the correct answers.\nIn such cases, justification cue string is not given in the instruction for GPTs and this makes it challenging to grasp scoring clues from the provided instruction examples, likely hindering the effective learning of appropriate grading and consequently impeding performance improvement.\n###figure_3###"
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "Settings",
            "text": "In our dataset, the label \u201cpartially correct\u201d was infrequently used, which transformed the grading of certain criteria into a binary classification task.\nTherefore, we used the -score to evaluate the performance of the analytic score prediction as it applies to both three-class and binary classification.\nWe also performed a 5-fold cross-validation by dividing the dataset of each question into a training set, a development set, and an evaluation set following a 3:1:1 ratio.\nWe finetuned the BERT model (described in Section 4  ###reference_###) for 50 epochs on each training set.\nFor each epoch, we calculated -score for each analytic criterion and used the parameters that produced the best results on the development set for each analytic criterion, respectively.\nAppendix C  ###reference_### provides details regarding these hyperparameters.\nFor the GPT models, we randomly selected few-shot examples for each score from the training set.\nSome analytic criteria contained extremely few incorrect responses because typical high school students found them too easy. Therefore, to ensure a proper performance evaluation, we used only those criteria that contained 10% or more incorrect instances."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "Results",
            "text": "Table 3  ###reference_### shows the performance of BERT, GPT-3.5, and GPT-4 on the test set in terms of  averages and standard deviations for each category (Expression, Word Order, Grammar).\nIn Section 4.2  ###reference_###, we hypothesized that the GPT models would demonstrate excellent performance because STEs evaluate the validity of English sentences within a highly limited grammar and vocabulary scope presented in an analytic criterion.\nSurprisingly, however, the BERT model outperformed the GPT models on our dataset.\nNevertheless, both models showed relatively high performance in grading correct responses.\nMeanwhile, the GPT models performed notably lower in grading incorrect responses.\nInterestingly, however, the GPT models outperformed BERT in grading partially correct responses.\nThis may be due to the limited data size for fine-tuning the BERT model for partially correct responses.\nWe also observed that the standard deviation exceeded 0.10 for nearly all results, indicating a substantial variance in grading performance across different analytic criteria, some of which showed poor results.\nThe result suggests that the grading of several analytic criteria is challenging for models.\nLLMs acquire sufficient knowledge about language, including grammar and vocabulary, through pretraining on massive corpora. However, these results showed that STEs grading remains a challenging task even for a cutting-edge LLM such as GPT-4, when provided with only few-shot examples.\nFurthermore, collecting and annotating enough responses to train the STE grading model poses a significant burden in actual educational settings, allowing room for improvement in deploying automatic grading models in actual classrooms."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "Analysis",
            "text": "As discussed in Section 5.2  ###reference_###  ###reference_###, the models showed notably lower performance in grading incorrect responses than in grading correct responses.\nThis discrepancy may be due to the difference in the number of variations between correct and incorrect responses.\nAs shown in Figure 1  ###reference_###  ###reference_###, the variation of acceptable correct responses is limited; meanwhile, the variation of incorrect responses shows considerable latitude, potentially encompassing any type of response besides the correct ones.\nConsequently, although the training data covered the majority of variations in correct responses, they cannot cover all potential incorrect responses.\nAdditionally, the GPT models significantly struggled in grading such incorrect responses, especially with fewer examples than the BERT models.\nTable 4  ###reference_###  ###reference_### shows a grading error made by GPT-3.5, in which the model significantly failed to recognize an incorrect response.\nSuch grading errors constitute the majority of inaccurate predictions by GPT-3.5.\nWe hypothesized that these inaccuracies are due to the specialized prompt and response format of STEs, including scores, detailed rubrics, and justification cues.\nHence, during pretraining, GPTs are not exposed to such a task, despite the extensive corpora collected from the Web.\nUtilizing GPT-3.5 for few-shot in-context learning is expected to be more suitable for classroom applications than fine-tuning the model with a substantial amount of training data.\nHowever, our observations suggest that this application of GPT-3.5 is inadequate for grading STEs.\nTo investigate the appropriate number of in-context examples, we evaluate performance by varying the number of examples provided in the prompt.\nFigure 3  ###reference_###  ###reference_### illustrates the -score of GPT-3.5 for each label as the number of in-context examples is varied between one, two, five, and 10.\nFrom the result, we can clearly see that the grading performance hardly changed even when the number of in-context examples was increased to more than two.\nAs a reason for this, in grading for correct responses, it is considered that our task design inherently results in a very limited number of patterns corresponding to correct expressions. Therefore, increasing the number of instruction samples may not significantly influence the accuracy for correct responses.\nIn the grading of incorrect responses, a considerable number of instances are labeled as incorrect due to the absence of expressions equivalent to the correct answers.\nIn such cases, justification cue string is not given in the instruction for GPTs and this makes it challenging to grasp scoring clues from the provided instruction examples, likely hindering the effective learning of appropriate grading and consequently impeding performance improvement.\n###figure_4###"
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Related work",
            "text": "Grammar Error Correction (GEC) and Short Answer Scoring (SAS) are the two major research areas in the automatic evaluation of descriptive English responses.\nWe position this study between these two research domains.\nThe dataset we created for the STE task followed the format of the RIKEN SAS dataset, which contains questions on Japanese reading comprehension questions Mizumoto et al. (2019  ###reference_b22###); Funayama et al. (2023  ###reference_b11###).\nOther SAS datasets include BEETLE  Dzikovska et al. (2013  ###reference_b8###), ASAP-SAS,222https://www.kaggle.com/c/asap-sas/  ###reference_### Powergrading, and the SAF dataset Filighera et al. (2022  ###reference_b10###), which focus on science or reading comprehension.\nOur dataset is the first STE dataset to concentrate on grading grammar and vocabulary use."
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "Grammar Error Correction (GEC)",
            "text": "The most famous GEC system is Grammarly,111https://www.grammarly.com  ###reference_www.grammarly.com### a writing assistant tool that also plays an important role in English learning Ranalli (2021  ###reference_b25###); Koltovskaia (2020  ###reference_b18###).\nIn a more educational context,  Nagata (2019  ###reference_b23###) proposed the task of feedback generation in GEC with a focus on effective ESL (English as a Second Language) learning.\nSome studies have also focused on methods to generate feedback for grammatical errors in sentences written by learners Hanawa et al. (2021  ###reference_b14###); Coyne (2023  ###reference_b6###); Lai and Chang (2019  ###reference_b19###).\nRegarding the use of LLMs in GEC, Fang et al. (2023  ###reference_b9###) reported that GPT-3.5 shows excellent GEC abilities.\nAll these previous studies have focused primarily on identifying grammatical errors present in freely-composed text.\nHowever, within real-world educational contexts that require the measurement of student progress in language learning, educators must direct their attention to the assessment of not only overarching grammatical constructs but also a precise understanding of certain grammatical or vocabulary items within specific units of English textbooks.\nSuch a methodology would determine students\u2019 comprehension and areas of unfamiliarity more accurately.\nTherefore, we adopted this practical approach by developing STEs specifically designed to evaluate students\u2019 understanding of various grammatical topics."
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "Short Answer Scoring (SAS)",
            "text": "We have formally defined our STE grading task within the established framework of the automated SAS task.\nHowever, these two tasks fundamentally differ in terms of their intended objectives and the descriptive content to be evaluated.\nSeveral SAS studies have primarily examined closed-domain questions that require knowledge and understanding in specific areas, such as science or reading comprehension Mizumoto et al. (2019  ###reference_b22###); Burrows et al. (2015  ###reference_b2###); Galhardi and Brancher (2018  ###reference_b12###), and a typical SAS framework does not directly consider grammatical errors and word usage errors in responses.\nIn this study, we created detailed and stringent analytic criteria for measuring learners\u2019 English proficiency, focusing on the grammatical aspects addressed in the questions.\nThe dataset we created for the STE task followed the format of the RIKEN SAS dataset, which contains questions on Japanese reading comprehension questions Mizumoto et al. (2019  ###reference_b22###  ###reference_b22###); Funayama et al. (2023  ###reference_b11###  ###reference_b11###).\nOther SAS datasets include BEETLE  Dzikovska et al. (2013  ###reference_b8###  ###reference_b8###), ASAP-SAS,222https://www.kaggle.com/c/asap-sas/  ###reference_###  ###reference_### Powergrading, and the SAF dataset Filighera et al. (2022  ###reference_b10###  ###reference_b10###), which focus on science or reading comprehension.\nOur dataset is the first STE dataset to concentrate on grading grammar and vocabulary use."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "This study introduced a novel task focusing on the automatic grading of Sentence Translation Exercises (STEs) for educational purposes. We formalized STEs as a task of grading each analytic criterion predetermined by teachers\u2019 intentions and constructed a dataset to implement the task. This first-of-its-kind dataset emulates and reflects the practical form of L2 learning in the responses of learners. We also used finetuned BERT and GPTs with few-shot in-context learning to establish a baseline and demonstrate the feasibility of the formulated framework. In our experiment, although the GPT models showed substantial performance in various NLP tasks, they remained inferior to the BERT model, suggesting that our newly defined task continues to be challenging even for the state-of-the-art LLMs, therefore necessitating further exploration. With regard to future direction, we are contemplating the integration of technologies such as GEC and machine translation within our model. We aim to build cross-questions strategies to automatically identify expressions that diverge from a provided rubric while preserving the text\u2019s fundamental meaning using a combination of these technologies. For this purpose, our plan involves further subdividing the STE grading task and leveraging LLMs to address each minimized task such as correcting grammatical errors, assessing the consistency of meaning with L1, and identifying expressions aligned with the learning objectives in each exercise. This approach also aims to investigate tasks where LLMs may not excel in STE scoring and enhance their overall performance. Additionally, in an educational context, we also consider generating more comprehensive feedback comments on the scoring results, extending beyond the estimation of justification cues."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Recruitment criteria",
            "text": "The recruitment criteria for selecting workers are as follows: (1) TOFEL iBT: 55-70, (2) TOEIC L&R: 550-750, and (3) The National Center Test: 140 points or higher 333The Center Test is a standardized test included in the entrance examination of almost all universities in Japan.. In addition, we also conducted a pretest on candidates for crowdsourcing workers, which consisted of 10 easy STE questions, and we only hired those who answered all of them correctly."
        },
        {
            "section_id": "Appendix 2",
            "parent_section_id": null,
            "section_name": "Appendix B Prompt example for the GPT models",
            "text": "Table 5  ###reference_### shows an example of a prompt in Q11 used for the GPT models.\nWe input the data into GPTs for each analytic criterion independently. We also input in-context examples for each label."
        },
        {
            "section_id": "Appendix 3",
            "parent_section_id": null,
            "section_name": "Appendix C Implementation and hyperparameter",
            "text": "We implemented our BERT model444We used a pretrained model from https://huggingface.co/bert-base-uncased  ###reference_### using the Hugging Face library Wolf et al. (2020  ###reference_b28###). During the fine-tuning, we used Adam Kingma and Ba (2014  ###reference_b17###) as the optimizer and set the learning rate to 0.001. The dimension of the hidden state in the Bi-LSTM was set to 128. We also used a batch size of 10, as our dataset contained a relatively small amount of training data."
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S2.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S2.T1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.1.1.1.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.1.1\">Chunk</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.2.1\">Category</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S2.T1.1.1.1.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.3.1\">Correct (2)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S2.T1.1.1.1.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.4.1\">Incorrect (0)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.1.2.2.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S2.T1.1.2.2.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.2.2.1.1.1\">\n<span class=\"ltx_tr\" id=\"S2.T1.1.2.2.1.1.1.1\">\n<span class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.2.2.1.1.1.1.1\">\u79c1\u306f</span></span>\n<span class=\"ltx_tr\" id=\"S2.T1.1.2.2.1.1.1.2\">\n<span class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.2.2.1.1.1.2.1\">(I)</span></span>\n</span></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.2.2.2\">E</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.2.2.3\">Expressed as \"I\"</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.2.2.4\">Otherwise</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.3.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.3.3.1\">O</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.3.3.2\">Word order is \"before + Subject\"</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.3.3.3\">Not \"before + Subject\"</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.1.4.4.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S2.T1.1.4.4.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.4.4.1.1.1\">\n<span class=\"ltx_tr\" id=\"S2.T1.1.4.4.1.1.1.1\">\n<span class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.4.4.1.1.1.1.1\">\u4e00\u6628\u5e74\u306b</span></span>\n<span class=\"ltx_tr\" id=\"S2.T1.1.4.4.1.1.1.2\">\n<span class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.4.4.1.1.1.2.1\">(two years ago)</span></span>\n</span></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.4.4.2\">E</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.4.4.3\">Expressed as \"two years ago\" or \u2026</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.4.4.4\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.4.4.4.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.4.4.4.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.4.4.4.1.1.1\">\"in the year before last\"</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.4.4.4.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.4.4.4.1.2.1\">and otherwise</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.5.5\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.5.5.1\">O</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.5.5.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.5.5.2.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.5.5.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.5.5.2.1.1.1\">Word order is \"in Australia &lt;chunk&gt;\" or \u2026</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.5.5.3\">Otherwise</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.1.6.6.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S2.T1.1.6.6.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.6.6.1.1.1\">\n<span class=\"ltx_tr\" id=\"S2.T1.1.6.6.1.1.1.1\">\n<span class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.6.6.1.1.1.1.1\">\u30aa\u30fc\u30b9\u30c8\u30e9\u30ea\u30a2\u3067</span></span>\n<span class=\"ltx_tr\" id=\"S2.T1.1.6.6.1.1.1.2\">\n<span class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.6.6.1.1.1.2.1\">(in Australia)</span></span>\n</span></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.6.6.2\">E</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.6.6.3\">Expressed as \"in Australia\"</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.6.6.4\">Otherwise</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.7.7\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.7.7.1\">O</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.7.7.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.7.7.2.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.7.7.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.7.7.2.1.1.1\">Word order is \"&lt;chunk&gt; two years ago\" or \u2026</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.7.7.3\">Otherwise</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.1.8.8.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S2.T1.1.8.8.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.8.8.1.1.1\">\n<span class=\"ltx_tr\" id=\"S2.T1.1.8.8.1.1.1.1\">\n<span class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.8.8.1.1.1.1.1\">\u898b\u308b\u307e\u3067</span></span>\n<span class=\"ltx_tr\" id=\"S2.T1.1.8.8.1.1.1.2\">\n<span class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.8.8.1.1.1.2.1\">(before I saw)</span></span>\n</span></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.8.8.2\">E</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.8.8.3\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.8.8.3.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.8.8.3.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.8.8.3.1.1.1\">Expressed as \"before I saw one,\"</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.8.8.3.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.8.8.3.1.2.1\">\"before I saw some,\" or \u2026</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.8.8.4\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.8.8.4.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.8.8.4.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.8.8.4.1.1.1\">The word \"it\" is used</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.8.8.4.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.8.8.4.1.2.1\">instead of \"one\" / \u2026</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.9.9\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.9.9.1\">O</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.9.9.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.9.9.2.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.9.9.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.9.9.2.1.1.1\">The order is</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.9.9.2.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.9.9.2.1.2.1\">\"Conjunction + Subject + Verb + Object\"</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.9.9.3\">Otherwise</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.10.10\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.10.10.1\">G</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.10.10.2\">The past tense\"saw\" is used.</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.10.10.3\">\"saw\" is not used</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.11.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.1.11.11.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S2.T1.1.11.11.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.11.11.1.1.1\">\n<span class=\"ltx_tr\" id=\"S2.T1.1.11.11.1.1.1.1\">\n<span class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.11.11.1.1.1.1.1\">\u30b3\u30a2\u30e9\u3092</span></span>\n<span class=\"ltx_tr\" id=\"S2.T1.1.11.11.1.1.1.2\">\n<span class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.11.11.1.1.1.2.1\">(a koala)</span></span>\n</span></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.11.11.2\">E</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.11.11.3\">Expressed as\"a koala, \" \"koalas,\" \"any koalas,\"\u2026</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.11.11.4\">Otherwise</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.12.12\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.12.12.1\">O</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.12.12.2\">The word immediately follows \"seen\"</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.12.12.3\">Otherwise</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.13.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.1.13.13.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S2.T1.1.13.13.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.13.13.1.1.1\">\n<span class=\"ltx_tr\" id=\"S2.T1.1.13.13.1.1.1.1\">\n<span class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.13.13.1.1.1.1.1\">\u898b\u305f</span></span>\n<span class=\"ltx_tr\" id=\"S2.T1.1.13.13.1.1.1.2\">\n<span class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.13.13.1.1.1.2.1\">(seen)</span></span>\n</span></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.13.13.2\">E</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.13.13.3\">Expressed as \"seen\"</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.13.13.4\">Otherwise</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.14.14\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.14.14.1\">O</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.14.14.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.14.14.2.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.14.14.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.14.14.2.1.1.1\">It is placed immediately after \"never,\" \"not,\" or \"n\u2019t.\"</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.14.14.3\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.14.14.3.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.14.14.3.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.14.14.3.1.1.1\">Otherwise</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.15.15\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.15.15.1\">G</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.15.15.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.15.15.2.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.15.15.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.15.15.2.1.1.1\">The past participle form \"seen\" is used</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.15.15.3\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.15.15.3.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.15.15.3.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.15.15.3.1.1.1\">Otherwise</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.16.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.1.16.16.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S2.T1.1.16.16.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.16.16.1.1.1\">\n<span class=\"ltx_tr\" id=\"S2.T1.1.16.16.1.1.1.1\">\n<span class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.16.16.1.1.1.1.1\">\uff5e\u3053\u3068\u304c\u306a\u304b\u3063\u305f</span></span>\n<span class=\"ltx_tr\" id=\"S2.T1.1.16.16.1.1.1.2\">\n<span class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.16.16.1.1.1.2.1\">(had never)</span></span>\n</span></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.16.16.2\">E</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.16.16.3\">Expressed as \"I had never,\" \"I had not,\" \u2026</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.16.16.4\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.16.16.4.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.16.16.4.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.16.16.4.1.1.1\">Expressed as \"I have</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.16.16.4.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.16.16.4.1.2.1\">never\", \u2026 , and others</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.17.17\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S2.T1.1.17.17.1\">O</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.17.17.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.17.17.2.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.17.17.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.17.17.2.1.1.1\">The word order is \"Subject + Verb\"</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.1.17.17.3\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.17.17.3.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.17.17.3.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.17.17.3.1.1.1\">Otherwise</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.18.18\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\" id=\"S2.T1.1.18.18.1\">G</th>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S2.T1.1.18.18.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.18.18.2.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.18.18.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.18.18.2.1.1.1\">The past perfect tense is used</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S2.T1.1.18.18.3\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1.18.18.3.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.18.18.3.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.18.18.3.1.1.1\">The present perfect or</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.18.18.3.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.18.18.3.1.2.1\">past tense are used</td>\n</tr>\n</table>\n</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Examples of analytic criteria excerpted from Q11: \u201c<span class=\"ltx_text ltx_font_italic\" id=\"S2.T1.3.1\">I had never seen a koala before I saw one in Australia two years ago.</span>\u201d \u201cChunk\u201d denotes a Japanese phrasal unit, often referred to as \u201cbunsetsu.\u201d Every chunk invariably includes the category E (Expression), with some incorporating the categories O (Word Order) and G (Grammar). The analytic criterion covers examples of expressions and structural patterns that correspond to each label.</figcaption>\n</figure>",
            "capture": "Table 1: Examples of analytic criteria excerpted from Q11: \u201cI had never seen a koala before I saw one in Australia two years ago.\u201d \u201cChunk\u201d denotes a Japanese phrasal unit, often referred to as \u201cbunsetsu.\u201d Every chunk invariably includes the category E (Expression), with some incorporating the categories O (Word Order) and G (Grammar). The analytic criterion covers examples of expressions and structural patterns that correspond to each label."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T2\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S3.T2.1.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S3.T2.1.1.1.2\">#Ans</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T2.1.1.1.3\">#Criteria</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T2.1.1.1.4\">2</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T2.1.1.1.5\">1</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T2.1.1.1.6\">0</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T2.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.1.2.1.1\">Q1</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.1.2.1.2\">159</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T2.1.2.1.3\">9</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T2.1.2.1.4\">923</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T2.1.2.1.5\">114</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T2.1.2.1.6\">235</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.3.2.1\">Q2</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.3.2.2\">172</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.3.2.3\">8</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.3.2.4\">652</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.3.2.5\">98</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.3.2.6\">454</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.4.3.1\">Q3</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.4.3.2\">77</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.4.3.3\">8</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.4.3.4\">357</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.4.3.5\">40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.4.3.6\">142</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.5.4.1\">Q4</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.5.4.2\">69</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.5.4.3\">9</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.5.4.4\">356</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.5.4.5\">76</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.5.4.6\">120</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.6.5.1\">Q5</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.6.5.2\">102</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.6.5.3\">9</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.6.5.4\">387</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.6.5.5\">161</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.6.5.6\">268</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.7.6.1\">Q6</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.7.6.2\">79</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.7.6.3\">12</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.7.6.4\">701</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.7.6.5\">14</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.7.6.6\">154</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.8.7.1\">Q7</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.8.7.2\">90</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.8.7.3\">10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.8.7.4\">534</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.8.7.5\">72</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.8.7.6\">204</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.9.8.1\">Q8</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.9.8.2\">200 (173)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.9.8.3\">6</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.9.8.4\">856</td>\n<td class=\"ltx_td\" id=\"S3.T2.1.9.8.5\"></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.9.8.6\">343</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.10.9.1\">Q9</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.10.9.2\">200 (169)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.10.9.3\">10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.10.9.4\">1324</td>\n<td class=\"ltx_td\" id=\"S3.T2.1.10.9.5\"></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.10.9.6\">676</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.11.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.11.10.1\">Q10</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.11.10.2\">200 (180)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.11.10.3\">9</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.11.10.4\">1197</td>\n<td class=\"ltx_td\" id=\"S3.T2.1.11.10.5\"></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.11.10.6\">612</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.12.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.12.11.1\">Q11</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.12.11.2\">200 (142)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.12.11.3\">10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.12.11.4\">1285</td>\n<td class=\"ltx_td\" id=\"S3.T2.1.12.11.5\"></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.12.11.6\">715</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.13.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.13.12.1\">Q12</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.13.12.2\">200 (135)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.13.12.3\">8</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.13.12.4\">1175</td>\n<td class=\"ltx_td\" id=\"S3.T2.1.13.12.5\"></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.13.12.6\">425</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.14.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.14.13.1\">Q13</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.14.13.2\">200 (137)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.14.13.3\">7</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.14.13.4\">850</td>\n<td class=\"ltx_td\" id=\"S3.T2.1.14.13.5\"></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.14.13.6\">550</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.15.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.15.14.1\">Q14</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.15.14.2\">150 (97)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.15.14.3\">8</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.15.14.4\">847</td>\n<td class=\"ltx_td\" id=\"S3.T2.1.15.14.5\"></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.15.14.6\">353</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.16.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.16.15.1\">Q15</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.16.15.2\">200 (159)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.16.15.3\">11</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.16.15.4\">1347</td>\n<td class=\"ltx_td\" id=\"S3.T2.1.16.15.5\"></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.16.15.6\">853</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.17.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.17.16.1\">Q16</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.17.16.2\">200 (144)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.17.16.3\">10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.17.16.4\">1565</td>\n<td class=\"ltx_td\" id=\"S3.T2.1.17.16.5\"></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.17.16.6\">435</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.18.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.18.17.1\">Q17</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.18.17.2\">200 (162)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.18.17.3\">11</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.18.17.4\">1082</td>\n<td class=\"ltx_td\" id=\"S3.T2.1.18.17.5\"></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.18.17.6\">1118</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.19.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.19.18.1\">Q18</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.19.18.2\">200 (162)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.19.18.3\">9</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.19.18.4\">1220</td>\n<td class=\"ltx_td\" id=\"S3.T2.1.19.18.5\"></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.19.18.6\">580</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.20.19\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.20.19.1\">Q19</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.20.19.2\">200 (166)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.20.19.3\">12</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.20.19.4\">1671</td>\n<td class=\"ltx_td\" id=\"S3.T2.1.20.19.5\"></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.20.19.6\">729</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.21.20\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.21.20.1\">Q20</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row\" id=\"S3.T2.1.21.20.2\">200 (149)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.21.20.3\">8</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.21.20.4\">1064</td>\n<td class=\"ltx_td\" id=\"S3.T2.1.21.20.5\"></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.1.21.20.6\">536</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.22.21\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T2.1.22.21.1\">Q21</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T2.1.22.21.2\">200 (131)</th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T2.1.22.21.3\">12</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T2.1.22.21.4\">1538</td>\n<td class=\"ltx_td ltx_border_bb\" id=\"S3.T2.1.22.21.5\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T2.1.22.21.6\">862</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>STE dataset statistics. The integers 2, 1, and 0 stand for \u201ccorrect,\u201d \u201cpartially correct,\u201d and \u201cincorrect\u201d labels, respectively. Q8 through Q21 include some identical responses following the distribution of the collected data. We show the number of distinct responses in parentheses.</figcaption>\n</figure>",
            "capture": "Table 2: STE dataset statistics. The integers 2, 1, and 0 stand for \u201ccorrect,\u201d \u201cpartially correct,\u201d and \u201cincorrect\u201d labels, respectively. Q8 through Q21 include some identical responses following the distribution of the collected data. We show the number of distinct responses in parentheses."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T3\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.3\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.3.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.3.1.1.1\" rowspan=\"2\">\n<span class=\"ltx_text\" id=\"S4.T3.3.1.1.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S4.T3.3.1.1.1.1.1\">\n<span class=\"ltx_tr\" id=\"S4.T3.3.1.1.1.1.1.1\">\n<span class=\"ltx_td ltx_align_left\" id=\"S4.T3.3.1.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.1.1.1.1.1.1.1.1\">Category</span></span></span>\n<span class=\"ltx_tr\" id=\"S4.T3.3.1.1.1.1.1.2\">\n<span class=\"ltx_td ltx_align_left\" id=\"S4.T3.3.1.1.1.1.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.1.1.1.1.1.2.1.1\">(#criteria)</span></span></span>\n</span></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S4.T3.3.1.1.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.1.1.2.1\">BERT</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S4.T3.3.1.1.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.1.1.3.1\">GPT-3.5 (2 shots)</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.2.2.1\">Correct</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.2.2.2\">Partial. Correct</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.2.2.3\">Incorrect</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.2.2.4\">Correct</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.2.2.5\">Partial. Correct</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.2.2.6\">Incorrect</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.3.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.3.3.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.3.3.1.1\">E : (96)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.3.3.3.2\">0.92\u00b1 0.15</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.3.3.3.3\">0.64\u00b10.36</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.3.3.3.4\">0.82\u00b10.24</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.3.3.3.5\">0.83\u00b1 0.12</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.3.3.3.6\">0.80\u00b10.23</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.3.3.3.7\">0.62\u00b10.20</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.4.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.4.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.4.4.1.1\">O : (42)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.4.4.2\">0.95\u00b10.05</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.4.4.3\">nan</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.4.4.4\">0.79\u00b10.25</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.4.4.5\">0.78\u00b10.11</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.4.4.6\">nan</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.4.4.7\">0.52\u00b10.21</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.5.5\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.3.5.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.5.5.1.1\">G : (45)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.3.5.5.2\">0.94\u00b10.11</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.3.5.5.3\">0.81\u00b10.21</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.3.5.5.4\">0.88\u00b10.13</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.3.5.5.5\">0.81\u00b10.13</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.3.5.5.6\">0.48\u00b10.11</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.3.5.5.7\">0.63\u00b10.25</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.6.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.6.6.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.6.6.1.1\">All</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.6.6.2\">0.93</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.6.6.3\">0.68</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.6.6.4\">0.83</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.6.6.5\">0.81</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.6.6.6\">0.73</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.6.6.7\">0.59</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt ltx_border_tt\" id=\"S4.T3.3.7.7.1\" rowspan=\"2\">\n<span class=\"ltx_text\" id=\"S4.T3.3.7.7.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S4.T3.3.7.7.1.1.1\">\n<span class=\"ltx_tr\" id=\"S4.T3.3.7.7.1.1.1.1\">\n<span class=\"ltx_td ltx_align_left\" id=\"S4.T3.3.7.7.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.7.7.1.1.1.1.1.1\">Category</span></span></span>\n<span class=\"ltx_tr\" id=\"S4.T3.3.7.7.1.1.1.2\">\n<span class=\"ltx_td ltx_align_left\" id=\"S4.T3.3.7.7.1.1.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.7.7.1.1.1.2.1.1\">(#criteria)</span></span></span>\n</span></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt\" colspan=\"3\" id=\"S4.T3.3.7.7.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.7.7.2.1\">GPT-3.5 (5 shots)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt\" colspan=\"3\" id=\"S4.T3.3.7.7.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.7.7.3.1\">GPT-4 (2 shots)</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.8.8\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.8.8.1\">Correct</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.8.8.2\">Partial. Correct</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.8.8.3\">Incorrect</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.8.8.4\">Correct</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.8.8.5\">Partial. Correct</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.8.8.6\">Incorrect</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.9.9\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.3.9.9.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.9.9.1.1\">E : (96)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.3.9.9.2\">0.84\u00b1 0.12</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.3.9.9.3\">0.79\u00b10.23</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.3.9.9.4\">0.65\u00b10.18</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.3.9.9.5\">0.91\u00b1 0.09</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.3.9.9.6\">0.80\u00b10.15</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.3.9.9.7\">0.78\u00b10.20</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.10.10\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.10.10.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.10.10.1.1\">O : (42)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.10.10.2\">0.80\u00b10.12</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.10.10.3\">nan</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.10.10.4\">0.53\u00b10.21</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.10.10.5\">0.87\u00b10.08</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.10.10.6\">nan</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.10.10.7\">0.65\u00b10.21</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.11.11\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.3.11.11.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.11.11.1.1\">G : (45)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.3.11.11.2\">0.82\u00b10.13</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.3.11.11.3\">0.48\u00b10.11</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.3.11.11.4\">0.64\u00b10.28</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.3.11.11.5\">0.90\u00b10.08</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.3.11.11.6\">0.62\u00b10.37</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.3.11.11.7\">0.77\u00b10.24</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.12.12\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.3.12.12.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.12.12.1.1\">All</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.3.12.12.2\">0.83</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.3.12.12.3\">0.73</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.3.12.12.4\">0.61</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.3.12.12.5\">0.89</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.3.12.12.6\">0.76</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.3.12.12.7\">0.73</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span> scores and standard deviations of the baseline models for each score label of the analytic criteria categories (E: Expression, O: Word Order, G: Grammar). The analytic criteria for the Word Order category do not include any partially correct expressions; therefore, the corresponding values are represented as \u201cnan.\u201d</figcaption>\n</figure>",
            "capture": "Table 3:  scores and standard deviations of the baseline models for each score label of the analytic criteria categories (E: Expression, O: Word Order, G: Grammar). The analytic criteria for the Word Order category do not include any partially correct expressions; therefore, the corresponding values are represented as \u201cnan.\u201d"
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T4\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T4.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T4.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.1.1.1.1.1\">Input summary</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T4.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.1.2.1.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T4.1.2.1.1.1\">\n<tr class=\"ltx_tr\" id=\"S5.T4.1.2.1.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.2.1.1.1.1.1\">Sentence:</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.2.1.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.2.1.1.1.2.1\">\u79c1\u306f / \u4e00\u6628\u5e74\u306b / \u30aa\u30fc\u30b9\u30c8\u30e9\u30ea\u30a2\u3067 / \u898b\u308b\u307e\u3067 /</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.2.1.1.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.2.1.1.1.3.1\">\u30b3\u30a2\u30e9\u3092 / \u898b\u305f / \u3053\u3068\u304c\u306a\u304b\u3063\u305f</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.2.1.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.2.1.1.1.4.1\">(I / the year before last / in Australia / before I saw one</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.2.1.1.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.2.1.1.1.5.1\">/ a koala / seen / had never)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.2.1.1.1.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.2.1.1.1.6.1\">Analytic criteria: G1 (Tense)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.2.1.1.1.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.2.1.1.1.7.1\">- Past tense \"saw\" is used as a verb</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.2.1.1.1.8\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.2.1.1.1.8.1\">Student answer:</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.2.1.1.1.9\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.2.1.1.1.9.1\">I had never seen a koala before I have seen it</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.2.1.1.1.10\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.2.1.1.1.10.1\">two years ago in Australia .</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.3.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T4.1.3.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.1.3.2.1.1\">GPT output &amp; (gold data)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.4.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S5.T4.1.4.3.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T4.1.4.3.1.1\">\n<tr class=\"ltx_tr\" id=\"S5.T4.1.4.3.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.4.3.1.1.1.1\">Label: 2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.4.3.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.4.3.1.1.2.1\">(Gold label: 0)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.4.3.1.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.4.3.1.1.3.1\">Justification cue: I had never</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.4.3.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.4.3.1.1.4.1\">(Gold justification cue: seen)</td>\n</tr>\n</table>\n</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Example of a prediction error made by GPT-3.5. </figcaption>\n</figure>",
            "capture": "Table 4: Example of a prediction error made by GPT-3.5. "
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"A2.T5\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A2.T5.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T5.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T5.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T5.1.1.1.1.1\">PROMPT(SYSTEM)</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T5.1.2.1.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A2.T5.1.2.1.1.1\">\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.1.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.1.1.1\">Your task is to classify the labels corresponding to the analytic criterion from the input response.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.2.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.2.1.1\">Please refer to the Classification Rubric and Classification Examples when performing the task.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.3.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.3.1.1\">_Your Outputs_</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.4.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.4.1.1\">E4: _Your Outputs_</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.5.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.5.1.1\">Justification Cue: _Your Outputs_</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.6.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.6.1.1\">_ Question_</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.7.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.7.1.1\">\"\u79c1\u306f\u4e00\u6628\u5e74\u306b\u30aa\u30fc\u30b9\u30c8\u30e9\u30ea\u30a2\u3067\u898b\u308b\u307e\u3067\u30b3\u30a2\u30e9\u3092\u898b\u305f\u3053\u3068\u304c\u306a\u304b\u3063\u305f\u3002</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.8\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.8.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.8.1.1\">&lt;I / the year before last / in Australia / before I saw one / a koala / seen / had never&gt; \"</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.9\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.9.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.9.1.1\">_Analytic criterion_</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.10\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.10.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.10.1.1\">E4:Tense of expressions corresponding to \"\u898b\u308b\u307e\u3067\"</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.11\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.11.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.11.1.1\">E4: 2 -Express \"\u898b\u308b\u307e\u3067\" as \"before I saw one(s)\" , \"before I saw some\", \"before I saw them\"</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.12\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.12.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.12.1.1\">E4: 0-Using \"it\" instead of \"one(s)\". Otherwise.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.13\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.13.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.13.1.1\">_Classification Examples_</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.14\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.14.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.14.1.1\">Ans\uff1aI have not seen koalas before I saw them in Australia 2 years ago .</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.15\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.15.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.15.1.1\">E4\uff1a 2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.16\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.16.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.16.1.1\">justification cue\uff1abefore I saw them</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.17\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.17.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.17.1.1\">Ans: I had never seen koalas before I saw ones in Australia two years ago .</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.18\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.18.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.18.1.1\">E4: 2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.19\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.19.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.19.1.1\">justification cue: before I saw ones</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.20\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.20.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.20.1.1\">Ans: I never see koala before I saw that at Australia last year .</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.21\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.21.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.21.1.1\">E4: 0</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.22\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.22.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.22.1.1\">justification cue: before I saw that</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.23\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.23.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.23.1.1\">Ans: I had never seen a koala until I saw it in Australia in the year before last .</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.24\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.24.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.24.1.1\">E4: 0</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.2.1.1.1.25\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.2.1.1.1.25.1\"><span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.1.2.1.1.1.25.1.1\">justification cue: until I saw it</span></td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.3.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A2.T5.1.3.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T5.1.3.2.1.1\">Input student response</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.1.4.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"A2.T5.1.4.3.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A2.T5.1.4.3.1.1\">\n<tr class=\"ltx_tr\" id=\"A2.T5.1.4.3.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T5.1.4.3.1.1.1.1\">I had never seen a koala before I saw one in Australia the year before last.</td>\n</tr>\n</table>\n</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>An example of a prompt for grading an analytic criterion for the phrase \u201c\u898b\u308b\u307e\u3067\u201d (before I saw). This prompt contains five parts; task instruction, description of the output format, Question (L1 sentence for translation), the analytic criterion, and a few-shot examples. The task instruction, located at the beginning of the prompt, explains the automatic scoring of STEs. The output format description follows the section labeled <span class=\"ltx_text ltx_font_italic\" id=\"A2.T5.3.1\">_Your Outputs_</span> in the prompt. The Analytic criterion provides representative examples of expressions that are deemed appropriate or inappropriate for the phrase \u201c\u898b\u308b\u307e\u3067\u201d (before I saw). We provide two examples for each label in the few-shot examples and inserted descriptions in \u2019&lt; &gt;\u2019 for clarification, but these are not included in the actual prompt.</figcaption>\n</figure>",
            "capture": "Table 5: An example of a prompt for grading an analytic criterion for the phrase \u201c\u898b\u308b\u307e\u3067\u201d (before I saw). This prompt contains five parts; task instruction, description of the output format, Question (L1 sentence for translation), the analytic criterion, and a few-shot examples. The task instruction, located at the beginning of the prompt, explains the automatic scoring of STEs. The output format description follows the section labeled _Your Outputs_ in the prompt. The Analytic criterion provides representative examples of expressions that are deemed appropriate or inappropriate for the phrase \u201c\u898b\u308b\u307e\u3067\u201d (before I saw). We provide two examples for each label in the few-shot examples and inserted descriptions in \u2019< >\u2019 for clarification, but these are not included in the actual prompt."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.03396v1_figure_1.png",
            "caption": "Figure 1: Example of sentence translation exercise. We excerpted the analytic criteria \u201cE3,\u201d \u201cO4,\u201d and \u201cG4\u201d from Q11 in our dataset. The correct answer is \u201cI had never seen a koala before I saw one in Australia two years ago.\u201d \u201cChunk\u201d denotes a Japanese phrasal unit. \u201cE,\u201d \u201cO,\u201d and \u201cG\u201d are categories of each analytic criterion, which stand for \u201cexpression,\u201d \u201cword order,\u201d and \u201cgrammar,\u201d respectively."
        },
        "2": {
            "figure_path": "2403.03396v1_figure_2.png",
            "caption": "Figure 2: Input for the GPT models"
        },
        "3": {
            "figure_path": "2403.03396v1_figure_3.png",
            "caption": "Figure 3: The performance of the GPT-3.5 model when changing the number of in-context examples. The x-axis represents the number of in-context examples. The y-axis represents the averaged F1subscript\ud835\udc391F_{1}italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-score among all analytic criteria."
        }
    },
    "references": [
        {
            "1": {
                "title": "Language models are few-shot learners.",
                "author": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020.",
                "venue": "Advances in neural information processing systems, 33:1877\u20131901.",
                "url": null
            }
        },
        {
            "2": {
                "title": "The eras and trends of automatic short answer grading.",
                "author": "Steven Burrows, Iryna Gurevych, and Benno Stein. 2015.",
                "venue": "International Journal of Artificial Intelligence in Education, 25(1):60\u2013117.",
                "url": null
            }
        },
        {
            "3": {
                "title": "The Bilingual Reform. A Paradigm shift in Foreign Language Teaching.",
                "author": "Wolfgang Butzkamm and John Caldwell. 2009.",
                "venue": "Narr Dr. Gunter.",
                "url": null
            }
        },
        {
            "4": {
                "title": "A coefficient of agreement for nominal scales.",
                "author": "Jacob Cohen. 1960.",
                "venue": "Educational and Psychological Measurement, 20(1):37\u201346.",
                "url": "https://doi.org/10.1177/001316446002000104"
            }
        },
        {
            "5": {
                "title": "Translation in Language Teaching: An Argument for Reassessment.",
                "author": "Guy Cook. 2010.",
                "venue": "Oxford University Press, Oxford.",
                "url": "https://oro.open.ac.uk/21266/"
            }
        },
        {
            "6": {
                "title": "Template-guided grammatical error feedback comment generation.",
                "author": "Steven Coyne. 2023.",
                "venue": "In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics: Student Research Workshop, pages 94\u2013104, Dubrovnik, Croatia. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2023.eacl-srw.10"
            }
        },
        {
            "7": {
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding.",
                "author": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.",
                "venue": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171\u20134186, Minneapolis, Minnesota. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "8": {
                "title": "SemEval-2013 task 7: The joint student response analysis and 8th recognizing textual entailment challenge.",
                "author": "Myroslava Dzikovska, Rodney Nielsen, Chris Brew, Claudia Leacock, Danilo Giampiccolo, Luisa Bentivogli, Peter Clark, Ido Dagan, and Hoa Trang Dang. 2013.",
                "venue": "pages 263\u2013274.",
                "url": null
            }
        },
        {
            "9": {
                "title": "Is chatgpt a highly fluent grammatical error correction system? a comprehensive evaluation.",
                "author": "Tao Fang, Shu Yang, Kaixin Lan, Derek F. Wong, Jinpeng Hu, Lidia S. Chao, and Yue Zhang. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2304.01746"
            }
        },
        {
            "10": {
                "title": "Your answer is incorrect\u2026 would you like to know why? introducing a bilingual short answer feedback dataset.",
                "author": "Anna Filighera, Siddharth Parihar, Tim Steuer, Tobias Meuser, and Sebastian Ochs. 2022.",
                "venue": "In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8577\u20138591, Dublin, Ireland. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2022.acl-long.587"
            }
        },
        {
            "11": {
                "title": "Reducing the cost: Cross-Prompt pre-finetuning for short answer scoring.",
                "author": "Hiroaki Funayama, Yuya Asazuma, Yuichiroh Matsubayashi, Tomoya Mizumoto, and Kentaro Inui. 2023.",
                "venue": "In Artificial Intelligence in Education, pages 78\u201389. Springer Nature Switzerland.",
                "url": null
            }
        },
        {
            "12": {
                "title": "Machine learning approach for automatic short answer grading: A systematic review.",
                "author": "Lucas Busatta Galhardi and Jacques Du\u00edlio Brancher. 2018.",
                "venue": "In Advances in Artificial Intelligence - IBERAMIA 2018, pages 380\u2013391. Springer International Publishing.",
                "url": null
            }
        },
        {
            "13": {
                "title": "Predicting perfect quality segments in mt output with fine-tuned openai llm: Is it possible to capture editing distance patterns from historical data?",
                "author": "Serge Gladkoff, Gleb Erofeev, Lifeng Han, and Goran Nenadic. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2308.00158"
            }
        },
        {
            "14": {
                "title": "Exploring methods for generating feedback comments for writing learning.",
                "author": "Kazuaki Hanawa, Ryo Nagata, and Kentaro Inui. 2021.",
                "venue": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 9719\u20139730, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2021.emnlp-main.766"
            }
        },
        {
            "15": {
                "title": "Medical reports summarization using text-to-text transformer.",
                "author": "Abdulkader Helwan, Danielle Azar, and Dilber Uzun Ozsahin. 2023.",
                "venue": "In 2023 Advances in Science and Engineering Technology International Conferences (ASET), pages 01\u201304. IEEE.",
                "url": null
            }
        },
        {
            "16": {
                "title": "LoRA: Low-Rank adaptation of large language models.",
                "author": "Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021.",
                "venue": null,
                "url": "http://arxiv.org/abs/2106.09685"
            }
        },
        {
            "17": {
                "title": "Adam: A method for stochastic optimization.",
                "author": "Diederik P Kingma and Jimmy Ba. 2014.",
                "venue": null,
                "url": "http://arxiv.org/abs/1412.6980"
            }
        },
        {
            "18": {
                "title": "Student engagement with automated written corrective feedback (AWCF) provided by grammarly: A multiple case study.",
                "author": "Svetlana Koltovskaia. 2020.",
                "venue": "Assessing Writing, 44:100450.",
                "url": null
            }
        },
        {
            "19": {
                "title": "TellMeWhy: Learning to explain corrective feedback for second language learners.",
                "author": "Yi-Huei Lai and Jason Chang. 2019.",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations, pages 235\u2013240, Hong Kong, China. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/D19-3040"
            }
        },
        {
            "20": {
                "title": "The measurement of observer agreement for categorical data.",
                "author": "J. Richard Landis and Gary G. Koch. 1977.",
                "venue": "Biometrics, 33(1):159\u2013174.",
                "url": "http://www.jstor.org/stable/2529310"
            }
        },
        {
            "21": {
                "title": "On the roles of repetition in language teaching and learning.",
                "author": "Diane Larsen-Freeman. 2012.",
                "venue": "Applied Linguistics Review, 3(2):195\u2013210.",
                "url": "https://doi.org/doi:10.1515/applirev-2012-0009"
            }
        },
        {
            "22": {
                "title": "Analytic score prediction and justification identification in automated short answer scoring.",
                "author": "Tomoya Mizumoto, Hiroki Ouchi, Yoriko Isobe, Paul Reisert, Ryo Nagata, Satoshi Sekine, and Kentaro Inui. 2019.",
                "venue": "In Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 316\u2013325, Florence, Italy. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "23": {
                "title": "Toward a task of feedback comment generation for writing learning.",
                "author": "Ryo Nagata. 2019.",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3206\u20133215, Hong Kong, China. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/D19-1316"
            }
        },
        {
            "24": {
                "title": "Gpt-4 technical report.",
                "author": "OpenAI. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2303.08774"
            }
        },
        {
            "25": {
                "title": "L2 student engagement with automated feedback on writing: Potential for learning and issues of trust.",
                "author": "Jim Ranalli. 2021.",
                "venue": "Journal of Second Language Writing, 52:100816.",
                "url": null
            }
        },
        {
            "26": {
                "title": "Plausibility and faithfulness of feature Attribution-Based explanations in automated short answer scoring.",
                "author": "Tasuku Sato, Hiroaki Funayama, Kazuaki Hanawa, and Kentaro Inui. 2022.",
                "venue": "In Artificial Intelligence in Education, pages 231\u2013242. Springer International Publishing.",
                "url": null
            }
        },
        {
            "27": {
                "title": "What\u2019s the problem? l2 learners\u2019 use of the l1 during consciousness-raising, form-focused tasks.",
                "author": "Virginia Scott and Mar\u00eda De la Fuente. 2008.",
                "venue": "The Modern Language Journal, 92:100 \u2013 113.",
                "url": "https://doi.org/10.1111/j.1540-4781.2008.00689.x"
            }
        },
        {
            "28": {
                "title": "Transformers: State-of-the-art natural language processing.",
                "author": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020.",
                "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38\u201345, Online. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2020.emnlp-demos.6"
            }
        },
        {
            "29": {
                "title": "Translanguaging in the development of efl learners\u2019 foreign language skills in turkish context.",
                "author": "Muhammet Yasar Yuzlu and Kenan Dikilitas. 2022.",
                "venue": "Innovation in Language Learning and Teaching, 16(2):176\u2013190.",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.03396v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2.1",
            "6",
            "6.1",
            "6.2"
        ],
        "methodology_sections": [
            "2.2",
            "4",
            "4.1",
            "4.2"
        ],
        "main_experiment_and_results_sections": [
            "3",
            "3.1",
            "3.2",
            "5",
            "5.1",
            "5.2",
            "5.3"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "5",
            "5.2",
            "5.3"
        ]
    },
    "research_context": {
        "paper_id": "2403.03396v1",
        "paper_title": "Japanese-English Sentence Translation Exercises Dataset for Automatic Grading",
        "research_background": "### Paper's Motivation:\nThe paper seeks to address a significant challenge in L2 language education, particularly between linguistically distant language pairs like Japanese and English. Sentence translation exercises (STEs) are beneficial pedagogically as they help learners practice specific grammatical items, basic vocabulary, and idioms, thereby enhancing their understanding of expressions in the target language. However, the manual grading of these exercises is labor-intensive, limiting their usage despite the benefits of repetitive practice. This bottleneck calls for an automated solution to facilitate more frequent and effective language learning through STEs.\n\n### Research Problem:\nThe primary research problem tackled by the paper is the development of a method to automate the grading of L1-to-L2 sentence translation exercises. Unlike tasks such as Grammatical Error Correction (GEC) and machine translation, STEs need to be graded with an understanding of and alignment with specific educational objectives and grading rubrics used by educators. The task, therefore, involves generating a dataset, creating an appropriate scoring framework, and evaluating the effectiveness of existing models and approaches to this end.\n\n### Relevant Prior Work:\n1. **Sentence Translation Exercises:**\n   - Early stage L2 language learning often employs STEs due to their effectiveness in cross-linguistic contexts (Cook, 2010; Butzkamm and Caldwell, 2009).\n   - These exercises facilitate understanding of basic grammar and idiomatic expressions, enhancing language acquisition (Cook, 2010).\n\n2. **Educational Tools and Manual Grading:**\n   - STEs offer brief, repeatable tests that efficiently support learning specific grammar items and vocabulary. However, the manual grading constitutes a significant burden (Larsen-Freeman, 2012).\n\n3. **Related Challenges in Automated Grading:**\n   - The automation aligns closely with tasks like Grammatical Error Correction (GEC), which focuses on the grammatical correctness of text. However, GEC alone does not stimulate effective learner engagement (Koltovskaia, 2020; Ranalli, 2021).\n\nBy leveraging the expertise in educational settings and employing state-of-the-art language models, this study aims to create an automated grading system that aligns closely with pedagogical intents, which is a novel and challenging task in the field of language learning technology.",
        "methodology": "### Proposed Method or Model\n\nThe proposed method for Japanese-English Sentence Translation Exercises (STE) involves automatic grading of students\u2019 responses by utilizing a scoring rubric with multiple independent analytical criteria. Here\u2019s a detailed description of the methodology:\n\n**1. Objectives and Scoring:**\n   - **Learning Objectives:** The STE questions are designed to assess several learning objectives as defined by the instructors. These objectives typically include various grammatical items such as number, tense, etc.\n   - **Scoring Rubric:** A well-constructed scoring rubric is used to evaluate students' performance. Each rubric is designed to target specific learning objectives and includes multiple analytical criteria necessary for a comprehensive evaluation.\n\n**2. Analytic Criteria:**\n   - **Independent Criteria:** The scoring rubric encompasses several independent criteria that separately assess specific grammatical items or aspects of the students\u2019 responses.\n   - **Analytic Scores:** For each criterion, an analytic score ranging from 0 to 2 is assigned:\n     - **2:** Correct\n     - **1:** Partially correct\n     - **0:** Incorrect\n\n**3. Automatic Scoring:**\n   - **Precedent:** This study builds on the methodology formulated by Mizumoto et al. (2019), which addressed the automatic analytic score prediction task for reading comprehension questions.\n   - **Adaptation for STE:** The current study adapts this approach to the context of STE, aiming to predict analytic scores for given responses automatically.\n\n**4. Model Operation:**\n   - **Input and Output:** \n     - Given a student\u2019s response text \\(\\mathbf{r}\\), the model aims to predict an analytic score \\(\\hat{s}\\) for each analytic criterion \\(c\\).\n   - **Scoring Interpretation:** The scores 2, 1, and 0 denote \"correct,\" \"partially correct,\" and \"incorrect,\" respectively.\n\nThe model thus serves to automate the otherwise manual and intricate task of evaluating multiple grammatical and learning objectives from student-translated sentences, leveraging a fine-grained, criterion-based scoring system.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n**Dataset:**\nThe primary dataset used for this experiment comprises 21 Japanese-to-English Sentence Translation Exercises (STE) questions with detailed rubrics and annotated student responses. Each question was designed by specialists to cover key grammar topics from well-known English textbooks used in Japanese high schools. The dataset contains 3,498 student responses, annotated with 196 analytic criteria.\n\nEach rubric includes 17 analytic criteria:\n- 3 for grammar (G)\n- 7 for vocabulary and expression (E)\n- 7 for word order (O)\n\nEach criterion is scored on a three-point scale:\n- 2 (correct)\n- 1 (partially correct) \n- 0 (incorrect)\n\n**Baselines:**\nThe experiment does not specify conventional baseline models but instead relies on human annotators to establish a baseline for evaluation. Mizumoto et al. (2019) and Sato et al. (2022) are referenced for methods of rubric generation and annotation of justification cues, but it\u2019s implicit that those methods serve as benchmarks.\n\n**Evaluation Metrics:**\nThe quality of the annotations is assessed through:\n- Cohen\u2019s Kappa coefficient for inter-grader agreement on analytic scoring.\n- F-score for agreement on justification cues.\n\n**Results:**\n- The average Kappa coefficient for analytic criteria was 0.74.\n  - This indicates substantial agreement among annotators, suggesting consistency in scoring across different graders.\n- The F-score for justification cues was 0.92.\n  - This high score signifies a strong agreement among annotators in identifying justification cues.\n\nIn summary, the experiment demonstrated that the annotators could reliably and consistently grade STE responses and identify justification cues, validating the dataset\u2019s robustness and the expert-derived rubrics' reliability. The distribution of scores (fewer instances of grade 0 and more of grade 2) was consistent with the expected performance of high school students, further validating the dataset\u2019s relevance and accuracy."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "Investigate the feasibility of the task formulation for Sentence Translation Exercises (STEs) using BERT and GPT-3.5/GPT-4 models, and assess the impact of the number of in-context examples on scoring performance.",
            "experiment_process": "The experiments utilized the BERT model and state-of-the-art GPT-4 and GPT-3.5 models to automatically grade Japanese-English STEs. The datasets included student and crowd worker responses to 21 questions. The evaluation metrics included grading accuracy for correct, incorrect, and partially correct responses. Performance was measured across different conditions by varying the number of in-context examples from one, two, five, to ten.",
            "result_discussion": "The BERT model demonstrated superior performance over the GPT models in grading both correct and incorrect responses, despite GPTs being pre-trained on vast corpora. GPT models, especially GPT-3.5, struggled with incorrect responses, failing to recognize them accurately. Increasing the number of in-context examples beyond two did not improve the grading performance significantly. The results highlighted the limitations of GPT-3.5 for STE applications, particularly due to the specific prompt and response formats of STEs, and the difficulty in covering all potential incorrect responses.",
            "ablation_id": "2403.03396v1.No1"
        },
        {
            "research_objective": "Compare the performance of finetuned BERT and GPT models in grading STE responses, and analyze standard deviations across different analytic criteria.",
            "experiment_process": "Performance was evaluated using BERT and GPT-3.5/GPT-4 models. The experimental setup included test sets categorized by Expression, Word Order, and Grammar to measure how well each model graded responses within these different categories. Performance measurement involved averages and standard deviations for each category.",
            "result_discussion": "The BERT model outperformed GPT-3.5 and GPT-4 models overall, particularly in grading incorrect responses. Both models performed well in grading correct responses. Interestingly, GPT models graded partially correct responses better than BERT, possibly due to the limited data size for fine-tuning BERT. The high standard deviation (over 0.10) across different analytic criteria suggests difficulty in grading more nuanced aspects of the STEs. The findings indicate that advanced language models still face challenges with STE grading, especially without sufficient training data.",
            "ablation_id": "2403.03396v1.No2"
        },
        {
            "research_objective": "Assess the models' lower performance in grading incorrect responses versus correct responses, and investigate reasons for this discrepancy.",
            "experiment_process": "The analysis involved evaluating the performance of BERT and GPT models on incorrect responses. The experimental procedures included examination of qualitative errors, analyzing model performance with varying in-context example sizes, and reviewing the task-specific nature of STEs against the models\u2019 pretraining data.",
            "result_discussion": "The models displayed significantly lower performance in grading incorrect responses compared to correct ones. This was attributed to the limited variation in correct responses versus the large and unpredictable variation in incorrect ones. GPT models, especially when given fewer in-context examples, particularly struggled with identifying incorrect responses. The task-specific prompt and response format of STEs likely contributed to these inaccuracies. Increasing the number of in-context examples did not significantly enhance performance, underscoring the inherent challenge in grading STEs with the current model architectures.",
            "ablation_id": "2403.03396v1.No3"
        }
    ]
}