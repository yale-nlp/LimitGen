{
    "title": "Self-Refinement of Language Models from External Proxy Metrics Feedback",
    "abstract": "It is often desirable for Large Language Models (LLMs) to capture multiple objectives when providing a response. In document-grounded response generation, for example, agent responses are expected to be relevant to a user\u2019s query while also being grounded in a given document. In this paper, we introduce Proxy Metric-based Self-Refinement (ProMiSe), which enables an LLM to refine its own initial response along key dimensions of quality guided by external metrics feedback, yielding an overall better final response. ProMiSe leverages feedback on response quality through principle-specific proxy metrics, and iteratively refines its response one principle at a time. We apply ProMiSe to open source language models flan-t5-xxl and llama-2-13b-chat, to evaluate its performance on document-grounded question answering datasets, MultiDoc2Dial and QuAC, demonstrating that self-refinement improves response quality. We further show that fine-tuning llama-2-13b-chat on the synthetic dialogue data generated by ProMiSe yields significant performance improvements over the zero-shot baseline as well as a supervised fine-tuned model on human annotated data.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "The state-of-the-art large language models (LLMs) have demonstrated to be effective in generating new synthetic data, useful in improving zero-shot task generalization through fine-tuning without requiring vast amounts of human annotations. Various approaches have been proposed to show the ability of models to evaluate and critique responses Saunders et al. (2022  ###reference_b16###); Scheurer et al. (2023  ###reference_b17###); Shinn et al. (2023  ###reference_b18###); Ye et al. (2023  ###reference_b24###), as well as their potential to refine: given feedback, correct their outputs Welleck et al. (2022  ###reference_b22###); Peng et al. (2023  ###reference_b15###); Madaan et al. (2023  ###reference_b11###); Huang et al. (2023  ###reference_b9###); Wang et al. (2023b  ###reference_b21###). These explorations have studied various feedback mechanisms (human-in-the-loop, reward models to capture human preferences, model-generated feedback) and forms (pairwise comparisons, scalar scores, natural language descriptions), as well as refinement techniques (separate supervised refiners, domain-specific refinement).\n\nOf particular note are recent works exploring the self-refinement phenomenon Madaan et al. (2023  ###reference_b11###); Wang et al. (2023b  ###reference_b21###); Shinn et al. (2023  ###reference_b18###), leveraging the same LLM to perform critique and/or refinement on top of generating responses. The observations of these works unveil shortcomings: smaller instruction-tuned models fail to replicate the results of systems such as GPT-3.5 and GPT-4 in refinement, and in the absence of well-designed stopping mechanisms, self-refinement applied to high-quality responses can make the results worse Huang et al. (2023  ###reference_b9###). When humans correct themselves, they do it often with one or more objectives in mind, i.e. principles. Such principles may include faithfulness, specificity, safety (i.e. non-toxic), relevance to a question posed, etc. and may vary across tasks \u2014 we seek to imbue these aspects into conversational agents, to ensure they are reflected in the agent\u2019s responses.\n\n###figure_1### To this effect, we introduce an iterative, principle-guided approach to self-refinement in relatively smaller language models where refinement has previously proven unsuccessful. Our algorithm, termed Proxy Metric-based Self-Refinement (ProMiSe), combines proxy metric thresholding for different principles with independent principle-specific few-shot refinement and best-of-N rejection sampling. This allows for the deliberate selection of task-appropriate metrics with calibrated sufficiency thresholds, and specific prompts better designed to match the instruction-following capabilities of smaller models. In this manner, we perform multi-aspect self-refinement via iterative single-aspect improvement queries, as opposed to simultaneous refinement on many dimensions.\n\nWe apply this method to content-grounded question answering, demonstrating consistent improvements on a diverse set of evaluation metrics for single-turn response generation. We then extend ProMiSe to multi-turn dialogue data generation to generate user queries in addition to agent responses. We fine-tune llama-2-13b-chat on the synthetic data, yielding significant improvement over the zero-shot baseline and supervised models solely fined-tuned on human annotations. Crucially, this approach is built on open-source models and does not rely on proprietary models with black-box API access; we note, however, that the proposed algorithm can be directly applied to closed-source models as well. Furthermore, it can be extended to other tasks, provided that proxy metrics can be defined and a few in-context exemplars can be created for the relevant principles.\n\nOur key contributions are: We introduce a novel domain-agnostic algorithm, ProMiSe, to perform multi-aspect self-refinement on desirable principles for a response through in-context learning, using proxy metrics as external quality feedback. ProMiSe is applied to both content-grounded single-turn question answering and multi-turn dialogue generation. Extensive evaluations on MultiDoc2Dial and QuAC datasets demonstrate its effectiveness both in few-shot and fine-tuning settings. We will release both the software and the synthetic dialogue data. We analyze the relationship between the change in proxy metric scores and the downstream evaluation metrics, revealing an unsupervised correlation and reinforcing the efficacy of our method."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Algorithm",
            "text": "Given an input, e.g. a document and conversation history, ProMiSe executes three main steps: (i) Generate an initial response, (ii) Obtain external feedback via proxy metrics, and (iii) Refine the response with respect to each principle, if the response is deemed inadequate by the feedback mechanism. The last two steps are run iteratively until the response meets a quality threshold. We present a detailed description of these steps below.\nWe perform rejection sampling, this time on the set of refinement candidates, scoring with each metric in  and selecting the response, , with the highest scores on the majority of metrics. The scores of , the best refinement candidate, are then compared against the threshold . If the scores of  exceed the threshold on all  metrics, then we stop refinement and accept it as the final response. Otherwise, we now compare against the scores of the previous best response, . The user assigns weights  for the respective metrics in ; these importances should likely be informed by the principles in  which each metric corresponds to, and the user\u2019s design goals. Then, given the scores for  and , we compute:\nFor each metric in , the indicator takes on a value of 1 if the new response is an improvement on the previous best response, with respect to that metric, or 0 otherwise, and is weighted by the elements in . If this sum fails to exceed a user-defined threshold of , we\ndo not update the best refinement response for this iteration (i.e. set ); else, we proceed to the next refinement iteration, until termination."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Initial Response Generation",
            "text": "For an input instance, we perform Best-of-N sampling to yield a set of responses, , from Language Model , given the input and an initial generation prompt. The initial generation prompt consists of an instruction and optional in-context demonstrations.\nThe instruction explicitly suggests that a response be generated which reflects desirable principles, the set of which is contained in . We determine the quality of the sampled responses based on a set of proxy metrics determined a priori, designated as . We note that the selected metrics should be designed by the user to improve alignment by reflecting the principle set for the response, , with respect to the current task. As such, each metric  is also predicated on the inputs provided which may be used as means to assess candidate responses \u2013 a text passage or document, conversation history, etc. (thus lending itself to the content-grounded setting). Each responses in  is scored with each metric  in , and the response with the highest scores on the greatest number of metrics is chosen as the best initial response, .\nNext, we determine the global sufficiency of  as an acceptable response, by comparing the proxy scores element-wise against a threshold , consisting of scalar values .  is the minimum value such that a response is deemed sufficient, for each metric  in . If the scores of  exceeds their respective thresholds, for all  components, we return it as the final response. If not (i.e.  fails to clear the threshold on at least one metric), we proceed to the refinement module."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Response Refinement",
            "text": "Our approach to response refinement is predicated on in-context exemplars of principle-specific refinement for the given task. The refinement prompt also contains the previous best response, denoted  \u2014 in the first iteration, this is equal to .\nAligning responses with multiple principles (i.e. where ) induces a multi-objective problem; rather than explicitly optimizing across the set simultaneously, we propose deliberate refinement with respect to one principle at a time, selecting an optimal candidate at each iteration based on the proxy metrics. For each iteration in the self-refinement phase, we loop through the set of principles  and generate a set of new responses, with the goal of each resulting response reflecting improvement on its respective principle. In each such query to Language Model , we introduce a principle-specific refinement prompt, consisting of in-context demonstrations of refinement and an instruction to improve the current best response, both with respect to the current principle. Examples of such prompts are contained in Appendix C  ###reference_###.\nWe perform rejection sampling, this time on the set of refinement candidates, scoring with each metric in  and selecting the response, , with the highest scores on the majority of metrics. The scores of , the best refinement candidate, are then compared against the threshold . If the scores of  exceed the threshold on all  metrics, then we stop refinement and accept it as the final response. Otherwise, we now compare against the scores of the previous best response, . The user assigns weights  for the respective metrics in ; these importances should likely be informed by the principles in  which each metric corresponds to, and the user\u2019s design goals. Then, given the scores for  and , we compute:\nFor each metric in , the indicator takes on a value of 1 if the new response is an improvement on the previous best response, with respect to that metric, or 0 otherwise, and is weighted by the elements in . If this sum fails to exceed a user-defined threshold of , we\ndo not update the best refinement response for this iteration (i.e. set ); else, we proceed to the next refinement iteration, until termination."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Evidence: Question Answering",
            "text": "We apply ProMiSe to content-grounded question answering: given a document and a conversation history, which may consist of a single user utterance (a question posed to the conversational agent) or a multi-turn dialogue between the user and the agent, we seek for the LLM to produce a response to the most recent user query. For the generation of an initial response consistent with the content-grounded QA setting, we extract 3 instances from the MultiDoc2Dial Feng et al. (2021) training data as in-context exemplars; the prompt template is included in Appendix C. This includes the document, conversation history, and the gold response provided by the annotators. The in-context exemplars for query generation work similarly, with 3 demonstrations consisting of different conversation lengths (in number of utterances), but where the last utterance is the final user query. To perform in-context refinement on a particular principle, we similarly take 3 in-context demonstrations from the training dataset, but seek to contrast between a better and worse response, with respect to the principle. To accomplish this, we manually annotate a worse response for each instance relative to the gold response. In the prompt, we model this as 3 separate utterances: the worse agent response, a user turn probing the agent to improve its response to update along the principle, and another agent utterance containing the better response (i.e., the gold response). To more explicitly suggest the presence of a response quality difference, we include the tags \u201cnot {principle}\u201d and \u201cmore {principle}\u201d, for the two agent turns, respectively, where {principle} is either \u2018specific\u2019, \u2018relevant\u2019, or \u2018accurate\u2019. Given a candidate response and the grounding document, WeCheck Wu et al. (2022) addresses the faithfulness principle. Our experiments evaluate each model in three thresholding settings: solely using the WeCheck model, and using a combination of both. If we use only WeCheck, rejection sampling is performed to yield the highest scoring response according to WeCheck and we determine whether a refined response constitutes an improvement solely using the WeCheck scores. During refinement, we yield a reward indicator with each category (reward model, i.e., WeCheck) which is 1 if deemed to have improved during the present iteration and 0 otherwise, and compute a weighted sum using a user-defined weight vector. If this sum is greater than 0.5, we update the best response to be the new one, else retain the previous best."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Set of Principles",
            "text": "We first identify an appropriate set of principles for the task, which define key characteristics of a good agent response. They are as follows:\n\nSpecificity. If an initial response is too vague, this would likely lead to more user interactions asking the agent to make its response more specific.\n\nFaithfulness. We suggest that accurate, factual responses are those grounded in the document, and thus should have high (semantic and lexical) overlap with the document.\n\nRelevance and Consistency. The conversational agent response should be relevant to the most recent user query, and by induction to the entire conversation history."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "In-Context Demonstration Selection",
            "text": "We explore our algorithm through the generation of both a single agent response and an entire multi-turn dialogue. For the generation of an initial response consistent with the content-grounded QA setting, we extract 3 instances from the MultiDoc2Dial Feng et al. (2021) training data as in-context exemplars; the prompt template is included in Appendix C. This includes the document, conversation history, and the gold response provided by the annotators. The in-context exemplars for query generation work similarly, with 3 demonstrations consisting of different conversation lengths (in number of utterances), but where the last utterance is the final user query.\n\nTo perform in-context refinement on a particular principle, we similarly take 3 in-context demonstrations from the training dataset, but seek to contrast between a better and worse response, with respect to the principle. To accomplish this, we manually annotate a worse response for each instance relative to the gold response. In the prompt, we model this as 3 separate utterances: the worse agent response, a user turn probing the agent to improve its response to update along the principle, and another agent utterance containing the better response (i.e. the gold response). To more explicitly suggest the presence of a response quality difference, we include the tags \u201cnot {principle}\u201d and \u201cmore {principle}\u201d, for the two agent turns, respectively, where {principle} is either \u2018specific\u2019, \u2018relevant\u2019, or \u2018accurate\u2019."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "External Proxy Metrics",
            "text": "To capture the aforementioned principles, we define relevant proxy metrics. The proxy metrics should be reflective of response quality improvement along our chosen dimensions and should not directly optimize the final evaluation metrics.\n\nGiven a candidate response and the grounding document, WeCheck Wu et al. (2022) addresses the faithfulness principle. Our experiments evaluate each model in three thresholding settings: solely using the WeCheck model, and using a combination of both. If we use only WeCheck, rejection sampling is performed to yield the highest scoring response according to WeCheck and we determine whether a refined response constitutes an improvement solely using the WeCheck scores. If using both metrics, a sufficient response must clear the threshold on all metrics. During refinement, we yield a reward indicator with each category (WeCheck) which is 1 if deemed to have improved during the present iteration and 0 otherwise, and compute a weighted sum using a user-defined weight vector. If this sum is greater than 0.5, we update the best response to be the new one, else retain the previous best."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experimental Results and Discussion",
            "text": "We use two widely-used open-source language models to evaluate our algorithm for content-grounded question answering, Flan-T5-XXL Chung et al. (2022) and Llama-2-13B-chat Touvron et al. (2023). \n\nWe evaluate the technique on the test dataset of MultiDoc2Dial Feng et al. (2021) (https://doc2dial.github.io/multidoc2dial/), content-grounded dialogues, and the validation dataset of QuAC Choi et al. (2018) (https://quac.ai/), short form question-answering. Both datasets feature conversations wherein answers to queries posed by the user are expected to come from a document. We use a sub-document split on MultiDoc2Dial to remove the information retrieval (IR) component such that we only have the most relevant document as opposed to the entire set of candidate documents. We use the validation dataset of QuAC as the test data since the test set is not publicly available.\n\nWe use five automatic evaluation metrics: BERTScore Recall, BERTScore K-Precision (K-Prec. hereafter), Zhang et al. (2020), Recall, and K-Precision. BERTScore Recall and Recall measure the agreement between the candidate response and the provided gold response. BERTScore K-Prec. and K-Prec. measure the agreement between the candidate response and the grounding document. We chose Recall and K-Prec. metrics due to their strong correlation with human assessments of instruction-following models in content-grounded QA tasks, Adlakah et al. (2023).\n\nWe explore the relationship between the improvement in the final evaluation metrics and the direction of change on the proxy metrics in ProMiSe. That is, is improvement on the proxy sufficiency metrics during the execution of the algorithm correlated with the downstream evaluation metric improvement from initial to final response?\n\nWe find that the chosen proxy metrics appear to serve as an unsupervised link to the final evaluation metrics. The number of samples that improve for each proxy metric change are roughly similar, a trend noticeable across settings. This highlights the value of our external metric feedback technique: by optimizing on a scoring scheme while simultaneously preserving the integrity of the downstream evaluation metrics, we can capture a similar notion of response quality and sufficiency."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Single-Turn QA Results",
            "text": "Table 1 presents the results across the two possible metric sets (the WeCheck reward model and both) as defined in Section 3.3. We find that using the WeCheck reward model as the sole sufficiency metric yields less consistent improvement across the set of evaluation metrics, yet boosts performance when applied in tandem with other metrics.\n\nTo identify the appropriate sufficiency threshold for the proxy metrics, we perform a rigorous study of various settings, included in Appendix B. Results involving the WeCheck reward model use a threshold of 0.5 between the response and document.\n\nIn Table 3, we compare the average length (word count) of the initial and final responses, for the MultiDoc2Dial and QuAC datasets. It can be observed that the length of final responses is marginally greater than the average initial response length. This suggests that our performance improvements exhibited in Table 1 are unlikely to be solely a result of longer responses (e.g., reproducing large sections of the document). Simultaneously, our model producing longer responses relative to the gold response likely explains slight declines with both models and both datasets; in particular, Llama-2\u2019s responses are much longer than Flan-T5\u2019s and the gold response.\n\nWe explore the relationship between the improvement in the final evaluation metrics and the direction of change on the proxy metrics in ProMiSe. That is, is improvement on the proxy sufficiency metrics during the execution of the algorithm correlated with the downstream evaluation metric improvement from initial to final response?\n\nThe relationship between the proxy metric scores and the BERTScore-Recall evaluation metrics is shown in Table 4.\n\nWe find that the chosen proxy metrics appear to serve as an unsupervised link to the final evaluation metrics. The number of samples that improve for each proxy metric change are roughly similar, a trend noticeable across settings. Furthermore, a greater degree of improvement on proxy metrics generally corresponds to a larger average improvement (or less negative change) for BERTScore-Recall with respect to the gold response. This highlights the value of our external metric feedback technique: by optimizing on a scoring scheme while simultaneously preserving the integrity of the downstream evaluation metrics, we can capture a similar notion of response quality and sufficiency."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Multi-Turn Synthetic Dialogues",
            "text": "We generate synthetic dialogues of varying lengths from Flan-T5-XXL, containing refinement instances: the initial response, a user query to improve the response along a principle, and the refined response. The dialogues are generated from scratch, bootstrapping solely on the grounding documents in MultiDoc2Dial training data. They alternate between user and agent utterances, and consist of 1-3 agent responses (thus containing total 2, 4, or 6 turns). We sampled 10k dialogues with 2 turns, 2k with 4 turns and another 2k with 6 turns. We QLoRA fine-tune Dettmers et al. (2023  ###reference_b5###) Llama-2-13B-Chat model on these synthetic data. See Section D  ###reference_### for details. The results are shown in Table 2  ###reference_###. \n\nWe observe sizable improvements across all metrics when comparing the performance without refinement, denoted initial, as opposed to with refinement, denoted final. Notably, these improvements are present on both lexical and semantic similarity measures; +6-6.75% for both BERT-Recall and Recall, and +7.5-8% for BERT K-Precision and K-Precision. Furthermore, merging the synthetic data with 38k samples of human annotated data from the MultiDoc2Dial train set yields improvements over solely training on human annotated data. These results suggest the value of response quality refinement in generating high-quality synthetic data and yielding downstream improvements on evaluation metrics."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "LLM-as-a-Judge Evaluation",
            "text": "We also perform automated evaluation with GPT-4 as a judge, Zheng et al. (2023  ###reference_b27###), which has been shown strongly correlate to human evaluation. Given the initial and final generations, we prompt the model to impartially assess which response is better. We largely adapt the prompts used for MT-bench evaluation in Zheng et al. (2023  ###reference_b27###), which we show in Appendix F  ###reference_###. For MultiDoc2Dial, we randomly sample 2,551 of the indices of the test set responses (exactly one quarter), and only perform evaluation on samples for which the initial and final responses differ as a result of refinement. With the QuAC dataset, analyze all 1,000 test set instances, likewise evaluating where initial and final responses differ. The results are shown in Figure 2  ###reference_###, where the numbers in percentage are the win rate of each response. We find that GPT-4 deems the final response to be better than the initial response on all conditions for MultiDoc2Dial. The relative outlier is the QuAC dataset with RM-only; this is likely because WeCheck measures entailment rather than agreement. Often the correct short response is less likely to be entailed than an incorrect longer response by the grounding document. Furthermore, the strong correlation between the automatic evaluation metrics in Table 1  ###reference_### with the GPT-4 evaluation results in Figure 2  ###reference_### evidences the efficacy of our algorithm."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Other Related Work",
            "text": "Various work on self-refinement may be distinguished according to the source of feedback, Pan et al. (2023  ###reference_b13###); Huang et al. (2023  ###reference_b9###). Internal feedback relies on the model\u2019s inherent knowledge and parameters to reassess its outputs. External feedback incorporates inputs from humans, other models. Our work is inspired by Madaan et al. (2023  ###reference_b11###). Unlike Madaan et al. (2023  ###reference_b11###), however, who rely on very large LLMs (GPT-3.5, ChatGPT, GPT-4) as the source of internal feedback, we introduce external feedback with proxy metrics and enable self-refinement technique to work with relatively small LLMs including Flan-T5-XXL and Llama-2-13B-Chat in content-grounded setups.\nRegarding internal feedback, Bai et al. (2022  ###reference_b2###) experiment with method for training a harmless AI assistant through self-improvement. Wang et al. (2023a  ###reference_b20###) propose Shepherd, a language model tuned to critique its own responses and suggest refinements.\nAs for external feedback, Paul et al. (2023  ###reference_b14###) propose refiner, a framework for finetuning LMs to explicitly generate intermediate reasoning steps while interacting with a critic model that provides automated feedback on the reasoning. Gou et al. (2023  ###reference_b8###) propose critic that interacts with appropriate tools, e.g. calculator, search engine, wikipedia, etc., to evaluate certain aspects of the text and then revise the output based on the feedback obtained during the validation process. Olausson et al. (2024  ###reference_b12###) critically examines the LLM\u2019s ability to perform self-repair on problems taken from HumanEval and APPS and concludes that self-repair still lags behind what can be achieved with human-level debugging. Gao et al. (2023  ###reference_b7###) propose RARR (Retrofit Attribution using Research and Revision) that revises a generated text on the basis of the relevant evidence retrieved by re-search."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "We present a novel algorithm, ProMiSe, for self-refinement of language models. ProMiSe uses external multi-aspect feedback via proxy metrics capturing desirable principles for a high-quality response. ProMiSe is applied to content-grounded single-turn question answering and multi-turn dialogue generation. Extensive evaluations on MultiDoc2Dial and QuAC datasets with 5 automatic evaluation metrics as well as LLM-as-a-judge with GPT-4, demonstrate its effectiveness in both few-shot learning and supervised fine-tuning setups. This approach crucially enables relatively small LMs like Flan-T5-XXL and Llama-2-13B-Chat to successfully perform self-refinement."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Limitations",
            "text": "Our work employs two open-source LMs: flan-t5-xxl and llama-2-13b-chat. Therefore, the generated data, including the synthetic multi-turn dialogues, can be susceptible to the limitations of such LMs, particularly the biases inherent in the training data which may be harmful with hate, abuse and social stereotypes. We have tested the algorithm ProMiSe on English only although it would have been more desirable to verify the value of the algorithm in multi-lingual setups. We have conducted extensive evaluations including 5 well-known automtic evaluation metrics and LLM-as-a-judge with GPT-4, which has been shown to correlate well with human evaluations. Nonetheless, inclusion of human evaluation would have strengthened our position further."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "Ethics and Impact",
            "text": "Our technique can be used to guide generations towards user-specified targets; however, this could be applied to generate toxic or malicious content, by way of an adversarial principle selection. Nonetheless, we note that ProMiSe does present meaningful implications in enabling alignment to human preferences (where preferences, in this setting, refer to the user-defined principles). We will release the software for the ProMiSe algorithm, enabling others in the community to consider other principles of interest, or applications to other tasks."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Self-Refinement Algorithm for Synthetic Dialogue Generation",
            "text": "We include a complete version of Algorithm 1 adapted for synthetic dialogue generation, leveraged in our fine-tuning experiments. At first, we sample a new user query from large language model , bootstrapping only off of the document. As the total number of turns (utterances) to be modeled is user-defined, we append each utterance to the end of the conversation history. For example, given the last user query, we append an agent response to it, which is either an initial (no refinement necessary) or final (post-refinement) response. If refinement did occur, then we first append the previous best agent response (), then a user turn  of \"User: Please make this response more \", and then the improved and sufficient agent response . Once an agent response has been procured and appended for the current turn, we continue back to line 1 and generate a new user query, this time conditioning on the conversation history as well; this repeats until the user-specified max turn limit is reached."
        },
        {
            "section_id": "Appendix 2",
            "parent_section_id": null,
            "section_name": "Appendix B Metric Selection and Threshold Calibration",
            "text": ""
        },
        {
            "section_id": "Appendix 3",
            "parent_section_id": null,
            "section_name": "Appendix C Initial Response Generation, Query Generation, and Principle Refinement Prompts",
            "text": ""
        },
        {
            "section_id": "Appendix 4",
            "parent_section_id": null,
            "section_name": "Appendix D Fine-tuning Experimental Setup",
            "text": "We QLoRA fine-tune llama-2-13b-chat on both human annotated and synthetically generated MultiDoc2Dial datasets. We set the learning rate to 1e-5, LoRA rank to 8 and LoRA alpha to 32. We apply 4bit quantization for both model training and inferencing. Unlike baseline model inferencing with few-shot learning for which we use sampling method, we use greedy decoding for fine-tuned models.\nWe train the models with 4 A100 (80GB memory) GPUs up to 10 epochs. Training takes between 5 hours for 8k training samples and 24 hours for about 50k samples. We select the best checkpoint on the basis of the 5 evaluation metrics (RougeL, BERTScore Recall, BERTScore K-Prec., Recall and K-Prec.) scores on the development test data."
        },
        {
            "section_id": "Appendix 5",
            "parent_section_id": null,
            "section_name": "Appendix E Zero-Shot vs Few-Shot Comparison",
            "text": "In Table 6  ###reference_###, we also present a comparison based on the number of few-shot exemplars employed in initial response generation. Notably, we observe that the 0-shot performance of initial responses are, in fact, higher than the 3-shot results for the same phase. This suggests that instruction-tuned LMs such as Flan-T5-XXL are already fairly adept at dialogue response generation without in-context exemplars. Furthermore, we find that the zero-shot setting achieves higher initial scores relative to 3-shot for Flan-T5-XXL, but such improvement is less consistent for Llama-2-13B-Chat. Simultaneously, we found that the 3-shot results with refinement constitute an improvement over the 0-shot performance. This indicates that in-context exemplars are necessary to improve performance during the refinement phase, although only three demonstrations are sufficient to illustrate the notion of the target principle to the LM. That is, despite fairly coherent initial responses, there is still room for improvement, achieved when using three in-context exemplars per principle. Thus, the results reported above and in Table 1  ###reference_### hold 3 exemplars constant for the refinement phase."
        },
        {
            "section_id": "Appendix 6",
            "parent_section_id": null,
            "section_name": "Appendix F LLM-as-a-Judge Evaluation Setup",
            "text": "Recent literature Zheng et al. (2023  ###reference_b27###); Zhang et al. (2024  ###reference_b25###) evidences the ability of using language models as discriminators, judging generation quality in lieu of (or as a supplement to) human evaluation feedback. The line of work has also been a strong motivator in influencing self-feedback and refinement approaches; it demonstrates the ability of powerful models to reflect human preferences and provide meaningful critiques. In pursuing such an approach, we deliberately choose to explicitly model certain properties in the instruction: for example, we seek permutation-invariance (while knowing that models are susceptible to position bias when given a set of multiple choice options and mitigating their preference for longer answers."
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T1\">\n<br class=\"ltx_break\"/>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S3.T1.1.1.1.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.1.1.1.1\">Proxy Metrics</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T1.1.1.1.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.1.1.2.1\">Stage</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T1.1.1.1.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.1.1.3.1\">Rouge-L</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T1.1.1.1.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.1.1.4.1\">BERT-Recall</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T1.1.1.1.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.1.1.5.1\">BERT K-Prec.</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T1.1.1.1.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.1.1.6.1\">Recall</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T1.1.1.1.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.1.1.7.1\">K-Prec.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.1.2.2.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.2.2.1.1\">MD2D</span><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.2.2.1.2\"> Flan-T5-XXL (11B)</span>\n</th>\n<td class=\"ltx_td ltx_border_t\" id=\"S3.T1.1.2.2.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S3.T1.1.2.2.3\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S3.T1.1.2.2.4\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S3.T1.1.2.2.5\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S3.T1.1.2.2.6\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S3.T1.1.2.2.7\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.1.3.3.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.3.3.1.1\">Only Rou-L + Rou-1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.3.3.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.3.3.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.3.3.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.3.3.3.1\">21.55</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.3.3.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.3.3.4.1\">28.11</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.3.3.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.3.3.5.1\">40.42</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.3.3.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.3.3.6.1\">32.34</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.3.3.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.3.3.7.1\">76.77</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.4.4\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S3.T1.1.4.4.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.4.4.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.4.4.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.4.4.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.4.4.3.1\">21.72</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.4.4.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.4.4.4.1\">29.29</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.4.4.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.4.4.5.1\">42.74</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.4.4.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.4.4.6.1\">34.14</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.4.4.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.4.4.7.1\">79.29</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.1.5.5.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.5.5.1.1\">Only RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.5.5.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.5.5.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.5.5.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.5.5.3.1\">22.33</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.5.5.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.5.5.4.1\">28.91</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.5.5.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.5.5.5.1\">44.58</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.5.5.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.5.5.6.1\">33.61</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.5.5.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.5.5.7.1\">81.29</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.6.6\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S3.T1.1.6.6.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.6.6.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.6.6.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.6.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.6.6.3.1\">22.43</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.6.6.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.6.6.4.1\">29.17</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.6.6.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.6.6.5.1\">45.60</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.6.6.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.6.6.6.1\">34.20</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.6.6.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.6.6.7.1\">82.25</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.1.7.7.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.7.7.1.1\">0-Shot / Rou + RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.7.7.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.7.7.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.7.7.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.7.7.3.1\">22.30</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.7.7.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.7.7.4.1\">28.94</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.7.7.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.7.7.5.1\">44.55</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.7.7.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.7.7.6.1\">33.68</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.7.7.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.7.7.7.1\">81.56</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.8.8\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S3.T1.1.8.8.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.8.8.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.8.8.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.8.8.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.8.8.3.1\">22.38</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.8.8.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.8.8.4.1\">30.10</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.8.8.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.8.8.5.1\">46.60</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.8.8.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.8.8.6.1\">35.58</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.8.8.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.8.8.7.1\">83.13</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S3.T1.1.9.9.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.9.9.1.1\">MD2D</span><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.9.9.1.2\"> Llama-2-13B-Chat</span>\n</th>\n<td class=\"ltx_td ltx_border_tt\" id=\"S3.T1.1.9.9.2\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S3.T1.1.9.9.3\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S3.T1.1.9.9.4\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S3.T1.1.9.9.5\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S3.T1.1.9.9.6\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S3.T1.1.9.9.7\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.1.10.10.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.10.10.1.1\">Only Rou-L + Rou-1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.10.10.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.10.10.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.10.10.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.10.10.3.1\">19.31</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.10.10.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.10.10.4.1\">28.92</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.10.10.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.10.10.5.1\">34.44</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.10.10.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.10.10.6.1\">38.45</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.10.10.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.10.10.7.1\">70.33</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.11.11\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S3.T1.1.11.11.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.11.11.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.11.11.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.11.11.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.11.11.3.1\">18.95</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.11.11.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.11.11.4.1\">29.67</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.11.11.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.11.11.5.1\">36.04</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.11.11.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.11.11.6.1\">40.43</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.11.11.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.11.11.7.1\">71.76</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.1.12.12.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.12.12.1.1\">Only RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.12.12.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.12.12.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.12.12.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.12.12.3.1\">19.97</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.12.12.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.12.12.4.1\">29.65</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.12.12.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.12.12.5.1\">34.33</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.12.12.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.12.12.6.1\">38.07</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.12.12.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.12.12.7.1\">70.08</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.13.13\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S3.T1.1.13.13.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.13.13.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.13.13.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.13.13.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.13.13.3.1\">19.95</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.13.13.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.13.13.4.1\">29.89</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.13.13.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.13.13.5.1\">40.68</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.13.13.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.13.13.6.1\">38.59</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.13.13.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.13.13.7.1\">76.73</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.14.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.1.14.14.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.14.14.1.1\">Rou + RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.14.14.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.14.14.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.14.14.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.14.14.3.1\">20.36</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.14.14.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.14.14.4.1\">30.17</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.14.14.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.14.14.5.1\">40.68</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.14.14.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.14.14.6.1\">38.59</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.14.14.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.14.14.7.1\">76.84</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.15.15\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S3.T1.1.15.15.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.15.15.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.15.15.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.15.15.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.15.15.3.1\">20.06</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.15.15.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.15.15.4.1\">30.64</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.15.15.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.15.15.5.1\">41.46</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.15.15.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.15.15.6.1\">40.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.15.15.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.15.15.7.1\">77.43</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.16.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt ltx_border_t\" id=\"S3.T1.1.16.16.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.16.16.1.1\">QuAC</span><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.16.16.1.2\"> Flan-T5-XXL (11B)</span>\n</th>\n<td class=\"ltx_td ltx_border_tt ltx_border_t\" id=\"S3.T1.1.16.16.2\"></td>\n<td class=\"ltx_td ltx_border_tt ltx_border_t\" id=\"S3.T1.1.16.16.3\"></td>\n<td class=\"ltx_td ltx_border_tt ltx_border_t\" id=\"S3.T1.1.16.16.4\"></td>\n<td class=\"ltx_td ltx_border_tt ltx_border_t\" id=\"S3.T1.1.16.16.5\"></td>\n<td class=\"ltx_td ltx_border_tt ltx_border_t\" id=\"S3.T1.1.16.16.6\"></td>\n<td class=\"ltx_td ltx_border_tt ltx_border_t\" id=\"S3.T1.1.16.16.7\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.17.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.1.17.17.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.17.17.1.1\">Only Rou-L + Rou-1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.17.17.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.17.17.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.17.17.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.17.17.3.1\">41.57</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.17.17.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.17.17.4.1\">40.70</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.17.17.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.17.17.5.1\">43.31</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.17.17.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.17.17.6.1\">44.87</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.17.17.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.17.17.7.1\">87.57</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.18.18\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S3.T1.1.18.18.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.18.18.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.18.18.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.18.18.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.18.18.3.1\">40.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.18.18.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.18.18.4.1\">41.47</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.18.18.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.18.18.5.1\">46.06</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.18.18.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.18.18.6.1\">45.77</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.18.18.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.18.18.7.1\">88.26</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.19.19\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.1.19.19.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.19.19.1.1\">Only RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.19.19.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.19.19.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.19.19.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.19.19.3.1\">37.01</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.19.19.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.19.19.4.1\">36.58</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.19.19.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.19.19.5.1\">48.82</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.19.19.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.19.19.6.1\">40.21</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.19.19.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.19.19.7.1\">91.51</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.20.20\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S3.T1.1.20.20.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.20.20.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.20.20.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.20.20.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.20.20.3.1\">34.99</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.20.20.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.20.20.4.1\">35.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.20.20.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.20.20.5.1\">49.69</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.20.20.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.20.20.6.1\">38.61</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.20.20.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.20.20.7.1\">91.58</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.21.21\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.1.21.21.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.21.21.1.1\">Rou + RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.21.21.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.21.21.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.21.21.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.21.21.3.1\">38.20</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.21.21.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.21.21.4.1\">37.28</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.21.21.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.21.21.5.1\">48.44</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.21.21.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.21.21.6.1\">40.78</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.21.21.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.21.21.7.1\">91.38</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.22.22\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S3.T1.1.22.22.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.22.22.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.22.22.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.22.22.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.22.22.3.1\">35.85</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.22.22.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.22.22.4.1\">37.13</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.22.22.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.22.22.5.1\">50.91</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.22.22.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.22.22.6.1\">41.21</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.22.22.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.22.22.7.1\">91.89</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.23.23\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S3.T1.1.23.23.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.23.23.1.1\">QuAC</span><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.23.23.1.2\"> Llama-2-13B-Chat</span>\n</th>\n<td class=\"ltx_td ltx_border_tt\" id=\"S3.T1.1.23.23.2\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S3.T1.1.23.23.3\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S3.T1.1.23.23.4\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S3.T1.1.23.23.5\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S3.T1.1.23.23.6\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S3.T1.1.23.23.7\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.24.24\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.1.24.24.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.24.24.1.1\">Only Rou-L + Rou-1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.24.24.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.24.24.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.24.24.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.24.24.3.1\">31.36</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.24.24.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.24.24.4.1\">35.12</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.24.24.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.24.24.5.1\">40.79</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.24.24.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.24.24.6.1\">42.86</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.24.24.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.24.24.7.1\">83.08</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.25.25\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S3.T1.1.25.25.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.25.25.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.25.25.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.25.25.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.25.25.3.1\">29.23</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.25.25.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.25.25.4.1\">35.28</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.25.25.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.25.25.5.1\">42.87</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.25.25.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.25.25.6.1\">43.63</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.25.25.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.25.25.7.1\">82.96</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.26.26\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.1.26.26.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.26.26.1.1\">Only RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.26.26.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.26.26.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.26.26.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.26.26.3.1\">29.83</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.26.26.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.26.26.4.1\">33.11</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.26.26.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.26.26.5.1\">46.64</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.26.26.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.26.26.6.1\">39.22</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.26.26.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.26.26.7.1\">87.78</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.27.27\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S3.T1.1.27.27.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.27.27.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.27.27.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.27.27.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.27.27.3.1\">28.70</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.27.27.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.27.27.4.1\">31.83</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.27.27.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.27.27.5.1\">47.79</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.27.27.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.27.27.6.1\">37.62</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.27.27.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.27.27.7.1\">87.24</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.28.28\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T1.1.28.28.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.28.28.1.1\">Rou + RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.28.28.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.28.28.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.28.28.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.28.28.3.1\">28.85</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.28.28.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.28.28.4.1\">32.29</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.28.28.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.28.28.5.1\">46.59</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.28.28.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.28.28.6.1\">38.54</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.28.28.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.28.28.7.1\">88.04</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.29.29\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T1.1.29.29.1\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.1.29.29.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.29.29.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.1.29.29.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.29.29.3.1\">26.76</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.1.29.29.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.29.29.4.1\">32.39</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.1.29.29.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.29.29.5.1\">48.05</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.1.29.29.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.1.29.29.6.1\">39.64</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.1.29.29.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.29.29.7.1\">88.11</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Experimental Results on the MultiDoc2Dial (MD2D) and QuAC test sets, containing 10,204 and 1,000 instances, respectively. Experiments are reported with the Flan-T5-XXL (11B) and Llama-2-13B-Chat models, using 3 Rouge (ROU) measures, the WeCheck reward model (RM), and both in tandem for thresholding. \"Initial\" refers to scoring generations after rejection sampling, while \"Final\" includes both \"sufficient\" initial responses and post-refinement responses. In proxy metrics, Rouge-L includes computing between the candidate response with both the grounding document and the given user query, and Rouge-1 is with respect to the document. Highest scores are boldfaced for each model. We decode with sampling method by setting temperature=0.7, top-k=50 and top-p=1.\n</figcaption>\n</figure>",
            "capture": "Table 1: Experimental Results on the MultiDoc2Dial (MD2D) and QuAC test sets, containing 10,204 and 1,000 instances, respectively. Experiments are reported with the Flan-T5-XXL (11B) and Llama-2-13B-Chat models, using 3 Rouge (ROU) measures, the WeCheck reward model (RM), and both in tandem for thresholding. \"Initial\" refers to scoring generations after rejection sampling, while \"Final\" includes both \"sufficient\" initial responses and post-refinement responses. In proxy metrics, Rouge-L includes computing between the candidate response with both the grounding document and the given user query, and Rouge-1 is with respect to the document. Highest scores are boldfaced for each model. We decode with sampling method by setting temperature=0.7, top-k=50 and top-p=1.\n"
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T2\">\n<br class=\"ltx_break\"/>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T2.9\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T2.9.10.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S3.T2.9.10.1.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.10.1.1.1\">Fine-tuning Data</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.10.1.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.10.1.2.1\">SynsetSize</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.10.1.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.10.1.3.1\">Rouge-L</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.10.1.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.10.1.4.1\">BERT-Recall</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.10.1.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.10.1.5.1\">Recall</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.10.1.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.10.1.6.1\">BERT-K-Prec.</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.10.1.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.10.1.7.1\">K-Prec.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.9.11.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S3.T2.9.11.2.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.11.2.1.1\">None (Baseline)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.11.2.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.11.2.2.1\">0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.11.2.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.11.2.3.1\">21.11</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.11.2.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.11.2.4.1\">30.95</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.11.2.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.11.2.5.1\">38.62</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.11.2.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.11.2.6.1\">40.05</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.11.2.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.11.2.7.1\">76.89</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.1.1.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.1.1.1.1\">-initial</span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.1.1.2.1\">8k</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.1.1.3.1\">24.63</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.1.1.4.1\">28.51</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.1.1.5.1\">34.21</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.1.1.6.1\">41.91</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.1.1.7.1\">78.26</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.2.2.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.2.2.1.1\">-final</span>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.2.2.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.2.2.2.1\">8k</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.2.2.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.2.2.3.1\">26.13</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.2.2.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.2.2.4.1\">33.65</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.2.2.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.2.2.5.1\">39.49</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.2.2.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.2.2.6.1\">46.98</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.2.2.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.2.2.7.1\">82.74</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.3.3.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.3.3.1.1\">-initial</span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.3.3.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.3.3.2.1\">10k</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.3.3.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.3.3.3.1\">24.51</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.3.3.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.3.3.4.1\">27.82</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.3.3.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.3.3.5.1\">33.81</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.3.3.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.3.3.6.1\">41.01</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.3.3.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.3.3.7.1\">76.71</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.4.4.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.4.4.1.1\">-final</span>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.4.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.4.4.2.1\">10k</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.4.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.4.4.3.1\">26.06</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.4.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.4.4.1\">33.83</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.4.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.4.5.1\">40.56</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.4.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.4.6.1\">48.67</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.4.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.4.7.1\">84.46</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.5.5.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.5.5.1.1\">-initial</span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.5.5.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.5.5.2.1\">14k</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.5.5.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.5.5.3.1\">26.18</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.5.5.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.5.5.4.1\">30.43</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.5.5.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.5.5.5.1\">34.81</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.5.5.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.5.5.6.1\">41.73</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.5.5.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.5.5.7.1\">79.08</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.6.6.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.6.6.1.1\">-final</span>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.6.6.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.6.6.2.1\">14k</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.6.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.6.6.3.1\">26.78</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.6.6.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.6.6.4.1\">33.57</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.6.6.5\"><span class=\"ltx_text ltx_font_italic\" id=\"S3.T2.6.6.5.1\">38.26</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.6.6.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.6.6.6.1\">46.32</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.6.6.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.6.6.7.1\">83.68</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.9.12.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S3.T2.9.12.3.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.12.3.1.1\">Human (Baseline)</span></th>\n<td class=\"ltx_td ltx_border_tt\" id=\"S3.T2.9.12.3.2\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.12.3.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.12.3.3.1\">55.32</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.12.3.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.12.3.4.1\">56.43</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.12.3.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.12.3.5.1\">56.75</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.12.3.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.12.3.6.1\">31.38</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.9.12.3.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.12.3.7.1\">75.22</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.7.7.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.7.7.1.1\">Human+</span><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.7.7.1.2\">-final</span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.7.7.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.7.7.2.1\">8k</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.7.7.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.7.7.3.1\">55.40</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.7.7.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.7.7.4.1\">57.24</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.7.7.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.7.7.5.1\">57.79</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.7.7.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.7.7.6.1\">32.53</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.7.7.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.7.7.7.1\">76.13</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.8.8.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.8.8.1.1\">Human+</span><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.8.8.1.2\">-final</span>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.8.8.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.8.8.2.1\">10k</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.8.8.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.8.8.3.1\">55.58</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.8.8.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.8.8.4.1\">57.18</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.8.8.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.8.8.5.1\">57.63</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.8.8.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.8.8.6.1\">31.79</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.8.8.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.8.8.7.1\">75.46</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T2.9.9.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.9.1.1\">Human+</span><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.9.1.2\">-final</span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T2.9.9.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.9.2.1\">14k</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T2.9.9.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.9.3.1\">55.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T2.9.9.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.9.4.1\">56.92</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T2.9.9.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.9.5.1\">57.56</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T2.9.9.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.9.9.6.1\">32.78</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T2.9.9.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.9.9.7.1\">75.87</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Effectiveness of the proposed refinement algorithm measured by the synthetic data qualities. We QLoRA fine-tune <span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.23.1\">Llama-2-13B-Chat</span> model on the two sets of synthetic multi-turn dialogues, one generated with the refinement algorithm denoted by -<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.24.2\">final</span>, and the other generated without the refinement algorithm denoted by -<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T2.25.3\">initial</span>.  includes 8k and , 10k samples of 2 turn dialogues.  includes 10k samples of 2 turn, 2k samples of 4 turn, and 2k samples of 6 turn dialogues.\nThe upper portion of the table compares the performance of the model fine-tuned on the synthetic data with the highest-scoring baseline without fine-tuning. The lower portion of the table compares the performance of the model fine-tuned on the combination of human annotated and synthetic data with the model fine-tuned on human annotated data only.</figcaption>\n</figure>",
            "capture": "Table 2: Effectiveness of the proposed refinement algorithm measured by the synthetic data qualities. We QLoRA fine-tune Llama-2-13B-Chat model on the two sets of synthetic multi-turn dialogues, one generated with the refinement algorithm denoted by -final, and the other generated without the refinement algorithm denoted by -initial.  includes 8k and , 10k samples of 2 turn dialogues.  includes 10k samples of 2 turn, 2k samples of 4 turn, and 2k samples of 6 turn dialogues.\nThe upper portion of the table compares the performance of the model fine-tuned on the synthetic data with the highest-scoring baseline without fine-tuning. The lower portion of the table compares the performance of the model fine-tuned on the combination of human annotated and synthetic data with the model fine-tuned on human annotated data only."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T3\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T3.3\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.3.1.1\">\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T3.3.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.3.1.1.2\">Initial</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.3.1.1.3\">Final</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.3.2.2.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.2.2.1.1\">MultiDoc2Dial</span> (Avg. Gold: 15.55)</td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T3.3.2.2.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T3.3.2.2.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.3.3.3.1\">Flan-T5-XXL ROU-Only</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.3.3.2\">32.06</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.3.3.3\">35.88</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.3.4.4.1\">Flan-T5-XXL RM-Only</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.4.4.2\">33.16</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.4.4.3\">33.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.5.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.3.5.5.1\">Flan-T5-XXL ROU + RM</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.5.5.2\">33.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.5.5.3\">36.09</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.3.6.6.1\">Llama-2-13B-Chat ROU-Only</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.6.6.2\">39.30</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.6.6.3\">44.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.7.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.3.7.7.1\">Llama-2-13B-Chat RM-Only</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.7.7.2\">38.45</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.7.7.3\">39.51</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.3.8.8.1\">Llama-2-13B-Chat ROUGE + RM</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.8.8.2\">38.56</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.8.8.3\">42.59</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T3.3.9.9.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.3.9.9.1.1\">QuAC</span> (Avg. Gold: 12.57)</td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T3.3.9.9.2\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T3.3.9.9.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.10.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.3.10.10.1\">Flan-T5-XXL ROU-Only</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.10.10.2\">17.40</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.10.10.3\">20.46</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.11.11\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.3.11.11.1\">Flan-T5-XXL RM-Only</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.11.11.2\">18.19</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.11.11.3\">19.07</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.12.12\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.3.12.12.1\">Flan-T5-XXL ROU + RM</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.12.12.2\">17.79</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.12.12.3\">21.49</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.13.13\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.3.13.13.1\">Llama-2-13B-Chat ROU-Only</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.13.13.2\">29.61</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.13.13.3\">33.41</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.14.14\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.3.14.14.1\">Llama-2-13B-Chat RM-Only</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.14.14.2\">27.73</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.14.14.3\">27.39</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.15.15\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S4.T3.3.15.15.1\">Llama-2-13B-Chat ROU + RM</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.3.15.15.2\">28.74</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.3.15.15.3\">32.58</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Average word token counts for initial and final generations with ProMiSe. Statistics are computed for the three different settings of the proxy metric set, ; RM is the WeCheck reward model.</figcaption>\n</figure>",
            "capture": "Table 3: Average word token counts for initial and final generations with ProMiSe. Statistics are computed for the three different settings of the proxy metric set, ; RM is the WeCheck reward model."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T4\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.16\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.16.17.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T4.16.17.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T4.16.17.1.2\">Count</th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.16.17.1.3\">ROU-L Diff.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.16.17.1.4\">BERT-R Diff.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.16.18.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.16.18.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.16.18.2.1.1\">ROU-Only</span></th>\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.16.18.2.2\"></th>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T4.16.18.2.3\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T4.16.18.2.4\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.1.1.1\">ROU 3 \n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.1.1.2\">376</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.3\">+2.31%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.4\">+8.26%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.2.2.1\">ROU 2 \n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.2.2.2\">128</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.2.2.3\">+2.41%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.2.2.4\">+6.81%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.3.3.1\">ROU 1 \n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.3.3.2\">69</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.3.3.3\">+0.64%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.3.3.4\">-1.74%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.16.19.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T4.16.19.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.16.19.3.1.1\">RM-only</span></th>\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T4.16.19.3.2\"></th>\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T4.16.19.3.3\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T4.16.19.3.4\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.4.4.1\">RM \n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.4.4.2\">169</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.4.4.3\">+0.68%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.4.4.4\">+1.68%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.16.20.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T4.16.20.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.16.20.4.1.1\">ROU + RM</span></th>\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T4.16.20.4.2\"></th>\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T4.16.20.4.3\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T4.16.20.4.4\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.6.6.2\">ROU 3 , RM \n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.6.6.3\">110</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.6.6.4\">+2.21%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.6.6.5\">+8.23%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.8.8.2\">ROU 2 , RM \n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.8.8.3\">45</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.8.8.4\">+0.25%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.8.8.5\">+1.57%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.10.10.2\">ROU 1 , RM \n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.10.10.3\">59</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.10.10.4\">+1.18%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.10.10.5\">-0.66%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.12.12.2\">ROU 3 , RM \n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.12.12.3\">195</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.12.12.4\">-1.40%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.12.12.5\">+5.67%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.14.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.14.14.2\">ROU 2 , RM \n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.14.14.3\">50</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.14.14.4\">+0.07%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.14.14.5\">+4.25%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.16.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\" id=\"S4.T4.16.16.2\">ROU 1 , RM \n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t\" id=\"S4.T4.16.16.3\">32</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T4.16.16.4\">+3.37%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T4.16.16.5\">+2.16%</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Analysis of the correlation between improvement on proxy ROUGE (ROU) and WeCheck reward model (RM) metrics with change in the final evaluation ROUGE-L and BERT-Recall with the gold response. Performed with Flan-T5-XXL on a 2,038 sample MultiDoc2Dial development set. Proxy metric scores are computed between the candidate and either the provided document or context.  and  represents improvement and decline, respectively. \"2 \" means that two of the proxy ROUGE metric set improved. The differences reported are averaged across the sample count.</figcaption>\n</figure>",
            "capture": "Table 4: Analysis of the correlation between improvement on proxy ROUGE (ROU) and WeCheck reward model (RM) metrics with change in the final evaluation ROUGE-L and BERT-Recall with the gold response. Performed with Flan-T5-XXL on a 2,038 sample MultiDoc2Dial development set. Proxy metric scores are computed between the candidate and either the provided document or context.  and  represents improvement and decline, respectively. \"2 \" means that two of the proxy ROUGE metric set improved. The differences reported are averaged across the sample count."
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"A2.T5\">\n<br class=\"ltx_break\"/>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A2.T5.13\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T5.13.14.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A2.T5.13.14.1.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.14.1.1.1\">Thresholding</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T5.13.14.1.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.14.1.2.1\">Stage</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T5.13.14.1.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.14.1.3.1\">Rouge-L</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T5.13.14.1.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.14.1.4.1\">BERT-Recall</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T5.13.14.1.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.14.1.5.1\">BERT K-Prec.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T5.13.14.1.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.14.1.6.1\">Recall</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T5.13.14.1.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.14.1.7.1\">K-Prec.</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T5.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T5.1.1.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.1.1.1.1\">Rouge-1 K-Prec. </span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.1.1.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.1.1.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.1.1.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.1.1.3.1\">22.06</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.1.1.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.1.1.4.1\">27.60</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.1.1.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.1.1.5.1\">39.45</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.1.1.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.1.1.6.1\">34.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.1.1.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.1.1.7.1\">76.08</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.13.15.1\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A2.T5.13.15.1.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.15.1.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.15.1.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.15.1.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.15.1.3.1\">22.21</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.15.1.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.15.1.4.1\">28.19</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.15.1.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.15.1.5.1\">40.29</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.15.1.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.15.1.6.1\">34.57</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.15.1.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.15.1.7.1\">77.23</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T5.2.2.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.2.2.1.1\">Rouge-1 K-Prec. </span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.2.2.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.2.2.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.2.2.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.2.2.3.1\">23.06</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.2.2.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.2.2.4.1\">28.65</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.2.2.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.2.2.5.1\">39.65</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.2.2.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.2.2.6.1\">35.42</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.2.2.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.2.2.7.1\">76.49</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.13.16.2\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A2.T5.13.16.2.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.16.2.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.16.2.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.16.2.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.16.2.3.1\">23.26</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.16.2.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.16.2.4.1\">29.36</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.16.2.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.16.2.5.1\">41.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.16.2.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.16.2.6.1\">36.34</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.16.2.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.16.2.7.1\">76.68</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T5.3.3.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.3.3.1.1\">Rouge-1 K-Prec. </span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.3.3.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.3.3.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.3.3.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.3.3.3.1\">22.71</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.3.3.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.3.3.4.1\">29.08</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.3.3.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.3.3.5.1\">40.79</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.3.3.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.3.3.6.1\">35.62</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.3.3.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.3.3.7.1\">75.58</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.13.17.3\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A2.T5.13.17.3.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.17.3.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.17.3.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.17.3.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.17.3.3.1\">22.79</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.17.3.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.17.3.4.1\">29.67</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.17.3.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.17.3.5.1\">42.40</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.17.3.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.17.3.6.1\">36.59</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.17.3.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.17.3.7.1\">78.63</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T5.4.4.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.4.4.1.1\">WeCheck </span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.4.4.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.4.4.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.4.4.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.4.4.3.1\">24.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.4.4.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.4.4.4.1\">29.87</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.4.4.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.4.4.5.1\">44.02</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.4.4.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.4.4.6.1\">36.45</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.4.4.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.4.4.7.1\">81.51</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.13.18.4\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A2.T5.13.18.4.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.18.4.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.18.4.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.18.4.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.18.4.3.1\">23.93</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.18.4.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.18.4.4.1\">30.02</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.18.4.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.18.4.5.1\">44.53</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.18.4.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.18.4.6.1\">36.67</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.18.4.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.18.4.7.1\">82.08</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T5.5.5.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.5.5.1.1\">WeCheck </span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.5.5.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.5.5.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.5.5.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.5.5.3.1\">23.84</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.5.5.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.5.5.4.1\">30.37</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.5.5.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.5.5.5.1\">44.18</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.5.5.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.5.5.6.1\">36.45</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.5.5.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.5.5.7.1\">81.58</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.13.19.5\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A2.T5.13.19.5.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.19.5.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.19.5.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.19.5.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.19.5.3.1\">23.89</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.19.5.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.19.5.4.1\">30.51</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.19.5.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.19.5.5.1\">44.99</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.19.5.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.19.5.6.1\">36.69</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.19.5.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.19.5.7.1\">82.40</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T5.6.6.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.6.6.1.1\">WeCheck </span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.6.6.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.6.6.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.6.6.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.6.6.3.1\">24.37</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.6.6.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.6.6.4.1\">30.19</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.6.6.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.6.6.5.1\">44.27</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.6.6.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.6.6.6.1\">36.48</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.6.6.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.6.6.7.1\">81.31</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.13.20.6\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A2.T5.13.20.6.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.20.6.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.20.6.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.20.6.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.20.6.3.1\">24.23</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.20.6.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.20.6.4.1\">30.17</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.20.6.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.20.6.5.1\">45.08</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.20.6.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.20.6.6.1\">36.72</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.20.6.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.20.6.7.1\">81.95</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T5.7.7.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.7.7.1.1\">WeCheck </span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.7.7.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.7.7.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.7.7.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.7.7.3.1\">23.85</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.7.7.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.7.7.4.1\">30.05</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.7.7.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.7.7.5.1\">44.48</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.7.7.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.7.7.6.1\">36.27</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.7.7.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.7.7.7.1\">81.75</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.13.21.7\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A2.T5.13.21.7.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.21.7.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.21.7.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.21.7.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.21.7.3.1\">23.82</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.21.7.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.21.7.4.1\">30.38</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.21.7.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.21.7.5.1\">45.64</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.21.7.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.21.7.6.1\">37.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.21.7.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.21.7.7.1\">82.63</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T5.8.8.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.8.8.1.1\">WeCheck </span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.8.8.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.8.8.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.8.8.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.8.8.3.1\">24.08</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.8.8.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.8.8.4.1\">29.93</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.8.8.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.8.8.5.1\">44.13</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.8.8.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.8.8.6.1\">36.03</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.8.8.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.8.8.7.1\">81.75</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.13.22.8\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A2.T5.13.22.8.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.22.8.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.22.8.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.22.8.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.22.8.3.1\">24.07</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.22.8.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.22.8.4.1\">30.31</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.22.8.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.22.8.5.1\">45.41</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.22.8.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.22.8.6.1\">36.74</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.22.8.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.22.8.7.1\">83.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T5.9.9.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.9.9.1.1\">All 3 Rouge + WeCheck </span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.9.9.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.9.9.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.9.9.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.9.9.3.1\">23.97</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.9.9.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.9.9.4.1\">30.12</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.9.9.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.9.9.5.1\">44.41</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.9.9.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.9.9.6.1\">36.45</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.9.9.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.9.9.7.1\">81.96</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.13.23.9\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A2.T5.13.23.9.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.23.9.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.23.9.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.23.9.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.23.9.3.1\">24.17</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.23.9.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.23.9.4.1\">31.57</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.23.9.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.23.9.5.1\">46.62</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.23.9.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.23.9.6.1\">38.67</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.23.9.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.23.9.7.1\">83.32</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T5.10.10.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.10.10.1.1\">All 3 Rouge + WeCheck </span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.10.10.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.10.10.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.10.10.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.10.10.3.1\">24.02</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.10.10.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.10.10.4.1\">30.08</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.10.10.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.10.10.5.1\">44.28</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.10.10.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.10.10.6.1\">36.86</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.10.10.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.10.10.7.1\">81.29</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.13.24.10\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A2.T5.13.24.10.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.24.10.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.24.10.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.24.10.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.24.10.3.1\">24.05</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.24.10.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.24.10.4.1\">31.29</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.24.10.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.24.10.5.1\">46.40</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.24.10.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.24.10.6.1\">38.74</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.24.10.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.24.10.7.1\">82.81</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.11.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T5.11.11.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.11.11.1.1\">All 3 Rouge + WeCheck </span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.11.11.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.11.11.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.11.11.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.11.11.3.1\">24.01</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.11.11.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.11.11.4.1\">29.91</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.11.11.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.11.11.5.1\">44.55</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.11.11.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.11.11.6.1\">36.07</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.11.11.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.11.11.7.1\">81.50</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.13.25.11\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A2.T5.13.25.11.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.25.11.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.25.11.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.25.11.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.25.11.3.1\">23.90</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.25.11.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.25.11.4.1\">31.11</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.25.11.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.25.11.5.1\">46.80</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.25.11.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.25.11.6.1\">38.05</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.25.11.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.25.11.7.1\">83.26</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T5.12.12.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.12.12.1.1\">All 3 Rouge + WeCheck </span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.12.12.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.12.12.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.12.12.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.12.12.3.1\">23.90</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.12.12.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.12.12.4.1\">30.06</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.12.12.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.12.12.5.1\">44.02</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.12.12.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.12.12.6.1\">36.49</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.12.12.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.12.12.7.1\">81.49</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.13.26.12\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A2.T5.13.26.12.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.26.12.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.26.12.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.26.12.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.26.12.3.1\">24.17</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.26.12.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.26.12.4.1\">31.62</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.26.12.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.26.12.5.1\">46.22</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.26.12.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.26.12.6.1\">38.88</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.13.26.12.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.26.12.7.1\">83.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.13.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T5.13.13.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.13.1.1\">All 3 Rouge + WeCheck </span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.13.13.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.13.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.13.13.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.13.3.1\">23.79</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.13.13.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.13.4.1\">29.94</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.13.13.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.13.5.1\">44.47</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.13.13.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.13.6.1\">36.49</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.13.13.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.13.7.1\">81.84</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.13.27.13\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_bb\" id=\"A2.T5.13.27.13.1\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T5.13.27.13.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.27.13.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T5.13.27.13.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.27.13.3.1\">23.35</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T5.13.27.13.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.27.13.4.1\">31.08</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T5.13.27.13.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.27.13.5.1\">47.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T5.13.27.13.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.27.13.6.1\">38.37</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T5.13.27.13.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A2.T5.13.27.13.7.1\">83.57</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>Threshold calibration and metric selection was performed on a development (validation) set split of the MultiDoc2Dial dataset, consisting of 2,038 samples. Experiments are reported with the Flan-T5-XXL <cite class=\"ltx_cite ltx_citemacro_cite\">Chung et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.00827v1#bib.bib4\" title=\"\">2022</a>)</cite> model. Note that Rouge-L between response and document (Rouge-L-Doc) as well as between response and the user query (Rouge-L-Query) are maintained constant, while we experiment with changing the third metric between Rouge-1 F1, Rouge-1 K-Precision, and Rouge-1 Recall. We also vary the threshold for the WeCheck reward model <cite class=\"ltx_cite ltx_citemacro_cite\">Wu et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.00827v1#bib.bib23\" title=\"\">2022</a>)</cite>, in isolation and in tandem with the best performing Rouge metric combination.</figcaption>\n</figure>",
            "capture": "Table 5: Threshold calibration and metric selection was performed on a development (validation) set split of the MultiDoc2Dial dataset, consisting of 2,038 samples. Experiments are reported with the Flan-T5-XXL Chung et\u00a0al. (2022) model. Note that Rouge-L between response and document (Rouge-L-Doc) as well as between response and the user query (Rouge-L-Query) are maintained constant, while we experiment with changing the third metric between Rouge-1 F1, Rouge-1 K-Precision, and Rouge-1 Recall. We also vary the threshold for the WeCheck reward model Wu et\u00a0al. (2022), in isolation and in tandem with the best performing Rouge metric combination."
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"A5.T6\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A5.T6.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A5.T6.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"A5.T6.1.1.1.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.1.1.1.1\">Initial Exemplars + Metrics</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A5.T6.1.1.1.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.1.1.2.1\">Stage</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A5.T6.1.1.1.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.1.1.3.1\">Rouge-L</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A5.T6.1.1.1.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.1.1.4.1\">BERT-Recall</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A5.T6.1.1.1.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.1.1.5.1\">BERT K-Prec.</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A5.T6.1.1.1.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.1.1.6.1\">Recall</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A5.T6.1.1.1.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.1.1.7.1\">K-Prec.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A5.T6.1.2.2.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.2.2.1.1\">Flan-T5-XXL (11B) Results</span></th>\n<td class=\"ltx_td ltx_border_t\" id=\"A5.T6.1.2.2.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"A5.T6.1.2.2.3\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"A5.T6.1.2.2.4\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"A5.T6.1.2.2.5\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"A5.T6.1.2.2.6\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"A5.T6.1.2.2.7\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A5.T6.1.3.3.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.3.3.1.1\">3-Shot / Only Rou-L + Rou-1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.3.3.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.3.3.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.3.3.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.3.3.3.1\">21.50</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.3.3.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.3.3.4.1\">27.27</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.3.3.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.3.3.5.1\">38.08</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.3.3.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.3.3.6.1\">31.19</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.3.3.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.3.3.7.1\">75.58</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.4.4\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A5.T6.1.4.4.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.4.4.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.4.4.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.4.4.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.4.4.3.1\">21.84</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.4.4.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.4.4.4.1\">28.96</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.4.4.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.4.4.5.1\">41.41</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.4.4.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.4.4.6.1\">33.96</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.4.4.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.4.4.7.1\">78.78</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A5.T6.1.5.5.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.5.5.1.1\">0-Shot / Only Rou-L + Rou-1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.5.5.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.5.5.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.5.5.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.5.5.3.1\">21.55</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.5.5.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.5.5.4.1\">28.11</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.5.5.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.5.5.5.1\">40.42</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.5.5.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.5.5.6.1\">32.34</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.5.5.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.5.5.7.1\">76.77</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.6.6\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A5.T6.1.6.6.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.6.6.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.6.6.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.6.6.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.6.6.3.1\">21.72</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.6.6.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.6.6.4.1\">29.29</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.6.6.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.6.6.5.1\">42.74</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.6.6.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.6.6.6.1\">34.14</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.6.6.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.6.6.7.1\">79.29</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A5.T6.1.7.7.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.7.7.1.1\">3-Shot / Only RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.7.7.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.7.7.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.7.7.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.7.7.3.1\">22.67</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.7.7.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.7.7.4.1\">28.80</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.7.7.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.7.7.5.1\">42.83</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.7.7.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.7.7.6.1\">33.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.7.7.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.7.7.7.1\">80.42</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.8.8\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A5.T6.1.8.8.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.8.8.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.8.8.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.8.8.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.8.8.3.1\">22.65</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.8.8.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.8.8.4.1\">28.91</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.8.8.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.8.8.5.1\">43.55</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.8.8.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.8.8.6.1\">33.31</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.8.8.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.8.8.7.1\">81.14</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A5.T6.1.9.9.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.9.9.1.1\">0-Shot / Only RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.9.9.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.9.9.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.9.9.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.9.9.3.1\">22.33</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.9.9.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.9.9.4.1\">28.91</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.9.9.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.9.9.5.1\">44.58</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.9.9.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.9.9.6.1\">33.61</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.9.9.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.9.9.7.1\">81.29</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.10.10\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A5.T6.1.10.10.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.10.10.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.10.10.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.10.10.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.10.10.3.1\">22.43</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.10.10.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.10.10.4.1\">29.17</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.10.10.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.10.10.5.1\">45.60</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.10.10.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.10.10.6.1\">34.20</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.10.10.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.10.10.7.1\">82.25</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.11.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A5.T6.1.11.11.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.11.11.1.1\">3-Shot / Rou + RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.11.11.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.11.11.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.11.11.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.11.11.3.1\">22.61</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.11.11.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.11.11.4.1\">28.75</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.11.11.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.11.11.5.1\">42.60</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.11.11.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.11.11.6.1\">32.75</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.11.11.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.11.11.7.1\">80.36</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.12.12\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A5.T6.1.12.12.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.12.12.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.12.12.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.12.12.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T6.1.12.12.3.1\">22.71</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.12.12.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.12.12.4.1\">29.89</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.12.12.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.12.12.5.1\">44.86</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.12.12.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.12.12.6.1\">34.76</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.12.12.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.12.12.7.1\">81.98</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.13.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A5.T6.1.13.13.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.13.13.1.1\">0-Shot / Rou + RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.13.13.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.13.13.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.13.13.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.13.13.3.1\">22.30</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.13.13.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.13.13.4.1\">28.94</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.13.13.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.13.13.5.1\">44.55</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.13.13.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.13.13.6.1\">33.68</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.13.13.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.13.13.7.1\">81.56</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.14.14\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A5.T6.1.14.14.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.14.14.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.14.14.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.14.14.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.14.14.3.1\">22.38</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.14.14.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T6.1.14.14.4.1\">30.10</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.14.14.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T6.1.14.14.5.1\">46.60</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.14.14.6\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T6.1.14.14.6.1\">35.58</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.14.14.7\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T6.1.14.14.7.1\">83.13</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.15.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"A5.T6.1.15.15.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.15.15.1.1\">Llama-2-13B-Chat Results</span></th>\n<td class=\"ltx_td ltx_border_tt\" id=\"A5.T6.1.15.15.2\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"A5.T6.1.15.15.3\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"A5.T6.1.15.15.4\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"A5.T6.1.15.15.5\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"A5.T6.1.15.15.6\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"A5.T6.1.15.15.7\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.16.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A5.T6.1.16.16.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.16.16.1.1\">3-Shot / Only Rou-L + Rou-1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.16.16.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.16.16.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.16.16.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.16.16.3.1\">20.63</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.16.16.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.16.16.4.1\">29.35</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.16.16.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.16.16.5.1\">34.32</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.16.16.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.16.16.6.1\">36.49</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.16.16.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.16.16.7.1\">71.03</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.17.17\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A5.T6.1.17.17.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.17.17.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.17.17.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.17.17.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.17.17.3.1\">20.23</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.17.17.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.17.17.4.1\">30.22</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.17.17.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.17.17.5.1\">36.07</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.17.17.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.17.17.6.1\">38.82</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.17.17.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.17.17.7.1\">72.74</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.18.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A5.T6.1.18.18.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.18.18.1.1\">0-Shot / Only Rou-L + Rou-1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.18.18.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.18.18.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.18.18.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.18.18.3.1\">19.31</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.18.18.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.18.18.4.1\">28.92</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.18.18.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.18.18.5.1\">34.44</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.18.18.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.18.18.6.1\">38.45</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.18.18.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.18.18.7.1\">70.33</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.19.19\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A5.T6.1.19.19.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.19.19.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.19.19.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.19.19.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.19.19.3.1\">18.95</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.19.19.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.19.19.4.1\">29.67</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.19.19.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.19.19.5.1\">36.04</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.19.19.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.19.19.6.1\">40.43</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.19.19.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.19.19.7.1\">71.76</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.20.20\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A5.T6.1.20.20.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.20.20.1.1\">3-Shot / Only RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.20.20.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.20.20.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.20.20.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T6.1.20.20.3.1\">21.50</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.20.20.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.20.20.4.1\">30.35</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.20.20.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.20.20.5.1\">39.20</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.20.20.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.20.20.6.1\">36.89</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.20.20.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.20.20.7.1\">76.29</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.21.21\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A5.T6.1.21.21.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.21.21.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.21.21.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.21.21.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.21.21.3.1\">21.25</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.21.21.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.21.21.4.1\">30.11</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.21.21.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.21.21.5.1\">39.51</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.21.21.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.21.21.6.1\">36.85</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.21.21.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.21.21.7.1\">76.53</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.22.22\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A5.T6.1.22.22.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.22.22.1.1\">0-Shot / Only RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.22.22.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.22.22.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.22.22.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.22.22.3.1\">19.97</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.22.22.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.22.22.4.1\">29.65</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.22.22.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.22.22.5.1\">34.33</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.22.22.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.22.22.6.1\">38.07</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.22.22.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.22.22.7.1\">70.08</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.23.23\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A5.T6.1.23.23.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.23.23.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.23.23.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.23.23.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.23.23.3.1\">19.95</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.23.23.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.23.23.4.1\">29.89</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.23.23.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.23.23.5.1\">40.68</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.23.23.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.23.23.6.1\">38.59</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.23.23.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.23.23.7.1\">76.73</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.24.24\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A5.T6.1.24.24.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.24.24.1.1\">3-Shot / Rou + RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.24.24.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.24.24.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.24.24.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.24.24.3.1\">21.48</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.24.24.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.24.24.4.1\">30.29</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.24.24.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.24.24.5.1\">39.15</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.24.24.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.24.24.6.1\">36.79</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.24.24.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.24.24.7.1\">76.34</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.25.25\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A5.T6.1.25.25.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.25.25.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.25.25.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.25.25.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.25.25.3.1\">21.11</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.25.25.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T6.1.25.25.4.1\">30.95</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.25.25.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.25.25.5.1\">40.05</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.25.25.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.25.25.6.1\">38.62</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A5.T6.1.25.25.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.25.25.7.1\">76.89</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.26.26\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A5.T6.1.26.26.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.26.26.1.1\">0-Shot / Rou + RM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.26.26.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.26.26.2.1\">Initial</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.26.26.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.26.26.3.1\">20.36</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.26.26.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.26.26.4.1\">30.17</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.26.26.5\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.26.26.5.1\">40.68</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.26.26.6\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.26.26.6.1\">38.59</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A5.T6.1.26.26.7\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.26.26.7.1\">76.84</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T6.1.27.27\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_bb\" id=\"A5.T6.1.27.27.1\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A5.T6.1.27.27.2\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.27.27.2.1\">Final</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A5.T6.1.27.27.3\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.27.27.3.1\">20.06</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A5.T6.1.27.27.4\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A5.T6.1.27.27.4.1\">30.64</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A5.T6.1.27.27.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T6.1.27.27.5.1\">41.46</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A5.T6.1.27.27.6\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T6.1.27.27.6.1\">40.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A5.T6.1.27.27.7\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T6.1.27.27.7.1\">77.43</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 6: </span>Experimental Results on MultiDoc2Dial test set, containing 10,204 instances. Experiments are reported with the Flan-T5-XXL and Llama-2-13B-Chat models, using 3 Rouge (ROU) measures, the WeCheck reward model (abbreviated as RM), and both in tandem for sufficiency thresholding. Highest scores are boldfaced for each model. The zero-shot results are the same as those included in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.00827v1#S3.T1\" title=\"Table 1 \u2023 Principle Refinement. \u2023 3.2 In-Context Demonstration Selection \u2023 3 Evidence: Question Answering \u2023 Self-Refinement of Language Models from External Proxy Metrics Feedback\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>; this table presents a comparison between 0-shot and 3-shot performance, for each metric set.\n</figcaption>\n</figure>",
            "capture": "Table 6: Experimental Results on MultiDoc2Dial test set, containing 10,204 instances. Experiments are reported with the Flan-T5-XXL and Llama-2-13B-Chat models, using 3 Rouge (ROU) measures, the WeCheck reward model (abbreviated as RM), and both in tandem for sufficiency thresholding. Highest scores are boldfaced for each model. The zero-shot results are the same as those included in Table 1; this table presents a comparison between 0-shot and 3-shot performance, for each metric set.\n"
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.00827v1_figure_1.png",
            "caption": "Figure 1: A high-level overview of our proposed self-refinement algorithm for content-grounded question answering, with both initial response generation and iterative refinement performed with the same Large Language Model \u2133\u2133\\mathcal{M}caligraphic_M."
        },
        "2": {
            "figure_path": "2403.00827v1_figure_2.png",
            "caption": "Figure 2: GPT-4-as-a-Judge results on Flan-T5-XXL for MultiDoc2Dial (MD2D) and QuAC. With 2551 randomly sampled instances from the MultiDoc2Dial test set, we examine those for which the initial and final response differ: 495 samples for ROUGE-only, 131 samples for RM-only (WeCheck), and 504 samples for ROUGE + RM. We perform a similar analysis with all 1000 QuAC test set instances; the respective counts are: 193 samples for ROUGE-only, 65 samples for RM-only, and 224 samples for ROUGE + RM."
        }
    },
    "references": [
        {
            "1": {
                "title": "Evaluating correctness and faithfulness of instruction-following models for question answering.",
                "author": "Vaibhav Adlakah, Parishad BehnamGhader, Xing Han Lu, Nicholas Meade, and Siva Reddy. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2307.16877"
            }
        },
        {
            "2": {
                "title": "Constitutional ai: Harmlessness from ai feedback.",
                "author": "Yuntao Bai, Saurav Kadavath, Sadipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain, Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perrez, Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosuite, Liane Lovitt, Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemi Mercado, Nova DasSarma, Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec, Sheer El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly, Tom Henighan, Tristan Hume, Samuel R. Bowman, Zac Hatfield-Dodds, Ben Mann, Dario Amodei, Nicholas Joseph, Sam McCandlish, Tom Brown, and Jared Kaplan. 2022.",
                "venue": null,
                "url": "http://arxiv.org/abs/2212.08073"
            }
        },
        {
            "3": {
                "title": "Quac : Question answering in context.",
                "author": "Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen tau Yih, Yejin Choi, Percy Liang, and Luke Zettlemoyer. 2018.",
                "venue": null,
                "url": "http://arxiv.org/abs/1808.07036"
            }
        },
        {
            "4": {
                "title": "Scaling instruction-finetuned language models.",
                "author": "Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. 2022.",
                "venue": null,
                "url": "http://arxiv.org/abs/2210.11416"
            }
        },
        {
            "5": {
                "title": "Qlora: Efficient finetuning of quantized llms.",
                "author": "Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2305.14314"
            }
        },
        {
            "6": {
                "title": "MultiDoc2Dial: Modeling dialogues grounded in multiple documents.",
                "author": "Song Feng, Siva Sankalp Patel, Hui Wan, and Sachindra Joshi. 2021.",
                "venue": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6162\u20136176, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2021.emnlp-main.498"
            }
        },
        {
            "7": {
                "title": "Rarr: Researching and revising what language models say, using language models.",
                "author": "Luyu Gao, Zhuyun Dai, Panupong Pasupat, Anthony Chen, Arun Tejasvi Chaganty, Yicheng Fan, Vincent Zhao, Ni Lao, Hongrae Lee, and Da-Cheng Juan. 2023.",
                "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics, Volume 1: Long Papers, pages 16477\u201316508.",
                "url": null
            }
        },
        {
            "8": {
                "title": "Critic: Large language models can self-correct with tool-interactive critiquing.",
                "author": "Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, and Weizhu Chen. 2023.",
                "venue": "arXiv preprint arXiv:2305.11738.",
                "url": null
            }
        },
        {
            "9": {
                "title": "Large language models cannot self-correct reasoning yet.",
                "author": "Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams Wei Yu, Xinying Song, and Denny Zhou. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2310.01798"
            }
        },
        {
            "10": {
                "title": "Rouge: A package for automatic evaluation of summaries.",
                "author": "Chin-Yew Lin. 2004.",
                "venue": "In Text Summarization Branches Out, pages 74\u201381.",
                "url": null
            }
        },
        {
            "11": {
                "title": "Self-refine: Iterative refinement with self-feedback.",
                "author": "Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Sean Welleck, Bodhisattwa Prasad Majumder, Shashank Gupta, Amir Yazdanbakhsh, and Peter Clark. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2303.17651"
            }
        },
        {
            "12": {
                "title": "Is self-repair a silver bullet for code generation?",
                "author": "Theo X Olausson, Jeevana Priya Inala, Chenglong Wang, Jianfeng Gao, and Armando Solar-Lezama. 2024.",
                "venue": "In Proceedings of ICLR 2024.",
                "url": null
            }
        },
        {
            "13": {
                "title": "Automatically correcting large language models: Surveying the landscape of diverse self correction strategies.",
                "author": "Liangming Pan, Michael Saxon, Wenda Xu, Deepak Nathani, Xinyi Wang, and William Yang Wang. 2023.",
                "venue": "arXiv preprint arXiv:2308.03188.",
                "url": null
            }
        },
        {
            "14": {
                "title": "Refiner: Reasoning feedback on intermediate representations.",
                "author": "Debjit Paul, Mete Ismayilzada, Maxime Peyrard, Beatriz Borges, Antoine Bosselut, Robert West, and Boi Faltings. 2023.",
                "venue": "arXiv preprint arXiv:2304.01904.",
                "url": null
            }
        },
        {
            "15": {
                "title": "Check your facts and try again: Improving large language models with external knowledge and automated feedback.",
                "author": "Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, and Jianfeng Gao. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2302.12813"
            }
        },
        {
            "16": {
                "title": "Self-critiquing models for assisting human evaluators.",
                "author": "William Saunders, Catherine Yeh, Jeff Wu, Steven Bills, Long Ouyang, Jonathan Ward, and Jan Leike. 2022.",
                "venue": null,
                "url": "http://arxiv.org/abs/2206.05802"
            }
        },
        {
            "17": {
                "title": "Training language models with language feedback at scale.",
                "author": "J\u00e9r\u00e9my Scheurer, Jon Ander Campos, Tomasz Korbak, Jun Shern Chan, Angelica Chen, Kyunghyun Cho, and Ethan Perez. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2303.16755"
            }
        },
        {
            "18": {
                "title": "Reflexion: Language agents with verbal reinforcement learning.",
                "author": "Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2303.11366"
            }
        },
        {
            "19": {
                "title": "Llama 2: Open foundation and fine-tuned chat models.",
                "author": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas\nScialom. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2307.09288"
            }
        },
        {
            "20": {
                "title": "Shepherd: A critic for language model generation.",
                "author": "Tianlu Wang, Ping Ya, Xiaoqing Ellen Tan, Sean O\u2019Brien, Ramakanth Pasunuru, Jane Dwivedi-Yu, Olga Golovneva, Luke Zettlemoyer, Maryam Fazel-Zarandi, and Asli Celikyilmaz. 2023a.",
                "venue": "arXiv preprint arXiv:2308.04592.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Enable language models to implicitly learn self-improvement from data.",
                "author": "Ziqi Wang, Le Hou, Tianjian Lu, Yuexin Wu, Yunxuan Li, Hongkun Yu, and Heng Ji. 2023b.",
                "venue": null,
                "url": "http://arxiv.org/abs/2310.00898"
            }
        },
        {
            "22": {
                "title": "Generating sequences by learning to self-correct.",
                "author": "Sean Welleck, Ximing Lu, Peter West, Faeze Brahman, Tianxiao Shen, Daniel Khashabi, and Yejin Choi. 2022.",
                "venue": null,
                "url": "http://arxiv.org/abs/2211.00053"
            }
        },
        {
            "23": {
                "title": "Wecheck: Strong factual consistency checker via weakly supervised learning.",
                "author": "Wenhao Wu, Wei Li, Xinyan Xiao, Jiachen Liu, Sujian Li, and Yajuan Lv. 2022.",
                "venue": "arXiv preprint arXiv:2212.10057.",
                "url": null
            }
        },
        {
            "24": {
                "title": "Selfee: Iterative self-revising llm empowered by self-feedback generation.",
                "author": "Seonghyeon Ye, Yongrae Jo, Doyoung Kim, Sungdong Kim, Hyeonbin Hwang, and Minjoon Seo. 2023.",
                "venue": "Blog post.",
                "url": "https://kaistai.github.io/SelFee/"
            }
        },
        {
            "25": {
                "title": "A comprehensive analysis of the effectiveness of large language models as automatic dialogue evaluators.",
                "author": "Chen Zhang, Luis Fernando D\u2019Haro, Yiming Chen, Malu Zhang, and Haizhou Li. 2024.",
                "venue": "In AAAI-2024.",
                "url": null
            }
        },
        {
            "26": {
                "title": "Bertscore: Evaluating text generation with bert.",
                "author": "Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020.",
                "venue": "In ICLR 2020.",
                "url": null
            }
        },
        {
            "27": {
                "title": "Judging llm-as-a-judge with mt-bench and chatbot arena.",
                "author": "Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2306.05685"
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.00827v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "5"
        ],
        "methodology_sections": [
            "2",
            "2.1",
            "2.2"
        ],
        "main_experiment_and_results_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3",
            "4",
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "3",
            "4",
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "research_context": {
        "paper_id": "2403.00827v1",
        "paper_title": "Self-Refinement of Language Models from External Proxy Metrics Feedback",
        "research_background": "### Paper's Motivation\nThe motivation behind this paper is to address the challenges associated with refining responses generated by smaller large language models (LLMs). While contemporary LLMs like GPT-3.5 and GPT-4 have demonstrated success in refining their outputs using various mechanisms and principles, smaller models often fail to achieve similar results. The paper aims to improve the efficacy of these smaller models by introducing a structured, principle-guided self-refinement approach that leverages proxy metrics as a feedback mechanism.\n\n### Research Problem\nThe primary research problem addressed in this paper is the underperformance of smaller instruction-tuned LLMs in self-refinement tasks. This problem is exacerbated by the lack of well-designed stopping mechanisms in existing methods, which can lead to degraded output quality even when starting from high-quality responses. Another aspect of the problem is the need to imbue principles such as faithfulness, specificity, safety, and relevance into the responses of conversational agents, ensuring that these qualities are reflected consistently across various tasks and models.\n\n### Relevant Prior Work\n1. **Evaluation and Critique of Responses**:\n   - Saunders et al. (2022)\n   - Scheurer et al. (2023)\n   - Shinn et al. (2023)\n   - Ye et al. (2023)\n\n2. **Feedback and Refinement Mechanisms**:\n   - Human-in-the-loop\n   - Reward models\n   - Model-generated feedback\n   - Feedback forms: pairwise comparisons, scalar scores, natural language descriptions\n\n3. **Refinement Techniques**:\n   - Separate supervised refiners\n   - Domain-specific refinement\n\n4. **Self-Refinement Approaches**:\n   - Madaan et al. (2023)\n   - Wang et al. (2023b)\n   - Shinn et al. (2023)\n   - Observations about the limitations of current methods, such as performance issues with smaller models and the need for stopping mechanisms, highlighted by Huang et al. (2023)\n\nThe paper's proposed solution, Proxy Metric-based Self-Refinement (ProMiSe), aims to address these gaps by providing a more directed and principle-focused method for self-refinement in smaller LLMs. This approach uses proxy metrics for quality feedback and independent principle-specific few-shot refinement combined with rejection sampling. It targets both content-grounded single-turn question answering and multi-turn dialogue generation, showing improvements across multiple evaluation metrics.",
        "methodology": "**Proposed Method: Self-Refinement of Language Models from External Proxy Metrics Feedback**\n\n**Overview:**\nThe methodology introduces ProMiSe, a model designed to improve responses iteratively, based on feedback from external proxy metrics, ensuring the generated responses meet a quality threshold aligned with certain principles.\n\n**Key Steps:**\n\n1. **Generate Initial Response:**\n   - Given an input (e.g., a document and conversation history), the model generates an initial response.\n\n2. **Obtain External Feedback:**\n   - Using proxy metrics, the model evaluates the generated response.\n   - These metrics provide feedback on various aspects of the response, linked to quality principles defined by the user.\n\n3. **Refine the Response:**\n   - If the initial response is found lacking, the model refines it according to the feedback received.\n   - This step involves iterating the refinement process until the response meets a predefined quality threshold.\n\n**Iterative Refinement Process:**\n\n- **Rejection Sampling:**\n  - Conducted on a set of refinement candidates.\n  - Each candidate is scored using the available metrics.\n  - The response with the highest scores across the majority of metrics is selected as the best candidate.\n\n- **Score Comparison and Acceptance:**\n  - The scores of the best refinement candidate (\\(\\mathbf{y}^*\\)) are compared against a threshold (\\(\\gamma\\)).\n  - If \\(\\mathbf{y}^*\\) meets or exceeds the threshold on all metrics, it is accepted as the final response.\n\n- **Further Refinement:**\n  - If \\(\\mathbf{y}^*\\) does not meet the threshold, it is compared with the scores of the previous best response (\\(\\mathbf{y}_{\\text{best}}\\)).\n  - The user assigns weights (\\(\\bm{\\omega}\\)) to each metric based on importance and design goals.\n  - Calculate an improvement indicator for each metric (\\(\\mathcal{M}\\)), set to 1 if the new response improves the previous, and 0 otherwise, weighted by \\(\\bm{\\omega}\\).\n  - Compute the sum of these weighted indicators and compare to a user-defined threshold (\\(\\tau\\)).\n  \n  \\[\n  \\text{If the sum exceeds } \\tau:\n  - Update the best refinement response to the new candidate.\n  \\text{Else:}\n  - Retain the previous best response for the next iteration.\n  \\]\n\n- **Termination:**\n  - The iterative process continues until the refinement meets the quality criteria or other stopping conditions are met.\n\n**Innovations:**\n- The integration of external proxy metrics as a feedback mechanism ensures responses align with specific quality principles.\n- A systematic approach to refining responses iteratively, guided by metric-based rejection sampling and weighted score comparison.\n- User customizability through weight assignments (\\(\\bm{\\omega}\\)) and thresholds (\\(\\gamma\\) and \\(\\tau\\)), allowing the model to cater to varied design goals and principles.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n**Experiment Setting:**\n- **Task:** Content-grounded question answering (QA).\n- **Data Source:** MultiDoc2Dial training dataset (Feng et al., 2021).\n- **Prompt Template:** Document, conversation history, and gold response as specified in Appendix C.\n- **Generation:** Initial response generation using 3 in-context exemplars from MultiDoc2Dial training data.\n  - Exemplars include various conversation lengths to align with the final user query.\n- **In-context Refinement:** Contrastive examples annotated manually to illustrate better and worse responses based on quality principles (specificity, relevance, accuracy).\n  - Tags used: \u201cnot {principle}\u201d and \u201cmore {principle}\u201d.\n\n**Evaluation Metrics:**\n1. **ROUGE-1 Recall (response vs. document):** Assesses specificity.\n2. **ROUGE-L (response vs. document):** Evaluates faithfulness, favoring extractive over hallucinated answers.\n3. **ROUGE-L (response vs. conversation history):** Measures relevance and consistency with the user query.\n4. **WeCheck Model (Wu et al., 2022):** Specifically evaluates faithfulness.\n\n**Threshold Settings Tested:**\n- Using three ROUGE metrics alone.\n- Using WeCheck model alone with rejection sampling based on WeCheck scores.\n- Combined approach using both ROUGE and WeCheck metrics.\n\n**Improvement Determination:**\n- For ROUGE metrics: All three metrics must meet a pre-defined threshold.\n- For WeCheck: The highest scoring response according to WeCheck is selected.\n- For Combined: A response must meet thresholds for all four metrics.\n- **Reward Indicator:** \n  - Yielded during refinement (1 if improved, 0 if not).\n  - Weighted sum of reward indicators; updating best response if sum > 0.5.\n\nThe results demonstrate the effectiveness of the ProMiSe method in refining responses in the content-grounded QA setting, significantly enhancing the quality based on the specified principles using the above thresholding and evaluation mechanisms."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To evaluate the performance of the ProMiSe algorithm in content-grounded question answering, specifically from refining responses along different quality dimensions guided by external proxy metrics feedback.",
            "experiment_process": "The ProMiSe algorithm was applied to instances from the MultiDoc2Dial and QuAC datasets for content-grounded question answering. Initial responses were generated using in-context exemplars and further refined using manual annotations to highlight quality differences concerning principles like 'specific', 'relevant', or 'accurate'. Three ROUGE metrics and the WeCheck model were used to assess the responses. Experiments were conducted using three settings: using only the ROUGE metrics, only the WeCheck model, and a combination of both.",
            "result_discussion": "The results demonstrated that combining ROUGE metrics with the WeCheck reward model consistently yielded improved performance across various metrics. The study highlighted the importance of the chosen proxy metrics as accessible links to final evaluation metrics, indicating a generally positive correlation between improvements in proxy metrics and final evaluation metrics, such as ROUGE-L and BERTScore-Recall.",
            "ablation_id": "2403.00827v1.No1"
        },
        {
            "research_objective": "To assess the relationship between the improvements in final evaluation metrics and changes in proxy metrics during the execution of the ProMiSe algorithm.",
            "experiment_process": "The study compared the proxy metric scores and final evaluation metrics such as ROUGE-L and BERTScore-Recall. A detailed analysis was performed to explore the correlation between proxy metric improvements and the overall improvement in downstream evaluation metrics. This includes various settings taking into account single-turn QA and multi-turn dialog refinements.",
            "result_discussion": "The findings indicated a correlation between the degree of improvement in proxy metrics and the final evaluation metrics. A larger improvement in proxy metrics generally corresponded to a noticeable positive change in evaluation metrics. This reinforced the value of using external metric feedback to preserve the integrity of downstream evaluation metrics.",
            "ablation_id": "2403.00827v1.No2"
        },
        {
            "research_objective": "To evaluate the impact of synthetic dialogue generation using ProMiSe on the performance of a fine-tuned Llama-2-13B-Chat model.",
            "experiment_process": "Synthetic dialogues of varying lengths were generated using Flan-T5-XXL and used to QLoRA fine-tune the Llama-2-13B-Chat model. Experiment datasets included MultiDoc2Dial training and test data with generated dialogues consisting of 1-3 agent responses. The performance was measured in terms of lexical and semantic similarity using metrics such as BERT-Recall, Recall, BERT K-Precision, and K-Precision.",
            "result_discussion": "Significant improvements across all metrics were observed when comparing models refined with synthetic data to those without. Notably, the refined model showed improvements over models trained on human-annotated data alone, suggesting the value of response quality refinement in generating useful synthetic data.",
            "ablation_id": "2403.00827v1.No3"
        },
        {
            "research_objective": "To validate the efficacy of the ProMiSe algorithm through automated evaluation using GPT-4 as a judge.",
            "experiment_process": "Automated evaluation with GPT-4 was conducted to compare the initial and refined responses generated by ProMiSe across MultiDoc2Dial and QuAC datasets. Samples where initial and final responses differed were evaluated randomly from the test set indices to determine which responses were deemed better by GPT-4. Prompts adapted from MT-bench evaluation methodologies were used for this assessment.",
            "result_discussion": "GPT-4 consistently judged the final responses to be better than the initial responses in most conditions for MultiDoc2Dial, validating the complementary nature of the proxy metrics used. The QuAC dataset showed some inconsistencies, potentially due to the nature of short responses and entailment measured by WeCheck. Overall, the results indicated the strong correlation between the proxy metrics optimization and the subjective judgments by GPT-4, reinforcing the effectiveness of the ProMiSe algorithm.",
            "ablation_id": "2403.00827v1.No4"
        }
    ]
}