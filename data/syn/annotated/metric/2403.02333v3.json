{
    "title": "Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning",
    "abstract": "Large language models (LLMs) have shown great potential in complex reasoning tasks, yet their performance is often hampered by the scarcity of high-quality and reasoning-focused training datasets. Addressing this challenge, we propose Key-Point-Driven Data Synthesis (KPDDS), a novel data synthesis framework that synthesizes question-answer pairs by leveraging key points and exemplar practices from authentic data sources. KPDDS ensures the generation of novel questions with rigorous quality control and substantial scalability.\n\nAs a result, we present KPMath, an extensive synthetic dataset tailored for mathematical reasoning, comprising over 800K question-answer pairs. Utilizing KPMath and augmenting it with additional reasoning-intensive corpora, we create the comprehensive KPMath-Plus dataset.\n\nThe Qwen1.5-72B model, fine-tuned on KPMath-Plus, surpasses competitors in the 7B to 70B range and best commercial models like GPT-4 across multiple math reasoning datasets.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "The recent advent of large language models (LLMs) such as GPT-4 (OpenAI, 2023), Gemini (Team et al., 2023), and Mistral (AI, 2024) has sparked significant interest due to their advanced capabilities in diverse domains. Despite this, their reasoning prowess, particularly in challenging domains like advanced mathematics, competitive programming, and integrated vision-language planning, remains under scrutiny. In current mathematical reasoning corpora, such as OpenWebMath and MathPile, the vast internet-sourced data often suffers from poor quality and relevance to the subject matter. Conversely, manually annotated high-quality datasets like the MATH dataset are scarce and sometimes lack detailed reasoning steps. Prior efforts to boost the mathematical reasoning capabilities of LLMs using synthetic data have primarily adopted two strategies. The first strategy focuses on augmenting existing datasets. It involves question rephrasing or generating similar questions. However, the primary issue is that the generated questions are not only textually or conceptually similar but also uncontrollable in their variations. The second strategy seeks to broaden the training dataset by generating new questions from established knowledge concepts. Knowledge bases are either compiled from online educational resources, such as Khan Academy\u2019s math courses, or synthesized from scratch using models like GPT-4. However, these methods depend on constructed knowledge that might not align with the existing dataset\u2019s distributions and are difficult to comprehend without examples to illustrate the concepts.\n\nConsidering these disadvantages of the two strategies, we introduce a novel data synthesis paradigm termed Key-Point-Driven Data Synthesis (KPDDS), which capitalizes on the strengths of both data synthesis strategies. It delves into datasets for knowledge mining, using relevant key points and associated problems to inform the generation of new problems. For knowledge construction, we begin by extracting topics and key points from seed problems using a labeling model, followed by a clustering algorithm to ensure deduplication and alignment. Therefore, we get the Math Practices with Key Points (MPKP) dataset and construct the Topic-level Co-occurrence Probability Matrix (TCPM) to understand the frequency and distribution of topic pairs within the dataset. For practice synthesis, we sample multiple topics and key points from MPKP using the TCPM as a guide. These key points, along with corresponding example practices, serve as input for the synthesizing model to generate new questions. A scoring model then assesses the quality of these questions, allowing only those with high scores to proceed. Then, a reasoning model generates a range of answer options, which are later consolidated into consensus solutions through a voting mechanism. Utilizing the training sets of the MATH and GSM8K datasets as foundational data, we developed a novel dataset named KPMath. Our training corpus was further enriched by integrating a series of mathematical reasoning datasets, leading to the creation of a comprehensive training dataset, KPMath-Plus. \n\nIn the Hungarian Exam Score test, the KPMath-Plus-Mistral-7B model outperforms the majority of models, indicating its competitive performance."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Math Reasoning with LLMs",
            "text": "Recently, solving math problems is treated as an important aspect of evaluating LLM\u2019s reasoning ability.\nHowever, the LLMs trained for general purposes like GPT-4 (Bubeck et al., 2023  ###reference_b9###), Llama2 (Touvron et al., 2023  ###reference_b53###), Mistral (Jiang et al., 2023  ###reference_b26###), InternLM2 (Team, 2023  ###reference_b52###), Qwen (Bai et al., 2023  ###reference_b7###), Gemini (Team et al., 2023  ###reference_b51###) and DeepSeek (Bi et al., 2024  ###reference_b8###) have shown limited capabilities in math reasoning.\nTo enhance the math reasoning ability of LLMs, researchers have turned their attention to research directions like prompting methods (Chia et al., 2023  ###reference_b13###; Zheng et al., 2023  ###reference_b68###; Chen et al., 2023  ###reference_b11###; Zhang et al., 2023b  ###reference_b67###), data construction for pretraining (Taylor et al., 2022  ###reference_b50###; Lewkowycz et al., 2022  ###reference_b30###; Paster et al., 2023a  ###reference_b43###; Azerbayev et al., 2022  ###reference_b5###; 2023  ###reference_b6###) and instruction tuning (Yue et al., 2024  ###reference_b64###; Yu et al., 2023b  ###reference_b63###; Luo et al., 2023a  ###reference_b34###; Gou et al., 2024b  ###reference_b20###; An et al., 2023  ###reference_b2###; Liu & Yao, 2024  ###reference_b32###; Huang et al., 2024  ###reference_b25###; Li et al., 2024  ###reference_b31###), interacting with external tools (Mishra et al., 2022  ###reference_b40###; Gao et al., 2022  ###reference_b18###; Gou et al., 2024a  ###reference_b19###; b  ###reference_b20###; Yue et al., 2024  ###reference_b64###; Zhou et al., 2023  ###reference_b70###; Zhang et al., 2024  ###reference_b65###), and reinforcement learning with rewards (Ma et al., 2023  ###reference_b37###; Yu et al., 2023a  ###reference_b62###; Wang et al., 2023a  ###reference_b55###; Luong et al., 2024  ###reference_b36###) for either outcomes or steps.\nThis work is in line with math reasoning data construction for instruction tuning."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Data Synthesis for Math Reasoning",
            "text": "In the realm of math reasoning, data synthesis is usually applied for instruction tuning, with each data sample encompassing a question text and its corresponding answer text. To advance this field, research efforts focus on three critical aspects: enhancing the quality of answers, generating novel questions, and implementing quality control measures.\nFor answer quality, some works focus on chain-of-thought (CoT) (Wei et al., 2022  ###reference_b58###; Yu et al., 2023b  ###reference_b63###) style answers, while others like Yue et al. (2024  ###reference_b64###) and Gou et al. (2024b  ###reference_b20###) investigate program-based answers.\nYue et al. (2024  ###reference_b64###) synthesize program-of-thought (PoT) (Chen et al., 2022  ###reference_b12###) style answers using GPT-4.\nGou et al. (2024b  ###reference_b20###) further explore interleaved answers with program-based tool use.\nIn this work, we focus on the synthesis of CoT-style answers.\nFor question novelty, research diverges into two approaches: starting from existing problems, Shao et al. (2023  ###reference_b47###) explore answer-first data synthesis and Yu et al. (2023b  ###reference_b63###) utilize backward reasoning, while Luo et al. (2023a  ###reference_b34###), An et al. (2023  ###reference_b2###), and Liu & Yao (2024  ###reference_b32###) focus on evolution instruction and iterative composition using reasoning steps. Alternatively, some work begins with knowledge-based techniques, where Huang et al. (2024  ###reference_b25###) extracts concepts from Khan Academy and Li et al. (2024  ###reference_b31###) uses GPT-4 to create a concepts taxonomy. The former is limited by poor scalability with existing data, and the latter often yields a synthetic data distribution that significantly deviates from real data. In our work, we create questions by extracting key points from real data and then synthesizing new problems based on these key points with authentic and reliable exercises.\nFor synthetic data quality, Huang et al. (2024  ###reference_b25###) prompt GPT-4 to convert CoT-style answers into verifiable Lean-3 code, while Trinh et al. (2024  ###reference_b54###)\u2019s AlphaGeometry ensures Euclidean geometry theorem accuracy using symbolic deduction. In contrast, We assess synthetic question and answer quality through GPT-4 scored evaluations and consensus scoring via repeated sampling."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "Data Synthesis for Other Applications",
            "text": "The aim of synthetic data is to offer a convincing and fuller depiction of the actual data source, maintaining key statistical characteristics such as the distribution patterns of continuous variables, categorical ratios, and the latent relationships among different variables.\nExcept for math reasoning, there are also works on data synthesis for other applications like code (Luo et al., 2023b  ###reference_b35###; Gunasekar et al., 2023  ###reference_b21###; Wei et al., 2023  ###reference_b59###), table reasoning (Lei et al., 2023  ###reference_b29###), medical application (Zhang et al., 2023a  ###reference_b66###; Tang et al., 2023  ###reference_b49###), visual reasoning (Du et al., 2023  ###reference_b17###), and general purposes (Wang et al., 2022  ###reference_b56###; Xu et al., 2023  ###reference_b61###; Li et al., 2024  ###reference_b31###)."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Method",
            "text": ""
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Overview",
            "text": "In the comprehensive framework illustrated in Figure 1, our methodology is systematically delineated into two primary phases: Knowledge Construction and Practice Generation, each consisting of two components. We will introduce these four components separately: Knowledge Extraction, Topic-level Co-occurrence Probability Matrix (TCPM) Construction, Question Generation with Quality Assessment, and Answer Generation with Consensus Assessment. The specific prompts utilized for each component are detailed in Appendix A."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Knowledge Extraction",
            "text": "We employ GPT-4 as the labeling model to extract knowledge pertinent to problem-solving from seed problems, as illustrated in Figure 1. The questions and solutions of seeds are input into GPT-4, which then extracts information at two levels of knowledge. Key excerpts from the prompt for knowledge extraction are showcased in Figure 2, and the complete details are shown in Figure 8. The first level of knowledge is the topics, which correspond to the subject and its subcategories that are pertinent to the problem, such as \"Geometry - Circles.\" The secondary level is key points (KPs), which comprise the theorems or methods essential for the resolution process, like \"Determining the center of a circle from its equation.\"\n\nThe process of knowledge extraction results in an uncontrolled, extensive number of topics, many of which exhibit semantic overlap. Examples of such redundancy include \"Arithmetic - Percentages\" and \"Arithmetic - Percentage.\" Furthermore, there are instances where a topic occurs only once, accompanied by very few KPs. Therefore, we further process the extracted knowledge data. Specifically, we use OpenAI\u2019s text-embedding-ada-002 to embed all KPs, and the topics are represented by the average value of the embeddings of their included KPs. Then, we calculate the cosine similarity of the topic embeddings for deduplication and clustering, obtaining several representative topics, which are displayed in Tables 4 and 3. Finally, we construct the Math Practices with Key Points (MPKP) dataset."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "TCPM Construction",
            "text": "Mathematical problems typically involve multiple topics and KPs, and the combination of topics within these problems follows a discernible pattern. For example, semantically highly similar topics do not appear repeatedly in the same problem, whereas arbitrarily meshing unrelated topics tends to result in nonsensical questions.\n\nIn light of this structured complexity, we compute the Topic-level Co-occurrence Probability Matrix (TCPM) from the topics present in mathematical questions within the MPKP dataset. Our methodology is systematically outlined in Algorithm 1. This algorithm quantifies the co-occurrence and self-interaction of topics within a dataset by constructing a matrix that logs the frequency of topic pairs and the instances where the number of KPs for individual topics exceeds five, followed by a logarithmic normalization. An increased co-occurrence probability between topic clusters indicates a likelihood of their concurrent appearance in the examined problems. Figures 10 and 11 presents a heatmap visualization of the co-occurrence probability matrix."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Question Generation with Quality Assessment",
            "text": "By extracting knowledge and constructing the TCPM from the seed problems, we pave the way for generating new problems that are similar yet varied in nature, building upon their foundational elements. Leveraging the TCPM, we perform probabilistic sampling of topics, with the probability calculation method as follows:\nwhere  represents the vector used for probabilistic topic sampling,  and  are index variables,  denotes the -th topic, and  denotes the -th row vector in TCPM.  denotes the Hadamard product (element-wise multiplication).\nWe proceed to sample two to three topics, and for each topic, we randomly select a problem along with the associated KPs for that topic. This process yields a foundational KPs-Practice information set as the basis for our problem generation. Employing GPT-4, we use this set to generate new problems, with the prompt presented in Figure 4.\n\nFollowing the generation of problems, we conduct a quantitative evaluation to determine the quality of each problem by GPT-4, with the prompt shown in Figure 9. This assessment is based on two criteria: the presence of the provided KPs and the absence of logical or factual errors. Each problem is assigned a quality score on a continuous scale from 0 to 1. Figure 4 shows the score distribution of our synthetic questions. In assembling quality-assured questions, a threshold of 0.85 is instituted to screen the newly generated problems, saving about 51% of high-quality questions. Figure 12 displays an example of a high-quality and a poor-quality problem originating from identical initial inputs."
        },
        {
            "section_id": "3.5",
            "parent_section_id": "3",
            "section_name": "Solution Generation with Consensus Assessment",
            "text": "Prior work in the domain did not emphasize the quality control measures or relied solely on answers generated by models like GPT-4. By integrating a voting protocol, our methodology is designed to minimize the effects of noisy data and enhance the reliability of the answer-generation process. To ensure the correctness of generated answers, we employ a few-shot strategy where the reference problem is utilized as a demonstration input. To procure a diverse array of CoT rationales, we employ nucleus sampling, thereby invoking multiple prompts. Subsequently, a voting mechanism, derived from an enhanced version of the script from Gou et al. (2024b ###reference_b20###), is employed to aggregate the solutions. This mechanism leverages packages such as sympy 111https://www.sympy.org ###reference_www.sympy.org### to ensure that equivalent answers, albeit in different forms (e.g., fractions and decimals), are recognized as equal. As illustrated in Figure 13 ###reference_###, some samples in our dataset include multiple sub-questions. We have excluded data with more than three sub-questions to maintain analytical clarity. For the multipart questions in our study, we extract the answers to sub-questions and apply a distinct voting mechanism for each. For each sub-question, we utilized GPT-4 with a temperature of 0.75 and a top-p of 0.95, resampling to obtain 10 potential responses, which then contribute to the formation of the Consensus Score Vector (CSV). Let be a question- with sub-questions. Then is defined as where each is the consensus score for the -th sub-question and is calculated based on the voting results from the potential responses. Each is in the range [0, 1]."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiment",
            "text": "This segment is based on the MATH (Hendrycks et al., 2021a ###reference_b22###) dataset\u2019s training set, which consists of 7,500 samples from high school math competitions, encompassing seven subjects and five difficulty levels. Utilizing the KPDDS approach on the seed problems, we generate a collection of 500K question-answer pairs. Considering that voting may produce multiple answers to the same question, such as in extreme cases where one question has ten answers, this type of data may not be conducive to model learning. Therefore, by rewriting each original question and its answers (not necessarily correct), we can obtain non-repetitive question-answer pairs.\n\nAfter a thorough examination of the consensus voting strategies optimization, detailed in Section \u00a7 4.7 ###reference_###, we refined our dataset to include the most representative 253K data points. Drawing from the GSM8K (Cobbe et al., 2021b ###reference_b15###) training set, which offers 7,473 samples of grade school math problems characterized by their 2 to 8 step solutions, we established the KPMATH-G component. We simplified our approach due to the dataset\u2019s emphasis on basic math operations. Instead of generating solutions through consensus assessment, we generated three potential solutions containing mathematical expressions for each question and then meticulously verified the accuracy of each expression. We removed any data with incorrect expressions and transformed the remaining correct solutions into detailed, expression-free explanations. This process contributed an additional 613K data points to our dataset.\n\nTo ensure diversity and quality, we curated a comprehensive collection from various high-quality open-source mathematical reasoning datasets. The collection encompasses the complete datasets of MetaMath (Yu et al., 2023b ###reference_b63###), MMIQC (Liu & Yao, 2024 ###reference_b32###), and Open-Platypus (Lee et al., 2023 ###reference_b28###), in addition to the training sets of GSM8K (Cobbe et al., 2021b ###reference_b15###), MATH (Hendrycks et al., 2021a ###reference_b22###), and TAL-SCQ5K-EN (math eval, 2023 ###reference_b38###), as well as the CoT subset of MathInstruct (Yue et al., 2024 ###reference_b64###). As there was significant overlap among these datasets, we applied min-hash techniques to minimize redundancy. We also omitted entries with excessively long numbers or those with empty answers. This careful curation resulted in a robust dataset of 711K data points. It is noteworthy that these procedural steps of deduplication and filtering out excessively long numbers were also applied to KPMATH-M and KPMATH-G datasets.\n\nThrough these comprehensive measures, the final KPMATH-Plus dataset aggregates the three individual components into a substantial collection, culminating in a total of 1,576K data points that embody the richness and variety of mathematical problem-solving challenges."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Training Dataset Construction",
            "text": "This segment is based on the MATH (Hendrycks et al., 2021a) dataset\u2019s training set, which consists of 7,500 samples from high school math competitions, encompassing seven subjects and five difficulty levels. Utilizing the KPDDS approach on the seed problems, we generate a collection of 500K question-answer pairs.\n\nConsidering that voting may produce multiple answers to the same question, such as in extreme cases where one question has ten answers, this type of data may not be conducive to model learning. Therefore, by rewriting each original question and its answers (not necessarily correct), we can obtain non-repetitive question-answer pairs.\n\nAfter a thorough examination of the consensus voting strategies optimization, detailed in Section \u00a7 4.7, we refined our dataset to include the most representative 253K data points.\n\nDrawing from the GSM8K (Cobbe et al., 2021b) training set, which offers 7,473 samples of grade school math problems characterized by their 2 to 8 step solutions, we established the KPMATH-G component.\n\nWe simplified our approach due to the dataset\u2019s emphasis on basic math operations. Instead of generating solutions through consensus assessment, we generated three potential solutions containing mathematical expressions for each question and then meticulously verified the accuracy of each expression. We removed any data with incorrect expressions and transformed the remaining correct solutions into detailed, expression-free explanations. This process contributed an additional 613K data points to our dataset.\n\nTo ensure diversity and quality, we curated a comprehensive collection from various high-quality open-source mathematical reasoning datasets. The collection encompasses the complete datasets of MetaMath (Yu et al., 2023b), MMIQC (Liu & Yao, 2024), and Open-Platypus (Lee et al., 2023), in addition to the training sets of GSM8K (Cobbe et al., 2021b), MATH (Hendrycks et al., 2021a), and TAL-SCQ5K-EN (math eval, 2023), as well as the CoT subset of MathInstruct (Yue et al., 2024). As there was significant overlap among these datasets, we applied min-hash techniques to minimize redundancy. We also omitted entries with excessively long numbers or those with empty answers. This careful curation resulted in a robust dataset of 711K data points.\n\nIt is noteworthy that these procedural steps of deduplication and filtering out excessively long numbers were also applied to KPMATH-M and KPMATH-G datasets. Through these comprehensive measures, the final KPMATH-Plus dataset aggregates the three individual components into a substantial collection, culminating in a total of 1,576K data points that embody the richness and variety of mathematical problem-solving challenges."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Implementation Details",
            "text": "In our supervised fine-tuning (SFT) experiments, we employed chat message templates to transform question-answer pairs into the format: \u201cUser: {question}\\nEnclose the final answer using \\boxed{}.\\n\\nAssistant: {answer}\u201d. We utilized the LLaMa-Factory repository (Zheng et al., 2024) to fine-tune the models for 3 epochs across all experiments. We adopted a linear learning rate schedule with a warm-up ratio. The maximum learning rate is 1e-5, except for DeepSeekMath, which is 5e-5. We trained all models with BFloat16 numerical format, DeepSpeed ZeRO Stage3 (Rajbhandari et al., 2021) and Flash-Attention 2 (Dao, 2023). For evaluation, we adopted the same template in SFT to prompt all questions. We employed greedy decoding with a maximum sequence length of 2,048 tokens."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Evaluation and Metrics",
            "text": "We evaluate our fine-tuned models on GSM8k (Cobbe et al., 2021a  ###reference_b14###) and MATH (Hendrycks et al., 2021b  ###reference_b23###), along with 4 out-of-distribution datasets, namely SVAMP (Patel et al., 2021  ###reference_b45###), ASDIV (Miao et al., 2021  ###reference_b39###), TabMWP (Lu et al., 2022  ###reference_b33###), MAWPS (Koncel-Kedziorski et al., 2016  ###reference_b27###). We utilize an enhanced version of the script from Gou et al. (2024b  ###reference_b20###) to extract answers, parse expressions, and compare the equivalency of the answers. The Hungarian Exam was first introduced by Grok-1 (xAI, 2023  ###reference_b60###), designed to evaluate the out-of-domain capabilities of mathematical models. We follow the evaluation method proposed by Paster (2023  ###reference_b42###), which divides this exam into 33 challenging problems suitable for model processing, and these answers require manual verification by humans."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "Baselines",
            "text": "We present results from a range of state-of-the-art (SoTA) proprietary LLMs, including OpenAI\u2019s GPT-4, ChatGPT (gpt-3.5-turbo), Google\u2019s PaLM-2, and Anthropic\u2019s Claude-2. Regarding open-source models, we consider base models such as LLaMA-2, DeepSeekMath, Mistral, Llemma, and Qwen1.5. Supervised Fine-Tuning (SFT) employs CoT rationales from the original GSM8k and MATH dataset (15k samples) for fine-tuning. We also showcase the performance of advanced models using SFT or RLHF on various mathematical reasoning datasets, including MAmmoTH, WizardMath, Platypus-2, MetaMath, and MMIQC."
        },
        {
            "section_id": "4.5",
            "parent_section_id": "4",
            "section_name": "Main Results",
            "text": "Table 1 presents the results on six widely-used mathematical benchmarks, highlighting several key observations: KPMath-Plus significantly enhances the performance of multiple base models, with average accuracy improvements ranging from 10.6% to 36.9%. The KPMath-Plus-Qwen1.5-72B model achieves promising performance on various math reasoning datasets, outperforming competitors in the 7B to 70B range.\n\nFigure 6 displays the Hungarian Exam Score versus GSM8K Performance of various models, with comparative data sourced from Paster (2023). KPMath-Plus-Mistral-7B is notably behind only to GPT-4 (OpenAI, 2023) and Grok-1 (xAI, 2023). Additionally, compared to other fine-tuned models, it exhibits a well-balanced performance between the two test sets, suggesting that our model does not overfit the seed data.\n\nOur comprehensive analysis across multiple widely recognized math reasoning datasets confirms the superiority of KPMath-Plus in achieving the highest performance. Remarkably, KPMath-Plus maintains exceptional competitiveness even when compared to numerous 70B models, despite being based on a 7B architecture."
        },
        {
            "section_id": "4.6",
            "parent_section_id": "4",
            "section_name": "Ablation Study on Training Data Components and Size",
            "text": "We conducted an ablation study with the KPMath-Plus data components on the Mistral-7B model, training over 3 epochs. Results in Table 2 indicate that integrating KPMath-G, derived from the GSM8K dataset, enhances performance on GSM8K by 5% compared to training solely on MathMix. Improvements extend to SVAMP, ASDiv, and MAWPS, while a slight performance decline in MATH and TabMWP is observed, potentially due to their higher complexity. Moreover, combining KPMath-M, based on the MATH dataset, with MixMath consistently increases scores by over 1% across all datasets. Merging KPMath-G and KPMath-M significantly boosts overall performance, with gains of 6.4% on GSM8K and 3.5% on MATH, averaging a 4.1% improvement, illustrating the comprehensive benefits of our synthesized data within KPMath-Plus for mathematical reasoning.\n\nWe also investigated the impact of training data size on the KPMath-Plus-Mistral-7B model\u2019s performance. As demonstrated in Figure 6, model performance exhibits a logarithmic increase with the expansion of training data. The model achieves impressive results with small data size and maintains a steady growth trend. This study underlines the exceptional quality of our data and establishes a clear linkage between training data size and model performance, particularly in tackling complex tasks. In our future work, we aim to further explore larger and higher-quality datasets to continue improving model performance."
        },
        {
            "section_id": "4.7",
            "parent_section_id": "4",
            "section_name": "Investigation on the Consensus Voting Strategy",
            "text": "We conducted a comparative analysis to identify the optimal consensus voting strategies for KPMath-M, experimenting with three distinct strategies on the Mistral-7B model. The first strategy, non-voting, involved retaining all answers, regardless of their differences. The second strategy, semi-voting, for questions with only one sub-question, preserved only the most popular answer to ensure complete consensus in the retained response. For questions with multiple sub-questions, consensus needed to be reached on at least one of the answers. The third strategy was full-voting, requiring consensus on every sub-question. Additionally, we conducted CSV threshold experiments on the latter two strategies. We integrated KPMath-M with different strategies into KPMath-G and MixMath, and after fine-tuning on Mistral-7B, we obtained results as demonstrated in Figure 7. The semi-voting with a CSV threshold of 0.1 proved to be the best setting, with the data volume reduced by 46.7% compared to non-voting, yet without any degradation in performance. Therefore, we retained KPMath-M under this setting as our final dataset. This experiment also validated the effectiveness of our consensus voting strategy in filtering data for quality."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we propose a new data synthesis paradigm that is focused on the generation of large-scale, high-quality, symbolically-driven training datasets. Leveraging this paradigm, we have developed an extensive synthetic dataset tailored for mathematical reasoning. By utilizing this data set, our fine-tuned model achieved excellent performance in multiple data sets including MATH and GSM8K, and the performance exceeded all 7B to 70B competitors. Our research underscores the efficacy of integrating key points in data synthesis and applying stringent quality control protocols to both questions and answers."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Prompts",
            "text": ""
        },
        {
            "section_id": "Appendix 2",
            "parent_section_id": null,
            "section_name": "Appendix B Mathematic Topic Details",
            "text": "###figure_6### ###figure_7###"
        },
        {
            "section_id": "Appendix 3",
            "parent_section_id": null,
            "section_name": "Appendix C QA Examples",
            "text": ""
        },
        {
            "section_id": "Appendix 4",
            "parent_section_id": null,
            "section_name": "Appendix D Data Contamination Test",
            "text": "To mitigate the risk of data contamination in our evaluation benchmark, we adhere to the methodology presented by Azerbayev et al. (2023  ###reference_b6###) for cross-examining -gram overlaps between our synthetic dataset and the test sets of Math and GSM8K. A hit is recorded if any -gram in the test sequence appears within any training set. Given the shorter length of questions, we implement a 20-gram check for questions and a 30-gram check for solutions. For GSM8K, our analysis identifies no hits. For Math, our analysis identifies 102 hits for KPMath questions and 108 hits for KPMath solutions, fewer than the 181 and 144 hits found in the MATH training set\u2019s problems and solutions, respectively. Notably, KPMath accounts for 9 unique problem hits, and 16 solution hits absent in the MATH train set, with details provided in Appendix D  ###reference_###. Moreover, we conducted a manual review of all hits. We determined that they were instances of repeated problem contexts or intermediate reasoning steps rather than exact duplicates of questions or solutions. This examination indicates a very low risk of data contamination for KPMath."
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T1\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Results on six mathematical reasoning tasks. The results of our model are bolded.\nZS: Zero-shot inference without demonstrations. Vanilla models are tested with CoT.\n</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T1.1\" style=\"width:433.6pt;height:624.6pt;vertical-align:-0.9pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-27.2pt,39.2pt) scale(0.88844366571379,0.88844366571379) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T1.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T1.1.1.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.1.1\">Model</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"S4.T1.1.1.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.2.1\">Base</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.1.1.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.3.1\">Size</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T1.1.1.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.4.1\">ZS</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.1.1.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.5.1\">GSM8k</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.1.1.1.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.6.1\">MATH</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.1.1.1.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.7.1\">SVAMP</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.1.1.1.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.8.1\">TabMWP</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.1.1.1.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.9.1\">ASDiv</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T1.1.1.1.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.10.1\">MAWPS</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.1.1.1.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.11.1\">AVG</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"11\" id=\"S4.T1.1.1.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Proprietary Models</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.1.3.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">GPT-4 (0613)</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.1.1.3.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.3.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.3.4.1\" style=\"color:#C80000;\">\u2717</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">92.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">42.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">93.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">67.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">91.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.3.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">97.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">80.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.4.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">ChatGPT</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.4.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.4.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.4.4.1\" style=\"color:#C80000;\">\u2717</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">80.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">35.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">83.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">69.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">87.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.4.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">94.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">75.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.5.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Claude-2</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.5.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.5.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.5.4.1\" style=\"color:#C80000;\">\u2717</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">85.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">32.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.5.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.6.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">PaLM-2</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.6.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.6.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">540B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.6.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.6.4.1\" style=\"color:#C80000;\">\u2717</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.6.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">80.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.6.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">34.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.6.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.6.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.6.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.6.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.6.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"11\" id=\"S4.T1.1.1.7.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Open-Source Models</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.1.8.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.1.1.8.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.8.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.8.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.8.4.1\" style=\"color:#C80000;\">\u2717</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.8.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">13.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.8.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">4.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.8.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">38.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.8.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">31.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.8.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">50.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.8.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">60.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.8.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">33.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.9\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.9.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2 SFT</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.9.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.9.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.9.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.9.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.9.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">41.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.9.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.9.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">31.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.9.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">27.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.9.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">47.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.9.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">60.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.9.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">35.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.10\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.10.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Platypus-2</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.10.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.10.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.10.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.10.4.1\" style=\"color:#C80000;\">\u2717</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.10.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">14.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.10.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">5.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.10.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">36.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.10.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">26.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.10.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">47.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.10.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">58.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.10.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">31.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.11\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.11.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MAmmoTH</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.11.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.11.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.11.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.11.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.11.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">45.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.11.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.11.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">48.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.11.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">28.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.11.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">62.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.11.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">74.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.11.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">44.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.12\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.12.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">WizardMath</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.12.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.12.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.12.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.12.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.12.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">54.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.12.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">10.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.12.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">57.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.12.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">38.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.12.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">59.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.12.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">73.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.12.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">49.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.13\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.13.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MetaMath</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.13.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.13.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.13.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.13.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.13.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">66.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.13.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">20.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.13.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">68.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.13.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">43.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.13.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">72.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.13.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">86.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.13.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">59.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.14\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.14.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Mistral</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.14.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.14.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.14.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.14.4.1\" style=\"color:#C80000;\">\u2717</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.14.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">42.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.14.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">12.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.14.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">65.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.14.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">55.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.14.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">68.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.14.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">86.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.14.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">55.3</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.15\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.15.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MAmmoTH</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.15.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Mistral</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.15.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.15.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.15.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.15.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">52.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.15.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">14.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.15.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">54.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.15.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">49.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.15.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">64.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.15.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">77.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.15.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">52.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.16\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.16.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MMIQC</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.16.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Mistral</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.16.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.16.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.16.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.16.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">74.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.16.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">36.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.16.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">73.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.16.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">62.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.16.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">81.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.16.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">90.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.16.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">69.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.17\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.17.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MetaMath</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.17.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Mistral</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.17.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.17.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.17.4.1\" style=\"color:#C80000;\">\u2717</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.17.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">77.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.17.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">29.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.17.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">78.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.17.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">64.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.17.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">81.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.17.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">93.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.17.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">70.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.18\" style=\"background-color:#E6E6E6;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.18.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.18.1.1\" style=\"background-color:#E6E6E6;\">KPMath-Plus</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.18.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.18.2.1\" style=\"background-color:#E6E6E6;\">Mistral</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.18.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.18.3.1\" style=\"background-color:#E6E6E6;\">7B</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.18.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.18.4.1\" style=\"color:#326400;background-color:#E6E6E6;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.18.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.18.5.1\" style=\"background-color:#E6E6E6;\">82.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.18.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.18.6.1\" style=\"background-color:#E6E6E6;\">46.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.18.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.18.7.1\" style=\"background-color:#E6E6E6;\">76.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.18.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.18.8.1\" style=\"background-color:#E6E6E6;\">66.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.18.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.18.9.1\" style=\"background-color:#E6E6E6;\">86.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.18.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.18.10.1\" style=\"background-color:#E6E6E6;\">94.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.18.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.18.11.1\" style=\"background-color:#E6E6E6;\">75.4\u00a0(+20.1)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.19\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.19.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">DeepSeekMath</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.19.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.19.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.19.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.19.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.19.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">63.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.19.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">32.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.19.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">73.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.19.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">68.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.19.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">82.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.19.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">92.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.19.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">68.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.20\" style=\"background-color:#E6E6E6;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.20.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.20.1.1\" style=\"background-color:#E6E6E6;\">KPMath-Plus</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.20.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.20.2.1\" style=\"background-color:#E6E6E6;\">DSMath</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.20.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.20.3.1\" style=\"background-color:#E6E6E6;\">7B</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.20.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.20.4.1\" style=\"color:#326400;background-color:#E6E6E6;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.20.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.20.5.1\" style=\"background-color:#E6E6E6;\">83.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.20.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.20.6.1\" style=\"background-color:#E6E6E6;\">48.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.20.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.20.7.1\" style=\"background-color:#E6E6E6;\">81.5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.20.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.20.8.1\" style=\"background-color:#E6E6E6;\">78.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.20.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.20.9.1\" style=\"background-color:#E6E6E6;\">88.9</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.20.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.20.10.1\" style=\"background-color:#E6E6E6;\">94.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.20.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.20.11.1\" style=\"background-color:#E6E6E6;\">79.4\u00a0(+10.6)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.21\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.1.21.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.1.1.21.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.21.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">13B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.21.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.21.4.1\" style=\"color:#C80000;\">\u2717</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.21.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">24.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.21.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">6.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.21.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">43.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.21.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">39.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.21.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">56.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.21.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">70.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.21.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">36.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.22\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.22.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2 SFT</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.22.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.22.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">13B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.22.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.22.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.22.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">51.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.22.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">9.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.22.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">46.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.22.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">35.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.22.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">58.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.22.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">75.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.22.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">42.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.23\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.23.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Platypus-2</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.23.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.23.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">13B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.23.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.23.4.1\" style=\"color:#C80000;\">\u2717</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.23.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">23.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.23.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.23.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">50.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.23.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">45.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.23.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">55.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.23.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">69.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.23.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">38.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.24\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.24.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MAmmoTH</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.24.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.24.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">13B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.24.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.24.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.24.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">49.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.24.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">9.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.24.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">49.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.24.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">40.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.24.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">60.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.24.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">73.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.24.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">47.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.25\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.25.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">WizardMath</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.25.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.25.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">13B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.25.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.25.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.25.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">63.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.25.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">14.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.25.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">64.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.25.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">46.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.25.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">65.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.25.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">79.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.25.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">51.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.26\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.26.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MetaMath</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.26.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.26.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">13B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.26.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.26.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.26.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">71.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.26.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">23.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.26.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">71.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.26.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">52.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.26.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">75.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.26.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">87.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.26.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">63.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.27\" style=\"background-color:#E6E6E6;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.27.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.27.1.1\" style=\"background-color:#E6E6E6;\">KPMath-Plus</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.27.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.27.2.1\" style=\"background-color:#E6E6E6;\">Llama-2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.27.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.27.3.1\" style=\"background-color:#E6E6E6;\">13B</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.27.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.27.4.1\" style=\"color:#326400;background-color:#E6E6E6;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.27.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.27.5.1\" style=\"background-color:#E6E6E6;\">81.6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.27.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.27.6.1\" style=\"background-color:#E6E6E6;\">41.0</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.27.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.27.7.1\" style=\"background-color:#E6E6E6;\">76.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.27.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.27.8.1\" style=\"background-color:#E6E6E6;\">63.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.27.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.27.9.1\" style=\"background-color:#E6E6E6;\">83.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.27.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.27.10.1\" style=\"background-color:#E6E6E6;\">92.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.27.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.27.11.1\" style=\"background-color:#E6E6E6;\">73.1\u00a0(+36.9)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.28\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.1.28.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llemma</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.1.1.28.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.28.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">34B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.28.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.28.4.1\" style=\"color:#C80000;\">\u2717</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.28.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">55.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.28.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">24.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.28.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">68.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.28.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">57.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.28.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">75.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.28.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">90.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.28.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">61.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.29\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.29.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MMIQC</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.29.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llemma</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.29.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">34B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.29.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.29.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.29.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">79.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.29.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">38.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.29.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">80.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.29.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">70.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.29.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">85.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.29.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">94.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.29.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">74.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.30\" style=\"background-color:#E6E6E6;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.30.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.30.1.1\" style=\"background-color:#E6E6E6;\">KPMath-Plus</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.30.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.30.2.1\" style=\"background-color:#E6E6E6;\">Llemma</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.30.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.30.3.1\" style=\"background-color:#E6E6E6;\">34B</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.30.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.30.4.1\" style=\"color:#326400;background-color:#E6E6E6;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.30.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.30.5.1\" style=\"background-color:#E6E6E6;\">82.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.30.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.30.6.1\" style=\"background-color:#E6E6E6;\">48.6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.30.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.30.7.1\" style=\"background-color:#E6E6E6;\">81.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.30.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.30.8.1\" style=\"background-color:#E6E6E6;\">71.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.30.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.30.9.1\" style=\"background-color:#E6E6E6;\">87.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.30.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.30.10.1\" style=\"background-color:#E6E6E6;\">94.5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.30.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.30.11.1\" style=\"background-color:#E6E6E6;\">77.7\u00a0(+15.8)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.31\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.1.31.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.1.1.31.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.31.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.31.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.31.4.1\" style=\"color:#C80000;\">\u2717</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.31.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">57.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.31.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">14.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.31.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">73.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.31.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">57.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.31.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">76.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.31.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">92.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.31.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">58.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.32\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.32.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2 SFT</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.32.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.32.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.32.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.32.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.32.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">69.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.32.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">14.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.32.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">64.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.32.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">53.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.32.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">71.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.32.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">84.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.32.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">56.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.33\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.33.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Platypus-2</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.33.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.33.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.33.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.33.4.1\" style=\"color:#C80000;\">\u2717</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.33.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">45.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.33.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">15.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.33.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">74.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.33.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">47.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.33.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">72.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.33.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">91.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.33.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">53.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.34\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.34.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">WizardMath</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.34.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.34.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.34.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.34.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.34.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">81.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.34.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">22.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.34.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">80.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.34.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">49.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.34.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">76.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.34.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">86.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.34.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">63.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.35\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.35.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MetaMath</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.35.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.35.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.35.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.35.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.35.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">82.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.35.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">27.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.35.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">85.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.35.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">63.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.35.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">84.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.35.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">95.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.35.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">73.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.36\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.36.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MAmmoTH</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.36.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Llama-2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.36.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.36.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.36.4.1\" style=\"color:#326400;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.36.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">65.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.36.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">14.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.36.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">60.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.36.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">38.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.36.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">70.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.36.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">80.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.36.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">54.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.37\" style=\"background-color:#E6E6E6;\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.37.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.37.1.1\" style=\"background-color:#E6E6E6;\">KPMath-Plus</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.37.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.37.2.1\" style=\"background-color:#E6E6E6;\">Llama-2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.37.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.37.3.1\" style=\"background-color:#E6E6E6;\">70B</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.37.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.37.4.1\" style=\"color:#326400;background-color:#E6E6E6;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.37.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.37.5.1\" style=\"background-color:#E6E6E6;\">87.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.37.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.37.6.1\" style=\"background-color:#E6E6E6;\">48.6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.37.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.37.7.1\" style=\"background-color:#E6E6E6;\">81.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.37.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.37.8.1\" style=\"background-color:#E6E6E6;\">75.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.37.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.37.9.1\" style=\"background-color:#E6E6E6;\">89.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.37.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.37.10.1\" style=\"background-color:#E6E6E6;\">95.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.37.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.37.11.1\" style=\"background-color:#E6E6E6;\">79.4\u00a0(+21.2)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.38\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.38.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Qwen1.5</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.1.38.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">-</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.38.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">72B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.38.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.38.4.1\" style=\"color:#C80000;\">\u2717</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.38.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">77.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.38.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">38.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.38.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">82.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.38.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">52.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.38.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">85.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.1.1.38.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">95.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.38.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">71.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.39\" style=\"background-color:#E6E6E6;\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.1.1.39.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.39.1.1\" style=\"background-color:#E6E6E6;\">KPMath-Plus</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T1.1.1.39.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.39.2.1\" style=\"background-color:#E6E6E6;\">Qwen1.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.1.39.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.39.3.1\" style=\"background-color:#E6E6E6;\">72B</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S4.T1.1.1.39.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.1.1.39.4.1\" style=\"color:#326400;background-color:#E6E6E6;\">\u2713</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.1.39.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.39.5.1\" style=\"background-color:#E6E6E6;\">87.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.1.39.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.39.6.1\" style=\"background-color:#E6E6E6;\">58.3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.1.39.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.39.7.1\" style=\"background-color:#E6E6E6;\">82.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.1.39.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.39.8.1\" style=\"background-color:#E6E6E6;\">76.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.1.39.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.39.9.1\" style=\"background-color:#E6E6E6;\">89.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S4.T1.1.1.39.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.39.10.1\" style=\"background-color:#E6E6E6;\">95.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.1.39.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.39.11.1\" style=\"background-color:#E6E6E6;\">81.5\u00a0(+9.6)</span></td>\n</tr>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 1: Results on six mathematical reasoning tasks. The results of our model are bolded.\nZS: Zero-shot inference without demonstrations. Vanilla models are tested with CoT.\n"
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T2\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Performance comparison of different data components (%).</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T2.1\" style=\"width:433.6pt;height:72pt;vertical-align:-0.8pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-57.2pt,9.4pt) scale(0.791189704843909,0.791189704843909) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T2.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T2.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.1.1\">Data</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.2.1\">GSM8K</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.3.1\">MATH</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.4.1\">SVAMP</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.5.1\">TabMWP</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.1.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.6.1\">ASDiv</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.1.1.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.7.1\">MAWPS</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.1.1.1.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.8.1\">AVG</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T2.1.1.2.1\">MixMath</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.2.2\">75.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.2.3\">43.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.2.4\">73.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.2.5\">63.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.2.6\">82.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.2.7\">89.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.2.8\">71.3</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.1.1.3.1\">MixMath + KPMath-G</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.3.2\">80.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.3.3\">43.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.3.4\">76.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.3.5\">60.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.3.6\">85.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.3.7\">93.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.3.8\">73.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.1.1.4.1\">MixMath + KPMath-M</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.4.2\">77.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.4.3\">45.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.4.4\">74.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.4.5\">65.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.4.6\">84.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.4.7\">92.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.4.8\">73.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S4.T2.1.1.5.1\">KPMath-Plus</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.1.1.5.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.5.2.1\">82.1</span>\u00a0(+6.4)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.1.1.5.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.5.3.1\">46.8</span>\u00a0(+3.5)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.1.1.5.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.5.4.1\">76.4</span>\u00a0(+2.8)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.1.1.5.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.5.5.1\">66.4</span>\u00a0(+3.3)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.1.1.5.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.5.6.1\">86.7</span>\u00a0(+3.8)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.1.1.5.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.5.7.1\">94.2</span>\u00a0(+5.1)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.1.1.5.8\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.5.8.1\">75.4</span>\u00a0(+4.1)</td>\n</tr>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 2: Performance comparison of different data components (%)."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"A2.T3\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Topics in MATH.</figcaption>\n<br class=\"ltx_break\"/>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"A2.T3.1\" style=\"width:397.5pt;height:371.7pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-186.2pt,174.2pt) scale(0.51623203614563,0.51623203614563) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A2.T3.1.1\">\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.1\">\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"A2.T3.1.1.1.1\">1</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A2.T3.1.1.1.2\">Calculus - Functions and their Properties</td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"A2.T3.1.1.1.3\">2</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A2.T3.1.1.1.4\">Calculus - Optimization</td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"A2.T3.1.1.1.5\">3</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A2.T3.1.1.1.6\">Calculus - Limits</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.2\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.2.1\">4</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.2.2\">Algebra - Solving Equations</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.2.3\">5</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.2.4\">Algebra - Polynomials</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.2.5\">6</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.2.6\">Algebra - Inequalities</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.3\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.3.1\">7</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.3.2\">Algebra - Functions</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.3.3\">8</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.3.4\">Algebra - Simplifying Expressions</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.3.5\">9</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.3.6\">Algebra - Linear Equations</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.4\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.4.1\">10</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.4.2\">Algebra - Quadratic Equations</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.4.3\">11</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.4.4\">Algebra - Square Roots</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.4.5\">12</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.4.6\">Algebra - Radicals</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.5\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.5.1\">13</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.5.2\">Algebra - Sequences and Series</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.5.3\">14</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.5.4\">Algebra - Linear Functions</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.5.5\">15</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.5.6\">Algebra - Complex Numbers</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.6\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.6.1\">16</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.6.2\">Algebra - Function Operations</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.6.3\">17</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.6.4\">Algebra - Exponents</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.6.5\">18</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.6.6\">Algebra - Rational Functions</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.7\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.7.1\">19</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.7.2\">Algebra - Function Transformations</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.7.3\">20</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.7.4\">Algebra - Proportions</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.7.5\">21</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.7.6\">Algebra - Proportional Relationships</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.8\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.8.1\">22</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.8.2\">Algebra - Logarithms</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.8.3\">23</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.8.4\">Algebra - Substitution</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.8.5\">24</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.8.6\">Algebra - Exponential Growth</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.9\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.9.1\">25</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.9.2\">Algebra - Summation</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.9.3\">26</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.9.4\">Algebra - Absolute Value</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.9.5\">27</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.9.6\">Algebra - Variables and Expressions</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.10\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.10.1\">28</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.10.2\">Algebra - Ratios and Proportions</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.10.3\">29</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.10.4\">Algebra - Geometric Series</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.10.5\">30</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.10.6\">Algebra - Interval Notation</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.11\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.11.1\">31</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.11.2\">Algebra - Polynomial Expansion</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.11.3\">32</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.11.4\">Algebra - Real Numbers</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.11.5\">33</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.11.6\">Others - Problem Context</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.12\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.12.1\">34</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.12.2\">Others - Graph Interpretation</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.12.3\">35</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.12.4\">Others - Problem Solving</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.12.5\">36</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.12.6\">Arithmetic - Order of Operations</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.13\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.13.1\">37</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.13.2\">Arithmetic - Time Calculations</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.13.3\">38</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.13.4\">Arithmetic - Division</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.13.5\">39</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.13.6\">Arithmetic - Basic Operations</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.14\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.14.1\">40</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.14.2\">Arithmetic - Fractions</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.14.3\">41</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.14.4\">Arithmetic - Multiplication</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.14.5\">42</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.14.6\">Arithmetic - Percentages</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.15\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.15.1\">43</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.15.2\">Arithmetic - Addition</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.15.3\">44</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.15.4\">Arithmetic - Averages</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.15.5\">45</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.15.6\">Arithmetic - Rate Problems</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.16\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.16.1\">46</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.16.2\">Arithmetic - Unit Conversion</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.16.3\">47</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.16.4\">Arithmetic - Rounding Numbers</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.16.5\">48</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.16.6\">Number Theory - Fractions and Decimals</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.17\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.17.1\">49</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.17.2\">Number Theory - Integer Properties</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.17.3\">50</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.17.4\">Number Theory - Powers and Roots</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.17.5\">51</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.17.6\">Number Theory - Floor Function</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.18\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.18.1\">52</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.18.2\">Number Theory - Floor and Ceiling Functions</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.18.3\">53</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.18.4\">Number Theory - Perfect Squares</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.18.5\">54</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.18.6\">Number Theory - Divisibility</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.19\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.19.1\">55</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.19.2\">Number Theory - Factors and Multiples</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.19.3\">56</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.19.4\">Number Theory - Prime Numbers</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.19.5\">57</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.19.6\">Number Theory - Multiples</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.20\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.20.1\">58</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.20.2\">Number Theory - Odd and Even Numbers</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.20.3\">59</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.20.4\">Number Theory - Digit Sums</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.20.5\">60</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.20.6\">Number Theory - Modulo Arithmetic</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.21\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.21.1\">61</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.21.2\">Number Theory - Properties of Integers</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.21.3\">62</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.21.4\">Number Theory - Units Digit</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.21.5\">63</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.21.6\">Number Theory - Greatest Common Divisor (GCD)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.22\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.22.1\">64</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.22.2\">Number Theory - Perfect Squares and Cubes</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.22.3\">65</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.22.4\">Number Theory - Counting Digits</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.22.5\">66</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.22.6\">Number Theory - Modular Arithmetic</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.23\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.23.1\">67</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.23.2\">Number Theory - Division and Remainders</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.23.3\">68</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.23.4\">Number Theory - Powers and Exponents</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.23.5\">69</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.23.6\">Geometry - Circles</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.24\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.24.1\">70</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.24.2\">Geometry - Coordinate Geometry</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.24.3\">71</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.24.4\">Geometry - Distance Formula</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.24.5\">72</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.24.6\">Geometry - Polygons</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.25\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.25.1\">73</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.25.2\">Geometry - Midpoint Formula</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.25.3\">74</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.25.4\">Geometry - Reflections</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.25.5\">75</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.25.6\">Geometry - Area Calculation</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.26\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.26.1\">76</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.26.2\">Geometry - Lines and Angles</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.26.3\">77</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.26.4\">Geometry - Perimeter</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.26.5\">78</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.26.6\">Geometry - Parabolas</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.27\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.27.1\">79</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.27.2\">Geometry - Area of a Circle</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.27.3\">80</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.27.4\">Geometry - Rectangles</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.27.5\">81</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.27.6\">Geometry - Triangles</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.28\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.28.1\">82</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.28.2\">Geometry - Transformations</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.28.3\">83</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.28.4\">Geometry - Squares</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.28.5\">84</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.28.6\">Geometry - 3D Shapes</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.29\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.29.1\">85</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.29.2\">Geometry - Angles</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.29.3\">86</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.29.4\">Geometry - Volume of Solids</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.29.5\">87</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.29.6\">Geometry - Pyramids</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.30\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.30.1\">88</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.30.2\">Geometry - Similar Triangles</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.30.3\">89</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.30.4\">Geometry - Cones</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.30.5\">90</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.30.6\">Geometry - Parallelograms</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.31\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.31.1\">91</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.31.2\">Geometry - Conic Sections</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.31.3\">92</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.31.4\">Geometry - Ellipse</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.31.5\">93</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.31.6\">Geometry - Coordinate Systems</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.32\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.32.1\">94</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.32.2\">Geometry - Planes in Three Dimensions</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.32.3\">95</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.32.4\">Financial Mathematics - Compound Interest</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.32.5\">96</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.32.6\">Sequences and Series - Infinite Series</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.33\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.33.1\">97</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.33.2\">Complex Numbers - Absolute Value</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.33.3\">98</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.33.4\">Combinatorics - Counting Problems</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.33.5\">99</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.33.6\">Combinatorics - Factorials</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.34\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.34.1\">100</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.34.2\">Combinatorics - Binomial Coefficients</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.34.3\">101</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.34.4\">Combinatorics - Pascal\u2019s Triangle</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.34.5\">102</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.34.6\">Measurement - Unit Conversion</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.35\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.35.1\">103</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.35.2\">Statistics - Mean</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.35.3\">104</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.35.4\">Statistics - Mean and Median</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.35.5\">105</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.35.6\">Probability - Basic Concepts</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.36\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.36.1\">106</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.36.2\">Probability - Expected Value</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.36.3\">107</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.36.4\">Probability - Geometric Probability</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.36.5\">108</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.36.6\">Data Interpretation - Bar Graphs</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.37\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.37.1\">109</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.37.2\">Trigonometry - Tangent Function</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.37.3\">110</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.37.4\">Trigonometry - Sine and Cosine Functions</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.37.5\">111</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.37.6\">Trigonometry - Polar Coordinates</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.38\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.38.1\">112</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.38.2\">Set Theory - Overlapping Sets</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.38.3\">113</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.38.4\">Number Systems - Base Conversion</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.38.5\">114</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.38.6\">Number Systems - Binary Numbers</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.39\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.39.1\">115</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.39.2\">Linear Algebra - Matrices</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.39.3\">116</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.39.4\">Linear Algebra - Vectors</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T3.1.1.39.5\">117</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T3.1.1.39.6\">Linear Algebra - Determinants</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T3.1.1.40\">\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"A2.T3.1.1.40.1\">118</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T3.1.1.40.2\">Linear Algebra - Vectors and Parametric Equations</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"A2.T3.1.1.40.3\">119</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T3.1.1.40.4\">Vector Algebra - Dot Product</td>\n<td class=\"ltx_td ltx_border_bb\" id=\"A2.T3.1.1.40.5\"></td>\n<td class=\"ltx_td ltx_border_bb\" id=\"A2.T3.1.1.40.6\"></td>\n</tr>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 3: Topics in MATH."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"A2.T4\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Topics in GSM.</figcaption>\n<br class=\"ltx_break\"/>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"A2.T4.1\" style=\"width:397.5pt;height:130.6pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-130.0pt,42.7pt) scale(0.604462102811465,0.604462102811465) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A2.T4.1.1\">\n<tr class=\"ltx_tr\" id=\"A2.T4.1.1.1\">\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"A2.T4.1.1.1.1\">1</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A2.T4.1.1.1.2\">Arithmetic - Basic Operations</td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"A2.T4.1.1.1.3\">2</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A2.T4.1.1.1.4\">Others - Problem Context</td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" id=\"A2.T4.1.1.1.5\">3</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A2.T4.1.1.1.6\">Arithmetic - Multiplication and Division</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.1.2\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.2.1\">4</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.2.2\">Arithmetic - Multiplication and Addition</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.2.3\">5</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.2.4\">Algebra - Word Problems</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.2.5\">6</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.2.6\">Word Problems - Problem Solving</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.1.3\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.3.1\">7</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.3.2\">Arithmetic - Division</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.3.3\">8</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.3.4\">Arithmetic - Addition and Subtraction</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.3.5\">9</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.3.6\">Arithmetic - Percentages</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.1.4\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.4.1\">10</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.4.2\">Arithmetic - Fractions</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.4.3\">11</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.4.4\">Proportional Reasoning</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.4.5\">12</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.4.6\">Arithmetic - Time Calculations</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.1.5\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.5.1\">13</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.5.2\">Arithmetic - Averages</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.5.3\">14</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.5.4\">Geometry - Volume Calculation</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.5.5\">15</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.5.6\">Measurement - Length</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.1.6\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.6.1\">16</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.6.2\">Arithmetic - Sequences and Series</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.6.3\">17</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.6.4\">Geometry - Rectangles</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.6.5\">18</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.6.6\">Arithmetic - Comparison</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.1.7\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.7.1\">19</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.7.2\">Set Theory - Overlapping Sets</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.7.3\">20</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.7.4\">Arithmetic - Rate Problems</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.7.5\">21</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.7.6\">Arithmetic - Unit Conversion</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.1.8\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.8.1\">22</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.8.2\">Arithmetic - Money</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.8.3\">23</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.8.4\">Geometry - Triangles</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.8.5\">24</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.8.6\">Problem Solving - Multi-step Problems</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.1.9\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.9.1\">25</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.9.2\">Probability</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.9.3\">26</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.9.4\">Geometry - Area Calculation</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.9.5\">27</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.9.6\">Arithmetic - Age Problems</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.1.10\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.10.1\">28</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.10.2\">Geometry - Perimeter</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.10.3\">29</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.10.4\">Measurement - Volume</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.10.5\">30</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.10.6\">Word Problems - Distance Problems</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.1.11\">\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.11.1\">31</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.11.2\">Measurement - Weight</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.11.3\">32</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.11.4\">Arithmetic - Subtraction and Multiplication</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A2.T4.1.1.11.5\">33</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T4.1.1.11.6\">Algebra - Exponential Growth</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T4.1.1.12\">\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"A2.T4.1.1.12.1\">34</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T4.1.1.12.2\">Fractions - Addition and Subtraction</td>\n<td class=\"ltx_td ltx_border_bb\" id=\"A2.T4.1.1.12.3\"></td>\n<td class=\"ltx_td ltx_border_bb\" id=\"A2.T4.1.1.12.4\"></td>\n<td class=\"ltx_td ltx_border_bb\" id=\"A2.T4.1.1.12.5\"></td>\n<td class=\"ltx_td ltx_border_bb\" id=\"A2.T4.1.1.12.6\"></td>\n</tr>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 4: Topics in GSM."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.02333v3_figure_1.png",
            "caption": "Figure 1: Overview of the Key-Point-Driven Data Synthesis (KPDDS) pipeline, from knowledge extraction to practice synthesis."
        },
        "2": {
            "figure_path": "2403.02333v3_figure_2.png",
            "caption": "Figure 4: Score Distribution of Synthetic Questions"
        },
        "3": {
            "figure_path": "2403.02333v3_figure_3.png",
            "caption": "Figure 5: Hungarian Exam Score vs GSM8K Performance of Various Models."
        },
        "4": {
            "figure_path": "2403.02333v3_figure_4.png",
            "caption": "Figure 6: Performance of KPMath-Plus-Mistral-7B across various training data size."
        },
        "5": {
            "figure_path": "2403.02333v3_figure_5.png",
            "caption": "Figure 7: Training Results with Different Voting Strategies (average performance on six mathematical dataset)."
        },
        "6": {
            "figure_path": "2403.02333v3_figure_6.png",
            "caption": "Figure 10: Visualized heat map of co-occurrence probability matrix."
        },
        "7": {
            "figure_path": "2403.02333v3_figure_7.png",
            "caption": "Figure 11: Visualized heat map of co-occurrence probability matrix."
        }
    },
    "references": [
        {
            "1": {
                "title": "Au large: Mistral large is our flagship model, with top-tier reasoning capacities, February 2024.",
                "author": "Mistral AI.",
                "venue": "URL https://mistral.ai/news/mistral-large/.",
                "url": null
            }
        },
        {
            "2": {
                "title": "Learning from mistakes makes llm better reasoner.",
                "author": "Shengnan An, Zexiong Ma, Zeqi Lin, Nanning Zheng, Jian-Guang Lou, and Weizhu Chen.",
                "venue": "arXiv preprint arXiv:2310.20689, 2023.",
                "url": null
            }
        },
        {
            "3": {
                "title": "Palm 2 technical report.",
                "author": "Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al.",
                "venue": "arXiv preprint arXiv:2305.10403, 2023.",
                "url": null
            }
        },
        {
            "4": {
                "title": "Model card and evaluations for claude models.",
                "author": "Anthropic.",
                "venue": "2023.",
                "url": null
            }
        },
        {
            "5": {
                "title": "https://huggingface.co/datasets/hoskinson-center/proof-pile, 2022.",
                "author": "Zhangir Azerbayev, Edward Ayers, and Bartosz Piotrowski.",
                "venue": "URL https://huggingface.co/datasets/hoskinson-center/proof-pile.",
                "url": null
            }
        },
        {
            "6": {
                "title": "Llemma: An open language model for mathematics.",
                "author": "Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco Dos Santos, Stephen McAleer, Albert Q Jiang, Jia Deng, Stella Biderman, and Sean Welleck.",
                "venue": "arXiv preprint arXiv:2310.10631, 2023.",
                "url": null
            }
        },
        {
            "7": {
                "title": "Qwen technical report.",
                "author": "Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al.",
                "venue": "arXiv preprint arXiv:2309.16609, 2023.",
                "url": null
            }
        },
        {
            "8": {
                "title": "Deepseek llm: Scaling open-source language models with longtermism.",
                "author": "Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu, et al.",
                "venue": "arXiv preprint arXiv:2401.02954, 2024.",
                "url": null
            }
        },
        {
            "9": {
                "title": "Sparks of artificial general intelligence: Early experiments with gpt-4.",
                "author": "S\u00e9bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al.",
                "venue": "arXiv preprint arXiv:2303.12712, 2023.",
                "url": null
            }
        },
        {
            "10": {
                "title": "Using left and right brains together: Towards vision and language planning.",
                "author": "Jun Cen, Chenfei Wu, Xiao Liu, Shengming Yin, Yixuan Pei, Jinglong Yang, Qifeng Chen, Nan Duan, and Jianguo Zhang.",
                "venue": "arXiv preprint arXiv:2402.10534, 2024.",
                "url": null
            }
        },
        {
            "11": {
                "title": "Skills-in-context prompting: Unlocking compositionality in large language models.",
                "author": "Jiaao Chen, Xiaoman Pan, Dian Yu, Kaiqiang Song, Xiaoyang Wang, Dong Yu, and Jianshu Chen.",
                "venue": "arXiv preprint arXiv:2308.00304, 2023.",
                "url": null
            }
        },
        {
            "12": {
                "title": "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks.",
                "author": "Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen.",
                "venue": "arXiv preprint arXiv:2211.12588, 2022.",
                "url": null
            }
        },
        {
            "13": {
                "title": "Contrastive chain-of-thought prompting.",
                "author": "Yew Ken Chia, Guizhen Chen, Luu Anh Tuan, Soujanya Poria, and Lidong Bing.",
                "venue": "arXiv preprint arXiv:2311.09277, 2023.",
                "url": null
            }
        },
        {
            "14": {
                "title": "Training verifiers to solve math word problems.",
                "author": "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman.",
                "venue": "arXiv preprint arXiv:2110.14168, 2021a.",
                "url": null
            }
        },
        {
            "15": {
                "title": "Training verifiers to solve math word problems.",
                "author": "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al.",
                "venue": "arXiv preprint arXiv:2110.14168, 2021b.",
                "url": null
            }
        },
        {
            "16": {
                "title": "Flashattention-2: Faster attention with better parallelism and work partitioning.",
                "author": "Tri Dao.",
                "venue": "arXiv preprint arXiv:2307.08691, 2023.",
                "url": null
            }
        },
        {
            "17": {
                "title": "What makes for good visual instructions? synthesizing complex visual reasoning instructions for visual instruction tuning.",
                "author": "Yifan Du, Hangyu Guo, Kun Zhou, Wayne Xin Zhao, Jinpeng Wang, Chuyuan Wang, Mingchen Cai, Ruihua Song, and Ji-Rong Wen.",
                "venue": "arXiv preprint arXiv:2311.01487, 2023.",
                "url": null
            }
        },
        {
            "18": {
                "title": "Pal: Program-aided language models.",
                "author": "Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig.",
                "venue": "arXiv preprint arXiv:2211.10435, 2022.",
                "url": null
            }
        },
        {
            "19": {
                "title": "CRITIC: Large language models can self-correct with tool-interactive critiquing.",
                "author": "Zhibin Gou, Zhihong Shao, Yeyun Gong, yelong shen, Yujiu Yang, Nan Duan, and Weizhu Chen.",
                "venue": "In The Twelfth International Conference on Learning Representations, 2024a.",
                "url": null
            }
        },
        {
            "20": {
                "title": "ToRA: A tool-integrated reasoning agent for mathematical problem solving.",
                "author": "Zhibin Gou, Zhihong Shao, Yeyun Gong, yelong shen, Yujiu Yang, Minlie Huang, Nan Duan, and Weizhu Chen.",
                "venue": "In The Twelfth International Conference on Learning Representations, 2024b.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Textbooks are all you need.",
                "author": "Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio C\u00e9sar Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, et al.",
                "venue": "arXiv preprint arXiv:2306.11644, 2023.",
                "url": null
            }
        },
        {
            "22": {
                "title": "Measuring mathematical problem solving with the math dataset.",
                "author": "Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt.",
                "venue": "arXiv preprint arXiv:2103.03874, 2021a.",
                "url": null
            }
        },
        {
            "23": {
                "title": "Measuring mathematical problem solving with the math dataset.",
                "author": "Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt.",
                "venue": "NeurIPS, 2021b.",
                "url": null
            }
        },
        {
            "24": {
                "title": "Competition-level problems are effective llm evaluators.",
                "author": "Yiming Huang, Zhenghao Lin, Xiao Liu, Yeyun Gong, Shuai Lu, Fangyu Lei, Yaobo Liang, Yelong Shen, Chen Lin, Nan Duan, et al.",
                "venue": "arXiv preprint arXiv:2312.02143, 2023.",
                "url": null
            }
        },
        {
            "25": {
                "title": "Mustard: Mastering uniform synthesis of theorem and proof data.",
                "author": "Yinya Huang, Xiaohan Lin, Zhengying Liu, Qingxing Cao, Huajian Xin, Haiming Wang, Zhenguo Li, Linqi Song, and Xiaodan Liang.",
                "venue": "arXiv preprint arXiv:2402.08957, 2024.",
                "url": null
            }
        },
        {
            "26": {
                "title": "Mistral 7b.",
                "author": "Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al.",
                "venue": "arXiv preprint arXiv:2310.06825, 2023.",
                "url": null
            }
        },
        {
            "27": {
                "title": "Mawps: A math word problem repository.",
                "author": "Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi.",
                "venue": "In Proceedings of the 2016 conference of the north american chapter of the association for computational linguistics: human language technologies, pp.  1152\u20131157, 2016.",
                "url": null
            }
        },
        {
            "28": {
                "title": "Platypus: Quick, cheap, and powerful refinement of llms.",
                "author": "Ariel N. Lee, Cole J. Hunter, and Nataniel Ruiz.",
                "venue": "arXiv preprint arxiv:2308.07317, 2023.",
                "url": null
            }
        },
        {
            "29": {
                "title": "S3eval: A synthetic, scalable, systematic evaluation suite for large language models.",
                "author": "Fangyu Lei, Qian Liu, Yiming Huang, Shizhu He, Jun Zhao, and Kang Liu.",
                "venue": "arXiv preprint arXiv:2310.15147, 2023.",
                "url": null
            }
        },
        {
            "30": {
                "title": "Solving quantitative reasoning problems with language models.",
                "author": "Aitor Lewkowycz, Anders Johan Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Venkatesh Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, and Vedant Misra.",
                "venue": "In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022.",
                "url": null
            }
        },
        {
            "31": {
                "title": "Synthetic data (almost) from scratch: Generalized instruction tuning for language models.",
                "author": "Haoran Li, Qingxiu Dong, Zhengyang Tang, Chaojun Wang, Xingxing Zhang, Haoyang Huang, Shaohan Huang, Xiaolong Huang, Zeqiang Huang, Dongdong Zhang, et al.",
                "venue": "arXiv preprint arXiv:2402.13064, 2024.",
                "url": null
            }
        },
        {
            "32": {
                "title": "Augmenting math word problems via iterative question composing.",
                "author": "Haoxiong Liu and Andrew Chi-Chih Yao.",
                "venue": "arXiv preprint arXiv:2401.09003, 2024.",
                "url": null
            }
        },
        {
            "33": {
                "title": "Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning.",
                "author": "Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Tanmay Rajpurohit, Peter Clark, and Ashwin Kalyan.",
                "venue": "arXiv preprint arXiv:2209.14610, 2022.",
                "url": null
            }
        },
        {
            "34": {
                "title": "Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct.",
                "author": "Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang.",
                "venue": "arXiv preprint arXiv:2308.09583, 2023a.",
                "url": null
            }
        },
        {
            "35": {
                "title": "Wizardcoder: Empowering code large language models with evol-instruct.",
                "author": "Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang.",
                "venue": "CoRR, abs/2306.08568, 2023b.",
                "url": null
            }
        },
        {
            "36": {
                "title": "Reft: Reasoning with reinforced fine-tuning.",
                "author": "Trung Quoc Luong, Xinbo Zhang, Zhanming Jie, Peng Sun, Xiaoran Jin, and Hang Li.",
                "venue": "arXiv preprint arXiv:2401.08967, 2024.",
                "url": null
            }
        },
        {
            "37": {
                "title": "Let\u2019s reward step by step: Step-level reward model as the navigators for reasoning.",
                "author": "Qianli Ma, Haotian Zhou, Tingkai Liu, Jianbo Yuan, Pengfei Liu, Yang You, and Hongxia Yang.",
                "venue": "arXiv preprint arXiv:2310.10080, 2023.",
                "url": null
            }
        },
        {
            "38": {
                "title": "Tal-scq5k.",
                "author": "math eval.",
                "venue": "https://github.com/math-eval/TAL-SCQ5K, 2023.",
                "url": null
            }
        },
        {
            "39": {
                "title": "A diverse corpus for evaluating and developing english math word problem solvers.",
                "author": "Shen-Yun Miao, Chao-Chun Liang, and Keh-Yih Su.",
                "venue": "arXiv preprint arXiv:2106.15772, 2021.",
                "url": null
            }
        },
        {
            "40": {
                "title": "Lila: A unified benchmark for mathematical reasoning.",
                "author": "Swaroop Mishra, Matthew Finlayson, Pan Lu, Leonard Tang, Sean Welleck, Chitta Baral, Tanmay Rajpurohit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark, and Ashwin Kalyan.",
                "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2022.",
                "url": null
            }
        },
        {
            "41": {
                "title": "Gpt-4 technical report, 2023.",
                "author": "OpenAI.",
                "venue": null,
                "url": null
            }
        },
        {
            "42": {
                "title": "Testing language models on a held-out high school national finals exam.",
                "author": "Keiran Paster.",
                "venue": "https://huggingface.co/datasets/keirp/hungarian_national_hs_finals_exam, 2023.",
                "url": null
            }
        },
        {
            "43": {
                "title": "Openwebmath: An open dataset of high-quality mathematical web text.",
                "author": "Keiran Paster,",
                "venue": "arXiv preprint, forthcoming, 2023a.",
                "url": null
            }
        },
        {
            "44": {
                "title": "Openwebmath: An open dataset of high-quality mathematical web text.",
                "author": "Keiran Paster, Marco Dos Santos, Zhangir Azerbayev, and Jimmy Ba.",
                "venue": "arXiv preprint arXiv:2310.06786, 2023b.",
                "url": null
            }
        },
        {
            "45": {
                "title": "Are nlp models really able to solve simple math word problems?",
                "author": "Arkil Patel, Satwik Bhattamishra, and Navin Goyal.",
                "venue": "arXiv preprint arXiv:2103.07191, 2021.",
                "url": null
            }
        },
        {
            "46": {
                "title": "Zero-infinity: Breaking the gpu memory wall for extreme scale deep learning.",
                "author": "Samyam Rajbhandari, Olatunji Ruwase, Jeff Rasley, Shaden Smith, and Yuxiong He.",
                "venue": "In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, pp.  1\u201314, 2021.",
                "url": null
            }
        },
        {
            "47": {
                "title": "Synthetic prompting: Generating chain-of-thought demonstrations for large language models.",
                "author": "Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu Chen.",
                "venue": "arXiv preprint arXiv:2302.00618, 2023.",
                "url": null
            }
        },
        {
            "48": {
                "title": "Deepseekmath: Pushing the limits of mathematical reasoning in open language models.",
                "author": "Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Mingchuan Zhang, YK Li, Y Wu, and Daya Guo.",
                "venue": "arXiv preprint arXiv:2402.03300, 2024.",
                "url": null
            }
        },
        {
            "49": {
                "title": "Does synthetic data generation of llms help clinical text mining?",
                "author": "Ruixiang Tang, Xiaotian Han, Xiaoqian Jiang, and Xia Hu.",
                "venue": "arXiv preprint arXiv:2303.04360, 2023.",
                "url": null
            }
        },
        {
            "50": {
                "title": "Galactica: A large language model for science, 2022.",
                "author": "Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic.",
                "venue": null,
                "url": null
            }
        },
        {
            "51": {
                "title": "Gemini: a family of highly capable multimodal models.",
                "author": "Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al.",
                "venue": "arXiv preprint arXiv:2312.11805, 2023.",
                "url": null
            }
        },
        {
            "52": {
                "title": "Internlm: A multilingual language model with progressively enhanced capabilities.",
                "author": "InternLM Team.",
                "venue": "https://github.com/InternLM/InternLM, 2023.",
                "url": null
            }
        },
        {
            "53": {
                "title": "Llama 2: Open foundation and fine-tuned chat models.",
                "author": "Hugo Touvron, Louis Martin, Kevin R. Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Daniel M. Bikel, Lukas Blecher, Cristian Cant\u00f3n Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony S. Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel M. Kloumann, A. V. Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, R. Subramanian, Xia Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zhengxu Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and\nThomas Scialom.",
                "venue": "ArXiv, abs/2307.09288, 2023.",
                "url": null
            }
        },
        {
            "54": {
                "title": "Solving olympiad geometry without human demonstrations.",
                "author": "Trieu H Trinh, Yuhuai Wu, Quoc V Le, He He, and Thang Luong.",
                "venue": "Nature, 625(7995):476\u2013482, 2024.",
                "url": null
            }
        },
        {
            "55": {
                "title": "Math-shepherd: A label-free step-by-step verifier for llms in mathematical reasoning.",
                "author": "Peiyi Wang, Lei Li, Zhihong Shao, RX Xu, Damai Dai, Yifei Li, Deli Chen, Y Wu, and Zhifang Sui.",
                "venue": "arXiv preprint arXiv:2312.08935, 2023a.",
                "url": null
            }
        },
        {
            "56": {
                "title": "Self-instruct: Aligning language model with self generated instructions.",
                "author": "Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi.",
                "venue": "arXiv preprint arXiv:2212.10560, 2022.",
                "url": null
            }
        },
        {
            "57": {
                "title": "Generative ai for math: Part i\u2013mathpile: A billion-token-scale pretraining corpus for math.",
                "author": "Zengzhi Wang, Rui Xia, and Pengfei Liu.",
                "venue": "arXiv preprint arXiv:2312.17120, 2023b.",
                "url": null
            }
        },
        {
            "58": {
                "title": "Chain-of-thought prompting elicits reasoning in large language models.",
                "author": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al.",
                "venue": "Advances in Neural Information Processing Systems, 35:24824\u201324837, 2022.",
                "url": null
            }
        },
        {
            "59": {
                "title": "Magicoder: Source code is all you need.",
                "author": "Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming Zhang.",
                "venue": "arXiv preprint arXiv:2312.02120, 2023.",
                "url": null
            }
        },
        {
            "60": {
                "title": "Grok-1, 2023.",
                "author": "xAI.",
                "venue": "URL https://x.ai/.",
                "url": null
            }
        },
        {
            "61": {
                "title": "Wizardlm: Empowering large language models to follow complex instructions.",
                "author": "Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang.",
                "venue": "arXiv preprint arXiv:2304.12244, 2023.",
                "url": null
            }
        },
        {
            "62": {
                "title": "Outcome-supervised verifiers for planning in mathematical reasoning.",
                "author": "Fei Yu, Anningzhe Gao, and Benyou Wang.",
                "venue": "arXiv preprint arXiv:2311.09724, 2023a.",
                "url": null
            }
        },
        {
            "63": {
                "title": "Metamath: Bootstrap your own mathematical questions for large language models.",
                "author": "Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T. Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu.",
                "venue": "arXiv preprint arXiv:2309.12284, 2023b.",
                "url": null
            }
        },
        {
            "64": {
                "title": "MAmmoTH: Building math generalist models through hybrid instruction tuning.",
                "author": "Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen.",
                "venue": "In The Twelfth International Conference on Learning Representations, 2024.",
                "url": null
            }
        },
        {
            "65": {
                "title": "Evaluating and improving tool-augmented computation-intensive math reasoning.",
                "author": "Beichen Zhang, Kun Zhou, Xilin Wei, Xin Zhao, Jing Sha, Shijin Wang, and Ji-Rong Wen.",
                "venue": "Advances in Neural Information Processing Systems, 36, 2024.",
                "url": null
            }
        },
        {
            "66": {
                "title": "Alpacare: Instruction-tuned large language models for medical application.",
                "author": "Xinlu Zhang, Chenxin Tian, Xianjun Yang, Lichang Chen, Zekun Li, and Linda Ruth Petzold.",
                "venue": "arXiv preprint arXiv:2310.14558, 2023a.",
                "url": null
            }
        },
        {
            "67": {
                "title": "Cumulative reasoning with large language models.",
                "author": "Yifan Zhang, Jingqin Yang, Yang Yuan, and Andrew Chi-Chih Yao.",
                "venue": "arXiv preprint arXiv:2308.04371, 2023b.",
                "url": null
            }
        },
        {
            "68": {
                "title": "Progressive-hint prompting improves reasoning in large language models.",
                "author": "Chuanyang Zheng, Zhengying Liu, Enze Xie, Zhenguo Li, and Yu Li.",
                "venue": "arXiv preprint arXiv:2304.09797, 2023.",
                "url": null
            }
        },
        {
            "69": {
                "title": "Llamafactory: Unified efficient fine-tuning of 100+ language models.",
                "author": "Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo, and Yongqiang Ma.",
                "venue": "arXiv preprint arXiv:2403.13372, 2024.",
                "url": null
            }
        },
        {
            "70": {
                "title": "Solving challenging math word problems using gpt-4 code interpreter with code-based self-verification.",
                "author": "Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song, Mingjie Zhan, et al.",
                "venue": "arXiv preprint arXiv:2308.07921, 2023.",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.02333v3",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2.1",
            "2.2"
        ],
        "methodology_sections": [
            "3.1",
            "3.2",
            "3.3",
            "3.4",
            "3.5"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.3",
            "4.4",
            "4.5"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4.6",
            "4.7"
        ]
    },
    "research_context": {
        "paper_id": "2403.02333v3",
        "paper_title": "Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning",
        "research_background": "### **Motivation:**\nThe paper is motivated by the need to improve the mathematical reasoning capabilities of large language models (LLMs). Although current LLMs like GPT-4, Gemini, and Mistral have shown advanced capabilities across various domains, their reasoning proficiency, particularly in challenging areas such as advanced mathematics, remains limited. Existing mathematical reasoning datasets either contain poor quality and irrelevant data, or are scarce and lack detailed reasoning steps. Therefore, enhancing the quality of mathematical reasoning datasets is essential.\n\n### **Research Problem:**\nThe primary research problem addressed in the paper is the enhancement of mathematical reasoning in LLMs through the creation of high-quality synthetic datasets. The existing strategies for data synthesis\u2014augmenting existing datasets through question rephrasing or generating new questions from established knowledge\u2014suffer from limitations such as uncontrollable variations and misalignment with the dataset\u2019s distribution. Thus, there is a need for a novel data synthesis approach that leverages both strategies while overcoming their disadvantages.\n\n### **Relevant Prior Work:**\n1. **LLMs and their Mathematical Reasoning Capabilities:**\n   - GPT-4 (OpenAI, 2023), Gemini (Team et al., 2023), and Mistral (AI, 2024) are noted for their capabilities but still face scrutiny in mathematical reasoning (Bubeck et al., 2023; Lewkowycz et al., 2022).\n   \n2. **Existing Mathematical Reasoning Corpora:**\n   - OpenWebMath (Paster et al., 2023b) and MathPile (Wang et al., 2023b) are examples of internet-sourced data with poor quality and relevance. High-quality manually annotated datasets like the MATH dataset (Hendrycks et al., 2021b) are scarce and sometimes lack detailed reasoning steps.\n\n3. **Synthetic Data Strategies:**\n   - **Augmentation through Rephrasing:** This involves rephrasing existing questions or generating similar ones (Yu et al., 2023b; Luo et al., 2023a; Liu & Yao, 2024).\n   - **Broadening Training Datasets:** New questions are generated from knowledge bases compiled from resources like Khan Academy (Huang et al., 2024) or synthesized from scratch using models like GPT-4 (Li et al., 2024). These methods, however, might not align with the existing datasets and can be challenging to understand without illustrative examples.\n\nThrough these efforts, the proposed Key-Point-Driven Data Synthesis (KPDDS) paradigm aims to combine the strengths and mitigate the weaknesses of the aforementioned strategies.",
        "methodology": "### Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning\n\n**Methodology**: Our methodology is systematically delineated into two primary phases:\n1. **Knowledge Construction**\n2. **Practice Generation**\n\nEach of these phases consists of two components, leading to a total of four interconnected components in our approach:\n\n1. **Knowledge Construction**\n    - **Knowledge Extraction**: This component involves extracting relevant and crucial information from a given dataset or knowledge base. The goal is to identify key points of information that are essential for constructing meaningful and contextually appropriate content.\n   \n    - **Topic-level Co-occurrence Probability Matrix (TCPM) Construction**: In this phase, a co-occurrence probability matrix is generated at the topic level. This matrix helps in understanding the relationships and co-occurrences of various topics within the dataset. By mapping these relationships, we can better organize and synthesize content that mirrors real-world topic interactions.\n\n2. **Practice Generation**\n    - **Question Generation with Quality Assessment**: Based on the extracted knowledge and the co-occurrence probabilities, this component focuses on generating questions. The generated questions are then subject to a quality assessment to ensure that they are meaningful, coherent, and contextually relevant. This step is crucial for maintaining high-quality content generation.\n   \n    - **Answer Generation with Consensus Assessment**: Finally, this component is responsible for generating answers to the previously generated questions. A consensus assessment mechanism is employed to verify and enhance the accuracy and quality of the answers. This collaborative and iterative approach ensures that the answers are reliable and valid for practical use.\n\nThe specific prompts utilized for each of these components are detailed in Appendix A (reference not provided).",
        "main_experiment_and_results": "**Main Experiment Setup and Results:**\n\n**Datasets:**\n- **MATH dataset** (Hendrycks et al., 2021a):\n  - Training set: 7,500 samples from high school math competitions, covering seven subjects and five difficulty levels.\n  - Generated data: 500K question-answer pairs using the KPDDS approach on the seed problems, refined to 253K data points after voting and optimization processes.\n\n- **GSM8K dataset** (Cobbe et al., 2021b):\n  - Training set: 7,473 samples of grade school math problems characterized by 2 to 8 step solutions.\n  - Generated data: 613K data points through three potential solutions generation, accuracy verification, and conversion into detailed explanations.\n\n- **Additional datasets included:**\n  - MetaMath (Yu et al., 2023b)\n  - MMIQC (Liu & Yao, 2024)\n  - Open-Platypus (Lee et al., 2023)\n  - CoT subset of MathInstruct (Yue et al., 2024)\n  - TAL-SCQ5K-EN (math eval, 2023)\n  \n  After applying min-hash techniques and filtering, a final collection of 711K data points resulted.\n\n**Final Dataset:**\n- The completion of deduplication and filtering, combined with the KPMATH-M and KPMATH-G data points:\n  - KPMATH-Plus aggregate dataset: 1,576K data points\n\n**Main Results:**\n  - The evaluation focuses on the effectiveness of the KPDDS approach and highlights the substantial enrichment achieved in the KPMATH-Plus dataset.\n  - The results indicate successful generation and curation of diverse and high-quality mathematical reasoning problem datasets, enhancing the robustness and variety of the available mathematical problem-solving challenges."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To examine the impact of different components and sizes of the KPMath-Plus dataset on the performance of the Mistral-7B model in mathematical reasoning tasks.",
            "experiment_process": "The study involved training the Mistral-7B model over 3 epochs using different components of the KPMath-Plus dataset. Specifically, the components involved were KPMath-G (derived from the GSM8K dataset) and KPMath-M (based on the MATH dataset). The performance was evaluated across datasets such as GSM8K, SVAMP, ASDiv, MAWPS, MATH, and TabMWP. Additionally, the study examined the impact of training data size on model performance, presenting a logarithmic performance trend with the expansion of the training data.",
            "result_discussion": "The integration of KPMath-G with MixMath improved performance on GSM8K by 5% and showed enhancements across other datasets like SVAMP, ASDiv, and MAWPS. Combining KPMath-M with MixMath led to consistent score increases of over 1% across all datasets. Merging KPMath-G and KPMath-M resulted in significant gains, including a 6.4% improvement on GSM8K and a 3.5% boost on MATH, averaging a 4.1% performance increase. The study also highlighted a steady performance growth with larger training data, emphasizing the exceptional quality of the synthesized data and its linkage to model performance.",
            "ablation_id": "2403.02333v3.No1"
        },
        {
            "research_objective": "To identify the optimal consensus voting strategy for improving the quality of synthesized data in KPMath-M, ensuring data quality without performance degradation.",
            "experiment_process": "The study involved experimenting with three distinct consensus voting strategies on the Mistral-7B model: non-voting (retaining all answers), semi-voting (preserving the most popular answer for single sub-question queries and reaching consensus on at least one answer for multiple sub-question queries), and full-voting (requiring consensus on every sub-question). CSV threshold experiments were conducted on the semi-voting and full-voting strategies. The KPMath-M data with different strategies was integrated into KPMath-G and MixMath, followed by fine-tuning on the Mistral-7B model.",
            "result_discussion": "The semi-voting strategy with a CSV threshold of 0.1 was identified as the best setting, reducing data volume by 46.7% compared to non-voting without any performance degradation. This setting was retained for the final dataset, and the effectiveness of the consensus voting strategy in filtering data for quality was validated.",
            "ablation_id": "2403.02333v3.No2"
        }
    ]
}