{
    "title": "Adapting Abstract Meaning Representation Parsing to the Clinical Narrative \u2013 the SPRING THYME parser",
    "abstract": "This paper is dedicated to the design and evaluation of the first AMR parser tailored for clinical notes. Our objective was to facilitate the precise transformation of the clinical notes into structured AMR expressions, thereby enhancing the interpretability and usability of clinical text data at scale. Leveraging the colon cancer dataset from the Temporal Histories of Your Medical Events (THYME) corpus, we adapted a state-of-the-art AMR parser utilizing continuous training. Our approach incorporates data augmentation techniques to enhance the accuracy of AMR structure predictions. Notably, through this learning strategy, our parser achieved an impressive F1 score of 88% on the THYME corpus\u2019s colon cancer dataset. Moreover, our research delved into the efficacy of data required for domain adaptation within the realm of clinical notes, presenting domain adaptation data requirements for AMR parsing. This exploration not only underscores the parser\u2019s robust performance but also highlights its potential in facilitating a deeper understanding of clinical narratives through structured semantic representations.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Abstract Meaning Representation Banarescu et al. (2013  ###reference_b4###)(AMR)is a highly adaptable and expressive framework designed to capture the semantics of natural language expressions. Automatic AMR parsing is a natural language processing (NLP) method that translates natural language inputs into formal AMR expressions \u2013 representations which have proven to be useful across a wide range of downstream applications Kapanipathi et al. (2021  ###reference_b20###); Liu et al. (2015  ###reference_b28###); Liao et al. (2018  ###reference_b27###); Li and Flanigan (2022  ###reference_b25###); Bonial et al. (2020  ###reference_b7###); Bai et al. (2021  ###reference_b1###) including those in the biomedical domain Garg et al. (2016  ###reference_b16###); Rao et al. (2017  ###reference_b32###).\nFormally, AMR expressions take the form of labeled, rooted, directed, and acyclic graphs, , where  represents the set of AMR nodes, which can be of type predicate, abstract concept and attributes;  represents the possible semantic relations between nodes such as prototypical agent and patient denoted by arg0 and arg1. The AMR graph structure underpinned by Neo-Davidsonian semantics can then effectively encapsulate the abstract concepts, relationships, and entities present in individual sentences or utterances.\nFrom a practical standpoint, AMR expressions encompass the semantic content typically addressed by individual representation schemes such as semantic role labeling Palmer et al. (2005  ###reference_b31###), named entities Wang et al. (2022  ###reference_b38###), and coreference chains Joshi et al. (2020  ###reference_b19###), thereby unifying these diverse aspects of meaning into a single comprehensive representation. Figure 1 illustrates an AMR expression selected from the clinical domain.\n###figure_1### As Figure 1  ###reference_### demonstrates, concepts including events, entities and properties are captured as nodes in the graph, while the relations among the concepts are captured by labeled edges connecting the nodes. Events are represented using PropBank frames Palmer et al. (2005  ###reference_b31###), and the semantic relations of both entities and events to these predicates are specified either by a frame\u2019s numbered argument or one of the relations from AMR\u2019s role inventory. For example, the see-09 predicate represents the event of \u201cvisit/consultation by a medical professional.\u201d In this case, the agent of the seeing event is \u201cDr. Chandler Bing\u201d, represented by see-09\u2019s ARG0 relation, and the semantic role of patient for the event is \u201cshe\u201d indicated by the ARG1 semantic relation. AMR graphs also specify the temporal information in a formal way. In the above example, the time of the seeing event is specified by two temporal modifier subgraphs. It is a conjunction of \u201cafter now\u201d and \u201cwithin this week\u201d which makes \u201clater this week\u201d a concrete time range.\nAMR parsers based on pretrained large language models and sequence-to-sequence (encoder-decoder) architectures have demonstrated impressive accuracy when trained and evaluated on standard datasets. The use of AMR parsers has contributed to improved performance across a range of NLP tasks including question answering Fu et al. (2021  ###reference_b15###), information retrieval Liao et al. (2018  ###reference_b27###), knowledge-graph construction Ribeiro et al. (2022  ###reference_b33###), and text generation Bai et al. (2022  ###reference_b2###).\nThese successes have sparked growing interest in employing AMR in domains that diverge from the existing training data, such as human-robot interaction tasks, educational applications involving classroom discourse analysis, and diverse biomedical use cases. Unfortunately, as language form and meaning deviate from the general language captured in generic training data, parsing performance shows a rapid decline. This decline stems from disparities in vocabulary, syntax, and overall discourse structure. Addressing these challenges necessitates dedicated human expert annotation efforts to create domain-specific AMR resources. However, such endeavors can be costly and time-consuming. Hence, the preference lies in maximizing the utilization of existing data and parsers and adapting them to new domains, rather than building entirely new systems from scratch.\nThe contributions of this paper include:\nWe adapted the high-performance SPRING parser Bevilacqua et al. (2021  ###reference_b5###) to the clinical domain, specifically leveraging the Temporal Histories of Your Medical Events (THYME) corpus Wright-Bettner et al. (2020  ###reference_b39###), and achieved state-of-the-art performance in AMR parsing within this context..\nWe demonstrated that by tailoring an existing general domain English neural AMR parser with a relatively modest amount of gold-standard in-domain data, we could attain significantly high accuracy.\nWe showcased data augmentation techniques that effectively enhance the parser\u2019s robustness across different domains."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Data",
            "text": "Supervised training data for AMR parsers consists of pairs of linguistic expressions along with their associated human annotated gold-standard AMR expressions. The current standard dataset for AMR development is AMR 3.0 Knight et al. (2020  ###reference_b22###) available from the Linguistic Data Consortium as LDC2020T02. This general domain dataset is the basis for our baseline efforts prior to domain adaptation. AMR 3.0 consists of over 59k English expressions from a variety of broadcast conversations, newswire, weblogs, web discussion forums, fiction and web text. To facilitate evaluation and model comparison, AMR 3.0 is divided into standard training, development and test splits consisting of 55,635, 1,722, and 1,898 expressions respectively.\nTo adapt AMR to the clinical narrative, we developed 8,327 in-domain AMRs (separate paper with detailed description under review) on a subset of the THYME colon cancer corpus Styler et al. (2014  ###reference_b36###); Wright-Bettner et al. (2020  ###reference_b39###). The colon cancer part of the THYME corpus consists of 594 de-identified physicians\u2019 notes for 198 patients with colon cancer. Each patient is represented by one pathology note and two clinical notes. The corpus has undergone several prior annotation efforts, including temporal and coreference annotation Styler et al. (2014  ###reference_b36###); Wright-Bettner et al. (2019  ###reference_b40###, 2020  ###reference_b39###) and entity tagging as defined by the Unified Medical Language System (UMLS Bodenreider (2004  ###reference_b6###)).\nAs part of our AMR annotation process, we adopted seven clinical-domain named entity (NE) types (anatomical-site, clinical-attribute, devices, disease-disorder, medications-drugs, sign-symptom) from the UMLS project and relied heavily on the UMLS in classifying many AMR concepts.\nLike other genre-specific AMR tasks Bonial et al. (2019  ###reference_b8###); Bonn et al. (2020  ###reference_b9###), we found it necessary to modify the standard AMR annotation approach to support meaningful annotation of domain-unique linguistic phenomena. Two phenomena are pervasive in the clinical narrative. First, physician notes frequently drop eventive mentions when they are inferable by human readers. For example, \u201cDeclines tetanus\u201d does not mean the patient declined having tetanus; they declined a tetanus immunization. We expanded AMR\u2019s guidelines to permit explicit rendering of certain implicit concepts like the immunization:\nSecond, like other specialized domains, clinical texts are rife with semantically dense noun phrases (NPs) Gr\u00f6n et al. (2018  ###reference_b17###). In AMR, NPs must be treated in one of two ways: Either all components are extracted and related (white marble = marble that is white), or they are analyzed as single units of meaning, i.e., NEs (White House). However, semantic compositionality exists on a spectrum Nakov (2013  ###reference_b30###), and many specialized NPs in particular strain the adequacy of a binary approach. This can be seen even in simple clinical NPs: One annotator might decide \u201cblood pressure\u201d is a single, cohesive unit of meaning and annotate it as an NE, while another might decide \u201cpressure\u201d is an extractable property of \u201cblood\u201d. To address this, we implemented a two-pass strategy: In the first pass, for NPs that fell under one of the clinical NE types mentioned above, an experienced annotator made these compositionality judgments and added each unique phrase to a searchable, phrasal NE Dictionary along with an AMR fragment that \u201cdefined\u201d the compositionality for each phrase. Annotators then referenced the Dictionary when building the AMR graphs in the second pass. This approach supported consistency and speed of annotation.\nFinally, the THYME corpus contains frequent repetition of many other multiword expressions and phrases. For extremely formulaic phrases, such as those found in Vital Signs sections (Height = 167.60 cm, e.g.), we implemented a template-filling script that deterministically produced the AMRs, again saving significant manual annotation time. Of the 8,327 AMRs, 1,640 were produced by this script; the rest were created manually. The final 8,327 THYME-AMR data are split into training, development and test sets randomly with 4,955, 1,641 and 1,731 sentence-AMR pairs, respectively. All of the model training is conducted on the training set of the AMR 3.0 and THYME AMR corpora. We show the Inter Annotator Agreement between three annotators on 107 THYME-AMRs in Table 1  ###reference_###"
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Methods",
            "text": "We treat the AMR parsing task as a supervised machine learning problem and train a parameterized model to map natural language expressions to their corresponding AMR graphs. Various model architectures and training methods and paradigms have been employed over the years Flanigan et al. (2014  ###reference_b13###); Foland and Martin (2017  ###reference_b14###); Lyu and Titov (2018  ###reference_b29###); Cai and Lam (2019  ###reference_b10###); Zhang et al. (2019  ###reference_b42###); Wang et al. (2015  ###reference_b37###); Ballesteros and Al-Onaizan (2017  ###reference_b3###); Fernandez Astudillo et al. (2020  ###reference_b12###); Hoang et al. (2021  ###reference_b18###), resulting in a continuous improvement in the state of the art on the general domain AMR dataset(i.e. AMR 2.0 and 3.0 corpus (LDC2020T2)). However, these improvements are highly dependent on the availability of significant amounts of annotated training data hampering the development of parsers for specific genres and languages other than English. Our approach here is to leverage an existing high-performance parser and adapt it to the clinical domain using the modest amount of domain-specific training data described in the last section.\nMeanwhile, the great advances of the pre-trained foundational models has introduced a new modeling paradigm in the field of NLP as well as to structure-prediction problems such as AMR parsing. In particular, the sequence-to-sequence modeling, originally developed for machine translation, has proven a highly effective approach for AMR parsing Bevilacqua et al. (2021  ###reference_b5###); Konstas et al. (2017  ###reference_b23###); Xu et al. (2020  ###reference_b41###). In this approach, two neural network components are involved: an encoder, which takes the natural language sentence as input and maps it to a continuous manifold as a sequence of high-dimensional vectors, and a decoder, which takes the embedded sentence representation vectors and maps them to the output embedding space, corresponding to the target sequence tokens.\nHere we make use of the SPRING parser Bevilacqua et al. (2021  ###reference_b5###), one of the state-of-the-art AMR parsers on AMR 3.0 evaluation. The underlying pre-trained language model is BART-large Lewis et al. (2020  ###reference_b24###), a transformer-based language model that has been trained using a set of denoising pre-training objectives, such as a masked language modeling objective and a document reconstruction objective, on general domain unlabeled English text. The neural network architecture relies on the self-attention and cross-attention mechanism to learn patterns from natural language texts. This pre-trained model is then fine-tuned on the AMR 3.0 training data to map English inputs to linearized AMR graphs, which consist of a sequence of AMR tokens. We show the linearization correspondence of an AMR graph to its sequence of AMR tokens in Figure 2  ###reference_###.\n###figure_2### A critical aspect of using sequence-to-sequence models for structured prediction tasks, like parsing, is transforming the task itself. In AMR parsing, the AMR graph is converted into a sequence of tokens through a linearization algorithm. Note that the vocabulary of the decoder differs from that of the encoder model, as the target sequence consists of AMR-specific tokens such as the relations arg0 and arg1, and predicates like test-01. During fine-tuning, we utilize the vocabulary derived from the AMR 3.0 corpus, which ensures consistency and accuracy in the parsing process. The parsing problem is then to convert an input text sequence into a valid sequence of AMR tokens that can be deterministically transformed into a directed AMR graph. The overall SPRING approach is depicted in Figure 3  ###reference_###.\n###figure_3### Given a high-performing SPRING model, we adapt it to the THYME domain by fine-tuning on the THYME-AMR training set (4,955 expressions). Here, fine-tuning involves continuous gradient-based updates to the original model parameters with a small learning rate () with batch size to be 20, we keep the maximum sequence length to be 1024.."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Evaluation",
            "text": "The standard metric to evaluate AMR parsing performance is SMATCH, which decomposes an AMR graph into triples that capture the edge list representation of a graph structure. For instance, the AMR for the sentence \u201cHe had never undergone a screening colonoscopy.\u201d can be decomposed into its edge list representation as AMR1 and edge list 1 as follows:\nWe conjured another slightly altered AMR2 with the he node replaced with a she node, indicating a potential mistake in the parser generated AMR. In the above decomposition of AMR graphs, instance() represents the nodes in the graph while the rest are the edges. Given the edge lists for a hypothetical parse and its corresponding gold-standard parse, the SMATCH metric produces precision (p), recall (r), and F1-measure scores as follows:\nA complication in computing these scores is that we need to know which of the proposed AMR nodes in the parse are supposed to correspond to which ones in the correct set. In other words, the graphs need to be matched before they can be scored. This issue originates from the encoding of AMR nodes with variables, through which different instantiations of a concept can be encoded. The standard SMATCH scorer Cai and Knight (2013  ###reference_b11###) employs a greedy heuristic method to provide the required alignment to avoid computing a computationally expensive optimal alignment.\nFinally, AMR representations are an amalgamation of semantic representations including predicate-argument relations, named entities, and coreference components. The SMATCH score represents an average over these component categories, obscuring the model performance over the various categories of information in AMR expressions, thus making it difficult to assess the usability of the results in downstream applications. To address this, a more fine-grained analysis tool111https://github.com/mdtux89/amr-evaluation  ###reference_### provides precision, recall and F1 measures across the various component AMR tasks. We will discuss the fine-grained categories in section 4.3  ###reference_###."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "We present the domain adaption training experiments in this section to show the characteristics of the text from THYME corpus when it comes to AMR parser development. Recent advancements in AI have significantly impacted art generation, enabling the creation of unique and sophisticated artworks. Techniques such as Generative Adversarial Networks (GANs) and neural style transfer have revolutionized digital art by allowing machines to learn and replicate distinctive styles and patterns."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Domain Adaptation",
            "text": "Table 2  ###reference_### provides the results of our primary domain adaptation experiments. The first column presents the evaluation results of the off-the-shelf SPRING AMR parser trained solely with the AMR 3.0 training data. The 83.0 SMATCH score for the SPRING parser reaches near state-of-the-art performance on the AMR 3.0 test set, whereas, the performance on the THYME-AMR test set is significantly lower at 51.7 SMATCH. The second column shows the results of the same parser fine-tuned using the THYME-AMR training data. Here, we see that the fine-tuned parser achieves excellent results on the THYME-AMR corpus test set with a 35.3 point absolute improvement over the original model. \n\nArtificial intelligence has made significant strides in the generation of art, with models such as DALL-E and Midjourney demonstrating the ability to create intricate and imaginative visual content. These AI systems leverage deep learning techniques, including GANs and transformers, to produce artwork that often rivals human creativity, transforming the landscape of digital art."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Avoiding Forgetting",
            "text": "Catastrophic forgetting is a frequently observed problem when fine-tuning large pre-trained models on domain specific data Li and Hoiem (2018  ###reference_b26###); Riemer et al. (2019  ###reference_b34###); Scialom et al. (2022  ###reference_b35###). While fitting the model\u2019s parameters to the new domain, there is often a significant loss in terms of the model\u2019s performance on its original domain. To assess the robustness and potential forgetting of general domain AMR knowledge, we evaluated the THYME-AMR fine-tuned parser on the AMR 3.0. The results showed a decrease in performance from 83.8 to 77.0, indicating significant forgetting of the general domain AMR. Based on this observation, we deployed a joint training approach to mitigate this forgetting phenomenon. In this experiment, we fine-tuned the parser on a mixture sampled from both the AMR 3.0 and THYME-AMR data. Considering the differing sizes of the two corpora, we sampled them in a 12-to-1 ratio between THYME-AMR and AMR 3.0 sources. As can be seen from Table 2  ###reference_###, this modest infusion of general domain data allowed the parser to attain high performance on the THYME-AMR test set while also largely maintaining its performance on the AMR 3.0 test set. This observation underscores the effectiveness of domain-specific annotation in improving semantic parsing in a joint fashion. This means that the understanding of semantics improves collectively rather than independently, thanks to domain-specific data. As more representative data are collected, we expect further improvements in the parser\u2019s performance, making it even more adept at comprehending the semantics in the given domain.\n\nIn recent years, AI has become instrumental in generating art, with advancements in models like GANs and transformer networks. Works by Elgammal et al. (2017) and Yang et al. (2022) illustrate AI's ability to produce innovative and aesthetically compelling pieces. By leveraging neural creativity, these systems challenge traditional concepts of artistry."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Fine-Grained Performance",
            "text": "Artificial Intelligence has notably transformed art generation by employing neural networks such as Generative Adversarial Networks (GANs) and transformers, enabling the creation of artworks that mimic human creativity. These models have achieved remarkable results in generating imaginative and stylistically diverse pieces, which continue to blur the lines between machine-generated and human art."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "Data Requirements for Successful Adaptation",
            "text": "Manual annotation of AMR data is time consuming and expensive. At the current time, the standard AMR 3.0 still consists of only 60k sentences, nearly 10 years after the initial data release. The results shown in Table 2 raise the question of how much data is actually required to attain high levels of parser accuracy through adaptation. To address this question, we conducted a series of experiments training models with progressively larger snapshots of the available training data. Specifically, we gradually augmented the training set size for each model by random sampling without replacement from the training data (resulting in training sets of size 500, 1,000, 2,000, 3,000, 4,000 and 4,955). The results in Figure 4 illustrate the parser\u2019s performance across these training sets. As can be seen, performance rapidly rises from the non-adapted baseline to 80 SMATCH with 1,000 training examples; the model trained on only 2,000 samples achieves 90% of the performance of our best parser trained on all available training data. This rapid improvement with domain specific data is a positive indication of the effectiveness of continued training from a generic model and its ability to rapidly generalize from the domain-specific data.\n\nAI has revolutionized art generation, exemplified by advancements in machine learning models such as GANs (Generative Adversarial Networks) and diffusion models. These techniques enable the creation of high-quality, unique artworks, challenging traditional boundaries and influencing contemporary art practices. Recent models have demonstrated significant capabilities in mimicking various artistic styles."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Discussion",
            "text": "Our results have highlighted the advantages of employing data augmentation techniques for domain adaptation fine-tuning. This opens up the possibility for additional follow-up studies, including the incorporation of data from domain-specific Propbank roleset development. For instance, in the case of THYME, leveraging example sentences for newly added named-entity types like \u201canatomical-site\u201d could prove beneficial. Initializing the word embedding vectors with such domain-specific concepts would enable a better fit with the pre-trained foundational models. Future investigations involving more sophisticated foundational models and data augmentation approaches hold great promise for enhancing AMR parsing in the medical domain and other specialized domains. By harnessing the capabilities of cutting-edge language models and innovative data augmentation strategies, we can expect significant advancements in semantic parsing tasks and domain adaptation techniques.\nWith these advances, AMR parses have wide applicability to core information extraction tasks from the clinical narrative such as entity recognition, negation detection, uncertainty detection, coreference, temporality and relation extraction."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In our investigation, we have presented substantial evidence highlighting the critical role of domain-specific AMR annotations in the context of domain adaptation. Our findings illuminate how variances in the distribution between original and target domains can precipitate a marked decline in the performance of AMR parsing. This phenomenon underscores the challenge of catastrophic forgetting, a significant hurdle in the training of neural network models where new learning can disrupt previously acquired knowledge.\nTo counteract this issue, we demonstrated the critical role of data augmentation techniques. Specifically, by integrating domain-specific examples into the training dataset, we significantly bolstered the model\u2019s capability to acclimate to the nuances of the new domain while preserving its proficiency in the original domain. This strategic approach of coupling domain-specific annotation with thoughtful data augmentation has emerged as a formidable solution, ensuring both the robustness and accuracy of AMR parsing across different domain adaptation scenarios.\nOur study reaffirms the indispensability of domain-specific annotation in achieving effective domain adaptation and also supports data augmentation as an essential tool in maintaining a delicate balance between learning new domain characteristics and retaining essential knowledge from the original domain. This balanced approach provides a promising avenue for future research and development in the field of AMR parsing, potentially paving the way for more nuanced and adaptable AI systems capable of navigating other domains with limited data yet maintain robustness."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Limitations and Future Work",
            "text": "Our study faced constraints primarily due to computational limitations, which necessitated a focus on a specific subset of model and data augmentation strategies. A reasonable extension of this research could involve the exploration of more advanced foundational models, including GPT-3.5, GPT-4, and their publicly accessible counterparts such as LLAMA. These platforms present opportunities for experimenting with zero- or few-shot learning techniques. Importantly, our use of clinical data mandates adherence to stringent privacy standards; thus, it is imperative that any models employed can be locally installed and operated within a secure, firewall-protected environment. This requirement currently excludes the use of proprietary models like those within the GPT family, which are tailored for commercial applications and do not meet the privacy criteria essential for our research objectives."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "Acknowledgements",
            "text": "This research and the paper it informs have been funded by the United States National Institutes of Health (grants R01LM010090, R01LM013486). The content is solely the responsibility of the authors and does not necessarily represent the official views of the United States National Institutes of Health. The results presented in this paper were obtained using the Chameleon testbedKeahey et al. (2020  ###reference_b21###) supported by the National Science Foundation. We wish to extend our heartfelt gratitude to Ahmed Elsayed and Gaby Dinh for their exceptional annotation efforts, without which this research would not have been possible. Additionally, we are deeply appreciative of the thorough discussions and invaluable suggestions from Skatje Myers, Steven Bethard, David Harris, Timothy Miller, Danielle Bitterman, Piet de Groen, and Dmitriy Dligach."
        }
    ],
    "url": "http://arxiv.org/html/2405.09153v1",
    "segmentation": {
        "research_background_sections": [
            "1"
        ],
        "methodology_sections": [
            "3"
        ],
        "main_experiment_and_results_sections": [
            "4.1",
            "4.2",
            "4.3",
            "4.4"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4.2",
            "4.4"
        ]
    },
    "research_context": {
        "paper_id": "2405.09153v1",
        "paper_title": "Adapting Abstract Meaning Representation Parsing to the Clinical Narrative \u2013 the SPRING THYME parser",
        "research_background": "### Motivation and Research Problem\n\nThe paper is motivated by the need to adapt Abstract Meaning Representation (AMR) parsing, traditionally trained on general language data, to successfully parse clinical narratives. AMR is a versatile framework that captures the semantics of natural language and has proven valuable in various downstream applications including biomedical contexts. However, the performance of AMR parsers significantly declines when applied to domains different from the training data, such as the clinical domain, due to variations in vocabulary, syntax, and discourse structure. Addressing this performance gap calls for domain-specific resources and adaptations, which can be cost-prohibitive and labor-intensive to produce from scratch. Therefore, the research problem this paper tackles is how to effectively adapt existing high-performance general-domain AMR parsers to clinical narratives with minimal domain-specific resources.\n\n### Relevant Prior Work\n\nThe paper builds on several foundational works and prior research in AMR parsing and its applications:\n\n1. **AMR Framework and Utility:**\n   - AMR as a semantic representation framework was introduced by Banarescu et al. (2013).\n   - Its effectiveness in various NLP applications is supported by studies such as Kapanipathi et al. (2021), Liu et al. (2015), Liao et al. (2018), Li and Flanigan (2022), Bonial et al. (2020), and Bai et al. (2021).\n\n2. **Application in Biomedical Domain:**\n   - Garg et al. (2016) and Rao et al. (2017) have explored AMR's utility in biomedical contexts.\n\n3. **General NLP Tasks:**\n   - AMR parsing\u2019s contribution to improving NLP tasks like question answering (Fu et al. 2021), information retrieval (Liao et al. 2018), knowledge-graph construction (Ribeiro et al. 2022), and text generation (Bai et al. 2022) are well documented.\n\n4. **AMR Parsing Methodologies:**\n   - Pretrained language models and sequence-to-sequence architectures, which have achieved notable success, are highlighted. Specifically, the SPRING parser by Bevilacqua et al. (2021) provides a foundation for the paper\u2019s adaptation efforts.\n\n5. **Challenges in Domain Adaptation:**\n   - Prior attempts to utilize AMR in specialized domains have highlighted the challenges related to differences in linguistic features and the necessity for extensive, costly annotations for effective domain-specific adaptation.\n\n### Contributions of this Paper\n\n1. **Adaptation of SPRING Parser:**\n   - The paper adapts the SPRING parser to clinical narratives using the Temporal Histories of Your Medical Events (THYME) corpus, achieving state-of-the-art performance.\n\n2. **Domain-Specific Tailoring:**\n   - Demonstrates significant improvements in accuracy by tailoring a neural AMR parser with a relatively small amount of in-domain annotated data.\n\n3. **Data Augmentation Techniques:**\n   - Introduces effective data augmentation methods that enhance the robustness of the parser across different domains, highlighting practical approaches to domain adaptation.",
        "methodology": "### Methodology: SPRING THYME Parser for AMR Parsing in Clinical Narrative\n\nWe conceptualize Abstract Meaning Representation (AMR) parsing as a supervised machine learning task. This entails training a parameterized model to map natural language expressions to their corresponding AMR graphs. Historically, several model architectures and training paradigms have been explored (Flanigan et al., 2014; Foland and Martin, 2017; Lyu and Titov, 2018; Cai and Lam, 2019; Zhang et al., 2019; Wang et al., 2015; Ballesteros and Al-Onaizan, 2017; Fernandez Astudillo et al., 2020; Hoang et al., 2021), resulting in continuous enhancements in state-of-the-art performance on general domain AMR datasets, such as AMR 2.0 and 3.0 corpora (LDC2020T2). However, these advancements rely heavily on the availability of substantial annotated training data, thus hindering the development of parsers for specific genres and non-English languages.\n\nOur strategy leverages an existing high-performance parser, adapting it to the clinical domain using a limited amount of domain-specific training data. The recent emergence of pre-trained foundational models has revolutionized NLP and structure-prediction tasks like AMR parsing. Sequence-to-sequence (seq2seq) modeling, initially intended for machine translation, has shown significant efficacy in AMR parsing (Bevilacqua et al., 2021; Konstas et al., 2017; Xu et al., 2020).\n\n**Sequence-to-Sequence Modeling Framework:**\nIn this approach, two neural network components are pivotal:\n- **Encoder:** Maps the natural language sentence to a continuous manifold, represented as high-dimensional vectors.\n- **Decoder:** Transforms the embedded sentence representation vectors into the output embedding space, corresponding to the target sequence tokens.\n\nWe utilize the SPRING parser (Bevilacqua et al., 2021), recognized for its state-of-the-art performance in AMR evaluations. The underlying pre-trained language model is BART-large (Lewis et al., 2020), a transformer-based model trained using denoising pre-training objectives, such as masked language modeling and document reconstruction, on unlabeled general domain English text. The architecture employs self-attention and cross-attention mechanisms to detect patterns in natural language texts.\n\nThis pre-trained BART model is then fine-tuned on AMR training data to map English inputs to linearized AMR graphs.\n\n**Task Transformation for Structured Prediction:**\nA crucial element in using seq2seq models for structured prediction tasks like parsing is transforming the task itself. In AMR parsing, we convert the AMR graph into a sequence of tokens using a linearization algorithm. The decoder's vocabulary, consisting of AMR-specific tokens (e.g., relations like arg0, arg1, and predicates like test-01), differs from the encoder's vocabulary. During fine-tuning, we employ the vocabulary derived from the AMR corpus to maintain consistency and ensure parsing accuracy. Thus, the parsing problem is reduced to converting an input text sequence into a valid AMR token sequence, which can be deterministically transformed back into a directed AMR graph.\n\n**Adapting SPRING to the Clinical Domain:**\nTo adapt the high-performing SPRING model to the THYME domain, we fine-tune it on the THYME-AMR training set (comprising 4,955 expressions). Fine-tuning involves continuous gradient-based updates to the original model parameters. We use a small learning rate, a batch size of 20, and set the maximum sequence length to 1024 during this process.",
        "main_experiment_and_results": "**Main Experiment Setup and Results**:\n\n**Datasets**:\n- **AMR 3.0 Training Data**: Used to train the off-the-shelf SPRING AMR parser.\n- **THYME-AMR Training Data**: Used for fine-tuning the SPRING AMR parser for the clinical domain.\n- **AMR 3.0 Test Set**: Used to evaluate the off-the-shelf SPRING AMR parser.\n- **THYME-AMR Test Set**: Used to evaluate both the off-the-shelf and fine-tuned SPRING AMR parsers.\n\n**Baselines**:\n- **Off-the-Shelf SPRING AMR Parser**: This baseline is trained solely on the AMR 3.0 training data without any fine-tuning on clinical data.\n\n**Evaluation Metrics**:\n- **SMATCH Score**: Used to evaluate the performance of the AMR parsers. It measures the overall quality of the abstract meaning representation (AMR) produced by the parsers.\n\n**Main Experimental Results**:\n- The off-the-shelf SPRING AMR parser achieves a SMATCH score of **83.0** on the AMR 3.0 test set but performs significantly worse on the THYME-AMR test set with a score of **51.7**.\n- After fine-tuning with THYME-AMR training data, the SPRING AMR parser shows a substantial improvement on the THYME-AMR test set, achieving a **35.3** point absolute improvement, raising its SMATCH score to **87.0** on the THYME-AMR."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To address catastrophic forgetting when fine-tuning large pre-trained models on domain-specific data and to evaluate the robustness of the THYME-AMR fine-tuned parser against general domain AMR knowledge.",
            "experiment_process": "The THYME-AMR fine-tuned parser was evaluated on the AMR 3.0 corpus to assess knowledge retention. A joint training approach was then deployed, where the parser was fine-tuned on a mixture of data sampled from both the AMR 3.0 and THYME-AMR corpora in a 12-to-1 ratio. This process aimed to maintain performance on the original domain while adapting to the new domain.",
            "result_discussion": "The initial evaluation showed a decrease in performance from 83.8 to 77.0, indicating significant forgetting of general domain AMR. However, the joint training approach allowed the parser to achieve high performance on the THYME-AMR test set while largely maintaining its performance on the AMR 3.0 test set. This underscores the effectiveness of domain-specific annotation in improving semantic parsing in a joint fashion.",
            "ablation_id": "2405.09153v1.No1"
        },
        {
            "research_objective": "To determine the amount of data required for successful adaptation of the AMR parser to the clinical domain.",
            "experiment_process": "Models were trained with progressively larger snapshots of available training data, ranging from 500 to 4,955 sentences. The training sets were augmented by random sampling without replacement from the training data, and the parser's performance across these sets was evaluated.",
            "result_discussion": "Performance rapidly increased with domain-specific data, rising to 80 SMATCH with 1,000 training examples. The model trained on 2,000 samples achieved 90% of the performance of the best parser trained on all available data. This demonstrates the effectiveness of continued training from a generic model and its ability to quickly generalize using domain-specific data.",
            "ablation_id": "2405.09153v1.No2"
        }
    ]
}