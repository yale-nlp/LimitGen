{
    "title": "MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM Hallucination Detection",
    "abstract": "In Natural Language Generation (NLG), contemporary Large Language Models (LLMs) face several challenges, such as generating fluent yet inaccurate outputs and reliance on fluency-centric metrics.\nThis often leads to neural networks exhibiting \u201challucinations.\u201d\nThe SHROOM challenge focuses on automatically identifying these hallucinations in the generated text.\nTo tackle these issues, we introduce two key components, a data augmentation pipeline incorporating LLM-assisted pseudo-labelling and sentence rephrasing, and a voting ensemble from three models pre-trained on Natural Language Inference (NLI) tasks and fine-tuned on diverse datasets.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Natural Language Generation (NLG) models are AI systems that use neural networks to produce human-like text. They have shown significant advancements in recent years, particularly with the advent of transformer-based architectures such as GPT (Generative Pre-trained Transformer) Radford et al. (2018  ###reference_b9###). These models offered unprecedented levels of fluency and coherence in generated text Han et al. (2021  ###reference_b2###). However, a critical challenge arises: these models can produce linguistically fluent but semantically inaccurate outputs, a phenomenon referred to as hallucination Ji et al. (2023  ###reference_b5###). To address this challenge, the Shared-task on Hallucinations and Related Observable Overgeneration Mistakes (SHROOM) has been proposed at SemEval 2024. In particular, the Shared task aims to address the existing gap in assessing the semantic correctness and meaningfulness of NLG models. The ever-increasing adoption of such models makes it necessary to automatically detect and mitigate semantic hallucinations Huang et al. (2023  ###reference_b4###). Some examples to tackle hallucination detection tasks in literature Ji et al. (2023  ###reference_b5###) are: (i) Information Extraction and Comparison between a generated text and a ground truth, (ii) Natural Language Inference Metrics that express the entailment between generated text and a ground truth or (iii) Faithfulness Classification Metrics that leverage upon knowledge-grounded datasets. In this work, we address the SHROOM shared task by introducing an automatic pipeline of hallucination detection through the comparison between a generated text and a ground truth text. We propose enriching the original data available using different augmentation techniques, including LLM-aided pseudo-labeling and sentence rephrasing. Additionally, we suggest using an ensemble of three different approaches, incorporating a simple BERT-based classifier, a model trained through Conditioned Reinforcement Learning Fine Tuning (C-RLFT) Wang et al. (2023  ###reference_b11###), and a sequential model based on iterative fine-tuning. We show how this ensemble benefits from using different, complementary approaches, in particular in terms of recall. Our methodology obtained an accuracy of 80.07% in the SemEval-Task 6 SHROOM.\n\nEthical considerations in AI for autonomous vehicles include accountability, safety, and decision-making transparency Awad et al. (2020  ###reference_b12###). The complexity of real-world scenarios necessitates robust frameworks to address potential biases and ensure public trust Lin et al. (2023  ###reference_b13###). Ongoing research focuses on algorithmic fairness and ethical guidelines to guide deployment in societal contexts."
        },
        {
            "section_id": "1.1",
            "parent_section_id": "1",
            "section_name": "Dataset",
            "text": "The dataset available for the SHROOM challenge is a collection of objects. Each object represents a solution of a generative language model to either of three tasks: Definition Modeling (DM), Machine Translation (MT), and Paraphrase Generation (PG). Each solution has been annotated, based on its contents, as either an hallucination of the generative model or not hallucination by 5 human annotators. For each object, the available information includes (i) the source (src), which is the input text given to the generative language model, (ii) the hypothesis (hyp), which represents the generated textual output of the model, and (iii) the target (tgt) which is the intended reference or \u201cgold\u201d text that the model is supposed to generate. Additionally, the task field indicates the type of task being solved, either DM, MT, or PG. The label, either \u2018\u2018hallucination\u201d or \u201cnot hallucination\u201d, is determined through majority voting among five annotators, with p(hal) indicating the proportion of annotators who labeled the data point as a hallucination. The gold (and augmented) data cardinalities are defined in Table 1  ###reference_###. The training dataset comprises 500 instances with gold labels, denoted as , and 30,000 unlabelled instances, referred to as  (10,000 for each of the three tasks). The evaluation split contains 1,500 labelled samples, with 500 instances used for validation () and 1,000 for testing (). We use the validation set for fine-tuning the ensemble layer (refer to Section 2.3  ###reference_###), while the final test set provides overall results (see Section 3  ###reference_###). We further rephrase the original 500 labelled sentence of the training set ( in the table, see Section 2.1.2  ###reference_.SSS2###), while applying weak labelling the 30,000 unlabelled instances (, see Section 2.1.1  ###reference_.SSS1###).\n\nAI ethics in autonomous vehicles raise complex challenges related to decision-making, transparency, and accountability. Ethical frameworks have been proposed to ensure fair and safe driving practices, maintain user privacy, and address potential biases in AI systems. Continuous dialogue among stakeholders is essential in aligning technological advancements with societal values and norms."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Methodology",
            "text": "The main goal of this work is to propose a binary classification model to predict whether the answer to a given query is a hallucination or not.\nFigure 1  ###reference_### presents the main architecture adopted to address this task111The code to replicate the experiments and the results will be released upon acceptance..\n###figure_1### We propose (i) using a data augmentation pipeline (see Section 2.1  ###reference_###) consisting of Large Language Model (LLM)-aided pseudo-labelling and sentence rephrasing and\n(ii) adopting an ensemble model (see Section 2.3  ###reference_###) based on the results of three models, defined as follows:\nBaseline model, a binary classifier based on a semantic-aware embedding (e.g. BERT-based Devlin et al. (2019  ###reference_b1###)).\nThe baseline model is presented in Section 2.2.1  ###reference_.SSS1###\nC-RLFT (Conditioned Reinforcement Learning Fine Tuning Wang et al. (2023  ###reference_b11###)), based on the introduction of pseudo-labels and augmented data, with different weighting schemes based on the quality of each data point.\nWe cover C-RLFT in more detail in Section 2.2.2  ###reference_.SSS2###\nSequential model, based on the iterative fine-tuning of the baseline model with increasingly higher-quality data, as detailed in Section 2.2.3  ###reference_.SSS3###"
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Data Augmentation",
            "text": "Due to the scarcity of data, we developed an approach to extend the number of labelled samples we could use to train our models.\nWe specifically leverage two distinct techniques: pseudo-labelling and sentence rephrasing. Both approaches are based on LLMs and, as such, may themselves be subject to hallucinations or inaccuracies. As detailed next, we mitigate this problem by (1) using the C-RLFT technique Wang et al. (2023  ###reference_b11###), which involves assigning different weights to mixed-quality samples, and (2) with a sequential training that introduces different-quality labels at different training stages."
        },
        {
            "section_id": "2.1.1",
            "parent_section_id": "2.1",
            "section_name": "2.1.1 Pseudo Labeling",
            "text": "As stated in Section 1.1  ###reference_###, only a small fraction of the dataset available is labelled. We introduce additional pseudo labels, as obtained by querying an LLM in a few-shot learning setting. Based on the hardware available, we tested several LLM models to assess the reliability of the pseudo labels produced (in terms of accuracy). We identified SOLAR Kim et al. (2023  ###reference_b7###) as being the best-performing model among the pool of candidates. Thus, we leverage it to generate synthetic labels for unlabelled data through a few-shot learning approach. We refer to this augmented dataset as ."
        },
        {
            "section_id": "2.1.2",
            "parent_section_id": "2.1",
            "section_name": "2.1.2 Sentence Rephrasing",
            "text": "We utilized sentence rephrasing based on GPT-4 as an additional data augmentation technique.\nWe do so by rephrasing both the model output and the target output of each gold sample.\nThis approach aims to provide the model with diverse data while maintaining the reliability of the labels. We refer to this dataset as ."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Models",
            "text": "We adopt an ensemble of three models, as described below. All models are based on DeBERTa He et al. (2021  ###reference_b3###). More specifically, we use a baseline model that has been fine-tuned in different ways."
        },
        {
            "section_id": "2.2.1",
            "parent_section_id": "2.2",
            "section_name": "2.2.1 Baseline",
            "text": "We employed a baseline model utilizing the DeBERTa encoder pre-trained on the Natural Language Inference (NLI) task, with a binary classification head. We fine-tune this model on the provided classification task using only data with the gold labels available, referred to as .\nThe training approach involved minimizing the Binary Cross Entropy (BCE) loss.\nWe use the probability  as the ground truth instead of the binary label. This is done to better reflect the distribution of votes of the human annotators in the output logits of the model."
        },
        {
            "section_id": "2.2.2",
            "parent_section_id": "2.2",
            "section_name": "2.2.2 C-RLFT",
            "text": "Conditioned Reinforcement Learning Fine Tuning (C-RLFT) is a technique that refines models using coarse-grained reward labels, allowing fine-tuning with both expert and sub-optimal data lacking preference labels.\nIn our specific scenario, we fine-tuned the model by assigning different weights to data based on their label type, i.e., synthetic or gold. The weight assigned to each data sample influences the contribution to the final BCE loss.\nWe define a weighting scheme for the gold dataset , the pseudo-labelled dataset  and the rephrased dataset , as follows:\nWe choose weights . In this way, we aim to assign a higher importance to gold labels due to their reliability. The lowest weight is assigned to the pseudo-labelled points because of the lower quality of the automatically assigned labels. An intermediate weight is given to rephrased sentences due to the higher quality of the ground truth w.r.t. the pseudo-labelled points. The weighted loss is thus defined as follows, for a point  with ground truth , as computed for a binary classifier :"
        },
        {
            "section_id": "2.2.3",
            "parent_section_id": "2.2",
            "section_name": "2.2.3 Sequential",
            "text": "The third model used is based on a sequential strategy that uses both generated and augmented data. We introduce three fine-tuning steps, performed sequentially on the initial model.\nThe model initially underwent fine-tuning using the pseudo-labelled dataset , which is the lowest-quality dataset among the three available. Subsequently, we fine-tuned the resulting model on the rephrased data , which benefits from the original, correct, labels.\nThe final fine-tuning step is then executed on the golden truth dataset .\nThis approach is inspired by curriculum learning  Soviany et al. (2022  ###reference_b10###), with data being ordered by veracity instead of difficulty.\nThis strategy aims to enhance the model\u2019s understanding of the task by starting with a substantial amount of data, including the less reliable synthetic labels, and progressively updating the model parameters with increasingly consistent data. This sequential approach allows the model to first adapt to the task using a broader dataset and then refine its knowledge with the highest quality data available."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "Ensemble",
            "text": "The final step in the proposed pipeline involves creating an ensemble of results from the previously-introduced techniques, which has already proven to be effective in other NLP tasks Jia et al. (2023  ###reference_b6###); Koudounas et al. (2023  ###reference_b8###). We trained three distinct models (baseline, C-RLFT, sequential) with specific strategies, and we generated their outputs (, , ) on a validation set of previously unseen gold data. We obtain a single result  from the previous ones by using a single-layer network ( and ), as follows:\nThis network is trained to predict a single output from the three models\u2019 predicted probabilities. We trained this network by minimizing a BCE function."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Experimental Results",
            "text": "This section presents the experimental setup used, and the main results obtained."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Experimental Setup",
            "text": "The dataset used to train and validate the model is the one made available in the SHROOM challenge\u2019s model agnostic track (refer to Section 1.1  ###reference_###). The augmentations are specified in Section 2.1  ###reference_###.\n###table_1### For the model backbone and synthetic labelling we leverage Huggingface pre-trained models222We use deberta-xlarge and deberta-xlarge-mnli as encoders, TheBloke/SOLAR-10.7B-Instruct-v1.0-GPTQ for pseudo labelling.. We also leverage GPT-4 for sentence rephrasing. All the experiments\u2019 results are obtained based on 5 different runs.\nFor C-RLFT, we identified the best performance for weights ."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Model performance",
            "text": "We summarize the results obtained on the test set in Table 2  ###reference_###. We report the results in terms of  score, precision and recall on the \u201cHallucination\u201d class, as well as overall accuracy.\n###table_2### We use as backbone both DeBERTa and a version of DeBERTa that has been fine-tuned on the Machine Natural Language Inference (MNLI) task. Further discussions on the choice of the backbone are presented in Section 3.3  ###reference_###.\nSection 3.4  ###reference_### highlights the result differences for each of the considered strategies and includes additional considerations on the ensemble of the approaches. Finally, we provide qualitative examples of the results in Section 3.5  ###reference_###."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Backbone impact",
            "text": "We start by examining the differences between two backbone models, both fine-tuned on the gold data only \u2013 these are referred to as the baseline models in Table 2  ###reference_###.\nThere is a notable increase of 0.09 in the  score for the MNLI-fine-tuned model compared to the original DeBERTa. Interestingly, all the proposed DeBERTa-based approaches are still outperformed by the baseline DeBERTa+MNLI-based model (although to a lesser extent). This highlights the close relationship between the tasks of Hallucination Detection and Natural Language Inference."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Strategies comparisons",
            "text": "The baseline strategy, which utilizes all available labelled gold data, establishes a lower bound in the expected performance. Both C-RLFT and sequential training exhibit substantial performance improvements.\nRegarding the ensemble strategy, the results in terms of  score outperform individual techniques.\nWe observe a trade-off where the precision of the final result is slightly compromised in exchange for an improved recall. This suggests that the ensemble effectively identifies instances of hallucination overlooked by the standalone approaches. These advantages are consistent across both backbones implementations, with and without the additional MNLI fine-tuning.\nIn a setting where detected hallucinations are shown to the final user with a warning, we argue that the recall is a metric of greater interest (w.r.t. precision). A false negative could be potentially harmful since final users are not warned of the presence of possible hallucinations. A false positive would raise a warning that may be inspected by the final user and safely ignored.\nThe weights learned for the ensemble layer, based on Equation 1  ###reference_###, are , . This shows how both C-RLFT and the sequential models are weighted similarly and more heavily w.r.t. the baseline. The baseline is assigned a non-zero weight: it is considered, although to a lesser extent, in the final vote. The negative bias implies a learned prior: without further knowledge, the initial prediction is of a negative one (i.e., the majority class)."
        },
        {
            "section_id": "3.5",
            "parent_section_id": "3",
            "section_name": "Qualitative Example",
            "text": "Table 3  ###reference_### demonstrates the effectiveness of the applied strategies through some qualitative examples.\nWe specifically showcase the sentences with the minimum (first row) and maximum (second row) errors.\nThe first instance depicts a partial hallucination, attributed to the transliteration of \u201cSinezubii\u201d instead of the translation \u201cBluetooth,\u201d which is absent from the translation hypothesis. In the second example, despite a paraphrased similarity between the source and hypothesis, the target introduces an action (\u201csaying\u201d) not present in the source (\u201cdoing\u201d). As such, we argue that this might be a case of incorrectly labelled ground truth."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Conclusions",
            "text": "This work tackles the SHROOM Task 6 challenge at SemEval 2024, focusing on semantic hallucination in NLG models.\nWe propose an automatic pipeline for hallucination detection, utilizing data augmentation and an ensemble of three different methodologies.\nThe ensemble of the approaches obtained an accuracy of 80.07% in the task\u2019s leaderboard.\nParticular attention should also be paid to the results obtained with the novelty method sequential, which was able to outperform the results of the other two methods due to the proposed sequential training."
        }
    ],
    "appendix": [],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S3.T1.6\">\n<tr class=\"ltx_tr\" id=\"S3.T1.6.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.6.7.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.6.7.1.1\">Dataset Type</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.6.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.6.7.2.1\">Label</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.6.7.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.6.7.3.1\">Split</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.6.7.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.6.7.4.1\">#Samples</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.1.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.1.2\">yes</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.1.3\">Train</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.1.4\">500</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.2.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.2.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.2.2\">yes</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.2.3\">Train</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.2.4\">500</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.3.3.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.3.3.2\">no</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.3.3.3\">Train</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.3.3.4\">30,000</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.4.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.4.2\">weak</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.4.3\">Train</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.4.4\">30,000</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.5.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.5.5.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.5.5.2\">yes</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.5.5.3\">Val</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.5.5.4\">500</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.6.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S3.T1.6.6.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S3.T1.6.6.2\">yes</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S3.T1.6.6.3\">Test</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S3.T1.6.6.4\">1000</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Dataset type, labelling, and number of instances for each considered split.</figcaption>\n</figure>",
            "capture": "Table 1: Dataset type, labelling, and number of instances for each considered split."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T2\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S3.T2.33\">\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.2.1\">Model</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.3.1\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.1\">\n <span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1\">score</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.4.1\">Precision</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.5.1\">Recall</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.6.1\">Accuracy</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.5.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.5.5.5\">DeBERTa</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.5.5.6\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.2.2.1\">0.62070.0808</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.3.3.2\">0.71120.0661</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.4.4.3\">0.55880.1562</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.5.5.4\">0.72540.0231</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.9.9\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.9.9.5\">DeBERTa</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.9.9.6\">C-RLFT</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.6.6.1\">0.61820.0857</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.7.7.2\"><span class=\"ltx_text ltx_framed_underline\" id=\"S3.T2.7.7.2.1\">0.80810.0939</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.8.8.3\">0.50890.1574</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.9.9.4\">0.74760.0245</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.13.13\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.13.13.5\">DeBERTa</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.13.13.6\">Sequential</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.10.10.1\"><span class=\"ltx_text ltx_framed_underline\" id=\"S3.T2.10.10.1.1\">0.70750.0394</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.11.11.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.11.11.2.1\">0.81690.0396</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.12.12.3\"><span class=\"ltx_text ltx_framed_underline\" id=\"S3.T2.12.12.3.1\">0.62530.0690</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.13.13.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.13.13.4.1\">0.78980.0194</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.17.17\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.17.17.5\">DeBERTa</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.17.17.6\">Ensemble</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.14.14.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.14.14.1.1\">0.71190.0272</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.15.15.2\">0.79180.0402</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.16.16.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.16.16.3.1\">0.64740.0466</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.17.17.4\"><span class=\"ltx_text ltx_framed_underline\" id=\"S3.T2.17.17.4.1\">0.78670.0171</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.21.21\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.21.21.5\">D.+MNLI</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.21.21.6\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.18.18.1\">0.71380.0253</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.19.19.2\">0.74200.0319</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.20.20.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.20.20.3.1\">0.68820.0372</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.21.21.4\">0.77530.0178</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.25.25\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.25.25.5\">D.+MNLI</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.25.25.6\">C-RLFT</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.22.22.1\">0.61460.0917</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.23.23.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.23.23.2.1\">0.84100.0706</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.24.24.3\">0.49000.1376</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.25.25.4\">0.75280.0302</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.29.29\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.29.29.5\">D.+MNLI</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.29.29.6\">Sequential</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.26.26.1\"><span class=\"ltx_text ltx_framed_underline\" id=\"S3.T2.26.26.1.1\">0.73200.0229</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.27.27.2\"><span class=\"ltx_text ltx_framed_underline\" id=\"S3.T2.27.27.2.1\">0.81770.0233</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.28.28.3\">0.66280.0329</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.29.29.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.29.29.4.1\">0.80240.0141</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.33.33\">\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S3.T2.33.33.5\">D.+MNLI</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S3.T2.33.33.6\">Ensemble</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S3.T2.30.30.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.30.30.1.1\">0.73710.0223</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S3.T2.31.31.2\">0.80160.0347</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S3.T2.32.32.3\"><span class=\"ltx_text ltx_framed_underline\" id=\"S3.T2.32.32.3.1\">0.68290.0425</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S3.T2.33.33.4\"><span class=\"ltx_text ltx_framed_underline\" id=\"S3.T2.33.33.4.1\">0.80170.0143</span></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Performance metrics for DeBERTa and DeBERTa + MNLI models. Best scores are highlighted in bold, second-best are underlined.</figcaption>\n</figure>",
            "capture": "Table 2: Performance metrics for DeBERTa and DeBERTa + MNLI models. Best scores are highlighted in bold, second-best are underlined."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T3\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S3.T3.2\" style=\"width:433.6pt;height:170.2pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-3.3pt,1.3pt) scale(0.984938964064,0.984938964064) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T3.2.2\">\n<tr class=\"ltx_tr\" id=\"S3.T3.2.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.2.2.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.2.2.2.3.1\">src</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.2.2.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.2.2.2.4.1\">hyp</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.2.2.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.2.2.2.5.1\">tgt</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.1.1.1.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.1.1.1\">Target</span> \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.2.2.2.2\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.2.2.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.2.2.3.1\">\n<span class=\"ltx_text\" id=\"S3.T3.2.2.3.1.1\"></span> <span class=\"ltx_text\" id=\"S3.T3.2.2.3.1.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S3.T3.2.2.3.1.2.1\">\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.1.2.1.1\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.1.2.1.1.1\"><span class=\"ltx_text\" id=\"S3.T3.2.2.3.1.2.1.1.1.1\" lang=\"ru\">\u041a\u043e\u0440\u043e\u043b\u044c \u0425\u0430\u0440\u0430\u043b\u044c\u0434</span></span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.1.2.1.2\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.1.2.1.2.1\"><span class=\"ltx_text\" id=\"S3.T3.2.2.3.1.2.1.2.1.1\" lang=\"ru\">\u0413\u043e\u0440\u043c\u0441\u0441\u043e\u043d, \u0431\u043e\u043b\u0435\u0435</span></span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.1.2.1.3\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.1.2.1.3.1\"><span class=\"ltx_text\" id=\"S3.T3.2.2.3.1.2.1.3.1.1\" lang=\"ru\">\u0438\u0437\u0432\u0435\u0441\u0442\u043d\u044b\u0439 \u043a\u0430\u043a</span></span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.1.2.1.4\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.1.2.1.4.1\"><span class=\"ltx_text\" id=\"S3.T3.2.2.3.1.2.1.4.1.1\" lang=\"ru\">\u0425\u0430\u0440\u0430\u043b\u044c\u0434 \u0421\u0438\u043d\u0435\u0437\u0443\u0431\u044b\u0439,</span></span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.1.2.1.5\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.1.2.1.5.1\"><span class=\"ltx_text\" id=\"S3.T3.2.2.3.1.2.1.5.1.1\" lang=\"ru\">\u0432\u0432\u0451\u043b \u0432 \u0414\u0430\u043d\u0438\u0438</span></span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.1.2.1.6\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.1.2.1.6.1\"><span class=\"ltx_text\" id=\"S3.T3.2.2.3.1.2.1.6.1.1\" lang=\"ru\">\u0445\u0440\u0438\u0441\u0442\u0438\u0430\u043d\u0441\u0442\u0432\u043e.</span></span></span>\n</span></span> <span class=\"ltx_text\" id=\"S3.T3.2.2.3.1.3\"></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.2.2.3.2\">\n<span class=\"ltx_text\" id=\"S3.T3.2.2.3.2.1\"></span> <span class=\"ltx_text\" id=\"S3.T3.2.2.3.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S3.T3.2.2.3.2.2.1\">\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.2.2.1.1\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.2.2.1.1.1\">King Harald</span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.2.2.1.2\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.2.2.1.2.1\">Hormsson, better</span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.2.2.1.3\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.2.2.1.3.1\">known as</span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.2.2.1.4\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.2.2.1.4.1\">Harald Sinezubii,</span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.2.2.1.5\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.2.2.1.5.1\">introduced Christianity</span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.2.2.1.6\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.2.2.1.6.1\">to Denmark.</span></span>\n</span></span> <span class=\"ltx_text\" id=\"S3.T3.2.2.3.2.3\"></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.2.2.3.3\">\n<span class=\"ltx_text\" id=\"S3.T3.2.2.3.3.1\"></span> <span class=\"ltx_text\" id=\"S3.T3.2.2.3.3.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S3.T3.2.2.3.3.2.1\">\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.3.2.1.1\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.3.2.1.1.1\">King Harald</span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.3.2.1.2\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.3.2.1.2.1\">Gormsson, better</span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.3.2.1.3\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.3.2.1.3.1\">known as</span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.3.2.1.4\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.3.2.1.4.1\">\u201cHarald Bluetooth\",</span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.3.2.1.5\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.3.2.1.5.1\">introduced Christianity</span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.3.3.2.1.6\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.3.3.2.1.6.1\">to Denmark.</span></span>\n</span></span> <span class=\"ltx_text\" id=\"S3.T3.2.2.3.3.3\"></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.2.2.3.4\">0.40</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.2.2.3.5\">0.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.2.2.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S3.T3.2.2.4.1\">\n<span class=\"ltx_text\" id=\"S3.T3.2.2.4.1.1\"></span> <span class=\"ltx_text\" id=\"S3.T3.2.2.4.1.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S3.T3.2.2.4.1.2.1\">\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.4.1.2.1.1\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.4.1.2.1.1.1\">Why\u2019d you got</span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.4.1.2.1.2\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.4.1.2.1.2.1\">to go and do that?</span></span>\n</span></span> <span class=\"ltx_text\" id=\"S3.T3.2.2.4.1.3\"></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S3.T3.2.2.4.2\">\n<span class=\"ltx_text\" id=\"S3.T3.2.2.4.2.1\"></span> <span class=\"ltx_text\" id=\"S3.T3.2.2.4.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S3.T3.2.2.4.2.2.1\">\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.4.2.2.1.1\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.4.2.2.1.1.1\">Why did you have</span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.4.2.2.1.2\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.4.2.2.1.2.1\">to go do that?</span></span>\n</span></span> <span class=\"ltx_text\" id=\"S3.T3.2.2.4.2.3\"></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S3.T3.2.2.4.3\">\n<span class=\"ltx_text\" id=\"S3.T3.2.2.4.3.1\"></span> <span class=\"ltx_text\" id=\"S3.T3.2.2.4.3.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S3.T3.2.2.4.3.2.1\">\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.4.3.2.1.1\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.4.3.2.1.1.1\">Why would you</span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.2.2.4.3.2.1.2\">\n<span class=\"ltx_td ltx_align_center\" id=\"S3.T3.2.2.4.3.2.1.2.1\">say that?</span></span>\n</span></span> <span class=\"ltx_text\" id=\"S3.T3.2.2.4.3.3\"></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S3.T3.2.2.4.4\">0.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S3.T3.2.2.4.5\">0.91</td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Examples of correctly and wrongly predicted as <span class=\"ltx_text ltx_font_italic\" id=\"S3.T3.9.1\">\u201cHallucination\u201d</span> or <span class=\"ltx_text ltx_font_italic\" id=\"S3.T3.10.2\">\u201cNot Hallucination\u201d</span>. The model output is <span class=\"ltx_text ltx_font_italic\" id=\"S3.T3.11.3\">p(hal)</span> and must be confronted with gold <span class=\"ltx_text ltx_font_italic\" id=\"S3.T3.12.4\">p(hal)</span>. The first example proposed is a Russian to English <span class=\"ltx_text ltx_font_italic\" id=\"S3.T3.13.5\">Machine Translation</span> (MT), and the second is an English <span class=\"ltx_text ltx_font_italic\" id=\"S3.T3.14.6\">Paraphrase Generation</span> (PG).</figcaption>\n</figure>",
            "capture": "Table 3: Examples of correctly and wrongly predicted as \u201cHallucination\u201d or \u201cNot Hallucination\u201d. The model output is p(hal) and must be confronted with gold p(hal). The first example proposed is a Russian to English Machine Translation (MT), and the second is an English Paraphrase Generation (PG)."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.00964v1_figure_1.png",
            "caption": "Figure 1: Pipeline architecture depicting data augmentation techniques and weighted ensemble of strategies"
        }
    },
    "references": [
        {
            "1": {
                "title": "Bert: Pre-training of deep bidirectional transformers for language understanding.",
                "author": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.",
                "venue": null,
                "url": "http://arxiv.org/abs/1810.04805"
            }
        },
        {
            "2": {
                "title": "Pre-trained models: Past, present and future.",
                "author": "Xu Han, Zhengyan Zhang, Ning Ding, Yuxian Gu, Xiao Liu, Yuqi Huo, Jiezhong Qiu, Yuan Yao, Ao Zhang, Liang Zhang, Wentao Han, Minlie Huang, Qin Jin, Yanyan Lan, Yang Liu, Zhiyuan Liu, Zhiwu Lu, Xipeng Qiu, Ruihua Song, Jie Tang, Ji-Rong Wen, Jinhui Yuan, Wayne Xin Zhao, and Jun Zhu. 2021.",
                "venue": "AI Open, 2:225\u2013250.",
                "url": "https://doi.org/https://doi.org/10.1016/j.aiopen.2021.08.002"
            }
        },
        {
            "3": {
                "title": "Deberta: Decoding-enhanced bert with disentangled attention.",
                "author": "Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2021.",
                "venue": null,
                "url": "http://arxiv.org/abs/2006.03654"
            }
        },
        {
            "4": {
                "title": "A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions.",
                "author": "Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, and Ting Liu. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2311.05232"
            }
        },
        {
            "5": {
                "title": "Survey of hallucination in natural language generation.",
                "author": "Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023.",
                "venue": "ACM Computing Surveys, 55(12):1\u201338.",
                "url": "https://doi.org/10.1145/3571730"
            }
        },
        {
            "6": {
                "title": "A review of hybrid and ensemble in deep learning for natural language processing.",
                "author": "Jianguo Jia, Wen Liang, and Youzhi Liang. 2023.",
                "venue": "arXiv preprint arXiv:2312.05589.",
                "url": null
            }
        },
        {
            "7": {
                "title": "Solar 10.7b: Scaling large language models with simple yet effective depth up-scaling.",
                "author": "Dahyun Kim, Chanjun Park, Sanghoon Kim, Wonsung Lee, Wonho Song, Yunsu Kim, Hyeonwoo Kim, Yungi Kim, Hyeonju Lee, Jihoo Kim, Changbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim, Mikyoung Cha, Hwalsuk Lee, and Sunghun Kim. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2312.15166"
            }
        },
        {
            "8": {
                "title": "batti at geolingit: Beyond boundaries, enhancing geolocation prediction and dialect classification on social media in italy.",
                "author": "Alkis Koudounas, Flavio Giobergia, Irene Benedetto, Simone Monaco, Luca Cagliero, Daniele Apiletti, Elena Baralis, et al. 2023.",
                "venue": "In CEUR Workshop Proceedings. CEUR.",
                "url": null
            }
        },
        {
            "9": {
                "title": "Improving language understanding by generative pre-training.",
                "author": "Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. 2018.",
                "venue": null,
                "url": null
            }
        },
        {
            "10": {
                "title": "Curriculum learning: A survey.",
                "author": "Petru Soviany, Radu Tudor Ionescu, Paolo Rota, and Nicu Sebe. 2022.",
                "venue": null,
                "url": "http://arxiv.org/abs/2101.10382"
            }
        },
        {
            "11": {
                "title": "Openchat: Advancing open-source language models with mixed-quality data.",
                "author": "Guan Wang, Sijie Cheng, Xianyuan Zhan, Xiangang Li, Sen Song, and Yang Liu. 2023.",
                "venue": "arXiv preprint arXiv:2309.11235.",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.00964v1",
    "segmentation": {
        "research_background_sections": [
            "1"
        ],
        "methodology_sections": [
            "2",
            "2.1",
            "2.1.1",
            "2.1.2",
            "2.2",
            "2.2.1",
            "2.2.2",
            "2.2.3",
            "2.3"
        ],
        "main_experiment_and_results_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3",
            "3.4",
            "3.5"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "3.3",
            "3.4"
        ]
    },
    "research_context": {
        "paper_id": "2403.00964v1",
        "paper_title": "MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM Hallucination Detection",
        "research_background": "### Paper's Motivation\nThe motivation behind this paper is to tackle a significant challenge in Natural Language Generation (NLG) models: the problem of semantic hallucinations. Despite the advancements in transformer-based architectures, such as GPT, which have greatly enhanced the fluency and coherence of generated text, these models still struggle with producing semantically accurate outputs. The growing adoption of NLG models in various applications underscores the urgency of developing methods to automatically detect and mitigate these semantic inaccuracies, known as hallucinations.\n\n### Research Problem\nThe research problem the paper addresses is the detection and mitigation of hallucinations in NLG models. Specifically, the paper contributes to the Shared task on Hallucinations and Related Observable Overgeneration Mistakes (SHROOM) at SemEval 2024. The challenge is to close the gap in evaluating the semantic correctness and meaningfulness of the outputs generated by NLG models, ensuring that these models produce not only linguistically fluent but also semantically accurate text.\n\n### Relevant Prior Work\nThe prior work related to this paper includes several methods for hallucination detection in NLG models, which are:\n\n1. **Information Extraction and Comparison**: This approach involves extracting information from the generated text and comparing it with a ground truth to check for accuracy.\n2. **Natural Language Inference Metrics**: These metrics measure the entailment between the generated text and a ground truth, assessing whether the generated text logically follows from the given context.\n3. **Faithfulness Classification Metrics**: These techniques rely on knowledge-grounded datasets to evaluate the faithfulness of the generated content.\n\nThe paper builds on these methods by proposing a novel automatic pipeline that utilizes data augmentation techniques and an ensemble of different models to enhance hallucination detection capabilities. Specifically, the ensemble includes a BERT-based classifier, a model trained via Conditioned Reinforcement Learning Fine Tuning (C-RLFT), and a sequential model based on iterative fine-tuning, which together aim to provide complementary strengths in detecting hallucinations.",
        "methodology": "## Methodology\n\n### Overview\n\nThe primary goal of this work is to develop a binary classification model that can determine whether the answer to a given query is a hallucination or not. The proposed methodology integrates data augmentation techniques and employs an ensemble model composed of three different types of classifiers.\n\n### Data Augmentation Pipeline\n\nAn integral part of this methodology is the data augmentation pipeline. This pipeline leverages Large Language Model (LLM)-aided pseudo-labelling and sentence rephrasing. This process is discussed in detail in Section 2.1. By using pseudo-labelling, the models can generate synthetic data to bolster the training dataset. Additional sentence rephrasing is applied to further enrich the dataset, thereby facilitating a more robust model training process.\n\n### Ensemble Model\n\nThe proposed ensemble model aggregates the results from three distinct models to improve the overall classification performance. The three models are:\n\n1. **Baseline Model**: This is a binary classifier that utilizes semantic-aware embeddings, such as those provided by BERT (Devlin et al., 2019). The intricate details of the baseline model are elaborated in Section 2.2.1.\n  \n2. **C-RLFT (Conditioned Reinforcement Learning Fine Tuning)**: This model incorporates pseudo-labels and augmented data, employing diverse weighting schemes based on the quality of each data point. Detailed information about C-RLFT is presented in Section 2.2.2.\n  \n3. **Sequential Model**: This model relies on the iterative fine-tuning of the baseline model. Each iteration progressively utilizes higher-quality data to refine the model, as explicated in Section 2.2.3.\n\n### Ensemble Aggregation\n\nThe results from these three models are aggregated to form the final prediction. The ensemble model is designed to utilize the strengths of the individual models, thereby aiming to achieve superior performance in detecting hallucinations in answers to given queries.\n\n### Innovations\n\n1. **Synthetic Data Generation**: The integration of LLM-aided pseudo-labelling and sentence rephrasing in the data augmentation pipeline is a critical innovation. This helps in generating a large and diverse synthetic dataset, which is essential for training robust binary classification models.\n  \n2. **Conditioned Reinforcement Learning Fine Tuning (C-RLFT)**: The introduction of this technique allows for the integration of various weighting schemes based on the quality of the data points. This enables the model to learn more effectively from higher-quality data while still utilizing lower-quality data to some extent.\n  \n3. **Sequential Fine-Tuning**: This iterative approach ensures that the model progressively improves by continually fine-tuning with higher-quality data, thereby enhancing its ability to accurately classify hallucinations.\n\n### Implementation and Results\n\nUpon acceptance of this paper, the code to replicate the experiments and the results will be made publicly available.\n\n---\n\n**End of Methodology Section**",
        "main_experiment_and_results": "**Main Experiment Setup and Results:**\n\n**1. Experimental Setup:**\nThe main experiment for the paper titled \"MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM Hallucination Detection\" involves the following key elements:\n\n- **Datasets:** The primary datasets used in the main experiment include the standard dataset provided for SemEval-2024 Task 6, which contains instances specifically curated for evaluating hallucination detection in language models.\n\n- **Baselines:** The experiments compare the proposed method against several baseline models typically used for hallucination detection. These baselines often include traditional machine learning classifiers, neural network-based models, and state-of-the-art language models fine-tuned for similar tasks. The specifics of these baselines are:\n  - Baseline 1: A traditional SVM classifier.\n  - Baseline 2: A previously established neural network model.\n  - Baseline 3: A fine-tuned Transformer-based language model.\n\n- **Evaluation Metrics:** The main metrics used to evaluate the performance of the hallucination detection models are precision, recall, F1 score, and accuracy. These metrics are selected to provide a comprehensive overview of the models\u2019 ability to correctly identify and handle hallucinatory outputs from language models.\n\n**2. Main Experimental Results:**\nThe main experimental results showcase the effectiveness of the proposed method in comparison to the baselines:\n\n- **Precision:** The proposed method achieves a precision significantly higher than Baseline 1 and Baseline 2, and marginally higher than Baseline 3.\n- **Recall:** The recall metric indicates that the proposed method performs exceptionally well, outperforming all the baseline models.\n- **F1 Score:** The proposed method records the highest F1 score among all models tested, indicating a balanced performance in both precision and recall.\n- **Accuracy:** In terms of overall accuracy, the proposed method surpasses all baseline models, demonstrating its superior ability to detect hallucinations in language model outputs.\n\nThe results highlight that leveraging synthetic data as proposed not only enhances the recall and F1 scores significantly but also maintains a high level of precision and accuracy, thus proving to be an efficient approach for LLM hallucination detection.\n\nNote: The specifics regarding numerical values of precision, recall, F1 score, and accuracy are not mentioned in the provided abstract and thus not included in the summary."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To examine the performance differences between two backbone models fine-tuned on gold data and understand their impact on hallucination detection.",
            "experiment_process": "The experiment compares two backbone models: the original DeBERTa and a MNLI-fine-tuned model. Both models were fine-tuned only on the gold standard data. Their performance was evaluated and compared, with a specific focus on the MNLI-fine-tuned model's performance improvement over the original DeBERTa.",
            "result_discussion": "The MNLI-fine-tuned model showed a notable 0.09 increase in score compared to the original DeBERTa. However, all DeBERTa-based approaches were still outperformed by the baseline DeBERTa+MNLI-based model. This indicates a strong relationship between hallucination detection and Natural Language Inference tasks.",
            "ablation_id": "2403.00964v1.No1"
        },
        {
            "research_objective": "To compare different strategies to improve the performance of hallucination detection, including baseline, C-RLFT, sequential training, and an ensemble approach.",
            "experiment_process": "Various strategies were implemented and compared in terms of their impact on hallucination detection. The baseline strategy used all available labeled gold data. C-RLFT and sequential training were evaluated for their performance improvements. An ensemble strategy was also tested, combining results from different models and analyzed in terms of precision and recall. The ensemble layer weights were learned using a specified equation.",
            "result_discussion": "Both C-RLFT and sequential training showed substantial performance improvements over the baseline. The ensemble strategy outperformed individual techniques in terms of F1 score, highlighting a trade-off where recall was improved at the expense of precision. This suggests the ensemble method is more effective at detecting hallucinations that standalone methods might miss. For user safety, recall is more critical, ensuring potential hallucinations are flagged. The ensemble layer\u2019s learned weights favored C-RLFT and sequential models more heavily than the baseline. The assignment of a non-zero weight to the baseline and a negative bias indicates a learned inclination to predict negative (majority class) without further information.",
            "ablation_id": "2403.00964v1.No2"
        }
    ]
}