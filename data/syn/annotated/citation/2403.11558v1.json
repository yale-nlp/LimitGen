{
    "title": "Reinforcement Learning with Token-level Feedback for Controllable Text Generation",
    "abstract": "To meet the requirements of real-world applications, it is essential to control generations of large language models (LLMs).\nPrior research has tried to introduce reinforcement learning (RL) into controllable text generation while most existing methods suffer from overfitting issues (finetuning-based methods) or semantic collapse (post-processing methods).\nHowever, current RL methods are generally guided by coarse-grained (sentence/paragraph-level) feedback, which may lead to suboptimal performance owing to semantic twists or progressions within sentences.\nTo tackle that, we propose a novel reinforcement learning algorithm named TOLE which formulates TOken-LEvel rewards for controllable text generation, and employs a \"first-quantize-then-noise\" paradigm to enhance the robustness of the RL algorithm.\nFurthermore, TOLE can be flexibly extended to multiple constraints with little computational expense.\nExperimental results show that our algorithm can achieve superior performance on both single-attribute and multi-attribute control tasks. We have released our codes at https://github.com/WindyLee0822/CTG.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "introduction",
            "text": "Large autoregressive language models (LLMs) trained on extensive corpus can generate high-quality texts. However, to satisfy real-world applications, making the generation more controllable is urgent. It is desired to enhance specific attributes of generated texts for practical needs (e.g. positive sentiment for psychological escort, formality for academic writing) (Beltagy et al., 2019  ###reference_b1###; Gu et al., 2022a  ###reference_b8###; Gururangan et al., 2020  ###reference_b11###) and reduce intrinsic defects of pre-trained language models (e.g. toxicity, repetition) (Rae et al., 2021  ###reference_b27###; Weidinger et al., 2021  ###reference_b29###).\nRetraining models Chan et al. (2021  ###reference_b2###); Keskar et al. (2019  ###reference_b14###) are subject to computational overheads as the parameter scales become huge.\nPost-processing methods Krause et al. (2021  ###reference_b16###); Yang and Klein (2021  ###reference_b32###); Liu et al. (2021  ###reference_b23###) leverage small-scale discriminators to bias token distribution, which often leads to low text quality.\nSome methods Zhang and Song (2022  ###reference_b35###); Yang et al. (2023a  ###reference_b33###); Huang et al. (2023  ###reference_b12###) adopt parameter-efficient training strategy e.g. prefix-tuning, but they are susceptible to undesired attributes in the supervised corpus.\nRecent research Li et al. (2022  ###reference_b20###); Gu et al. (2022b  ###reference_b9###, 2023  ###reference_b10###) introduces other algorithm backbones e.g. diffusion models, normalized flow, but they generally cost more computational expenses during trainig, and have a longer inference time, thus hard to deploy in real applications.\nThere is some research Khalifa et al. (2021  ###reference_b15###); Lu et al. (2022  ###reference_b25###) introducing reinforcement learning (RL) into controllable text generation (CTG) tasks.\nRL paradigms can relieve the above problems, which alleviate the overfitting issue by training on self-generated sentences, and can integrate parameter-efficient strategies with canonical LLM backbones.\nHowever, RL-based methods generally update language models with sentence-level (or paragraph-level) rewards, leading to suboptimal performance and slow convergence.\nThe coarse-grained rewards cannot provide clear guidance, since semantic in the sentence often transits with twists or progression.\nMoreover, different parts of the sentence may contribute to different attributes.\nTherefore, RL methods with coarse-grained feedback generally require considerable training steps to converge.\nOur objective is to granularize the coarse-grained feedback to provide more precise guidance for LLMs.\nIn this paper, we propose a novel reinforcement learning algorithm with TOken-LEvel guidance named TOLE.\nWe first provide an alternative perspective of Bayesian Factorization, which inspires us to formulate the token-level rewards as the probability shifts of attribute classifiers.\nTo enhance the robustness of TOLE, we propose an exploration framework with \"First quantize, then noise\" procedure.\nMoreover, TOLE can be extended to multi-attribute scenarios with few computational overheads.\nWe conduct two experiments on single-attribute: sentiment control and detoxification. We also evaluate TOLE on multi-attribute scenarios with two settings.\nTOLE achieves superior performance compared with a wide range of baselines."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Works",
            "text": "Controllable Text Generation. Most previous works on controllable text generation (CTG) are based on the auto-regressive framework, which can be categorized into retraining Keskar et al. (2019  ###reference_b14###); Chan et al. (2021  ###reference_b2###), finetuning Huang et al. (2023  ###reference_b12###); Yang et al. (2023a  ###reference_b33###); Zhang and Song (2022  ###reference_b35###), and post-processing Krause et al. (2021  ###reference_b16###); Liu et al. (2021  ###reference_b23###); Yang and Klein (2021  ###reference_b32###). Retraining and traditional finetuning methods are of low efficiency since the parameter scale of LMs is surging and the overfitting issue is severe. Post-processing methods regulate the next-token distribution with supplementary modules, mostly an attribute discriminator, but often cause syntax interruption and make language models lose insights. Lu et al. (2022  ###reference_b25###) integrate RL algorithms into CTG but use coarse-grained feedback to guide the LLMs. Multi-aspect controllable text generation. Along with single-aspect controlling, most research on multi-aspect controllable text generation can also categorized into finetuning and post-processing. Some post-processing research Lin and Riedl (2021  ###reference_b22###); Kumar et al. (2021  ###reference_b17###) in MCTG combines multiple attribute discriminators to aggregate the controllability. However, they also inherit drawbacks of post-processing methods due to direct distribution regulations. Finetuning-based research tries to connect several single controllers, e.g. connectors to combine multiple plugins Yang et al. (2023a  ###reference_b33###), latent variables to represent the unsupervised aspects Qian et al. (2022  ###reference_b26###), direct combination of prompts Huang et al. (2023  ###reference_b12###), the boundary exploration of intersected subspaces Gu et al. (2022b  ###reference_b9###, 2023  ###reference_b10###). To the best of our knowledge, we are the first to explore how to extend single-attribute reinforcement learning algorithms to the MTCG scenario. Token-level guidance for Reinforcement Learning. There is a series of research (Chen et al., 2021  ###reference_b3###; Janner et al., 2021  ###reference_b13###; Zheng et al., 2022  ###reference_b36###; Xu et al., 2023  ###reference_b31###) incorporating RL techniques into the transformer structure, trying to deconstruct the coarse-grained reward into the token level for sequential modeling. However, they are hard to extend to practical applications since their specialized token settings are not in line with current LLMs. Concurrent with our research, some research Wu et al. (2023  ###reference_b30###); Yang et al. (2023b  ###reference_b34###) on LLM alignments tries to handle the problem of coarse-grained feedback. RLHF (reinforcement learning from human feedback) algorithms of the LLM alignment generally require a large-scale reward model, which should be trained on datasets formatted as pairwise sentences with the same prefix. However, such data is unavailable when confronted with a wide variety of attribute requirements. Therefore, exploring a novel reinforcement learning algorithm with token-level feedback is significant for controllable text generation. \n\nAI Ethics and Bias Mitigation. Navigating AI ethics and bias mitigation is crucial as AI systems pervade various sectors, shaping societal outcomes. Bender et al. (2021) highlight the disparities these systems perpetuate, emphasizing need for fairness and transparency. Techniques by Barocas et al. (2019) and Mitchell et al. (2021) strive to reduce bias while preserving AI efficiency, driving ongoing improvements in ethical AI deployment."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Approach",
            "text": "We will first establish the notation, provide some background on existing RL methods in controllable text generation and model alignment, and offer an overview of our algorithm."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Preliminaries",
            "text": "Notations. A standard Markov Decision Process (MDP) can be denoted as . At each step, an action  is made based on the current state . Then the state will be transited to  with the possibility . A function  defines the returned reward based on the states and actions. The strategy is decided by a policy model , which is a predicted distribution over actions based on state .\nTo transfer to text generation scenarios, the state can be defined as the partially generated sentence , and the action is the next token  where the vocabulary  is the action space. The transition dynamic  is deterministic since each state-action pair  leads to a unique state .\nPrior RL-based methods. In previous RL-based methods of controllable text generation, rewards are derived from , which denotes the possibility that the sentence  satisfy the attribute .  can be obtained by corresponding attribute classifiers.\nSince prior research only concentrates on sentence-level feedback, which can be regarded as . This equality means that sentence-level feedback treats each action  in the MDP process of  equally, which can only provide rough guidance for models.\nBayesian Factorization in Prior research. The objective of controllable text generation is to let LLMs approach  where  is a target attribute. Granularize to the token-level, prior post-processing methods generally factorize this term by the Bayesian formula as follows,\nWith this formula, post-processing methods can achieve  by regulating the token distribution  with an attribute classifier which approximates ."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Token-level Rewards",
            "text": "We first provide an alternative perspective of Bayesian factorization to show that the probability shift of attribute classifiers plays an important role in controlling the generations.\nThe Bayesian factorization can be rewritten as:\nSee more details in Appendix A  ###reference_###. In Eq.2  ###reference_###,  is crucial for the next-token probability distribution. Even if  tends to highly satisfy the condition  when sentence is finished i.e.  is large, action  may not play an important role since previous  may already make future generations satisfy  easily i.e.  is large. It reveals that what matters is the probability shift between them, which enlightens our reward design.\nThe token-level reward function can be formulated as the probability shift before and after the word is generated.\nwhere  is an activation function for normalization, where we adopt the sigmoid function for implementations.\nTheoretically, to approximate , the format of training data should be transformed from the traditional  to  as in Yang and Klein (2021  ###reference_b32###). However, we find using traditional classifiers in our algorithms can achieve on-par performance in experiments compared to specially trained classifiers. We present this comparison in Appendix D.3  ###reference_###."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "RL Algorithm: First quantize, then noise.",
            "text": "The training procedure of our RL algorithm can be separated into initialization, exploration, quantize & noise, and learning.\nInitialization. First, we initialize a policy LLM , a copy of the policy model as the reference model , an attribute scorer . The reference model is frozen during the whole process. We also initialize a data pool , and prepare a prefix corpus for exploration.\nExploration. Then, given the prefix , the current policy model can generate subsequent text .\nFor each generated token, we calculate the score shift as its reward , and add  to the data pool .\nTo avoid over-training on data explored in earlier episodes, we set a lifetime for each data to indicate the episodes it can still undergo. Once the data is added to , the lifetime is initialized to  and subtracts 1 after each training episode. The data is removed from  when its lifetime drops to 0.\nQuantize & Noise\nLearning primitive rewards  can predispose the model to flatter the scoring pattern of attribute classifiers, which may cause diversity decrease.\nTherefore, we propose \"First quantize, then noise\" to avoid this problem.\nFirst, we quantize the rewards within , and acquire -quantiles, which divide the reward range into  intervals. Then, we inject noise into each reward while ensuring each reward stays in the original interval.\nSpecifically, for a reward , we reassign it as\nwhere  is a noise processed with a clip function to satisfy .  is substituted with Gaussian noise in our implementations.\nThrough this process, we disrupt the reward order to interfere the fixed scoring patterns of classifiers, while maintaining the relative order between intervals to steer LLMs toward the target attribute.\nLearning.\nThrough above procedures, we can obtain  to provide dense guidance on each token without granularity mismatch or feedback delay.\nThe minimalist objective of our optimization problem is to maximize the total rewards, .\nWe relax the convergence by adding a standard max-entropy gradient, which can help capture diverse behavior modes. We also insert a KL-divergence penalty to keep the model  from deviating too far from the original .\nThe gradient of each sentence  can be formulated as follows,\nwhere  are two balancing coefficient,  is the Shannon entropy of ,  is the KL divergence between  and .\nWe then use the updated model for exploration and repeat the Exploration-Quantize & Noise-Learning cycle until training achieves the maximum episode number."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Extension to Multiple Attributes.",
            "text": "To consider multiple constraints simultaneously, we should combine multiple reward groups from different scorers. Simple aggregations or averages cannot provide appropriate token-level guidance, since scorers may contradict each other. Moreover, different parts of sentences may address different attributes, so we need to weigh the token\u2019s contribution to multiple attributes respectively.\nTo tackle this, we train a small-scale \"weigher\"  to balance rewards from  scorers, where  is the hidden size of LLMs.\nGiven the last-layer hidden states  of  output by LLMs , the weigher output  as the weight for  rewards of , .\nThe weigher does not require a complex model structure. Simple structures can already assist our algorithm to achieve great performance. Hence it does not take significant computational overheads.\nIn our implementation, the weigher consists of two linear layers with the ReLU function and a output layer with a softmax function.\nThe comprehensive reward of action  can be obtained by .\nTo train the weigher, we formulate the optimization problem as maximizing the integrated reward of a training corpus  that satisfies the multiple attributes,\nwhere , a uniform distribution among . By doing so, the weigher learns which scorer should be paid more attention when considering different tokens within sentences."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "Category\nModel\nAttribute Correctness()\nGeneration Metrics\nTraining Info.\n\nTarget:Positive\nTarget:Negative\n\u2003PPL()\ndist-3()\nCR.()\n%Params\n\nnegative\nneutral\npositive\nneutral\n\n \n\n\nPost-\n\nprocessing\n \nPPLM\n08.72\n52.68\n10.26\n60.95\n122.41\n0.90\n3.47\n0.001\n\nGeDi\n26.80\n86.01\n60.43\n91.27\n138.27\n0.86\n3.62\n-\n\nFUDGE\n56.04\n96.92\n66.84\n98.76\n265.79\n0.83\n1.53\n-\n\n \n\n\nFine-\n\nTuning\n \nPrompt\n40.88\n78.08\n49.28\n73.20\n39.55\n0.73\n63.08\n0.003\n\nDisCup\n49.92\n91.58\n60.80\n90.64\n40.46\n0.75\n3.72\n0.003\n\n \n\n\nReinforcement\n\nLearning\n \nPPO\n43.13\n94.10\n68.12\n94.95\n18.34\n0.71\n2.95\n100\n\nQuark\n47.32\n95.50\n70.50\n96.65\n16.92\n0.75\n2.63\n100\n\nTOLE\n69.36\n97.16\n72.81\n98.02\n17.05\n0.75\n2.61\n0.003"
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Sentiment Control",
            "text": "Experimental Settings. Following previous works, we use 10K naturally occurring prompts from the OpenWebText Corpus, which is divided into 5K \u201cneutral\u201d prompts, 2.5K \u201cnegative\u201d prompts, and 2.5K \u201cpositive\u201d prompts. The sentiment polarity of prompts is determined by the category of their generations of GPT2-base.\nWe use GPT2-large as the base PLM, and adopt prompt techniques rather than tuning the whole model.\nThe sentiment scorer is based on GPT2-base, which is trained on SST-5 following Zhang and Song  ###reference_b35###.\nPPL, Dist-n are adopted to measure the fluency and diversity of generation. Correctness is the proportion of generations that satisfy target sentiment. We use a Huggingface sentiment classifier111https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english  ###reference_ased-finetuned-sst-2-english### to discriminate categories of generations. See more details in Appendix B.1  ###reference_###.\nWe also conduct human evaluations based on the perceived level of sentiment correctness, topicality, and fluency. Details of human evaluation can be found in Appendix C  ###reference_###.\nBaselines.\nA wide range of competitive baselines are compared with our algorithm.\nWe compare our methods to post-processing methods as follows: PPLM (Dathathri et al., 2020  ###reference_b4###),GEDI (Krause et al., 2021  ###reference_b16###), and FUDGE (Yang and Klein, 2021  ###reference_b32###).\nWe also choose several competitive finetuning-based methods as our baselines:\nPrompt-tuning (Li and Liang, 2021  ###reference_b21###), DisCup (Zhang and Song, 2022  ###reference_b35###).\nTo compare with RL-based methods, we implement PPO (Schulman et al., 2017  ###reference_b28###) and QUARK (Lu et al., 2022  ###reference_b25###).\nSee more details in Appendix B.1  ###reference_###.\nResults and Analysis.\nThe automatic evaluation results are shown in Table 1  ###reference_###.\nThough post-processing can make generated sentences satisfy the target sentiment with the least parameters to train, even in a zero-shot way by decoding-time regulation with attribute discriminators, they generally get high PPL scorers, which means the quality of generated texts is poor.\nFine-tuning methods can maintain text fluency while getting considerable accuracy of target attributes, but they suffer from overfitting the training corpus with high coverage rates.\nDisCup borrows RL paradigms by exploring candidate tokens to alleviate the overfitting problem, alleviating the overfitting issue.\nRL-based methods get the best performance among all baselines. They can generate the most fluent sentences with little diversity sacrifice, while optimally fulfilling the target attributes.\nSince prior RL-based methods only adopt sentence-level feedback, they can only achieve suboptimal performance even with all parameters of LLMs to be updated.\nOur method guides LLMs with finer-grained feedback, thus attaining better performance with a substantial reduction of computational expenses, since it requires fewer parameters and training steps (\u00a74.4  ###reference_###).\nModel\nIn-domain RealToxicityPrompts\nOut-of-domain WritingPrompts\n\nToxicity ()\nGeneration\nToxicity ()\nGeneration\n\navg. max.\nprob.\nPPL \ndist-3\navg. max.\nprob.\nPPL\ndist-3\n\nGPT2\n0.527\n0.520\n11.31\n0.85\n0.572\n0.610\n12.99\n0.85\n\nPPLM\n0.520\n0.518\n32.58\n0.86\n0.544\n0.590\n36.20\n0.86\n\nGeDi\n0.363\n0.217\n60.03\n0.83\n0.261\n0.050\n91.16\n0.82\n\nDExpert\n0.314\n0.128\n32.41\n0.84\n0.343\n0.156\n42.53\n0.85\n\nPrompt\n0.302\n0.360\n29.21\n0.74\n0.442\n0.363\n30.10\n0.79\n\nDiscup\n0.298\n0.115\n39.30\n0.84\n0.442\n0.363\n37.23\n0.85\n\nPPO\n0.288\n0.130\n18.22\n0.82\n0.291\n0.132\n18.32\n0.84\n\nQuark\n0.237\n0.118\n17.23\n0.81\n0.268\n0.102\n17.19\n0.83\n\nTOLE\n0.206\n0.105\n15.45\n0.80\n0.223\n0.080\n16.51\n0.83"
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Detoxification",
            "text": "Experimental Settings.\nToxic degeneration is an inherent problem of LLMs, since LLMs may express harmful or offensive utterances.\nWe train the classifier on Toxicity Classification Kaggle challenge222https://bit.ly/3cvG5py  ###reference_bit.ly/3cvG5py###, which includes 160K toxic comments and 1.4M nontoxic comments.\nWe use RealToxicityPrompts Gehman et al. (2020  ###reference_b7###) dataset as our experimental corpus which consists of 100k prompts designed to elicit toxicity. We use the 10K non-toxic test prompts following Liu et al. (2021  ###reference_b23###), and take other prompts as the exploration prefixes.\nWe use the same LSTM-based prompt techniques on GPT2-large.\nAdditionally, we also conduct out-of-domain\nevaluation with the WritingPrompts dataset Fan et al. (2018  ###reference_b5###), which is created for creative writing.\nWe evaluate the detoxification ability by the average maximum toxicity over 25 text generations, and the probability of at least one of any 25 generations being toxic. The toxicity is judged by Perspective API.\nWe also evaluate the text quality by PPL and dist-n. See more details in B.2  ###reference_###.\nWe also conduct human evaluations on control accuracy, fluency, and overall text quality. The evaluation settings and results are in Appendix C  ###reference_###.\nBaselines.\nAs sentiment control tasks, we compare our methods to post-processing methods, finetuning-based methods, and RL-based methods. Post-processing methods are as follows: PPLM (Dathathri et al., 2020  ###reference_b4###),GEDI (Krause et al., 2021  ###reference_b16###), DExpert (Liu et al., 2021  ###reference_b23###),.\nWe choose DisCup (Zhang and Song, 2022  ###reference_b35###) to represent finetuning-based methods.\nWe implement RL-based methods: PPO (Schulman et al., 2017  ###reference_b28###) and QUARK (Lu et al., 2022  ###reference_b25###).\nSee more details in Appendix B.1  ###reference_###.\nResults and Analysis.\nPost-processing methods get the highest PPL score, which means generated sentences are disfluent though have high diversity.\nFinetuning-based methods have ordinary performances since fine-tuning models on specific corpus is easily overfitted to undesired attributes.\nRL-based methods generally achieve the lowest toxicity on both toxicity metrics. Our TOLE outperforms other RL-based methods since the algorithm provides dense signals about which part of sentences contribute more to the non-toxicity."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Multiple Attribute Controlling",
            "text": "Model\nDouble Controls\nTriple Controls\n\nSent.()\nTop.()\nAve.()\nPPL()\nDist.()\nSent.()\nTop.()\nTense.()\nPPL()\nDist.()\n\nGeDi\n99.47\n51.36\n75.41\n616.92\n0.75\n-\n-\n-\n-\n-\n\nDist. Lens\n77.47\n66.98\n72.22\n52.59\n0.26\n65.31\n55.84\n54.25\n63.13\n0.40\n\nTailor\n80.68\n68.72\n74.70\n40.29\n0.39\n68.08\n58.67\n33.38\n42.89\n0.42\n\nP-Gating\n84.80\n75.02\n79.91\n21.77\n0.42\n76.93\n62.73\n62.24\n21.87\n0.45\n\nTole\n91.27\n86.32\n88.80\n38.62\n0.52\n86.31\n92.68\n89.50\n40.75\n0.51\n\n- weigher\n93.68\n78.72\n74.70\n39.13\n0.51\n85.10\n84.72\n70.82\n39.08\n0.51\nExperimental Settings.\nWe conduct experiments on a double-attribute control task and a triple-attribute control task. We adopt the widely-used Yelp Lample et al. (2019  ###reference_b18###) benchmark, containing restaurant reviews with the sentiment (positive and negative) and the subject (American, Mexican, and Asian) labels. To measure whether the sentence satisfies given attributes, we finetuned two RoBERTa-based Liu et al. (2019  ###reference_b24###) classifiers for the evaluations of sentiment and subject with its original setting. Following Huang et al. (2023  ###reference_b12###), we add another constraint, tense (past and present) Ficler and Goldberg (2017  ###reference_b6###) where their labels are automatically extracted from the reviews with an open-source toolkit333https://github.com/ajitrajasekharan/simple_tense_detector  ###reference__tense_detector###.\nPerplexity (PPL) and averaged distinctness Li et al. (2016  ###reference_b19###) are reported to demonstrate the fluency and diversity of the generated text. We also conduct human evaluations on generated results. Due to page limit, see Appendix B.2  ###reference_### for more details.\nBaselines.\nResearch on multi-attribute CTG is not as abundant as single-attribute CTG. We extend\nGEDI Krause et al. (2021  ###reference_b16###), which adopts a small-scale conditional generative discriminator to bias the token distribution, to multi-attribute controlling according to Huang et al. (2023  ###reference_b12###). We also include DIST. LENS Khalifa et al. (2021  ###reference_b15###), which introduces an autoencoder to map constraints to latent subspaces, and explore the intersection of multiple constraints.\nTailor Yang et al. (2023a  ###reference_b33###) which proposes a connector to combine several prompts. Meanwhile, it modifies the attention mask and position indexes to narrow the gap between training and inference.\nPrompt-gating Huang et al. (2023  ###reference_b12###): it gates the prompts before appended into the LLMs to mitigate the mutual interference.\nWe also implement sentence-level RL methods, PPO Schulman et al. (2017  ###reference_b28###) and Quark Lu et al. (2022  ###reference_b25###), whose rewards are the sum of single-attribute rewards. We also conduct human evaluations. See Appendix C  ###reference_### for more details.\nResults and Analysis.\nThe results are shown in Table 3  ###reference_###. The post-processing method, GeDi, though gets competitive results on attribute accuracy, the deterioration of text quality caused by direct decoding-time regulation is more severe than in single-attribute generation, indicated by the highest PPL score.\nDist. Lens though achieves considerable results, it requires over six times inference time to determine the intersection boundary of attribute subspaces.\nPrompt-based methods Tailor and Prompt-Gating achieve suboptimal performance on both double- and triple-attribute scenarios. However, since they are easily overfitted to undesirable attributes in the training corpus which may contradict other target attributes, their performance is limited. With more fine-grained guidance on sampled sentences,\nour method can achieve the best control accuracy in both settings without significant inference expenses.\n###figure_2### ###figure_3###"
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "Further Studies",
            "text": "What effect do \"Quantization\" and \"Noise\" have respectively? To visualize the difference made by \"First quantize, then noise\", we implement two variations of our algorithm, and conduct experiments on sentiment control tasks.\nFirst, we directly use the scores output by classifiers as rewards without any interference. We display the performance transition over the training steps of sentiment control tasks as in Figure 2  ###reference_###. The figure demonstrates that the control accuracy and the text diversity both decrease. Our algorithm can achieve higher attribute accuracy since the noising procedure can promote the generalization of models, though initially converge slower. Moreover, the noising procedure can prevent models from flattering the scorers, thus achieving higher text diversity.\nWe also implement another variance that noise the reward without quantization boundaries.\nAs shown in Figure 3  ###reference_###, we can see that quantization enhances the stability of algorithms. The model can learn from the relative order of datasets, even with a big standard deviation of Gaussian noise. If we ablate the quantization procedure, the algorithm will be sensitive to the amplitude of noise.\n###figure_4### ###figure_5### ###figure_6### ###figure_7### What if we ablate the \"weigher\" from the multi-attribute combination, but adopt averages as overall rewards? We implement a model variation that combines several scorers by averaging their output scores. Table 3  ###reference_### shows that ablating \"weigher\" leads to a performance decrease. To further prove that \"weigher\" can provide more clear guidance with no contradiction between different scorers, we display the scores by averaging and aggregating by \"weigher\" respectively in Figure 4  ###reference_###.\nThe left subgraph concentrate within small values due to the scorer contradiction without \"weigher\".\nOn the contrary, the right heatmap shows more distinct guidance for models.\nConvergence speed compared to sentence-level feedback.\nToken-level feedback can provide dense and precise signals for models, thus requiring fewer learning steps to achieve ideal performance. We implement a variance of Tole with sentence-level guidance with the same quantization & noise process. We display the performance transition over training steps in Figure 2  ###reference_###. The figure shows that the sentence-level feedback slows down the convergence significantly, compared to the token-level feedback.\nWhat effect does the number of quantiles have? \n of -quantile does not have a significant effect on final performance. However, the convergence of the process is slightly slower if  is relatively large or small. When  is small, relative orders between quantiles are more ambiguous. A large  confines noise within a small interval, diminishing noise impact, which results in a lower generalization. A moderate q-value allows the model to reach the desired result faster. See more details in Appendix D.1  ###reference_###.\nWhat effect does the number of  have?\n are two hyper-coefficients of KL-divergence and entropy term Eq.5  ###reference_### respectively.\nWe conduct experiments with varying  of . Experimental results indicate that higher  can increase text fluency, but sacrifice controllability slightly, since higher  more tightly constrain the model not to deviate too much.\nOur experiments also demonstrate that the entropy term has a relatively slight effect on performance, not as much as KL-divergence. As  increases, attribute accuracy and text diversity have a slight increase.\nSee more details in Appendix D.2  ###reference_###.\nDiscussion about reward hacking. Though our algorithm achieves great results in the above experiments, we are concerned that reward hacking occurs in some scenarios when scorers are too simple for LLMs to find unintended shortcuts.\nOne solution to reward hacking is to complicate reward design, which is easy to implement in our algorithms by adding new constraints with weighers.\n###figure_8### ###figure_9###"
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "To summarize, we propose an extensible reinforcement learning algorithm for controllable text generation with token-level feedback. We provide an alternative perspective of Bayesian Factorization, which enlightens our token-level reward design. We also introduce \"Quantization & Noise\" into RL to enhance the algorithm robustness. We also propose a small-scale module \"weigher\" to extend our algorithm to multiple constraints. Extensive experiments demonstrates the effectiveness of our algorithm."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Bayesian Factorization",
            "text": "The Bayesian factorization is widely used in controllable text generation as the following formulation:\nwhere  is the -th token of a sentence  in corpora.\nPost-processing methods regulate the distribution of the next token with attribute classifiers through Eq.7  ###reference_###, where  is approximated with logits output by LLMs, and  is scored by the attribute classifier.\nFinetune-based methods train language models on attribute-specific corpora.  in  is represented through continuous prompts or control codes (Yang et al., 2023a  ###reference_b33###; Keskar et al., 2019  ###reference_b14###).\nCompared to the traditional Bayesian factorization form as in Eq.7  ###reference_###, the difference of our derivation is that we reserve a term  during the derivation. This term is usually ignored considering its invariance to . The novel Bayesian factorization can be transformed into:\nwhere  indicates the the probability shift."
        },
        {
            "section_id": "Appendix 2",
            "parent_section_id": null,
            "section_name": "Appendix B Experimental Details",
            "text": ""
        },
        {
            "section_id": "Appendix 3",
            "parent_section_id": null,
            "section_name": "Appendix C Human Evaluation",
            "text": ""
        },
        {
            "section_id": "Appendix 4",
            "parent_section_id": null,
            "section_name": "Appendix D Further Studies",
            "text": ""
        },
        {
            "section_id": "Appendix 5",
            "parent_section_id": null,
            "section_name": "Appendix E Quanlitative Results",
            "text": "Soon, it becomes clear: if a female is in the right place and time of year at\nSoon, it becomes clear: we still have time to solve the problem, hope it\nSoon, it becomes clear: her work here will be a success. she will be a great\nFor France, Germany\u2019s primary partner in the G8, and a leading member of Europe\u2019s \"G\nFor France, Germany\u2019s primary partner in the Euro zone, this is a moment of great challenge, and\nFor France, Germany\u2019s primary partner in the fight against terrorism. We share a long history of friendship and\nEven Vladimir Lenin himself couldn\u2019t have been a good husband, so he had to take on\nEven Vladimir Lenin himself couldn\u2019tdo what he\u2019s doing right now. We must take action\nEven Vladimir Lenin himself couldn\u2019t do more. We are blessed with great leaders in our country\nI\u2019m not saying it was my fault. I am not the one who did this\nI\u2019m not saying I\u2019m a Christian.\u2019 \u2019This is my first time. We\nI\u2019m not saying that. We always back you up and be at your side. Believe\nThose, too, are the first and foremost in the \"Rough\" category of the \"\nThose, too, are the men and women of the Navy.\" The statement also referred to the\nThose, too, are the most beautiful people I know. We have much to learn together \"\n###table_1### The prisoners are the bad guys, and herson is Peter, the evil one. And to soothe his pain, he is going to\nThe prisoners are the bad guys, and I was into the struggle for their freedom. At school in Thailand\u2019s Narathiwat prison\nThe prisoners are the bad guys, and by setting their cages up so close to the street, they were the least of their problems. But\nThe prisoners are the bad guys, and the good guys are in jail. The bad guys will always get a free pass. The prisoners\nThe prisoners are the bad guys, and the prisoners can get away with it, but it\u2019s not the end. We can get more justice if\nThe prisoners are the bad guys, and people may look down upon them, but many of them behavior well after being released from prison.\nOnce upon a time, great food. the service is great and very friendly.\nAdvertisements - yummy! *** Helpful!! :)\nOnce upon a time, i was a big fan of this establishment. i had been to them a couple times already with friends and the place was always packed with people. this place was a hit, so much so that now I am going to go there every time\nOnce upon a time i was at the restaurant and had dinner at a friend\u2019s place, the food was great. the chef is very knowledgeable (the owner\u2019s daughter is a sushi professional), but i can only say that the restaurant was very clean and the food was very flavorful.\nOnce upon a time, chuan is an awesome restaurant in a strip mall. authentic chinese comfort food with great service. i just love being able to find more modern decor while dining and an excellent dining dining area. while i\u2019ve been here twice and still the least half at the same dining experience is very nice. and if i eat a\nThe year is 1910. great food and the service was great. will be back!\nAdvertisements for good sushi!!! Follow me @wendie\nThe year is 1910. this is not your average sushi bar. the atmosphere was very casual and cozy. the food was good. the service was prompt and fast. the food was fresh and delicious.\nThe year is 1910. we went to this place for the first year. it looks nice. there are a couple of booths, a table\nfor 4 (and a counter) to get seated in. we had an early reservation. i ordered the steak. the steak was great. my boyfriend enjoyed the chicken wings. i was very impressed by the steak.\nThe year is 1910. a coffee culture ( not only for coffee ) or a liquor to spend a few dollars to the sugar it in a paper cupcake for an after a long vegas strip\u2019s worth. you can walk to mr. wynn\u2026 that\u2019s how crowded and you could wait for a good cheap meal on the\nWhile this is happening, great food! the margaritas are fantastic and friendly staff. Advertisements = good mexican restaurant! Related\nWhile this is happening to be my new favorite restaurant, and my new favorite location, i can\u2019t say that i\u2019ve ever been to this place with all the other reviews. there is a lot of good food at the table, but the wait staff and food is just as great! i love that there are no waiters to take my orders, but that doesn\u2019t mean the food is bad. the food here was good.\nWhile this is happening i\u2019m going here for dinner for the first time. the food here was very, very good and very tasty!!we ordered a couple of different salads and some tacos. i got a vego beef taco with a spicy sauce (it is very good). i also got an onion rings (it does not have any onions, nor are there many onions in this recipe), and it was delicious!\nWhile this is happening, you can select items and choose the sauces and hot salsa ; you \u2019ll realize your face tremb for making a burrito place and a burrito you have to be glad it goes!!! i would highly recommend this joint!!!!!!! you get there at lunchtime, it\u2019s at the plaza"
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T1\">\n<p class=\"ltx_p ltx_align_center\" id=\"S4.T1.4\"><span class=\"ltx_text\" id=\"S4.T1.4.4\" style=\"width:433.6pt;color:#000000;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S4.T1.4.4.4.4.4\" style=\"width:415.0pt;height:198pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1,1) ;\">\n<span class=\"ltx_p\" id=\"S4.T1.4.4.4.4.4.4\"><span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S4.T1.4.4.4.4.4.4.4.4\">\n<span class=\"ltx_tr\" id=\"S4.T1.1.1.1.1.1.1.1.1.1\">\n<span class=\"ltx_td ltx_align_center ltx_border_tt ltx_rowspan ltx_rowspan_3\" id=\"S4.T1.1.1.1.1.1.1.1.1.1.2\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.1.1.1.1.1.1.2.1\">Category</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_rowspan ltx_rowspan_3\" id=\"S4.T1.1.1.1.1.1.1.1.1.1.3\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.1.1.1.1.1.1.3.1\">Model</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_colspan ltx_colspan_4\" id=\"S4.T1.1.1.1.1.1.1.1.1.1.1\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.1.1.1.1.1.1.1.1\">Attribute Correctness</span>()</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_colspan ltx_colspan_3\" id=\"S4.T1.1.1.1.1.1.1.1.1.1.4\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.1.1.1.1.1.1.4.1\">Generation Metrics</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.1.1.1.1.1.1.1.1.1.5\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.1.1.1.1.1.1.5.1\">Training Info.</span></span></span>\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.4\">\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2\" id=\"S4.T1.4.4.4.4.4.4.4.4.4.4\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.4.4.4.4.4.4.4.4.4.4.1\">Target</span>:<span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T1.4.4.4.4.4.4.4.4.4.4.2\">Positive</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2\" id=\"S4.T1.4.4.4.4.4.4.4.4.4.5\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.4.4.4.4.4.4.4.4.4.5.1\">Target</span>:<span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T1.4.4.4.4.4.4.4.4.4.5.2\">Negative</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t ltx_rowspan ltx_rowspan_2\" id=\"S4.T1.2.2.2.2.2.2.2.2.2.1\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.2.2.2.2.2.2.2.2.2.1.1\">\u2003PPL()</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t ltx_rowspan ltx_rowspan_2\" id=\"S4.T1.3.3.3.3.3.3.3.3.3.2\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.3.3.3.3.3.3.3.3.3.2.1\">dist-3()</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2\" id=\"S4.T1.4.4.4.4.4.4.4.4.4.3\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4.4.4.3.1\">CR.()</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t ltx_rowspan ltx_rowspan_2\" id=\"S4.T1.4.4.4.4.4.4.4.4.4.6\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4.4.4.6.1\">%Params</span></span></span>\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.5\">\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.5.1\" style=\"padding:0.5pt 3.0pt;\">negative</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.5.2\" style=\"padding:0.5pt 3.0pt;\">neutral</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.5.3\" style=\"padding:0.5pt 3.0pt;\">positive</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.5.4\" style=\"padding:0.5pt 3.0pt;\">neutral</span></span>\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.6\">\n<span class=\"ltx_td ltx_align_center ltx_border_tt ltx_rowspan ltx_rowspan_3\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.1\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.1.1\"><span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.1.1.1\"></span> <span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.1.1.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.1.1.2.1\">\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.1.1.2.1.1\">\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.1.1.2.1.1.1\" style=\"padding:0.5pt 3.0pt;\">Post-</span></span>\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.1.1.2.1.2\">\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.1.1.2.1.2.1\" style=\"padding:0.5pt 3.0pt;\">processing</span></span>\n</span></span> <span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.1.1.3\"></span></span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.2\" style=\"padding:0.5pt 3.0pt;\">PPLM</span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.3\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_phantom\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.3.1\"><span style=\"visibility:hidden\">0</span></span>8.72</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.4\" style=\"padding:0.5pt 3.0pt;\">52.68</span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.5\" style=\"padding:0.5pt 3.0pt;\">10.26</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.6\" style=\"padding:0.5pt 3.0pt;\">60.95</span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.7\" style=\"padding:0.5pt 3.0pt;\">122.41</span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.8\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.8.1\">0.90</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.9\" style=\"padding:0.5pt 3.0pt;\">3.47</span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.4.4.4.4.4.4.4.4.6.10\" style=\"padding:0.5pt 3.0pt;\">0.001</span></span>\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.7\">\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.7.1\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T1.4.4.4.4.4.4.4.4.7.1.1\">GeDi</span></span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.7.2\" style=\"padding:0.5pt 3.0pt;\">26.80</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.7.3\" style=\"padding:0.5pt 3.0pt;\">86.01</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.7.4\" style=\"padding:0.5pt 3.0pt;\">60.43</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.7.5\" style=\"padding:0.5pt 3.0pt;\">91.27</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.7.6\" style=\"padding:0.5pt 3.0pt;\">138.27</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.7.7\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.4.4.4.4.4.4.4.4.7.7.1\">0.86</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.7.8\" style=\"padding:0.5pt 3.0pt;\">3.62</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.7.9\" style=\"padding:0.5pt 3.0pt;\">-</span></span>\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.8\">\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.8.1\" style=\"padding:0.5pt 3.0pt;\">FUDGE</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.8.2\" style=\"padding:0.5pt 3.0pt;\">56.04</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.8.3\" style=\"padding:0.5pt 3.0pt;\">96.92</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.8.4\" style=\"padding:0.5pt 3.0pt;\">66.84</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.8.5\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.4.4.4.4.4.4.4.4.8.5.1\">98.76</span></span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.8.6\" style=\"padding:0.5pt 3.0pt;\">265.79</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.8.7\" style=\"padding:0.5pt 3.0pt;\">0.83</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.8.8\" style=\"padding:0.5pt 3.0pt;\">1.53</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.8.9\" style=\"padding:0.5pt 3.0pt;\">-</span></span>\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.9\">\n<span class=\"ltx_td ltx_align_center ltx_border_t ltx_rowspan ltx_rowspan_2\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.1\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.1.1\"><span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.1.1.1\"></span> <span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.1.1.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.1.1.2.1\">\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.1.1.2.1.1\">\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.1.1.2.1.1.1\" style=\"padding:0.5pt 3.0pt;\">Fine-</span></span>\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.1.1.2.1.2\">\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.1.1.2.1.2.1\" style=\"padding:0.5pt 3.0pt;\">Tuning</span></span>\n</span></span> <span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.1.1.3\"></span></span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.2\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.2.1\">Prompt</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.3\" style=\"padding:0.5pt 3.0pt;\">40.88</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.4\" style=\"padding:0.5pt 3.0pt;\">78.08</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.5\" style=\"padding:0.5pt 3.0pt;\">49.28</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.6\" style=\"padding:0.5pt 3.0pt;\">73.20</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.7\" style=\"padding:0.5pt 3.0pt;\">39.55</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.8\" style=\"padding:0.5pt 3.0pt;\">0.73</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.9\" style=\"padding:0.5pt 3.0pt;\">63.08</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.9.10\" style=\"padding:0.5pt 3.0pt;\">0.003</span></span>\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.10\">\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.10.1\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T1.4.4.4.4.4.4.4.4.10.1.1\">DisCup</span></span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.10.2\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.4.4.4.4.4.4.4.4.10.2.1\">49.92</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.10.3\" style=\"padding:0.5pt 3.0pt;\">91.58</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.10.4\" style=\"padding:0.5pt 3.0pt;\">60.80</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.10.5\" style=\"padding:0.5pt 3.0pt;\">90.64</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.10.6\" style=\"padding:0.5pt 3.0pt;\">40.46</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.10.7\" style=\"padding:0.5pt 3.0pt;\">0.75</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.10.8\" style=\"padding:0.5pt 3.0pt;\">3.72</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.10.9\" style=\"padding:0.5pt 3.0pt;\">0.003</span></span>\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.11\">\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t ltx_rowspan ltx_rowspan_3\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.1\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.1.1\"><span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.1.1.1\"></span> <span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.1.1.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.1.1.2.1\">\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.1.1.2.1.1\">\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.1.1.2.1.1.1\" style=\"padding:0.5pt 3.0pt;\">Reinforcement</span></span>\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.1.1.2.1.2\">\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.1.1.2.1.2.1\" style=\"padding:0.5pt 3.0pt;\">Learning</span></span>\n</span></span> <span class=\"ltx_text\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.1.1.3\"></span></span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.2\" style=\"padding:0.5pt 3.0pt;\">PPO</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.3\" style=\"padding:0.5pt 3.0pt;\">43.13</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.4\" style=\"padding:0.5pt 3.0pt;\">94.10</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.5\" style=\"padding:0.5pt 3.0pt;\">68.12</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.6\" style=\"padding:0.5pt 3.0pt;\">94.95</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.7\" style=\"padding:0.5pt 3.0pt;\">18.34</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.8\" style=\"padding:0.5pt 3.0pt;\">0.71</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.9\" style=\"padding:0.5pt 3.0pt;\">2.95</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.11.10\" style=\"padding:0.5pt 3.0pt;\">100</span></span>\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.12\">\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.12.1\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T1.4.4.4.4.4.4.4.4.12.1.1\">Quark</span></span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.12.2\" style=\"padding:0.5pt 3.0pt;\">47.32</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.12.3\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.4.4.4.4.4.4.4.4.12.3.1\">95.50</span></span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.12.4\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.4.4.4.4.4.4.4.4.12.4.1\">70.50</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.12.5\" style=\"padding:0.5pt 3.0pt;\">96.65</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.12.6\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.4.4.4.4.4.4.4.4.12.6.1\">16.92</span></span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.12.7\" style=\"padding:0.5pt 3.0pt;\">0.75</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.4.4.4.4.4.4.4.4.12.8\" style=\"padding:0.5pt 3.0pt;\">2.63</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T1.4.4.4.4.4.4.4.4.12.9\" style=\"padding:0.5pt 3.0pt;\">100</span></span>\n<span class=\"ltx_tr\" id=\"S4.T1.4.4.4.4.4.4.4.4.13\">\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.13.1\" style=\"padding:0.5pt 3.0pt;\">TOLE</span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.13.2\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.4.4.4.4.4.4.4.4.13.2.1\">69.36</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.13.3\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.4.4.4.4.4.4.4.4.13.3.1\">97.16</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.13.4\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.4.4.4.4.4.4.4.4.13.4.1\">72.81</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.13.5\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.4.4.4.4.4.4.4.4.13.5.1\">98.02</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.13.6\" style=\"padding:0.5pt 3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T1.4.4.4.4.4.4.4.4.13.6.1\">17.05</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.13.7\" style=\"padding:0.5pt 3.0pt;\">0.75</span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.13.8\" style=\"padding:0.5pt 3.0pt;\">2.61</span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T1.4.4.4.4.4.4.4.4.13.9\" style=\"padding:0.5pt 3.0pt;\">0.003</span></span>\n</span></span></span>\n</span></span></span></p>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Automatic evaluation results of the sentiment control task. \"Params\" indicates the ratio of trainable parameters to the whole LLM. Boldface and underline indicate the best two results.</figcaption>\n</figure>",
            "capture": "Table 1: Automatic evaluation results of the sentiment control task. \"Params\" indicates the ratio of trainable parameters to the whole LLM. Boldface and underline indicate the best two results."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T2\">\n<p class=\"ltx_p ltx_align_center\" id=\"S4.T2.6\"><span class=\"ltx_text\" id=\"S4.T2.6.6\" style=\"width:433.6pt;color:#000000;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S4.T2.6.6.6.6.6\" style=\"width:288.9pt;height:216pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1,1) ;\">\n<span class=\"ltx_p\" id=\"S4.T2.6.6.6.6.6.6\"><span class=\"ltx_text\" id=\"S4.T2.6.6.6.6.6.6.6\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S4.T2.6.6.6.6.6.6.6.6\">\n<span class=\"ltx_tr\" id=\"S4.T2.6.6.6.6.6.6.6.6.7\">\n<span class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt ltx_rowspan ltx_rowspan_3\" id=\"S4.T2.6.6.6.6.6.6.6.6.7.1\">\u00a0\u00a0\u00a0\u00a0\u00a0<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.6.6.6.6.6.6.6.7.1.1\">Model</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_colspan ltx_colspan_4\" id=\"S4.T2.6.6.6.6.6.6.6.6.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.6.6.6.6.6.6.6.7.2.1\">In-domain</span> <span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T2.6.6.6.6.6.6.6.6.7.2.2\">RealToxicityPrompts</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_4\" id=\"S4.T2.6.6.6.6.6.6.6.6.7.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.6.6.6.6.6.6.6.7.3.1\">Out-of-domain</span> <span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T2.6.6.6.6.6.6.6.6.7.3.2\">WritingPrompts</span></span></span>\n<span class=\"ltx_tr\" id=\"S4.T2.2.2.2.2.2.2.2.2.2\">\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2\" id=\"S4.T2.1.1.1.1.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.1.1.1.1.1.1.1.1\">Toxicity</span> ()</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2\" id=\"S4.T2.2.2.2.2.2.2.2.2.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.2.2.2.2.2.2.2.2.2.3.1\">Generation</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2\" id=\"S4.T2.2.2.2.2.2.2.2.2.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.2.2.2.2.2.2.2.2.2.2.1\">Toxicity</span> ()</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t ltx_colspan ltx_colspan_2\" id=\"S4.T2.2.2.2.2.2.2.2.2.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.2.2.2.2.2.2.2.2.2.4.1\">Generation</span></span></span>\n<span class=\"ltx_tr\" id=\"S4.T2.6.6.6.6.6.6.6.6.6\">\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.6.5\">avg.\u00a0max.</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.6.6\">prob.</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.3.3.3.3.3.3.3.3.1\">PPL </span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.4.4.4.4.4.4.4.4.4.2\">dist-3</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.6.7\">avg.\u00a0max.</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.6.8\">prob.</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.5.5.5.5.5.5.5.5.5.3\">PPL</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.6.4\">dist-3</span></span>\n<span class=\"ltx_tr\" id=\"S4.T2.6.6.6.6.6.6.6.6.8\">\n<span class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.8.1\">GPT2</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.8.2\">0.527</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.8.3\">0.520</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.8.4\">11.31</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.8.5\">0.85</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.8.6\">0.572</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.8.7\">0.610</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.8.8\">12.99</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.8.9\">0.85</span></span>\n<span class=\"ltx_tr\" id=\"S4.T2.6.6.6.6.6.6.6.6.9\">\n<span class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.9.1\">PPLM</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.9.2\">0.520</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.9.3\">0.518</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.9.4\">32.58</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.9.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.6.6.6.6.6.6.6.9.5.1\">0.86</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.9.6\">0.544</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.9.7\">0.590</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.9.8\">36.20</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.9.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.6.6.6.6.6.6.6.9.9.1\">0.86</span></span></span>\n<span class=\"ltx_tr\" id=\"S4.T2.6.6.6.6.6.6.6.6.10\">\n<span class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.10.1\">GeDi</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.10.2\">0.363</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.10.3\">0.217</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.10.4\">60.03</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.10.5\">0.83</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.10.6\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T2.6.6.6.6.6.6.6.6.10.6.1\">0.261</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.10.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.6.6.6.6.6.6.6.10.7.1\">0.050</span></span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.10.8\">91.16</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.10.9\">0.82</span></span>\n<span class=\"ltx_tr\" id=\"S4.T2.6.6.6.6.6.6.6.6.11\">\n<span class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.11.1\">DExpert</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.11.2\">0.314</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.11.3\">0.128</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.11.4\">32.41</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.11.5\">0.84</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.11.6\">0.343</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.11.7\">0.156</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.11.8\">42.53</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.11.9\">0.85</span></span>\n<span class=\"ltx_tr\" id=\"S4.T2.6.6.6.6.6.6.6.6.12\">\n<span class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.12.1\">Prompt</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.12.2\">0.302</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.12.3\">0.360</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.12.4\">29.21</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.12.5\">0.74</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.12.6\">0.442</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.12.7\">0.363</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.12.8\">30.10</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.12.9\">0.79</span></span>\n<span class=\"ltx_tr\" id=\"S4.T2.6.6.6.6.6.6.6.6.13\">\n<span class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.13.1\">Discup</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.13.2\">0.298</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.13.3\">0.115</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.13.4\">39.30</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.13.5\">0.84</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.13.6\">0.442</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.13.7\">0.363</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.13.8\">37.23</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.13.9\">0.85</span></span>\n<span class=\"ltx_tr\" id=\"S4.T2.6.6.6.6.6.6.6.6.14\">\n<span class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.14.1\">PPO</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.14.2\">0.288</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.14.3\">0.130</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.14.4\">18.22</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.14.5\">0.82</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.14.6\">0.291</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.14.7\">0.132</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.14.8\">18.32</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.14.9\">0.84</span></span>\n<span class=\"ltx_tr\" id=\"S4.T2.6.6.6.6.6.6.6.6.15\">\n<span class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.15.1\">Quark</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.15.2\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T2.6.6.6.6.6.6.6.6.15.2.1\">0.237</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.15.3\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T2.6.6.6.6.6.6.6.6.15.3.1\">0.118</span></span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.15.4\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T2.6.6.6.6.6.6.6.6.15.4.1\">17.23</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.15.5\">0.81</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.15.6\">0.268</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.6.6.6.6.6.15.7\">0.102</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.15.8\">17.19</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.6.6.6.6.6.15.9\">0.83</span></span>\n<span class=\"ltx_tr\" id=\"S4.T2.6.6.6.6.6.6.6.6.16\">\n<span class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.1\">TOLE</span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.2.1\">0.206</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.3.1\">0.105</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.4.1\">15.45</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.5\">0.80</span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.6.1\">0.223</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.7\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.7.1\">0.080</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.8.1\">16.51</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.6.6.6.6.6.6.6.6.16.9\">0.83</span></span>\n</span></span></span>\n</span></span></span></p>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Automatic evaluation results of unlearning toxicity experiments. Boldface and underline indicate the best two results.</figcaption>\n</figure>",
            "capture": "Table 2: Automatic evaluation results of unlearning toxicity experiments. Boldface and underline indicate the best two results."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T3\">\n<p class=\"ltx_p ltx_align_center\" id=\"S4.T3.10\"><span class=\"ltx_text\" id=\"S4.T3.10.10\" style=\"width:433.6pt;color:#000000;\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" id=\"S4.T3.10.10.10.10.10\" style=\"width:388.1pt;height:144pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1,1) ;\">\n<span class=\"ltx_p\" id=\"S4.T3.10.10.10.10.10.10\"><span class=\"ltx_text\" id=\"S4.T3.10.10.10.10.10.10.10\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S4.T3.10.10.10.10.10.10.10.10\">\n<span class=\"ltx_tr\" id=\"S4.T3.10.10.10.10.10.10.10.10.11\">\n<span class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt ltx_rowspan ltx_rowspan_2\" id=\"S4.T3.10.10.10.10.10.10.10.10.11.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\u00a0\u00a0\u00a0\u00a0\u00a0<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.10.10.10.10.10.10.10.10.11.1.1\">Model</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_colspan ltx_colspan_5\" id=\"S4.T3.10.10.10.10.10.10.10.10.11.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.10.10.10.10.10.10.10.10.11.2.1\">Double Controls</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_5\" id=\"S4.T3.10.10.10.10.10.10.10.10.11.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.10.10.10.10.10.10.10.10.11.3.1\">Triple Controls</span></span></span>\n<span class=\"ltx_tr\" id=\"S4.T3.10.10.10.10.10.10.10.10.10\">\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.1.1.1.1.1.1.1.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Sent.()</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.2.2.2.2.2.2.2.2.2.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Top.()</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.3.3.3.3.3.3.3.3.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Ave.()</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.4.4.4.4.4.4.4.4.4.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">PPL()</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.5.5.5.5.5.5.5.5.5.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Dist.()</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.6.6.6.6.6.6.6.6.6.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Sent.()</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.7.7.7.7.7.7.7.7.7.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Top.()</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.8.8.8.8.8.8.8.8.8.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Tense.()</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.9.9.9.9.9.9.9.9.9.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">PPL()</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.10.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Dist.()</span></span>\n<span class=\"ltx_tr\" id=\"S4.T3.10.10.10.10.10.10.10.10.12\">\n<span class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.12.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T3.10.10.10.10.10.10.10.10.12.1.1\">GeDi</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.12.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.10.10.10.10.10.10.10.10.12.2.1\">99.47</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.12.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">51.36</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.12.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">75.41</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.12.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">616.92</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.12.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.10.10.10.10.10.10.10.10.12.6.1\">0.75</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.12.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">-</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.12.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">-</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.12.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">-</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.12.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">-</span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.12.11\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">-</span></span>\n<span class=\"ltx_tr\" id=\"S4.T3.10.10.10.10.10.10.10.10.13\">\n<span class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T3.10.10.10.10.10.10.10.10.13.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T3.10.10.10.10.10.10.10.10.13.1.1\">Dist. Lens</span></span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.13.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">77.47</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.13.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">66.98</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.13.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">72.22</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.13.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">52.59</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.10.10.10.10.10.10.10.10.13.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.26</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.13.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">65.31</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.13.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">55.84</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.13.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">54.25</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.13.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">63.13</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.13.11\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.40</span></span>\n<span class=\"ltx_tr\" id=\"S4.T3.10.10.10.10.10.10.10.10.14\">\n<span class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T3.10.10.10.10.10.10.10.10.14.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T3.10.10.10.10.10.10.10.10.14.1.1\">Tailor</span></span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.14.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">80.68</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.14.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">68.72</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.14.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">74.70</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.14.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">40.29</span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.10.10.10.10.10.10.10.10.14.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.39</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.14.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">68.08</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.14.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">58.67</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.14.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">33.38</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.14.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">42.89</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.14.11\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.42</span></span>\n<span class=\"ltx_tr\" id=\"S4.T3.10.10.10.10.10.10.10.10.15\">\n<span class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.1.1\">P-Gating</span></span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">84.80</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.3.1\">75.02</span></span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.4.1\">79.91</span></span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.5.1\">21.77</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.42</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">76.93</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">62.73</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">62.24</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">21.87</span>\n<span class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.10.10.10.10.15.11\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.45</span></span>\n<span class=\"ltx_tr\" id=\"S4.T3.10.10.10.10.10.10.10.10.16\">\n<span class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.1.1\">Tole</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.2.1\">91.27</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.3.1\">86.32</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.4.1\">88.80</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.5.1\">38.62</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.6.1\">0.52</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.7.1\">86.31</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.8.1\">92.68</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.9.1\">89.50</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.10.1\">40.75</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.11\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T3.10.10.10.10.10.10.10.10.16.11.1\">0.51</span></span></span>\n<span class=\"ltx_tr\" id=\"S4.T3.10.10.10.10.10.10.10.10.17\">\n<span class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" id=\"S4.T3.10.10.10.10.10.10.10.10.17.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">- weigher</span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.10.10.10.10.10.10.10.10.17.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">93.68</span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.10.10.10.10.10.10.10.10.17.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">78.72</span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.10.10.10.10.10.10.10.10.17.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">74.70</span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.10.10.10.10.10.10.10.10.17.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">39.13</span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S4.T3.10.10.10.10.10.10.10.10.17.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.51</span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.10.10.10.10.10.10.10.10.17.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T3.10.10.10.10.10.10.10.10.17.7.1\">85.10</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.10.10.10.10.10.10.10.10.17.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T3.10.10.10.10.10.10.10.10.17.8.1\">84.72</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.10.10.10.10.10.10.10.10.17.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_framed_underline\" id=\"S4.T3.10.10.10.10.10.10.10.10.17.9.1\">70.82</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.10.10.10.10.10.10.10.10.17.10\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">39.08</span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.10.10.10.10.10.10.10.10.17.11\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.51</span></span>\n</span></span></span>\n</span></span></span>\n</p>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Automatic evaluation results of the multi-attribute control task. Boldface and underline indicate the best two results.</figcaption>\n</figure>",
            "capture": "Table 3: Automatic evaluation results of the multi-attribute control task. Boldface and underline indicate the best two results."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T4\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"A3.T4.1\">\n<tr class=\"ltx_tr\" id=\"A3.T4.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"A3.T4.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T4.1.1.2\">Cor.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T4.1.1.3\">Top.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T4.1.1.4\">Flu.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T4.1.1.5\">Kappa</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T4.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A3.T4.1.2.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A3.T4.1.2.1.1\">GeDi</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.1.2.2\">7.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.1.2.3\">5.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.1.2.4\">4.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T4.1.2.5\">0.65</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T4.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A3.T4.1.3.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A3.T4.1.3.1.1\">P.T.</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T4.1.3.2\">7.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T4.1.3.3\">5.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T4.1.3.4\">6.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T4.1.3.5\">0.71</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T4.1.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A3.T4.1.4.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A3.T4.1.4.1.1\">Quark</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T4.1.4.2\">8.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T4.1.4.3\">6.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T4.1.4.4\">7.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T4.1.4.5\">0.66</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T4.1.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"A3.T4.1.5.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A3.T4.1.5.1.1\">Tole</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T4.1.5.2\">8.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T4.1.5.3\">6.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T4.1.5.4\">7.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T4.1.5.5\">0.68</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Human evaluation results of sentiment control tasks. Cor., Top., Flu. denotes Correctness, Topicality, and Fluency respectively. P.T. denotes the vallina prompt-tuning methods. Kappa denotes Fleiss\u2019s kappa value.</figcaption>\n</figure>",
            "capture": "Table 4: Human evaluation results of sentiment control tasks. Cor., Top., Flu. denotes Correctness, Topicality, and Fluency respectively. P.T. denotes the vallina prompt-tuning methods. Kappa denotes Fleiss\u2019s kappa value."
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T5\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"A3.T5.1\">\n<tr class=\"ltx_tr\" id=\"A3.T5.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"A3.T5.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T5.1.1.2\">Tox.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T5.1.1.3\">Top.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T5.1.1.4\">Flu.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T5.1.1.5\">Kappa</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T5.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A3.T5.1.2.1\">GeDi</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.1.2.2\">7.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.1.2.3\">5.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.1.2.4\">5.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T5.1.2.5\">0.73</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T5.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A3.T5.1.3.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A3.T5.1.3.1.1\">P.T.</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.1.3.2\">7.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.1.3.3\">6.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.1.3.4\">6.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.1.3.5\">0.68</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T5.1.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A3.T5.1.4.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A3.T5.1.4.1.1\">Quark</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.1.4.2\">7.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.1.4.3\">7.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.1.4.4\">7.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.1.4.5\">0.63</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T5.1.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"A3.T5.1.5.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A3.T5.1.5.1.1\">Tole</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T5.1.5.2\">8.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T5.1.5.3\">7.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T5.1.5.4\">7.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T5.1.5.5\">0.71</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>Human evaluation results of detoxification. Tox., Top., Flu. denote Less-Toxicity, Topicality, and Fluency respectively. P.T. denotes the vallina prompt-tuning methods. Kappa denotes Fleiss\u2019s kappa value.</figcaption>\n</figure>",
            "capture": "Table 5: Human evaluation results of detoxification. Tox., Top., Flu. denote Less-Toxicity, Topicality, and Fluency respectively. P.T. denotes the vallina prompt-tuning methods. Kappa denotes Fleiss\u2019s kappa value."
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T6\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"A3.T6.1\">\n<tr class=\"ltx_tr\" id=\"A3.T6.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"A3.T6.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T6.1.1.2\">Acc.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T6.1.1.3\">Flu.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T6.1.1.4\">OA</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T6.1.1.5\">Kappa</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A3.T6.1.2.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A3.T6.1.2.1.1\">GeDi</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.1.2.2\">6.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.1.2.3\">4.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.1.2.4\">4.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.1.2.5\">0.79</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A3.T6.1.3.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A3.T6.1.3.1.1\">Dist. Lens</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.1.3.2\">7.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.1.3.3\">6.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.1.3.4\">6.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.1.3.5\">0.66</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.1.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A3.T6.1.4.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A3.T6.1.4.1.1\">Tailor</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.1.4.2\">7.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.1.4.3\">6.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.1.4.4\">6.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.1.4.5\">0.68</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.1.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"A3.T6.1.5.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A3.T6.1.5.1.1\">Tole</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T6.1.5.2\">8.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T6.1.5.3\">6.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T6.1.5.4\">6.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T6.1.5.5\">0.71</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 6: </span>Human evaluation results of multi-aspect controlling. Acc., Flu., OA denote Accuracy, Fluency, and Overall respectively. Kappa denotes Fleiss\u2019s kappa value.</figcaption>\n</figure>",
            "capture": "Table 6: Human evaluation results of multi-aspect controlling. Acc., Flu., OA denote Accuracy, Fluency, and Overall respectively. Kappa denotes Fleiss\u2019s kappa value."
        },
        "7": {
            "table_html": "<figure class=\"ltx_table\" id=\"A4.T7\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"A4.T7.1\" style=\"width:433.6pt;height:115pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(115.0pt,-30.5pt) scale(2.1305155691557,2.1305155691557) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A4.T7.1.1\">\n<tr class=\"ltx_tr\" id=\"A4.T7.1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"A4.T7.1.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A4.T7.1.1.1.2\">neg-pos</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A4.T7.1.1.1.3\">neu-pos</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A4.T7.1.1.1.4\">pos-neg</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A4.T7.1.1.1.5\">neu-neg</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T7.1.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A4.T7.1.1.2.1\">normal+TOLE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A4.T7.1.1.2.2\">69.36</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A4.T7.1.1.2.3\">97.16</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A4.T7.1.1.2.4\">72.81</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A4.T7.1.1.2.5\">98.02</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T7.1.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"A4.T7.1.1.3.1\">special+TOLE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A4.T7.1.1.3.2\">69.13</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A4.T7.1.1.3.3\">97.56</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A4.T7.1.1.3.4\">72.85</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A4.T7.1.1.3.5\">98.24</td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 7: </span>Experiments on different classifier settings. \"normal\" and \"special\" denotes the canonical training method and the decomposed training method respectively. \"a\"-\"b\" means that the goal is to steer prompt of \"a\" to the target \"b\".</figcaption>\n</figure>",
            "capture": "Table 7: Experiments on different classifier settings. \"normal\" and \"special\" denotes the canonical training method and the decomposed training method respectively. \"a\"-\"b\" means that the goal is to steer prompt of \"a\" to the target \"b\"."
        },
        "8": {
            "table_html": "<figure class=\"ltx_table\" id=\"A5.T8\">\n<div class=\"ltx_flex_figure ltx_flex_table\">\n<div class=\"ltx_flex_cell ltx_flex_size_1\">\n<table class=\"ltx_tabular ltx_centering ltx_flex_size_1 ltx_align_middle\" id=\"A5.T8.1\">\n<tr class=\"ltx_tr\" id=\"A5.T8.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" colspan=\"2\" id=\"A5.T8.1.1.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A5.T8.1.1.1.1\">Prompts:</span> Soon, it becomes clear:</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A5.T8.1.2.1\">GPT2</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A5.T8.1.2.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.1.2.2.1\">Soon, it becomes clear: if a female is in the right place and time of year at</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T8.1.3.1\">Quark</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T8.1.3.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.1.3.2.1\">Soon, it becomes clear: we still have time to solve the problem, hope it</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.1.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"A5.T8.1.4.1\">TOLE</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"A5.T8.1.4.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.1.4.2.1\">Soon, it becomes clear: her work here will be a success. she will be a great</p>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ltx_flex_break\"></div>\n<div class=\"ltx_flex_cell ltx_flex_size_1\">\n<table class=\"ltx_tabular ltx_centering ltx_flex_size_1 ltx_align_middle\" id=\"A5.T8.2\">\n<tr class=\"ltx_tr\" id=\"A5.T8.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" colspan=\"2\" id=\"A5.T8.2.1.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A5.T8.2.1.1.1\">Prompts</span>:For France, Germany\u2019s primary partner</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A5.T8.2.2.1\">GPT2</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A5.T8.2.2.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.2.2.2.1\">For France, Germany\u2019s primary partner in the G8, and a leading member of Europe\u2019s \"G</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.2.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T8.2.3.1\">Quark</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T8.2.3.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.2.3.2.1\">For France, Germany\u2019s primary partner in the Euro zone, this is a moment of great challenge, and</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.2.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"A5.T8.2.4.1\">TOLE</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"A5.T8.2.4.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.2.4.2.1\">For France, Germany\u2019s primary partner in the fight against terrorism. We share a long history of friendship and</p>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ltx_flex_break\"></div>\n<div class=\"ltx_flex_cell ltx_flex_size_1\">\n<table class=\"ltx_tabular ltx_centering ltx_flex_size_1 ltx_align_middle\" id=\"A5.T8.3\">\n<tr class=\"ltx_tr\" id=\"A5.T8.3.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" colspan=\"2\" id=\"A5.T8.3.1.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A5.T8.3.1.1.1\">Prompts</span>:Even Vladimir Lenin himself couldn\u2019t</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.3.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A5.T8.3.2.1\">GPT2</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A5.T8.3.2.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.3.2.2.1\">Even Vladimir Lenin himself couldn\u2019t have been a good husband, so he had to take on</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T8.3.3.1\">Quark</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T8.3.3.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.3.3.2.1\">Even Vladimir Lenin himself couldn\u2019tdo what he\u2019s doing right now. We must take action</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.3.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"A5.T8.3.4.1\">TOLE</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"A5.T8.3.4.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.3.4.2.1\">Even Vladimir Lenin himself couldn\u2019t do more. We are blessed with great leaders in our country</p>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ltx_flex_break\"></div>\n<div class=\"ltx_flex_cell ltx_flex_size_1\">\n<table class=\"ltx_tabular ltx_centering ltx_flex_size_1 ltx_align_middle\" id=\"A5.T8.4\">\n<tr class=\"ltx_tr\" id=\"A5.T8.4.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" colspan=\"2\" id=\"A5.T8.4.1.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A5.T8.4.1.1.1\">Prompts</span>:I\u2019m not saying</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.4.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A5.T8.4.2.1\">GPT2</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A5.T8.4.2.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.4.2.2.1\">I\u2019m not saying it was my fault. I am not the one who did this</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.4.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T8.4.3.1\">Quark</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T8.4.3.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.4.3.2.1\">I\u2019m not saying I\u2019m a Christian.\u2019 \u2019This is my first time. We</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"A5.T8.4.4.1\">TOLE</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"A5.T8.4.4.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.4.4.2.1\">I\u2019m not saying that. We always back you up and be at your side. Believe</p>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ltx_flex_break\"></div>\n<div class=\"ltx_flex_cell ltx_flex_size_1\">\n<table class=\"ltx_tabular ltx_centering ltx_flex_size_1 ltx_align_middle\" id=\"A5.T8.5\">\n<tr class=\"ltx_tr\" id=\"A5.T8.5.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" colspan=\"2\" id=\"A5.T8.5.1.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A5.T8.5.1.1.1\">Prompts</span>:Those, too, are the</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.5.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A5.T8.5.2.1\">GPT2</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A5.T8.5.2.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.5.2.2.1\">Those, too, are the first and foremost in the \"Rough\" category of the \"</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.5.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T8.5.3.1\">Quark</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T8.5.3.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.5.3.2.1\">Those, too, are the men and women of the Navy.\" The statement also referred to the</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T8.5.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"A5.T8.5.4.1\">TOLE</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"A5.T8.5.4.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T8.5.4.2.1\">Those, too, are the most beautiful people I know. We have much to learn together \"</p>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 8: </span>Generation examples of the sentiment control task. Since both Quark and Tole can achieve &gt;90% final results. To explicitly show that our methods converges quicker. We choose to present interim results from models trained for 5k steps.</figcaption>\n</figure>",
            "capture": "Table 8: Generation examples of the sentiment control task. Since both Quark and Tole can achieve >90% final results. To explicitly show that our methods converges quicker. We choose to present interim results from models trained for 5k steps."
        },
        "9": {
            "table_html": "<figure class=\"ltx_table\" id=\"A5.T9\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"A5.T9.1\">\n<tr class=\"ltx_tr\" id=\"A5.T9.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" colspan=\"2\" id=\"A5.T9.1.1.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A5.T9.1.1.1.1\">Prompts:</span> The prisoners are the bad guys, and</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T9.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A5.T9.1.2.1\">PPLM</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A5.T9.1.2.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T9.1.2.2.1\">The prisoners are the bad guys, and herson is Peter, the evil one. And to soothe his pain, he is going to</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T9.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T9.1.3.1\">GeDi</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T9.1.3.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T9.1.3.2.1\">The prisoners are the bad guys, and I was into the struggle for their freedom. At school in Thailand\u2019s Narathiwat prison</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T9.1.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T9.1.4.1\">DExpert</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T9.1.4.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T9.1.4.2.1\">The prisoners are the bad guys, and by setting their cages up so close to the street, they were the least of their problems. But</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T9.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T9.1.5.1\">Prompt</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T9.1.5.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T9.1.5.2.1\">The prisoners are the bad guys, and the good guys are in jail. The bad guys will always get a free pass. The prisoners</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T9.1.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T9.1.6.1\">DisCup</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T9.1.6.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T9.1.6.2.1\">The prisoners are the bad guys, and the prisoners can get away with it, but it\u2019s not the end. We can get more justice if</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T9.1.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"A5.T9.1.7.1\">TOLE</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"A5.T9.1.7.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T9.1.7.2.1\">The prisoners are the bad guys, and people may look down upon them, but many of them behavior well after being released from prison.</p>\n</td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 9: </span>Baselines results for the detoxification task. This table present the final model for each method.</figcaption>\n</figure>",
            "capture": "Table 9: Baselines results for the detoxification task. This table present the final model for each method."
        },
        "10": {
            "table_html": "<figure class=\"ltx_table\" id=\"A5.T10\">\n<div class=\"ltx_flex_figure ltx_flex_table\">\n<div class=\"ltx_flex_cell ltx_flex_size_1\">\n<table class=\"ltx_tabular ltx_centering ltx_flex_size_1 ltx_align_middle\" id=\"A5.T10.1\">\n<tr class=\"ltx_tr\" id=\"A5.T10.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" colspan=\"2\" id=\"A5.T10.1.1.1\">Positive, Asian</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T10.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A5.T10.1.2.1\">Dist. Lens</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A5.T10.1.2.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T10.1.2.2.1\">Once upon a time, great food. the service is great and very friendly.\nAdvertisements - yummy! *** Helpful!! :)</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T10.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T10.1.3.1\">Tailor</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T10.1.3.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T10.1.3.2.1\">Once upon a time, i was a big fan of this establishment. i had been to them a couple times already with friends and the place was always packed with people. this place was a hit, so much so that now I am going to go there every time</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T10.1.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T10.1.4.1\">Prompt-gating</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T10.1.4.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T10.1.4.2.1\">Once upon a time i was at the restaurant and had dinner at a friend\u2019s place, the food was great. the chef is very knowledgeable (the owner\u2019s daughter is a sushi professional), but i can only say that the restaurant was very clean and the food was very flavorful.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T10.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"A5.T10.1.5.1\">TOLE</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"A5.T10.1.5.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T10.1.5.2.1\">Once upon a time, chuan is an awesome restaurant in a strip mall. authentic chinese comfort food with great service. i just love being able to find more modern decor while dining and an excellent dining dining area. while i\u2019ve been here twice and still the least half at the same dining experience is very nice. and if i eat a</p>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ltx_flex_break\"></div>\n<div class=\"ltx_flex_cell ltx_flex_size_1\">\n<table class=\"ltx_tabular ltx_centering ltx_flex_size_1 ltx_align_middle\" id=\"A5.T10.2\">\n<tr class=\"ltx_tr\" id=\"A5.T10.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" colspan=\"2\" id=\"A5.T10.2.1.1\">Positive, American</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T10.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A5.T10.2.2.1\">Dist. Lens</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A5.T10.2.2.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T10.2.2.2.1\">The year is 1910. great food and the service was great. will be back!\nAdvertisements for good sushi!!! Follow me @wendie</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T10.2.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T10.2.3.1\">Tailor</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T10.2.3.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T10.2.3.2.1\">The year is 1910. this is not your average sushi bar. the atmosphere was very casual and cozy. the food was good. the service was prompt and fast. the food was fresh and delicious.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T10.2.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T10.2.4.1\">Prompt-gating</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T10.2.4.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T10.2.4.2.1\">The year is 1910. we went to this place for the first year. it looks nice. there are a couple of booths, a table\nfor 4 (and a counter) to get seated in. we had an early reservation. i ordered the steak. the steak was great. my boyfriend enjoyed the chicken wings. i was very impressed by the steak.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T10.2.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"A5.T10.2.5.1\">TOLE</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"A5.T10.2.5.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T10.2.5.2.1\">The year is 1910. a coffee culture ( not only for coffee ) or a liquor to spend a few dollars to the sugar it in a paper cupcake for an after a long vegas strip\u2019s worth. you can walk to mr. wynn\u2026 that\u2019s how crowded and you could wait for a good cheap meal on the</p>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ltx_flex_break\"></div>\n<div class=\"ltx_flex_cell ltx_flex_size_1\">\n<table class=\"ltx_tabular ltx_centering ltx_flex_size_1 ltx_align_middle\" id=\"A5.T10.3\">\n<tr class=\"ltx_tr\" id=\"A5.T10.3.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" colspan=\"2\" id=\"A5.T10.3.1.1\">Positive, Mexican</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T10.3.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A5.T10.3.2.1\">Dist. Lens</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"A5.T10.3.2.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T10.3.2.2.1\">While this is happening, great food! the margaritas are fantastic and friendly staff. Advertisements = good mexican restaurant! Related</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T10.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T10.3.3.1\">Tailor</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T10.3.3.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T10.3.3.2.1\">While this is happening to be my new favorite restaurant, and my new favorite location, i can\u2019t say that i\u2019ve ever been to this place with all the other reviews. there is a lot of good food at the table, but the wait staff and food is just as great! i love that there are no waiters to take my orders, but that doesn\u2019t mean the food is bad. the food here was good.</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T10.3.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"A5.T10.3.4.1\">Prompt-gating</td>\n<td class=\"ltx_td ltx_align_justify\" id=\"A5.T10.3.4.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T10.3.4.2.1\">While this is happening i\u2019m going here for dinner for the first time. the food here was very, very good and very tasty!!we ordered a couple of different salads and some tacos. i got a vego beef taco with a spicy sauce (it is very good). i also got an onion rings (it does not have any onions, nor are there many onions in this recipe), and it was delicious!</p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A5.T10.3.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"A5.T10.3.5.1\">TOLE</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" id=\"A5.T10.3.5.2\">\n<p class=\"ltx_p ltx_align_top\" id=\"A5.T10.3.5.2.1\">While this is happening, you can select items and choose the sauces and hot salsa ; you \u2019ll realize your face tremb for making a burrito place and a burrito you have to be glad it goes!!! i would highly recommend this joint!!!!!!! you get there at lunchtime, it\u2019s at the plaza</p>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 10: </span>Baselines comparsion for multi-control tasks. This table present the final model for each method.</figcaption>\n</figure>",
            "capture": "Table 10: Baselines comparsion for multi-control tasks. This table present the final model for each method."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.11558v1_figure_1.png",
            "caption": "Figure 1: Overall Framework of our algorithm."
        },
        "2": {
            "figure_path": "2403.11558v1_figure_2.png",
            "caption": "Figure 2: Performance of sentiment control with respect to training steps. \"none\" denotes the variance of no \"quantize\" nor \"noise\". \"gauss.\" denotes the standard Tole with guassian noise. \"sent.\" denotes the variance with sentence-level feedback."
        },
        "3": {
            "figure_path": "2403.11558v1_figure_3.png",
            "caption": "Figure 2: Performance of sentiment control with respect to training steps. \"none\" denotes the variance of no \"quantize\" nor \"noise\". \"gauss.\" denotes the standard Tole with guassian noise. \"sent.\" denotes the variance with sentence-level feedback."
        },
        "4": {
            "figure_path": "2403.11558v1_figure_4.png",
            "caption": "Figure 3: The performance comparison between model variances with or without quantization procedure. The above two subgraphs are from neutral-to-positive experiments. The below are from detoxification."
        },
        "5": {
            "figure_path": "2403.11558v1_figure_5.png",
            "caption": "Figure 3: The performance comparison between model variances with or without quantization procedure. The above two subgraphs are from neutral-to-positive experiments. The below are from detoxification."
        },
        "6": {
            "figure_path": "2403.11558v1_figure_6.png",
            "caption": "Figure 3: The performance comparison between model variances with or without quantization procedure. The above two subgraphs are from neutral-to-positive experiments. The below are from detoxification."
        },
        "7": {
            "figure_path": "2403.11558v1_figure_7.png",
            "caption": "Figure 3: The performance comparison between model variances with or without quantization procedure. The above two subgraphs are from neutral-to-positive experiments. The below are from detoxification."
        },
        "8": {
            "figure_path": "2403.11558v1_figure_8.png",
            "caption": "Figure 4: Final scores of generated samples in explorations. The left is the average of two classifiers. The right is aggregated by \"weigher\"."
        },
        "9": {
            "figure_path": "2403.11558v1_figure_9.png",
            "caption": "Figure 4: Final scores of generated samples in explorations. The left is the average of two classifiers. The right is aggregated by \"weigher\"."
        },
        "10": {
            "figure_path": "2403.11558v1_figure_10.png",
            "caption": "Figure 5: Caption"
        },
        "11": {
            "figure_path": "2403.11558v1_figure_11.png",
            "caption": "Figure 6: Performance (y-axis) on sentiment control task to generate positive/negative sentences from neutral sentences, with varying KL/Entropy coefficient (x-axis)."
        },
        "12": {
            "figure_path": "2403.11558v1_figure_12.png",
            "caption": "Figure 6: Performance (y-axis) on sentiment control task to generate positive/negative sentences from neutral sentences, with varying KL/Entropy coefficient (x-axis)."
        },
        "13": {
            "figure_path": "2403.11558v1_figure_13.png",
            "caption": "Figure 6: Performance (y-axis) on sentiment control task to generate positive/negative sentences from neutral sentences, with varying KL/Entropy coefficient (x-axis)."
        },
        "14": {
            "figure_path": "2403.11558v1_figure_14.png",
            "caption": "Figure 6: Performance (y-axis) on sentiment control task to generate positive/negative sentences from neutral sentences, with varying KL/Entropy coefficient (x-axis)."
        },
        "15": {
            "figure_path": "2403.11558v1_figure_15.png",
            "caption": "Figure 6: Performance (y-axis) on sentiment control task to generate positive/negative sentences from neutral sentences, with varying KL/Entropy coefficient (x-axis)."
        },
        "16": {
            "figure_path": "2403.11558v1_figure_16.png",
            "caption": "Figure 6: Performance (y-axis) on sentiment control task to generate positive/negative sentences from neutral sentences, with varying KL/Entropy coefficient (x-axis)."
        }
    },
    "references": [
        {
            "1": {
                "title": "Scibert: A pretrained language model for scientific text.",
                "author": "Iz Beltagy, Kyle Lo, and Arman Cohan. 2019.",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019, pages 3613\u20133618. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/D19-1371"
            }
        },
        {
            "2": {
                "title": "Cocon: A self-supervised approach for controlled text generation.",
                "author": "Alvin Chan, Yew-Soon Ong, Bill Pung, Aston Zhang, and Jie Fu. 2021.",
                "venue": "In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net.",
                "url": "https://openreview.net/forum?id=VD_ozqvBy4W"
            }
        },
        {
            "3": {
                "title": "Decision transformer: Reinforcement learning via sequence modeling.",
                "author": "Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch. 2021.",
                "venue": "In Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pages 15084\u201315097.",
                "url": "https://proceedings.neurips.cc/paper/2021/hash/7f489f642a0ddb10272b5c31057f0663-Abstract.html"
            }
        },
        {
            "4": {
                "title": "Plug and play language models: A simple approach to controlled text generation.",
                "author": "Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason Yosinski, and Rosanne Liu. 2020.",
                "venue": "In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.",
                "url": "https://openreview.net/forum?id=H1edEyBKDS"
            }
        },
        {
            "5": {
                "title": "Hierarchical neural story generation.",
                "author": "Angela Fan, Mike Lewis, and Yann N. Dauphin. 2018.",
                "venue": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers, pages 889\u2013898. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/V1/P18-1082"
            }
        },
        {
            "6": {
                "title": "Controlling linguistic style aspects in neural language generation.",
                "author": "Jessica Ficler and Yoav Goldberg. 2017.",
                "venue": "CoRR, abs/1707.02633.",
                "url": "http://arxiv.org/abs/1707.02633"
            }
        },
        {
            "7": {
                "title": "Realtoxicityprompts: Evaluating neural toxic degeneration in language models.",
                "author": "Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah A. Smith. 2020.",
                "venue": "In Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020, volume EMNLP 2020 of Findings of ACL, pages 3356\u20133369. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/V1/2020.FINDINGS-EMNLP.301"
            }
        },
        {
            "8": {
                "title": "Domain-specific language model pretraining for biomedical natural language processing.",
                "author": "Yu Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto Usuyama, Xiaodong Liu, Tristan Naumann, Jianfeng Gao, and Hoifung Poon. 2022a.",
                "venue": "ACM Trans. Comput. Heal., 3(1):2:1\u20132:23.",
                "url": "https://doi.org/10.1145/3458754"
            }
        },
        {
            "9": {
                "title": "A distributional lens for multi-aspect controllable text generation.",
                "author": "Yuxuan Gu, Xiaocheng Feng, Sicheng Ma, Lingyuan Zhang, Heng Gong, and Bing Qin. 2022b.",
                "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 1023\u20131043. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/V1/2022.EMNLP-MAIN.67"
            }
        },
        {
            "10": {
                "title": "Controllable text generation via probability density estimation in the latent space.",
                "author": "Yuxuan Gu, Xiaocheng Feng, Sicheng Ma, Lingyuan Zhang, Heng Gong, Weihong Zhong, and Bing Qin. 2023.",
                "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 12590\u201312616. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2023.acl-long.704"
            }
        },
        {
            "11": {
                "title": "Don\u2019t stop pretraining: Adapt language models to domains and tasks.",
                "author": "Suchin Gururangan, Ana Marasovic, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, and Noah A. Smith. 2020.",
                "venue": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020, pages 8342\u20138360. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2020.acl-main.740"
            }
        },
        {
            "12": {
                "title": "An extensible plug-and-play method for multi-aspect controllable text generation.",
                "author": "Xuancheng Huang, Zijun Liu, Peng Li, Tao Li, Maosong Sun, and Yang Liu. 2023.",
                "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 15233\u201315256. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2023.acl-long.849"
            }
        },
        {
            "13": {
                "title": "Offline reinforcement learning as one big sequence modeling problem.",
                "author": "Michael Janner, Qiyang Li, and Sergey Levine. 2021.",
                "venue": "In Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pages 1273\u20131286.",
                "url": "https://proceedings.neurips.cc/paper/2021/hash/099fe6b0b444c23836c4a5d07346082b-Abstract.html"
            }
        },
        {
            "14": {
                "title": "CTRL: A conditional transformer language model for controllable generation.",
                "author": "Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, and Richard Socher. 2019.",
                "venue": "CoRR, abs/1909.05858.",
                "url": "http://arxiv.org/abs/1909.05858"
            }
        },
        {
            "15": {
                "title": "A distributional approach to controlled text generation.",
                "author": "Muhammad Khalifa, Hady Elsahar, and Marc Dymetman. 2021.",
                "venue": "In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net.",
                "url": "https://openreview.net/forum?id=jWkw45-9AbL"
            }
        },
        {
            "16": {
                "title": "Gedi: Generative discriminator guided sequence generation.",
                "author": "Ben Krause, Akhilesh Deepak Gotmare, Bryan McCann, Nitish Shirish Keskar, Shafiq R. Joty, Richard Socher, and Nazneen Fatema Rajani. 2021.",
                "venue": "In Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November, 2021, pages 4929\u20134952. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2021.findings-emnlp.424"
            }
        },
        {
            "17": {
                "title": "Controlled text generation as continuous optimization with multiple constraints.",
                "author": "Sachin Kumar, Eric Malmi, Aliaksei Severyn, and Yulia Tsvetkov. 2021.",
                "venue": "In Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pages 14542\u201314554.",
                "url": "https://proceedings.neurips.cc/paper/2021/hash/79ec2a4246feb2126ecf43c4a4418002-Abstract.html"
            }
        },
        {
            "18": {
                "title": "Multiple-attribute text rewriting.",
                "author": "Guillaume Lample, Sandeep Subramanian, Eric Michael Smith, Ludovic Denoyer, Marc\u2019Aurelio Ranzato, and Y-Lan Boureau. 2019.",
                "venue": "In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net.",
                "url": "https://openreview.net/forum?id=H1g2NhC5KQ"
            }
        },
        {
            "19": {
                "title": "A diversity-promoting objective function for neural conversation models.",
                "author": "Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2016.",
                "venue": "In NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, San Diego California, USA, June 12-17, 2016, pages 110\u2013119. The Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/V1/N16-1014"
            }
        },
        {
            "20": {
                "title": "Diffusion-lm improves controllable text generation.",
                "author": "Xiang Li, John Thickstun, Ishaan Gulrajani, Percy Liang, and Tatsunori B. Hashimoto. 2022.",
                "venue": "In NeurIPS.",
                "url": "http://papers.nips.cc/paper_files/paper/2022/hash/1be5bc25d50895ee656b8c2d9eb89d6a-Abstract-Conference.html"
            }
        },
        {
            "21": {
                "title": "Prefix-tuning: Optimizing continuous prompts for generation.",
                "author": "Xiang Lisa Li and Percy Liang. 2021.",
                "venue": "In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021, pages 4582\u20134597. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2021.acl-long.353"
            }
        },
        {
            "22": {
                "title": "Plug-and-blend: A framework for plug-and-play controllable story generation with sketches.",
                "author": "Zhiyu Lin and Mark O. Riedl. 2021.",
                "venue": "In Proceedings of the Seventeenth AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, AIIDE 2021, virtual, October 11-15, 2021, pages 58\u201365. AAAI Press.",
                "url": "https://ojs.aaai.org/index.php/AIIDE/article/view/18891"
            }
        },
        {
            "23": {
                "title": "Dexperts: Decoding-time controlled text generation with experts and anti-experts.",
                "author": "Alisa Liu, Maarten Sap, Ximing Lu, Swabha Swayamdipta, Chandra Bhagavatula, Noah A. Smith, and Yejin Choi. 2021.",
                "venue": "In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021, pages 6691\u20136706. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2021.acl-long.522"
            }
        },
        {
            "24": {
                "title": "Roberta: A robustly optimized BERT pretraining approach.",
                "author": "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.",
                "venue": "CoRR, abs/1907.11692.",
                "url": "http://arxiv.org/abs/1907.11692"
            }
        },
        {
            "25": {
                "title": "QUARK: controllable text generation with reinforced unlearning.",
                "author": "Ximing Lu, Sean Welleck, Jack Hessel, Liwei Jiang, Lianhui Qin, Peter West, Prithviraj Ammanabrolu, and Yejin Choi. 2022.",
                "venue": "In NeurIPS.",
                "url": "http://papers.nips.cc/paper_files/paper/2022/hash/b125999bde7e80910cbdbd323087df8f-Abstract-Conference.html"
            }
        },
        {
            "26": {
                "title": "Controllable natural language generation with contrastive prefixes.",
                "author": "Jing Qian, Li Dong, Yelong Shen, Furu Wei, and Weizhu Chen. 2022.",
                "venue": "In Findings of the Association for Computational Linguistics: ACL 2022, Dublin, Ireland, May 22-27, 2022, pages 2912\u20132924. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/V1/2022.FINDINGS-ACL.229"
            }
        },
        {
            "27": {
                "title": "Scaling language models: Methods, analysis & insights from training gopher.",
                "author": "Jack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, H. Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, Eliza Rutherford, Tom Hennigan, Jacob Menick, Albin Cassirer, Richard Powell, George van den Driessche, Lisa Anne Hendricks, Maribeth Rauh, Po-Sen Huang, Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saffron Huang, Jonathan Uesato, John Mellor, Irina Higgins, Antonia Creswell, Nat McAleese, Amy Wu, Erich Elsen, Siddhant M. Jayakumar, Elena Buchatskaya, David Budden, Esme Sutherland, Karen Simonyan, Michela Paganini, Laurent Sifre, Lena Martens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gribovskaya, Domenic Donato, Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong, Daniel Toyama, Cyprien de Masson d\u2019Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan Clark, Diego de Las Casas, Aurelia Guy,\nChris Jones, James Bradbury, Matthew J. Johnson, Blake A. Hechtman, Laura Weidinger, Iason Gabriel, William Isaac, Edward Lockhart, Simon Osindero, Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu, and Geoffrey Irving. 2021.",
                "venue": "CoRR, abs/2112.11446.",
                "url": "http://arxiv.org/abs/2112.11446"
            }
        },
        {
            "28": {
                "title": "Proximal policy optimization algorithms.",
                "author": "John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. 2017.",
                "venue": "CoRR, abs/1707.06347.",
                "url": "http://arxiv.org/abs/1707.06347"
            }
        },
        {
            "29": {
                "title": "Ethical and social risks of harm from language models.",
                "author": "Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh, Zac Kenton, Sasha Brown, Will Hawkins, Tom Stepleton, Courtney Biles, Abeba Birhane, Julia Haas, Laura Rimell, Lisa Anne Hendricks, William Isaac, Sean Legassick, Geoffrey Irving, and Iason Gabriel. 2021.",
                "venue": "CoRR, abs/2112.04359.",
                "url": "http://arxiv.org/abs/2112.04359"
            }
        },
        {
            "30": {
                "title": "Fine-grained human feedback gives better rewards for language model training.",
                "author": "Zeqiu Wu, Yushi Hu, Weijia Shi, Nouha Dziri, Alane Suhr, Prithviraj Ammanabrolu, Noah A. Smith, Mari Ostendorf, and Hannaneh Hajishirzi. 2023.",
                "venue": "CoRR, abs/2306.01693.",
                "url": "https://doi.org/10.48550/ARXIV.2306.01693"
            }
        },
        {
            "31": {
                "title": "Hyper-decision transformer for efficient online policy adaptation.",
                "author": "Mengdi Xu, Yuchen Lu, Yikang Shen, Shun Zhang, Ding Zhao, and Chuang Gan. 2023.",
                "venue": "In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net.",
                "url": "https://openreview.net/pdf?id=AatUEvC-Wjv"
            }
        },
        {
            "32": {
                "title": "FUDGE: controlled text generation with future discriminators.",
                "author": "Kevin Yang and Dan Klein. 2021.",
                "venue": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021, pages 3511\u20133535. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2021.naacl-main.276"
            }
        },
        {
            "33": {
                "title": "Tailor: A soft-prompt-based approach to attribute-based controlled text generation.",
                "author": "Kexin Yang, Dayiheng Liu, Wenqiang Lei, Baosong Yang, Mingfeng Xue, Boxing Chen, and Jun Xie. 2023a.",
                "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 410\u2013427. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2023.acl-long.25"
            }
        },
        {
            "34": {
                "title": "Preference-grounded token-level guidance for language model fine-tuning.",
                "author": "Shentao Yang, Shujian Zhang, Congying Xia, Yihao Feng, Caiming Xiong, and Mingyuan Zhou. 2023b.",
                "venue": "CoRR, abs/2306.00398.",
                "url": "https://doi.org/10.48550/ARXIV.2306.00398"
            }
        },
        {
            "35": {
                "title": "Discup: Discriminator cooperative unlikelihood prompt-tuning for controllable text generation.",
                "author": "Hanqing Zhang and Dawei Song. 2022.",
                "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 3392\u20133406. Association for Computational Linguistics.",
                "url": "https://aclanthology.org/2022.emnlp-main.223"
            }
        },
        {
            "36": {
                "title": "Online decision transformer.",
                "author": "Qinqing Zheng, Amy Zhang, and Aditya Grover. 2022.",
                "venue": "In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 27042\u201327059. PMLR.",
                "url": "https://proceedings.mlr.press/v162/zheng22c.html"
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.11558v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3",
            "3.4"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.2",
            "4.3",
            "4.4"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4.4"
        ]
    },
    "research_context": {
        "paper_id": "2403.11558v1",
        "paper_title": "Reinforcement Learning with Token-level Feedback for Controllable Text Generation",
        "research_background": "**Motivation:**\nThe primary motivation for this research lies in addressing the urgent need for controllable text generation (CTG) in real-world applications using large autoregressive language models (LLMs). While LLMs are proficient at generating high-quality text, they often lack the ability to modulate specific attributes such as sentiment or formality. This control is critical for practical applications like ensuring positive sentiment in psychological support or maintaining formality in academic writing. Additionally, there is a need to mitigate inherent flaws in pre-trained language models, such as toxicity and repetition.\n\n**Research Problem:**\nThe main research problem focuses on improving the controllability of text generated by LLMs without incurring significant computational overheads or compromising text quality. Current methods often fall short due to the following reasons:\n- Retraining approaches demand substantial computational resources as model sizes grow.\n- Post-processing techniques typically utilize small-scale discriminators that can degrade text quality.\n- Parameter-efficient strategies like prefix-tuning may still inherit undesired traits from supervised corpora.\n- Alternative models (e.g., diffusion models, normalized flow) introduce high computational costs and longer inference times.\n\nCurrent RL-based CTG methods offer a promising solution by training on self-generated sentences and integrating parameter-efficient strategies. However, these methods are hindered by their reliance on sentence-level or paragraph-level rewards, which are coarse-grained and lead to suboptimal performance and slow convergence.\n\n**Relevant Prior Work:**\n1. **Controllable Text Generation**:\n   - Enhancing attributes like sentiment and formality is discussed in works by Beltagy et al. (2019), Gu et al. (2022a), and Gururangan et al. (2020).\n   - Addressing intrinsic defects like toxicity and repetition is covered by Rae et al. (2021) and Weidinger et al. (2021).\n\n2. **Retraining Models**:\n   - Chan et al. (2021) and Keskar et al. (2019) acknowledge the computational burdens of retraining models as they scale.\n\n3. **Post-processing Methods**:\n   - Techniques by Krause et al. (2021), Yang and Klein (2021), and Liu et al. (2021) often lead to degraded text quality due to small-scale discriminators.\n\n4. **Parameter-efficient Strategies**:\n   - Strategies like prefix-tuning are adopted by Zhang and Song (2022), Yang et al. (2023a), and Huang et al. (2023), but are limited by supervised corpus attributes.\n\n5. **Alternative Models**:\n   - Li et al. (2022), Gu et al. (2022b, 2023) introduce other algorithms like diffusion models and normalized flow yet face computational and inference challenges.\n\n6. **Reinforcement Learning in CTG**:\n   - Reinforcement learning approaches for CTG as explored by Khalifa et al. (2021) and Lu et al. (2022) can reduce overfitting via self-generated sentences and integrate parameter-efficient strategies but suffer from the inefficiencies of coarse-grained feedback.\n\n**Proposed Solution:**\nThe paper proposes a novel reinforcement learning algorithm named TOLE (TOken-LEvel guidance), which granularizes coarse-grained feedback to provide precise guidance for LLMs. This algorithm harnesses Bayesian Factorization to formulate token-level rewards based on attribute classifier probability shifts, uses an exploration framework to enhance robustness via a \"First quantize, then noise\" procedure, and efficiently extends to multi-attribute scenarios.",
        "methodology": "Certainly! Based on the section title \"Methodology: We will first establish the notation, provide some background on existing RL methods in controllable text generation and model alignment, and offer an overview of our algorithm,\" here is the proposed method or model, including key components and innovations:\n\n**Reinforcement Learning (RL) with Token-Level Feedback for Controllable Text Generation**\n\n**1. Establish Notation**\nWe establish the notation to set a consistent framework for discussing the new methodology. \n\n**2. Background on Existing RL Methods**\nWe provide an overview of current reinforcement learning methods applied in controllable text generation and model alignment. This step includes a brief summary of traditional approaches and their limitations in providing fine-grained control over the generated text.\n\n**3. Key Components of the Proposed Method**\n     - **Token-Level Feedback**: Unlike conventional methods which may provide feedback at the sentence or document level, our approach introduces token-level feedback. This granularity allows more precise adjustments and refinements of text generation as it progresses, leading to higher quality and more controllable outputs.\n     - **RL Algorithm**: An overview of the specific reinforcement learning algorithm employed, detailing how it incorporates token-level feedback. This may involve defining the reward function, the states and actions within the RL framework, and how the model learns and updates its policies based on the feedback received.\n    \n**4. Model Alignment**\nWe discuss strategies to align the generated text with desired attributes or goals, using token-level feedback to guide the model iteratively towards better performance and closer adherence to specified criteria.\n\nBy retaining the original wording and phrases, the proposed methodology appears innovative primarily due to its focus on token-level feedback within the reinforcement learning paradigm. This fine-grained level of control is a key component that differentiates it from prior approaches in the field.\n\nWould you like a more detailed breakdown of any specific part?",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n#### Model Categories\n\nThe models evaluated in the main experiment are categorized into three strategies for controllable text generation: Post-processing, Fine-tuning, and Reinforcement Learning.\n\n#### Datasets\n\nThe specific datasets used for training and evaluating the models are not explicitly mentioned in the provided snippet. However, typical controllable text generation tasks generally involve datasets labeled with the desired target attributes, such as sentiment.\n\n#### Baselines\n\n1. **Post-processing Methods:**\n   - **PPLM**\n   - **GeDi**\n   - **FUDGE**\n  \n2. **Fine-Tuning Methods:**\n   - **Prompt**\n   - **DisCup**\n  \n3. **Reinforcement Learning Methods:**\n   - **PPO**\n   - **Quark**\n   - **TOLE**\n\n#### Evaluation Metrics\n\n1. **Attribute Correctness (CR):** Measures how accurately the generated text aligns with the desired target attributes (positive, negative, and neutral).\n2. **PPL (Perplexity):** Measures the fluency of the generated text, with lower values indicating more fluent text.\n3. **dist-3:** Measures lexical diversity based on the number of distinct trigrams, with higher values indicating more diverse text.\n\n#### Main Experimental Results\n\nThe following results represent the models' performance metrics in different target sentiment categories (Positive, Negative, Neutral):\n\n1. **PPLM:**\n   - Positive: CR (8.72), PPL (122.41), dist-3 (0.90)\n   - Negative: CR (52.68), PPL (60.95), dist-3 (3.47)\n   - Neutral: CR (10.26), PPL (122.41), dist-3 (0.90)\n   \n2. **GeDi:**\n   - Positive: CR (26.80), PPL (138.27), dist-3 (0.86)\n   - Negative: CR (86.01), PPL (91.27), dist-3 (3.62)\n   - Neutral: CR (60.43), PPL (138.27), dist-3 (0.86)\n\n3. **FUDGE:**\n   - Positive: CR (56.04), PPL (265.79), dist-3 (0.83)\n   - Negative: CR (96.92), PPL (98.76), dist-3 (1.53)\n   - Neutral: CR (66.84), PPL (265.79), dist-3 (0.83)\n\n4. **Prompt:** \n   - Positive: CR (40.88), PPL (39.55), dist-3 (0.73)\n   - Negative: CR (78.08), PPL (73.20), dist-3 (63.08)\n   - Neutral: CR (49.28), PPL (39.55), dist-3 (0.73)\n   \n5. **DisCup:**\n   - Positive: CR (49.92), PPL (40.46), dist-3 (0.75)\n   - Negative: CR (91.58), PPL (90.64), dist-3 (3.72)\n   - Neutral: CR (60.80), PPL (40.46), dist-3 (0.75)\n\n6. **PPO:**\n   - Positive: CR (43.13), PPL (18.34), dist-3 (0.71)\n   - Negative: CR (94.10), PPL (94.95), dist-3 (2.95)\n   - Neutral: CR (68.12), PPL (18.34), dist-3 (0.71)\n\n7. **Quark:**\n   - Positive: CR (47.32), PPL (16.92), dist-3 (0.75)\n   - Negative: CR (95.50), PPL (96.65), dist-3 (2.63)\n   - Neutral: CR (70.50), PPL (16.92), dist-3 (0.75)\n\n8. **TOLE:**\n   - Positive: CR (69.36), PPL (17.05), dist-3 (0.75)\n   - Negative: CR (97.16), PPL (98.02), dist-3 (2.61)\n   - Neutral: CR (72.81), PPL (17.05), dist-3 (0.75)\n\nThe results show that the TOLE model, under the reinforcement learning category, achieves the highest attribute correctness across all sentiment targets (positive, negative, and neutral) with relatively low perplexity, indicating controlled and fluent text generation with high attribute accuracy."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "The study aims to understand the impact of 'Quantization' and 'Noise' on the performance of a new reinforcement learning algorithm designed for controllable text generation. The goal is to see how these methods affect sentiment control tasks.",
            "experiment_process": "The experiment involved implementing two variations of the algorithm: one using direct scores output by classifiers as rewards without interference, and another that applies noise to the reward without quantization boundaries. The performance transitions over training steps of sentiment control tasks were then monitored and visualized in two different figures. Additionally, a further experiment involved comparing the model's convergence speed using token-level feedback versus sentence-level feedback.",
            "result_discussion": "The results showed that without any interference, both control accuracy and text diversity decrease over training steps. With the noising procedure, higher attribute accuracy was achieved despite slower initial convergence, and increased text diversity was maintained. Applying quantization boundaries improved the stability of the algorithms compared to just adding noise. Token-level feedback provided denser and more precise signals, thus requiring fewer learning steps to achieve ideal performance. The number of quantiles affected the convergence speed but not the final performance significantly. Higher values of the KL-divergence coefficient increased text fluency slightly at the expense of controllability, while the entropy term had a minor impact on performance.",
            "ablation_id": "2403.11558v1.No1"
        },
        {
            "research_objective": "This part investigates the effect of removing the 'weigher' from multi-attribute combination rewards and replacing it with averages as overall rewards.",
            "experiment_process": "A model variation was implemented that combines several scorers by averaging their output scores. The scores were then compared using both averaging and aggregating by 'weigher', and the results were displayed in a table and corresponding figures.",
            "result_discussion": "Results indicated that removing the 'weigher' led to a performance decrease. Averaging the scores resulted in values that clustered within small ranges due to scorer contradiction, whereas aggregation by 'weigher' provided clearer guidance. Thus, the 'weigher' aids in avoiding contradictions between different scorers and offers distinct and effective guidance for model training.",
            "ablation_id": "2403.11558v1.No2"
        }
    ]
}