{
    "title": "Continuous Language Model Interpolation for Dynamic and Controllable Text Generation",
    "abstract": "As large language models (LLMs) have gained popularity for a variety of use cases, making them adaptable and controllable has become increasingly important, especially for user-facing applications. While the existing literature on LLM adaptation primarily focuses on finding a model (or models) that optimizes a single predefined objective, here we focus on the challenging case where the model must dynamically adapt to diverse \u2014and often changing\u2014 user preferences. For this, we leverage adaptation methods based on linear weight interpolation, casting them as continuous multi-domain interpolators that produce models with specific prescribed generation characteristics on-the-fly. Specifically, we use low-rank updates to fine-tune a base model to various different domains, yielding a set of anchor models with distinct generation profiles. Then, we use the weight updates of these anchor models to parametrize the entire (infinite) class of models contained within their convex hull. We empirically show that varying the interpolation weights yields predictable and consistent change in the model outputs with respect to all of the controlled attributes. We find that there is little entanglement between most attributes and identify and discuss the pairs of attributes for which this is not the case. Our results suggest that linearly interpolating between the weights of fine-tuned models facilitates predictable, fine-grained control of model outputs with respect to multiple stylistic characteristics simultaneously.111Code: https://github.com/skangasl/continuous-lm-interpolation",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Large language models (LLMs) are used for a diverse set of applications due to their high performance across a wide spectrum of tasks (Bubeck et al., 2023  ###reference_b1###). In many common LLM use cases (such as chatbots), different users often have distinct and continuously evolving preferences for the type of output they want. For example, a user might want a creative and verbose response for certain queries, but a concise and precise response for others. In practice, a user may try different variations of the same query succesively until they elicit a generation that matches their goal. This trial-and-error process can be time-consuming and lacks guaranteed results, especially since minor word changes in a prompt can have disproportionate impact on the output. Additionally, expressing fine-grained continuous preferences (e.g., simplicity of the response) is often difficult in\u2004\u2014inherently discrete\u2014\u2004natural language. These challenges are exacerbated when the user has complex, multi-faceted preferences (e.g., a specific combination of simplicity, formality, and verbosity) that they expect the generation to satisfy all at once. As a result, there is a pressing need for methods that allow for fine-grained and predictable control over LLM text generation, and which can adapt on-the-fly to mutable user preferences and constraints.\nPrior work in controllable text generation (CTG) has largely focused on optimizing for one set of control criteria through techniques such as instruction tuning (Zhou et al., 2023  ###reference_b39###), modifying the output probability distributions (Pascual et al., 2021  ###reference_b26###; Yang & Klein, 2021  ###reference_b37###; Dekoninck et al., 2024  ###reference_b2###), changing model activations at inference time (Li et al., 2023  ###reference_b18###), learning modifications to the embeddings (Li & Liang, 2021  ###reference_b19###; Han et al., 2023  ###reference_b7###), or training (Keskar et al., 2019  ###reference_b14###; Krause et al., 2021  ###reference_b16###). These methods, however, do not naturally allow for the composition of multiple objectives and lack fine-grained control, especially those that rely on the user expressing preferences in natural language, for the reasons described above. Embedding modification and inference-time approaches do not allow for as complex tuning to the objective as fine-tuning based ones and often require additional training for each control variable value. While fine-tuning to each desired objective would likely allow for the most precise optimization, this is computationally infeasible to do for each combination of control variables and strengths of control in the entire (infinite) set of possible combinations.\nWith these challenges in mind, here we seek to enable dynamic and controllable text generation in a manner that takes advantage of the strengths of fine-tuning while remaining computationally feasible for dynamically changing control variables. Recent work has demonstrated that multiple pre-trained or fine-tuned models can be effectively composed through linear weight interpolation (Wortsman et al., 2022  ###reference_b34###; Ilharco et al., 2023  ###reference_b11###). This has also been shown to extend to models trained with parameter-efficient fine-tuning (PEFT) methods (Zhang et al., 2023  ###reference_b38###; Huang et al., 2024  ###reference_b10###) such as low-rank adaptation (Hu et al., 2021  ###reference_b9###). We build upon and extend this line of work by showing that linear weight interpolation can be used to obtain models with specific mixtures of characteristics on-the-fly and without additional training, effectively providing a continuous parametrization of the (infinite) \u2018convex hull\u2019 of a set of fine-tuned models. To do so, we fine-tune two endpoint anchor models for each control attribute, one at each extreme of attribute strength. We then interpolate along the vector between the weights of these two models for each attribute before computing a weighted average across all of the single-attribute interpolated models. Thus, varying the interpolation and averaging weights gives us dense coverage of the model parameter space, allowing us to create models tailored to any preference profile spanned by the fine-tuned models. We evaluate linear weight interpolation for multiple style attributes and demonstrate empirically that changes in the interpolation and averaging weights yield predictable and consistent responses in the level of each attribute in the generated text.\n###figure_1### A potential pitfall of this approach is that, as seen in prior work in the vision domain (Ortiz-Jimenez et al., 2023  ###reference_b25###), the weights for different single-attribute interpolated models may be entangled. This could lead to unexpected correlations between attributes in the averaged models. These correlations are detrimental to CTG, as changing the interpolation weights for one attribute could have an unexpected effect on the correlated attributes in the output text. However, we find that there is surprisingly little entanglement between the vast majority of control attributes and analyze the pairs of controls where this is not the case.\nIn summary, our key contributions are: (1) we show how parameter-efficient adaptation methods can be used to continuously interpolate between models fine-tuned with various distinct generation objectives, allowing for on-the-fly adaptation to user-specified generation preferences expressed in terms of interpretable control variables; and (2) we demonstrate that changes in the interpolation yield smooth and predictable changes in the properties of the generated text across multiple sets of controls with limited entanglement."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Fine-tuning and weight interpolation",
            "text": "We evaluate the ability of weight interpolation to control the outputs of LLMs on five commonly used style attributes defined in prior style transfer literature (Jin et al., 2022  ###reference_b13###): simplicity, formality, politeness, sentiment, and humor. For every style characteristic, we first fine-tune two endpoint \u2018anchor\u2019 models, each of which optimizes for one extreme of the style attribute. We then use these models as the basis of the interpolation scheme."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Datasets",
            "text": "For each style attribute, we fine-tune a separate anchor Llama2-7b model (Touvron et al., 2023  ###reference_b32###) on two datasets representing the extremes of the attribute level. For simplicity, we use the TinyStories dataset (Eldan & Li, 2023  ###reference_b3###) to fine-tune a simple model and novel chapters from the BookSum dataset (Kryscinski et al., 2021  ###reference_b17###) to fine-tune a complex model. We use the documents classified as formal and informal in Grammarly\u2019s Yahoo Answers Formality Corpus (GYAFC) dataset (Rao & Tetreault, 2018  ###reference_b29###) to fine-tune formal and informal models. For the politeness attribute, we use the documents in the highest and lowest politeness class in the work by Madaan et al. (2020  ###reference_b21###) for fine-tuning polite and impolite models, respectively. We fine-tune positive and negative sentiment models using the Stanford Sentiment Treebank (SST-2) dataset (Socher et al., 2013  ###reference_b30###). For humor, we use the FlickrStyle dataset (Gan et al., 2017  ###reference_b5###) to fine-tune humorous and non-humorous models."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Fine-tuning",
            "text": "We employ Low-Rank Adaptation (LoRA) in order to fine-tune our models in a parameter-efficient manner (Hu et al., 2021  ###reference_b9###). In LoRA fine-tuning, at each layer of the transformer model, the pretrained model weights are frozen and low-rank decomposition matrices are learned to adapt the model in fine-tuning. Denoting the pretrained language model weights as , LoRA computes the updated weights as follows:\nHere,  and  (with ) are trainable parameters learned during fine-tuning. We use LoRA as an adaptation method because it requires significantly fewer parameters than traditional fine-tuning while maintaining similar performance, so LoRA weights can be quickly modified and applied to large pretrained language models. We use the parameters in Appendix A.1  ###reference_### for fine-tuning the models and fine-tune two LoRA models per style characteristic, one on each of the extreme classes outlined in 2.1  ###reference_###."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "Linear weight interpolation",
            "text": "We formulate linear weight interpolation between the LoRA fine-tuned models in terms of interpolation weights  and attribute mixing weights  as shown in Figure 1  ###reference_###. We denote  and  as the two LoRA fine-tuned endpoint anchor models for attribute . Then, for a single attribute, we interpolate along the vector between the two fine-tuned endpoint models by computing\nWe call  the interpolation weight for the th attribute dimension. We note that  and  correspond to letting the interpolated model equal the fine-tuned models  and , respectively. Using Equation 2  ###reference_###, we then combine multiple interpolated models  by taking their weighted sum:\nWe denote  to be the mixing weight for the th attribute and constrain . We note that the case with one attribute dimension corresponds to the sum having a single term with . With this formulation, we can construct any model in the convex hull of the fine-tuned models by choosing appropriate interpolation weights  and mixing weights .\n###figure_2### ###figure_3### ###figure_4###"
        },
        {
            "section_id": "2.4",
            "parent_section_id": "2",
            "section_name": "Evaluation",
            "text": "To evaluate the generations of each interpolated model, we use a subset of 1k randomly sampled prompts from the WritingPrompts dataset (Fan et al., 2018  ###reference_b4###) and generate 3 continuations for each prompt. We compute scores for each of the attributes to evaluate the level of each control criterion. Similarly to prior work on text style transfer (Xu et al., 2018  ###reference_b35###), we fine-tune a RoBERTa (Liu et al., 2019  ###reference_b20###) classification head on each attribute and compute a sigmoid over the output logits to obtain the probability of class , which we report as the attribute score. We label the documents such that an attribute score closer to  corresponds to a document that is more simple, formal, polite, positive in sentiment, or humorous. We also compute perplexity on the test split of the WikiText dataset (Merity et al., 2016  ###reference_b23###) to evaluate model fluency."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Continuous Language Model Interpolation",
            "text": "We begin by investigating the linear interpolations between each pair of low-rank fine-tuned anchor models (3.1  ###reference_###). We then extend this analysis to the convex hull of fine-tuned models for multiple attributes (3.2  ###reference_###).\n###figure_5###"
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Linear interpolation for a single attribute dimension",
            "text": "We first explore the effect of moving along the vector between a single pair of fine-tuned anchor models. We note that  and  correspond to the two fine-tuned anchor models, while  is an interpolation along the vector between the two models and  is a linear extrapolation along the vector between the models.\nLinear interpolation: Figure 2  ###reference_### shows the effect of  on attribute score. For all of the attributes, when interpolating between the two fine-tuned models (Figure 1(a)  ###reference_sf1###), as  increases, there is a smooth increase in the attribute score for all of the control dimensions. The model output quality also remains high, as for every attribute the perplexity in the interpolation region is either less than or between the perplexities of the two fine-tuned models (Figure 3  ###reference_###). These results indicate that for one control attribute, interpolating between two endpoint models yields fine-grained control over the model outputs. Furthermore, similarly to Dekoninck et al. (2024  ###reference_b2###), the trend of increase with  appears linear in some cases (and nonlinear in others). For the majority of the attribute dimensions (politeness, formality, and simplicity) we observe a linear increase in the score as  increases in the interpolation region. On the other hand, the other control dimensions (sentiment and humor) have a nonlinear increase in attribute score with  due to plateaus at one or more of the extremes.\nLinear extrapolation: Figure 1(b)  ###reference_sf2### shows the attribute scores when extrapolating linearly beyond the two fine-tuned models along the vector between them. We find that even beyond the region of interpolation between the two fine-tuned models, there is a small stable extrapolation regime up to  values of around  and  (Figure 1(b)  ###reference_sf2###). In this region, for many of the attributes, the attribute score continues to behave predictably as  is increased. However, beyond the stable extrapolation values, there is an unstable extrapolation regime where the attribute score changes unpredictably as  is varied. This is likely due to the model output quality degrading, since as shown in Figure 3  ###reference_###, the model perplexity increases sharply starting near the edges of the stable extrapolation regime. While prior work has shown that linear weight extrapolation can be used for tasks such as model unlearning (Ilharco et al., 2023  ###reference_b11###; Zhang et al., 2023  ###reference_b38###), these results provide a cautionary tale against extrapolating too far, as they suggest that this ability only extends to a certain threshold before the attribute score and model outputs become unpredictable due to poor quality outputs. For the remainder of our experiments, we thus focus on the interpolation regime."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Multi-dimensional interpolation",
            "text": "In real-world LLM applications, users often have diverse output preferences across multiple control dimensions at once, and these preferences may change dynamically for different inputs to the LLM. In this section, we show that linear interpolation between fine-tuned parameter-efficient adapters can be used to parametrize a whole convex hull of models, which can be used to dynamically generate text with attribute levels specified on-the-fly."
        },
        {
            "section_id": "3.2.1",
            "parent_section_id": "3.2",
            "section_name": "3.2.1 Parametrization of the convex hull",
            "text": "Fine-grained analysis of the interpolation parameter : We find that when interpolating across up to five attribute dimensions, modifying the weight parameters  and  results in predictable, fine-grained control over the attribute scores for the desired attributes while having a comparatively small effect on the remaining attributes. Each spider plot in Figure 4  ###reference_### shows that increasing the  parameter for interpolating between the fine-tuned models increases the attribute score for the th attribute while the other scores remain fairly constant. Similarly, as the model mixture parameter  increases, the effect on the attribute score of changing  increases. While there is also more effect on the other attributes as  increases, this effect is still comparatively small in relation to the effect on the desired attribute.\n###figure_6### ###figure_7### Fine-grained analysis of the mixing parameter : The effect of  is further demonstrated in Figure 4(a)  ###reference_sf1###, which plots the scores from Figure 4  ###reference_### for each attribute dimension and  value when  across all values of  for the other control dimensions. We note that in this case, increasing  should upweight the  model and thus decrease the attribute score. Figure 4(b)  ###reference_sf2### is the analogous plot for , showing the scores averaged across all combinations of weights from Figure 11  ###reference_### when  for the attribute dimension being plotted. In this case, increasing  should increase the score, since the weight of the  model is increasing. Combined, these plots shows that as  increases, the output scores move smoothly toward the desired extreme model for both the  and  case, showing that the  parameter also provides fine-grained control over the model outputs.\n###figure_8### ###figure_9### ###figure_10### ###figure_11### ###figure_12### ###figure_13### Changing mixing parameters  for multiple attributes at once: We also analyze the relationship throughout the whole simplex of  weights for sets of three control dimensions in Figures 6  ###reference_### and 7  ###reference_### (as well as Figures 12  ###reference_###-21  ###reference_### in the Appendix). For each set of three attributes listed, these plots show the scores in the three dimensional simplex of mixing weights  for which . The value of the interpolation weight  for each of the attributes is equal to 1 in Figures 6  ###reference_### and 7  ###reference_###, so increasing the  weight of each attribute should increase the attribute score. We find that surprisingly, there is very limited entanglement between the majority of the combinations of attributes (such as in Figure 6  ###reference_###). In these cases, we observe an approximately even increase in score as  for a given attribute dimension increases, regardless of the other  parameters.\nHowever, in the case of humor in the humor-formality-simplicity simplex and formality in the humor-formality-simplicity simplex with  (Figure 7  ###reference_###) and the sentiment-politeness-formality simplex with  (Figure 17  ###reference_###), we observe regions at the corners of the simplex that are close to the other fine-tuned models and have a high attribute score. This is because these other models are correlated with a positive attribute score, so the mixture of models is the most neutral model. Nevertheless, this still has a limited effect on the attribute score, since even in these cases with correlations, the score still has the expected behavior unless the mixing weight  is greater than around  to  for the correlated control dimensions. This indicates that in practice, the model has smoothly increasing attribute scores with  for all pairs of attributes when  for the other attribute dimensions remains sufficiently low.\nThese results demonstrate that as the parameters  and  are increased for the th attribute, there is a significant effect on the attribute score for the th control dimension and a limited effect on the scores for the remaining attributes. Therefore,  and  parametrize the convex hull of models between all of the attribute dimensions and yield fine-grained control over the model outputs with respect to all of the attributes being considered."
        },
        {
            "section_id": "3.2.2",
            "parent_section_id": "3.2",
            "section_name": "3.2.2 Fine-tuned models and correlations",
            "text": "Given the results from the simplex plots, we analyze the relationships between the fine-tuned endpoint models to better understand the attribute score correlations. Figure 8  ###reference_###, which plots the average cosine similarity between the LoRA layers of each pair of models, shows that the LoRA weights are relatively orthogonal to each other in most cases. We hypothesize that the lower orthogonality between each pair of endpoint models for the same attribute is because the models are trained on similar datasets. This is supported by the fact that the simple and complex models are the most orthogonal of the pairs of endpoint models and they are the only two models trained on different datasets rather than different classes from the same dataset. In addition, the humor models tend to deviate the most from orthogonality with the other models (such as politeness), so this may provide a partial explanation for why some of the other models were correlated with a higher humor score.\n###figure_14###"
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Related work",
            "text": ""
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Controllable text generation (CTG)",
            "text": "As it is crucial to constrain generated text in many downstream applications, CTG has been a recent focus of NLP research. Methods such as CTRL (Keskar et al., 2019 ###reference_b14###) and GeDI (Krause et al., 2021 ###reference_b16###) pretrain language models on text prepended with control codes and generate text conditioned on the desired control. However, these methods require pretraining a new model if new controls are added, which is computationally expensive. To mitigate these issues, a variety of methods have been proposed to perform CTG without additional language model training. For example, Khalifa et al. (2021 ###reference_b15###); Pascual et al. (2021 ###reference_b26###); Yang & Klein (2021 ###reference_b37###); Dekoninck et al. (2024 ###reference_b2###) constrain language model outputs by modifying their output probability distributions. Li & Liang (2021 ###reference_b19###); Qian et al. (2022 ###reference_b27###) learn prefixes and Han et al. (2023 ###reference_b7###) train a linear factor in the word embedding space. Subramani et al. (2022 ###reference_b31###); Hernandez et al. (2023 ###reference_b8###); Li et al. (2023 ###reference_b18###); Turner et al. (2023 ###reference_b33###) control model outputs by changing activations at inference time. Zhou et al. (2023 ###reference_b39###) use instruction tuning for CTG. In this prior CTG research, only Dekoninck et al. (2024 ###reference_b2###) show that their method is composable and achieves fine-grained control over multiple attributes at once. However, as this method requires composing multiple models at inference time, the inference cost is significantly higher than inference from a single weight-interpolated model, especially as the model size and number of controlled attributes increases. In addition, combining low-rank fine-tuning weights instead of probability distributions allows for more complex relationships between the models to be taken into account when composing them, which will likely allow for greater flexibility as the number of controlled attributes increases.\n\nIn the realm of AI in healthcare, studies such as those by Esteva et al. (2019) and Topol (2019) have highlighted AI's transformative potential in diagnostic and predictive analytics, advancing personalized medicine and rapid data processing. However, challenges in data privacy, ethical considerations, and integration into clinical workflows continue to necessitate further research and development."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Weight interpolation",
            "text": "Our work builds on prior work on linear weight interpolation, such as task vectors (Ilharco et al., 2023  ###reference_b11###), parameter-efficient task vectors (Zhang et al., 2023  ###reference_b38###), and model souping (Wortsman et al., 2022  ###reference_b34###), as we use linear interpolation and weighted model averaging as the basis for our analysis. Prior work in this domain has focused mainly on improving multitask performance when composing fully fine-tuned models (Matena & Raffel, 2021  ###reference_b22###; Yadav et al., 2023  ###reference_b36###; Ortiz-Jimenez et al., 2023  ###reference_b25###; Ram\u00e9 et al., 2023  ###reference_b28###) or parameter-efficient fine-tuned models (Huang et al., 2024  ###reference_b10###; Jiang et al., 2024  ###reference_b12###). However, these methods all differ from our work, since they focus on combining model weights to improve a single multitask objective rather than analyzing performance across a wide range of flexible, diverse objectives. These approaches are orthogonal to our work and could be used in conjunction with it to better combine the -interpolated models. Perhaps most similar to our work are methods that interpolate between the weights of fine-tuned models to control over a range of outputs (Gandikota et al., 2023  ###reference_b6###; Nylund et al., 2023  ###reference_b24###). However, Gandikota et al. (2023  ###reference_b6###) focus on the vision domain and use a fine-tuning objective specific to diffusion models, and Nylund et al. (2023  ###reference_b24###) only analyze control over the time dimension. \n\nAI in healthcare has rapidly progressed, transforming diagnostics, treatment personalization, and patient monitoring. Recent studies demonstrate AI's capability to enhance disease prediction accuracy and improve treatment outcomes (Esteva et al., 2022  ###reference_b13###; Rajpurkar et al., 2023  ###reference_b29###). Such advancements are reshaping patient care and clinical decision-making, marking a significant shift in healthcare practices."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion and future work",
            "text": "In this work, we show that continuous linear interpolation between low-rank fine-tuned models can be used to parametrize the models in their convex hull. We achieve fine-grained, predictable control over multiple attributes of style at once by changing the interpolation weights between two anchor fine-tuned models and the mixing weights between different interpolated attribute models. We find that the interpolation profiles between models are smooth and there is surprisingly little entanglement between the models for different control dimensions. In other words, changing the weight for one attribute has a very small effect on the scores for other attributes, especially for sufficiently small mixing weights. As a result, we show that linear weight interpolation can be used to dynamically adjust to diverse sets of changing preferences and generate text that adheres to multiple controls simultaneously.\nLimitations and future work: The main limitation of our work is that some pairs of attributes are correlated, so when a correlated model has a large mixing weight, it can unpredictably affect other control attributes. Thus, a natural extension of this work would be to investigate whether this correlation is inherent to the pair of tasks or if it can be eliminated. For example, text that is more polite might always be more formal. However, it may be the case that some correlations can be reduced by regularizing the LoRA updates to be more orthogonal to each other or by merging the -interpolated using more sophisticated methods that have recently shown improvement over naive weight averaging in the multitask setting (Matena & Raffel, 2021  ###reference_b22###; Yadav et al., 2023  ###reference_b36###; Ortiz-Jimenez et al., 2023  ###reference_b25###; Ram\u00e9 et al., 2023  ###reference_b28###).\nAnother potential focus of future work could be to extend the extrapolation results to multiple control dimensions to analyze whether it is possible to reliably generate text beyond the fine-tuned models when controlling multiple attributes at once. This could be useful to further extend the range of control over the model outputs."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Ethics Statement",
            "text": "Continuous weight interpolation may output text that contains existing biases from the pre-trained models and fine-tuning datasets. It could also be used to control the level of undesirable attributes such as toxicity. However, we believe that this work is still beneficial overall, since it can be used to improve the experience of LLM users for a variety of applications, and these issues are faced by all pre-trained and fine-tuned language models."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Reproducibility",
            "text": "We provide code and the scripts used to run experiments at https://github.com/skangasl/continuous-lm-interpolation  ###reference_interpolation###. The fine-tuning hyperparameters are included in Appendix A.1  ###reference_###."
        }
    ],
    "url": "http://arxiv.org/html/2404.07117v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "4",
            "4.1",
            "4.2"
        ],
        "methodology_sections": [
            "2",
            "2.2",
            "2.3"
        ],
        "main_experiment_and_results_sections": [
            "2.1",
            "2.4",
            "3",
            "3.1",
            "3.2",
            "3.2.1",
            "3.2.2"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "3.1",
            "3.2",
            "3.2.1",
            "3.2.2"
        ]
    },
    "research_context": {
        "paper_id": "2404.07117v1",
        "paper_title": "Continuous Language Model Interpolation for Dynamic and Controllable Text Generation",
        "research_background": "The paper \"Continuous Language Model Interpolation for Dynamic and Controllable Text Generation\" addresses the significant challenge of enabling fine-grained and predictable control over text generation by large language models (LLMs) to adapt dynamically to user preferences. Here, the paper's motivation, research problem, and prior work have been described:\n\n### Motivation:\nThe motivation stems from the observation that current LLMs, while highly performant, aren't efficiently adaptable to the continuously evolving and multifaceted preferences of individual users. Users often have to undergo a trial-and-error process to achieve desired outputs from LLMs, which is both time-consuming and unpredictable. Expressing nuanced preferences through natural language is inherently difficult, and current methods fall short in melding multiple such preferences seamlessly. Therefore, there is a pressing need for a method that allows for intricate and fluid control of text generation, adapting promptly to dynamic user requirements.\n\n### Research Problem:\nThe core research problem the paper aims to solve is how to enable dynamic, fine-grained control in LLMs that can adapt instantaneously to changing user preferences without having to undergo additional training for each new preference combination. The authors propose a solution leveraging linear weight interpolation among pre-trained or fine-tuned models to achieve this adaptability.\n\n### Relevant Prior Work:\n1. **Prior Approaches for Controllable Text Generation (CTG)**:\n   - **Instruction tuning**: Simplifies optimizing output for a specific set of instructions (Zhou et al., 2023).\n   - **Output probability adjustment**: Methods modifying output distributions (Pascual et al., 2021; Yang & Klein, 2021; Dekoninck et al., 2024).\n   - **Inference-time activation modifications**: Altering model's activations during inference for control (Li et al., 2023).\n   - **Embedding modifications**: Learning to change embeddings for control (Li & Liang, 2021; Han et al., 2023).\n   - **Training approaches**: Various fine-tuning techniques (Keskar et al., 2019; Krause et al., 2021).\n\n   Despite their contributions, these techniques are limited as they do not naturally allow for composite control and lack the granularity needed for dynamically changing preferences.\n\n2. **Model Interpolation**:\n   - **Linear weight interpolation**: Combining multiple models to create hybrid models for desired characteristics (Wortsman et al., 2022; Ilharco et al., 2023).\n   - **Parameter-efficient fine-tuning methods (PEFT)**: Techniques like low-rank adaptation for efficient model adaptation (Hu et al., 2021).\n   \n   These prior methods form the basis of the proposed technique, which extends linear interpolation to combine fine-tuned models dynamically.\n\n### Contribution and Novelty:\nThe paper builds upon the concept of linear weight interpolation, applying it to fine-tuned models specifically for generating text with controllable attributes. By interpolating between 'anchor models' fine-tuned to the extremes of each control attribute, and then averaging these interpolations, the authors achieve a continuous and dense parametrization of the model space. This innovation allows for continuously adjustable and predictable text generation capabilities, validated through empirical demonstration and analysis of entanglement between attributes.\n\nIn summary, the paper proposes a novel application of model interpolation in controllable text generation, addressing the limitations of previous methods and achieving a new level of adaptability and precision in meeting user preferences.",
        "methodology": "Continuous Language Model Interpolation for Dynamic and Controllable Text Generation\n\n### Methodology\n\n**Key Components and Innovations:**\n\n1. **Style Attributes:** The study examines five style attributes: simplicity, formality, politeness, sentiment, and humor, which are derived from existing style transfer literature. \n\n2. **Endpoint 'Anchor' Models:** For each style characteristic, two endpoint 'anchor' models are fine-tuned. Each model optimizes for one extreme of the given style attribute. \n\n3. **Interpolation Scheme:** The interpolation method involves using the two endpoint anchor models as the foundation of the interpolation process. By adjusting the interpolation weights between these models, the generated text can be dynamically and controllably influenced to reflect varying degrees of the targeted style attribute.\n\nThis approach leverages the concept of weight interpolation between language models to achieve a controlled generation of text that can span a continuum between different stylistic extremes.",
        "main_experiment_and_results": "### Main Experiment Setup\n\n**Model Configuration:** The main experiment involves fine-tuning separate anchor Llama2-7b models for each style attribute using two datasets that represent the extremes of each attribute. \n\n**Datasets:**\n- **Simple vs. Complex:**\n  - **Simple Model:** TinyStories dataset (Eldan & Li, 2023)\n  - **Complex Model:** Novel chapters from the BookSum dataset (Kryscinski et al., 2021)\n- **Formality:**\n  - **Formal Model:** Formal documents from Grammarly\u2019s Yahoo Answers Formality Corpus (GYAFC) dataset (Rao & Tetreault, 2018)\n  - **Informal Model:** Informal documents from the same GYAFC dataset\n- **Politeness:**\n  - **Polite Model:** Documents from the highest politeness class (Madaan et al., 2020)\n  - **Impolite Model:** Documents from the lowest politeness class (Madaan et al., 2020)\n- **Sentiment:**\n  - **Positive Sentiment Model:** Stanford Sentiment Treebank (SST-2) dataset (Socher et al., 2013)\n  - **Negative Sentiment Model:** Stanford Sentiment Treebank (SST-2) dataset\n- **Humor:**\n  - **Humorous Model:** FlickrStyle dataset (Gan et al., 2017)\n  - **Non-humorous Model:** FlickrStyle dataset\n\n### Baselines\nThe paper does not explicitly mention specific baseline models within the main experiment setup description provided. However, each fine-tuned model serves as a baseline for its corresponding attribute along the determined extremes.\n\n### Evaluation Metrics\nThe evaluation metrics to confirm the success of these models are not described in the provided excerpt. Common evaluation metrics for text generation tasks typically include:\n- **Perplexity:** Measures how well the model predicts a sample.\n- **BLEU Score:** Evaluates the match between the generated text and the reference text.\n- **Human Evaluation:** Human raters assess the generated text for attributes like fluency, coherence, and adherence to the desired style attribute.\n- **Accuracy:** For categorical attributes like formality or sentiment, accuracy can be used to gauge performance by checking correct classifications.\n\n### Main Experimental Results\nThe specific results of the main experiment, detailing the performance of these fine-tuned models on the evaluated metrics, are not included in the provided text. Generally, such results would discuss the effectiveness of each fine-tuned model in generating text that adheres to the intended attribute (simple/complex, formal/informal, polite/impolite, positive/negative sentiment, humorous/non-humorous).\n\nTo succinctly summarize, the main experiment setup involves fine-tuning Llama2-7b models on specific datasets tailored to different attributes such as complexity, formality, politeness, sentiment, and humor. The outcomes of this fine-tuning process would typically be analyzed via standard text generation evaluation metrics, although the specific values and interpretations of these results are not provided in the description."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "Explore the effect of moving along the vector between a single pair of fine-tuned anchor models to dynamically control model outputs with specific attributes.",
            "experiment_process": "This study investigates the effect of linear interpolation and extrapolation on attribute scores when moving along the vector between two fine-tuned anchor models. For interpolation, a parameter \u03b1 is varied between 0 and 1. For extrapolation, the parameter \u03b2 extends beyond the interpolation range. The impact on multiple attributes (politeness, formality, simplicity, sentiment, and humor) is evaluated, along with the model quality measured by perplexity.",
            "result_discussion": "Linear interpolation showed a smooth increase in attribute scores with minimal degradation in output quality for most attributes, demonstrating fine-grained control. Linear extrapolation maintained predictable attribute changes up to certain thresholds, after which the model became unstable, highlighting a limit to extrapolation reliability.",
            "ablation_id": "2404.07117v1.No1"
        },
        {
            "research_objective": "Investigate whether linear interpolation across multiple control dimensions can provide fine-grained and dynamic control over model attributes.",
            "experiment_process": "Up to five attributes were manipulated using interpolation parameters \u03b1i. Spider plots were used to visualize changes in attribute scores. Detailed analysis was performed for varying interpolation weights of \u03b1i and \u03b2i across multiple dimensions to test for entanglement between attributes.",
            "result_discussion": "The interpolation provided predictable control over desired attributes with minimal effect on the remaining attributes. The plots showed smooth attribute score adjustments towards extreme models, indicating effective control. Limited entanglement was observed between attributes, allowing the model to maintain expected behaviors even with correlated dimensions.",
            "ablation_id": "2404.07117v1.No2"
        },
        {
            "research_objective": "Analyze the correlations between fine-tuned endpoint models to understand attribute score relationships.",
            "experiment_process": "The cosine similarity between the LoRA (Low-Rank Adaptation) layers of pairs of fine-tuned models was measured to assess their orthogonality. Comparisons were made to understand how dataset similarities influence attribute score correlations.",
            "result_discussion": "Most pairs of models were relatively orthogonal, suggesting minimal correlation. However, models trained on similar datasets showed lower orthogonality, particularly humor models deviating the most. This lower orthogonality explains some attribute correlation, indicating dataset similarity's role in attribute entanglement.",
            "ablation_id": "2404.07117v1.No3"
        }
    ]
}