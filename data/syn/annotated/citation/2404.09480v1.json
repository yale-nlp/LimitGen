{
    "title": "Mitigating Hallucination in Abstractive Summarization with Domain-Conditional Mutual Information",
    "abstract": "A primary challenge in abstractive summarization is hallucination\u2014the phenomenon where a model generates plausible text that is absent in the source text. We hypothesize that the domain (or topic) of the source text triggers the model to generate text that is highly probable in the domain, neglecting the details of the source text. To alleviate this model bias, we introduce a decoding strategy based on domain-conditional pointwise mutual information. This strategy adjusts the generation probability of each token by comparing it with the token\u2019s marginal probability within the domain of the source text. According to evaluation on the XSUM dataset, our method demonstrates improvement in terms of faithfulness and source relevance. The code is publicly available at https://github.com/qqplot/dcpmi.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Abstractive summarization is the task of generating a summary by interpreting and rewriting a source text. State-of-the-art pre-trained language models have achieved remarkable performance in this task Lewis et al. (2019  ###reference_b7###); Zhang et al. (2020  ###reference_b20###). However, upon closer examination, a common issue emerges: hallucination between the source document and the generated text. Prior studies have made efforts to enhance the faithfulness of the summary to the source text, yet hallucination remains a persistent challenge Maynez et al. (2020  ###reference_b11###); Mao et al. (2021  ###reference_b10###); Zhu et al. (2021  ###reference_b25###); Zhang et al. (2023  ###reference_b21###).\nTo solve this issue, we introduce a decoding strategy based on domain-conditional pointwise mutual information (). The motivation for  is that the domain of the source text provokes the model to generate text that is highly probable in the source domain, leading to plausible but factually inconsistent text.\nBuilding on this motivation,  computes how much more likely a token becomes in the summary when conditioned on the input source text, compared to when the token is conditioned only on the domain of the source text. This effectively penalizes the model\u2019s tendency to fall back to domain-associated words when the model has high uncertainty about the generated token.\nThis idea was inspired by conditional pointwise mutual information (CPMI) van der Poel et al. (2022  ###reference_b15###), which similarly penalizes a token\u2019s marginal probability. But CPMI does not capture the important fact that a token\u2019s probability depends highly on the source domain in summarization.\nFor example, consider the example presented in Table 1  ###reference_###. The source text states, \u201cOur latest economic data shows that many Scottish businesses will have a successful 2017\u201d.\nCPMI undesirably introduces the term \u201cwarning\u201d, which frequently appears in the domain of economy in the training data, generating information that contradicts the source text. By contrast,  lowers the probability of the term \u201cwarning\u201d by capturing the high conditional likelihood of this term given the domain and avoids the hallucination.\nWe use automated metrics for evaluation on the challenging XSUM dataset Narayan et al. (2018  ###reference_b12###) achieving significant improvements in faithfulness and relevance to source texts according to metrics like AlignScore, FactCC, BARTScore, and BS-Fact, with only a marginal decrease in ROUGE and BERTScore. This highlights the effectiveness and robustness of  in abstractive summarization.\n\nIn healthcare, AI has shown great potential in disease prediction, offering improved accuracy over traditional methods. Advanced algorithms analyze vast datasets, identifying patterns to predict diseases like diabetes, cancer, and cardiovascular conditions Mahajan et al. (2019  ###reference_b30###); Esteva et al. (2021  ###reference_b32###). However, issues of data bias and interpretability remain significant challenges Bohr et al. (2020  ###reference_b34###)."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Preliminaries",
            "text": "We adopt the problem definition in van der Poel et al. (2022  ###reference_b15###). In abstractive summarization, an input source text, denoted as , is condensed into an output string represented by . This output string is a sequence of tokens from the vocabulary . Each sequence begins with token  and ends with , and the length of the output is .\nThe optimal  that belongs to a valid string set  is obtained via a scoring function as follows:\nUtilizing beam search is a practical solution for searching possible strings.\nThe typical beam search with an autoregressive generation model uses the following scoring function:\nwhere  is a token-level log probability computed by the model.\nPMI scoring utilizes mutual information between the input and output. This penalizes the generation of tokens that are marginally likely but not related to the input. The formula for PMI scoring can be expressed as follows:\nvan der Poel et al. (2022  ###reference_b15###) have demonstrated a connection between hallucinations and token-wise predictive entropy, denoted as . A model tends to hallucinate a token if the entropy is high. Hence, instead of penalizing the marginal probability of  in Equation 2  ###reference_### all the time, CPMI does this only when the entropy at the -th decoding step is higher than a threshold.\nwhere ."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Domain-conditional Scoring Strategy",
            "text": "Our approach improves upon CPMI by conditioning the probability of a generated token on the source domain.\nIn our domain-conditional strategy (), we employ the following scoring function:\nis a domain prompt Holtzman et al. (2021  ###reference_b3###), a subset of tokens in  that contains information about the source domain. This seemingly simple extension is well grounded in the previous observation that summarization models are likely to templatize the summaries of source texts that share the same domain or topic and hallucinate tokens that are frequent in the \u201ctemplate\u201d of the source domain King et al. (2022  ###reference_b5###). Accordingly, our method can effectively account for different marginal probabilities of the token depending on the source domain and outperforms CPMI, as will be demonstrated later.\nTo compute the marginal probabilities , we employ a smaller language model, denoted as , while  represents a larger summarization model. The hyperparameters  and  are optimized through random grid-search.\nTo condition the generation probability of a token on the source domain, we incorporate domain information into the prompts of both the summarization and language models (i.e., ). We explored three types of domain information: (1) domain-specific keywords, (2) the first sentence of the source text, and (3) a randomly chosen sentence from the source text.\nWe assumed that domain-specific keywords enable the model to calculate the conditional probability of a token within the specified domain. The open-source module KeyBERT Grootendorst (2020  ###reference_b2###) was utilized to extract three keywords from each source text (Appendix A.4  ###reference_###). The expectation was that these selected keywords would effectively represent the source document with high similarity. Additionally, we also considered that sentences extracted from the source text could represent the domain of the entire text. Therefore, sentences from the source text, including the first sentence, and a randomly selected sentence were examined as the source domain.\nIn conjunction with the aforementioned domain information, we incorporated a simple priming phrase into the domain prompt. We have discovered that using an appropriate lexical form yields better results compared to inputting the domain alone. We referred to the prompt design outlined by Yuan et al. (2021  ###reference_b18###). The 18 phrases we examined include expressions such as \u201ckeyword,\u201d \u201cin summary,\u201d and \u201cin other words.\u201d Table 2  ###reference_### displays the seed prompts along with examples of paraphrased prompts (see more details in Appendix D  ###reference_###)."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experimental Setup",
            "text": "We used the eXtreme Summarization Dataset, XSUM Narayan et al. (2018  ###reference_b12###), which consists of BBC articles as source documents and single-sentence summaries as gold summaries.\nWe examined three baseline decoding methods: standard beam search, PINOCCHIO King et al. (2022  ###reference_b5###), and CPMI van der Poel et al. (2022  ###reference_b15###). Additionally, we analyzed FactPEG Wan and Bansal (2022  ###reference_b16###), which underwent separate fine-tuning using FactCC and ROUGE with the source document.\nFor the summarization model, we utilized encoder-decoder structures of BART Lewis et al. (2019  ###reference_b7###) and PEGASUS Zhang et al. (2020  ###reference_b20###). As for the language model, a GPT2-based model Radford et al. (2019  ###reference_b13###) was employed. Each of these models was pre-trained on the XSUM dataset. More details can be found in Appendix B  ###reference_###.\nWe have categorized the evaluation into three key divisions: Faithfulness, Relevance (with the source), and Similarity (with the target). For faithfulness, we used AlignScore Zha et al. (2023  ###reference_b19###) and FactCC Kryscinski et al. (2020  ###reference_b6###). To measure relevance to the source and informativeness, we employed BARTScore Yuan et al. (2021  ###reference_b18###) and BS-FACT. Lastly, to assess similarity to the target, we utilized ROUGE-L and BERTScore Zhang* et al. (2020  ###reference_b22###)."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Results",
            "text": "We presented the results from BART in Table 3  ###reference_###. The complete result, including those from PEGASUS, are provided in Table 9  ###reference_###. For all cases, the prompt used was \u201cThat is to say\u201d, and the domain consisted of three keywords extracted from the source document. In Table 3  ###reference_###, we compared the summarization performance of different decoding strategies with BART. Our results revealed that PINOCCHIO exhibited suboptimal performance overall, while CPMI showed performance that was nearly on par with standard beam search. However,  showed significant improvement in terms of faithfulness and relevance.\nIn Table 4  ###reference_###, the term Type indicates whether the subset is at the word or sentence level, while Domain refers to a subset of tokens within the source. Notably, the Keyword approach within the word-level domain demonstrated robust performance. Therefore, we selected the Keyword approach for our domain prompt."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "Comparison with Fine-tuned Model",
            "text": "FactPEG Wan and Bansal (2022  ###reference_b16###) reduces hallucinations by incorporating factual metrics during training, leveraging ROUGE and FactCC with the source document to produce faithful summaries. In Table 5  ###reference_###, FactPEG outperforms  in terms of faithfulness. On the other hand,  achieves a more balanced performance across different metrics.\nFactPEG is trained with a focus on faithfulness, which has led to the loss of other summarization abilities. For instance, using a random sentence as a summary (as shown in the top row in Table 5  ###reference_###) demonstrates high faithfulness but a notable drop in the other two categories. Therefore, solely targeting faithfulness may risk the summarization capabilities of pre-trained models (refer to Table 6  ###reference_###)."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "Effectiveness of Uncertainty-Aware Scoring",
            "text": "Recall that in , the marginal probability of a token conditional to the domain  is utilized only when the model\u2019s uncertainty of a token exceeds a threshold (i.e., ). Here, we examined whether this uncertainty-aware scoring is more effective than without .\nIn Table 7  ###reference_###, the first and second rows demonstrate the PMI scores regardless of uncertainty, while the third row shows uncertainty-aware PMI score. To ensure faithful token generation without degrading the performance of original summarization models, it is more effective to replace only specific uncertain tokens suspected of hallucination through uncertainty-aware scoring, rather than adjusting all tokens."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "Error Analysis",
            "text": "While PMI effectively controlled hallucinated terms, there were instances of failure. We conducted a manual evaluation on 500 XSUM samples selected from Maynez et al. (2020  ###reference_b11###), categorizing the error cases into three types (Table 8  ###reference_###):\nCase 1: Extracted keywords may not fully reflect the domains of the source text.\nCase 2: Appropriate domains, but errors in representing numbers, proper nouns, or statistics.\nCase 3: Appropriate domains, yet still hallucinated cases.\nCase 1 occurs when the extracted keywords may not fully reflect the domains of the source text. We used keywords to represent the domain. However, in some cases, the extracted keywords may not adequately capture the \u201ctopic\u201d or \u201ccategory\u201d of the source text and did not guide the model as we expected (Table 11  ###reference_###).\nCase 2 occurs when handling numbers, proper nouns, or statistics. Numbers, proper nouns, or statistics are among the primary causes of hallucination in the model. Despite extracting the appropriate domain, there are instances where incorrect numerical information is presented in the generated text (Table 12  ###reference_###).\nCase 3 refers to situations where summarization fails even though they do not fall into Case 1 or Case 2. One such scenario happens when imposing significant penalties on domain-specific keywords. This can result in avoiding direct expressions, leading to ambiguity (Table 13  ###reference_###). Additionally, there are occurrences of hallucination due to the inherent difficulty of the task. For instance, when the source text contains multiple pieces of information, summarizing them into a single sentence becomes a challenging task."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "We proposed a decoding strategy based on domain-conditional pointwise mutual information (PMI) to reduce hallucination in abstractive summarization. PMI penalizes the model\u2019s tendency to generate text inconsistent with the source document by considering the source text\u2019s domain. This simple but innovative approach significantly improves faithfulness and relevance to the source text, as demonstrated through evaluation on the XSUM dataset."
        }
    ],
    "url": "http://arxiv.org/html/2404.09480v1",
    "segmentation": {
        "research_background_sections": [
            "1"
        ],
        "methodology_sections": [
            "2",
            "3"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "5",
            "5.1",
            "5.2",
            "5.3"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "3",
            "5.2"
        ]
    },
    "research_context": {
        "paper_id": "2404.09480v1",
        "paper_title": "Mitigating Hallucination in Abstractive Summarization with Domain-Conditional Mutual Information",
        "research_background": "### Motivation and Research Problem\nThe paper addresses a significant challenge in the field of abstractive summarization: hallucination. Hallucination occurs when the generated summaries contain information that is not present or is inconsistent with the source text. Current state-of-the-art pre-trained language models, despite their impressive performance, are still prone to generating such hallucinations (Lewis et al., 2019; Zhang et al., 2020). The paper acknowledges that existing methods aiming to enhance the faithfulness of summaries have not been fully successful in mitigating this issue (Maynez et al., 2020; Mao et al., 2021; Zhu et al., 2021; Zhang et al., 2023). Therefore, the research problem tackled in this paper is how to effectively reduce hallucinations in abstractive summarization while maintaining the quality of the generated summaries.\n\n### Proposed Solution\nTo address this problem, the paper introduces a novel decoding strategy based on domain-conditional pointwise mutual information (DCPMI). The motivation behind this approach is to leverage the domain-specific characteristics of the source text to direct the model to generate text that is more faithful to the source content. DCPMI computes the conditional likelihood of a token appearing in the summary given the input source text, compared to its likelihood conditioned solely on the domain of the source text. This strategy aims to penalize the generation of domain-associated words that do not align closely with the source text, thereby reducing the instances of hallucinations.\n\n### Inspiration and Relevant Prior Work\nThe idea of using mutual information is inspired by the concept of conditional pointwise mutual information (CPMI) (van der Poel et al., 2022), which penalizes a token's marginal probability. However, CPMI does not take into account the dependency of a token's probability on the source domain, which is crucial in the context of summarization. \n\nBy contrast, the proposed DCPMI approach addresses this gap by factoring in the high conditional likelihood of domain-specific terms, thereby ensuring that the generated text remains consistent and relevant to the source. For instance, in an example related to economic data, CPMI might introduce irrelevant terms like \"warning,\" which are common in the economy domain but contradict the specific content of the source text. DCPMI, however, effectively reduces the probability of such hallucinations by considering the contextual relevance.\n\n### Evaluation and Results\nThe effectiveness of the proposed DCPMI strategy is demonstrated through extensive evaluations on the challenging XSUM dataset (Narayan et al., 2018). The results show significant improvements in the faithfulness and relevance of the generated summaries according to automated metrics like AlignScore, FactCC, BARTScore, and BS-Fact. Notably, these improvements come with only a marginal decrease in ROUGE and BERTScore, underscoring the robustness and practical utility of the DCPMI approach in mitigating hallucinations in abstractive summarization.",
        "methodology": "### Mitigating Hallucination in Abstractive Summarization with Domain-Conditional Mutual Information\n\n**Methodology:**\n\nThe problem definition for abstractive summarization follows van der Poel et al. (2022). In this task, an input source text, denoted as \\( X \\), needs to be condensed into an output string, represented by \\( Y \\). The output string \\( Y \\) is a sequence of tokens from the vocabulary \\( V \\). Each sequence begins with a special start-of-sequence token and ends with a special end-of-sequence token, and the length of the output is \\( T \\).\n\nThe goal is to find the optimal \\( Y \\) that belongs to a valid string set \\( V_T \\) using a scoring function, formulated as:\n\n\\[ Y^* = \\arg\\max_{Y \\in V_T} score(X, Y) \\]\n\nTo efficiently search possible strings, beam search is utilized. This technique leverages an autoregressive generation model, which typically uses the following scoring function:\n\n\\[ score(X, Y) = \\sum_{t=1}^T \\log P(y_t | y_{<t}, X) \\]\n\nwhere \\( \\log P(y_t | y_{<t}, X) \\) is the token-level log probability computed by the model.\n\n**PMI Scoring:**\n\nPointwise Mutual Information (PMI) scoring incorporates mutual information between the input \\( X \\) and the output \\( Y \\). This approach aims to penalize the generation of tokens that are marginally likely but not contextually related to the input. The formula for PMI scoring is:\n\n\\[ PMI(X, Y) = \\log P(Y | X) - \\log P(Y) \\]\n\n**Novelty - Conditional PMI (CPMI) Scoring:**\n\nvan der Poel et al. (2022) established a connection between hallucinations and token-wise predictive entropy, denoted as \\( H_t \\). The likelihood of a model generating a hallucinated token increases with higher entropy. Therefore, Conditional PMI (CPMI) is introduced to selectively penalize the marginal probability of \\( y_t \\) only when the entropy at the \\( t \\)-th decoding step exceeds a designated threshold \\( \\tau \\):\n\n\\[ CPMI(X, Y) = \\begin{cases} \n      PMI(X, Y) & H_t > \\tau \\\\\n      \\log P(y_t | y_{<t}, X) - \\lambda \\log P(y_t) & \\text{otherwise}\n   \\end{cases} \\]\n\nwhere \\( \\lambda \\) is a tuning parameter to adjust the penalty level. \n\nIn this way, CPMI effectively mitigates hallucination by dynamically responding to token-wise predictive entropy, rather than applying a blanket penalty throughout the entire generation process.\n\n---\n\nThis methodology introduces key innovations, especially the CPMI scoring, which enhances traditional PMI scoring by incorporating token-wise entropy to better manage hallucination in abstractive summarization models.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n#### Dataset\nThe main experiment was conducted using the eXtreme Summarization Dataset (XSUM) [Narayan et al., 2018], which includes BBC articles as source documents and corresponding single-sentence gold summaries.\n\n#### Baselines\nThree baseline decoding methods were examined:\n1. Standard beam search\n2. PINOCCHIO [King et al., 2022]\n3. CPMI [van der Poel et al., 2022]\n\nAdditionally, the FactPEG method [Wan and Bansal, 2022], which underwent separate fine-tuning using FactCC and ROUGE with the source document, was analyzed.\n\n#### Models\nThe summarization models utilized were:\n1. Encoder-decoder structures of BART [Lewis et al., 2019]\n2. PEGASUS [Zhang et al., 2020]\n\nFor the language model, a GPT2-based model [Radford et al., 2019] was employed. All these models were pre-trained on the XSUM dataset.\n\n#### Evaluation Metrics\nThe evaluation was categorized into three key divisions:\n1. **Faithfulness**: Measured using AlignScore [Zha et al., 2023] and FactCC [Kryscinski et al., 2020]\n2. **Relevance** (with the source) and **Informativeness**: Measured using BARTScore [Yuan et al., 2021] and BS-FACT\n3. **Similarity** (with the target): Assessed using ROUGE-L and BERTScore [Zhang* et al., 2020]\n\n#### Main Experimental Results\nThe results indicated that models evaluated with domain-conditional mutual information presented improvements in the context of believed metrics. The detailed comparative performance among the baselines and proposed methods are elaborated in the appendix section B.\n\n(Note: Exact numerical results and statistical significance details would typically be part of the main results section in the research paper, but they are not available in the provided text.)"
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To enhance the faithfulness and relevance of abstractive summarization by mitigating the problem of hallucination in generated summaries through a domain-conditional mutual information-based decoding strategy.",
            "experiment_process": "The proposed domain-conditional strategy employs a scoring function that adjusts the probability of a generated token based on its marginal probability within the source domain. The marginal probabilities are computed using a smaller language model, while the summarization model is a larger one. Hyperparameters are optimized via random grid-search. Domain information incorporated into both models' prompts includes: (1) domain-specific keywords extracted via KeyBERT, (2) the first sentence of the source text, and (3) a randomly chosen sentence from the source text. A priming phrase is added to the domain prompts, exploring 18 different phrases such as 'keyword,' 'in summary,' and 'in other words.'",
            "result_discussion": "Results indicate that incorporating domain-specific information through keywords or sentences into the prompts helps in calculating the conditional probability of tokens more accurately, thus reducing the likelihood of hallucinations. The use of appropriate lexical forms in prompts further improves performance.",
            "ablation_id": "2404.09480v1.No1"
        },
        {
            "research_objective": "To evaluate the effectiveness of uncertainty-aware scoring for token generation in mitigating hallucinations in abstractive summarization.",
            "experiment_process": "The experiment compares PMI scores regardless of uncertainty (first and second rows in Table 7) with uncertainty-aware PMI scores (third row in Table 7). This setup tests whether conditioning token marginal probabilities on domain information only when uncertainty exceeds a certain threshold leads to more faithful token generation without degrading summarization model performance.",
            "result_discussion": "Results from Table 7 show that using uncertainty-aware scoring is more effective. Faithful token generation is achieved without degrading summarization performance by replacing only specific uncertain tokens suspected of hallucination rather than adjusting all tokens.",
            "ablation_id": "2404.09480v1.No2"
        }
    ]
}