{
    "title": "Investigating LLM\u2019s Value Inclination on the Perspective of Age",
    "abstract": "In this paper, we explore the alignment of values in Large Language Models (LLMs) with specific age groups. Through a diverse set of prompts tailored to ensure response robustness, we find a general inclination of LLM values towards younger demographics, especially in the US. Additionally, we explore the impact of incorporating age identity information in prompts and observe challenges in mitigating value discrepancies with different age cohorts. Our findings highlight the age bias in LLMs and provide insights for future work. Materials for our analysis will be available via anonymous.github.com.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Widely used Large Language Models (LLMs) should be reflective of all age groups Dwivedi et al. (2021  ###reference_b9###); Wang et al. (2019  ###reference_b29###); Hong et al. (2023  ###reference_b12###). Age statistics estimate that by 2030, 44.8% of the US population will be over 45 years old Vespa et al. (2018  ###reference_b28###), and one in six people worldwide will be aged 60 years or over World Health Organization (2022  ###reference_b30###). Analyzing how the values (e.g, religious values) in LLMs align with different age groups can enhance our understanding of the experience that users of different ages have with an LLM. For instance, for an older group that may exhibit less inclination towards new technologies Czaja et al. (2006  ###reference_b6###); Colley and Comber (2003  ###reference_b5###), an LLM that embodies the values of a tech-savvy individual may lead to less empathetic interactions. Minimizing the value disparities between LLMs and the older population has the potential to lead to better communication between these demographics and the digital products they engage with. \n\nFurthermore, we study the effect of adding age identity information when prompting LLMs. Specifically, we instruct LLMs to use an age and country identity before requesting their responses. Surprisingly, we find that adding age identity fails to eliminate the value discrepancies with targeted age groups on eight out of thirteen categories, despite occasional success in specific instances.\n\nWe advocate for increased awareness within the research community regarding the potential age bias inherent in LLMs, particularly concerning their predisposition towards certain values. We also emphasize the complexities involved in calibrating prompts to effectively address this bias."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": "Due to the recent advancements in LLMs in manifesting human-level performance across various tasks Brown et al. (2020  ###reference_b3###); Radford et al. (2019  ###reference_b21###); Ouyang et al. (2022  ###reference_b20###), there is a growing concern regarding the presence of social bias in these models Kasneci et al. (2023  ###reference_b15###).\nRecent research has shown that LLMs exhibit \u201cpreferences\u201d for certain demographic groups, such as White and female individuals Sun et al. (2023  ###reference_b25###), and political inclination Santurkar et al. (2023  ###reference_b23###); McGee (2023  ###reference_b17###); Atari et al. (2023  ###reference_b1###). Despite extensive scrutiny on LLM bias Santurkar et al. (2023  ###reference_b23###); Sun et al. (2023  ###reference_b25###), the age-related preferences of LLMs remain less explored.\nPrevious work has mentioned age as one of multi-facets of bias in LLM performance Kamruzzaman et al. (2023  ###reference_b14###); Haller et al. (2023  ###reference_b11###); Draxler et al. (2023  ###reference_b7###); Levy et al. (2024  ###reference_b16###); Oketunji et al. (2023  ###reference_b18###), while lacking a direct study on the age aspect.\nRecent research Duan et al. (2024  ###reference_b8###) publishes an evaluation for well-known LLMs on age bias through 50 multi-choice questions; unlike it focuses on discriminatory narratives towards specific age groups, our investigation is running at an implicit level.\nWe argue that understanding the underlying value systems is crucial, as the value discrepancies between users and LLMs can significantly impact their adoption of LLMs, even though the explicit discrimination is rectified, as exemplified in our discussion on technology attitudes in Sec 1  ###reference_###.\n###figure_2### ###figure_3###"
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Analytic Method",
            "text": "We derive human values by grouping respondents by age group and country. Subsequently, we compute the average values for each age group and country to represent their respective cohorts, ignoring the invalid negative numbers.\n\nWe conduct our analysis on six LLMs. We identify three key components for each inquiry: context, question content, and options. To ensure robustness, we made several format variations for the prompt, adopting minor changes to avoid significant deviations.\n\nEventually, we build a set of eight distinct prompts per inquiry. Through careful analysis of the prompt responses, we observe instability in LLM responses to prompt variations. However, multiple prompt trials assist in achieving a convergence point. On 95.5% of questions, more than half of the eight prompts led to responses centered on the same choice or adjacent options, making it acceptable to consider the average of the outcomes across the eight prompt variations as the LLM\u2019s final response.\n\nAdditionally, due to the instability of LLMs in following instructions, we encountered seven types of unexpected replies and present our coping methods for each. In the process of averaging responses, we ignore invalid negative numbers. Parameter settings and prompting details for reproducing our work are reported in the appendix."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Human Data Acquisition",
            "text": "We derive human values by grouping respondents by age group and country. Respondents are organized into age groups: 18-24, 25-34, 35-44, 45-54, 55-64, and 65+. We then compute the average values for each age group and country to represent their respective cohorts, ignoring invalid entries."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Prompting",
            "text": "We conduct our analysis on six LLMs, as introduced in Tab 1.\n\nWe identify three key components for each inquiry in the survey: context, question ID&content, and options. To ensure robustness, we made several format variations for the prompt. Despite adopting format variations, we were cautious to not include major changes as previous research uncovered inconsistent performance in LLMs after receiving a minor prompt variation.\n\nEventually, we build a set of eight distinct prompts per inquiry. Please see prompt design details in Tab 3 in Appendix. Through a careful analysis on the prompt responses (Appx B), we observe unstableness of LLM\u2019s responses to prompt variations. However, multiple prompt trials assist with achieving a convergence point.\n\nOn 95.5% of questions, more than half of the eight prompts led to responses centered on the same choice or adjacent options, and thus we believe it is acceptable to consider the average of the outcomes across the eight prompt variations as the LLM\u2019s final responses.\n\nIn addition, due to the instability of LLMs in following instructions, we encountered seven types of unexpected replies and present our coping methods for each, as summarized in Tab 4. In the process of averaging responses, we ignore the invalid negative numbers, as we did in calculating human values. For reproducing our work, parameter setting and prompting details are reported in Appendix D."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Measures",
            "text": "We use vector  to represent values belonging to a certain category . Each question is treated as a dimension:\nwhere  is a numeric response to the th question in the section of , and  denotes the total question number.\nNote the acquisition of numeric responses for human groups and LLM has been illustrated in Sec 3.1 ###reference_### and 3.2 ###reference_###.\nBy collecting value vectors that represent people across 6 age groups, along with a value vector for the LLM to compare, we utilize principle component analysis (PCA) Tipping and Bishop (1999  ###reference_b27###) for representation learning. We acquire value representations for all groups with the dimensionality of three. Our consideration of using PCA is added in Appx C ###reference_###.\nLet  be the index of age group in [18-24, 25-34, 35-44, 45-54, 55-64, 65+] and the value representation for the th age group be . We derive three metrics below for our further analyses:\nEuclidean Distance, the distance between two value representations.\nwhere  represents values of LLM on category .\nAlignment Rank, the ascending rank of distances between LLM values and people across six age groups.\nTrend Coefficient, the slope of the value gap between LLM and humans across six age groups.  is the slope we would like to fit by linear regression."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Aligning with Which Age on Which Values?",
            "text": "As shown in Fig 1 ###reference_###, we observe a general inclination of popular LLMs favoring the values of younger demographics in the US on different value categories, indicated by the trend coefficient. Fig 2 ###reference_### exemplifies the bias for LMMs across six age groups in several countries. Due to the limited paper pages, results on other LLMs and countries can be found in Appx E ###reference_### and F ###reference_###. Significant testing procedure is available in Appx G ###reference_###. We observe that in the US and China, as countries of large population, the models tend to have a higher alignment rank on younger groups on the most categories, despite few exceptions (e.g., happiness and well-being). However, in Ethiopia and Nigeria (Tab 8 ###reference_###), the inclination is less evident. We leave this phenomenon for future study. ###figure_52### In Fig 3 ###reference_###, we show two representative prompts and their responses from ChatGPT and human groups, to illustrate sample values where ChatGPT exhibits a clear bias toward a specific age group."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "The Effect of Adding Identity in Prompts",
            "text": "To analyze if adding age identity in the prompt helps to align values of LLM with the targeted age groups, we adjust our prompts by adding a sentence like \u201cSuppose you are from [country] and your age is between [lowerbound] and [upperbound].\u201d at the beginning of the required component of the original prompt and get responses that corresponds with six age groups.\nWe illustrate the change of Euclidean distance between values of LLM and different age groups after adding identity information. As is presented in Fig 4  ###reference_###, in eight out of thirteen categories (No.1,2,4,5,7,8,9,12) no improvement is observed.\n###figure_53### We also showcase a successful calibration example for a question about the source of acquiring information in Fig 5  ###reference_###. The value pyramid illustrates LLMs\u2019 responses for different age ranges compares to the answers from the U.S. population. When age is factored into the LLM prompt, the LLM\u2019s views are more aligned with the U.S. population of that respective age group, as it reports higher frequency using radio news for the older group.\n###figure_54###"
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Recommendations for Future Work",
            "text": "We have observed that simply including an age in prompts fails to eliminate the value disparity for the targeted age groups. Out of the thirteen categories inquired upon, eight have shown no improvement.\nTo this end, we recommend a careful data curation during pretraining. Doing so involves a deliberate and thoughtful selection of data sources that are diverse and representative of various age groups. By doing so, we can ensure that the model\u2019s training material reflects a wide range of perspectives and experiences, thereby reducing biases and disparities in the model\u2019s responses. We also recommend a consideration of human feedback optimization (e.g., RLHF). Through this iterative process, LLMs can learn to generate responses that fit better with the needs of different age groups. These strategies help mitigate the value disparities associated with targeted age groups, enhancing the LLM\u2019s abilities to be more equitable and inclusive."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we investigated the alignment of values in LLMs with specific age groups. Our findings suggest a general inclination of LLM values towards younger demographics. Our study contributes to raising attention to the potential age bias in LLMs and advocate continued efforts from the community to address this issue. Moving forward, efforts to calibrate value inclinations in LLMs should consider the complexities involved in prompting engineering and strive for equitable representation across diverse age cohorts."
        }
    ],
    "url": "http://arxiv.org/html/2404.08760v2",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "5"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4",
            "5"
        ]
    },
    "research_context": {
        "paper_id": "2404.08760v2",
        "paper_title": "Investigating LLM\u2019s Value Inclination on the Perspective of Age",
        "research_background": "### Motivation\nThe motivation behind this paper stems from the necessity for widely-used Large Language Models (LLMs) to represent and be reflective of diverse age groups. Given the growing demographic of older adults, both in the U.S. and worldwide, it becomes crucial to examine how LLMs' value inclinations align\u2014or fail to align\u2014with the values held by different age demographics. Misalignment may result in less empathetic and effective interactions, thereby potentially alienating segments of the population from digital interactions that are increasingly central to everyday life.\n\n### Research Problem\nThis paper addresses the research problem of whether LLMs' value inclinations align with specific age groups and seeks to identify which values are more closely associated with younger or older demographics. Moreover, it investigates the efficacy of using age identity information in prompts to mitigate any detected discrepancies.\n\n### Relevant Prior Work\n1. **Demographic Representation in LLMs**: Previous research has underscored the importance of demographic inclusivity in LLMs to ensure that diverse user groups have positive interactions with these models (Dwivedi et al., 2021; Wang et al., 2019; Hong et al., 2023).\n2. **Demographic Trends**: Vespa et al. (2018) and the World Health Organization (2022) have highlighted the increasing proportion of older adults, making it pertinent to consider how this demographic interacts with technology.\n3. **Technology Adoption by Older Adults**: Studies by Czaja et al. (2006) and Colley and Comber (2003) indicate that older adults generally show less inclination towards new technologies, suggesting that an LLM biased towards younger, tech-savvy values may not meet the needs of this group.\n4. **World Value Survey Utilization**: The World Value Survey (Haerpfer et al., 2020) serves as a foundational tool to elicit and analyze the values represented in LLMs across age demographics, providing a structured approach to compare these values systematically.\n\nBy integrating these insights, the paper aims to contribute to the understanding and mitigation of age biases in LLMs, enhancing their usability for a broader spectrum of age groups.\n\n",
        "methodology": "### Investigating LLM\u2019s Value Inclination on the Perspective of Age\n#### Methodology\n\n##### Overview\n\nThe methodology for exploring the value inclinations of Large Language Models (LLMs) against human values is based on data from the 7th wave of the World Values Survey (WVS) (Haerpfer et al., 2020). The WVS probes 94,000 individuals globally on 13 categories encompassing social, political, economic, religious, and cultural values, with each inquiry represented as single-choice questions quantified numerically.\n\n##### Data Preparation\n\n1. **Human Values Computation**:\n   - **Grouping by Age and Country**: Respondents are categorized into age groups (18-24, 25-34, 35-44, 45-54, 55-64, and 65+ years) and by country.\n   - **Average Value Calculation**: The average values for each age and country cohort are calculated, ignoring invalid negative numbers.\n\n2. **LLM Analysis**:\n   - **Six LLMs**: Analysis is conducted on six distinct LLMs.\n   - **Survey Inquiry Components**: For each survey inquiry, three key components are identified: context, question ID & content, and options.\n\n##### Prompt Design\n\n- **Format Variations**: To ensure robustness, eight distinct prompts per inquiry are created by making format variations (e.g., alternating wordings and order of components). This approach addresses inconsistencies in LLM performance noted in previous studies (Shu et al., 2023; R\u00f6ttger et al., 2024; Beck et al., 2023).\n\n##### Response Analysis\n\n1. **Response Stability**:\n   - **Multiple Trials**: Multiple prompt trials identify a convergence point for LLM responses. On 95.5% of questions, the majority of the eight prompts led to responses centered on the same choice or adjacent options.\n   - **Unexpected Replies**: Seven types of unexpected replies were encountered, and coping methods for each are summarized.\n\n2. **Averaging Responses**:\n   - Similar to human values, invalid negative numbers are ignored during the averaging process of LLM responses.\n\n##### Reproducing Work\n\n- For the replication of the study, detailed parameter settings and prompting details are reported in Appendix D.\n\n---\n\nThis methodology leverages systematic data categorization and robust prompts to measure the convergence of responses amongst LLMs, ensuring the relevance and consistency of results against human value benchmarks.",
        "main_experiment_and_results": "### Main Experiment Setup and Results:\n\n#### Main Experiment Setup:\n\n**Datasets**:\nThe study examines datasets that capture various value inclinations across diverse demographics, specifically focusing on different age groups in several countries, including the US, China, Ethiopia, and Nigeria.\n\n**Baselines**:\nThe key baseline evaluates the alignment of LLMs with different age groups' values across multiple categories. The models analyzed include popular LLMs, with ChatGPT being one highlighted example.\n\n**Evaluation Metrics**:\n- **Trend Coefficient**: Measures the inclination of the models towards values of younger demographics.\n- **Alignment Rank**: Assesses the degree of value alignment between the model responses and the values of specific age groups.\n\n#### Main Experimental Results:\n\n- **US and China**: The models demonstrate a higher alignment rank with younger age groups across most value categories. Exceptions include categories like happiness and well-being, where the trend may differ.\n- **Ethiopia and Nigeria**: The models show a less evident inclination toward younger age groups, with no significant trend observed.\n\nSignificant testing outcomes and additional details on other models and countries are referenced in the appendices."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To assess the age-related value bias in Large Language Models (LLMs) across different demographic groups and compare their alignment to various age groups in several countries.",
            "experiment_process": "The study involved analyzing the inclination of LLMs' values towards different age groups using data from the World Value Survey across thirteen categories. The experiment used specific prompts tailored for robustness and included comparisons across six age groups in countries like the US, China, Ethiopia, and Nigeria. The results were evaluated using the trend coefficient to determine the alignment rank on different value categories, with significant testing detailed in Appendix G.",
            "result_discussion": "The findings indicate that LLMs, particularly in the US and China, favor the values of younger age groups across most categories, although exceptions like happiness and well-being exist. In Ethiopia and Nigeria, this inclination is less pronounced. These results suggest a prevalent age bias in LLMs, especially favoring younger demographics in more populous countries.",
            "ablation_id": "2404.08760v2.No1"
        },
        {
            "research_objective": "To evaluate whether incorporating age identity information in prompts can enhance the alignment of LLM values with those of different targeted age groups.",
            "experiment_process": "The experiment modified original prompts to include age identity information, e.g., 'Suppose you are from [country] and your age is between [lowerbound] and [upperbound].' Responses were analyzed for six different age groups across thirteen value categories. The Euclidean distance between LLM responses and actual values of different age groups was measured, and results were illustrated using figures, including a detailed example on the source of information acquisition.",
            "result_discussion": "Adding age identity to prompts resulted in no improvement in aligning LLM values with target age groups in eight out of thirteen categories. However, a successful calibration example showed that specifying age in the prompt allowed the LLM to better align its responses with the age group's behavior, as demonstrated in the increased reported use of radio news among older groups.",
            "ablation_id": "2404.08760v2.No2"
        }
    ]
}