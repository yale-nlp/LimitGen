{
    "title": "Improving Attributed Text Generation of Large Language Models via Preference Learning",
    "abstract": "Large language models have been widely adopted in natural language processing, yet they face the challenge of generating unreliable content. Recent works aim to reduce misinformation and hallucinations by resorting to attribution as a means to provide evidence (i.e., citations). However, current attribution methods usually focus on the retrieval stage and automatic evaluation that neglect mirroring the citation mechanisms in human scholarly writing to bolster credibility. In this paper, we address these challenges by modeling the attribution task as preference learning and introducing an Automatic Preference Optimization (APO) framework. First, we create a curated collection for post-training with 6,330 examples by collecting and filtering from existing datasets. Second, considering the high cost of labeling preference data, we further propose an automatic method to synthesize attribution preference data resulting in 95,263 pairs. Moreover, inspired by the human citation process, we further propose a progressive preference optimization method by leveraging fine-grained information. Extensive experiments on two datasets (i.e., ASQA and StrategyQA) demonstrate that APO achieves state-of-the-art citation F1 with higher answer quality. We will release the code upon publication.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Large Language Models (LLMs) have demonstrated emergent abilities and have gained widespread application in Natural Language Processing (NLP) Brown et al. (2020); Wei et al. (2022); OpenAI (2022); Anil et al. (2023). For example, LLMs have shown remarkable in-context learning capabilities across a variety of domains and tasks Dong et al. (2023). Although LLMs have been widely adopted, a prominent issue is that they produce hallucinations in certain situations Ye et al. (2023a); Zhang et al. (2023). In other words, they generate information that sounds plausible but is nonfactual, thereby limiting their applicability in the real world. To mitigate hallucinations, researchers have resorted to grounding statements in responses generated by LLMs to supported evidence, either by providing rationales or by adding citations to the statements Li et al. (2023a); Liu et al. (2023).\n\nRecent works have utilized external knowledge sources such as retrieved documents and knowledge graphs for attribution Shuster et al. (2021); Li et al. (2023c). Generally, these works are divided into two types: 1) the model generates an answer with citations based on the retrieved documents Li et al. (2023b); 2) an answer is first generated, then modified again to add attribution references by retrieving with query and initial answer Gao et al. (2023a). However, these works focus mainly on the retrieval stage Ye et al. (2023b) and the evaluation process Yue et al. (2023). Considering the selection of the model\u2019s desired responses and behavior from its very broad knowledge and capabilities, it is more necessary to optimize the generation process, not only reducing the hallucination of the original answer but also avoiding the hallucination of the attribution process.\n\nOn the other hand, fine-tuning LLMs after pre-training can also significantly improve performance for users\u2019 downstream tasks. First, given positive examples of correct behavior, supervised fine-tuning can be performed using standard likelihood-based training. Secondly, given positive and negative examples (binary feedback or pairwise feedback), methods such as unlikelihood training on negative examples Welleck et al. (2020) or RLHF-PPO Ziegler et al. (2019) can be used for learning. However, these methods usually suffer from expensive data collection process, reward model training, sparse reward and text degeneration problems, making them difficult to use in practical applications Azar et al. (2023).\n\nIn this paper, inspired by the citation mechanisms in human scholarly writing Brooks (1986); Teplitskiy et al. (2022), we address these challenges by conceptualizing the attribution task for LLMs as preference learning and proposing an Automatic Preference Optimization (APO) framework, as shown in Figure 1. Initially, we assemble a curated dataset comprising 6,330 examples sourced and refined from existing datasets for post-training. This step makes the LLMs know the basic format and requirements of attribution.\n\nConsidering the substantial cost and extremely time-consuming nature of preference pair annotations, we thus introduce an automated approach to generate attribution preference data, yielding 95,263 pairs. Furthermore, drawing inspiration from the human process of citation and direct preference optimization Rafailov et al. (2023), we propose a progressive preference optimization method with experience replay bypassing the need for explicit reward modeling or reinforcement learning.\n\nOur contributions are summarized as follows:\nTo the best of our knowledge, we are the first to apply preference learning for attribution tasks. We also show that our method can be applied under synthesized preference scenarios.\nWe establish a full data collection pipeline for attribution tasks and will open-source our all authorized data after publication for future research.\nWe propose a progressive preference optimization method to alleviate the sparse reward problem by leveraging fine-grained information. We further benchmark existing direct preference optimization methods and provide insights for attribution tasks."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Text Generation for Verification",
            "text": "Prior works have studied methods and evaluations for verification that identify supporting sources for model outputs. For instance,  Rashkin et al. (2021  ###reference_b33###) introduce the concept of Attributable to Identified Sources (AIS) which transforms model outputs into standalone, interpretable propositions. The response s can be attributed to a source P if they meet the intuitive criterion \u201cAccording to P, s\u201d. Bohnet et al. (2022  ###reference_b7###) adapt the AIS framework for QA scenarios. Further, Gao et al. (2023b  ###reference_b15###) extrapolate AIS to evaluate generated text of LLMs with citations. Additionally, several works focus on building and using automated AIS evaluations  Honovich et al. (2022  ###reference_b18###); Gao et al. (2023a  ###reference_b14###); Liu et al. (2023  ###reference_b28###). For a comprehensive overview, please refer to Li et al. (2023a  ###reference_b24###). In contrast to existing approaches, our work broadens the scope of attribution beyond just verifiable text generation and devises a methodology to enhance these attributions which frames it as a preference learning problem."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Preference Optimization Methods",
            "text": "Preference Optimization (PO) methods significantly improve generate quality to align with human values Christiano et al. (2017  ###reference_b11###); Ziegler et al. (2019  ###reference_b52###); Stiennon et al. (2020  ###reference_b38###); Bai et al. (2022  ###reference_b6###). It usually first collects pairs of generations under the same context and a pairwise human preference to indicate which generation is better. Then the PO is used to optimize generating policy to generate better candidates from the pair.\nFor example, Reinforcement Learning from Human Feedback (RLHF) is a model-based algorithm to optimize preference learning Ouyang et al. (2022  ###reference_b31###).\nHowever, the RLHF process is complex, time-consuming, and unstable. The direct PO uses an off-policy algorithm to directly optimize the generating policy, eliminating the need for a reward model Rafailov et al. (2023  ###reference_b32###); An et al. (2023  ###reference_b1###); Kang et al. (2023  ###reference_b22###); Zhao et al. (2023  ###reference_b50###). These approach are more data-efficient and stable.\nFor example, DPO uses the Bradley-Terry model  Bradley and Terry (1952  ###reference_b8###) and log-loss, which can lead to over-fitting to the preference data, especially when preference is deterministic and ignores the KL-regularization term.\nThe IPO algorithm Azar et al. (2023  ###reference_b5###) addresses this issue by using a root-finding MSE loss to solve the problem of ignoring KL-regularization when preference is deterministic. However, these methods fail to fully account for more fine-grained preferences and that is exactly what we want to do."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Preliminary",
            "text": "The main pipeline of preference learning usually consists of: 1) pretraining and Supervised Fine-Tuning (SFT), where SFT is not a must; 2) preference data collection;\n3) preference optimization.\nPreference learning typically starts with a pretrained LLMs or LLMs fine-tuned on high-quality data using maximum likelihood estimation.\nThe final policy  after this phase is represented as\nwhere  denotes the training data distribution.\nAfter pretraining and SFT phase,  is prompted by context ,\nand generate two responses . Then  is labeled by humans to judge which response is preferred and denote  if  is preferred,\nand  if  is preferred. We define a new symbol , and all <> consist the preference dataset :\nIn the final phase, the prevailing method uses reinforcement learning algorithm to learn an explicit or implicit\nreward from the preference data, and then using on-policy or off-policy policy gradient algorithm to maximize the reward.\nRecently, some methods have derived the optimal policy using reward maximization under KL-regularization and also\nderive a loss with optimal policy as its solution,\nthen learn the optimal policy by minimizing the derived loss on empirical dataset.\nThe RLHF uses standard two-phase reward model-based reinforcement learning to maximize the reward. It contains two steps:\n1) reward estimation from preference data 2) reward maximization using PPO algorithm.\nIt aims to maximize reward with a KL constraint on the reference model  (inputs  omitted):\nwhere  is the regularization weight and  is the reward function learned using\nthe Bradley-Terry model on the preference dataset of generating .\nDPO eliminates the training of reward model.\nIt derives a loss on the current policy  (,  omitted):\ni.e., the binary cross entropy with\nand target . We describe more PO methods in details in Appendix A  ###reference_###."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Methodology",
            "text": "We construct the post-training data from training sets using existing attribution datasets including EVIGSE Liu et al. (2023  ###reference_b28###), ExpertQA Malaviya et al. (2023  ###reference_b29###) and HARGID Kamalloo et al. (2023  ###reference_b21###). We select these datasets because they are high-quality attribution datasets with diverse domains and sources annotated by human experts or powerful LLMs. After preprocessing and formatting, the final post-training data collection includes 6,330 samples. The pre-processing details are shown in Appendices B  ###reference_### and C  ###reference_###, and the statistics of training data are shown in Table 1  ###reference_###.\nAfter that, instruction , documents  and question  are formatted to be the input while answer  composed of multiple statements is formatted as output. We tune the model using autoregressive language modeling objectives, resulting in initial generator .\nIn general, attributed text generation should be both relevant and supported Asai et al. (2023b  ###reference_b4###). Being relevant needs the reference document in the answer to be helpful in handling the question. It is used to measure whether  provides useful information to solve . Being supported asks the generated text be grounded on the reference documents. It is used to measure whether all of the verification-worthy statements in  are supported by .\nFollowing the requirements above, we first get initial responses and related labels for each query with the Algorithm 1  ###reference_###.\nThe query comes from multiple open domain tasks or high-quality instruction data sets shown in Table 1  ###reference_###. The source of retrieved documents is English Wikipedia. The retriever  we use here is gtr-t5-large222huggingface.co/sentence-transformers/gtr-t5-large  ###reference_5-large###.\nThe objective is to generate the attributed text with relevant and supported labels for related documents using the critic model . Here, we use pre-trained selfrag_llama2_7b333huggingface.co/selfrag/selfrag_llama2_7b  ###reference_### as  in Asai et al. (2023b  ###reference_b4###) because it can give fine-grained feedback using reflection tokens.\nAfter that, we generate preference pairs using an automatic collection algorithm.\nSpecifically, we determine whether the citations  of each statement  of query  are all related to it based on the relevant tags. If it is all relevant, we add the current statement and its preceding statements  to the set  for subsequent processing. For example, if  meets the requirement, we add  to . The motivation here is that we want to select the statements that can answer the question based on the document as the initial set.\nThen, for each entry in , we first retrieve another top- () documents and filter them into 10 irrelevant documents  scored by relevant logits predicted by . If all documents in  are relevant, we use the last 10 documents as .\nAfter that, we generate the positive and negative pair for each statement . There are two situations: the statement  is fully supported by  and otherwise. For the first situation, we first expand  with supported document by second judgment in  using . Then, we generate one positive statement using ,  and new  and two negative statements using , ,  and , , new , error instruction  respectively.\nThus, there are two preference pairs in this context.\nFor the second situation, we generate one positive statement using ,  and new  and one negative statement using , , , error instruction . The full procedure is shown in Algorithm 2  ###reference_###.\nIn the generation of negative samples, we use the error instruction , which defines two types: irrelevant but supported means the generated text  is grounded on unhelpful reference documents , while relevant but unsupported further has three fine-grained subtypes: 1) fabricated statement refers to the generated text contains facts or information that cannot be derived from reference documents; 2) mistaken synthesis means that several reference documents are used, but facts or logics are mistakenly intermingled. The generated text thus contains factual error or logic error; 3) unintentional omission means that reference documents are used, but the key points are incomplete. There are no factual errors in generated text, but some information is omitted.\nThe irrelevant but supported error derives from attribution hallucination, whereas the relevant but unsupported error is the result of generation hallucination. Note that irrelevant and unsupported errors are not included, since it is more like easy negatives. The details of error instructions are in Appendix D  ###reference_###.\nTo reinforce the preference feature and alleviate sparse reward problem Zheng et al. (2023  ###reference_b51###); Lightman et al. (2023  ###reference_b27###), we propose a progressive preference optimization method. Considering generations can be separated into several consecutive statements, each statement may contain hallucinations at all. The entire response-level reward preference modeling performs in the global context and potentially oversights the fine-grained deterministic preferences we constructed. Hence, we use fine-grained statement-level reward to perform preference optimization to update the model in a more effective and efficient way.\nFormally, assuming that deterministic preference is performed at statement-level, we can rewrite the preference optimization loss in Eqn. (4  ###reference_###) as follows ( omitted):\nThe progressive preference optimization loss can be further written as follows ( omitted):\nThe main difference between vanilla preference optimization in Eqn. (4  ###reference_###) and progressive preference optimization is that the latter contains an implicit mean pooling procedure when implementing the preference optimization loss.\nFurthermore, the directed preference optimization may face the challenges of overfitting to some deterministic preference due to weak KL constraint Azar et al. (2023  ###reference_b5###). Hence, we propose to leverage experience replay Rolnick et al. (2019  ###reference_b34###) as learning with rehearsal to alleviate the over-fitting phenomenon. The idea of replaying experience typically stores a few old training samples within a small memory buffer. Therefore, we iteratively add post-training autoregressive language modeling loss to the preference optimization procedure in a fixed interval, resulting in final generator ."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Problem Formulation",
            "text": "Formally, consider a query  and a corpus of text documents . The goal is to produce an output , where  is a collection of  distinct statements: . Each statement  is associated with a set of citations . This set  is defined as , where each  is a document from the corpus . For application purposes, the output from LLMs can be divided into individual statements using sentence boundaries. This approach is utilized because a single sentence typically encapsulates a coherent statement while maintaining brevity, facilitating easy verification. Regarding the citation format, citations are typically presented in square brackets, e.g., The sun is formed approximately 4.6 billion years ago [1][2]. However, it should be noted that these citations can be attributed to specific phrases as well, not just at the end of sentences.\nMoreover, in this paper, we define generation hallucination refers to a situation where the model generates content that is not based on factual information and attribution hallucination means that the statement corresponding to one citation is unfaithful or not supported by the referred source content."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Overall Framework",
            "text": "As shown in Figure 2  ###reference_###, we introduce the APO framework to apply preference learning for attribution task. The APO framework consists of the post-training procedure to ground the base model for attribution (\u00a74.3  ###reference_###), and the preference optimization procedure to address both generation hallucination and attribution hallucination (\u00a74.4  ###reference_###)."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Post-training",
            "text": "###table_1### The goal of post-training procedure is to ensure that given a specific question  and a corpus of text documents , the model can be successfully instructed to generate answer  and add citation  for each statement  in its response when necessary.\nWe construct the post-training data from training sets using existing attribution datasets including EVIGSE Liu et al. (2023  ###reference_b28###  ###reference_b28###), ExpertQA Malaviya et al. (2023  ###reference_b29###  ###reference_b29###) and HARGID Kamalloo et al. (2023  ###reference_b21###  ###reference_b21###). We select these datasets because they are high-quality attribution datasets with diverse domains and sources annotated by human experts or powerful LLMs. After preprocessing and formatting, the final post-training data collection includes 6,330 samples. The pre-processing details are shown in Appendices B  ###reference_###  ###reference_### and C  ###reference_###  ###reference_###, and the statistics of training data are shown in Table 1  ###reference_###  ###reference_###.\nAfter that, instruction , documents  and question  are formatted to be the input while answer  composed of multiple statements is formatted as output. We tune the model using autoregressive language modeling objectives, resulting in initial generator ."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "Preference Optimization",
            "text": "In this section, we describe our preference optimization procedure to enable a model-agnostic approach for improving the quality of generated responses. First, considering the cost of labeling preference data, we devise an automatic data collection algorithm motivated by errors where previous models may have misattributed. Second, we propose a progressive preference optimization approach to amplify the preference signal by using synthesized preference pairs. We further apply the experience replay to alleviate the over-fitting and text degradation phenomenon due to the distribution shift introduced by automatic data generation.\nIn general, attributed text generation should be both relevant and supported Asai et al. (2023b  ###reference_b4###  ###reference_b4###). Being relevant needs the reference document in the answer to be helpful in handling the question. It is used to measure whether  provides useful information to solve . Being supported asks the generated text be grounded on the reference documents. It is used to measure whether all of the verification-worthy statements in  are supported by .\nFollowing the requirements above, we first get initial responses and related labels for each query with the Algorithm 1  ###reference_###  ###reference_###.\nThe query comes from multiple open domain tasks or high-quality instruction data sets shown in Table 1  ###reference_###  ###reference_###. The source of retrieved documents is English Wikipedia. The retriever  we use here is gtr-t5-large222huggingface.co/sentence-transformers/gtr-t5-large  ###reference_5-large###  ###reference_5-large###.\nThe objective is to generate the attributed text with relevant and supported labels for related documents using the critic model . Here, we use pre-trained selfrag_llama2_7b333huggingface.co/selfrag/selfrag_llama2_7b  ###reference_###  ###reference_### as  in Asai et al. (2023b  ###reference_b4###  ###reference_b4###) because it can give fine-grained feedback using reflection tokens.\nAfter that, we generate preference pairs using an automatic collection algorithm.\nSpecifically, we determine whether the citations  of each statement  of query  are all related to it based on the relevant tags. If it is all relevant, we add the current statement and its preceding statements  to the set  for subsequent processing. For example, if  meets the requirement, we add  to . The motivation here is that we want to select the statements that can answer the question based on the document as the initial set.\nThen, for each entry in , we first retrieve another top- () documents and filter them into 10 irrelevant documents  scored by relevant logits predicted by . If all documents in  are relevant, we use the last 10 documents as .\nAfter that, we generate the positive and negative pair for each statement . There are two situations: the statement  is fully supported by  and otherwise. For the first situation, we first expand  with supported document by second judgment in  using . Then, we generate one positive statement using ,  and new  and two negative statements using , ,  and , , new , error instruction  respectively.\nThus, there are two preference pairs in this context.\nFor the second situation, we generate one positive statement using ,  and new  and one negative statement using , , , error instruction . The full procedure is shown in Algorithm 2  ###reference_###  ###reference_###.\nIn the generation of negative samples, we use the error instruction , which defines two types: irrelevant but supported means the generated text  is grounded on unhelpful reference documents , while relevant but unsupported further has three fine-grained subtypes: 1) fabricated statement refers to the generated text contains facts or information that cannot be derived from reference documents; 2) mistaken synthesis means that several reference documents are used, but facts or logics are mistakenly intermingled. The generated text thus contains factual error or logic error; 3) unintentional omission means that reference documents are used, but the key points are incomplete. There are no factual errors in generated text, but some information is omitted.\nThe irrelevant but supported error derives from attribution hallucination, whereas the relevant but unsupported error is the result of generation hallucination. Note that irrelevant and unsupported errors are not included, since it is more like easy negatives. The details of error instructions are in Appendix D  ###reference_###  ###reference_###.\nTo reinforce the preference feature and alleviate sparse reward problem Zheng et al. (2023  ###reference_b51###  ###reference_b51###); Lightman et al. (2023  ###reference_b27###  ###reference_b27###), we propose a progressive preference optimization method. Considering generations can be separated into several consecutive statements, each statement may contain hallucinations at all. The entire response-level reward preference modeling performs in the global context and potentially oversights the fine-grained deterministic preferences we constructed. Hence, we use fine-grained statement-level reward to perform preference optimization to update the model in a more effective and efficient way.\nFormally, assuming that deterministic preference is performed at statement-level, we can rewrite the preference optimization loss in Eqn. (4  ###reference_###  ###reference_###) as follows ( omitted):\nThe progressive preference optimization loss can be further written as follows ( omitted):\nThe main difference between vanilla preference optimization in Eqn. (4  ###reference_###  ###reference_###) and progressive preference optimization is that the latter contains an implicit mean pooling procedure when implementing the preference optimization loss.\nFurthermore, the directed preference optimization may face the challenges of overfitting to some deterministic preference due to weak KL constraint Azar et al. (2023  ###reference_b5###  ###reference_b5###). Hence, we propose to leverage experience replay Rolnick et al. (2019  ###reference_b34###  ###reference_b34###) as learning with rehearsal to alleviate the over-fitting phenomenon. The idea of replaying experience typically stores a few old training samples within a small memory buffer. Therefore, we iteratively add post-training autoregressive language modeling loss to the preference optimization procedure in a fixed interval, resulting in final generator ."
        },
        {
            "section_id": "4.5",
            "parent_section_id": "4",
            "section_name": "Inference and Refinement",
            "text": "During inference, for query ,  is first retrieved and then sent to  output to the final answer  consists of  statements.\nAs there may not be all statements correctly attributing documents, we additionally perform the post-hoc refinement after the original generation. We maintain a collection of citations .\nStarting from the last statement of , if the current  has the citations, update the  to the citations of the current ; if the current  does not have a citation, add the current citation set  to this statement until all  statements have been traversed. Then we concatenate these  statements together as the final answer ."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Setup",
            "text": "We mainly focus on attributable long-form question-answering (QA) task using ASQA dataset. In addition to these factoid long-form QA tasks, we test the generation quality on StrategyQA dataset Geva et al. (2021  ###reference_b17###), which focuses on open-domain QA where the required reasoning steps are implicit in the question. We use the official test set as our evaluation set.\n\nFollowing Gao et al. (2023b  ###reference_b15###), we report citation recall, precision, and F1, which uses TRUE Honovich et al. (2022  ###reference_b18###) as the attribution evaluation model to automatically examine whether the cited documents entail the model generation.\n\nFor ASQA dataset, we report the recall of correct short answers (EM-R) by checking whether the short answers (provided by the dataset) are exact substrings of the generation.\n\nFor StrategyQA dataset, we report the accuracy for task performance."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "Datasets and Evaluation Metrics",
            "text": "We mainly focus on the attributable long-form question-answering (QA) task using the ASQA dataset. In addition to these factoid long-form QA tasks, we test the generation quality on the StrategyQA dataset Geva et al. (2021) which focuses on open-domain QA where the required reasoning steps are implicit in the question. We use the official test set as our evaluation set.\n\nFollowing Gao et al. (2023b), we report citation recall, precision, and F1 using TRUE Honovich et al. (2022) as the attribution evaluation model to automatically examine whether the cited documents entail the model generation.\n\nFor the ASQA dataset, we report the recall of correct short answers (EM-R) by checking whether the short answers (provided by the dataset) are exact substrings of the generation.\n\nFor the StrategyQA dataset, we report the accuracy for task performance."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "Competitive Methods",
            "text": "We compare APO with several baselines. For each baseline, we use gtr-t5-large as our retriever.\n\nIn-Context Learning (ICLCite): We prompt LLMs with few-shot examples, each consisting of a query, a set of retrieved documents, and an answer with inline citations. The LLMs can in-context learn from the examples and generate grounded responses for the test query and retrieved documents.\n\nPost-Hoc Cite (PostCite): Given a query, we first instruct LLMs to answer without retrieved documents. Then, we use the attribution evaluation model to link each statement to the most relevant document retrieved by the query.\n\nPost-Hoc Attribute (PostAttr): Instead of citing the most relevant document, for each statement, we further retrieve a set of k documents and then use the model to link to the document that maximally supports the statement by threshold.\n\nSelf-RAG Asai et al. (2023b): Self-RAG is the state-of-the-art (SoTA) method that adaptively retrieves documents on-demand. It generates with reflection on retrieved documents and its generations by special token control.\n\nAGREE Ye et al. (2023b): AGREE leverages test-time adaptation to reinforce unverified statements which iteratively improves the responses of LLMs. It tunes a pre-trained LLM to self-ground its response in retrieved documents using automatically collected data."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "Implementation Details",
            "text": "If not specified, we retrieve the top 5 documents as the related documents and we set the decoding temperature to 0.01 during inference. For the post-training, we tune the model for 2 epochs with a learning rate of 5e-5. For the preference optimization, we tune the model with LoRA Hu et al. (2022  ###reference_b20###) for 1 epoch, and we set alpha to 2 and lora ranks to 16. We set to 100. We use llama-2-13b-base Touvron et al. (2023  ###reference_b41###) for fair comparison. We run all the experiments on NVIDIA A100 80G GPUs."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Results",
            "text": ""
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "Main Result",
            "text": "Table 2  ###reference_### shows the comparison results of APO with other baselines on three datasets. In terms of correctness and citation quality, our method outperforms the baselines on all three datasets. It shows that APO has better overall generation performance in various scenarios. Specifically, our method outperforms Self-RAG by 8.8 points on the EM-R metric. We speculate that this inconsistency stems from the difference between coherent generation and step-wise generation in Self-RAG. Our method also shows consistent improvements over AGREE across multiple benchmarks which suggests that APO can more effectively exploit the power of LLM to enhance retrieval. APO can be used to complement these active or adaptive retrieval-based methods and we leave it for future work. Compared to the post-training baseline, the preference optimization shows further improvement with an 8.0 average increased citation F1. Furthermore, we observe a trade-off between correctness and citation quality in several baselines including Self-RAG and AGREE, possibly due to the generation hallucination and attribution hallucination defined in \u00a74.1  ###reference_###. In contrast, APO helps to deal with these hallucinations and performs well in terms of both correctness and citation quality."
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "Ablation Study",
            "text": "We evaluate the effectiveness of each predefined error type and the results are shown in Table 3  ###reference_###. Specifically, we perform progressive PO on the model after post-training and remove data corresponding to a predefined type. We observe that without data corresponding to hallucinated statement error, citation F1 drops significantly which suggests that our approach improves the groundedness of the model. Mistaken synthesis error seems to contribute little to performance improvement, but we observe that it can help improve groundedness under human evaluation (\u00a76.5  ###reference_###). Without unintentional omission error, the model shows poor generation quality. This means that the model may generate incomplete answers.\nMoreover, we perform an ablation study on the training strategy of preference optimization. We find that the model can also be improved under the response-level preference optimization method such as vanilla DPO, but the improvement is slightly less. In addition, we ablation the PO by removing the ASQA questions from our preference data. Note that we construct the preference data based on the training set of ASQA, and use its test set for evaluation. We have verified and guaranteed that there is no data overlap between the two. We find that the generation quality and citation quality have decreased. We attribute it to high-quality in-domain questions in ASQA as a long-form question answering dataset."
        },
        {
            "section_id": "6.3",
            "parent_section_id": "6",
            "section_name": "Different Prompting Strategy",
            "text": "We explore applying APO to four prompting strategies Gao et al. (2023b  ###reference_b15###): 1) Vanilla that provides the top-5 retrieved documents for each question. It is our default setting. 2) Summ that provides summaries instead of the full text of the top-10 retrieved documents for each question. 3) Snippet that provides snippets instead of the full text of the top 10 retrieved documents for each question. 4) Oracle that provides 5 gold documents for each question. We use llama-2-13b-chat as the comparison method because it has impressive instruction following ability and moderate size. As shown in Table 4  ###reference_###, we find that in most cases, APO achieves better performance than baseline. For example, APO under Vanilla and Oracle settings performs best in Citation F1 on ASQA, while it under Summ and Snippet settings in ELI5 has improved Citation F1. It shows that the format of the context has an impact on attribution task."
        },
        {
            "section_id": "6.4",
            "parent_section_id": "6",
            "section_name": "Different PO Methods",
            "text": "Table 5  ###reference_### illustrates the results of different direct preference optimization methods adopted by . We include a SFT baseline to tune the  using the positive part in the chosen preference pairs that we created. We observe that our method can be transferred to several different preference optimization methods, but the performance swings in several metrics. All preference optimization methods have performance boosts compared with the post-training baseline and the SFT baseline. It shows that preference optimization can help improve the generation quality to some extent."
        },
        {
            "section_id": "6.5",
            "parent_section_id": "6",
            "section_name": "Error Analysis",
            "text": "We conduct human evaluation of model response on ASQA dataset.\nSpecifically, we collect 50 samples that contain errors judged by the attribution evaluation model . We then perform a detailed manual review of these samples to identify error types. Our evaluation results are shown in Table 6  ###reference_###.\nWe find that nearly half of the errors are of fabrication error. We reveal that the model either generated text not supported by the reference documents or incorrectly attributed information to irrelevant documents. In certain instances, hallucinations are due to the documents with low quality. For example, some documents are truncated, and the model attempts to complete or extrapolate the incomplete text. Additionally, we notice omission errors on both generated text and citation where the model fails to generate necessary citations to substantiate its statements. Although synthesis errors are less common, we observe some cases which model conflated information from multiple documents and generated counterfactual statements.\nThe case study is shown in Appendix E  ###reference_###."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "This paper introduces the APO framework for attributed text generation. We treat attribution as a preference learning task, utilizing curated post-training collections and an automated synthesis algorithm to reduce manual labeling costs. Experiments on three datasets demonstrate the effectiveness of APO which achieves leading citation F1 and improved response quality. Future work can explore extending APO to real-world applications."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Details about Preference Optimization Methods",
            "text": ""
        },
        {
            "section_id": "Appendix 2",
            "parent_section_id": null,
            "section_name": "Appendix B Details about Pre-processing",
            "text": "For ExpertQA dataset, we remove samples whose 1) citations attribute to empty references; 2) documents contain different document IDs but same context. For EVIGSE dataset, we remove samples whose 1) citation attribute to \u201cNone\u201d references; 2) do not have reference documents. We further normalize the \u201csupported\u201d label and the citation format for these datasets. The details of each dataset we used for post-training procedure after pre-processing are shown in Table 7  ###reference_###."
        },
        {
            "section_id": "Appendix 3",
            "parent_section_id": null,
            "section_name": "Appendix C Post-training Templates",
            "text": "The post-training template we used follows the question answering template used by  Gao et al. (2023b  ###reference_b15###) since we find that preposition question before document can result in a performance boost when trying ICLCite method in the preliminary experiments. The concrete templates are shown in Table 8  ###reference_###."
        },
        {
            "section_id": "Appendix 4",
            "parent_section_id": null,
            "section_name": "Appendix D Details about the Instruction",
            "text": "The templates employed for generating preference data are detailed in Table 9  ###reference_### for positive instances, Table 10  ###reference_### for statements exhibiting hallucination errors, Table 11  ###reference_### for statements with synthesis errors, and Table 12  ###reference_### for statements characterized by omission errors."
        },
        {
            "section_id": "Appendix 5",
            "parent_section_id": null,
            "section_name": "Appendix E Case Study",
            "text": "In this section, we perform a detailed case study and demonstrate several examples of each type of error we defined. As shown in Table 13  ###reference_###, we classify it as a fabrication error since it uses an undefined entity. In Table 14  ###reference_###, we classify it as a synthesis error since it mixes up facts from document 4 and document 5, which results in a factual error. In Table 15  ###reference_###, we classify it as a omission error since it used facts from document 4 and document 5, but document 4 is not attributed."
        },
        {
            "section_id": "Appendix 6",
            "parent_section_id": null,
            "section_name": "Appendix F Related Works of Retrieval Augmentation of LLMs",
            "text": "Retrieval augmentation has emerged as a prominent technique aimed at enhancing the accuracy and veracity of LLMs Gao et al. (2023c  ###reference_b16###); Asai et al. (2023a  ###reference_b3###). Specifically, Sun et al. (2023  ###reference_b39###) couples LLMs with long-term and short-term memories, resulting in improved claim and citation generation. Meanwhile, in order to effectively incorporate external knowledge into LLMs, SearChain proposes a global reasoning chain strategy that facilitates retrieval augmentation generation at each node within the chain Xu et al. (2023  ###reference_b45###). In another line of research, the self-reflection is leveraged for retrieval verification during the retrieval-augmented generation process Li et al. (2023b  ###reference_b25###); Asai et al. (2023b  ###reference_b4###). Despite these advancements, prior studies have not adequately addressed the issue of attribution hallucination Zuccon et al. (2023  ###reference_b53###). In contrast, we focus on making the model better answer the query and align with the reference.\n###figure_2###"
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.1.1\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.2.1\">Source</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.3.1\"># Examples</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.2.2.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S4.T1.1.2.2.1.1\">Post-training</span></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.1.2.2.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.1.2.2.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.3.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.3.3.1\">EVIGSE</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.3.3.2\">Internet</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.3.3.3\">3508</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.4.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.4.4.1\">ExpertQA</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.4.2\">Internet</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.4.3\">906</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.5.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.5.5.1\">HAGRID</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.5.5.2\">Wiki</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.5.5.3\">1301+615(dev)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.6.6.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S4.T1.1.6.6.1.1\">Preference Optimization</span></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.1.6.6.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.1.6.6.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.7.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.7.7.1\">stanford_alpaca</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.7.7.2\">Wiki</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.7.7.3\">7741</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.8.8\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.8.8.1\">oasst1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.8.8.2\">Wiki</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.8.8.3\">2478</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.9.9\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.9.9.1\">asqa</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.9.9.2\">Wiki</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.9.9.3\">2333</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.10.10\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.10.10.1\">sharegpt</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.10.10.2\">Wiki</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.10.10.3\">2490</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.11.11\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.11.11.1\">wow</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.11.11.2\">Wiki</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.11.11.3\">3689</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.12.12\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.12.12.1\">gpt4_alpaca</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.12.12.2\">Wiki</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.12.12.3\">6679</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.13.13\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.13.13.1\">flan_v2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.13.13.2\">Wiki</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.13.13.3\">1693</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.14.14\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.14.14.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S4.T1.1.14.14.1.1\">Test</span></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.1.14.14.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.1.14.14.3\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.15.15\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.15.15.1\">ASQA</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.15.15.2\">Wiki</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.15.15.3\">948</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.16.16\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.16.16.1\">StrategyQA</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.16.16.2\">Wiki</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.16.16.3\">490</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.17.17\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.1.17.17.1\">ELI5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.17.17.2\">Sphere</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.17.17.3\">1000</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Statistics of data collections used at different stages in the APO framework.</figcaption>\n</figure>",
            "capture": "Table 1: Statistics of data collections used at different stages in the APO framework."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T2\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T2.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" id=\"S5.T2.1.1.1.1\" rowspan=\"3\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.1.1.1\">Dataset &amp; Metrics</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"4\" id=\"S5.T2.1.1.1.2\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.1.2.1\">ASQA</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"4\" id=\"S5.T2.1.1.1.3\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.1.3.1\">StrategyQA</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"4\" id=\"S5.T2.1.1.1.4\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.1.4.1\">ELI5</span></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S5.T2.1.1.1.5\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td class=\"ltx_td ltx_border_tt\" id=\"S5.T2.1.1.1.6\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.2.2.1\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.2.2.1.1\">Correct</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"3\" id=\"S5.T2.1.2.2.2\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.2.2.2.1\">Citation</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.2.2.3\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.2.2.3.1\">Correct</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"3\" id=\"S5.T2.1.2.2.4\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.2.2.4.1\">Citation</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.2.2.5\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.2.2.5.1\">Correct</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"3\" id=\"S5.T2.1.2.2.6\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.2.2.6.1\">Citation</span></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S5.T2.1.2.2.7\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td class=\"ltx_td\" id=\"S5.T2.1.2.2.8\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.3.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.3.3.1\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.3.3.1.1\">EM-R</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.3.3.2\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.3.3.2.1\">Rec</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.3.3.3\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.3.3.3.1\">Prec</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.3.3.4\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.3.3.4.1\">F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.3.3.5\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.3.3.5.1\">ACC</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.3.3.6\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.3.3.6.1\">Rec</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.3.3.7\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.3.3.7.1\">Prec</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.3.3.8\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.3.3.8.1\">F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.3.3.9\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.3.3.9.1\">Claim</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.3.3.10\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.3.3.10.1\">Rec</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.3.3.11\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.3.3.11.1\">Prec</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.3.3.12\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.3.3.12.1\">F1</span></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S5.T2.1.3.3.13\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td class=\"ltx_td\" id=\"S5.T2.1.3.3.14\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T2.1.4.4.1\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S5.T2.1.4.4.1.1\">ICLCite</span>\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Gao et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib15\" title=\"\">2023b</a>)</cite>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.4.4.2\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">35.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.4.4.3\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">38.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.4.4.4\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">39.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.4.4.5\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">38.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.4.4.6\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.4.4.6.1\">65.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.4.4.7\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">20.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.4.4.8\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">33.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.4.4.9\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">25.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.4.4.10\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">13.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.4.4.11\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">17.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.4.4.12\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">15.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.4.4.13\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">16.5</td>\n<td class=\"ltx_td ltx_border_t\" id=\"S5.T2.1.4.4.14\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S5.T2.1.4.4.15\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T2.1.5.5.1\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S5.T2.1.5.5.1.1\">PostCite</span>\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Gao et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib15\" title=\"\">2023b</a>)</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.5.5.2\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">25.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.5.5.3\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">23.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.5.5.4\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">23.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.5.5.5\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">23.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.5.5.6\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">64.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.5.5.7\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">8.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.5.5.8\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">8.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.5.5.9\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">8.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.5.5.10\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">7.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.5.5.11\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">5.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.5.5.12\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">5.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.5.5.13\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">5.8</td>\n<td class=\"ltx_td\" id=\"S5.T2.1.5.5.14\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td class=\"ltx_td\" id=\"S5.T2.1.5.5.15\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T2.1.6.6.1\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S5.T2.1.6.6.1.1\">PostAttr</span>\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Ye et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib47\" title=\"\">2023b</a>)</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.6.6.2\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">25.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.6.6.3\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">33.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.6.6.4\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">33.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.6.6.5\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">33.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.6.6.6\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">64.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.6.6.7\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">12.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.6.6.8\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">12.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.6.6.9\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">12.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.6.6.10\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">7.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.6.6.11\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">12.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.6.6.12\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">12.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.6.6.13\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">12.2</td>\n<td class=\"ltx_td\" id=\"S5.T2.1.6.6.14\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td class=\"ltx_td\" id=\"S5.T2.1.6.6.15\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T2.1.7.7.1\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Self-RAG\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Asai et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib4\" title=\"\">2023b</a>)</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.7.7.2\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">31.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.7.7.3\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">70.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.7.7.4\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.7.7.4.1\">71.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.7.7.5\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">70.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.7.7.6\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">62.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.7.7.7\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">31.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.7.7.8\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">36.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.7.7.9\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">33.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.7.7.10\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">10.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.7.7.11\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">20.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.7.7.12\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">22.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.7.7.13\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">21.6</td>\n<td class=\"ltx_td\" id=\"S5.T2.1.7.7.14\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td class=\"ltx_td\" id=\"S5.T2.1.7.7.15\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T2.1.8.8.1\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">AGREE\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Ye et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib47\" title=\"\">2023b</a>)</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.8.8.2\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">39.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.8.8.3\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">64.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.8.8.4\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">66.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.8.8.5\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">65.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.8.8.6\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">64.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.8.8.7\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">30.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.8.8.8\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">37.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.8.8.9\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">33.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.8.8.10\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">9.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.8.8.11\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">21.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.8.8.12\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">16.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.8.8.13\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">18.4</td>\n<td class=\"ltx_td\" id=\"S5.T2.1.8.8.14\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td class=\"ltx_td\" id=\"S5.T2.1.8.8.15\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T2.1.9.9.1\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">APO (only post-training)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.9.9.2\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">36.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.9.9.3\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">65.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.9.9.4\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">62.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.9.9.5\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">63.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.9.9.6\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">62.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.9.9.7\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">30.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.9.9.8\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">30.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.9.9.9\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">30.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.9.9.10\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">13.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.9.9.11\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">18.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.9.9.12\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">17.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.9.9.13\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">18.2</td>\n<td class=\"ltx_td ltx_border_t\" id=\"S5.T2.1.9.9.14\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S5.T2.1.9.9.15\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T2.1.10.10.1\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">APO (our method)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.10.10.2\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.10.10.2.1\">40.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.10.10.3\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.10.10.3.1\">72.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.10.10.4\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">69.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.10.10.5\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.10.10.5.1\">71.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.10.10.6\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">61.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.10.10.7\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.10.10.7.1\">40.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.10.10.8\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.10.10.8.1\">39.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.10.10.9\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.10.10.9.1\">39.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.10.10.10\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.10.10.10.1\">13.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.10.10.11\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.10.10.11.1\">26.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.10.10.12\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.10.10.12.1\">24.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.10.10.13\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.10.10.13.1\">25.2</span></td>\n<td class=\"ltx_td ltx_border_bb\" id=\"S5.T2.1.10.10.14\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td class=\"ltx_td ltx_border_bb\" id=\"S5.T2.1.10.10.15\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>The performance comparison between our method and extensive baselines. Experiments are evaluated on ASQA\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Stelmakh et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib37\" title=\"\">2022</a>)</cite>, StrategyQA\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Geva et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib17\" title=\"\">2021</a>)</cite> and ELI5 dataset\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Fan et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib13\" title=\"\">2019</a>)</cite>. For most baselines, we use the results of previous works\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Gao et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib15\" title=\"\">2023b</a>); Ye et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib47\" title=\"\">2023b</a>)</cite>.\n</figcaption>\n</figure>",
            "capture": "Table 2: The performance comparison between our method and extensive baselines. Experiments are evaluated on ASQA\u00a0Stelmakh et\u00a0al. (2022), StrategyQA\u00a0Geva et\u00a0al. (2021) and ELI5 dataset\u00a0Fan et\u00a0al. (2019). For most baselines, we use the results of previous works\u00a0Gao et\u00a0al. (2023b); Ye et\u00a0al. (2023b).\n"
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S6.T3\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S6.T3.1\" style=\"width:433.6pt;height:228.9pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(80.4pt,-42.4pt) scale(1.58931963105364,1.58931963105364) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S6.T3.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S6.T3.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T3.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.1.1.1.1.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T3.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.1.1.1.1.2.1\">EM-R</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T3.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.1.1.1.1.3.1\">Rec</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T3.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.1.1.1.1.4.1\">Prec</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T3.1.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.1.1.1.1.5.1\">F1</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S6.T3.1.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S6.T3.1.1.2.1.1\">Our Method</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T3.1.1.2.1.2\">36.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T3.1.1.2.1.3\">65.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T3.1.1.2.1.4\">62.1</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S6.T3.1.1.2.1.5\">63.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.1.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T3.1.1.3.2.1\">\n<span class=\"ltx_ERROR undefined\" id=\"S6.T3.1.1.3.2.1.1\">\\hdashline</span>\u00a0\u00a0 w/o asqa</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.3.2.2\">38.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.3.2.3\">71.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.3.2.4\">67.2</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T3.1.1.3.2.5\">69.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.1.1.4.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T3.1.1.4.3.1\">\u00a0\u00a0\u00a0\u00a0 w/o hallucinated statement</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.4.3.2\">40.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.4.3.3\">69.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.4.3.4\">65.3</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T3.1.1.4.3.5\">67.3</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.1.1.5.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T3.1.1.5.4.1\">\u00a0\u00a0\u00a0\u00a0 w/o mistaken synthesis</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.5.4.2\">40.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.5.4.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.1.1.5.4.3.1\">73.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.5.4.4\">69.2</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T3.1.1.5.4.5\">71.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.1.1.6.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T3.1.1.6.5.1\">\u00a0\u00a0\u00a0\u00a0 w/o unintentional omission</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.6.5.2\">39.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.6.5.3\">72.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.6.5.4\">68.2</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T3.1.1.6.5.5\">70.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.1.1.7.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T3.1.1.7.6.1\">\n<span class=\"ltx_ERROR undefined\" id=\"S6.T3.1.1.7.6.1.1\">\\hdashline</span>\u00a0\u00a0 w/ response-level PO</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.7.6.2\">38.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.7.6.3\">69.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T3.1.1.7.6.4\">65.1</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T3.1.1.7.6.5\">67.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.1.1.8.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S6.T3.1.1.8.7.1\">\u00a0\u00a0\u00a0\u00a0 w/ statement-level PO</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S6.T3.1.1.8.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.1.1.8.7.2.1\">40.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S6.T3.1.1.8.7.3\">72.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S6.T3.1.1.8.7.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.1.1.8.7.4.1\">69.6</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S6.T3.1.1.8.7.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.1.1.8.7.5.1\">71.2</span></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Ablation study on the ASQA dataset. We ablate not only the source and predefined error type used to construct PO data, but also the training strategy.</figcaption>\n</figure>",
            "capture": "Table 3: Ablation study on the ASQA dataset. We ablate not only the source and predefined error type used to construct PO data, but also the training strategy."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"S6.T4\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S6.T4.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S6.T4.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" id=\"S6.T4.1.1.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.1.1.1.1\">Method &amp; Metrics</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"4\" id=\"S6.T4.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.1.1.2.1\">ASQA</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.2.2.1.1\">Correct</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.2.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.2.2.2.1\">Rec</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.2.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.2.2.3.1\">Prec</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S6.T4.1.2.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.2.2.4.1\">F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S6.T4.1.3.3.1\"><span class=\"ltx_text ltx_font_typewriter ltx_font_bold\" id=\"S6.T4.1.3.3.1.1\">llama-2-13b-chat</span></th>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.3.3.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.3.3.3\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.3.3.4\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.3.3.5\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S6.T4.1.4.4.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.4.4.1.1\">Vanilla</span>(5-psg)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.4.4.2\">32.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.4.4.3\">60.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.4.4.4\">52.1</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S6.T4.1.4.4.5\">55.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T4.1.5.5.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.5.5.1.1\">Summ</span>(10-psg)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.5.5.2\">42.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.5.5.3\">58.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.5.5.4\">50.4</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T4.1.5.5.5\">54.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T4.1.6.6.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.6.6.1.1\">Snippet</span>(10-psg)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.6.6.2\">41.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.6.6.3\">57.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.6.6.4\">52.1</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T4.1.6.6.5\">54.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T4.1.7.7.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.7.7.1.1\">Oracle</span>(5-psg)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.7.7.2\">41.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.7.7.3\">54.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.7.7.4\">52.9</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T4.1.7.7.5\">53.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S6.T4.1.8.8.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.8.8.1.1\">Our method</span></th>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.8.8.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.8.8.3\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.8.8.4\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.8.8.5\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S6.T4.1.9.9.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.9.9.1.1\">Vanilla</span>(5-psg)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.9.9.2\">40.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.9.9.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.9.9.3.1\">72.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.9.9.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.9.9.4.1\">69.6</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S6.T4.1.9.9.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.9.9.5.1\">71.2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T4.1.10.10.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.10.10.1.1\">Summ</span>(10-psg)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.10.10.2\">42.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.10.10.3\">60.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.10.10.4\">53.4</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T4.1.10.10.5\">56.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.11.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T4.1.11.11.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.11.11.1.1\">Snippet</span>(10-psg)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.11.11.2\">42.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.11.11.3\">57.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.11.11.4\">51.6</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T4.1.11.11.5\">54.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T4.1.12.12.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.12.12.1.1\">Oracle</span>(5-psg)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.12.12.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.12.12.2.1\">52.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.12.12.3\">70.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.12.12.4\">66.2</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T4.1.12.12.5\">68.3</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.13.13\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S6.T4.1.13.13.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.13.13.1.1\">Method &amp; Metrics</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"4\" id=\"S6.T4.1.13.13.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.13.13.2.1\">ELI5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.14.14\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.14.14.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.14.14.1.1\">Correct</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.14.14.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.14.14.2.1\">Rec</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.14.14.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.14.14.3.1\">Prec</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S6.T4.1.14.14.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.14.14.4.1\">F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.15.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S6.T4.1.15.15.1\"><span class=\"ltx_text ltx_font_typewriter ltx_font_bold\" id=\"S6.T4.1.15.15.1.1\">llama-2-13b-chat</span></th>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.15.15.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.15.15.3\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.15.15.4\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.15.15.5\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.16.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S6.T4.1.16.16.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.16.16.1.1\">Vanilla</span>(5-psg)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.16.16.2\">12.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.16.16.3\">16.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.16.16.4\">19.7</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S6.T4.1.16.16.5\">17.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.17.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T4.1.17.17.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.17.17.1.1\">Summ</span>(10-psg)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.17.17.2\">6.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.17.17.3\">9.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.17.17.4\">14.3</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T4.1.17.17.5\">11.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.18.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T4.1.18.18.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.18.18.1.1\">Snippet</span>(10-psg)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.18.18.2\">11.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.18.18.3\">29.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.18.18.4\">28.6</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T4.1.18.18.5\">29.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.19.19\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T4.1.19.19.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.19.19.1.1\">Oracle</span>(5-psg)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.19.19.2\">16.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.19.19.3\">21.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.19.19.4\">27.3</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T4.1.19.19.5\">24.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.20.20\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S6.T4.1.20.20.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.20.20.1.1\">Our method</span></th>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.20.20.2\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.20.20.3\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.20.20.4\"></td>\n<td class=\"ltx_td ltx_border_t\" id=\"S6.T4.1.20.20.5\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.21.21\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S6.T4.1.21.21.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.21.21.1.1\">Vanilla</span>(5-psg)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.21.21.2\">13.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.21.21.3\">26.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T4.1.21.21.4\">24.5</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S6.T4.1.21.21.5\">25.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.22.22\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T4.1.22.22.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.22.22.1.1\">Summ</span>(10-psg)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.22.22.2\">12.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.22.22.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.22.22.3.1\">37.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.22.22.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.22.22.4.1\">35.7</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T4.1.22.22.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.22.22.5.1\">36.7</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.23.23\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T4.1.23.23.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.23.23.1.1\">Snippet</span>(10-psg)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.23.23.2\">14.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.23.23.3\">37.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T4.1.23.23.4\">34.8</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T4.1.23.23.5\">36.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T4.1.24.24\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S6.T4.1.24.24.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S6.T4.1.24.24.1.1\">Oracle</span>(5-psg)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S6.T4.1.24.24.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T4.1.24.24.2.1\">21.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S6.T4.1.24.24.3\">32.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S6.T4.1.24.24.4\">30.8</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S6.T4.1.24.24.5\">31.7</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Comparisons with different retrieval context.</figcaption>\n</figure>",
            "capture": "Table 4: Comparisons with different retrieval context."
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"S6.T5\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S6.T5.1\" style=\"width:433.6pt;height:246.1pt;vertical-align:-0.9pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-37.8pt,21.4pt) scale(0.851445275031398,0.851445275031398) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S6.T5.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T5.1.1.1.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.1.1.1.1\">Method &amp; Metrics</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"4\" id=\"S6.T5.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.1.1.2.1\">ASQA</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T5.1.1.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.2.2.1.1\">Correct</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T5.1.1.2.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.2.2.2.1\">Rec</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T5.1.1.2.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.2.2.3.1\">Prec</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T5.1.1.2.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.2.2.4.1\">F1</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.3.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S6.T5.1.1.3.1.1\">APO (only post-training)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T5.1.1.3.1.2\">36.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T5.1.1.3.1.3\">65.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T5.1.1.3.1.4\">62.1</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S6.T5.1.1.3.1.5\">63.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.4.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T5.1.1.4.2.1\">\n<span class=\"ltx_ERROR undefined\" id=\"S6.T5.1.1.4.2.1.1\">\\hdashline</span>\u00a0\u00a0 w/ Positive statement SFT</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.4.2.2\">29.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.4.2.3\">66.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.4.2.4\">56.8</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T5.1.1.4.2.5\">61.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.5.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T5.1.1.5.3.1\">\u00a0\u00a0\u00a0\u00a0 w/ IPO\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Azar et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib5\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.5.3.2\">39.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.5.3.3\">72.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.5.3.4\">69.2</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T5.1.1.5.3.5\">70.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.6.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T5.1.1.6.4.1\">\u00a0\u00a0\u00a0\u00a0 w/ SLiC\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Zhao et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib50\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.6.4.2\">40.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.6.4.3\">72.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.6.4.4\">69.1</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T5.1.1.6.4.5\">70.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.7.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T5.1.1.7.5.1\">\u00a0\u00a0\u00a0\u00a0 w/ KTO\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Kawin et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib23\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.7.5.2\">39.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.7.5.3\">72.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.7.5.4\">68.7</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T5.1.1.7.5.5\">70.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.8.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T5.1.1.8.6.1\">\u00a0\u00a0\u00a0\u00a0 w/ Progressive PO</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.8.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.8.6.2.1\">40.5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.8.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.8.6.3.1\">72.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.8.6.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.8.6.4.1\">69.6</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T5.1.1.8.6.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.8.6.5.1\">71.2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.9.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T5.1.1.9.7.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.9.7.1.1\">Method &amp; Metrics</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"4\" id=\"S6.T5.1.1.9.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.9.7.2.1\">ELI5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.10.8\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T5.1.1.10.8.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.10.8.1.1\">Correct</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T5.1.1.10.8.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.10.8.2.1\">Rec</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T5.1.1.10.8.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.10.8.3.1\">Prec</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S6.T5.1.1.10.8.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.10.8.4.1\">F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.11.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S6.T5.1.1.11.9.1\">APO (only post-training)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T5.1.1.11.9.2\">13.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T5.1.1.11.9.3\">18.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T5.1.1.11.9.4\">17.9</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S6.T5.1.1.11.9.5\">18.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.12.10\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T5.1.1.12.10.1\">\n<span class=\"ltx_ERROR undefined\" id=\"S6.T5.1.1.12.10.1.1\">\\hdashline</span>\u00a0\u00a0 w/ Positive statement SFT</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.12.10.2\">10.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.12.10.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.12.10.3.1\">34.5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.12.10.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.12.10.4.1\">30.8</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T5.1.1.12.10.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.12.10.5.1\">32.5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.13.11\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T5.1.1.13.11.1\">\u00a0\u00a0\u00a0\u00a0 w/ IPO\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Azar et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib5\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.13.11.2\">13.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.13.11.3\">26.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.13.11.4\">24.8</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T5.1.1.13.11.5\">25.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.14.12\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T5.1.1.14.12.1\">\u00a0\u00a0\u00a0\u00a0 w/ SLiC\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Zhao et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib50\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.14.12.2\">13.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.14.12.3\">30.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.14.12.4\">22.0</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T5.1.1.14.12.5\">25.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.15.13\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T5.1.1.15.13.1\">\u00a0\u00a0\u00a0\u00a0 w/ KTO\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">Kawin et\u00a0al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.18381v1#bib.bib23\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.15.13.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T5.1.1.15.13.2.1\">14.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.15.13.3\">24.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T5.1.1.15.13.4\">26.5</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T5.1.1.15.13.5\">25.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T5.1.1.16.14\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S6.T5.1.1.16.14.1\">\u00a0\u00a0\u00a0\u00a0 w/ Progressive PO</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S6.T5.1.1.16.14.2\">13.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S6.T5.1.1.16.14.3\">26.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S6.T5.1.1.16.14.4\">24.5</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S6.T5.1.1.16.14.5\">25.2</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>Comparisons with different preference method.</figcaption>\n</figure>",
            "capture": "Table 5: Comparisons with different preference method."
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"S6.T6\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S6.T6.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S6.T6.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S6.T6.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T6.1.1.1.1.1\">Error Type</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S6.T6.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T6.1.1.1.2.1\"># Proportion (%)</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T6.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S6.T6.1.2.2.1\">Attribution hallucination</th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S6.T6.1.2.2.2\">26.4</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S6.T6.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" id=\"S6.T6.1.3.1.1\">\n<span class=\"ltx_ERROR undefined\" id=\"S6.T6.1.3.1.1.1\">\\hdashline</span>Generation hallucination</th>\n<td class=\"ltx_td ltx_nopad_r\" id=\"S6.T6.1.3.1.2\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T6.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T6.1.4.2.1\">\u00a0\u00a0\u00a0\u00a0- Fabrication</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T6.1.4.2.2\">48.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T6.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S6.T6.1.5.3.1\">\u00a0\u00a0\u00a0\u00a0- Omission</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S6.T6.1.5.3.2\">18.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T6.1.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S6.T6.1.6.4.1\">\u00a0\u00a0\u00a0\u00a0- Synthesis</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S6.T6.1.6.4.2\">6.5</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 6: </span>Error types of the proposed methods.</figcaption>\n</figure>",
            "capture": "Table 6: Error types of the proposed methods."
        },
        "7": {
            "table_html": "<figure class=\"ltx_table\" id=\"A2.T7\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"A2.T7.1\" style=\"width:433.6pt;height:77.6pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-34.5pt,6.2pt) scale(0.862756882411952,0.862756882411952) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A2.T7.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T7.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A2.T7.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T7.1.1.1.1.1.1\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A2.T7.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T7.1.1.1.1.2.1\"># Sample</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T7.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T7.1.1.1.1.3.1\">Avg. Query Length</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T7.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T7.1.1.1.1.4.1\">Avg. Response Length</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T7.1.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T7.1.1.1.1.5.1\">Avg. Statements</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T7.1.1.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T7.1.1.1.1.6.1\">Avg. Citations</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T7.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T7.1.1.2.1.1\">EVIGSE</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"A2.T7.1.1.2.1.2\">3508</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T7.1.1.2.1.3\">51.03</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T7.1.1.2.1.4\">379.05</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T7.1.1.2.1.5\">4.32</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"A2.T7.1.1.2.1.6\">3.19</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T7.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T7.1.1.3.2.1\">ExpertQA</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"A2.T7.1.1.3.2.2\">906</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.1.1.3.2.3\">106.90</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.1.1.3.2.4\">999.84</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.1.1.3.2.5\">7.16</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"A2.T7.1.1.3.2.6\">5.67</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T7.1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T7.1.1.4.3.1\">HARGID(train)</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"A2.T7.1.1.4.3.2\">1301</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.1.1.4.3.3\">38.55</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.1.1.4.3.4\">368.22</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T7.1.1.4.3.5\">4.62</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"A2.T7.1.1.4.3.6\">2.85</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T7.1.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"A2.T7.1.1.5.4.1\">HARGID(dev)</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"A2.T7.1.1.5.4.2\">615</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T7.1.1.5.4.3\">40.43</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T7.1.1.5.4.4\">292.46</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T7.1.1.5.4.5\">3.63</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"A2.T7.1.1.5.4.6\">2.54</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 7: </span>Details for our post-training data after pre-processing.</figcaption>\n</figure>",
            "capture": "Table 7: Details for our post-training data after pre-processing."
        },
        "8": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T8\"><svg class=\"ltx_picture\" height=\"228.29\" id=\"A3.T8.pic1\" overflow=\"visible\" version=\"1.1\" width=\"600\"><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" transform=\"translate(0,228.29) matrix(1 0 0 -1 0 0)\"><g fill=\"#404040\" fill-opacity=\"1.0\"><path d=\"M 0 5.91 L 0 222.39 C 0 225.65 2.64 228.29 5.91 228.29 L 594.09 228.29 C 597.36 228.29 600 225.65 600 222.39 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z\" style=\"stroke:none\"></path></g><g fill=\"#F2F2F2\" fill-opacity=\"1.0\"><path d=\"M 1.97 5.91 L 1.97 222.39 C 1.97 224.56 3.73 226.33 5.91 226.33 L 594.09 226.33 C 596.27 226.33 598.03 224.56 598.03 222.39 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z\" style=\"stroke:none\"></path></g><g color=\"#404040\" fill=\"#404040\" stroke=\"#404040\" stroke-dasharray=\"2.84528pt,2.84528pt\" stroke-dashoffset=\"1.42264pt\" stroke-opacity=\"1.0\"><path d=\"M 1.97 56.03 L 598.03 56.03\" style=\"fill:none\"></path></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 67.84)\"><foreignobject color=\"#000000\" height=\"146.67\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A3.T8.pic1.1.1.1.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A3.T8.pic1.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T8.pic1.1.1.1.1.1.1.1\">Input\n<br class=\"ltx_break\"/></span>Write an accurate, engaging, and concise answer for the given question using only the provided documents (some of which might be irrelevant) and cite them properly. Use an unbiased and journalistic tone. Always cite for any factual claim. When citing several search results, use [1][2][3]. Cite at least one document and at most three documents in each sentence. If multiple documents support the sentence, only cite a minimum sufficient subset of the documents.</span>\n<span class=\"ltx_p\" id=\"A3.T8.pic1.1.1.1.1.1.2\">Question: {{question}}</span>\n<span class=\"ltx_p\" id=\"A3.T8.pic1.1.1.1.1.1.3\">Document [1](Title: {{title 1}}): {{context 1}}</span>\n<span class=\"ltx_p\" id=\"A3.T8.pic1.1.1.1.1.1.4\">Document [2](Title: {{title 2}}): {{context 2}}</span>\n<span class=\"ltx_p\" id=\"A3.T8.pic1.1.1.1.1.1.5\">Document [3](Title: {{title 3}}): {{context 3}}</span>\n<span class=\"ltx_p\" id=\"A3.T8.pic1.1.1.1.1.1.6\">\u2026</span>\n<span class=\"ltx_p\" id=\"A3.T8.pic1.1.1.1.1.1.7\">Document [n](Title: {{title n}}): {{context n}}</span>\n<span class=\"ltx_p\" id=\"A3.T8.pic1.1.1.1.1.1.8\">Answer:</span>\n</span></foreignobject></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 13.78)\"><foreignobject color=\"#000000\" height=\"30.44\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A3.T8.pic1.2.2.2.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A3.T8.pic1.2.2.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T8.pic1.2.2.2.1.1.1.1\">Output</span></span>\n<span class=\"ltx_p\" id=\"A3.T8.pic1.2.2.2.1.1.2\">{{output}}</span>\n</span></foreignobject></g></g></svg>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 8: </span>Post-training Template with instruction </figcaption>\n</figure>",
            "capture": "Table 8: Post-training Template with instruction "
        },
        "9": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T9\"><svg class=\"ltx_picture\" height=\"294.71\" id=\"A3.T9.pic1\" overflow=\"visible\" version=\"1.1\" width=\"600\"><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" transform=\"translate(0,294.71) matrix(1 0 0 -1 0 0)\"><g fill=\"#404040\" fill-opacity=\"1.0\"><path d=\"M 0 5.91 L 0 288.81 C 0 292.07 2.64 294.71 5.91 294.71 L 594.09 294.71 C 597.36 294.71 600 292.07 600 288.81 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z\" style=\"stroke:none\"></path></g><g fill=\"#F2F2F2\" fill-opacity=\"1.0\"><path d=\"M 1.97 5.91 L 1.97 288.81 C 1.97 290.98 3.73 292.74 5.91 292.74 L 594.09 292.74 C 596.27 292.74 598.03 290.98 598.03 288.81 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z\" style=\"stroke:none\"></path></g><g color=\"#404040\" fill=\"#404040\" stroke=\"#404040\" stroke-dasharray=\"2.84528pt,2.84528pt\" stroke-dashoffset=\"1.42264pt\" stroke-opacity=\"1.0\"><path d=\"M 1.97 56.03 L 598.03 56.03\" style=\"fill:none\"></path></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 67.84)\"><foreignobject color=\"#000000\" height=\"213.09\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A3.T9.pic1.1.1.1.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A3.T9.pic1.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T9.pic1.1.1.1.1.1.1.1\">Input\n<br class=\"ltx_break\"/></span>Task: Your job is to write a high quality response with requirements as follows:</span>\n<span class=\"ltx_p\" id=\"A3.T9.pic1.1.1.1.1.1.2\">General: Given Request, incomplete response and evidence, continue write a single sentence as the next sentence of the unfinished response. If text in unfinished response is \u201cNone\u201d, you should start the response(the first sentence).</span>\n<span class=\"ltx_p\" id=\"A3.T9.pic1.1.1.1.1.1.3\">Detail: You should always use the facts from the evidences to propuse your response. Your response is correct and comprehensive, fully supported by the evidence we provided. **Don\u2019t use any evidence that can be directly retrieved from the evidences we provided**. No hallucinations, no factual errors, no logic errors.</span>\n<span class=\"ltx_p\" id=\"A3.T9.pic1.1.1.1.1.1.4\">Request: {{request}}</span>\n<span class=\"ltx_p\" id=\"A3.T9.pic1.1.1.1.1.1.5\">Evidence:</span>\n<span class=\"ltx_p\" id=\"A3.T9.pic1.1.1.1.1.1.6\">Document [1](Title: {{title 1}}): {{context 1}}</span>\n<span class=\"ltx_p\" id=\"A3.T9.pic1.1.1.1.1.1.7\">Document [2](Title: {{title 2}}): {{context 2}}</span>\n<span class=\"ltx_p\" id=\"A3.T9.pic1.1.1.1.1.1.8\">Document [3](Title: {{title 3}}): {{context 3}}</span>\n<span class=\"ltx_p\" id=\"A3.T9.pic1.1.1.1.1.1.9\">\u2026</span>\n<span class=\"ltx_p\" id=\"A3.T9.pic1.1.1.1.1.1.10\">Document [n](Title: {{title n}}): {{context n}}</span>\n<span class=\"ltx_p\" id=\"A3.T9.pic1.1.1.1.1.1.11\">Unfinished response: {{past statements}}</span>\n<span class=\"ltx_p\" id=\"A3.T9.pic1.1.1.1.1.1.12\">Next sentence(good):</span>\n</span></foreignobject></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 13.78)\"><foreignobject color=\"#000000\" height=\"30.44\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A3.T9.pic1.2.2.2.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A3.T9.pic1.2.2.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T9.pic1.2.2.2.1.1.1.1\">Output</span></span>\n<span class=\"ltx_p\" id=\"A3.T9.pic1.2.2.2.1.1.2\">{{output}}</span>\n</span></foreignobject></g></g></svg>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 9: </span>Positive Template</figcaption>\n</figure>",
            "capture": "Table 9: Positive Template"
        },
        "10": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T10\"><svg class=\"ltx_picture\" height=\"278.11\" id=\"A3.T10.pic1\" overflow=\"visible\" version=\"1.1\" width=\"600\"><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" transform=\"translate(0,278.11) matrix(1 0 0 -1 0 0)\"><g fill=\"#404040\" fill-opacity=\"1.0\"><path d=\"M 0 5.91 L 0 272.2 C 0 275.46 2.64 278.11 5.91 278.11 L 594.09 278.11 C 597.36 278.11 600 275.46 600 272.2 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z\" style=\"stroke:none\"></path></g><g fill=\"#F2F2F2\" fill-opacity=\"1.0\"><path d=\"M 1.97 5.91 L 1.97 272.2 C 1.97 274.38 3.73 276.14 5.91 276.14 L 594.09 276.14 C 596.27 276.14 598.03 274.38 598.03 272.2 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z\" style=\"stroke:none\"></path></g><g color=\"#404040\" fill=\"#404040\" stroke=\"#404040\" stroke-dasharray=\"2.84528pt,2.84528pt\" stroke-dashoffset=\"1.42264pt\" stroke-opacity=\"1.0\"><path d=\"M 1.97 56.03 L 598.03 56.03\" style=\"fill:none\"></path></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 67.84)\"><foreignobject color=\"#000000\" height=\"196.49\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A3.T10.pic1.1.1.1.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A3.T10.pic1.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T10.pic1.1.1.1.1.1.1.1\">Input\n<br class=\"ltx_break\"/></span>Task: Your job is to write a low quality response with requirements as follows:</span>\n<span class=\"ltx_p\" id=\"A3.T10.pic1.1.1.1.1.1.2\">General: Given Request, incomplete response and evidence, continue write a single sentence as the next sentence of the unfinished response. If text in unfinished response is \u201cNone\u201d, you should start the response(the first sentence).</span>\n<span class=\"ltx_p\" id=\"A3.T10.pic1.1.1.1.1.1.3\">Detail: You will always ignore the evidence. On one hand, you won\u2019t follow the evidence we provided, your response should be irrelevant to the evidence we provided. On the other hand, your response should be relevant to the unfinished response.</span>\n<span class=\"ltx_p\" id=\"A3.T10.pic1.1.1.1.1.1.4\">Request: {{request}}</span>\n<span class=\"ltx_p\" id=\"A3.T10.pic1.1.1.1.1.1.5\">Evidence:</span>\n<span class=\"ltx_p\" id=\"A3.T10.pic1.1.1.1.1.1.6\">Document [1](Title: {{title 1}}): {{context 1}}</span>\n<span class=\"ltx_p\" id=\"A3.T10.pic1.1.1.1.1.1.7\">Document [2](Title: {{title 2}}): {{context 2}}</span>\n<span class=\"ltx_p\" id=\"A3.T10.pic1.1.1.1.1.1.8\">Document [3](Title: {{title 3}}): {{context 3}}</span>\n<span class=\"ltx_p\" id=\"A3.T10.pic1.1.1.1.1.1.9\">\u2026</span>\n<span class=\"ltx_p\" id=\"A3.T10.pic1.1.1.1.1.1.10\">Document [n](Title: {{title n}}): {{context n}}</span>\n<span class=\"ltx_p\" id=\"A3.T10.pic1.1.1.1.1.1.11\">Unfinished response: {{past statements}}</span>\n<span class=\"ltx_p\" id=\"A3.T10.pic1.1.1.1.1.1.12\">Raw sentence(good): {{positive statement}}</span>\n<span class=\"ltx_p\" id=\"A3.T10.pic1.1.1.1.1.1.13\">Worse sentence(bad, ignore the evidence):</span>\n</span></foreignobject></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 13.78)\"><foreignobject color=\"#000000\" height=\"30.44\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A3.T10.pic1.2.2.2.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A3.T10.pic1.2.2.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T10.pic1.2.2.2.1.1.1.1\">Output</span></span>\n<span class=\"ltx_p\" id=\"A3.T10.pic1.2.2.2.1.1.2\">{{output}}</span>\n</span></foreignobject></g></g></svg>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 10: </span>Negative, fabrication template</figcaption>\n</figure>",
            "capture": "Table 10: Negative, fabrication template"
        },
        "11": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T11\"><svg class=\"ltx_picture\" height=\"311.32\" id=\"A3.T11.pic1\" overflow=\"visible\" version=\"1.1\" width=\"600\"><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" transform=\"translate(0,311.32) matrix(1 0 0 -1 0 0)\"><g fill=\"#404040\" fill-opacity=\"1.0\"><path d=\"M 0 5.91 L 0 305.41 C 0 308.67 2.64 311.32 5.91 311.32 L 594.09 311.32 C 597.36 311.32 600 308.67 600 305.41 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z\" style=\"stroke:none\"></path></g><g fill=\"#F2F2F2\" fill-opacity=\"1.0\"><path d=\"M 1.97 5.91 L 1.97 305.41 C 1.97 307.59 3.73 309.35 5.91 309.35 L 594.09 309.35 C 596.27 309.35 598.03 307.59 598.03 305.41 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z\" style=\"stroke:none\"></path></g><g color=\"#404040\" fill=\"#404040\" stroke=\"#404040\" stroke-dasharray=\"2.84528pt,2.84528pt\" stroke-dashoffset=\"1.42264pt\" stroke-opacity=\"1.0\"><path d=\"M 1.97 56.03 L 598.03 56.03\" style=\"fill:none\"></path></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 67.84)\"><foreignobject color=\"#000000\" height=\"229.69\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A3.T11.pic1.1.1.1.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A3.T11.pic1.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T11.pic1.1.1.1.1.1.1.1\">Input\n<br class=\"ltx_break\"/></span>Task: Your job is to write a low quality response with requirements as follows:</span>\n<span class=\"ltx_p\" id=\"A3.T11.pic1.1.1.1.1.1.2\">General: Given Request, incomplete response and evidence, continue write a single sentence as the next sentence of the unfinished response. If text in unfinished response is \u201cNone\u201d, you should start the response(the first sentence).</span>\n<span class=\"ltx_p\" id=\"A3.T11.pic1.1.1.1.1.1.3\">Detail: You should first, identify the relationships and entities in evidence; second, continue writing the next sentence of the response span with regard to the evidence. In your response, the relationships and entities should be mistakenly intermingled(you are making negative samples, we need low-quality data).</span>\n<span class=\"ltx_p\" id=\"A3.T11.pic1.1.1.1.1.1.4\">Request: {{request}}</span>\n<span class=\"ltx_p\" id=\"A3.T11.pic1.1.1.1.1.1.5\">Evidence:</span>\n<span class=\"ltx_p\" id=\"A3.T11.pic1.1.1.1.1.1.6\">Document [1](Title: {{title 1}}): {{context 1}}</span>\n<span class=\"ltx_p\" id=\"A3.T11.pic1.1.1.1.1.1.7\">Document [2](Title: {{title 2}}): {{context 2}}</span>\n<span class=\"ltx_p\" id=\"A3.T11.pic1.1.1.1.1.1.8\">Document [3](Title: {{title 3}}): {{context 3}}</span>\n<span class=\"ltx_p\" id=\"A3.T11.pic1.1.1.1.1.1.9\">\u2026</span>\n<span class=\"ltx_p\" id=\"A3.T11.pic1.1.1.1.1.1.10\">Document [n](Title: {{title n}}): {{context n}}</span>\n<span class=\"ltx_p\" id=\"A3.T11.pic1.1.1.1.1.1.11\">Unfinished response: {{past statements}}</span>\n<span class=\"ltx_p\" id=\"A3.T11.pic1.1.1.1.1.1.12\">Raw sentence(good): {{positive statement}}</span>\n<span class=\"ltx_p\" id=\"A3.T11.pic1.1.1.1.1.1.13\">Worse sentence(bad, entities in evidences mistakenly intermingled):</span>\n</span></foreignobject></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 13.78)\"><foreignobject color=\"#000000\" height=\"30.44\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A3.T11.pic1.2.2.2.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A3.T11.pic1.2.2.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T11.pic1.2.2.2.1.1.1.1\">Output</span></span>\n<span class=\"ltx_p\" id=\"A3.T11.pic1.2.2.2.1.1.2\">{{output}}</span>\n</span></foreignobject></g></g></svg>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 11: </span>Negative, synthesis template</figcaption>\n</figure>",
            "capture": "Table 11: Negative, synthesis template"
        },
        "12": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T12\"><svg class=\"ltx_picture\" height=\"394.34\" id=\"A3.T12.pic1\" overflow=\"visible\" version=\"1.1\" width=\"600\"><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" transform=\"translate(0,394.34) matrix(1 0 0 -1 0 0)\"><g fill=\"#404040\" fill-opacity=\"1.0\"><path d=\"M 0 5.91 L 0 388.43 C 0 391.69 2.64 394.34 5.91 394.34 L 594.09 394.34 C 597.36 394.34 600 391.69 600 388.43 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z\" style=\"stroke:none\"></path></g><g fill=\"#F2F2F2\" fill-opacity=\"1.0\"><path d=\"M 1.97 5.91 L 1.97 388.43 C 1.97 390.61 3.73 392.37 5.91 392.37 L 594.09 392.37 C 596.27 392.37 598.03 390.61 598.03 388.43 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z\" style=\"stroke:none\"></path></g><g color=\"#404040\" fill=\"#404040\" stroke=\"#404040\" stroke-dasharray=\"2.84528pt,2.84528pt\" stroke-dashoffset=\"1.42264pt\" stroke-opacity=\"1.0\"><path d=\"M 1.97 56.03 L 598.03 56.03\" style=\"fill:none\"></path></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 67.84)\"><foreignobject color=\"#000000\" height=\"312.72\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A3.T12.pic1.1.1.1.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A3.T12.pic1.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T12.pic1.1.1.1.1.1.1.1\">Input\n<br class=\"ltx_break\"/></span>Task: Your job is to write a low quality response with requirements as follows:</span>\n<span class=\"ltx_p\" id=\"A3.T12.pic1.1.1.1.1.1.2\">General: Given Request, unfinished response and next sentence, omit some important points from the next sentence(good) and convert it into a worse response. Your converted worse response should be consistent with the unfinished response.</span>\n<span class=\"ltx_p\" id=\"A3.T12.pic1.1.1.1.1.1.3\">Request: List the ingredients needed to make a peanut butter and jelly sandwich</span>\n<span class=\"ltx_p\" id=\"A3.T12.pic1.1.1.1.1.1.4\">Unfinished response:</span>\n<span class=\"ltx_p\" id=\"A3.T12.pic1.1.1.1.1.1.5\">Raw sentence(good): To make a peanut butter and jelly sandwich, you will need peanut butter, jelly or jam of your choice, and bread.</span>\n<span class=\"ltx_p\" id=\"A3.T12.pic1.1.1.1.1.1.6\">Worse sentence(bad, omit the evidence): To make a peanut butter and jelly sandwich, you will need peanut butter and bread.</span>\n<span class=\"ltx_p\" id=\"A3.T12.pic1.1.1.1.1.1.7\">Request: What are the three features of a cloud-based Database-as-a-Service (DBaaS)?</span>\n<span class=\"ltx_p\" id=\"A3.T12.pic1.1.1.1.1.1.8\">Unfinished response: The three main features of a cloud-based DBaaS are scalability, cost efficiency, and backups. Scalability allows you to increase or decrease the resources used by the DBaaS with ease.</span>\n<span class=\"ltx_p\" id=\"A3.T12.pic1.1.1.1.1.1.9\">Raw sentence(good): Cost efficiency is another important feature of a cloud-based DBaaS, as it allows you to pay for only the resources you need and eliminates the need for upfront hardware investments.</span>\n<span class=\"ltx_p\" id=\"A3.T12.pic1.1.1.1.1.1.10\">Worse sentence(bad, omit the evidence): Cost efficiency is another important feature of a cloud-based DBaaS, as it allows you to pay for only the resources you need.</span>\n<span class=\"ltx_p\" id=\"A3.T12.pic1.1.1.1.1.1.11\">Request: {{request}}</span>\n<span class=\"ltx_p\" id=\"A3.T12.pic1.1.1.1.1.1.12\">Unfinished response: {{past statements}}</span>\n<span class=\"ltx_p\" id=\"A3.T12.pic1.1.1.1.1.1.13\">Raw sentence(good): {{positive statement}}</span>\n<span class=\"ltx_p\" id=\"A3.T12.pic1.1.1.1.1.1.14\">Worse sentence(bad, omit the evidence):</span>\n</span></foreignobject></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 13.78)\"><foreignobject color=\"#000000\" height=\"30.44\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A3.T12.pic1.2.2.2.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A3.T12.pic1.2.2.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T12.pic1.2.2.2.1.1.1.1\">Output</span></span>\n<span class=\"ltx_p\" id=\"A3.T12.pic1.2.2.2.1.1.2\">{{output}}</span>\n</span></foreignobject></g></g></svg>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 12: </span>Negative, omission template</figcaption>\n</figure>",
            "capture": "Table 12: Negative, omission template"
        },
        "13": {
            "table_html": "<figure class=\"ltx_table\" id=\"A5.T13\"><svg class=\"ltx_picture\" height=\"722.2\" id=\"A5.T13.pic1\" overflow=\"visible\" version=\"1.1\" width=\"600\"><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" transform=\"translate(0,722.2) matrix(1 0 0 -1 0 0)\"><g fill=\"#404040\" fill-opacity=\"1.0\"><path d=\"M 0 5.91 L 0 716.29 C 0 719.55 2.64 722.2 5.91 722.2 L 594.09 722.2 C 597.36 722.2 600 719.55 600 716.29 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z\" style=\"stroke:none\"></path></g><g fill=\"#F2F2F2\" fill-opacity=\"1.0\"><path d=\"M 1.97 5.91 L 1.97 716.29 C 1.97 718.47 3.73 720.23 5.91 720.23 L 594.09 720.23 C 596.27 720.23 598.03 718.47 598.03 716.29 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z\" style=\"stroke:none\"></path></g><g color=\"#404040\" fill=\"#404040\" stroke=\"#404040\" stroke-dasharray=\"2.84528pt,2.84528pt\" stroke-dashoffset=\"1.42264pt\" stroke-opacity=\"1.0\"><path d=\"M 1.97 72.64 L 598.03 72.64\" style=\"fill:none\"></path></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 84.45)\"><foreignobject color=\"#000000\" height=\"623.97\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A5.T13.pic1.1.1.1.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A5.T13.pic1.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T13.pic1.1.1.1.1.1.1.1\">Question\n<br class=\"ltx_break\"/></span>When did the rams go to st louis?</span>\n<span class=\"ltx_p\" id=\"A5.T13.pic1.1.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T13.pic1.1.1.1.1.1.2.1\">Documents\n<br class=\"ltx_break\"/></span>Document [1](Title: History of St. Louis): 2011, with performances by Jay Leno and Aretha Franklin. In January 1995, Georgia Frontiere, the owner of the National Football League team known as the Los Angeles Rams (now St. Louis Rams), announced she would move that team to St. Louis. The team replaced the St. Louis Cardinals (now Arizona Cardinals), an NFL franchise that had moved to St. Louis in 1960 but departed for Arizona in 1988. The Rams played their first game in their St. Louis stadium, the Edward Jones Dome, on October 22, 1996. Starting in the early 1980s, more rehabilitation and construction projects began, some of</span>\n<span class=\"ltx_p\" id=\"A5.T13.pic1.1.1.1.1.1.3\">Document [2](Title: History of the St. Louis Rams): History of the St. Louis Rams The professional American football franchise now known as the Los Angeles Rams played in St. Louis, Missouri, as the St. Louis Rams from the 1995 through the 2015 seasons before relocating back to Los Angeles where the team had played from the 1946 season to the 1994 season. The Rams franchise relocated from Los Angeles to St. Louis in 1995, which had been without a National Football League (NFL) team since the Cardinals moved to Phoenix, Arizona in 1988. The Rams\u2019 first home game in St. Louis was at Busch Memorial Stadium against the</span>\n<span class=\"ltx_p\" id=\"A5.T13.pic1.1.1.1.1.1.4\">Document [3](Title: History of the St. Louis Rams): History of the St. Louis Rams The professional American football franchise now known as the Los Angeles Rams played in St. Louis, Missouri, as the St. Louis Rams from the 1995 through the 2015 seasons before relocating back to Los Angeles where the team had played from the 1946 season to the 1994 season. The Rams franchise relocated from Los Angeles to St. Louis in 1995, which had been without a National Football League (NFL) team since the Cardinals moved to Phoenix, Arizona in 1988. The Rams\u2019 first home game in St. Louis was at Busch Memorial Stadium against the</span>\n<span class=\"ltx_p\" id=\"A5.T13.pic1.1.1.1.1.1.5\">Document [4](Title: Los Angeles Rams): in 1980. After the 1994 NFL season, the Rams left California and moved east to St. Louis, Missouri. Five seasons after relocating, the team won Super Bowl XXXIV in a 23\u201316 victory over the Tennessee Titans. They appeared again in Super Bowl XXXVI, where they lost 20\u201317 to the New England Patriots. The Rams continued to play in Edward Jones Dome in St. Louis until the end of the 2015 NFL season, when the team filed notice with the NFL of its intent to pursue a relocation back to Los Angeles. The move was approved by a 30\u20132 margin at</span>\n<span class=\"ltx_p\" id=\"A5.T13.pic1.1.1.1.1.1.6\">Document [5](Title: 1994 Los Angeles Rams season): 1994 Los Angeles Rams season The 1994 Los Angeles Rams season was the franchise\u2019s 57th year with the National Football League and the 49th and last season in the Greater Los Angeles Area until their 2016 relocation back to Los Angeles. After nearly 50 years in the Greater Los Angeles Area, owner Georgia Frontiere announced that the team would relocate to St. Louis, Missouri on January 15, 1995. While the owners initially rejected the move, permission was eventually granted therefore bringing an end to Southern California\u2019s first major professional sports franchise until 2016. The threat of relocation dominated talk about</span>\n</span></foreignobject></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 13.78)\"><foreignobject color=\"#000000\" height=\"47.05\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A5.T13.pic1.2.2.2.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A5.T13.pic1.2.2.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T13.pic1.2.2.2.1.1.1.1\">Output</span></span>\n<span class=\"ltx_p\" id=\"A5.T13.pic1.2.2.2.1.1.2\">\u2026Their first home game in St. Louis was at Busch Memorial Stadium against the Chicago Bears on October 22,1996 [1]\u2026.</span>\n</span></foreignobject></g></g></svg>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 13: </span>Sample containing fabrication error. In this sample, <span class=\"ltx_text ltx_font_bold\" id=\"A5.T13.2.1\">Chicago Bears</span> does not appear in the reference documents.</figcaption>\n</figure>",
            "capture": "Table 13: Sample containing fabrication error. In this sample, Chicago Bears does not appear in the reference documents."
        },
        "14": {
            "table_html": "<figure class=\"ltx_table\" id=\"A5.T14\"><svg class=\"ltx_picture\" height=\"758.1\" id=\"A5.T14.pic1\" overflow=\"visible\" version=\"1.1\" width=\"600\"><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" transform=\"translate(0,758.1) matrix(1 0 0 -1 0 0)\"><g fill=\"#404040\" fill-opacity=\"1.0\"><path d=\"M 0 5.91 L 0 752.19 C 0 755.45 2.64 758.1 5.91 758.1 L 594.09 758.1 C 597.36 758.1 600 755.45 600 752.19 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z\" style=\"stroke:none\"></path></g><g fill=\"#F2F2F2\" fill-opacity=\"1.0\"><path d=\"M 1.97 5.91 L 1.97 752.19 C 1.97 754.37 3.73 756.13 5.91 756.13 L 594.09 756.13 C 596.27 756.13 598.03 754.37 598.03 752.19 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z\" style=\"stroke:none\"></path></g><g color=\"#404040\" fill=\"#404040\" stroke=\"#404040\" stroke-dasharray=\"2.84528pt,2.84528pt\" stroke-dashoffset=\"1.42264pt\" stroke-opacity=\"1.0\"><path d=\"M 1.97 72.64 L 598.03 72.64\" style=\"fill:none\"></path></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 84.45)\"><foreignobject color=\"#000000\" height=\"659.87\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A5.T14.pic1.1.1.1.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A5.T14.pic1.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T14.pic1.1.1.1.1.1.1.1\">Question\n<br class=\"ltx_break\"/></span>Who performed at the champions league final 2018?</span>\n<span class=\"ltx_p\" id=\"A5.T14.pic1.1.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T14.pic1.1.1.1.1.1.2.1\">Documents\n<br class=\"ltx_break\"/></span>Document [1](Title: 2016 UEFA Champions League Final): worldwide via UEFA.com from 1 to 14 March 2016 in four price categories: \u20ac440, \u20ac320, \u20ac160 and \u20ac70. The remaining tickets were allocated to the local organising committee, UEFA and national associations, commercial partners and broadcasters, and to serve the corporate hospitality programme. American singer Alicia Keys performed in the opening ceremony prior to the match, the first time it has featured a live music performance. Italian tenor Andrea Bocelli performed the UEFA Champions League Anthem. The 2016 UEFA Women\u2019s Champions League Final was held two days prior, on 26 May 2016, at the Mapei Stadium \u2013 Citt\u00e0 del Tricolore</span>\n<span class=\"ltx_p\" id=\"A5.T14.pic1.1.1.1.1.1.3\">Document [2](Title: 2018 UEFA Champions League Final): Lipa performed at the opening ceremony preceding the final. Jamaican rapper Sean Paul joined her as a special guest to perform their collaborative song, N\u0308o Lie.\u0308 The 2018 UEFA Women\u2019s Champions League Final was held two days earlier, on 24 May 2018, at the Valeriy Lobanovskyi Dynamo Stadium between Wolfsburg and Lyon, Lyon emerging victorious 4\u20131. This was also the last time that the host city for the men\u2019s Champions League final was also automatically assigned the Women\u2019s Champions League final. The annual UEFA Champions Festival was held between 24\u201327 May 2018 at the Kiev city centre. In late May,</span>\n<span class=\"ltx_p\" id=\"A5.T14.pic1.1.1.1.1.1.4\">Document [3](Title: UEFA Champions League Anthem): the two teams are lined up, as well as at the beginning and end of television broadcasts of the matches. Special vocal versions have been performed live at the Champions League Final with lyrics in other languages, changing over to the host country\u2019s language for the chorus. These versions were performed by Andrea Bocelli (Italian) (Rome 2009, Milan 2016 and Cardiff 2017), Juan Diego Flores (Spanish) (Madrid 2010), All Angels (Wembley 2011), Jonas Kaufmann and David Garrett (Munich 2012), Mariza (Lisbon 2014, unlike the previous final performers, Mariza sang the main lyric of the anthem), and Nina Maria Fischer and</span>\n<span class=\"ltx_p\" id=\"A5.T14.pic1.1.1.1.1.1.5\">Document [4](Title: 2018 UEFA Champions League Final): 2018 UEFA Champions League Final The 2018 UEFA Champions League Final was the final match of the 2017\u201318 UEFA Champions League, the 63rd season of Europe\u2019s premier club football tournament organised by UEFA, and the 26th season since it was renamed from the European Cup to the UEFA Champions League. It was played at the NSC Olimpiyskiy Stadium in Kiev, Ukraine on 26 May 2018, between Spanish side and defending champions Real Madrid, who had won the competition in each of the last two seasons, and English side Liverpool. Real Madrid won the final 3\u20131 for their third consecutive and</span>\n<span class=\"ltx_p\" id=\"A5.T14.pic1.1.1.1.1.1.6\">Document [5](Title: 2017 UEFA Champions League Final): 2017 UEFA Champions League Final The 2017 UEFA Champions League Final was the final match of the 2016\u201317 UEFA Champions League, the 62nd season of Europe\u2019s premier club football tournament organised by UEFA, and the 25th season since it was renamed from the European Champion Clubs\u2019 Cup to the UEFA Champions League. It was played at the Millennium Stadium in Cardiff, Wales on 3 June 2017, between Italian side Juventus and Spanish side and title holders Real Madrid, in a repeat of the 1998 final. Real Madrid won the match 4\u20131 to secure their 12th title in this competition. With</span>\n</span></foreignobject></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 13.78)\"><foreignobject color=\"#000000\" height=\"47.05\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A5.T14.pic1.2.2.2.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A5.T14.pic1.2.2.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T14.pic1.2.2.2.1.1.1.1\">Output</span></span>\n<span class=\"ltx_p\" id=\"A5.T14.pic1.2.2.2.1.1.2\">\u2026Real Madrid won the final 3-1 for their third consecutive and overall 12th title in this competition[4]\u2026</span>\n</span></foreignobject></g></g></svg>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 14: </span>Sample containing synthesis error. In this sample, document 4 and document 5 are mistakenly intermingled.</figcaption>\n</figure>",
            "capture": "Table 14: Sample containing synthesis error. In this sample, document 4 and document 5 are mistakenly intermingled."
        },
        "15": {
            "table_html": "<figure class=\"ltx_table\" id=\"A5.T15\"><svg class=\"ltx_picture\" height=\"805.22\" id=\"A5.T15.pic1\" overflow=\"visible\" version=\"1.1\" width=\"600\"><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" transform=\"translate(0,805.22) matrix(1 0 0 -1 0 0)\"><g fill=\"#404040\" fill-opacity=\"1.0\"><path d=\"M 0 5.91 L 0 799.32 C 0 802.58 2.64 805.22 5.91 805.22 L 594.09 805.22 C 597.36 805.22 600 802.58 600 799.32 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z\" style=\"stroke:none\"></path></g><g fill=\"#F2F2F2\" fill-opacity=\"1.0\"><path d=\"M 1.97 5.91 L 1.97 799.32 C 1.97 801.49 3.73 803.25 5.91 803.25 L 594.09 803.25 C 596.27 803.25 598.03 801.49 598.03 799.32 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z\" style=\"stroke:none\"></path></g><g color=\"#404040\" fill=\"#404040\" stroke=\"#404040\" stroke-dasharray=\"2.84528pt,2.84528pt\" stroke-dashoffset=\"1.42264pt\" stroke-opacity=\"1.0\"><path d=\"M 1.97 89.24 L 598.03 89.24\" style=\"fill:none\"></path></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 101.05)\"><foreignobject color=\"#000000\" height=\"690.39\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A5.T15.pic1.1.1.1.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A5.T15.pic1.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T15.pic1.1.1.1.1.1.1.1\">Question\n<br class=\"ltx_break\"/></span>When was the 13th amendment ratified by the states?</span>\n<span class=\"ltx_p\" id=\"A5.T15.pic1.1.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T15.pic1.1.1.1.1.1.2.1\">Documents\n<br class=\"ltx_break\"/></span>Document [1](Title: Thirteenth Amendment to the United States Constitution): ratification did not imply federal power to legislate on the status of former slaves. During the first week of December, North Carolina and Georgia gave the amendment the final votes needed for it to become part of the Constitution. The Thirteenth Amendment became part of the Constitution on December 6, 1865, based on the following ratifications: Having been ratified by the legislatures of three-fourths of the several states (27 of the 36 states, including those that had been \u00efn rebellion)\u0308, Secretary of State Seward, on December 18, 1865, certified that the Thirteenth Amendment had become valid, to all intents and</span>\n<span class=\"ltx_p\" id=\"A5.T15.pic1.1.1.1.1.1.3\">Document [2](Title: Thirteenth Amendment to the United States Constitution): Thirteenth Amendment to the United States Constitution The Thirteenth Amendment (Amendment XIII) to the United States Constitution abolished slavery and involuntary servitude, except as punishment for a crime. In Congress, it was passed by the Senate on April 8, 1864, and by the House on January 31, 1865. The amendment was ratified by the required number of states on December 6, 1865. On December 18, 1865, Secretary of State William H. Seward proclaimed its adoption. It was the first of the three Reconstruction Amendments adopted following the American Civil War. Since the American Revolution, states had divided into states that</span>\n<span class=\"ltx_p\" id=\"A5.T15.pic1.1.1.1.1.1.4\">Document [3](Title: Emancipation Proclamation): Winning re-election, Lincoln pressed the lame duck 38th Congress to pass the proposed amendment immediately rather than wait for the incoming 39th Congress to convene. In January 1865, Congress sent to the state legislatures for ratification what became the Thirteenth Amendment, banning slavery in all U.S. states and territories. The amendment was ratified by the legislatures of enough states by December 6, 1865, and proclaimed 12 days later. There were about 40,000 slaves in Kentucky and 1,000 in Delaware who were liberated then. As the years went on and American life continued to be deeply unfair towards blacks, cynicism towards</span>\n<span class=\"ltx_p\" id=\"A5.T15.pic1.1.1.1.1.1.5\">Document [4](Title: Thirteenth Amendment to the United States Constitution): Enforcement, and Contemporary Implications Thirteenth Amendment to the United States Constitution The Thirteenth Amendment (Amendment XIII) to the United States Constitution abolished slavery and involuntary servitude, except as punishment for a crime. In Congress, it was passed by the Senate on April 8, 1864, and by the House on January 31, 1865. The amendment was ratified by the required number of states on December 6, 1865. On December 18, 1865, Secretary of State William H. Seward proclaimed its adoption. It was the first of the three Reconstruction Amendments adopted following the American Civil War. Since the American Revolution, states had</span>\n<span class=\"ltx_p\" id=\"A5.T15.pic1.1.1.1.1.1.6\">Document [5](Title: Thirteenth Amendment to the United States Constitution): joint resolution was sent to Lincoln for his signature. Under the usual signatures of the Speaker of the House and the President of the Senate, President Lincoln wrote the word \u00c4pproved\u00e4nd added his signature to the joint resolution on February 1, 1865. On February 7, Congress passed a resolution affirming that the Presidential signature was unnecessary. The Thirteenth Amendment is the only ratified amendment signed by a President, although James Buchanan had signed the Corwin Amendment that the 36th Congress had adopted and sent to the states in March 1861. When the Thirteenth Amendment was submitted to the states</span>\n</span></foreignobject></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 13.78)\"><foreignobject color=\"#000000\" height=\"63.65\" overflow=\"visible\" transform=\"matrix(1 0 0 -1 0 16.6)\" width=\"556.69\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" id=\"A5.T15.pic1.2.2.2.1.1\" style=\"width:402.3pt;\">\n<span class=\"ltx_p\" id=\"A5.T15.pic1.2.2.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A5.T15.pic1.2.2.2.1.1.1.1\">Output</span></span>\n<span class=\"ltx_p\" id=\"A5.T15.pic1.2.2.2.1.1.2\">\u2026The amendment was ratified by the required number of states on December 6,1865, and President Lincoln signed the joint resolution on February 1,1865, after it was passed by Congress on February 7,1865 [5]\u2026</span>\n</span></foreignobject></g></g></svg>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 15: </span>Sample containing omission error. In this sample, document 4 is not attributed.</figcaption>\n</figure>",
            "capture": "Table 15: Sample containing omission error. In this sample, document 4 is not attributed."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.18381v1_figure_1.png",
            "caption": "Figure 1: A brief overview of our APO framework. We show APO in more detail in Figure 2."
        },
        "2": {
            "figure_path": "2403.18381v1_figure_2.png",
            "caption": "Figure 2: \nThe overall framework of the APO."
        }
    },
    "references": [
        {
            "1": {
                "title": "Direct preference-based policy optimization without reward modeling.",
                "author": "Gaon An, Junhyeok Lee, Xingdong Zuo, Norio Kosaka, Kyung-Min Kim, and Hyun Oh Song. 2023.",
                "venue": "In Neural Information Processing Systems.",
                "url": null
            }
        },
        {
            "2": {
                "title": "Gemini: A family of highly capable multimodal models.",
                "author": "Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M. Dai, Anja Hauth, Katie Millican, David Silver, Slav Petrov, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser, Amelia Glaese, Jilin Chen, Emily Pitler, Timothy P. Lillicrap, Angeliki Lazaridou, Orhan Firat, James Molloy, Michael Isard, Paul Ronald Barham, Tom Hennigan, Benjamin Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, Ryan Doherty, Eli Collins, Clemens Meyer, Eliza Rutherford, Erica Moreira, Kareem Ayoub, Megha Goel, George Tucker, Enrique Piqueras, Maxim Krikun, Iain Barr, Nikolay Savinov, Ivo Danihelka, Becca Roelofs, Ana\u00efs White, Anders Andreassen, Tamara von Glehn, Lakshman Yagati, Mehran Kazemi, Lucas Gonzalez, Misha Khalman, Jakub Sygnowski, and et al. 2023.",
                "venue": "ArXiv preprint, abs/2312.11805.",
                "url": "https://arxiv.org/abs/2312.11805"
            }
        },
        {
            "3": {
                "title": "Retrieval-based language models and applications.",
                "author": "Akari Asai, Sewon Min, Zexuan Zhong, and Danqi Chen. 2023a.",
                "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts, ACL 2023, Toronto, Canada, July 9-14, 2023, pages 41\u201346.",
                "url": "https://doi.org/10.18653/V1/2023.ACL-TUTORIALS.6"
            }
        },
        {
            "4": {
                "title": "Self-rag: Learning to retrieve, generate, and critique through self-reflection.",
                "author": "Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. 2023b.",
                "venue": "ArXiv preprint, abs/2310.11511.",
                "url": "https://arxiv.org/abs/2310.11511"
            }
        },
        {
            "5": {
                "title": "A general theoretical paradigm to understand learning from human preferences.",
                "author": "Mohammad Gheshlaghi Azar, Mark Rowland, Bilal Piot, Daniel Guo, Daniele Calandriello, Michal Valko, and R\u00e9mi Munos. 2023.",
                "venue": "ArXiv preprint, abs/2310.12036.",
                "url": "https://arxiv.org/abs/2310.12036"
            }
        },
        {
            "6": {
                "title": "Training a helpful and harmless assistant with reinforcement learning from human feedback.",
                "author": "Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom B. Brown, Jack Clark, Sam McCandlish, Chris Olah, Benjamin Mann, and Jared Kaplan. 2022.",
                "venue": "ArXiv preprint, abs/2204.05862.",
                "url": "https://arxiv.org/abs/2204.05862"
            }
        },
        {
            "7": {
                "title": "Attributed question answering: Evaluation and modeling for attributed large language models.",
                "author": "Bernd Bohnet, Vinh Q. Tran, Pat Verga, Roee Aharoni, Daniel Andor, Livio Baldini Soares, Jacob Eisenstein, Kuzman Ganchev, Jonathan Herzig, Kai Hui, Tom Kwiatkowski, Ji Ma, Jianmo Ni, Tal Schuster, William W. Cohen, Michael Collins, Dipanjan Das, Donald Metzler, Slav Petrov, and Kellie Webster. 2022.",
                "venue": "ArXiv preprint, abs/2212.08037.",
                "url": "https://arxiv.org/abs/2212.08037"
            }
        },
        {
            "8": {
                "title": "Rank analysis of incomplete block designs: I. the method of paired comparisons.",
                "author": "Ralph Allan Bradley and Milton E Terry. 1952.",
                "venue": "Biometrika, 39(3/4):324\u2013345.",
                "url": null
            }
        },
        {
            "9": {
                "title": "Evidence of complex citer motivations.",
                "author": "Terrence A Brooks. 1986.",
                "venue": "Journal of the American Society for Information Science, 37(1):34\u201336.",
                "url": null
            }
        },
        {
            "10": {
                "title": "Language models are few-shot learners.",
                "author": "Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020.",
                "venue": "In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.",
                "url": "https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html"
            }
        },
        {
            "11": {
                "title": "Deep reinforcement learning from human preferences.",
                "author": "Paul F. Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, and Dario Amodei. 2017.",
                "venue": "In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pages 4299\u20134307.",
                "url": "https://proceedings.neurips.cc/paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html"
            }
        },
        {
            "12": {
                "title": "A survey for in-context learning.",
                "author": "Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. 2023.",
                "venue": "ArXiv preprint, abs/2301.00234.",
                "url": "https://arxiv.org/abs/2301.00234"
            }
        },
        {
            "13": {
                "title": "ELI5: Long form question answering.",
                "author": "Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli. 2019.",
                "venue": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3558\u20133567.",
                "url": "https://doi.org/10.18653/v1/P19-1346"
            }
        },
        {
            "14": {
                "title": "RARR: researching and revising what language models say, using language models.",
                "author": "Luyu Gao, Zhuyun Dai, Panupong Pasupat, Anthony Chen, Arun Tejasvi Chaganty, Yicheng Fan, Vincent Y. Zhao, Ni Lao, Hongrae Lee, Da-Cheng Juan, and Kelvin Guu. 2023a.",
                "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 16477\u201316508.",
                "url": "https://doi.org/10.18653/V1/2023.ACL-LONG.910"
            }
        },
        {
            "15": {
                "title": "Enabling large language models to generate text with citations.",
                "author": "Tianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen. 2023b.",
                "venue": "In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pages 6465\u20136488.",
                "url": "https://aclanthology.org/2023.emnlp-main.398"
            }
        },
        {
            "16": {
                "title": "Retrieval-augmented generation for large language models: A survey.",
                "author": "Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang. 2023c.",
                "venue": "ArXiv preprint, abs/2312.10997.",
                "url": "https://arxiv.org/abs/2312.10997"
            }
        },
        {
            "17": {
                "title": "Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies.",
                "author": "Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021.",
                "venue": "Transactions of the Association for Computational Linguistics, 9:346\u2013361.",
                "url": "https://doi.org/10.1162/tacl_a_00370"
            }
        },
        {
            "18": {
                "title": "TRUE: Re-evaluating factual consistency evaluation.",
                "author": "Or Honovich, Roee Aharoni, Jonathan Herzig, Hagai Taitelbaum, Doron Kukliansy, Vered Cohen, Thomas Scialom, Idan Szpektor, Avinatan Hassidim, and Yossi Matias. 2022.",
                "venue": "In Proceedings of the Second DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering, pages 161\u2013175.",
                "url": "https://doi.org/10.18653/v1/2022.dialdoc-1.19"
            }
        },
        {
            "19": {
                "title": "LCSTS: A large scale chinese short text summarization dataset.",
                "author": "Baotian Hu, Qingcai Chen, and Fangze Zhu. 2015.",
                "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015, pages 1967\u20131972. The Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/V1/D15-1229"
            }
        },
        {
            "20": {
                "title": "Lora: Low-rank adaptation of large language models.",
                "author": "Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022.",
                "venue": "In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022.",
                "url": "https://openreview.net/forum?id=nZeVKeeFYf9"
            }
        },
        {
            "21": {
                "title": "HAGRID: A human-llm collaborative dataset for generative information-seeking with attribution.",
                "author": "Ehsan Kamalloo, Aref Jafari, Xinyu Zhang, Nandan Thakur, and Jimmy Lin. 2023.",
                "venue": "ArXiv preprint, abs/2307.16883.",
                "url": "https://arxiv.org/abs/2307.16883"
            }
        },
        {
            "22": {
                "title": "Beyond reward: Offline preference-guided policy optimization.",
                "author": "Yachen Kang, Diyuan Shi, Jinxin Liu, Li He, and Donglin Wang. 2023.",
                "venue": "In International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA, volume 202 of Proceedings of Machine Learning Research, pages 15753\u201315768.",
                "url": "https://proceedings.mlr.press/v202/kang23b.html"
            }
        },
        {
            "23": {
                "title": "Human-centered loss functions (halos).",
                "author": "Ethayarajh Kawin, Xu Winnie, Jurafsky Dan, and Kiela Douwe. 2023.",
                "venue": "Technical report, Contextual AI.",
                "url": "https://github.com/ContextualAI/HALOs/blob/main/assets/report.pdf"
            }
        },
        {
            "24": {
                "title": "A survey of large language models attribution.",
                "author": "Dongfang Li, Zetian Sun, Xinshuo Hu, Zhenyu Liu, Ziyang Chen, Baotian Hu, Aiguo Wu, and Min Zhang. 2023a.",
                "venue": "ArXiv preprint, abs/2311.03731.",
                "url": "https://arxiv.org/abs/2311.03731"
            }
        },
        {
            "25": {
                "title": "Llatrieval: Llm-verified retrieval for verifiable generation.",
                "author": "Xiaonan Li, Changtai Zhu, Linyang Li, Zhangyue Yin, Tianxiang Sun, and Xipeng Qiu. 2023b.",
                "venue": "ArXiv preprint, abs/2311.07838.",
                "url": "https://arxiv.org/abs/2311.07838"
            }
        },
        {
            "26": {
                "title": "Towards verifiable generation: A benchmark for knowledge-aware language model attribution.",
                "author": "Xinze Li, Yixin Cao, Liangming Pan, Yubo Ma, and Aixin Sun. 2023c.",
                "venue": null,
                "url": "http://arxiv.org/abs/2310.05634"
            }
        },
        {
            "27": {
                "title": "Let\u2019s verify step by step.",
                "author": "Hunter Lightman, Vineet Kosaraju, Yura Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. 2023.",
                "venue": "ArXiv preprint, abs/2305.20050.",
                "url": "https://arxiv.org/abs/2305.20050"
            }
        },
        {
            "28": {
                "title": "Evaluating verifiability in generative search engines.",
                "author": "Nelson F. Liu, Tianyi Zhang, and Percy Liang. 2023.",
                "venue": "In Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023, pages 7001\u20137025.",
                "url": "https://aclanthology.org/2023.findings-emnlp.467"
            }
        },
        {
            "29": {
                "title": "Expertqa: Expert-curated questions and attributed answers.",
                "author": "Chaitanya Malaviya, Subin Lee, Sihao Chen, Elizabeth Sieber, Mark Yatskar, and Dan Roth. 2023.",
                "venue": "ArXiv preprint, abs/2309.07852.",
                "url": "https://arxiv.org/abs/2309.07852"
            }
        },
        {
            "30": {
                "title": "Chatgpt: Optimizing language models for dialogue.",
                "author": "OpenAI. 2022.",
                "venue": null,
                "url": null
            }
        },
        {
            "31": {
                "title": "Training language models to follow instructions with human feedback.",
                "author": "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022.",
                "venue": "In Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022.",
                "url": "http://papers.nips.cc/paper_files/paper/2022/hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html"
            }
        },
        {
            "32": {
                "title": "Direct preference optimization: Your language model is secretly a reward model.",
                "author": "Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn. 2023.",
                "venue": "ArXiv preprint, abs/2305.18290.",
                "url": "https://arxiv.org/abs/2305.18290"
            }
        },
        {
            "33": {
                "title": "Measuring attribution in natural language generation models.",
                "author": "Hannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Michael Collins, Dipanjan Das, Slav Petrov, Gaurav Singh Tomar, Iulia Turc, and David Reitter. 2021.",
                "venue": "ArXiv preprint, abs/2112.12870.",
                "url": "https://arxiv.org/abs/2112.12870"
            }
        },
        {
            "34": {
                "title": "Experience replay for continual learning.",
                "author": "David Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy P. Lillicrap, and Gregory Wayne. 2019.",
                "venue": "In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 348\u2013358.",
                "url": "https://proceedings.neurips.cc/paper/2019/hash/fa7cdfad1a5aaf8370ebeda47a1ff1c3-Abstract.html"
            }
        },
        {
            "35": {
                "title": "Proximal policy optimization algorithms.",
                "author": "John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. 2017.",
                "venue": "ArXiv preprint, abs/1707.06347.",
                "url": "https://arxiv.org/abs/1707.06347"
            }
        },
        {
            "36": {
                "title": "Retrieval augmentation reduces hallucination in conversation.",
                "author": "Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. 2021.",
                "venue": "In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3784\u20133803.",
                "url": "https://doi.org/10.18653/v1/2021.findings-emnlp.320"
            }
        },
        {
            "37": {
                "title": "ASQA: Factoid questions meet long-form answers.",
                "author": "Ivan Stelmakh, Yi Luan, Bhuwan Dhingra, and Ming-Wei Chang. 2022.",
                "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 8273\u20138288.",
                "url": "https://aclanthology.org/2022.emnlp-main.566"
            }
        },
        {
            "38": {
                "title": "Learning to summarize with human feedback.",
                "author": "Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel M. Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul F. Christiano. 2020.",
                "venue": "In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.",
                "url": "https://proceedings.neurips.cc/paper/2020/hash/1f89885d556929e98d3ef9b86448f951-Abstract.html"
            }
        },
        {
            "39": {
                "title": "Towards verifiable text generation with evolving memory and self-reflection.",
                "author": "Hao Sun, Hengyi Cai, Bo Wang, Yingyan Hou, Xiaochi Wei, Shuaiqiang Wang, Yan Zhang, and Dawei Yin. 2023.",
                "venue": "ArXiv preprint, abs/2312.09075.",
                "url": "https://arxiv.org/abs/2312.09075"
            }
        },
        {
            "40": {
                "title": "How status of research papers affects the way they are read and cited.",
                "author": "Misha Teplitskiy, Eamon Duede, Michael Menietti, and Karim R Lakhani. 2022.",
                "venue": "Research Policy, 51(4):104484.",
                "url": null
            }
        },
        {
            "41": {
                "title": "Llama 2: Open foundation and fine-tuned chat models.",
                "author": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aur\u00e9lien Rodriguez, Robert Stojnic, Sergey Edunov,\nand Thomas Scialom. 2023.",
                "venue": "ArXiv preprint, abs/2307.09288.",
                "url": "https://arxiv.org/abs/2307.09288"
            }
        },
        {
            "42": {
                "title": "Self-instruct: Aligning language models with self-generated instructions.",
                "author": "Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023.",
                "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 13484\u201313508.",
                "url": "https://doi.org/10.18653/V1/2023.ACL-LONG.754"
            }
        },
        {
            "43": {
                "title": "Emergent abilities of large language models.",
                "author": "Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022.",
                "venue": "Trans. Mach. Learn. Res., 2022.",
                "url": null
            }
        },
        {
            "44": {
                "title": "Neural text generation with unlikelihood training.",
                "author": "Sean Welleck, Ilia Kulikov, Stephen Roller, Emily Dinan, Kyunghyun Cho, and Jason Weston. 2020.",
                "venue": "In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020.",
                "url": "https://openreview.net/forum?id=SJeYe0NtvH"
            }
        },
        {
            "45": {
                "title": "Search-in-the-chain: Towards the accurate, credible and traceable content generation for complex knowledge-intensive tasks.",
                "author": "Shicheng Xu, Liang Pang, Huawei Shen, Xueqi Cheng, and Tat-Seng Chua. 2023.",
                "venue": "ArXiv preprint, abs/2304.14732.",
                "url": "https://arxiv.org/abs/2304.14732"
            }
        },
        {
            "46": {
                "title": "Cognitive mirage: A review of hallucinations in large language models.",
                "author": "Hongbin Ye, Tong Liu, Aijia Zhang, Wei Hua, and Weiqiang Jia. 2023a.",
                "venue": "ArXiv preprint, abs/2309.06794.",
                "url": "https://arxiv.org/abs/2309.06794"
            }
        },
        {
            "47": {
                "title": "Effective large language model adaptation for improved grounding.",
                "author": "Xi Ye, Ruoxi Sun, Sercan \u00d6 Arik, and Tomas Pfister. 2023b.",
                "venue": "ArXiv preprint, abs/2311.09533.",
                "url": "https://arxiv.org/abs/2311.09533"
            }
        },
        {
            "48": {
                "title": "Automatic evaluation of attribution by large language models.",
                "author": "Xiang Yue, Boshi Wang, Kai Zhang, Ziru Chen, Yu Su, and Huan Sun. 2023.",
                "venue": "ArXiv preprint, abs/2305.06311.",
                "url": "https://arxiv.org/abs/2305.06311"
            }
        },
        {
            "49": {
                "title": "Siren\u2019s song in the ai ocean: A survey on hallucination in large language models.",
                "author": "Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei Bi, Freda Shi, and Shuming Shi. 2023.",
                "venue": "ArXiv preprint, abs/2309.01219.",
                "url": "https://arxiv.org/abs/2309.01219"
            }
        },
        {
            "50": {
                "title": "Slic-hf: Sequence likelihood calibration with human feedback.",
                "author": "Yao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J. Liu. 2023.",
                "venue": "ArXiv preprint, abs/2305.10425.",
                "url": "https://arxiv.org/abs/2305.10425"
            }
        },
        {
            "51": {
                "title": "Secrets of RLHF in large language models part I: PPO.",
                "author": "Rui Zheng, Shihan Dou, Songyang Gao, Yuan Hua, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin Liu, Yuhao Zhou, Limao Xiong, Lu Chen, Zhiheng Xi, Nuo Xu, Wenbin Lai, Minghao Zhu, Cheng Chang, Zhangyue Yin, Rongxiang Weng, Wensen Cheng, Haoran Huang, Tianxiang Sun, Hang Yan, Tao Gui, Qi Zhang, Xipeng Qiu, and Xuanjing Huang. 2023.",
                "venue": "ArXiv preprint, abs/2307.04964.",
                "url": "https://arxiv.org/abs/2307.04964"
            }
        },
        {
            "52": {
                "title": "Fine-tuning language models from human preferences.",
                "author": "Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul F. Christiano, and Geoffrey Irving. 2019.",
                "venue": "ArXiv preprint, abs/1909.08593.",
                "url": "https://arxiv.org/abs/1909.08593"
            }
        },
        {
            "53": {
                "title": "Chatgpt hallucinates when attributing answers.",
                "author": "Guido Zuccon, Bevan Koopman, and Razia Shaik. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2309.09401"
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.18381v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.1",
            "2.2"
        ],
        "methodology_sections": [
            "4",
            "4.1",
            "4.2",
            "4.3",
            "4.4",
            "4.5"
        ],
        "main_experiment_and_results_sections": [
            "5",
            "5.1",
            "5.2",
            "5.3",
            "6",
            "6.1",
            "6.2",
            "6.3",
            "6.4",
            "6.5"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "6.2",
            "6.3",
            "6.4"
        ]
    },
    "research_context": {
        "paper_id": "2403.18381v1",
        "paper_title": "Improving Attributed Text Generation of Large Language Models via Preference Learning",
        "research_background": "The paper is motivated by the widespread adoption of large language models (LLMs) in various natural language processing (NLP) applications despite their tendency to produce hallucinations, which are plausible but nonfactual outputs. This issue significantly restricts the applicability of LLMs in real-world scenarios. To address this, previous research has focused on grounding the statements generated by LLMs in supported evidence, either by adding citations or rationales. Additionally, the use of external knowledge sources like retrieved documents and knowledge graphs has been explored for attribution purposes.\n\nThe research problem addressed in this paper centers around the improvement of attributed text generation in LLMs by mitigating hallucinations not just in the original text, but also in the attribution process itself. Existing methods primarily focus on retrieval and evaluation stages without optimizing the text generation process effectively. Moreover, fine-tuning methods such as supervised fine-tuning, unlikelihood training, or reinforcement learning with human feedback (RLHF-PPO) are often hampered by expensive data collection, reward model training, and sparsity of rewards, making them impractical for real-world applications.\n\nTo tackle these challenges, the authors propose a novel framework called Automatic Preference Optimization (APO). The framework builds on the conceptualization of the attribution task as a preference learning problem. The core of their approach involves creating a curated dataset for post-training to familiarize LLMs with attribution requirements and employing an automated technique to generate a large amount of attribution preference data. This bypasses the need for expensive and time-consuming annotation processes. Furthermore, the authors suggest a progressive preference optimization method with experience replay, which avoids the complexities associated with explicit reward modeling and reinforcement learning.\n\nRelevant prior work includes:\n1. Emergent abilities of LLMs and their application in various NLP tasks (Brown et al., 2020; Wei et al., 2022; OpenAI, 2022; Anil et al., 2023).\n2. The problem of hallucinations in LLM outputs and efforts to mitigate them (Ye et al., 2023a; Zhang et al., 2023).\n3. Methods for grounding LLM outputs using external knowledge sources such as retrieved documents and knowledge graphs (Shuster et al., 2021; Li et al., 2023c). \n4. The limitations of current methods focusing on retrieval and evaluation stages without optimizing the generation stage (Ye et al., 2023b; Yue et al., 2023).\n5. Fine-tuning methods to improve LLM performance, which face challenges such as data collection costs and sparse rewards (Welleck et al., 2020; Ziegler et al., 2019; Azar et al., 2023).\n6. The inspiration from citation mechanisms in human scholarly writing and direct preference optimization (Brooks, 1986; Teplitskiy et al., 2022; Rafailov et al., 2023).\n\nThe authors believe their contributions represent the first application of preference learning in attribution tasks, offer a full data collection pipeline for attribution tasks, and propose a method that alleviates sparse reward problems, providing new insights and benchmarks for relevant future research.",
        "methodology": "### Methodology: Improving Attributed Text Generation of Large Language Models via Preference Learning\n\n#### Data Construction and Preprocessing\n\n1. **Data Sources**: The authors construct post-training data from training sets using high-quality attribution datasets, specifically:\n    - EVIGSE\n    - ExpertQA\n    - HARGID \n    \n   These datasets are selected because they come from diverse domains and sources and are annotated by human experts or powerful Large Language Models (LLMs).\n\n2. **Sample Preparation**: \n    - After preprocessing and formatting the data, a final post-training dataset containing 6,330 samples is created.\n    - Detailed preprocessing steps can be found in Appendices B and C.\n\n3. **Data Formats**:\n    - Instructions, documents, and questions are formatted as inputs.\n    - Answers composed of multiple statements are formatted as outputs.\n   \n#### Model Tuning and Initial Generator\n\n4. **Autoregressive Language Modeling**: \n    - The model is tuned using autoregressive language modeling objectives, yielding an initial generator.\n\n#### Relevant and Supported Text Generation\n\n5. **Relevance and Support Criteria**:\n    - Relevance: Measures whether the reference document in the answer is helpful in handling the question.\n    - Support: Determines whether all verification-worthy statements in the generated text are grounded in the reference documents.\n\n6. **Initial Responses and Labels**:\n    - Initial responses and related labels for each query are obtained using Algorithm 1.\n    - Queries come from open-domain tasks or high-quality instruction datasets, and the source of retrieved documents is English Wikipedia.\n\n7. **Retrieval Model**: \n    - The retriever used is `gtr-t5-large`.\n\n#### Critic Model and Feedback\n\n8. **Critic Model**:\n    - The critic model used is `selfrag_llama2_7b`, as it can provide fine-grained feedback using reflection tokens.\n\n#### Generating Preference Pairs\n\n9. **Automatic Collection Algorithm**:\n    - For each statement in a query, citations are checked for relevance.\n    - Relevant statements are added to a set for subsequent processing.\n    - For each entry in the set, additional top documents are retrieved and filtered.\n    - Positive and negative pairs are generated based on whether statements are fully supported by the documents.\n\n10. **Negative Sample Generation**:\n    - Includes specific error instructions:\n        - Irrelevant but Supported: Text grounded in unhelpful documents.\n        - Relevant but Unsupported: \n            - Fabricated Statement: Contains facts not derived from documents.\n            - Mistaken Synthesis: Misinterpreted facts from multiple documents.\n            - Unintentional Omission: Key points missing but no factual errors.\n\n#### Handling Errors\n\n11. **Error Types**:\n    - Attribution Hallucination: Errors where generated text is relevant but unsupported.\n    - Generation Hallucination: Errors where text contains false or misinterpreted information.\n\n#### Progressive Preference Optimization\n\n12. **Reward Optimization**:\n    - Conventional preference optimization may overlook fine-grained deterministic preferences due to a global context evaluation.\n    - The proposed solution: Statement-level fine-grained reward preferences to update the model more effectively and efficiently.\n\n13. **Experience Replay for Overfitting**:\n    - To address overfitting, the method incorporates experience replay, adding old training samples in iterations to the preference optimization process.\n\n14. **Progressive vs. Vanilla Preference Optimization**:\n    - Progressive Preference Optimization includes mean pooling in the preference optimization loss.\n    - This method uses both statement-level and response-level rewards, combined with experience replay, to yield the final generator.\n\nIn sum, the methodology involves constructing high-quality datasets, fine-tuning the model with autoregressive objectives, defining relevance and support criteria, generating preference pairs, and employing a progressive preference optimization method combined with experience replay to enhance the attributed text generation capabilities of large language models.",
        "main_experiment_and_results": "### Main Experiment Setup\n\n- **Datasets:**\n  - **ASQA dataset:** Focuses on attributable long-form question-answering (QA) tasks.\n  - **ELI5 subsets:** Used for factoid long-form QA tasks.\n  - **StrategyQA dataset:** Focusing on open-domain QA with implicit reasoning steps.\n\n- **Evaluation Metrics:**\n  - **Attribution Evaluation:**\n    - **Citation Recall**\n    - **Citation Precision**\n    - **Citation F1**\n    These metrics use the TRUE model (Honovich et al., 2022) to verify if the cited documents support the model's generated content.\n  - **ASQA Dataset:**\n    - **Recall of Correct Short Answers (EM-R):** Measures if the short answers provided by the dataset are found as exact substrings in the generated answers.\n  - **ELI5 Dataset:**\n    - **Claim Recall (Claim):** Checks if the model output supports the sub-claims generated by text-davinci-003 (Ouyang et al., 2022).\n  - **StrategyQA Dataset:**\n    - **Accuracy:** Measures overall task performance.\n\n### Main Experimental Results\n\n- **Attributable Long-Form QA Tasks (ASQA and ELI5 datasets):**\n  The results are primarily reported in terms of citation recall, precision, and F1 to assess the model's ability to generate text that is well-supported by cited documents. Additionally:\n  - **ASQA Dataset:** Recall of correct short answers (EM-R) is reported, indicating how accurately the generated answers contain the correct short answers as substrings.\n  - **ELI5 Dataset:** Claim recall is used to determine if the generated answers contain claims that entail the sub-claims provided by the benchmark text-davinci-003 model.\n\n- **StrategyQA Dataset:**\n  - The accuracy is reported to measure the generation quality for open-domain QA, where reasoning steps are not explicitly provided in the question. \n\nThe provided setup and results indicate a focus on evaluating both attributional integrity (linking generated text to reliable sources) and factual correctness in various QA scenarios."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To evaluate the effectiveness of each predefined error type in improving model performance, specifically groundedness and generation quality.",
            "experiment_process": "Progressive PO was performed on the model after post-training by removing data corresponding to a predefined error type. Experiments were conducted to measure the impact of the absence of data related to hallucinated statements, mistaken synthesis errors, and unintentional omission errors. Additionally, an ablation study on the training strategy of preference optimization was performed by removing ASQA questions from the preference data, ensuring that the test set of ASQA was used for evaluation to prevent data overlap.",
            "result_discussion": "The absence of hallucinated statement data significantly decreased citation F1, indicating groundedness improvement due to this data. Mistaken synthesis errors contributed little to automated performance improvements but enhanced groundedness under human evaluation. The lack of unintentional omission errors resulted in poor generation quality, suggesting the model may generate incomplete answers without this data. Furthermore, the study found that the preference optimization method improved the model, but less so than when including ASQA data, pointing to the importance of high-quality in-domain questions.",
            "ablation_id": "2403.18381v1.No1"
        },
        {
            "research_objective": "To explore the impact of different prompting strategies on the performance of the Automatic Preference Optimization framework.",
            "experiment_process": "Four prompting strategies (Vanilla, Summ, Snippet, and Oracle) were applied: Vanilla used the top-5 retrieved documents for each question; Summ used summaries of the top-10 retrieved documents; Snippet used snippets of the top-10 retrieved documents; Oracle used 5 gold documents for each question. Llama-2-13b-chat was used as the comparison method.",
            "result_discussion": "APO showed consistently better performance than the baseline across most cases. Specifically, APO under Vanilla and Oracle settings achieved the best Citation F1 on ASQA, while Summ and Snippet settings improved Citation F1 on ELI5, indicating that the format of the context significantly impacts the attribution task.",
            "ablation_id": "2403.18381v1.No2"
        },
        {
            "research_objective": "To analyze the impact of different direct preference optimization methods on model performance.",
            "experiment_process": "Various direct preference optimization methods were tested and compared to a SFT baseline which tuned the model using only the positive part of the chosen preference pairs. Performance was measured across several metrics to determine the effectiveness of different preference optimization methods.",
            "result_discussion": "All preference optimization methods outperformed the post-training and SFT baselines, indicating that preference optimization can enhance generation quality. However, performance varied across different metrics depending on the optimization method used.",
            "ablation_id": "2403.18381v1.No3"
        }
    ]
}