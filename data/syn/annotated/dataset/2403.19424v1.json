{
    "title": "The Role of Syntactic Span Preferences in Post-Hoc Explanation Disagreement",
    "abstract": "Post-hoc explanation methods are an important tool for increasing model transparency for users. Unfortunately, the currently used methods for attributing token importance often yield diverging patterns. In this work, we study potential sources of disagreement across methods from a linguistic perspective. We find that different methods systematically select different classes of words and that methods that agree most with other methods and with humans display similar linguistic preferences. Token-level differences between methods are smoothed out if we compare them on the syntactic span level. We also find higher agreement across methods by estimating the most important spans dynamically instead of relying on a fixed subset of size. We systematically investigate the interaction between and spans and propose an improved configuration for selecting important tokens.\n\nKeywords:\u2009interpretability, spans, agreement",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1.   Introduction",
            "text": "Transformer-based models learn to map features in the input to some output. When training an NLP system, the model learns to identify the most important features (in our case tokens) for the final prediction. Post-hoc explanation methods such as LIME (Ribeiro et al., 2016) and Integrated Gradient (Sundararajan et al., 2017) aim to attribute an importance score to the individual features to interpret the model\u2019s decisions. Generally, these methods tend to disagree with each other when ranking token importance on a set of top- tokens based on attribution scores (Neely et al., 2022). Given their disagreement, and assuming that explanations that are faithful to the transformer\u2019s inner mechanisms should be agreeable (Jain and Wallace, 2019), the faithfulness of these methods comes under question. However, methods might agree more than initially appears.\n\nFor example, Figure 1 shows that none of the methods selects the same top-4 tokens and that 12 of the 13 tokens appear in at least one top-4 selection, indicating a high variance across methods. Intuitively though, methods seem to target the verb phrases are standing and are unloading to a high degree as the vast majority highlights at least one of the tokens in each of these phrases. Similarly, some methods tend to agree on the noun phrases shipyard workers (first occurrence) and the ships, and even more so on different tokenised subwords of the same word, namely un and ##loading. This leads us to hypothesise that agreement between methods is systematically higher when we look at the linguistic spans they are targeting: the constituents to which tokens syntactically belong.\n\nThis example shows that a single method may have a specific preference for one word class over another, e.g. noun over adjective, auxiliary over inflected verb form or modifier over head. For example, Ramnath et al. (2020) report part-of-speech (POS) preference statistics for the different layers of BERT (Devlin et al., 2019) for the Integrated Gradient method. However, the extent to which preferences differ across methods remains unclear, as well as its impact on method\u2013method agreement.\n\nA methodological aspect that directly affects agreement is the selection of the top- most important tokens for each method to compare. This is a relatively under-explored parameter and is defined as the number of features that are assigned highest scores by the attribution method, relative to all the features in the input example. A common way of picking is by selecting a fixed number, generally in the range . Intuitively, a that is fixed across instances (e.g. 4) is suboptimal, and the selection process of is often overlooked (Jesus et al., 2021; Camburu et al., 2019) or obtained by an approximation (Krishna et al., 2022). As an alternative, can be estimated dynamically across instances (Pruthi et al., 2022; Kamp et al., 2023), but different conceptual settings for this approach and their effect on agreement have not been investigated yet.\n\nInstead of ranking tokens by attribution score and manually setting a , Kamp et al. (2023) propose to automatically detect tokens that are signal peaks in the input. Hypothesising that spans are better suited for agreement than tokens conceptually overlaps with this dynamic approach. Precisely, the latter suggests that solely focusing on token-level attribution scores, semi-arbitrary importance cut-offs and the consequent agreement measurements between tokens may be undesirable for interpreting model behaviour.\n\nIn this paper, we aim to disentangle the interdependencies between word class preference, span-level agreement, and the determination of . We show that methods systematically select different word classes and that methods that agree most with other methods and with humans exhibit similar word class preferences. We also find that dynamic and spans work well in combination, and that an adapted threshold for dynamically selecting the most important tokens passes our baseline tests for both token- and span-level estimation. Our main contributions are: i) a linguistic analysis of disagreement on the token-level and on the span-level and ii) an improvement to the dynamic estimation algorithm. All analyses are available at: https://github.com/jbkamp/repo-Span-Pref."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2.   Related Work",
            "text": "In this section, we place our work in the context of prior work on interpretability (\u00a72.1  ###reference_###), the patterns of linguistic information that attribution methods reveal (\u00a72.2  ###reference_###) and top- estimation (\u00a72.3  ###reference_###)."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1.   Model Interpretation",
            "text": "Tracing the decision processes in neural models poses difficulties due to various factors, including their non-linear nature and the absence of explicit human-defined rules to link patterns in the input features with output labels. Different research lines exist to interpret different aspects of the model (Choudhary et al., 2022  ###reference_b12###; R\u00e4uker et al., 2023  ###reference_b30###), such as the linguistic information that might implicitly be learned by the model, or the importance that single input features might have had towards the model\u2019s decision (Madsen et al., 2022  ###reference_b23###).\nTo address the latter, post-hoc attribution methods in NLP have been developed to assign a score to each token in the input, creating an attribution profile over the tokens. While these methods are often being used in error analyses (Bongard et al., 2022  ###reference_b8###, i.a.), their reliability is questionable. In fact, attribution profiles obtained from different methods can differ strongly even on the same input. This leads to an overall low inter-method agreement (Neely et al., 2022  ###reference_b25###), which has also been found for domains outside of NLP (Krishna et al., 2022  ###reference_b20###). Diverging experimental results of such methods on different models, datasets and tasks provide additional evidence on their inconsistency. For example, when trying to identify the attribution methods that best align with human preferences\u2013the most plausible (Jacovi and Goldberg, 2020  ###reference_b14###) methods\u2013, Atanasova et al. (2020  ###reference_b3###) and Attanasio et al. (2022  ###reference_b4###) come to fundamentally opposing conclusions. Roy et al. (2022  ###reference_b32###) characterise disagreement between methods in a software defect prediction task as being highest in terms of top- feature importance, followed by rank, then sign. Similarly to Pirie et al. (2023  ###reference_b26###), they propose aggregation schemes for different explanation methods that aim to tackle disagreement in real-world use cases.\nOne question that, to our knowledge, remains under-explored, is why attribution methods in NLP disagree. A key to answering this would be comparing methods on their faithfulness, i.e. the degree to which methods are reflecting the model\u2019s decision making process, as recent work (Atanasova et al., 2023  ###reference_b2###, i.a.) aims to assess. However, directly measuring faithfulness might only find glimpses of the model\u2019s inner workings rather than providing a conclusive answer (Jacovi and Goldberg, 2020  ###reference_b14###). Therefore, we think that the first step should be explaining disagreement by the observable output of the methods, i.e. the attribution profiles. We aim to provide a linguistic comparison by quantifying the kind of features that are targeted, expecting different methods to consistently target different classes of words."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2.   Linguistic Patterns in Attributions",
            "text": "Identifying the linguistic preferences of models is important in order to pinpoint the cues upon which models depend during inference time. Only a handful of studies have explored POS preference. Especially in a feature attribution setting, there is little evidence that shows certain preferences by different attribution methods and how these preferences differ. Lai et al. (2019  ###reference_b21###) find that different models (i.e. LSTM, XGBoost and SVM) have different POS preferences on the same data and task, but they do not explore preferences for different attribution methods. Ramnath et al. (2020  ###reference_b29###) examine the top-5 most important tokens in each layer and find that BERT (Devlin et al., 2019  ###reference_b13###) primarily focuses on nouns in all 12 layers, followed by verbs and adjectives. Interestingly, both punctuation tokens and stop words each correspond to 10% in the top-5 selections. However, only Integrated Gradient (Sundararajan et al., 2017  ###reference_b38###) was used in this experiment, limiting the generalisability of their findings. Our analyses differ from theirs in that we compare different methods and investigate the overlap between agreement and linguistic preference.\nLanguage (and model behavior) can often not be explained by merely highlighting individual tokens. Rather, we would ideally observe how features act in combination with each other and, for example, if they do so hierarchically. As an alternative way of analysing the attributions of tokens in isolation, we find a growing line of research on feature interactions. Jumelet and Zuidema (2023  ###reference_b17###) find evidence of attribution methods faithfully reflecting linguistic structure in language models. Sikdar et al. (2021  ###reference_b35###) combine token-wise attribution scores into scores assigned to syntactic parent constituents. Similarly, Babiker et al. (2023  ###reference_b6###) train a model on intermediate representations in a hierarchical fashion. Song et al. (2023  ###reference_b37###) aim to capture the causal effect of word group combinations on the prediction but limit their scope to the Integrated Gradient method. Pruthi et al. (2022  ###reference_b28###) anticipate that certain spans of tokens should be highlighted by attribution methods in a sentiment analysis task.\nWhile their intuition is on point, the relatively broad expectations found in the latter underscore the relevance of a clear definition of token spans and their role in demonstrating how neighboring features are grouped.\nAs far as we know, there is no prior work that covers a linguistic analysis of the token selections targeted by different attribution methods. To the best of our knowledge, we are also the first to investigate the relation between disagreement on the linguistic level to overall disagreement among methods. We provide a linguistic analysis in terms of individual tokens, and also in terms of spans that have a clear syntactic definition. In particular, we link disagreement to linguistic preference on the token level and within spans."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "2.3.   Top- Estimation",
            "text": "We analyse the factors of disagreement through an additional scope, namely top- estimation.  represents the number of most important tokens in the attribution profile. Studies reporting on consistent disagreement between methods do not take the impact of the  number of selected tokens into account (Pruthi et al., 2022  ###reference_b28###; Krishna et al., 2022  ###reference_b20###; Neely et al., 2022  ###reference_b25###). A common way of selecting  is approximating it to a low value, e.g. 1 or 2 (Bastings et al., 2022  ###reference_b7###), 5 (Ramnath et al., 2020  ###reference_b29###), 5 or 10 (Camburu et al., 2019  ###reference_b9###), 25% of the average input length (Krishna et al., 2022  ###reference_b20###). However, a  that is fixed does not account for variability among instances. A  that is too low can exclude important tokens from the comparison, whereas a  that is too high will include non-important tokens while artificially boosting agreement between methods. Keeping  relatively low also helps users to more easily digest the explanations in a real-world scenario.\nThe value of  has also been estimated dynamically. Pruthi et al. (2022  ###reference_b28###) set  to 10% of the input length, assuming that longer inputs have a higher number of important features than shorter inputs. Kamp et al. (2023  ###reference_b18###) propose a  that varies dynamically based on properties of the attribution profile of each instance, aiming to include features that display above average importance and that focus more on the targeted region of the input instead of the specific token. While their method estimates a value for  that is close to human preference, we find that their algorithm necessitates further experiments and refinement. Different importance thresholds are possible and need baseline benchmarking. Also, as of now, prior methods for determining dynamic  do not explicitly account for negative attribution scores.\nWe adopt and improve the dynamic  estimation by Kamp et al. (2023  ###reference_b18###) throughout \u00a74  ###reference_###, when measuring agreement at the span level compared to the token level. Formally, this dynamic approach defines a strong signal in the attribution profile as a score that is higher than its neighboring scores according to two principles: local importance and global importance. Local importance requires that a score must be higher than its strict neighbors ( window) to reduce redundancy of tokens belonging to the same signal. In other words, a set of adjacent tokens with relatively high scores is converted to a single important signal and the highest attribution in the set is kept as the peak of the signal. Similarly, the global importance principle requires important signals to be minimally above average signal strength, i.e. , where  is the attribution profile. By only adopting the global importance threshold, the inclusion of groups of (redundant) neighboring tokens with high attribution scores is expected to increase , unnecessarily boosting the agreement scores. Therefore, the addition of a local importance setting, which we keep unaltered for our remaining experiments, is necessary to estimate signal peaks. As for global importance, we keep the threshold constant in \u00a74.2  ###reference_### to compare span-level agreement to token-level agreement in previous work, and explore different settings in \u00a74.3  ###reference_###."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3.   Linguistic Analysis",
            "text": "We hypothesize that one of the reasons attribution methods disagree is that different methods have different preferences for the classes of words they target. Following from this, we expect that differences in word class preferences are put under a different light when we look at the syntactic spans they are assigned to."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1.   Setup",
            "text": "To analyze the disagreement problem, we consider six different attribution methods on a natural language inference task. For the sake of testing our hypothesis against the agreement results from prior work, we follow Kamp et al. (2023) for the experimental setup. \n\nOne instance in the dataset corresponds to the concatenation of a premise followed by a hypothesis. The possible output labels are contradiction, entailment, and neutral, making it a multi-class problem. Classes are balanced and indicate the relation between premise and hypothesis. The words in every instance are also annotated as being important or not important towards the output label (3 annotators per instance, 43 important words on average), producing so-called human rationales (Carton et al., 2020).\n\nFrom these human rationales, we derive word-level aggregation scores indicating the proportion of annotators that found the word important. These scores are used to compare attribution scores to human preference when considering a top-selection (see Human in Figures 1, 2, and 3).\n\nAs for the attribution methods, we use both gradient-based approaches by including Vanilla Gradient (Simonyan et al., 2014), Integrated Gradient (Sundararajan et al., 2017), and both versions multiplied with the input (Shrikumar et al., 2017), as well as perturbation-based approaches, by including Partition SHAP (Lundberg and Lee, 2017) and LIME (Ribeiro et al., 2016). Ferret package v0.4.1 (Attanasio et al., 2023)."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2.   Preference for a Word Class",
            "text": "The first step in our analysis compares word class preference of different attribution methods on top-tokens. We set the parameter to 4 based on preliminary observations in similar datasets. Figure 2 illustrates the occurrence of different word classes among the tokens with the highest attribution values (i.e. important tokens) for each method and for human aggregated annotations. \n\nWe compare the ratio of important stop words (Figure 2(a)), punctuation tokens (2(b)), and the distribution of the five most preferred POS tags by humans: noun, verb, adj, adp, det (Figure 2(c)). Interestingly, with regards to Integrated Gradient, Gradient\u2009\u00d7\u2009Input, and Integrated Gradient\u2009\u00d7\u2009Input, roughly 10% in each top-4 selection on average consists of punctuation. Despite question answering and natural language inference being different tasks, we replicate the findings on punctuation preference for Integrated Gradient by Ramnath et al. (2020). Notably, these findings do not generalize to the other methods.\n\nIntuitively, this preference seems to be inherent to the method and not to the underlying model, as each instance is normally a concatenation of two sentences tailed by a full stop each. Hence, it is very unlikely that the model is using punctuation as shortcut signals to the output labels. This might suggest that some methods pick up information about the approximate location of a signal in the sentence (locality information), rather than the precise token (lexical information). While punctuation may be a simple symptom of locality, it is important to further examine this phenomenon in the broader context of spans. We do so through a linguistic analysis of spans of locally adjacent tokens, the use of dynamic variables, and their intersection in \u00a74.\n\nStop words, on the other hand, do not display a similar preference as found by Ramnath et al. (2020) (40% versus 10% for Integrated Gradient), indicating that this difference might be task-related. For the other POS tag preferences, we do not observe a clear overlap with prior research for Integrated Gradient (noun: no overlap; verb: overlap; adj: no overlap; adp: cannot compare; det: cannot compare). From Figure 2, we observe the systematic different preference for stop words, punctuation, and most frequent POS tags by Integrated Gradient, Gradient\u2009\u00d7\u2009Input, and Integrated Gradient\u2009\u00d7\u2009Input (Group 1), compared to the other methods and to humans (Group 2). Hence, this intuitively leaves us with two groups displaying different word class preferences.\n\nAssuming that methods (including human rationales) are independent, we apply Chi-Square tests to method\u2013method (and human\u2013method) pairs\u2019 preference distributions. For each pair, we measure whether there is a significant difference between stop word distributions, between punctuation distributions, and between POS tag distributions. The tests confirm our initial observations that most distributions from one group are significantly different from the other group (25/36 pairs) and that no significant differences are found within groups. Most of the exceptions arise for pairs involving Integrated Gradient\u2009\u00d7\u2009Input, with 3 out of 3 non-significant differences found in combination with Partition SHAP, 2 out of 3 with LIME, and 1 out of 3 with human rationales. Hence, Integrated Gradient\u2009\u00d7\u2009Input explains half of the non-significant differences found and can roughly be placed in between the two groups. Additionally, punctuation preferences account for half of the non-significant differences between groups. This might be due to the small numbers of the punctuation frequencies, which may have affected the Chi-Square statistics.\n\nPrimarily Integrated Gradient and Gradient\u2009\u00d7\u2009Input, followed by Integrated Gradient\u2009\u00d7\u2009Input, are indeed the methods for which agreement levels are lowest. This shows that the high similarity in terms of word class preference for the methods in Group 1 results in consistently lower agreement. Simultaneously, the similar preference for methods in Group 2, which happens to be close to human preference, correlates with higher agreement. From the opposite perspective: methods that are similar in terms of agreement scores exhibit similar word class preferences."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "3.3.   Span Definition",
            "text": "We obtain syntactic spans by shallow parsing the data with Flair chunker (Akbik et al., 2018), similarly to Zhou et al. (2020) who use parsed constituents as pre-processed spans for a parsing experiment. Chunking is commonly adopted in Named Entity Recognition where usually noun phrases or verb phrases are the focus of interest (Taufiq et al., 2023). For our task, the advantage of this method over full constituency parsing (Kitaev et al., 2019, e.g.) or dependency parsing (Chen and Manning, 2014, e.g.) is that the chunker output of discrete non-overlapping units facilitates direct alignment with attribution values. Punctuation tokens are ignored by the parser; we treat them as separate spans. Sikdar et al. (2021) use constituency parsing (Mrini et al., 2020) as a basis for hierarchically attributing feature importance scores from tokens to phrases (including any subphrases). However, different methods can have different word class preferences (e.g. a noun modifier may systematically be attributed more importance over its head) and it is therefore questionable whether score aggregation of any kind is a sensible approach. Having clearly defined, non-overlapping phrases is instead crucial to our initial hypothesis. In our dataset, each sentence contains on average 24.4 tokens (6\u201373), which are grouped into 15.3 spans (3\u201345). The average ratio of spans over tokens is 0.63 (0.23\u20131.0). A targeted span is a span that contains at least one token included in the top- selection by the attribution method. During agreement evaluation we treat spans as atomic units, meaning that a span is assigned 1 if targeted, otherwise 0 (similarly to tokens in top- selection). For a fixed set to 4, the average number of targeted spans in a sentence is slightly lower: Partition SHAP 3.5, LIME 3.6, Vanilla Grad 3.5, Grad\u2009\u00d7\u2009Input 3.6, Integrated Gradient 3.7, Integrated Gradient\u2009\u00d7\u2009Input 3.5, Human 3.3. The average over methods is 3.5."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "3.4.   Head vs. Modifier Preference",
            "text": "We have seen that Gradient\u2009\u00d7\u2009Input and Vanilla Gradient exhibit complementary linguistic preferences for noun tokens (the lowest versus highest ratio of noun tokens in the top-4). We zoom in on this phenomenon and investigate the attribution patterns in noun phrases (NPs), focusing on methods that select the head over its modifier and vice versa. \n\nWe examine a subset of noun phrase spans grouped by Gradient\u2009\u00d7\u2009Input and Vanilla Gradient. The NPs must span a minimum of two tokens to make the preference analysis for different word classes possible. To add some consensus stability to this subset, the spans under question should also be targeted by highly agreeing methods Partition SHAP and LIME. We compare the attribution profiles of Gradient\u2009\u00d7\u2009Input and Vanilla Gradient on the token and the span level for the specific [det, noun] construction, the most prevalent among length-2 noun phrases (73%, 1,963). Interestingly, of the cases where Vanilla Gradient targeted the noun (99%, 1,951), Gradient\u2009\u00d7\u2009Input targeted the det half of the times (899). This example clearly illustrates how methods do not only target different word classes in absolute terms, but also how that translates to systematic, alternating differences within syntactic spans.\n\nFurthermore, the ratio of targeted tokens in the [det, noun] NPs is comparable: 57% for Vanilla Gradient versus 60% for Gradient\u2009\u00d7\u2009Input. This detail strengthens the claim of systematic preference in that the det\u2013noun alternation, i.a., is usually exclusive. In other words, it is uncommon for the two described methods to target both tokens from the NPs. This increases the prominence of the preference phenomenon in cases where one selects the det and the other the noun."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4.   Agreement at the Span Level",
            "text": "We showed that different methods have different word class preferences and that the preference can be strong in the case of syntactic noun phrases. A consistently strong preference by two methods leads to a strong disagreement at the token level. The expectation that methods should agree on the token level might therefore be too strict. Given these insights, we measure method\u2013method and human\u2013method agreement at the span level, expecting a relative improvement compared to token-level agreement."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1.   Setup",
            "text": "The dataset, model configurations, and pool of attribution methods that we use are identical to those described in the linguistic analysis (\u00a73  ###reference_###). In addition, we adopt the definition for spans given in \u00a73.3  ###reference_###. Our data therefore has a version where the instances are divided into tokens and one where instances are split into spans. The details of dynamic correspond to those described in \u00a72.3  ###reference_###."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2.   The Effect of Dynamic  on Spans",
            "text": "We compare the effect of dynamic masking on the span level versus dynamic masking on the token level. We measure the effect as the increase in agreement i) versus a baseline to assess overall difficulty of the task and ii) versus fixed masking to assess the ability of the dynamic approach to detect important spans. We expect dynamic masking to be better suited than fixed masking to identify linguistic spans that the model considers important in the instance. Specifically, the local importance setting (in combination with global importance) appears to work as a pooling operator, highlighting the distinct important parts of the instance rather than few concentrated parts. We assume here that for the specific NLI task, certain parts of the input should be considered important.\n\nAgreement is measured as follows. We denote an attribution method as M. M assigns an attribution profile a to the input sequence of tokens {t1, t2, ..., tn} so that each ai indicates the importance of token ti towards the inferred class. The subset of m tokens with the highest attribution values are formalized as B_@m. We compare m attribution methods in pairs by calculating sentence-level agreement@k. Agreement@k is based on the relevance of each token. Relevance for a token ti is equal to the ratio of methods that include the token in their respective B_@m subsets. Agreement@k ignores perfect agreement on non-important tokens (where relevance = 0) in order not to inflate the score. For our experiments, we report mean agreement@k, the averaged agreement over instances in the dataset D.\n\nThe average pair-wise agreement (all method\u2013method combinations) for dynamic masking is 0.61 on the token level and 0.69 on the span level. 0.5 indicates perfect disagreement and 1.0 perfect agreement. While agreement seems relatively low, it might still suggest that consistently the same, few types of signals are identified by a pair of methods.\n\nWe compute a baseline to measure how likely methods are to agree on the token and span level with a pseudo-random attribution method. In other words, we measure task difficulty of making two vectors with a subset of important tokens and spans to agree given a low value of m. For fixed masks, 16% of the tokens in a sentence would be highlighted on average; consequently, 23% of the spans would be highlighted on average. For the token-level baseline, we then randomly shuffle two binary vectors of 100 elements, 16 of which are 1s, and compute pairwise agreement. We repeat the process n times. For the span-level baseline we adopt the same procedure, with the exception that the 1s in the vector are 23. The resulting baselines are 0.54 and 0.57, respectively, indicating that agreeing on tokens and spans is similarly difficult at low values of m. We thus observe the token-wise baseline for fixed masks being outperformed by 0.07 (0.54 to 0.61), whereas the span-wise baseline is outperformed by a relatively larger increase of 0.12 (0.57 to 0.69).\n\nThe comparison results between span agreement on fixed masks versus dynamic masking are given in Figure 3. While dynamic masking provided marginal boosts (+0.00, +0.01, +0.02 compared to fixed masks) on the token level for Gradient\u2009\u00d7\u2009Input and Integrated Gradient, it proves to have a larger positive effect on the span level. Specifically, the span agreement for method\u2013method pairs that include Gradient\u2009\u00d7\u2009Input and/or Integrated Gradient remains constant or increases (changes from +0.00 to +0.07 compared to fixed masks). At the same time, other method\u2013method and human\u2013method agreement scores remain constant or marginally decrease (+0.01, +0.00, -0.01).\n\nWith regards to the largest difference observed between dynamic and fixed masks, namely Integrated Gradient versus Gradient\u2009\u00d7\u2009Input, this can also be explained through the concentration levels of targeted tokens within spans. In fact, dynamic masking scatters the important tokens so that more spans are targeted compared to selecting an average fixed mask. While fixed masks yield 3.7 and 3.6 spans on average for the two methods, dynamic masking yields 6.9 and 6.5. Since it becomes easier for methods to agree when more tokens (and therefore more spans) are targeted, we investigate the settings of dynamic masking further."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "4.3.   Adjusting Dynamic",
            "text": "How can we validate or improve the dynamic algorithm? A solid global importance threshold should meet two conditions: i) resulting values of should be low, preferably close to human preference average of 43; ii) they should outperform a baseline. We explore multiple thresholds: different combinations of , typical distances from the mean in a distribution; the median, which is more robust to outliers than . The thresholds are calculated for (a) all scores and (b) positive scores. Thresholds for positive scores should ignore attributions with negative importance towards the inferred class. These are common in methods such as Integrated Gradient\u2009\u00d7\u2009Input. The influence of negative values and peaks in the attribution profiles is not accounted for by the current threshold set at .\n\nWe find that for different thresholds, resulting s are comparable across methods, which might indicate that the attribution profiles have overall similar distributions. The three thresholds that yield closest s to human preference are , , and median . Closeness corresponds to the averaged Euclidean distance between the meanstdev pairs and human preference of 43, for each threshold column. Among these three, had already proven to keep low and close to ground truth average (Kamp et al., 2023).\n\nEven if the estimated s by the three candidate thresholds are relatively low, it could be, for example, that a method-specific is too high, positively biasing the agreement score. A high would even give high agreement for a pseudo-random attribution profile, which should not be possible if the threshold is properly set. Hence, we compare each method\u2019s agreement scores with other methods to the method\u2019s agreement with a baseline. This gives us an indication of how well a specific threshold works with different attribution profiles. We do this both on the token level and on the span level. The baseline method operates pseudo-randomly by assigning attribution scores to the tokens without knowledge about token importance. For each method, we randomly shuffle the scores in each attribution profile. Each method has its own baseline so that the different distributional properties of the attribution profiles are preserved. We then compute agreement@dynamic- between original and shuffled attribution profiles, which are consequently averaged over the dataset. If the threshold for -estimation is strong, the agreement with the baseline for each method should be lower than the agreement with other methods.\n\nWe find that for , Integrated Gradient and Gradient\u2009\u00d7\u2009Input have higher baseline agreement than the other methods. This can be explained by the higher values of for this threshold (i.e. 6.83 and 7.30). Importantly, both methods have method\u2013method agreement scores that do not beat the baseline (which pseudo-randomly selects tokens), neither on the token level nor on the span level. With regards to median , multiple methods do not beat their baselines either. The threshold instead does, for all methods and both on tokens and on spans. This is an indication of the fact that the latter might be a better threshold than for dynamic estimation. An additional interpretation of why works better than is that negative local maxima in the attribution profiles are hereby ignored, leading to less but more important tokens (and spans) to be targeted. This baseline testing also shows that Gradient\u2009\u00d7\u2009Input and Integrated Gradient are unreliable methods: they have low agreement with other methods and often fail to beat a random baseline."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5.   Discussion",
            "text": "Analysing disagreement from a linguistic perspective helps us to better understand the differences between attribution methods. We briefly discuss the implications of token- and span-level analyses on other tasks than NLI. With an eye on the ability and reliability of these methods to reflect the model\u2019s decision process, we also consider the implications for the faithfulness aspect in interpretability research.\nGenerally speaking, an NLI task is sufficiently challenging that it avoids sentences of different classes (e.g. contradiction, entailment) differing by exactly one word. It is therefore fair to expect methods to target the same span and not to penalise them for disagreeing on the token level. However, targeting a modifier instead of its syntactic head can make a big difference for other tasks. Additionally, the span-token ratio should determine the difficulty of assessing span-level agreement compared to tokens.\nThe choice of considering spans rather than tokens should therefore be weighted against the type of task and data.\nOn a similar note, \u00a73.2  ###reference_### describes the systematic differences in punctuation preferences. We may hypothesise that methods that consistently include full stops in their top- are actually catching the signal\u2019s onset (locality information) rather than the full stop being itself a signal (lexical information). To this end, our choice of treating punctuation as separate spans might have influenced the span agreement of such methods. More research is necessary to disentangle locality from lexical information.\nAgreement is linked with both plausibility and faithfulness. We considered plausibility when estimating dynamic  thresholds, as we aimed for s close to human preference. However, a more direct way of testing for plausibility in this context is by assessing human\u2013method agreement, which we mostly left out of scope in this study. To that end, we did find that agreement results are constant on both tokens and spans, possibly suggesting that human\u2013method agreement reaches a ceiling already at the token level (i.e. tokens are targeted that belong to different signals in the sentence). This interpretation might even hold for more faithful methods. In fact, models do often not rely on the same patterns as humans do, instead resorting to shortcut signals.\nMeasuring faithfulness, on the other hand, is less straightforward. Following Jain and Wallace (2019  ###reference_b15###), who state that faithful attention-based explanations should be agreeable, we carefully extend their perspective in that agreement between method-generic explanations can be considered as a proxy for faithfulness. According to the principle of reproducibility in science (Popper, 2005  ###reference_b27###), a finding that is confirmed through different means is, in principle, more likely to be correct. As such, if two attribution methods with distinct means yield similar results, they are likely similarly (un)faithful. If one method disagrees with the majority of the batch, either the one, the majority, or all are unfaithful. Because of the reproducibility principle, however, it is more likely that the majority is more faithful.\nIn this light, we could therefore speculate that Gradient\u2009\u00d7\u2009Input and Integrated Gradient were two of the less faithful methods in our study, an argument that is supported by their scarce agreement compared to a pseudo-random baseline. Given that some methods might highly correlate with other methods by design, one must be careful at drawing conclusions. Constructing a batch of methods that is representative of different ways of interpreting the model is, for this reason, not a simple task."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6.   Conclusion and Future Directions",
            "text": "In this study, we approached post-hoc explanation disagreement from a syntactic perspective. We found that methods that agree most with other methods and with aggregated scores of human rationales have similar POS tag preferences for the targeted tokens. We then determined that attribution methods agree more at the span level than at the token level, which appear to be similarly difficult tasks at low values of . One particular reason for disagreement is the consistent preference by one method to target the determiners instead of the noun head within the same noun phrase. We showed that dynamic  works well in combination with spans, as it seeks for non-neighboring important signals in the sentence. Finally, we empirically tested for different thresholds of the global importance setting of dynamic , suggesting a value () that accounts for both negative attribution scores and results in low s.\n\nOne issue that dynamic  aims to tackle is the targeting of redundant tokens as signals in the same span. To complement this, a more in-depth analysis would provide a better understanding about the way that different methods concentrate their targeted tokens in the same spans. Intuitively, for a fixed , some methods highlight tokens that are more sparse across the instance, whereas other more quickly concentrate targeted tokens within the same spans. To obtain such a concentration metric, one could measure how rapidly a set of tokens belonging to the most important ground truth span are being targeted, at increasing values of .\n\nFuture directions of research include the exploration of different local importance criteria in the dynamic  algorithm, such as different windows (current 1 versus 2, 3). Another is to exploit (syntactic) span-based information to improve interpretability accuracy at the token level, or to improve explanation aggregation techniques. Finally, we advise future evaluation datasets based on multiple annotators\u2019 rationales to preserve specific instance\u2013annotator mappings in the metadata. This would facilitate new directions in assessing the plausibility of attribution methods, specifically how variations in human subjectivity relate to agreement."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7.   Ethical Considerations",
            "text": "We would like to reiterate that attribution scores cannot be blindly relied upon to precisely determine model functioning, as they can be influenced by experimental factors such as task and model performance. To avoid drawing generalised conclusions, it is advisable to employ multiple metrics when studying feature attribution."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "8.   Acknowledgements",
            "text": "Jonathan Kamp\u2019s research was funded by the Dutch National Science Organisation (NWO) through the project InDeep: Interpreting Deep Learning Models for Text and Sound (NWA.1292.19.399). Antske Fokkens was supported by the EU Horizon 2020 project InTaVia: In/Tangible European Heritage - Visual Analysis, Curation and Communication (http://intavia.eu) under grant agreement No. 101004825. Lisa Beinborn\u2019s work was funded by the Dutch National Science Organisation (NWO) through the VENI program (Vl.Veni.211C.039). We would like to thank the anonymous reviewers for their valuable contribution."
        },
        {
            "section_id": "9",
            "parent_section_id": null,
            "section_name": "9.   Bibliographical References",
            "text": ""
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Appendix",
            "text": "The baseline tests for importance thresholds  and median  described in \u00a74.3  ###reference_### are given in Table 3  ###reference_### and Table 4  ###reference_###, respectively. The averaged Euclidean distances that led to selecting these thresholds (\u00a74.3  ###reference_###) are reported in Table 5  ###reference_###. In Table 6  ###reference_###, we find the results of the Chi-Square tests adopted within the linguistic analysis in \u00a73.2  ###reference_###."
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.78\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.78.79.1\">\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T1.78.79.1.1\"></td>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.78.79.1.2\"></th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.78.79.1.3\"></th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.78.79.1.4\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.78.79.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.78.79.1.5.1\">Thresholds</span></th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.78.79.1.6\"></th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.78.79.1.7\"></th>\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T1.78.79.1.8\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.5.5\">\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.5.5.6\"></td>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.5.5.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.5.5.7.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.2.2.2\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.3.3.3\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.4.4.4\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.5.5.5\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.5.5.8\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T1.5.5.8.1\">median</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.11.11\">\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.11.11.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.11.11.8\">PartSHAP</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.6.6.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.6.6.1.1\" style=\"background-color:#BFBFBF;\">4.541.73</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.7.7.2\">2.160.95</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.8.8.3\">1.250.65</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.9.9.4\">7.36 1.89</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.10.10.5\">7.371.89</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.11.11.6\">6.191.62</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.17.17\">\n<td class=\"ltx_td\" id=\"S4.T1.17.17.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.17.17.8\">LIME</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.12.12.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.12.12.1.1\" style=\"background-color:#BFBFBF;\">5.342.35</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.13.13.2\">2.241.05</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.14.14.3\">1.230.65</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.15.15.4\">8.312.86</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.16.16.5\">8.322.87</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.17.17.6\">7.132.48</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.23.23\">\n<td class=\"ltx_td\" id=\"S4.T1.23.23.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.23.23.8\">VanGrad</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.18.18.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.18.18.1.1\" style=\"background-color:#BFBFBF;\">4.581.68</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.19.19.2\">2.411.02</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.20.20.3\">1.390.61</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.21.21.4\">7.632.68</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.22.22.5\">7.642.69</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.23.23.6\">6.202.08</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.29.29\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.29.29.7\">all</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.29.29.8\">Grad\u00d7I</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.24.24.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.24.24.1.1\" style=\"background-color:#BFBFBF;\">6.832.59</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.25.25.2\">2.391.12</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.26.26.3\">0.680.65</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.27.27.4\">8.212.82</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.28.28.5\">8.282.83</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.29.29.6\">7.082.51</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.35.35\">\n<td class=\"ltx_td\" id=\"S4.T1.35.35.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.35.35.8\">IntGrad</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.30.30.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.30.30.1.1\" style=\"background-color:#BFBFBF;\">7.302.63</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.31.31.2\">2.661.23</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.32.32.3\">0.640.63</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.33.33.4\">8.412.88</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.34.34.5\">8.462.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.35.35.6\">7.412.58</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.41.41\">\n<td class=\"ltx_td\" id=\"S4.T1.41.41.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.41.41.8\">IntGrad\u00d7I</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.36.36.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.36.36.1.1\" style=\"background-color:#BFBFBF;\">5.682.37</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.37.37.2\">2.271.08</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.38.38.3\">1.020.62</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.39.39.4\">8.042.80</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.40.40.5\">8.072.82</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.41.41.6\">6.832.39</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.47.47\">\n<td class=\"ltx_td ltx_border_tt\" id=\"S4.T1.47.47.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.47.47.8\">PartSHAP</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.42.42.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.42.42.1.1\" style=\"background-color:#BFBFBF;\">3.341.33</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.43.43.2\">1.860.82</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.44.44.3\">1.070.55</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.45.45.4\">7.002.01</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.46.46.5\">7.281.93</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T1.47.47.6\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.47.47.6.1\" style=\"background-color:#BFBFBF;\">5.011.61</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.53.53\">\n<td class=\"ltx_td\" id=\"S4.T1.53.53.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.53.53.8\">LIME</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.48.48.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.48.48.1.1\" style=\"background-color:#BFBFBF;\">3.561.56</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.49.49.2\">1.870.87</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.50.50.3\">1.060.53</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.51.51.4\">7.952.91</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.52.52.5\">8.252.89</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.53.53.6\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.53.53.6.1\" style=\"background-color:#BFBFBF;\">5.592.04</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.59.59\">\n<td class=\"ltx_td\" id=\"S4.T1.59.59.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.59.59.8\">VanGrad</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.54.54.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.54.54.1.1\" style=\"background-color:#BFBFBF;\">4.581.68</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.55.55.2\">2.411.02</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.56.56.3\">1.390.61</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.57.57.4\">7.632.68</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.58.58.5\">7.642.69</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.59.59.6\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.59.59.6.1\" style=\"background-color:#BFBFBF;\">6.202.08</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.66.66\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.60.60.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.66.66.8\">Grad\u00d7I</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.61.61.2\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.61.61.2.1\" style=\"background-color:#BFBFBF;\">3.511.56</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.62.62.3\">1.750.83</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.63.63.4\">0.730.56</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.64.64.5\">6.812.82</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.65.65.6\">7.862.92</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.66.66.7\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.66.66.7.1\" style=\"background-color:#BFBFBF;\">4.691.88</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.72.72\">\n<td class=\"ltx_td\" id=\"S4.T1.72.72.7\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.72.72.8\">IntGrad</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.67.67.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.67.67.1.1\" style=\"background-color:#BFBFBF;\">3.471.60</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.68.68.2\">1.670.81</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.69.69.3\">0.620.55</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.70.70.4\">6.602.81</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.71.71.5\">7.813.05</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.72.72.6\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.72.72.6.1\" style=\"background-color:#BFBFBF;\">4.541.86</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.78.78\">\n<td class=\"ltx_td ltx_border_bb\" id=\"S4.T1.78.78.7\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.78.78.8\">IntGrad\u00d7I</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.73.73.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.73.73.1.1\" style=\"background-color:#BFBFBF;\">3.831.69</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.74.74.2\">1.910.90</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.75.75.3\">0.980.53</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.76.76.4\">7.572.74</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.77.77.5\">7.992.81</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.78.78.6\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"S4.T1.78.78.6.1\" style=\"background-color:#BFBFBF;\">5.381.96</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T1.83.2.1\" style=\"font-size:90%;\">Table 1</span>: </span><span class=\"ltx_text\" id=\"S4.T1.80.1\" style=\"font-size:90%;\">Values of <span class=\"ltx_text ltx_font_italic\" id=\"S4.T1.80.1.1\">k</span> for different global importance thresholds. The three methods that yield values of  closest to human preference are visually indicated with a dark background.</span></figcaption>\n</figure>",
            "capture": "Table 1: Values of k for different global importance thresholds. The three methods that yield values of  closest to human preference are visually indicated with a dark background."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T2\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.6\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.6.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T2.6.1.1.1\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.6.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.1.1.2.1\">Token</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.6.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.1.1.3.1\">Span</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.6.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.2.2.1.1\">Method</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\" id=\"S4.T2.6.2.2.2\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T2.6.2.2.2.1\">BL:minAgr\u2013maxAgr</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.3.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.6.3.3.1\">PartSHAP</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.3.3.2\">0.56:0.56\u20130.78</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.3.3.3\">0.64:0.64\u20130.82</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.4.4\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T2.6.4.4.1\">LIME</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.4.4.2\">0.57:0.57\u20130.78</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.4.4.3\">0.65:0.65\u20130.82</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.5.5\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T2.6.5.5.1\">VanGrad</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.5.5.2\">0.56:0.58\u20130.68</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.5.5.3\">0.64:0.66\u20130.73</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.6.6\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T2.6.6.6.1\">Grad\u00d7I</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.2\">0.59:<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.6.6.2.1\">0.56</span>\u20130.60</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.3\">0.68:<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.6.6.3.1\">0.64</span>\u20130.69</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.7.7\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T2.6.7.7.1\">IntGrad</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.7.7.2\">0.60:<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.7.7.2.1\">0.58</span>\u2013<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.7.7.2.2\">0.59</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.7.7.3\">0.69:<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.7.7.3.1\">0.66</span>\u2013<span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.7.7.3.2\">0.68</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.8.8\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T2.6.8.8.1\">IntGrad\u00d7I</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.6.8.8.2\">0.58:0.58\u20130.64</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.6.8.8.3\">0.66:0.66\u20130.70</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S4.T2.11.3.1\" style=\"font-size:90%;\">Table 2</span>: </span><span class=\"ltx_text\" id=\"S4.T2.4.2\" style=\"font-size:90%;\">Token and span agr. with other methods (range <span class=\"ltx_text ltx_font_italic\" id=\"S4.T2.4.2.1\">minAgr</span> to <span class=\"ltx_text ltx_font_italic\" id=\"S4.T2.4.2.2\">maxAgr</span>) versus baseline (<span class=\"ltx_text ltx_font_italic\" id=\"S4.T2.4.2.3\">BL</span>), for threshold . Scores  baseline in <span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.2.4\">bold</span>.</span></figcaption>\n</figure>",
            "capture": "Table 2: Token and span agr. with other methods (range minAgr to maxAgr) versus baseline (BL), for threshold . Scores  baseline in bold."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"A1.T3\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A1.T3.6\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T3.6.1.1\">\n<td class=\"ltx_td ltx_border_tt\" id=\"A1.T3.6.1.1.1\"></td>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T3.6.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T3.6.1.1.2.1\">Token</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T3.6.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T3.6.1.1.3.1\">Span</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T3.6.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A1.T3.6.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T3.6.2.2.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"2\" id=\"A1.T3.6.2.2.2\"><span class=\"ltx_text ltx_font_italic\" id=\"A1.T3.6.2.2.2.1\">BL:minAgr\u2013maxAgr</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T3.6.3.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T3.6.3.3.1\">PartSHAP</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T3.6.3.3.2\">0.55:0.55\u20130.81</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T3.6.3.3.3\">0.60:0.61\u20130.83</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T3.6.4.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T3.6.4.4.1\">LIME</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T3.6.4.4.2\">0.55:0.55\u20130.81</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T3.6.4.4.3\">0.60:0.61\u20130.83</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T3.6.5.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T3.6.5.5.1\">VanGrad</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T3.6.5.5.2\">0.56:0.58\u20130.68</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T3.6.5.5.3\">0.64:0.64\u20130.72</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T3.6.6.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T3.6.6.6.1\">Grad\u00d7I</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T3.6.6.6.2\">0.55:0.55\u20130.58</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T3.6.6.6.3\">0.60:0.60\u20130.65</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T3.6.7.7\">\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T3.6.7.7.1\">IntGrad</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T3.6.7.7.2\">0.55:0.55\u20130.58</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T3.6.7.7.3\">0.59:0.61\u20130.64</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T3.6.8.8\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T3.6.8.8.1\">IntGrad\u00d7I</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T3.6.8.8.2\">0.55:0.57\u20130.65</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T3.6.8.8.3\">0.61:0.61\u20130.69</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"A1.T3.11.3.1\" style=\"font-size:90%;\">Table 3</span>: </span><span class=\"ltx_text\" id=\"A1.T3.4.2\" style=\"font-size:90%;\">Token and span agr. with other methods (range <span class=\"ltx_text ltx_font_italic\" id=\"A1.T3.4.2.1\">minAgr</span> to <span class=\"ltx_text ltx_font_italic\" id=\"A1.T3.4.2.2\">maxAgr</span>) versus baseline (<span class=\"ltx_text ltx_font_italic\" id=\"A1.T3.4.2.3\">BL</span>), for thresh. . Scores  baseline in <span class=\"ltx_text ltx_font_bold\" id=\"A1.T3.4.2.4\">bold</span>.</span></figcaption>\n</figure>",
            "capture": "Table 3: Token and span agr. with other methods (range minAgr to maxAgr) versus baseline (BL), for thresh. . Scores  baseline in bold."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"A1.T4\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A1.T4.8\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T4.8.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"A1.T4.8.1.1.1\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A1.T4.8.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T4.8.1.1.2.1\">Token</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A1.T4.8.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T4.8.1.1.3.1\">Span</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T4.8.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"A1.T4.8.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T4.8.2.2.1.1\">Method</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\" id=\"A1.T4.8.2.2.2\"><span class=\"ltx_text ltx_font_italic\" id=\"A1.T4.8.2.2.2.1\">BL:minAgr\u2013maxAgr</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T4.8.3.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"A1.T4.8.3.3.1\">PartSHAP</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T4.8.3.3.2\">0.57:<span class=\"ltx_text ltx_font_bold\" id=\"A1.T4.8.3.3.2.1\">0.56</span>\u20130.76</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T4.8.3.3.3\">0.65:<span class=\"ltx_text ltx_font_bold\" id=\"A1.T4.8.3.3.3.1\">0.63</span>\u20130.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T4.8.4.4\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"A1.T4.8.4.4.1\">LIME</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T4.8.4.4.2\">0.57:<span class=\"ltx_text ltx_font_bold\" id=\"A1.T4.8.4.4.2.1\">0.56</span>\u20130.76</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T4.8.4.4.3\">0.65:<span class=\"ltx_text ltx_font_bold\" id=\"A1.T4.8.4.4.3.1\">0.63</span>\u20130.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T4.8.5.5\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"A1.T4.8.5.5.1\">VanGrad</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T4.8.5.5.2\">0.59:<span class=\"ltx_text ltx_font_bold\" id=\"A1.T4.8.5.5.2.1\">0.58</span>\u20130.68</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T4.8.5.5.3\">0.69:<span class=\"ltx_text ltx_font_bold\" id=\"A1.T4.8.5.5.3.1\">0.66</span>\u20130.74</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T4.8.6.6\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"A1.T4.8.6.6.1\">Grad\u00d7I</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T4.8.6.6.2\">0.56:0.56\u20130.59</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T4.8.6.6.3\">0.63:<span class=\"ltx_text ltx_font_bold\" id=\"A1.T4.8.6.6.3.1\">0.62</span>\u20130.67</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T4.8.7.7\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"A1.T4.8.7.7.1\">IntGrad</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T4.8.7.7.2\">0.56:0.56\u20130.58</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T4.8.7.7.3\">0.62:0.62\u20130.66</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T4.8.8.8\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"A1.T4.8.8.8.1\">IntGrad\u00d7I</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T4.8.8.8.2\">0.57:0.57\u20130.64</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T4.8.8.8.3\">0.65:0.66\u20130.74</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"A1.T4.14.4.1\" style=\"font-size:90%;\">Table 4</span>: </span><span class=\"ltx_text\" id=\"A1.T4.6.3\" style=\"font-size:90%;\">Token and span agr. with other methods (range <span class=\"ltx_text ltx_font_italic\" id=\"A1.T4.6.3.1\">minAgr</span> to <span class=\"ltx_text ltx_font_italic\" id=\"A1.T4.6.3.2\">maxAgr</span>) vs. baseline (<span class=\"ltx_text ltx_font_italic\" id=\"A1.T4.6.3.3\">BL</span>), for thresh.  <span class=\"ltx_text ltx_font_italic\" id=\"A1.T4.6.3.4\">median</span> . Scores  baseline in <span class=\"ltx_text ltx_font_bold\" id=\"A1.T4.6.3.5\">bold</span>.</span></figcaption>\n</figure>",
            "capture": "Table 4: Token and span agr. with other methods (range minAgr to maxAgr) vs. baseline (BL), for thresh.  median . Scores  baseline in bold."
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"A1.T5\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A1.T5.6\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T5.5.5\">\n<td class=\"ltx_td ltx_border_tt\" id=\"A1.T5.5.5.6\"></td>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T5.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T5.2.2.2\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T5.3.3.3\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T5.4.4.4\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T5.5.5.5\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T5.5.5.7\"><span class=\"ltx_text ltx_font_italic\" id=\"A1.T5.5.5.7.1\">median</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T5.6.7.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T5.6.7.1.1\">all</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T5.6.7.1.2\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T5.6.7.1.2.1\" style=\"background-color:#BFBFBF;\">12.286</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T5.6.7.1.3\">15.200</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T5.6.7.1.4\">22.782</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T5.6.7.1.5\">24.165</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T5.6.7.1.6\">24.342</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T5.6.7.1.7\">17.596</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T5.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T5.6.6.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T5.6.6.2\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T5.6.6.2.1\" style=\"background-color:#BFBFBF;\">9.082</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T5.6.6.3\">17.893</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T5.6.6.4\">23.354</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T5.6.6.5\">19.756</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T5.6.6.6\">23.020</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T5.6.6.7\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T5.6.6.7.1\" style=\"background-color:#BFBFBF;\">10.265</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"A1.T5.8.1.1\" style=\"font-size:90%;\">Table 5</span>: </span><span class=\"ltx_text\" id=\"A1.T5.9.2\" style=\"font-size:90%;\">The averaged Euclidean distances between the methods\u2019 mean\u00b1stdev values for each threshold, and human preference (4\u00b13). We analyse further the three thresholds visually indicated with a dark background that have nearest distance to human preference.</span></figcaption>\n</figure>",
            "capture": "Table 5: The averaged Euclidean distances between the methods\u2019 mean\u00b1stdev values for each threshold, and human preference (4\u00b13). We analyse further the three thresholds visually indicated with a dark background that have nearest distance to human preference."
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"A1.T6\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A1.T6.6\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T6.6.7.1\">\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"A1.T6.6.7.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" colspan=\"3\" id=\"A1.T6.6.7.1.2\"><span class=\"ltx_text ltx_font_italic\" id=\"A1.T6.6.7.1.2.1\">Stop words</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" colspan=\"3\" id=\"A1.T6.6.7.1.3\"><span class=\"ltx_text ltx_font_italic\" id=\"A1.T6.6.7.1.3.1\">Punctuation</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" colspan=\"3\" id=\"A1.T6.6.7.1.4\"><span class=\"ltx_text ltx_font_italic\" id=\"A1.T6.6.7.1.4.1\">POS</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt\" id=\"A1.T6.6.6.7\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T6.6.6.7.1\">Comparison</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T6.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T6.2.2.2\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" id=\"A1.T6.6.6.8\">df</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T6.3.3.3\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T6.4.4.4\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" id=\"A1.T6.6.6.9\">df</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T6.5.5.5\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T6.6.6.6\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T6.6.6.10\">df</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T6.6.8.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"A1.T6.6.8.1.1\">PartSHAP vs LIME</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A1.T6.6.8.1.2\">0.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A1.T6.6.8.1.3\">1.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"A1.T6.6.8.1.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A1.T6.6.8.1.5\">0.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A1.T6.6.8.1.6\">1.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"A1.T6.6.8.1.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A1.T6.6.8.1.8\">0.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A1.T6.6.8.1.9\">1.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A1.T6.6.8.1.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.9.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.9.2.1\">PartSHAP vs VanGrad</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.9.2.2\">1.247</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.9.2.3\">0.264</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.9.2.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.9.2.5\">0.255</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.9.2.6\">0.614</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.9.2.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.9.2.8\">2.580</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.9.2.9\">0.630</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.9.2.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.10.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.10.3.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T6.6.10.3.1.1\" style=\"background-color:#BFBFBF;\">PartSHAP vs Grad\u00d7I</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.10.3.2\">7.642</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.10.3.3\">0.006*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.10.3.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.10.3.5\">3.763</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.10.3.6\">0.052</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.10.3.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.10.3.8\">10.361</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.10.3.9\">0.035*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.10.3.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.11.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.11.4.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T6.6.11.4.1.1\" style=\"background-color:#BFBFBF;\">PartSHAP vs IntGrad</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.11.4.2\">6.155</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.11.4.3\">0.013*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.11.4.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.11.4.5\">2.216</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.11.4.6\">0.137</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.11.4.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.11.4.8\">9.578</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.11.4.9\">0.048*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.11.4.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.12.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.12.5.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T6.6.12.5.1.1\" style=\"background-color:#BFBFBF;\">PartSHAP vs IntGrad\u00d7I</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.12.5.2\">3.611</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.12.5.3\">0.057</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.12.5.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.12.5.5\">2.962</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.12.5.6\">0.085</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.12.5.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.12.5.8\">5.219</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.12.5.9\">0.266</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.12.5.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.13.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.13.6.1\">PartSHAP vs Human</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.13.6.2\">0.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.13.6.3\">1.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.13.6.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.13.6.5\">0.255</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.13.6.6\">0.614</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.13.6.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.13.6.8\">0.117</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.13.6.9\">0.998</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.13.6.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.14.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.14.7.1\">LIME vs VanGrad</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.14.7.2\">0.886</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.14.7.3\">0.347</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.14.7.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.14.7.5\">0.820</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.14.7.6\">0.365</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.14.7.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.14.7.8\">2.580</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.14.7.9\">0.630</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.14.7.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.15.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.15.8.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T6.6.15.8.1.1\" style=\"background-color:#BFBFBF;\">LIME vs Grad\u00d7I</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.15.8.2\">8.595</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.15.8.3\">0.003*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.15.8.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.15.8.5\">2.595</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.15.8.6\">0.107</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.15.8.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.15.8.8\">10.361</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.15.8.9\">0.035*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.15.8.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.16.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.16.9.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T6.6.16.9.1.1\" style=\"background-color:#BFBFBF;\">LIME vs IntGrad</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.16.9.2\">7.018</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.16.9.3\">0.008*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.16.9.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.16.9.5\">1.316</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.16.9.6\">0.251</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.16.9.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.16.9.8\">9.578</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.16.9.9\">0.048*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.16.9.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.17.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.17.10.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T6.6.17.10.1.1\" style=\"background-color:#BFBFBF;\">LIME vs IntGrad\u00d7I</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.17.10.2\">4.287</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.17.10.3\">0.038*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.17.10.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.17.10.5\">1.920</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.17.10.6\">0.166</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.17.10.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.17.10.8\">5.219</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.17.10.9\">0.266</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.17.10.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.18.11\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.18.11.1\">LIME vs Human</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.18.11.2\">0.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.18.11.3\">1.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.18.11.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.18.11.5\">0.820</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.18.11.6\">0.365</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.18.11.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.18.11.8\">0.117</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.18.11.9\">0.998</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.18.11.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.19.12\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.19.12.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T6.6.19.12.1.1\" style=\"background-color:#BFBFBF;\">VanGrad vs Grad\u00d7I</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.19.12.2\">15.855</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.19.12.3\">&lt;0.001*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.19.12.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.19.12.5\">7.181</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.19.12.6\">0.007*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.19.12.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.19.12.8\">20.485</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.19.12.9\">&lt;0.001*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.19.12.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.20.13\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.20.13.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T6.6.20.13.1.1\" style=\"background-color:#BFBFBF;\">VanGrad vs IntGrad</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.20.13.2\">13.747</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.20.13.3\">&lt;0.001*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.20.13.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.20.13.5\">5.158</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.20.13.6\">0.023*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.20.13.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.20.13.8\">19.476</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.20.13.9\">&lt;0.001*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.20.13.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.21.14\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.21.14.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T6.6.21.14.1.1\" style=\"background-color:#BFBFBF;\">VanGrad vs IntGrad\u00d7I</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.21.14.2\">9.896</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.21.14.3\">0.002*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.21.14.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.21.14.5\">6.157</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.21.14.6\">0.013*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.21.14.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.21.14.8\">13.148</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.21.14.9\">0.011*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.21.14.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.22.15\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.22.15.1\">VanGrad vs Human</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.22.15.2\">0.886</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.22.15.3\">0.347</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.22.15.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.22.15.5\">0.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.22.15.6\">1.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.22.15.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.22.15.8\">2.635</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.22.15.9\">0.621</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.22.15.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.23.16\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.23.16.1\">Grad\u00d7I vs IntGrad</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.23.16.2\">0.021</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.23.16.3\">0.885</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.23.16.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.23.16.5\">0.056</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.23.16.6\">0.814</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.23.16.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.23.16.8\">0.095</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.23.16.9\">0.999</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.23.16.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.24.17\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.24.17.1\">Grad\u00d7I vs IntGrad\u00d7I</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.24.17.2\">0.536</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.24.17.3\">0.464</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.24.17.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.24.17.5\">0.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.24.17.6\">1.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.24.17.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.24.17.8\">1.544</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.24.17.9\">0.819</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.24.17.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.25.18\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.25.18.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T6.6.25.18.1.1\" style=\"background-color:#BFBFBF;\">Grad\u00d7I vs Human</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.25.18.2\">8.595</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.25.18.3\">0.003*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.25.18.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.25.18.5\">7.181</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.25.18.6\">0.007*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.25.18.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.25.18.8\">10.212</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.25.18.9\">0.037*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.25.18.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.26.19\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.26.19.1\">IntGrad vs IntGrad\u00d7I</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.26.19.2\">0.195</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.26.19.3\">0.659</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.26.19.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.26.19.5\">0.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.26.19.6\">1.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.26.19.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.26.19.8\">1.242</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.26.19.9\">0.871</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.26.19.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.27.20\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"A1.T6.6.27.20.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T6.6.27.20.1.1\" style=\"background-color:#BFBFBF;\">IntGrad vs Human</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.27.20.2\">7.018</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.27.20.3\">0.008*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.27.20.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.27.20.5\">5.158</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.27.20.6\">0.023*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T6.6.27.20.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.27.20.8\">9.381</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.27.20.9\">0.052</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T6.6.27.20.10\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.6.28.21\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\" id=\"A1.T6.6.28.21.1\" style=\"background-color:#BFBFBF;\"><span class=\"ltx_text\" id=\"A1.T6.6.28.21.1.1\" style=\"background-color:#BFBFBF;\">IntGrad\u00d7I vs Human</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"A1.T6.6.28.21.2\">4.287</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"A1.T6.6.28.21.3\">0.038*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"A1.T6.6.28.21.4\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"A1.T6.6.28.21.5\">6.157</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"A1.T6.6.28.21.6\">0.013*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"A1.T6.6.28.21.7\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"A1.T6.6.28.21.8\">4.876</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"A1.T6.6.28.21.9\">0.300</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"A1.T6.6.28.21.10\">4</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"A1.T6.8.1.1\" style=\"font-size:90%;\">Table 6</span>: </span><span class=\"ltx_text\" id=\"A1.T6.9.2\" style=\"font-size:90%;\">Chi-Square test results for comparing different methods on their preference for stop words, punctuation and POS. Asterisk (*) indicates statistical significance at the 0.05 level. A dark background visually highlights the hypothesised Group 1 \u2013 Group 2 comparisons.</span></figcaption>\n</figure>",
            "capture": "Table 6: Chi-Square test results for comparing different methods on their preference for stop words, punctuation and POS. Asterisk (*) indicates statistical significance at the 0.05 level. A dark background visually highlights the hypothesised Group 1 \u2013 Group 2 comparisons."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.19424v1_figure_1.png",
            "caption": "Figure 1: Top-k\ud835\udc58kitalic_k highlights (light background) per attribution method and human preference for k=4\ud835\udc584k=4italic_k = 4. The syntactic spans are given underneath."
        },
        "2": {
            "figure_path": "2403.19424v1_figure_2.png",
            "caption": "(a) Relative frequency for important stop words, k=4\ud835\udc584k=4italic_k = 4."
        },
        "3": {
            "figure_path": "2403.19424v1_figure_3.png",
            "caption": "(b) Relative frequency for important punctuation, k=4\ud835\udc584k=4italic_k = 4."
        },
        "4": {
            "figure_path": "2403.19424v1_figure_4.png",
            "caption": "(c) Relative frequency for important POS, k=4\ud835\udc584k=4italic_k = 4. We consider the 5 most preferred POS tags by humans."
        },
        "5": {
            "figure_path": "2403.19424v1_figure_5.png",
            "caption": "(a) Mean span agreement@k=4\ud835\udc584k=4italic_k = 4."
        },
        "6": {
            "figure_path": "2403.19424v1_figure_6.png",
            "caption": "(b) Mean span agreement@k=\ud835\udc58absentk=italic_k = dynamic."
        }
    },
    "references": [
        {
            "1": {
                "title": "Contextual string embeddings for sequence labeling.",
                "author": "Alan Akbik, Duncan Blythe, and Roland Vollgraf. 2018.",
                "venue": "In COLING 2018, 27th International Conference on Computational Linguistics, pages 1638\u20131649.",
                "url": null
            }
        },
        {
            "2": {
                "title": "Faithfulness tests for natural language explanations.",
                "author": "Pepa Atanasova, Oana-Maria Camburu, Christina Lioma, Thomas Lukasiewicz, Jakob Grue Simonsen, and Isabelle Augenstein. 2023.",
                "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 283\u2013294, Toronto, Canada. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2023.acl-short.25"
            }
        },
        {
            "3": {
                "title": "A diagnostic study of explainability techniques for text classification.",
                "author": "Pepa Atanasova, Jakob Grue Simonsen, Christina Lioma, and Isabelle Augenstein. 2020.",
                "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 3256\u20133274.",
                "url": null
            }
        },
        {
            "4": {
                "title": "Benchmarking post-hoc interpretability approaches for transformer-based misogyny detection.",
                "author": "Giuseppe Attanasio, Debora Nozza, Eliana Pastor, Dirk Hovy, et al. 2022.",
                "venue": "In Proceedings of NLP Power! The First Workshop on Efficient Benchmarking in NLP. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "5": {
                "title": "ferret: a framework for benchmarking explainers on transformers.",
                "author": "Giuseppe Attanasio, Eliana Pastor, Chiara Di Bonaventura, and Debora Nozza. 2023.",
                "venue": "In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations, pages 256\u2013266, Dubrovnik, Croatia. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2023.eacl-demo.29"
            }
        },
        {
            "6": {
                "title": "From intermediate representations to explanations: Exploring hierarchical structures in nlp.",
                "author": "Housam KB Babiker, Mi-Young Kim, and Randy Goebel. 2023.",
                "venue": "In ECAI 2023, pages 157\u2013164. IOS Press.",
                "url": null
            }
        },
        {
            "7": {
                "title": "\u201cwill you find these shortcuts?\u201d a protocol for evaluating the faithfulness of input salience methods for text classification.",
                "author": "Jasmijn Bastings, Sebastian Ebert, Polina Zablotskaia, Anders Sandholm, and Katja Filippova. 2022.",
                "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 976\u2013991, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2022.emnlp-main.64"
            }
        },
        {
            "8": {
                "title": "The legal argument reasoning task in civil procedure.",
                "author": "Leonard Bongard, Lena Held, and Ivan Habernal. 2022.",
                "venue": "In Proceedings of the Natural Legal Language Processing Workshop 2022, pages 194\u2013207.",
                "url": null
            }
        },
        {
            "9": {
                "title": "Can i trust the explainer? verifying post-hoc explanatory methods.",
                "author": "Oana-Maria Camburu, Eleonora Giunchiglia, Jakob Foerster, Thomas Lukasiewicz, and Phil Blunsom. 2019.",
                "venue": "arXiv preprint arXiv:1910.02065.",
                "url": null
            }
        },
        {
            "10": {
                "title": "Evaluating and characterizing human rationales.",
                "author": "Samuel Carton, Anirudh Rathore, and Chenhao Tan. 2020.",
                "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 9294\u20139307, Online. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2020.emnlp-main.747"
            }
        },
        {
            "11": {
                "title": "A fast and accurate dependency parser using neural networks.",
                "author": "Danqi Chen and Christopher D Manning. 2014.",
                "venue": "In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 740\u2013750.",
                "url": null
            }
        },
        {
            "12": {
                "title": "Interpretation of black box nlp models: A survey.",
                "author": "Shivani Choudhary, Niladri Chatterjee, and Subir Kumar Saha. 2022.",
                "venue": "arXiv preprint arXiv:2203.17081.",
                "url": null
            }
        },
        {
            "13": {
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding.",
                "author": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.",
                "venue": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171\u20134186, Minneapolis, Minnesota. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/N19-1423"
            }
        },
        {
            "14": {
                "title": "Towards faithfully interpretable nlp systems: How should we define and evaluate faithfulness?",
                "author": "Alon Jacovi and Yoav Goldberg. 2020.",
                "venue": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4198\u20134205.",
                "url": null
            }
        },
        {
            "15": {
                "title": "Attention is not explanation.",
                "author": "Sarthak Jain and Byron C Wallace. 2019.",
                "venue": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 3543\u20133556.",
                "url": null
            }
        },
        {
            "16": {
                "title": "How can i choose an explainer? an application-grounded evaluation of post-hoc explanations.",
                "author": "S\u00e9rgio Jesus, Catarina Bel\u00e9m, Vladimir Balayan, Jo\u00e3o Bento, Pedro Saleiro, Pedro Bizarro, and Jo\u00e3o Gama. 2021.",
                "venue": "In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pages 805\u2013815.",
                "url": null
            }
        },
        {
            "17": {
                "title": "Feature interactions reveal linguistic structure in language models.",
                "author": "Jaap Jumelet and Willem Zuidema. 2023.",
                "venue": "In Findings of the Association for Computational Linguistics: ACL 2023, pages 8697\u20138712, Toronto, Canada. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2023.findings-acl.554"
            }
        },
        {
            "18": {
                "title": "Dynamic top-k estimation consolidates disagreement between feature attribution methods.",
                "author": "Jonathan Kamp, Lisa Beinborn, and Antske Fokkens. 2023.",
                "venue": "In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 6190\u20136197, Singapore. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2023.emnlp-main.379"
            }
        },
        {
            "19": {
                "title": "Multilingual constituency parsing with self-attention and pre-training.",
                "author": "Nikita Kitaev, Steven Cao, and Dan Klein. 2019.",
                "venue": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3499\u20133505, Florence, Italy. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/P19-1340"
            }
        },
        {
            "20": {
                "title": "The disagreement problem in explainable machine learning: A practitioner\u2019s perspective.",
                "author": "Satyapriya Krishna, Tessa Han, Alex Gu, Javin Pombra, Shahin Jabbari, Steven Wu, and Himabindu Lakkaraju. 2022.",
                "venue": "arXiv preprint arXiv:2202.01602.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Many faces of feature importance: Comparing built-in and post-hoc feature importance in text classification.",
                "author": "Vivian Lai, Zheng Cai, and Chenhao Tan. 2019.",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 486\u2013495.",
                "url": null
            }
        },
        {
            "22": {
                "title": "A unified approach to interpreting model predictions.",
                "author": "Scott M Lundberg and Su-In Lee. 2017.",
                "venue": "Advances in neural information processing systems, 30.",
                "url": null
            }
        },
        {
            "23": {
                "title": "Post-hoc interpretability for neural nlp: A survey.",
                "author": "Andreas Madsen, Siva Reddy, and Sarath Chandar. 2022.",
                "venue": "ACM Computing Surveys, 55(8):1\u201342.",
                "url": null
            }
        },
        {
            "24": {
                "title": "Rethinking self-attention: Towards interpretability in neural parsing.",
                "author": "Khalil Mrini, Franck Dernoncourt, Quan Hung Tran, Trung Bui, Walter Chang, and Ndapandula Nakashole. 2020.",
                "venue": "In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 731\u2013742.",
                "url": null
            }
        },
        {
            "25": {
                "title": "A song of (dis) agreement: Evaluating the evaluation of explainable artificial intelligence in natural language processing.",
                "author": "Michael Neely, Stefan F Schouten, Maurits Bleeker, and Ana Lucic. 2022.",
                "venue": "In HHAI2022: Augmenting Human Intellect, pages 60\u201378. IOS Press.",
                "url": null
            }
        },
        {
            "26": {
                "title": "AGREE: a feature attribution aggregation framework to address explainer disagreements with alignment metrics.",
                "author": "Craig Pirie, Nirmalie Wiratunga, Anjana Wijekoon, and Carlos Francisco Moreno-Garcia. 2023.",
                "venue": "In Proceedings of the Workshops at the 31st International Conference on Case-Based Reasoning (ICCBR-WS 2023), pages 184\u2013199. CEUR.",
                "url": null
            }
        },
        {
            "27": {
                "title": "The logic of scientific discovery.",
                "author": "Karl Popper. 2005.",
                "venue": "Routledge.",
                "url": null
            }
        },
        {
            "28": {
                "title": "Evaluating explanations: How much do explanations from the teacher aid students?",
                "author": "Danish Pruthi, Rachit Bansal, Bhuwan Dhingra, Livio Baldini Soares, Michael Collins, Zachary C Lipton, Graham Neubig, and William Cohen. 2022.",
                "venue": "Transactions of the Association for Computational Linguistics, 10:359\u2013375.",
                "url": null
            }
        },
        {
            "29": {
                "title": "Towards interpreting bert for reading comprehension based qa.",
                "author": "Sahana Ramnath, Preksha Nema, Deep Sahni, and Mitesh M Khapra. 2020.",
                "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 3236\u20133242.",
                "url": null
            }
        },
        {
            "30": {
                "title": "Toward transparent ai: A survey on interpreting the inner structures of deep neural networks.",
                "author": "Tilman R\u00e4uker, Anson Ho, Stephen Casper, and Dylan Hadfield-Menell. 2023.",
                "venue": "In 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), pages 464\u2013483. IEEE.",
                "url": null
            }
        },
        {
            "31": {
                "title": "\u201cwhy should I trust you?\u201d: Explaining the predictions of any classifier.",
                "author": "Marco Ribeiro, Sameer Singh, and Carlos Guestrin. 2016.",
                "venue": "In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations, pages 97\u2013101, San Diego, California. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/N16-3020"
            }
        },
        {
            "32": {
                "title": "Why don\u2019t xai techniques agree? characterizing the disagreements between post-hoc explanations of defect predictions.",
                "author": "Saumendu Roy, Gabriel Laberge, Banani Roy, Foutse Khomh, Amin Nikanjam, and Saikat Mondal. 2022.",
                "venue": "In 2022 IEEE International Conference on Software Maintenance and Evolution (ICSME), pages 444\u2013448. IEEE.",
                "url": null
            }
        },
        {
            "33": {
                "title": "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter.",
                "author": "Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019.",
                "venue": "arXiv preprint arXiv:1910.01108.",
                "url": null
            }
        },
        {
            "34": {
                "title": "Learning important features through propagating activation differences.",
                "author": "Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje. 2017.",
                "venue": "In Proceedings of the 34th International Conference on Machine Learning - Volume 70, ICML\u201917, page 3145\u20133153. JMLR.org.",
                "url": null
            }
        },
        {
            "35": {
                "title": "Integrated directional gradients: Feature interaction attribution for neural nlp models.",
                "author": "Sandipan Sikdar, Parantapa Bhattacharya, and Kieran Heese. 2021.",
                "venue": "In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 865\u2013878.",
                "url": null
            }
        },
        {
            "36": {
                "title": "Deep inside convolutional networks: visualising image classification models and saliency maps.",
                "author": "K Simonyan, A Vedaldi, and A Zisserman. 2014.",
                "venue": "In Proceedings of the International Conference on Learning Representations (ICLR). ICLR.",
                "url": null
            }
        },
        {
            "37": {
                "title": "Automatic counterfactual augmentation for robust text classification based on word-group search.",
                "author": "Rui Song, Fausto Giunchiglia, Yingji Li, and Hao Xu. 2023.",
                "venue": "arXiv preprint arXiv:2307.01214.",
                "url": null
            }
        },
        {
            "38": {
                "title": "Axiomatic attribution for deep networks.",
                "author": "Mukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017.",
                "venue": "In International conference on machine learning, pages 3319\u20133328. PMLR.",
                "url": null
            }
        },
        {
            "39": {
                "title": "Named entity recognition and dependency parsing for better concept extraction in summary obfuscation detection.",
                "author": "Umar Taufiq, Reza Pulungan, and Yohanes Suyanto. 2023.",
                "venue": "Expert Systems with Applications, 217:119579.",
                "url": null
            }
        },
        {
            "40": {
                "title": "Parsing all: Syntax and semantics, dependencies and spans.",
                "author": "Junru Zhou, Zuchao Li, and Hai Zhao. 2020.",
                "venue": "In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 4438\u20134449, Online. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2020.findings-emnlp.398"
            }
        },
        {
            "41": {
                "title": "e-snli: Natural language inference with natural language explanations.",
                "author": "Camburu, Oana-Maria and Rockt\u00e4schel, Tim and Lukasiewicz, Thomas and Blunsom, Phil. 2018.",
                "venue": "GitHub Repository without PID/islrn: https://github.com/OanaMariaCamburu/e-SNLI.",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.19424v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.1",
            "2.2",
            "2.3"
        ],
        "methodology_sections": [
            "3.1",
            "3.2",
            "3.3",
            "3.4"
        ],
        "main_experiment_and_results_sections": [
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "3.1",
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "research_context": {
        "paper_id": "2403.19424v1",
        "paper_title": "The Role of Syntactic Span Preferences in Post-Hoc Explanation Disagreement",
        "research_background": "The paper \"The Role of Syntactic Span Preferences in Post-Hoc Explanation Disagreement\" addresses the motivation, research problem, and relevant prior work related to interpretability in transformer-based NLP models. Below, these elements are detailed using the paper's original wording and phrases as much as possible.\n\n### Motivation\nThe primary motivation of this study is to investigate the disagreement among post-hoc explanation methods when ranking token importance in transformer-based NLP models. The authors are concerned with the faithfulness of these explanation methods, given that methods tend to disagree significantly on which tokens are most important for prediction. It is hypothesized that agreement might be systematically higher at the span level, i.e., when considering the linguistic spans to which tokens belong, rather than at the individual token level. This is suggested by initial observations that methods often highlight similar linguistic structures like verb phrases and noun phrases, though they may select different specific tokens within those structures.\n\n### Research Problem\nThe research problem tackled in this paper is multifaceted:\n1. **Disagreement Between Methods**: The study aims to determine to what extent different post-hoc explanation methods, such as LIME and Integrated Gradient, disagree in their token-level attributions and how this disagreement impacts the interpretation of transformer-based models' behavior.\n2. **Span-Level Agreement**: The authors seek to explore whether considering syntactic spans rather than individual tokens can lead to higher agreement between different explanation methods.\n3. **Word Class Preferences**: The paper examines the preferences of different methods for specific word classes (e.g., nouns, adjectives) and investigates the extent to which these preferences contribute to method-method agreement.\n4. **Dynamic Selection of Top-k Tokens**: The study also looks into dynamically determining the number of top tokens (k) based on their attribution scores, contrasting this with the common practice of fixing k across instances.\n\n### Relevant Prior Work\nThe authors reference several prior works to contextualize their study:\n1. **Post-Hoc Explanation Methods**: Standard post-hoc explanation techniques like LIME (Ribeiro et al., 2016) and Integrated Gradient (Sundararajan et al., 2017) have been considered, which aim to attribute importance scores to individual features (tokens).\n2. **Disagreement Among Methods**: Neely et al. (2022) noted the variance and disagreement among these methods in ranking token importance.\n3. **Faithfulness of Explanations**: Jain and Wallace (2019) proposed the notion that explanations faithful to the inner mechanisms of the transformer model should exhibit agreement.\n4. **Syntactic Preferences**: Ramnath et al. (2020) reported part-of-speech (POS) preferences in different layers of BERT using Integrated Gradient analysis.\n5. **Top-k Selection**: Prior approaches like those of Jesus et al. (2021), Camburu et al. (2019), and Kamp et al. (2023), which focus on selecting the top-k tokens for comparison, are examined, especially in the context of dynamically deciding k (e.g., Kamp et al. (2023) proposed detecting signal peaks in the input rather than setting a fixed k).\n\nBy addressing these various aspects, the paper aims to provide a more nuanced understanding of how explanation methods target different linguistic structures and how dynamic token selection can enhance interpretability and agreement in model explanations.",
        "methodology": "### Methodology\n\nIn this study, we investigate the disagreement problem among various attribution methods applied to a natural language inference (NLI) task. Specifically, we evaluate six attribution methods within this task to test our hypothesis in line with the experimental setup provided by Kamp et al. (2023).\n\n### Experimental Setup\n\n**Dataset and Model:**\n- **Dataset:** We use the e-SNLI dataset (Camburu et al., 2018) with its default training split, which consists of 549,361 instances.\n- **Backbone Model:** DistilBERT (Sanh et al., 2019) is finetuned on the dataset using 10 different random seeds. After training, we choose the model displaying the least variation in attribution profiles on the default test split (comprising 9,842 instances) for further analysis. This model achieves an F1 score of 0.89.\n- **Instances:** Each instance in the dataset is generated by concatenating a premise with a hypothesis. The output labels are multi-class (contradiction, entailment, neutral) and balanced, describing the relationship between the premise and hypothesis.\n\n**Human Rationales:**\n- Each word in every instance is annotated for importance towards the output label by three human annotators. On average, 43 words per instance are annotated as important.\n- From these annotations, we derive word-level aggregation scores ranging between 0 and 1. These scores represent the proportion of annotators who identified a word as important. They are used to compare with the attribution scores from automated methods, especially when considering a top-k word selection.\n\n### Attribution Methods\n\nWe use both gradient-based and perturbation-based attribution methods:\n\n1. **Gradient-Based Methods:**\n   - **Vanilla Gradient (Simonyan et al., 2014)**\n   - **Integrated Gradient (Sundararajan et al., 2017)**\n   - Both methods are also evaluated in a version where attributions are multiplied by the input values (Shrikumar et al., 2017).\n\n2. **Perturbation-Based Methods:**\n   - **Partition SHAP (Lundberg and Lee, 2017)**\n   - **LIME (Ribeiro et al., 2016)**\n\nTo carry out these evaluations and analyses, we utilize the Ferret package v0.4.1 (Attanasio et al., 2023).\n\n### Analysis and Comparison\n\nWe focus on comparing the attribution scores generated by these methods to human-derived preference scores. This comparison is crucial for understanding the extent of agreement or disagreement between human rationale and automated attribution methods when identifying important words in the NLI task. By following these steps, we aim to uncover the role of syntactic span preferences and how they contribute to post-hoc explanation disagreement.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n#### Dataset and Model Configurations\nThe dataset, model configurations, and pool of attribution methods utilized in the main experiment are identical to those described in the linguistic analysis section. Additionally, we adopt the span definitions as specified. Therefore, our data is available in two versions: one where the instances are divided into tokens and another where instances are split into spans.\n\n#### Evaluation Metrics\nWe measure the role of syntactic span preferences in post-hoc explanation disagreement by analyzing and comparing attributions in the two versions of our dataset (token-based and span-based formats).\n\n#### Main Experimental Results\nThe main experimental results focus on understanding how syntactic span preferences influence the disagreements observed in post-hoc explanations when different attribution methods are applied. Specific quantitative results or comparative analyses underlying these observations are not detailed in the provided excerpt, but the setup highlights the impact of span definitions on attribution evaluations."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "Analyze the disagreement problem across six different attribution methods on a natural language inference task to identify linguistic spans that models consider important.",
            "experiment_process": "The study uses the e-SNLI dataset to fine-tune DistilBERT on 10 different random seeds, employing six attribution methods: Vanilla Gradient, Integrated Gradient, Gradient\u00d7Input, Integrated Gradient\u00d7Input, Partition SHAP, and LIME. Classes are balanced and are labeled as contradiction, entailment, or neutral. Words in every instance are annotated as important or not by human annotators, yielding word-level aggregation scores. Human preferences are compared to the top-k selection of attribution scores.",
            "result_discussion": "Different methods systematically select different classes of words, and methods with higher agreement with humans display similar linguistic preferences. Token-level differences are smoothed out when compared on a syntactic span level, suggesting higher agreement.",
            "ablation_id": "2403.19424v1.No1"
        },
        {
            "research_objective": "Evaluate the effect of dynamically estimated top-k (k*) for identifying important spans versus fixed k in a natural language inference task.",
            "experiment_process": "Adopt the same dataset, model configurations, and attribution methods as in the previous study. Instances are split into tokens and spans. Agreement@k is measured by comparing the subset of tokens with the highest attribution scores for pairs of methods. The baseline agreement is computed by pseudo-randomly shuffling two binary vectors. The effect of dynamic k* is compared to fixed k.",
            "result_discussion": "Dynamic k* significantly increases agreement on the span level compared to fixed k, with larger positive effects specifically for Gradient\u00d7Input and Integrated Gradient. Pairwise agreement scores show that dynamic k* outperforms the baseline, indicating it is better at highlighting important spans.",
            "ablation_id": "2403.19424v1.No2"
        },
        {
            "research_objective": "Validate and improve the dynamic k* algorithm to ensure resulting k values are close to human preferences and outperform baselines.",
            "experiment_process": "Different thresholds for estimating dynamic k* are explored, including mean\u00b1standard deviation (\u03bc\u00b1\u03c3) and median. Positive scores exclude attributions with negative importance. Agreement scores for each method are compared against a baseline where scores are shuffled, testing token-level and span-level agreement.",
            "result_discussion": "Threshold \u03bc-\u03c3 maintains low k close to human preference and outperforms baselines, showing it is an effective threshold for dynamic k*. Integrated Gradient and Gradient\u00d7Input have higher baseline agreements, indicating they may be unreliable due to high k values. The threshold \u03bc-\u03c3 appears to more accurately target important tokens and spans.",
            "ablation_id": "2403.19424v1.No3"
        }
    ]
}