{
    "title": "Generalization Measures for Zero-Shot Cross-Lingual Transfer",
    "abstract": "A model\u2019s capacity to generalize its knowledge to interpret unseen inputs with different characteristics is crucial to build robust and reliable machine learning systems. Language model evaluation tasks lack information metrics about model generalization and their applicability in a new setting is measured using task and language-specific downstream performance, which is often lacking in many languages and tasks. In this paper, we explore a set of efficient and reliable measures that could aid in computing more information related to the generalization capability of language models in cross-lingual zero-shot settings. In addition to traditional measures such as variance in parameters after training and distance from initialization, we also measure the effectiveness of sharpness in loss landscape in capturing the success in cross-lingual transfer and propose a novel and stable algorithm to reliably compute the sharpness of a model optimum that correlates to generalization. 111Code: https://anonymous.4open.science/r/strikegen-7288",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Generalization enables models to use prior knowledge to reasonably respond to previously unseen stimuli. Although traditional machine learning evaluation is performed based on a preselected set of prediction or generation tasks, accuracy on many public benchmarks may often not be sufficient to extensively assess the ability to perform well in new settings. Therefore, a majority of researchers have found it worthwhile to investigate measures that could evaluate the generalization capability of models with properties, such as VC dimension Vapnik & Chervonenkis (1971), cross-entropy Shannon (1948), complexity Mohri et al. (2012), or variation in parameters during training Nagarajan & Kolter (2019).\n\nAmong these, recent findings support the smoothness in the loss curvature to correlate best with generalization capability Chaudhari et al. (2019); Petzka et al. (2021); Kaddour et al. (2022), motivating the development of learning methods that induce smoothness in the learning trajectory such that the model becomes more robust; either through data perturbation Jiang et al. (2020a); Aghajanyan et al. (2021); Liang et al. (2021); Hua et al. (2021); Park et al. (2022); Zheng et al. (2021); Wang et al. (2021); Huang et al. (2021) or by integrating the measure directly to the optimization objective Izmailov et al. (2018); Jastrzebski et al. (2021); Cha et al. (2021); Foret et al. (2021); Hu et al. (2022); Zaken et al. (2022); Stickland & Murray (2021). However, it might often not be straightforward to compute such measures in high-dimensional feature space in a stable fashion Nachum et al. (2024).\n\nAs models get larger and cover more languages, the possibility of improving the applicability of NLP systems in many under-resourced languages gets more promising. An essential requirement in studying the dynamics of cross-lingual knowledge transfer is to have an evaluation methodology that can reliably measure the model\u2019s capability in generalization of knowledge under different scenarios. There is a common hypothesis that states that a model demonstrating an extended flat optimum area of low loss value surrounding the minimized loss is indicative of better generalization capability. \n\nWe pick prominent measures that were previously shown to correlate well with generalization performance Jiang et al. (2020b), such as the Frobenius distance of the learned parameters after training Nagarajan & Kolter (2019), the margin between model predictions and true labels Wei et al. (2018), and sharpness in loss minima to test applicability to zero-shot cross-lingual generalization measurement Keskar et al. (2017); Foret et al. (2021).\n\nWe also extend the formulation of state-of-the-art sharpness computation methods Keskar et al. (2017); Foret et al. (2021) to provide a sharpness prediction algorithm such that the optimization of the parameters can converge in a more stable fashion."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related work",
            "text": "Loss-landscape Minima One of the most promising indicators of generalization capability to date seems to be related to the form of the loss landscape, in particular, the sharpness in the loss curvature. A potential reason for this fallback is traced to stochastic gradient descent (SGD) Bottou (2012  ###reference_b2###) methods which often fall into sharp minima of the loss surface Keskar et al. (2017  ###reference_b20###); Chaudhari et al. (2019  ###reference_b4###); Wang et al. (2021  ###reference_b34###).\nAlthough clear conclusions on the relationship between sharpness and generalization performance, such as whether sharper Dinh et al. (2017  ###reference_b8###) vs. flatter Li et al. (2018  ###reference_b21###); Keskar et al. (2017  ###reference_b20###) minima would generally yield better generalization, are still due.\nThe main idea behind these methods is that their objective is to explicitly find flat minima, often using stochastic averaging methods Polyak & Juditsky (1992  ###reference_b30###); Izmailov et al. (2018  ###reference_b15###), mini-max or sharpness-aware minimization methods, which can be computed by direct formulation based on the Hessian matrix of the loss function Chaudhari et al. (2019  ###reference_b4###); Petzka et al. (2021  ###reference_b29###) or Monte-Carlo approximations of the minimizer\u2019s neighborhood Foret et al. (2021  ###reference_b11###); Cha et al. (2021  ###reference_b3###).\nAdversarial optimization Comparison of two approaches finds that for NLP tasks, mini-max methods are more competitive over averaging-based optimization Kaddour et al. (2022  ###reference_b19###). Jastrzebski et al. (2021  ###reference_b16###) hypothesize that regularizing the trace of the Fisher information matrix amplifies the implicit bias of SGD, which prevents memorization. The Fisher information Fisher (1925  ###reference_b10###) measures local curvature, so a smaller trace implies a flatter minimum, which gives the model more freedom to reach an optimum. Instead of explicitly minimizing the values of parameters, Foret et al. (2021  ###reference_b11###) propose minimizing both loss and sharpness while optimizing the parameters such that they lie in neighborhoods with low loss values. Perturbation is an auxiliary objective that encourages the model predictions to be similar in the vicinity of the observed training samples Englesson & Azizpour (2021  ###reference_b9###), usually by penalizing the KL-divergence between the probability distribution of the perturbed and normal model.\nPerturbations can be adversarial inputs Jiang et al. (2020a  ###reference_b17###) or inputs with Gaussian or uniform noise Aghajanyan et al. (2021  ###reference_b1###). To improve cross-lingual generalization, translations of the input generated by machine translation systems were used as perturbed input Wang et al. (2021  ###reference_b34###); Zheng et al. (2021  ###reference_b40###). Other work also has found the benefit of enforcing consistency for perturbations within the model in addition to the input distribution Liang et al. (2021  ###reference_b22###); Hua et al. (2021  ###reference_b13###)."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Methodology",
            "text": "In this study, we undertake the development of a methodology that could benefit an accurate assessment of the generalization capability of models for the purpose of cross-lingual knowledge transfer into under-resourced languages. This section first presents approaches to improving generalization performance and the selected measures that provide stable results for measuring zero-shot cross-lingual transfer performance."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Sharpness-based Optimization",
            "text": "We chose the following objective functions as fine-tuning methods for a given pre-trained model as a means of comparison since their main purpose is to enhance the generalization and robustness of models. Following the work of Stickland & Murray (2021  ###reference_b32###), as the two most prominent approaches to mini-max optimization, we include Sharpness-Aware Minimization (SAM) Foret et al. (2021  ###reference_b11###) and regularization with Fisher Information Matrix (FIM) Jastrzebski et al. (2021  ###reference_b16###) in our evaluation study on cross-lingual generalization.We also include Multi-view Subword Regularization (MVR) as a perturbation-based optimization method Wang et al. (2021  ###reference_b34###) which induces stochasticity into the shared subword vocabulary across languages for easing cross-lingual transfer.\nSAM Foret et al. (2021  ###reference_b11###) works on the principle of a mini-max objective function: , which essentially means the optimizing function tries to minimize the maximum loss value in a given radius in loss landscape. Therefore, SAM states that it tries to seek \u201dparameters lying in uniformly low-loss neighborhoods\u201d.\nFisher Penalty is defined as explicitly penalizing the trace of the Fisher information matrix (FIM). Jastrzebski et al. (2021  ###reference_b16###), Stickland & Murray (2021  ###reference_b32###) observed penalizing FIM during training correlates to better generalization performance. It can be written mathematically as  where  is the loss at the data point .\nMVR Wang et al. (2021  ###reference_b34###) function on the concept of consistency regularization where the divergence between the model predictions on deterministic and probabilistic segmentation inputs is minimized. The objective function is formulated as\nwhere the first term is the model loss on deterministic segmentation of the  data sample (most probable segmentation), the second term is the model loss on probabilistic segmentation of the  data sample (random segmentation) and the third term is the KL divergence between these two output predictions. This technique influences the model to be consistent on the predictions of different input types which successively motivates the model to be more adversarially robust."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Generalization Measures",
            "text": "Our study aims to investigate which type and characteristics of methods would best correlate with better performance in generalization, in this case, zero-shot cross-lingual transfer. We are especially interested in confirming the applicability of the flatness hypothesis for cross-lingual generalization. In order to assess whether a flat optimum loss-scape region corresponds to generalization, we essentially break down the experiment to measure two things, flatness, and generalization, such that their correlation can be measured.\nJiang et al. (2020b  ###reference_b18###) conducted an extensive study on image classification tasks using generalization measures such as flatness-based measures (sharpness metrics), margin and norm-based metrics (based on parameter norms and distance from initial weights) to find correlations between measures and model performance which supported the usability of measures. These measures can be useful to explore the capabilities of language models to transfer knowledge from high-resource languages to low-resource ones."
        },
        {
            "section_id": "3.2.x",
            "parent_section_id": "3.2",
            "section_name": "Margin",
            "text": "Higher certainty in predicting the correct label leads to a model that is robust to perturbations and unseen examples. Margin is the distinction between model prediction for ground truth label and the next highest prediction probability. We use an average based margin formula defined by Wei et al. (2018  ###reference_b35###) to calculate margin values on the entire test set. Jiang et al. (2020b  ###reference_b18###) observed that the margin was directly proportional to better generalization in the image classification tasks. Margin is\nwhere  is the  input to model,  is the ground truth label,  is the model function. A larger value of the margin of a model on a given dataset would mean higher confidence in the model to predict the correct label - including unseen examples (from languages not included in fine-tuning)."
        },
        {
            "section_id": "3.2.x",
            "parent_section_id": "3.2",
            "section_name": "Sharpness of optimum",
            "text": "In simpler terms, we can define sharpness as the change in the model loss value at two neighboring points in the model weights plane. It can also be loosely interpreted as the inverse of the maximum radius the loss function can sustain a low loss value at the optimum. Sharpness-based measures resulted in the highest correlation with generalization in Jiang et al. (2020b  ###reference_b18###).\nJiang et al. (2020b  ###reference_b18###) formulates the sharpness to be\nsuch that , where  is the maximum radius in the model\u2019s loss landscape possible,  and  are the models finetuned weights and model initial weights respectively,  is the number of parameters,  is the total number of observations,  is the standard deviation of Gaussian noise added. In this work, as we are comparing models with the same architecture (considering mBERT only), on the same dataset, we can remove the constants, and simplify the equation further for comparative analysis.\nIntuitively, if the radius of the low-loss region in the loss-landscape () is small, that means the model has a higher loss value near the optimum, which would mean the landscape of the optimum is not flat. We can relate this to resulting in an unstable prediction when having perturbations in either the data or model weights. Jiang et al.  ###reference_b18###\u2019s formula didn\u2019t result in stable results for our experimental set-up which might be because the ascent steps taken to optimize the  value resulted in either having a large or a very small final . The values of  occurred at extreme points because the algorithm was using a binary search method and whenever optimal  was not found, the search algorithm stopped with the final  value at either of the extreme points. The correlation results of the above sharpness method are shown in Table 3  ###reference_###.\nWe present an alternative definition (inclined with sharpness measure mentioned in the works of Keskar et al.  ###reference_b20###, and Foret et al.  ###reference_b11###),  that removes the need to optimize  by calculating the difference between loss values at two points in the optimum region, formulated as\nwhere  is  ( being Gaussian noise) and  is the optimum weight parameters. The details of our definition are in Algorithm 1  ###reference_### and performs calculation at about roughly 5-10 times faster than Jiang et al.  ###reference_b18###\u2019s algorithm for a given batch size of 8."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "For comparison, we implement each Sharpness-based optimization as a fine-tuning objective on the multilingual mBERT base variant (bert-base-multilingual-cased from huggingface) Devlin et al. (2019) in addition to mT5 model (google/mt5-small) Xue et al. (2021). We use a linear classification layer of size 768x3 where the output dimension is equal to the number of labels. We adopt a two-step training approach in our experiments."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Data, Model details, and Settings",
            "text": "We fine-tune pretrained mBERT models for 15 epochs each with a batch size of 32, with a learning rate of , and select best checkpoint on validation. The objective function we use for the baseline model with the classification layer is the AdamW optimizer Loshchilov & Hutter (2019) with cross-entropy loss, the mBERT+FIM model has an additional loss as Fisher Penalty, the mBERT+SAM model uses the SAM optimizer and mBERT+MVR uses the MVR algorithm for fine-tuning. We use the hyperparameters and code presented in XTREME222https://github.com/google-research/xtreme and MVR codebase333https://github.com/cindyxinyiwang/multiview-subword-regularization. We run the models with 8 random seeds and present the average performance of these models. In Algorithm 1, the amount of Gaussian noise we add to model weights during calculating sharpness is controlled using a scale that we empirically find (among [0.001, 0.005, 0.01, 0.02]) for each model, with equal to 0.05.\n\nAdditional experiments were run on PAWS-X dataset Yang et al. (2019) which has 7 languages: German \"de\", English \"en\", Spanish \"es\", French \"fr\", Japanese \"ja\", Korean \"ko\", Chinese \"zh\". We use similar experimentation of fine-tuning on English and doing a zero-shot transfer on 6 other languages as defined above for this dataset. We used Huggingface\u2019s models: mBERT (bert-base-multilingual-cased), RoBERTa (roberta-base), and XLM (xlm-mlm-en-2048) using Adam optimizers."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "Enabling cross-lingual knowledge transfer is an important step towards extending the applicability of NLP models to more languages. Despite recent efforts to develop better optimization methods for improving the generalization of language models in new languages or domains; these techniques try different types of methods to achieve higher performance such as sharpness-based minimizations, reducing gradient of loss functions, or consistency regularization. Evaluating these techniques thoroughly without a standardized methodology remains a difficult task. This work aims to uncover insights into how to measure cross-lingual generalization by exploring suitable measures that work well under different settings. Our experiments studying model loss landscape and parameter properties find strong relationships between the margin, sharpness in the loss minima neighborhood, and zero-shot cross-lingual downstream task performance, both on validation and test sets, supporting strong applicability to evaluate models before deploying them in new languages."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Limitations",
            "text": "The algorithm presented in our paper, the difference-based sharpness measure, is a great novelty for more robust sharpness computation, however, we would like to acknowledge that a few variables in the algorithm still require tuning heuristically, including the noise scale and the multiplication coefficient required to compute the projected radius. Secondly, the mean-based margin distance is only applicable to classification tasks. Due to the limited scope of this project, we leave the development of generalization measures more suitable for generative tasks to future work."
        }
    ],
    "url": "http://arxiv.org/html/2404.15928v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.2.x"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "3",
            "3.1",
            "3.2",
            "3.2.x"
        ]
    },
    "research_context": {
        "paper_id": "2404.15928v1",
        "paper_title": "Generalization Measures for Zero-Shot Cross-Lingual Transfer",
        "research_background": "### Motivation:\n\nThe primary motivation of this paper is rooted in the necessity to reliably assess the generalization capabilities of machine learning models beyond traditional accuracy metrics. With the expansion of NLP models to cover multiple languages, especially for under-resourced languages, there is a growing need to develop evaluation methodologies that can gauge a model's ability to generalize across different languages and unseen settings. Traditional measures such as VC dimension, cross-entropy, and model complexity have been explored, but recent research indicates that measures related to the smoothness in loss curvature provide a better correlation with generalization performance.\n\n### Research Problem:\n\nThe specific research problem addressed in this paper is the development of methods to measure and evaluate the generalization capability of language models in a zero-shot cross-lingual transfer scenario. The hypothesis under investigation is whether an extended flat area of low loss value around the minimized loss can serve as a reliable indicator of a model's generalization capability. The paper aims to test this hypothesis and propose new evaluation metrics adapted for cross-lingual settings.\n\n### Relevant Prior Work:\n\n1. **Generalization Measures:**\n   - **VC Dimension:** Vapnik & Chervonenkis (1971)\n   - **Cross-Entropy:** Shannon (1948)\n   - **Model Complexity:** Mohri et al. (2012)\n   - **Parameter Variation During Training:** Nagarajan & Kolter (2019)\n   \n2. **Smoothness in Loss Curvature:**\n   - Supported by works such as Chaudhari et al. (2019), Petzka et al. (2021), Kaddour et al. (2022)\n   - Techniques such as data perturbation (e.g., Jiang et al. (2020a), Aghajanyan et al. (2021)) and integrating measures into optimization objectives (e.g., Izmailov et al. (2018), Jastrzebski et al. (2021))\n   - Challenges in computation in high-dimensional spaces highlighted by Nachum et al. (2024)\n   \n3. **Measures for Zero-Shot Cross-Lingual Generalization Measurement:**\n   - Frobenius distance of learned parameters: Nagarajan & Kolter (2019)\n   - Margin between model predictions and true labels: Wei et al. (2018)\n   - Sharpness in loss minima: Keskar et al. (2017), Foret et al. (2021)\n\nBy leveraging and extending these existing measures, the paper proposes an evaluation framework specifically tailored for zero-shot cross-lingual transfer tasks, providing new insights into the generalization capabilities of multilingual models.",
        "methodology": "Methodology: \n\nIn this study, we undertake the development of a methodology that could benefit an accurate assessment of the generalization capability of models for the purpose of cross-lingual knowledge transfer into under-resourced languages. This section first presents approaches to improving generalization performance and the selected measures that provide stable results for measuring zero-shot cross-lingual transfer performance.\n\n**Proposed Method:**\n\nThe key components of the proposed method include:\n\n1. **Approaches to Improving Generalization Performance:**\n   - This involves the development and implementation of techniques and strategies aimed at enhancing the ability of models to generalize well across different languages, particularly focusing on under-resourced languages where data might be scarce.\n\n2. **Selected Measures:**\n   - Identification of specific metrics and evaluation criteria that reliably assess zero-shot cross-lingual transfer performance. These measures should provide stable and consistent results, enabling accurate assessment of how well the model transfers knowledge from one language to another without additional training data in the target language.\n\n**Key Innovations:**\n\n- **Focus on Under-Resourced Languages:**\n  - The methodology emphasizes the importance of evaluating and improving the model\u2019s performance in languages that lack extensive resources, addressing the challenge of cross-lingual knowledge transfer in these contexts.\n\n- **Zero-Shot Learning:**\n  - Implementation of zero-shot learning techniques to assess the model\u2019s capability to perform tasks in a target language without having seen any task-specific examples in that language during training.\n\nBy refining these methodologies and accurately measuring generalization performance, the study aims to bring forth significant improvements in the generalization assessments for models used in cross-lingual knowledge transfer scenarios.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n**Experiment Setup:**\n- **Models:** The experiments involve two main models: the multilingual BERT base variant (bert-base-multilingual-cased from Huggingface) and the mT5 model (google/mt5-small).\n- **Datasets:** The initial fine-tuning is performed on the English language part of the XNLI (Cross-lingual Natural Language Inference) dataset.\n- **Fine-Tuning Objective:** Sharpness-based optimization methods are implemented as fine-tuning objectives on the selected multilingual models.\n- **Architecture:** A linear classification layer with a size of 768x3 is used, where the output dimension corresponds to the number of labels.\n- **Training Procedure:** A two-step training approach is adopted:\n  - **Step 1:** Fine-tuning the model on the English part of the XNLI dataset to specialize the model in learning the task in English.\n  - **Step 2:** Conducting a zero-shot transfer of the fine-tuned model to evaluate its performance and generalization capabilities across 14 other languages present in the XNLI dataset.\n\n**Evaluation Metrics:**\n- The evaluation focuses on measuring the performance of the models after zero-shot transfer to the 14 non-English languages of the XNLI dataset.\n- Standard evaluation metrics for natural language inference tasks, likely including accuracy metrics on the zero-shot cross-lingual transfer tasks, are used to assess model generalization.\n\n**Main Experimental Results:**\n- The specific numerical results of the main experiments, such as accuracies or other performance metrics for each of the 14 languages, are not detailed here.\n- The focus of the results is likely on comparing the effectiveness of the Sharpness-based optimization techniques in enhancing zero-shot cross-lingual generalization of the mBERT and mT5 models compared to baseline performances without such optimizations."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To investigate and compare various optimization techniques with a focus on enhancing generalization and robustness in models for zero-shot cross-lingual transfer.",
            "experiment_process": "Selected fine-tuning methods include Sharpness-Aware Minimization (SAM), regularization with Fisher Information Matrix (FIM), and Multi-view Subword Regularization (MVR). The SAM aims to minimize the maximum loss value within a radius in the loss landscape, FIM penalizes the trace of the Fisher information matrix during training, and MVR minimizes the divergence between model predictions on deterministic and probabilistic segmentation inputs. These methods are applied to a pre-trained model and their performance on cross-lingual generalization is evaluated.",
            "result_discussion": "Each method focuses on different aspects: SAM looks for low-loss parameter neighborhoods, FIM emphasizes penalizing the Fisher information matrix which correlates better to generalization, and MVR ensures consistency across different input types. These theoretically help in improving the model's generalization and robustness in a cross-lingual setting.",
            "ablation_id": "2404.15928v1.No1"
        },
        {
            "research_objective": "To explore different generalization measures to identify which ones correlate best with zero-shot cross-lingual transfer performance, particularly focusing on the applicability of the flatness hypothesis.",
            "experiment_process": "Generalization measures being evaluated include margin and sharpness of optimum. Margin is calculated as the difference between the model predictions for the ground truth label and the next highest prediction probability, averaged over the test set. Sharpness is defined as the change in the loss value at neighboring points in the weight plane. The study computes these measures to determine their correlation with generalization.",
            "result_discussion": "Higher margin values were found to correlate with better generalization, indicating that models with greater certainty in predictions are more robust to perturbations and unseen examples. Original sharpness measures showed high correlation with generalization; however, modifications to the sharpness calculation were needed for stability and performance consistency, resulting in a faster and robust algorithm for measuring sharpness.",
            "ablation_id": "2404.15928v1.No2"
        }
    ]
}