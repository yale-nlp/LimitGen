{
    "title": "Iterative Feature Boosting for Explainable Speech Emotion Recognition",
    "abstract": "In speech emotion recognition (SER), using predefined features without considering their practical importance may lead to high dimensional datasets, including redundant and irrelevant information. Consequently, high-dimensional learning often results in decreasing model accuracy while increasing computational complexity. Our work underlines the importance of carefully considering and analyzing features in order to build efficient SER systems. We present a new supervised SER method based on an efficient feature engineering approach. We pay particular attention to the explainability of results to evaluate feature relevance and refine feature sets. This is performed iteratively through a feature evaluation loop, using Shapley values to boost feature selection and improve overall framework performance. Our approach allows thus to balance the benefits between model performance and transparency. The source code of this paper is publicly available at Iterative-Feature-Boosting-for-Explainable-Speech-Emotion-Recognition.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Human emotions are complex and essential aspects of human behavior. They correspond to subjective experiences characterized by physiological, behavioral, and cognitive changes, and can be influenced by various factors, such as social interactions, and cultural considerations. Emotions play an important role in various aspects of human life. Therefore, emotion recognition and interpretation is considered as a key problem in psychology, with a wide range of AI applications, including human-computer interaction, affective computing, and mental disorder detection [1]. \n\nTo solve the speech emotion recognition (SER) problem, various machine learning algorithms have been explored, including support vector machines [2], hidden Markov models [3], and deep neural networks [4]. These algorithms are trained on large datasets, and use various feature representations, such as spectral features, prosodic features, and spectral envelope features [5]. Given the multitude of features and their several categories, one of the main challenges is to find the appropriate feature representation for a given SER task. In fact, the use of large predefined feature sets often leads to high-dimensional datasets [6], making it difficult for the model to learn effectively from data, in addition to increasing computational complexity [7].\n\nIn the literature, little attention has been paid to finding relevant features for SER as most of existing works used principal component analysis (PCA) for dimensionality reduction [8], while some other works relied on 1D convolutions through end-to-end deep learning models [9].\n\nIn our work, we argue that the performance of SER systems heavily depends on the used features. We thus present a comprehensive approach, placing a special emphasis on the feature extraction and selection process. The proposed framework comprises three main components: 1) a feature boosting module guided by the feedback loop of the third component to extract and select features, 2) a classification module using a supervised classification model, and 3) an explainability module where the contribution of features to the classification decision is evaluated using SHapley Additive exPlanations (SHAP) [10]. This explainability component serves as a feedback mechanism at the end of each iteration, to continuously refine and boost the feature set in the first component.\n\nAccordingly, our main contributions can be summarized as follows:\n\n- A new SER approach with an emphasis on feature selection through iterative feature boosting.\n- Incorporation of model explainability and SHAP technique for identifying the most relevant features for the SER task, as well as for transparency purposes.\n- An experimental evaluation of the proposed method by comparison to human-level performance and state-of-the-art algorithms.\n- The source code of our framework for reproducibility and future research on SER."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "II RELATED WORKS",
            "text": "###figure_1### Modern SER methods are mostly based on supervised learning approaches. They can be broadly divided into two categories: traditional machine learning methods [11  ###reference_b11###] [12  ###reference_b12###], and deep learning methods [13  ###reference_b13###] [14  ###reference_b14###] [9  ###reference_b9###].\nSeveral techniques related to feature extraction have been explored in previous works. They are mostly based on handcrafted features, which are designed by incorporating expert knowledge or domain-specific insights, and using traditional feature selection techniques.\nOne of the major challenges is handling the high dimensionality of the data and ensuring that the used features are meaningful and relevant. This is because a large number of features are often extracted from signals without considering their practical importance and suitability for the emotion classification task.\nIn [11  ###reference_b11###], the authors propose to use Mel Frequency Cepstral Coefficients (MFCC) for feature extraction and Support Vector Machines (SVM) for classification. MFCCs are calculated through a series of steps including sampling and quantization, windowing, discrete Fourier transform, and a Mel filter bank. The resulting MFCCs are then used for emotion classification using an SVM classifier. A sensitivity analysis is also conducted to evaluate the impact of different feature combinations on the classification performance.\nIn [13  ###reference_b13###], the authors present two-way approach for SER. The first involves the direct extraction of features from the audio dataset using a combination of mel-scale related features. Then, PCA is used to reduce data dimensionality and eliminate correlated variables.\nThe resulting features are then fed into a deep neural network (DNN) for classification. The authors observed that PCA allowed to significantly reduce overfitting, which in turn leads to a more effective training of the DNN. Their second approach is based on using 2D representation of spectrograms considered as images for classification, which is then carried out by the VGG16 CNN [15  ###reference_b15###] model retrained on Mel-Spectrogram images to classify emotions.\nIn [16  ###reference_b16###], the authors present the robust discriminative sparse regression (RDSR) approach to deal with feature selection and emotion classification in a joint learning framework. The RDSR algorithm is designed to select the most discriminative feature subset from the original high-dimensional feature set. It uses sparse regression to improve model robustness to outliers and noise, and introduces a feature selection regularization constraint to select the most relevant features.\nIn [17  ###reference_b17###], an SER model based on continuous hidden Markov model (CHMM) was proposed, as the random generation of states in HMMs allows for statistical modeling of the sequential nature of the data. The model extracts 33-dimensional feature parameters based on temporal sequence and uses PCA to reduce the dimensionality of initial feature set. The experimental results showed that the PCA-CHMM model improves emotion recognition performance compared to the standard HMM model using the entire feature set.\nIn [9  ###reference_b9###], the authors propose a hybrid end-to-end deep learning model for feature extraction and emotion classification. The proposed model consists of two main components: one-dimensional convolutional neural network (1D-CNN) and Gated Recurrent Unit (GRU). The 1D-CNN serves for spatial features extraction through convolutional layers, while the GRU component captures time-distributed features due to memory and gate principles.\nPrevious research has shown that extracting efficient acoustic characteristics is crucial for capturing various emotional aspects of speech in SER. However, existing works mostly relied on predefined features, without fully investigating their relevance for SER, and how they can be used to improve performance. Some deep learning-based works attempted to address the feature selection issue implicitly through 1D convolutions, while other supervised learning methods aimed to handle the high dimensionality problem by merely applying PCA to compute principal components. We present a new approach for supervised SER with a focus on feature importance and model explainability over the entire framework."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "III PROPOSED METHOD",
            "text": ""
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "III-A Motivation and overview",
            "text": "Both the quality and quantity of used features can significantly impact the performance of emotion recognition. Using too many irrelevant or redundant features can lead to overfitting and lack of generalization, while using few or insufficient features can result in underfitting and poor performance. Therefore, it is important to carefully select the features that are most useful for emotion recognition, by considering the voice signal characteristics that are most indicative of emotions. Our method is based on domain-specific voice features and comprises three main components. A feature boosting module is firstly used to compute a preliminary feature set assumed to be useful for emotion recognition, these features are iteratively refined afterwards via a feedback mechanism. Then, we identify optimal feature combinations from the resulting feature set and reduce dimensionality. Secondly, a classification module formulates the SER task as a supervised classification problem. Classification decisions are then analyzed by an explainability module, which utilizes Shapley values to evaluate the importance of features in the classification decision, thus, to provide insights into the feature boosting module. By incorporating explainability into the SER process, we aim to enhance the performance of the model with a better understanding of the contribution of each feature to the final decision. The obtained explainability results are then used iteratively via a feedback mechanism to further boost the feature selection process in the first module. This is achieved through a feedback loop at the end of each iteration."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "III-B Method",
            "text": "The proposed method is illustrated in Fig. 1. In the feature boosting module, we compute a preliminary feature set representation including pitch, energy, and rhythm-related characteristics, which we assume being meaningful for SER. We also calculate related statistical characteristics including the mean, median, standard deviation, minimum, and maximum, resulting in a set of initial features. To further improve the performance and interpretability of our technique, we select optimal distinct combinations of features from the dataset according to the following steps. We use PCA to reduce data dimensionality of each combination and remove noise by transforming it using an eigenvector matrix and a corresponding eigenvalues vector. Each column of the eigenvector matrix represents a principal component capturing specific data information and determining the dimension of the reduced subset.\n\nThe percentage of variance explained by the principal component of the combination can be evaluated. This allows us to determine which features contribute the most to each principal component. This is done to identify the best combination of features representing information in our dataset. We use a threshold on the sum of the first explained variances as a criterion to determine feature combinations that are most informative. The resulting feature set consists of the principal components of each selected combination. In this way, we eliminate redundant and less informative features and use only the most relevant ones. This process is refined iteratively through the feedback loop of our architecture\u2019s explainability module, which we will describe later in this section.\n\nIn the classification module, we compare the performance of candidate classification models on the resulting features. Our choice of classification models aligns with those commonly used classifiers in the SER literature. The selected machine learning models have been widely used in various domains for SER and have been known to achieve good results. The process of comparing the performance of different classification models on the initial dataset and the resulting feature set helps us determine how well our approach performs, to consequently select the appropriate model. Beyond SER, the framework could be applied to a wide range of classification problems, where other candidate classification models could be evaluated.\n\nClass-wise feature importance - Extra Trees classifier: The values on the x-axis are the mean of absolute values of Shapley values, representing the average impact on the model\u2019s output magnitude, where a higher value indicates a more important feature. The features on the y-axis in Fig. 3 are represented as principal components, which are the result of applying PCA to the optimal combinations of selected features using the explained variance threshold.\n\nIn the explainability module, we incorporate explainable artificial intelligence (XAI) capabilities into the SER system. Thus, we create a system that is transparent and understandable in terms of prediction and decision making. To achieve this, we use the Shapley explanation values to explain the model\u2019s predictions. Shapley values allow us to understand the contribution of each feature in the resulting feature set to a model\u2019s prediction, which enables us to identify which combination\u2019s principal components are most important for the emotion recognition. We define the contribution of each feature in the resulting feature set as a function of its impact on the output of the classification model for a given input. This allows us to conduct a feature importance analysis and gain insight into how the model works and what factors are most important.\n\nThe process involves an iterative feedback loop where we use the explainability module to determine the most relevant principal components that capture the essential information for emotion recognition and eliminate less important ones. We then incorporate the contribution of the initial features to each of the relevant principal components to identify the most participating features to the principal components, and thus, to the classification decision process. We eliminate features that do not contribute significantly to the model\u2019s performance and iterate the process until convergence."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "IV EXPERIMENTS",
            "text": ""
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "IV-A Dataset and experimental setup",
            "text": "We first set the sampling rate of the audio data to 16 KHz using a mono-channel format. This ensures that audio signals are properly processed and analyzed by our system, as most SER algorithms require specific sampling rates and number of channels for each audio signal. After going through the feature extraction and selection process, we use stratified random sampling [21  ###reference_b21###] to divide the dataset into three homogeneous groups (or strata): training, validation, and testing. We keep 10% of the data as unseen to be used for testing, 80% for training, and 10% for validation. This ensures that the distribution of classes is maintained across all subsets. Then, we use 10-fold cross-validation [22  ###reference_b22###] to train machine learning models: Extra Trees (ET), Light Gradient Boosting Machine (LGBM), Random Forest (RF), Quadratic Discriminant Analysis (QDA), Gradient Boosting Classifier (GBC), Linear Discriminant Analysis (LDA), and Decision Tree (DT), to select the optimal model. By using cross-validation, our performance evaluation should be less sensitive to data partitioning.\n\nIn order to improve the performance of our best-performing machine learning models, we use the grid search technique, which involves exhaustively searching through a specified parameter space to find the best combination of hyperparameters for a given model [23  ###reference_b23###]. In this way, we are able to fine-tune the model by adjusting its hyperparameters to increase robustness. We thus find the optimal set of hyperparameters producing the highest performance on the validation dataset.\n\nWe then assess the performance of the final models on the testing set. The testing performance is an indicator of how well the model would perform on unseen data without overfitting the training set. Finally, we use the SHAP approach in our explainability module to evaluate the feature importance in the predictions of the optimal model. This allows us to understand how the model is making its predictions and to identify which features are most important for determining emotions. For performance evaluation, we use accuracy, recall, precision, and F1-Score metrics."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "IV-B Model explainability",
            "text": "One key aspect of our approach is the use of feature boosting module to select the optimal combinations of features that best capture the variance and information in our dataset. To demonstrate this, we show importance values in figures 3 and 3. We can observe the contribution of each feature to the predicted emotion class. The principal components in Fig. 3 are labeled as principal components, referring to the principal component of the feature combination. Additionally, it can also help in understanding which principal components are not important and can be removed without relatively affecting the performance of the model. By examining Fig. 3, we can determine the principal components that have the highest impact on the output of our model. Through this analysis, we can also identify the feature combination that corresponds to each principal component and the contribution of each feature to a principal component. This leads us ultimately to determine the most relevant features for our SER decision (see Fig. 3). Thus, we can identify the features that contribute the most to each of the important principal components, this information is valuable because it allows us to refine our SER system by eliminating less relevant features and improving the accuracy of the classification decision in the next iteration.\n\nWe set a threshold on the cumulative explained variance by the first two principal components of each of the feature combinations. This means that we select only the combinations that explain at least 80% of the data variance. Thus, we obtain the best 19 combinations representing the data. As an example, we have found a combination of features that are particularly informative. This feature set captures 84.56% of the total explained variance in the first two principal components and 98.22% in the first four.\n\nThe length of the arrows represents the relative importance of each feature in the dataset, and the angle between the arrows represents the correlation between the features. The biplot in Fig. 4 displays the data points on a 2D scatter plot, with the position of each point representing the values of the first two principal components of the optimal feature combination data. Additionally, the biplot also shows the directions and the lengths of the arrows representing the optimal features in the transformed space. Analyzing the biplot allow us to understand how the optimal features are related to the principal components as the direction of the arrow indicates the sign of the contribution (positive or negative), while the length indicates the magnitude of the contribution. This informs us on how these features contribute to the overall variance of the data. Moreover, the cumulative explained variance can be added to the biplot, which indicates the percentage of the total variance in the optimal feature combination data explained by each principal component. This is helpful in determining the optimal number of principal components to retain when performing PCA to the selected feature combinations."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "IV-C Results",
            "text": ""
        },
        {
            "section_id": "4.3.1",
            "parent_section_id": "4.3",
            "section_name": "IV-C1 Comparison with SOTA methods",
            "text": "Compared methods\n\nThe performance metrics of these state-of-the-art methods are taken from the original papers.\n\nWe have two main evaluation approaches for our method. SER methods typically involve two main stages: feature extraction and classification. Many of the compared methods in the literature use MFCC for feature extraction, while some others use spectrograms combined with PCA or Empirical Mode Decomposition (EMD). For classification, some methods employ traditional machine learning techniques such as SVM or Latent Dirichlet Allocation (LDA), while others use deep neural networks.\n\nOur method outperformed the compared machine learning methods, achieving the highest accuracy and F1-score."
        },
        {
            "section_id": "4.3.2",
            "parent_section_id": "4.3",
            "section_name": "IV-C2 Importance of feature boosting and model explainability",
            "text": "In Table II, we can see the performance of various machine learning models without feature boosting and model explainability on the initially computed features. It is clear from the table that the ET classifier performs the best, as it achieves 95.8% in terms of accuracy, recall, precision, and F1-score. The LGBM also performs well with 95% accuracy. RF and GBC also have very high accuracy at 94.6% and 94.3%, respectively. This indicates that the initially computed features do indeed contain valuable information for the SER task. Therefore, we can conclude that the ET classifier and LGBM are the best models for this dataset, and we can use them to achieve high performance.\n\nThe confusion matrix in Fig. 5 shows the results of the ET classifier. The matrix indicates that the model performs well overall, as can be seen by the high rate of correct predictions on the diagonal elements. For example, 100% of the actual class \u201dsad\u201d are correctly predicted as \u201dsad\u201d. However, there are also some misclassifications, such as when 5.45% of the actual class \u201dsurprise\u201d is predicted as \u201dhappy\u201d and 8.33% of the actual class \u201dhappy\u201d is predicted as \u201dsurprise\u201d. This means that \u201dhappy\u201d and \u201dsurprise\u201d share some acoustic characteristics.\n\n### Model Performance on Initial Features\n- ET: Acc. 95.8, Recall 95.8, Prec. 95.8, F1 95.8\n- LGBM: Acc. 95, Recall 94.9, Prec. 95, F1 95\n- RF: Acc. 94.6, Recall 94.6, Prec. 94.7, F1 94.5\n- GBC: Acc. 94.3, Recall 94.3, Prec. 94.3, F1 94.3\n- LDA: Acc. 92.9, Recall 93, Prec. 93.3, F1 92.9\n- DT: Acc. 92.9, Recall 92.1, Prec. 92.3, F1 92.1\n- QDA: Acc. 83.2, Recall 83.3, Prec. 85.7, F1 82\n\n### Model Performance with Boosted Features and Explainability Feedback\n- ET: Acc. 98.7, Recall 98.6, Prec. 98.7, F1 98.7\n- LGBM: Acc. 95.9, Recall 96, Prec. 96.3, F1 96\n- RF: Acc. 95, Recall 95, Prec. 95, F1 95\n- LDA: Acc. 94.5, Recall 94.5, Prec. 94.6, F1 94.5\n- GBC: Acc. 93.6, Recall 93.6, Prec. 93.7, F1 93.7\n- QDA: Acc. 92.6, Recall 92.7, Prec. 92.7, F1 92.6\n- DT: Acc. 90.3, Recall 90.3, Prec. 90.6, F1 90.2\n\nTable III compares the performance of the same machine learning models using the boosted feature set and the incorporation of model explainability feedback. The best-performing model in terms of accuracy is the ET classifier with an accuracy of 98.7% and F1-score of 98.7%. The second-best performing model is LGBM with an accuracy and F1-score of 95.9% and 96%, respectively. RF also has relatively high accuracy of 95%, and good scores for the other evaluation metrics.\n\nSome other models have lower accuracy and less favorable scores for the other evaluation metrics. Few of these low-performing models appear to lose their effectiveness when feature boosting and model explainability are employed. This may be due to their need for more complex datasets in order to achieve reasonable output, resulting in increased computational complexity. This suggests that these models may be less suitable for SER tasks than the models that perform well under the same conditions. In summary, the ET classifier and LGBM are the best-performing models on this dataset with high accuracy and F1-score.\n\nThe confusion matrix in Fig. 5, again examining the ET classifier, shows that it performs well overall with a high number of correct predictions on the diagonal elements for each emotion. For example, 100% of the actual class \u201dneutral\u201d are correctly predicted as \u201dneutral\u201d and 99.09% of the actual class \u201dfear\u201d are correctly predicted as \u201dfear\u201d. However, there are also some mis"
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Discussion",
            "text": "In this work, the objective is to extract the most relevant features for accurately detecting emotions in speech. We noticed a lack of consensus in the existing literature regarding a clear set of features that effectively capture emotional information from speech signals. This knowledge gap highlights the importance of our research in addressing this issue and providing valuable insights into feature selection for SER. Through this study, we make significant contributions to the field by exploring and identifying the features that play a crucial role in detecting and distinguishing emotional states in speech.\nOur analysis focused on identifying features with high discriminative power and informativeness for differentiating between various emotional categories and how can we explain and interpret that. We employ a rigorous feature selection process to identify the most relevant features. By using an iterative feature boosting technique supported by the explainabilty module, we aim to enhance the discriminative power of the selected features and the SER\u2019s overall performance.\nOne of the key features that emerges as highly relevant in our study is MFCC, which capture the spectral characteristics of speech and have been widely used in speech analysis tasks. MFCCs are known to effectively capture the distinctive characteristics and spectral variations associated with different patterns. Another important feature that we find valuable for SER is pitch or fundamental frequency (F0). Variations in pitch convey important emotional cues and can help discriminate between different emotional states. Analyzing pitch-related features such as pitch contour, pitch range, or pitch dynamics can provide valuable information for emotion classification. Additionally, we find that energy and intensity measures play a significant role in capturing emotional intensity and arousal. These features reflect the overall energy distribution and loudness of speech, which are closely related to emotional expressiveness. Furthermore, temporal features such as speech rate or duration demonstrated relevance in capturing the temporal patterns and dynamics of emotional speech. The rate at which speech is produced and the duration of specific speech segments can provide important cues for SER.\nOne limitation of our study is that it was tested solely on the TESS dataset. While the results obtained from this dataset are promising, it is important to validate our approach on multiple datasets and in real-world scenarios to ensure the generalizability of our findings. Validation on diverse datasets would provide a more comprehensive assessment of the effectiveness of our feature boosting approach in different contexts and with different speech samples. It would enable us to evaluate the robustness and reliability of the selected features across various data sources, potentially uncovering any dataset-specific biases or limitations. Furthermore, real-world scenarios often present additional challenges, such as varying recording conditions, speaker characteristics, and noise levels. These factors can impact the performance of the SER system and the relevance of the selected features.\nHowever, it is worth noting that our research provides a comprehensive analysis of the feature selection process and highlights the rationale behind selecting specific features. By presenting these findings, we contribute to the development of a standardized feature set for SER, which can serve as a foundation for future research in the field. This standardized set of features will enable researchers to focus on these key features when designing and implementing robust SERs, ultimately enhancing the accuracy and effectiveness of trustworthy emotion detection in real-world applications."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "VI Conclusion",
            "text": "In this study, we presented a new approach for supervised SER based on acoustic features of the voice and their statistical characteristics values. Our work highlights the importance of feature selection and the role of explainability in improving the accuracy of SER. Our method involves several steps including computing speech features, selecting the optimal feature combinations, boosting the final feature subset, and applying various machine learning models to evaluate their performance and fine-tune the best performing model. Additionally, we incorporate XAI into SER to create a system that is more understandable, to boost feature selection process via the feedback loop. To the best of our knowledge, this is the first work incorporating model explainability into an SER framework. Our work provides a comprehensive SER approach that aims to balance the benefits of advanced machine learning techniques with the need for transparency and comprehensibility. Our future work aims to investigate feature boosting within deep learning frameworks. Moreover, we aim to generalize our feature boosting approach for other classification problems, addressing the feature relevance and high dimensionality problems."
        }
    ],
    "url": "http://arxiv.org/html/2405.20172v3",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2"
        ],
        "methodology_sections": [
            "3.1",
            "3.2"
        ],
        "main_experiment_and_results_sections": [
            "4.1",
            "4.3.1",
            "4.3.2"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4.2",
            "4.3.2"
        ]
    },
    "research_context": {
        "paper_id": "2405.20172v3",
        "paper_title": "Iterative Feature Boosting for Explainable Speech Emotion Recognition",
        "research_background": "### Paper's Motivation\n\nHuman emotions are vital elements of human interaction and behavior, influencing a broad spectrum of experiences and interactions. The ability to recognize and interpret emotions accurately\u2014known as Speech Emotion Recognition (SER)\u2014is fundamental for various applications in human-computer interaction, affective computing, and diagnosing mental disorders. Despite extensive research into SER using diverse machine learning techniques, finding an optimal feature representation remains a significant challenge. This stems from the complexity and high dimensionality of feature sets, which can complicate model training and increase computational burden. The motivation behind this paper is to address these challenges by enhancing SER performance through improved feature selection and explainability.\n\n### Research Problem\n\nThe paper targets the longstanding issue in SER of effectively selecting and extracting the most relevant features from complicated, high-dimensional feature sets, which can otherwise hinder model performance and increase computational complexity. Existing methods often rely on techniques such as PCA for dimensionality reduction or end-to-end deep learning models, but these approaches may not adequately focus on identifying the most relevant features for SER tasks. The research aims to develop a novel framework that iteratively refines the feature set for improved classification performance and incorporates model explainability to understand the importance of individual features.\n\n### Relevant Prior Work\n\n1. **Machine Learning Algorithms for SER**:\n   - Various algorithms like support vector machines [2  ###reference_b2###], hidden Markov models [3  ###reference_b3###], and deep neural networks [4  ###reference_b4###] have been employed to address the SER problem, employing features such as spectral, prosodic, and spectral envelope attributes [5  ###reference_b5###].\n\n2. **Dimensionality Challenges**:\n   - High-dimensional datasets generated from expansive feature sets can impede model learning and elevate computational complexity [6  ###reference_b6###], [7  ###reference_b7###].\n   \n3. **Current Feature Selection Methods**:\n   - Most existing SER research uses PCA for dimensionality reduction [8  ###reference_b8###], although some newer approaches use 1D convolutions in deep learning models [9  ###reference_b9###]. Despite these methods, the emphasis on identifying the most pertinent features specifically for SER tasks has been limited.\n\n4. **Explainability in Models**:\n   - Model transparency and interpretability have become essential, particularly techniques such as SHapley Additive exPlanations (SHAP) [10  ###reference_b10###], which explain the contribution of each feature to the model's decisions.\n\n### Contributions of the Paper\n\n1. Introduction of a new SER approach that prioritizes feature selection through iterative feature boosting.\n2. Integration of the SHAP technique for explainability, enabling identification of the most relevant features and enhancing model transparency.\n3. Conducting experimental evaluations to compare the proposed method against human-level performance and state-of-the-art algorithms.\n4. Providing the source code for reproducibility and to facilitate future SER research.",
        "methodology": "**Iterative Feature Boosting for Explainable Speech Emotion Recognition**\n\n**Methodology:**\n\n1. **Feature Selection and Boosting Module**:\n    - This initial module is pivotal to the method, focusing on the selection and refinement of features critical for emotion recognition.\n    - **Initial Feature Computation**: A preliminary set of voice features presumed to be indicative of emotions is computed.\n    - **Iterative Refinement**: These features undergo iterative refinement through a feedback mechanism to enhance their relevance and reduce redundancy.\n\n2. **Optimal Feature Combination and Dimensionality Reduction**:\n    - Post initial feature selection, this component identifies optimal combinations of features.\n    - Dimensionality reduction techniques are employed to streamline the feature set, eliminating irrelevant or redundant features and ensuring the features used are the most indicative of the emotional content of the voice signal.\n\n3. **Classification Module**:\n    - The SER task is approached as a supervised classification problem within this module.\n    - The classification model trained on the optimized feature set predicts the emotional state from the voice signal.\n\n4. **Explainability Module**:\n    - Shapley values are utilized to appraise the significance of each feature in the classification decision.\n    - By interpreting these values, the module provides a clear understanding of which features are most influential in the emotion recognition process.\n\n5. **Feedback Loop**:\n    - Insights garnered from the explainability module are fed back into the feature selection module.\n    - This feedback loop informs and refines further iterations, continuously boosting and optimizing feature selection.\n\n**Innovations**:\n- **Iterative Feature Refinement**: The method's ability to iteratively refine the feature set through a feedback loop significantly enhances feature relevance.\n- **Explainability Integration**: Utilizing Shapley values to impart explainability ensures a transparent understanding of feature impact, which subsequently guides and improves the feature boosting process.\n- **Domain-specific Focus**: The model\u2019s reliance on domain-specific voice features ensures its tailored effectiveness for speech emotion recognition, leveraging the most indicative voice signal characteristics.\n\nBy combining these components, the method aims to optimize feature selection and enhance model performance, reinforced by clear interpretability of the contributions of various features.",
        "main_experiment_and_results": "### Main Experiment Setup and Results:\n\n**Dataset:**\n- **Toronto Emotional Speech Set (TESS)**\n  - **Size:** 2800 audio recordings.\n  - **Participants:** Two.\n  - **Content:** 200 target phrases.\n  - **Emotions:** Anger, disgust, pleasant surprise, fear, sadness, happiness, and neutral (400 recordings per emotion).\n\n**Preprocessing and Feature Handling:**\n- **Sampling Rate:** Audio data resampled to 16 KHz in a mono-channel format.\n  \n**Data Splitting:**\n- **Stratified Random Sampling:**\n  - **Training Set:** 80% of the data.\n  - **Validation Set:** 10% of the data.\n  - **Testing Set:** 10% of the data.\n  - Ensures class distribution is maintained across subsets.\n\n**Model Training and Evaluation:**\n- **Algorithms Used:**\n  - Extra Trees (ET)\n  - Light Gradient Boosting Machine (LGBM)\n  - Random Forest (RF)\n  - Quadratic Discriminant Analysis (QDA)\n  - Gradient Boosting Classifier (GBC)\n  - Linear Discriminant Analysis (LDA)\n  - Decision Tree (DT)\n\n- **Validation Approach:** \n  - 10-fold cross-validation to minimize sensitivity to data partitioning.\n  \n- **Hyperparameter Tuning:**\n  - **Technique:** Grid Search.\n  - Exhaustive search through specified parameter space to identify optimal hyperparameters.\n\n**Model Assessment:**\n1. **Metrics Used:**\n   - Accuracy\n   - Recall\n   - Precision\n   - F1-Score\n\n2. **Procedure:**\n   - Apply the final models with optimal hyperparameters on the testing set.\n   - Analyze performance on unseen data for robustness and overfitting check.\n\n**Explainability:**\n- **Method:** SHAP (SHapley Additive exPlanations).\n- **Goal:** Evaluate feature importance in the model\u2019s predictions to understand the decision-making process of the optimal model.\n\n### Main Experimental Results:\nThe paper does not explicitly list the main experimental results in the provided snippet. However, the methodology suggests that the optimal models' performance, evaluated in terms of accuracy, recall, precision, and F1-Score on the testing set, would be benchmarked. The most important features for predictions as identified by SHAP would also be discussed in the context of the best-performing models."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To demonstrate the importance and impact of selecting optimal combinations of features on the performance of a speech emotion recognition (SER) system.",
            "experiment_process": "The experiment uses a feature boosting module to identify and select the optimal combinations of features that best capture the variance and information in the dataset. Principal components analysis (PCA) is employed to analyze the contribution of each feature. The study sets a threshold on the cumulative explained variance by the first two principal components, selecting combinations that explain at least 80% of the data variance. This results in the identification of the best 19 feature combinations. The effectiveness of these feature sets is visualized using biplots to understand their relation to principal components.",
            "result_discussion": "The study found that certain combinations of features capture a significant portion of the total explained variance (e.g., 84.56% by the first two principal components, 98.22% by the first four). This process allows for the identification of the most relevant features, which can be used to refine the SER system by removing less relevant features and improving classification accuracy.",
            "ablation_id": "2405.20172v3.No1"
        },
        {
            "research_objective": "To evaluate the effect of feature boosting and model explainability on the performance of various machine learning models for SER.",
            "experiment_process": "The performance of several machine learning models (ET, LGBM, RF, GBC, LDA, DT, QDA) is tested both with and without feature boosting and model explainability on the initially computed features. Metrics used include accuracy, recall, precision, and F1-score. The confusion matrix is employed to understand the misclassifications. Hyperparameters tuning is performed using random grid search and cross-validation to optimize model performance.",
            "result_discussion": "Without feature boosting and model explainability, ET achieves the highest accuracy at 95.8%. With feature boosting and model explainability, ET's accuracy improves to 98.7%. Misclassifications such as 'happy' being predicted as 'surprise' are observed. The study concludes that feature boosting and model explainability significantly enhance model performance by reducing data dimensionality and refining feature selection, leading to better representation and generalization.",
            "ablation_id": "2405.20172v3.No2"
        }
    ]
}