{
    "title": "Explaining Black-box Model Predictions via Two-level Nested Feature Attributions with Consistency Property",
    "abstract": "Techniques that explain the predictions of black-box machine learning models are crucial to make the models transparent, thereby increasing trust in AI systems.\nThe input features to the models often have a nested structure that consists of high- and low-level features, and each high-level feature is decomposed into multiple low-level features.\nFor such inputs, both high-level feature attributions (HiFAs) and low-level feature attributions (LoFAs) are important for better understanding the model\u2019s decision.\nIn this paper, we propose a model-agnostic local explanation method that effectively exploits the nested structure of the input to estimate the two-level feature attributions simultaneously.\nA key idea of the proposed method is to introduce the consistency property that should exist between the HiFAs and LoFAs, thereby bridging the separate optimization problems for estimating them.\nThanks to this consistency property, the proposed method can produce HiFAs and LoFAs that are both faithful to the black-box models and consistent with each other, using a smaller number of queries to the models.\nIn experiments on image classification in multiple instance learning and text classification using language models, we demonstrate that the HiFAs and LoFAs estimated by the proposed method are accurate, faithful to the behaviors of the black-box models, and provide consistent explanations.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "The rapid increase in size and complexity of machine learning (ML) models has led to a growing concern about their black-box nature.\nModels provided as cloud services are literal black boxes, as users have no access to the models themselves and the training data used.\nThis opacity raises numerous concerns, including issues of trust, accountability, and transparency.\nConsequently, techniques to explain the predictions made by those black-box models have been attracting significant attention [3  ###reference_b3###, 6  ###reference_b6###, 25  ###reference_b25###].\nVarious model-agnostic local explanation methods have been proposed to explain the predictions of black-box models.\nThe representative methods are, for example, local interpretable model-agnostic explanation (LIME) [22  ###reference_b22###] and kernel Shapley additive explanations (Kernel SHAP) [18  ###reference_b18###], which estimate the feature attributions of the individual prediction by approximating the model\u2019s behavior with local linear surrogate models around the input.\nIn LIME and Kernel SHAP, the input to the model is generally assumed to be a flat structure, where the input features are treated as independent variables.\nIn many realistic tasks for various domains, such as image, text, geographic, e-commerce, and social network data, however, the input features have a nested structure that consists of high- and low-level features, and each high-level feature is decomposed into multiple low-level features.\nA typical task with such nested features is multiple instance learning (MIL) [13  ###reference_b13###] where the model is formulated as set functions [16  ###reference_b16###].\nIn MIL, the input is a set of instances, the high-level feature is an instance in the set, and the low-level features represent the features of the instance.\nIn addition, even if the input is not represented with a nested structure when it is fed into the model, it may be more natural to interpret it with the nested structure.\nFor example, although a text input is usually represented as a sequence of words, it is natural to interpret it as having high-level features such as phrases, sentences, and paragraphs.\nThe two-level features enable us to understand the model predictions with two types of feature attributions that have different levels of granularity in explanation, which we name high-level feature attributions (HiFAs) and low-level feature attributions (LoFAs), respectively.\nFigure 1  ###reference_### shows an example of the prediction for a nested structured input and its corresponding HiFAs and LoFAs.\nThe HiFAs represent how much each of the high-level features contributes to the prediction.\nThese are also referred to as instance attributions in the MIL literature [7  ###reference_b7###, 15  ###reference_b15###], which are used to reveal which instances strongly affected the model\u2019s decision.\nOn the other hand, the LoFAs represent how much each of the low-level features contributes to the prediction, providing a more fine-grained explanation of how the components of the instances affected the prediction.\nBoth the HiFAs and LoFAs are important for understanding the model\u2019s decision.\nHowever, existing studies have focused on estimating either-level attributions, and no study has addressed estimating the HiFAs and LoFAs simultaneously.\nFor the estimation of the HiFAs and LoFAs, two naive approaches can be applied.\nOne is to estimate the HiFAs and LoFAs separately by applying existing model-agnostic local explanation methods to the high- and low-level features, respectively.\nThe other is to estimate the LoFAs first, as with the former approach, and then estimate the HiFAs by aggregating the LoFAs.\nHowever, these approaches have two rooms for improvement in terms of using the nested structure of the input.\nFirst, even though the queries to the black-box model are often limited in practice due to the computational time and request costs, the input structure is not utilized to reduce the number of queries in the estimation.\nSecond, the former approach can produce inconsistent explanations between the HiFAs and LoFAs, for example, the most influential high-level feature and the high-level feature to which the most influential low-level feature belongs may not match.\n###figure_1### To address these issues, we propose a model-agnostic local explanation method that effectively exploits the nested structure of the input to estimate the HiFAs and LoFAs simultaneously.\nA key idea of the proposed method is to introduce the consistency property that should exist between the HiFAs and LoFAs, thereby bridging the separate optimization problems for them.\nWe solve a joint optimization problem to estimate the HiFAs and LoFAs simultaneously with the consistency constraints depicted in Figure 1  ###reference_### based on the alternating direction method of multipliers (ADMM) [1  ###reference_b1###].\nThe algorithm is a general framework that can also introduce various types of regularizations and constraints for the HiFAs and LoFAs, such as the  and  regularizations and non-negative constraints, which lead to the ease of interpretability for humans.\nIn experiments, we quantitatively and qualitatively assess the HiFAs and LoFAs estimated by the proposed method on image classification in the MIL setting and text classification using language models, compared with estimating them separately and using a recent attribution method for MIL [7  ###reference_b7###].\nThe experimental results show that the HiFAs and LoFAs estimated by the proposed method 1) satisfy the consistency property, 2) are faithful explanations to the black-box models even when the number of queries to the model is small, 3) can accurately guess the ground-truth positive instances and their features in the MIL task, and 4) are reasonable explanations visually.\nThe contributions of this work are summarized as follows:\nThis study is the first to propose a model-agnostic local explanation method to estimate the two-level nested feature attributions simultaneously, which satisfies the consistency property between them.\nIn the experiments on practical tasks, we demonstrated that the proposed method could produce accurate, faithful, and consistent two-level feature attributions with a smaller number of queries to the black-box models."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": "Numerous studies for explaining the individual predictions of black-box models have been proposed in the literature [22  ###reference_b22###, 18  ###reference_b18###, 23  ###reference_b23###, 20  ###reference_b20###, 21  ###reference_b21###]. A versatile approach is to explain feature attributions estimated by approximating the model predictions with surrogate models around the input, such as LIME [22  ###reference_b22###] and Kernel SHAP [18  ###reference_b18###]. The proposed method is in line with this type of approach. Set data is one of the nested input features, which treats a set of multiple instances as a single input. Set data appears in various ML applications, such as point cloud classification [10  ###reference_b10###], medical image analysis [2  ###reference_b2###], and group recommendation [4  ###reference_b4###], and the explainability on those applications has also been studied in the literature [28  ###reference_b28###, 30  ###reference_b30###]. Unlike our work, most such studies focus only on estimating instance attributions corresponding to those of high-level features. For example, Early et al. proposed to estimate instance attributions by learning surrogate models with MIL-suitable kernel functions [7  ###reference_b7###]. Several studies have addressed estimating feature attributions effectively by leveraging group information of input features. In the natural language processing literature, some studies estimated sentence- and phrase-level feature attributions by grouping words in the same sentence and phrase together and regarding them as a single feature [33  ###reference_b33###, 19  ###reference_b19###]. In addition, Rychener et al. showed that word-level feature attributions can be improved by generating perturbations at a sentence level, mitigating the issues of out-of-distribution for the model and high-dimensional search space [24  ###reference_b24###]. In the official SHAP library [27  ###reference_b27###], by grouping input features by hierarchical clustering in advance and generating perturbations at the group level, one can reduce the number of queries to the model. If we consider high-level features as nodes and low-level features as the features of the nodes and then somehow put edges between the nodes, we can think of an input as a graph. By doing so, model-agnostic explanation methods for graphs, such as GNNExplainer [32  ###reference_b32###] and GraphLIME [12  ###reference_b12###], can be applied to our task. However, since this approach highly relies on the graph structure, additional information is required to create appropriate edges."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Proposed Method",
            "text": "In the proposed method, the dominant computation cost is brought by the predictions of the black-box model  for the perturbations, whose computational time complexity is  where  and  are the numbers of perturbations for the HiFAs and LoFAs, respectively, and  is the computational time complexity of  in prediction once.\n is often large when executing large models and models provided as cloud services.\nTherefore, estimating the HiFAs and LoFAs accurately with small  and  is crucial.\nIn the experiments in Section 4  ###reference_###, we demonstrate that the proposed method can estimate high-quality HiFAs and LoFAs even when  and  are small.\nA detailed discussion on the computational time complexity is provided in Appendix B  ###reference_###."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Two-level Nested Feature Attributions with Surrogate Models",
            "text": "The model  to be explained is a trained black-box model that takes an arbitrary input, such as tabular, image and text, , and outputs a prediction  where  is the input space and  is the number of classes.\nThe input  is made of two-level nested features, referred to as high-level and low-level features, and the high-level feature is decomposed into multiple low-level features.\nIn particular, the input  is represented as a set or sequence of  high-level features, i.e.,  where  is the -dimensional low-level feature vector representing the -th high-level feature.\nOne example of such input appears in image classification under the MIL setting.\nIn this setting, the input is a bag of images, the high-level feature is an image in the bag, and the low-level features correspond to super-pixels in the image.\nAnother example appears in a document classification where the input is a sequence of sentences, the high-level feature is a sentence in the sequence, and the low-level features correspond to the words in the sentence.\nWe consider estimating the high-level feature attributions (HiFAs) and low-level feature attributions (LoFAs) that explain the prediction of the black-box model  for the input  using surrogate models as with LIME and Kernel SHAP.\nThe HiFAs and LoFAs represent how much high- and low-level features in the input contribute to the prediction, respectively.\nIn the aforementioned MIL setting, the HiFAs represent how much images in the input bag contribute to the prediction, which is also referred to as instance attributions in the literature, and the LoFAs represent how much super-pixels in the images contribute to the prediction. To estimate the HiFAs and LoFAs, we introduce two-level local linear surrogate models for high-level and low-level features,  and , that mimic the behaviors of the black-box model  around the input , as follows:\nwhere  and  with  are simplified inputs associated with the input , which are used to indicate the presence or absence of the high- and low-level features in , respectively;  and  with  are the learnable coefficients of these surrogate models, and after learning, they will be the HiFAs and LoFAs themselves, respectively.\nFor ease of computation below, we define the concatenation of  and  over the high-level features as  and , where .\nThe surrogate models are learned with the predictions of the black-box model  for perturbations around the input .\nThe perturbations are generated by sampling the simplified inputs  and  from binary uniform distributions and then constructing masked inputs  depending on the simplified inputs, respectively.\nHere,  and  are mask functions that replace the input \u2019s dimensions associated with the dimensions being zero in the simplified inputs  and  with uninformative values, such as zero, respectively.\nLet  and  be the matrices whose rows are the generated simplified inputs for the high- and low-level features, respectively, where  and  are the numbers of perturbations used to estimate the HiFAs and LoFAs, respectively.\nAlso, let  and  be the predictions of the black-box model for the perturbations where  and .\nSimply, the parameters of the surrogate models, i.e., the HiFAs  and LoFAs , can be estimated by solving the following weighted least squares separately:\nwhere  and  are the diagonal matrices whose th diagonal elements represent the sample weights for the th perturbation;  and  are the regularizers for the HiFAs and LoFAs, respectively;  and  are the regularization strengths."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Joint Optimization with Consistency Constraints",
            "text": "Although the HiFAs and LoFAs provide different levels of explanations, these explanations for the same black-box model should be consistent between them.\nFrom the linearity of the surrogate models and the fact that each high-level feature can be decomposed into low-level features, the following property is expected to be satisfied:\nThe two surrogate models (1  ###reference_###) satisfying the consistency property behave equivalently for the simplified inputs  and  such that if  then , and if  then  where  and  are the -dimensional zero and one vectors, respectively.\nThe consistency property is essential to provide consistent and convincing explanations to humans.\nHowever, it is often not satisfied for two reasons in practice.\nFirst, the number of perturbations is insufficient to accurately estimate the feature attributions because the number of queries to the model  is often limited due to the computational time and request costs.\nSecond, in the predictions for the perturbations, the behaviors of the model  can differ between when the high-level features are masked out and when the low-level ones are masked out due to missingness bias [14  ###reference_b14###].\nTo overcome these problems, the proposed method estimates the HiFAs and LoFAs simultaneously by solving the following optimization with consistency constraints:\nThe consistency constraints bridge the two surrogate models, forcing them to behave equivalently.\nThis helps complement the insufficiency of the queries to the model and mitigate the negative effects of the missingness bias on the estimation of the HiFAs and LoFAs.\nWe solve the optimization based on the alternating direction method of multipliers (ADMM) [1  ###reference_b1###].\nThe detailed derivation of the optimization algorithm is provided in Appendix A  ###reference_###.\nAn advantage of employing the ADMM is that despite the interdependence of  and  caused by the consistency constraints, they can be estimated independently as in (2  ###reference_###) and (3  ###reference_###).\nIn addition, the solution has another merit in that we can implement various types of regularizations and constraints for  and , such as sparse regularization and non-negative constraints in  and .\nIn this paper, we instantiate the proposed method with the LIME-like formulation, that is, we use the cosine kernel for calculating the sample weights  and  and the  regularization for  and .\nThe optimization algorithm for this instantiation is provided in Algorithm 1  ###reference_### in Appendix A  ###reference_###.\nIn the proposed method, the dominant computation cost is brought by the predictions of the black-box model  for the perturbations, whose computational time complexity is  where  and  are the numbers of perturbations for the HiFAs and LoFAs, respectively, and  is the computational time complexity of  in prediction once.\n is often large when executing large models and models provided as cloud services.\nTherefore, estimating the HiFAs and LoFAs accurately with small  and  is crucial.\nIn the experiments in Section 4  ###reference_###  ###reference_###, we demonstrate that the proposed method can estimate high-quality HiFAs and LoFAs even when  and  are small.\nA detailed discussion on the computational time complexity is provided in Appendix B  ###reference_###  ###reference_###."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "We conducted experiments on two tasks, image classification in an MIL setting and text classification using language models, to evaluate the effectiveness of the proposed method, referred to as Consistent Two-level Feature Attribution (C2FA).\nIn the experiments, we implemented the proposed method in Algorithm 1  ###reference_### in Appendix A  ###reference_###.\nIts hyperparameters, , , and , were tuned using the validation subset of each dataset within the following ranges: , and .\nThe remaining hyperparameters were set to , , respectively.\nAll the experiments were conducted on a server with an Intel Xeon Gold 6148 CPU and an NVIDIA Tesla V100 GPU.\nAs comparing methods, we used the following five methods, named LIME [22  ###reference_b22###], MILLI [7  ###reference_b7###], Bottom-Up LIME (BU-LIME), Top-Down LIME (TD-LIME), and Top-Down MILLI (TD-MILLI).\nWith LIME, we estimated the HiFAs and LoFAs separately by solving (2  ###reference_###) and (3  ###reference_###), respectively, where we used the cosine kernel for the sample weights and  regularization for  and .\nHence, LIME can be regarded as the proposed method without the consistency constraints.\nMILLI is the state-of-the-art instance attribution method in the MIL setting, which was proposed for estimating the HiFAs only.\nTherefore, we estimated the LoFAs in MILLI as with LIME.\nWith BU-LIME, we first estimated the LoFAs using LIME and then calculated the HiFAs of each high-level feature by summing the LoFAs associated with the high-level feature.\nThis method always satisfies the consistency property because the HiFAs are calculated from the LoFAs.\nWith TD-LIME and TD-MILLI, we first estimated the HiFAs using LIME and MILLI, respectively.\nThen, for the th high-level feature, we determined the FAs associated with it, , with the samples from the normal distribution with the mean of the th HiFA  and the standard deviation of .\nFinally, by selecting the th low-level feature at random and replacing it with , we obtained the LoFAs associated with the th high-level feature such that they satisfy the consistency property.\nWe constructed an MIL dataset from the Pascal VOC semantic segmentation dataset [8  ###reference_b8###] that allows us to evaluate the estimated HiFAs and LoFAs with the ground-truth instance- and pixel-level labels.\nWith the training subset of the dataset, each sample (bag) has from three to five images (high-level features) drawn at random from the training subset of the Pascal VOC.\nHere, low-level features correspond to regions (super-pixels) of each image, which are obtained by the quick shift algorithm [31  ###reference_b31###].\nEach bag is labeled positive if at least an image in the bag is associated with \u201ccat\u201d label and negative otherwise.\nAlso, each image pixel is labeled positive if the pixel is associated with \u201ccat\u201d label and negative otherwise.\nWe used the instance- and pixel-level supervision only for evaluation.\nSimilarly, we constructed validation and test subsets whose samples contain images from the training and test subsets of the Pascal VOC, respectively.\nThe number of samples in training, validation, and test subsets is 5,000, 1,000, and 2,000, respectively, and the positive and negative samples ratio is equal.\nWe used DeepSets permutation-invariant model [34  ###reference_b34###] with ResNet-50 [11  ###reference_b11###] as black-box model  to be explained.\nWe describe the implementation details of the model in Appendix C.1  ###reference_###.\nHere, the test accuracy of the model was 0.945.\nWe assessed the estimated HiFAs and LoFAs in terms of correctness, faithfulness, and consistency.\nThe correctness is evaluated using the ground-truth instance- and pixel-level labels.\nFollowing the evaluation in the MIL study [7  ###reference_b7###], we evaluated the estimated HiFAs with normalized discounted cumulative gain (NDCG).\nFor the estimated LoFAs, as with the evaluation of the LoFAs for single image classification [26  ###reference_b26###], we evaluated them as the predictions of the pixel-level labels by the area under ROC curve (AUROC) in the binary semantic segmentation manner.\nIn the faithfulness evaluation, we assessed whether the estimated HiFAs and LoFAs are faithful to the behaviors of the model  based on insertion and deletion metrics.\nThe insertion and deletion metrics evaluate the change in the predictions of the model  when features deemed important in the LoFAs are gradually added and removed from the sample, respectively [20  ###reference_b20###].\nIn our experiments, we gradually add and remove the low-level features across all the high-level features in descending order of their LoFAs.\nAlso, for the HiFAs, we add and remove the high-level features instead of the low-level ones, respectively.\nIn terms of the consistency evaluation, we used the following two metrics.\nThe first one is the consistency between the estimated HiFAs and LoFAs, which is calculated with  used to calculate the penalty for the consistency constraints in (A  ###reference_###).\nThe second one is the agreement of the most important high- and low-level feature (MIHL), which is calculated by the ratio that the high-level feature of the highest HiFA is identical to the one associated with the low-level feature of the highest LoFA.\nWe evaluated the above metrics using only the samples with the positive bag label because we could not evaluate the correctness of those with the negative bag label.\nWe ran the evaluations three times with different random seeds and reported the average scores and their standard deviation.\nFor evaluation, we constructed a dataset whose validation and test subsets are made of 500 and 1,000 product review texts extracted randomly from the training and test subsets of the Amazon reviews dataset [35  ###reference_b35###], respectively.\nEach sample in the dataset is made of multiple sentences regarded as high-level features, where each sentence is represented as a sequence of words regarded as low-level features, and the sample label represents the review\u2019s polarity, positive or negative.\nTo simulate access to black-box language models provided as cloud services, we experimented using BERT [5  ###reference_b5###] with the weights fine-tuned on the original Amazon reviews dataset, which is provided on Hugging Face [9  ###reference_b9###].\nThe test accuracy of the model is 0.947.\nWhen masking a word in the input to generate perturbed inputs, we replaced the word with the predefined mask token [MASK].\nSimilarly, when masking a sentence, we replaced all the words in the sentence with the mask token.\nBecause no ground-truth labels for HiFAs and LoFAs are available in the dataset, we evaluated the estimated HiFAs and LoFAs only in terms of faithfulness and consistency, as with Section 4.1  ###reference_###."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Image Classification in Multiple Instance Learning",
            "text": "###figure_2### ###figure_3### ###figure_4### ###figure_5### ###figure_6### ###figure_7### We constructed an MIL dataset from the Pascal VOC semantic segmentation dataset [8  ###reference_b8###  ###reference_b8###] that allows us to evaluate the estimated HiFAs and LoFAs with the ground-truth instance- and pixel-level labels.\nWith the training subset of the dataset, each sample (bag) has from three to five images (high-level features) drawn at random from the training subset of the Pascal VOC.\nHere, low-level features correspond to regions (super-pixels) of each image, which are obtained by the quick shift algorithm [31  ###reference_b31###  ###reference_b31###].\nEach bag is labeled positive if at least an image in the bag is associated with \u201ccat\u201d label and negative otherwise.\nAlso, each image pixel is labeled positive if the pixel is associated with \u201ccat\u201d label and negative otherwise.\nWe used the instance- and pixel-level supervision only for evaluation.\nSimilarly, we constructed validation and test subsets whose samples contain images from the training and test subsets of the Pascal VOC, respectively.\nThe number of samples in training, validation, and test subsets is 5,000, 1,000, and 2,000, respectively, and the positive and negative samples ratio is equal.\nWe used DeepSets permutation-invariant model [34  ###reference_b34###  ###reference_b34###] with ResNet-50 [11  ###reference_b11###  ###reference_b11###] as black-box model  to be explained.\nWe describe the implementation details of the model in Appendix C.1  ###reference_###  ###reference_###.\nHere, the test accuracy of the model was 0.945.\nWe assessed the estimated HiFAs and LoFAs in terms of correctness, faithfulness, and consistency.\nThe correctness is evaluated using the ground-truth instance- and pixel-level labels.\nFollowing the evaluation in the MIL study [7  ###reference_b7###  ###reference_b7###], we evaluated the estimated HiFAs with normalized discounted cumulative gain (NDCG).\nFor the estimated LoFAs, as with the evaluation of the LoFAs for single image classification [26  ###reference_b26###  ###reference_b26###], we evaluated them as the predictions of the pixel-level labels by the area under ROC curve (AUROC) in the binary semantic segmentation manner.\nIn the faithfulness evaluation, we assessed whether the estimated HiFAs and LoFAs are faithful to the behaviors of the model  based on insertion and deletion metrics.\nThe insertion and deletion metrics evaluate the change in the predictions of the model  when features deemed important in the LoFAs are gradually added and removed from the sample, respectively [20  ###reference_b20###  ###reference_b20###].\nIn our experiments, we gradually add and remove the low-level features across all the high-level features in descending order of their LoFAs.\nAlso, for the HiFAs, we add and remove the high-level features instead of the low-level ones, respectively.\nIn terms of the consistency evaluation, we used the following two metrics.\nThe first one is the consistency between the estimated HiFAs and LoFAs, which is calculated with  used to calculate the penalty for the consistency constraints in (A  ###reference_###  ###reference_###).\nThe second one is the agreement of the most important high- and low-level feature (MIHL), which is calculated by the ratio that the high-level feature of the highest HiFA is identical to the one associated with the low-level feature of the highest LoFA.\nWe evaluated the above metrics using only the samples with the positive bag label because we could not evaluate the correctness of those with the negative bag label.\nWe ran the evaluations three times with different random seeds and reported the average scores and their standard deviation."
        },
        {
            "section_id": "4.1.1",
            "parent_section_id": "4.1",
            "section_name": "4.1.1 Results",
            "text": "Figure 2(a)  ###reference_sf1### shows the NDCG and deletion scores of the estimated HiFAs over various numbers of perturbations for the LoFAs, , where we fixed the number of perturbations for the HiFAs, .\nWe found that the proposed method (C2FA) consistently achieved the best NDCG and deletion scores, and the superiority of the proposed method is especially noticeable when  is small.\nAlthough BU-LIME improved the scores as  increased, the scores were still lower than those of the proposed method.\nSince the other comparing methods estimate the HiFAs without the effects of the LoFAs, their scores were constant regardless of the value of .\nIn Appendix C.2  ###reference_###, we show that similar results were obtained in terms of the insertion metric.\nIn addition, when we fixed , the methods other than BU-LIME equally achieved the highest NDCG and insertion scores regardless of  because  was sufficiently large to estimate the HiFAs accurately.\nFigure 2(b)  ###reference_sf2### shows the AUROC and deletion scores of the estimated LoFAs over various values of  where we fixed .\nWhen  is small, we found that the proposed method significantly achieved the highest AUROC and deletion scores.\nIn particular, the AUROC score of the proposed method at  was much the same as those of the second-best methods, LIME, MILLI, and BU-LIME, at , and the deletion score of the proposed method at  was much the same as that of the second-best methods at .\nThese results show that the proposed method is very efficient for the number of queries to the model  owing to the simultaneous estimation of the HiFAs and LoFAs.\nInput (bag of images)\n\n\nC2FA\n\n\nLIME\n###figure_8### ###figure_9### ###figure_10### Figure 2(c)  ###reference_sf3### shows the consistency scores and the agreement scores of MIHL over various values of  where we fixed .\nHere, the consistency scores of BU-LIME, TD-LIME, and TD-MILLI are always zero by definition.\nWe found that the consistency scores of LIME and MILLI were worse because they estimated the HiFAs and LoFAs separately.\nOn the other hand, those of the proposed method were nearly zero, which means that the estimated HiFAs and LoFAs satisfied the consistency property.\nWith the agreement scores of MIHL, we found that the proposed method outperformed the other methods regardless of the values of , and the differences in the scores were especially noticeable at the small  values, i.e., .\nWe visualize an example of the estimated HiFAs and LoFAs by the proposed method and the best-comparing method, LIME, in Figure 3  ###reference_###.\nHere, we only display the LoFAs larger than 0.1 for ease of understanding.\nThe figure shows that the proposed method assigned a high LoFA to the super-pixel in\nthe high-level feature with the positive and highest HiFA (HiFA = 0.89), although LIME assigned high LoFAs to the super-pixels in the negative instances.\nThe critical difference between the two methods is whether the HiFAs and LoFAs are estimated simultaneously or separately.\nSince both the proposed method and LIME assigned the highest HiFA to the positive instance correctly, the result indicates that estimating the HiFAs and LoFAs simultaneously is effective.\nSimilar results were obtained in other examples shown in Appendix C.3  ###reference_###."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Text Classification Using Language Models",
            "text": "Another practical application of the proposed method is to explain the attributions of sentences and the words they contain in text classification with language models.\nFor evaluation, we constructed a dataset whose validation and test subsets are made of 500 and 1,000 product review texts extracted randomly from the training and test subsets of the Amazon reviews dataset [35  ###reference_b35###  ###reference_b35###], respectively.\nEach sample in the dataset is made of multiple sentences regarded as high-level features, where each sentence is represented as a sequence of words regarded as low-level features, and the sample label represents the review\u2019s polarity, positive or negative.\nTo simulate access to black-box language models provided as cloud services, we experimented using BERT [5  ###reference_b5###  ###reference_b5###] with the weights fine-tuned on the original Amazon reviews dataset, which is provided on Hugging Face [9  ###reference_b9###  ###reference_b9###].\nThe test accuracy of the model is 0.947.\nWhen masking a word in the input to generate perturbed inputs, we replaced the word with the predefined mask token [MASK].\nSimilarly, when masking a sentence, we replaced all the words in the sentence with the mask token.\nBecause no ground-truth labels for HiFAs and LoFAs are available in the dataset, we evaluated the estimated HiFAs and LoFAs only in terms of faithfulness and consistency, as with Section 4.1  ###reference_###  ###reference_###."
        },
        {
            "section_id": "4.2.1",
            "parent_section_id": "4.2",
            "section_name": "4.2.1 Results",
            "text": "###figure_11### ###figure_12### ###figure_13### ###figure_14### Figure 4(a)  ###reference_sf1### shows the deletion scores of the estimated HiFAs and LoFAs over various values of  where we fixed  and , respectively.\nWith the deletion scores of the HiFAs, although the scores of the proposed method were equal to or worse than those of MILLI and TD-MILLI at , the proposed method achieved the best at .\nWe found that in this task, the LIME-based methods, including the proposed method, were worse than the MILLI-based methods at the small  values.\nAs  increased, the proposed method benefited from the consistency constraints and became the only LIME-based method that outperformed the MILLI-based methods.\nIn Appendix D.1  ###reference_###, we show that similar results were obtained in terms of the insertion metric, and when we fixed , the scores did not change regardless of the values of  because  was sufficiently large to estimate the HiFAs accurately.\nWith the deletion scores of the LoFAs, the proposed method outperformed the other methods regardless of the values of .\nFigure 4(b)  ###reference_sf2### shows the consistency scores and the agreement scores of MIHL over various values of  where we fixed .\nAgain, in this task, the consistency scores of the proposed method were nearly zero regardless of the values of .\nWith the agreement scores of MIHL, the proposed method kept high scores regardless of the values of , although the scores of BU-LIME were slightly better than the proposed method at .\nInput (bag of sentences)\n\n\n\n\nS1:\n\n\ndo not buy this product .\n\n\nS2:\n\n\nthey break too easily and when you want to replace them it is labeled poorly .\n\n\n\n\nC2FA\n\nBU-LIME\n###figure_15### ###figure_16### Figure 5  ###reference_### shows an example of the HiFAs and LoFAs estimated by the proposed method and the second-best method, BU-LIME.\nIn the example, we fixed at  and ; that is,  is insufficient to estimate the LoFAs accurately.\nWe found that although the comparing method assigned higher LoFAs to the words in the second sentence (S2), the proposed method assigned higher LoFAs to the words in the first sentence (S1).\nThis result is because the proposed method can regularize the LoFAs by exploiting the fact that S1 has a high HiFA via the consistency constraints.\nOther examples are shown in Appendix D.3  ###reference_###."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Limitations and Broader Impacts",
            "text": "A possible limitation of the proposed method is that the quality of the HiFAs and LoFAs may be worse in cases where the consistency property is inherently not satisfied.\nFor example, they may happen when the HiFAs and LoFAs are estimated with the combination of different approaches, such as MILLI and LIME, and when the behaviors of the black-box model vary significantly between perturbed inputs that high- and low-level features are partially masked.\nTo detect such an undesirable situation early, monitoring the losses of the surrogate models,  in (2  ###reference_###) and  in (3  ###reference_###), is effective because they are likely to be worse even if the objective (5  ###reference_###) is minimized.\nOur work contributes to improving the transparency of black-box models.\nHowever, it should be noted that high-quality feature attributions may give hints about stealing the information that the model\u2019s providers want to hide, such as the training data and the model\u2019s decision-making process.\nTo prevent such risks, it is essential to establish guidelines that ensure that the feature attributions are not used for malicious purposes."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "We proposed a model-agnostic local explanation method for nested structured inputs, which explains two-level feature attributions, referred to as HiFAs and LoFAs, simultaneously.\nWe hypothesized that the consistency property naturally derived from the characteristics of the surrogate models is essential to produce explanations that are accurate, faithful and consistent between HiFAs and LoFAs with a smaller number of queries to the model.\nThen, we presented an optimization algorithm that estimates the HiFAs and LoFAs while forcing them to ensure the consistency property.\nWe demonstrated that the proposed method can produce high-quality explanations query-efficiently in the experiments on image classification in multiple instance learning and text classification using large language models.\nIn future work, we will expand the applicability of the proposed method by extending it to tasks with three or more levels of nested features, such as multi-multi instance learning [29  ###reference_b29###]."
        }
    ],
    "url": "http://arxiv.org/html/2405.14522v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.1.1",
            "4.2",
            "4.2.1"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4",
            "4.1",
            "4.2",
            "4.1.1",
            "4.2.1"
        ]
    },
    "research_context": {
        "paper_id": "2405.14522v1",
        "paper_title": "Explaining Black-box Model Predictions via Two-level Nested Feature Attributions with Consistency Property",
        "research_background": "### Motivation:\nThe paper is motivated by the growing concern around the opacity of increasingly complex machine learning (ML) models. With models being offered as black-box services, where users have no access to the internal workings or the training data, issues of trust, accountability, and transparency have come to the forefront. This has driven a significant interest in developing techniques to explain predictions made by these black-box models, making their decisions more transparent and interpretable.\n\n### Research Problem:\nThe primary research problem addressed in the paper is the lack of methods that can simultaneously estimate two levels of feature attributions\u2014high-level feature attributions (HiFAs) and low-level feature attributions (LoFAs)\u2014for inputs with nested structures in black-box models. Existing model-agnostic local explanation methods like LIME and Kernel SHAP treat input features as independent variables, which is inadequate for realistic tasks where input features have a nested structure. Existing methods either estimate HiFAs or LoFAs independently or aggregate LoFAs to derive HiFAs, leading to potential inconsistencies and inefficiencies, especially when query constraints exist.\n\n### Relevant Prior Work:\n1. **Local Interpretable Model-agnostic Explanation (LIME) [22] and Kernel SHAP [18]**: Both are representative model-agnostic local explanation methods that approximate the model's behavior with local linear surrogate models around the input. However, they assume a flat structure for inputs.\n   \n2. **Multiple Instance Learning (MIL) [13, 16]**: This is a typical task with nested features where the input is a set of instances, each being a high-level feature decomposable into multiple low-level features.\n\n3. **Instance Attributions in MIL literature [7, 15]**: While HiFAs (referred to as instance attributions) are addressed, there's no simultaneous estimation of both HiFAs and LoFAs observed in prior work.\n\nIn addressing the limitations of existing methods, the paper introduces a new model-agnostic local explanation method that ensures consistency between HiFAs and LoFAs via joint optimization, which leverages the nested structure of inputs, thus potentially reducing the number of queries and improving the interpretability of machine learning models.",
        "methodology": "The proposed method aims to explain the predictions of black-box models by utilizing two levels of Nested Feature Attributions that ensure consistency. The primary innovation lies in the introduction and calculation of High-level Feature Attributions (HiFAs) and Low-level Feature Attributions (LoFAs), which collectively enhance the interpretation of the black-box model's behavior.\n\nKey Components and Innovations:\n\n1. **Two-level Nested Feature Attributions:**\n    - **High-level Feature Attributions (HiFAs):** These provide a broader overview of feature importance.\n    - **Low-level Feature Attributions (LoFAs):** These offer finer, more detailed insights into feature contributions.\n\n2. **Consistency Property:** \n    - The method ensures that the feature attributions remain consistent across different perturbations and model predictions, providing reliable interpretability.\n\n3. **Computational Efficiency:**\n    - The computational time complexity of obtaining model predictions for perturbations is given by \\( \\mathcal{O}(MN) \\), where \\( M \\) and \\( N \\) denote the numbers of perturbations for HiFAs and LoFAs respectively, and \\( P \\) is the computational time complexity of a single prediction by the black-box model.\n    - The method emphasizes the need for accurate estimation of HiFAs and LoFAs with small values of \\( M \\) and \\( N \\) to manage computational resources efficiently.\n\n4. **Practical Implementation:**\n    - The dominant computation cost arises from the predictions of the black-box model on the perturbed data.\n    - The necessity of estimating HiFAs and LoFAs effectively, even with reduced \\( M \\) and \\( N \\), ensures that the method remains applicable to large models, including those provided as cloud services.\n\nThe methodology section states that further experimental validation and a detailed discussion on the computational time complexity are available in other sections of the paper and its appendices.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n#### Experiment Setup\n\n**Tasks:** \n1. **Image Classification in a Multiple Instance Learning (MIL) Setting**\n2. **Text Classification using Language Models**\n\n**Proposed Method:**\n- Consistent Two-level Feature Attribution (C2FA)\n\n**Baseline Methods:**\n1. LIME [22]\n2. MILLI [7]\n3. Bottom-Up LIME (BU-LIME)\n4. Top-Down LIME (TD-LIME)\n5. Top-Down MILLI (TD-MILLI)\n\n**Image Classification Dataset:**\n- Constructed from Pascal VOC semantic segmentation dataset [8]\n- Training, validation, and test subsets with 5,000, 1,000, and 2,000 samples, respectively, with an equal ratio of positive and negative samples\n- DeepSets permutation-invariant model with ResNet-50 as the black-box model\n- Model test accuracy: 0.945\n\n**Text Classification Dataset:**\n- Constructed from Amazon reviews dataset [35]\n- Validation and test subsets with 500 and 1,000 samples, respectively\n- Using BERT fine-tuned on the original Amazon reviews dataset\n- Model test accuracy: 0.947\n\n**Evaluation Metrics:**\n1. **Correctness**\n   - HiFAs: Normalized Discounted Cumulative Gain (NDCG) using ground-truth instance-level labels\n   - LoFAs: Area Under ROC Curve (AUROC) using ground-truth pixel-level labels in a binary semantic segmentation manner\n   \n2. **Faithfulness**\n   - Evaluated using insertion and deletion metrics to assess if the estimated HiFAs and LoFAs are faithful to model behavior\n   \n3. **Consistency**\n   - Consistency between HiFAs and LoFAs calculated using penalty for consistency constraints\n   - Agreement of the most important high- and low-level feature (MIHL)\n\n**Setup Specifics:**\n- Experiments ran on a server with an Intel Xeon Gold 6148 CPU and an NVIDIA Tesla V100 GPU\n- Hyperparameters tuned using validation subsets, with specific values not defined\n\n#### Main Experimental Results\n\n**Image Classification Performance:**\n- **Correctness:** \n   - HiFAs evaluated with NDCG\n   - LoFAs evaluated with AUROC in the binary semantic segmentation manner\n   \n- **Faithfulness:** \n   - Improvement shown by C2FA in insertion and deletion metrics when compared to baselines\n   \n- **Consistency:** \n   - Metrics showed that C2FA consistently improved the consistency between HiFAs and LoFAs over the baseline methods\n\n**Text Classification Performance:**\n- **Faithfulness:** \n   - Improved faithfulness for C2FA demonstrated via insertion and deletion metrics\n   \n- **Consistency:** \n   - Consistency between HiFAs and LoFAs was higher in C2FA relative to baselines\n\nThe results collectively demonstrated that C2FA achieved improvements in correctness for the image classification task, and both faithfulness and consistency for both image and text classification tasks, highlighting the efficacy of the proposed method."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "The goal of this study is to evaluate the effectiveness of the proposed Consistent Two-level Feature Attribution (C2FA) method in estimating high-level and low-level feature attributions simultaneously, and to demonstrate its advantages over existing methods in image classification under a Multiple Instance Learning (MIL) setting.",
            "experiment_process": "Experiments were conducted with five comparative methods: LIME, MILLI, Bottom-Up LIME (BU-LIME), Top-Down LIME (TD-LIME), and Top-Down MILLI (TD-MILLI). The dataset used is a constructed MIL dataset from the Pascal VOC semantic segmentation dataset. Each sample consists of three to five images, and within each image, regions are defined as super-pixels. The models used include DeepSets permutation-invariant model with ResNet-50. Evaluation metrics included correctness (using NDCG for HiFAs and AUROC for LoFAs), faithfulness (using insertion and deletion metrics), and consistency (using two tailored consistency metrics). The study involved running the evaluations three times with different seeds to report average scores and standard deviations.",
            "result_discussion": "C2FA method consistently achieved the best NDCG and deletion scores, and was particularly advantageous when the number of perturbations (n_2) was small. BU-LIME saw improved scores with increased perturbations but still lagged behind C2FA. The proposed method achieved high correctness with best scores in consistency metrics, as well as superior efficiency in terms of queries to the model. Visualizations showed C2FA assigning high low-level feature attributions (LoFAs) to the correct high-level features, unlike LIME. Overall, simultaneous estimation of HiFAs and LoFAs was found to be effective.",
            "ablation_id": "2405.14522v1.No1"
        },
        {
            "research_objective": "This study aims to extend the effectiveness of the C2FA method to text classification using language models, by evaluating the method's ability to explain high-level and low-level feature attributions in text reviews.",
            "experiment_process": "The constructed dataset consists of product review texts from the Amazon reviews dataset where reviews are segmented into sentences (high-level features) and words within sentences (low-level features). The experiment uses a fine-tuned BERT model available on Hugging Face, with an accuracy of 0.947. Masked words and sentences are used for generating perturbed inputs. Metrics used for evaluation include faithfulness (deletion and insertion metrics) and consistency (the same tailored metrics as used in the image classification study).",
            "result_discussion": "In the text classification task, despite some disadvantages in deletion scores for HiFAs at low perturbation numbers, C2FA outperformed other methods at higher perturbation numbers. The deletion scores for LoFAs indicated C2FA's overall superiority. Consistency scores were nearly zero for C2FA, suggesting strong adherence to consistency constraints. Examples and visualizations demonstrated that C2FA assigned higher LoFAs to words in highly relevant sentences, showcasing its regularizing efficacy via consistency constraints.",
            "ablation_id": "2405.14522v1.No2"
        }
    ]
}