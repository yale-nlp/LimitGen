{
    "title": "Presentations are not always linear! GNN meets LLM for Document-to-Presentation Transformation with Attribution",
    "abstract": "Automatically generating a presentation from the text of a long document is a challenging and useful problem. In contrast to a flat summary, a presentation needs to have a better and non-linear narrative, i.e., the content of a slide can come from different and non-contiguous parts of the given document. However, it is difficult to incorporate such non-linear mapping of content to slides and ensure that the content is faithful to the document. LLMs are prone to hallucination and their performance degrades with the length of the input document. Towards this, we propose a novel graph based solution where we learn a graph from the input document and use a combination of graph neural network and LLM to generate a presentation with attribution of content for each slide. We conduct thorough experiments to show the merit of our approach compared to directly using LLMs for this task.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Presentations are a very effective medium of communication in several day-to-day and business workflows.\nCompared to a flat summarization, generating a presentation is more complex because it should have a nice narrative and coherence in the content along with the ability to convey the core ideas to the audience. This makes generating presentation a very tedious process for humans Reynolds (2011  ###reference_b19###).\nDocument-to-slide generation using automatic methods has been garnering attention for several years.\nThese methods include using handcrafted and pre-defined heuristics or web schemas Al Masum et al. (2005  ###reference_b1###); Winters and Mathewson (2019  ###reference_b27###). There are approaches which generate the agenda (i.e., sequence of slide titles) of a presentation based on the sections present in the document (Hu and Wan, 2013  ###reference_b5###; Wang et al., 2017a  ###reference_b24###) or require users to provide an agenda (Sun et al., 2021  ###reference_b21###; Li et al., 2021  ###reference_b9###) and subsequently generate the slides as a single-document query-based summarization. However, manually coming up with an agenda is a difficult task, particularly for documents in the range of 10s of pages.\n###figure_1### This issue can be mitigated to an extent given the recent advances in generative language models Brown et al. (2020  ###reference_b3###); Touvron et al. (2023  ###reference_b23###) with increasing context limits, in which we can prompt a large language model (LLM) to ingest the entire document context and generate an outline and the text content for a presentation. However this approach has three major limitations. First, the LLMs tend to hallucinate more and they often ignore the middle portion of a context as the context length grows Liu et al. (2023a  ###reference_b12###). This can be a serious issue if we want to generate slides from large documents and ensure good coverage of all the important concepts in the presentation. Second, processing the entire document in its reading order by an LLM often results in a summary-like overview of the document, as opposed to capturing a narrative-centric view that is required for a presentation.\nNarratives (flow of information in the form of a story) (Xie and Riedl, 2024  ###reference_b28###) in presentations can be non-linear in nature, i.e., paragraphs from across multiple sections of an input document contribute to a slide, and this is not necessarily in the linear reading order of the document (refer to Figure 1  ###reference_###). As shown in Section 4.6  ###reference_###, non-linearity in presentations generated by the authors for the set of research papers in SciDuet dataset (Sun et al., 2021  ###reference_b21###) is 38.6%, whereas the ones generated by a GPT-based clustering baseline (GDP-GPT in Section 4.2  ###reference_###) has only 1.2%.\nTo generate these narratives, the non-linear relationship between the various pieces of content in the given document needs to be captured. Moreover, LLMs do not attribute the source content (e.g., a paragraph) for each part (e.g., a slide) of the generated content. This attribution is necessary to improve the reliability of the generated presentation and for further editing.\nOne can potentially think of posing the problem of non-linear way of generating presentation as a classification task of classifying a sequence of text elements (say, paragraphs) to one of the  classes where each class represents a slide; or a clustering task of cluster the paragraphs to  clusters. However, the number of slides needed from a document cannot be fixed over a set of documents. It can even vary for the same document depending on the audience, intent and the duration of presentation. Thus, it is not possible to pose it as a -class classification task. Also, clustering as an unsupervised task can cluster text based on multiple aspects such as frequency of common words, common sub-topics, etc., where each generated cluster does not match to a slide.\nTo address the research gaps mentioned above, we propose a novel method of generating text presentation from a long input document as shown in Figure 2  ###reference_###. Our motivation is to infer the structure present between the text elements (i.e., paragraphs) of a document via corresponding latent slides (as shown in Figure 1  ###reference_###) by a learnable graph.\nFollowing are the contributions made in this paper: \n1. Automatically generating a non-linear presentation integrated with the content attribution from a given long document is a novel task to the best of our knowledge. \n2. We propose a novel approach, referred as GDP (Graph based automated transformation of Documents to Presentation), which uses a combination of graph neural network (GNN) and LLM. Our method by design is able to capture the non-linearity in generating the presentation and it attributes the source paragraphs for each generated slide within the presentation. \n3. We propose an evaluation framework which includes both automated and human evaluated metrics for document to presentation transformation. Our analysis shows the merit of GDP over the approaches that directly use SOTA LLM along with intelligent prompting techniques."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Problem Formulation",
            "text": "We are given with a training dataset which is a set of documents and the corresponding presentation slides. Let us denote this dataset as , where  is a document consisting of a sequence of  text paragraphs as , . These paragraphs are indexed following the reading order in the document. Similarly,  is a human-generated presentation from the document . A presentation is a sequence of slides. So, . Please note that different documents can have different number of paragraphs and the corresponding presentations can have different number of slides. As discussed in Section 1  ###reference_###, we consider both the input document and the generated slides to contain only text. Ideally, the presentation should cover all the important aspects of the input document, with a nice flow of information such that it is easy to follow by a broader audience. Given this data, our goal is to generate a presentation for each document present in a test set . The number of slides  to be generated from the test document ,  is a user input during the inference time and we can not assumed this to be a constant over all the test documents. The training set and the test set of documents may come from the same distribution or from different distributions to test the generalizability of our proposed approach.\n###figure_2###"
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Solution Approach",
            "text": "Following are the details of different components of our proposed approach GDP. Figure 2  ###reference_### shows the overall architecture.\nWe assume the input documents are in pdf format. We use a publicly available PDF Extract API ***https://developer.adobe.com/document-services/apis/pdf-extract/  ###reference_ces/apis/pdf-extract/### to extract the text content from the documents. The output of extract is processed in such a way that we have the section and subsection titles and the text in the form of paragraphs within each section or subsection. The sequence of text elements is the same as the reading order of text in the pdf. We are not considering images, tables and other multimodal information present in the document in this work."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Classifier: Dataset and Training",
            "text": "The first step in our approach is training a classifier that can predict the probability of a pair of paragraphs from the given document going into the same slide.\nWe use SciDuet dataset (Sun et al., 2021  ###reference_b21###) which consists of document-presentation pairs, as discussed in section 4.1  ###reference_###. We leverage this dataset to create a synthetic dataset for training our classifier.\nWe use sentence embedding Reimers and Gurevych (2019  ###reference_b18###) for this. Let  be the embedding of -th slide from -th training presentation, and  be the embedding of  paragraph from the corresponding document.\nThe set of selected paragraphs  for a given slide  is determined as .\nWe use a simple heuristic to define the threshold () for paragraph selection as ,\nwhere  is a list of cosine similarity between  and the paragraphs in , and  is standard deviation of that. Paragraphs with a cosine similarity of less than  are discarded to ensure a high-quality dataset. Additionally, we select a maximum of  paragraphs per slide to ensure a balanced dataset. After this exercise, we get the lists of paragraphs that contribute together in the same slide within our training dataset.\n###table_1### Each pair of paragraphs in the list corresponding to a slide forms a positive sample for the classifier. For creating negative samples, for each paragraph, we sample ten random paragraphs from the document that never occurred with that paragraph. Note that by this approach, negative samples will be more than positive ones reflecting the real world scenario. After creating a dataset like this, we select  samples for training and  for testing and validation. Please note that the documents used to create training, test, and validation datasets are mutually exclusive to prevent leakage. Please refer to Table 1  ###reference_### for the dataset details.\nWe fine-tuned a RoBERTa-base model Liu et al. (2019  ###reference_b14###) on this dataset. Since the dataset is imbalanced, we use the standard weighted binary cross-entropy loss function. Best hyperparameters are found using a grid search on the validation set which gives an accuracy of  and an F1 score of  on the test set."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Learning the Graph Structure",
            "text": "For the simplicity of notation, we will use  as the current document from which the presentation needs to be generated. The trained classifier from Section 3.1  ###reference_### will generate a pairwise probability  for any two paragraphs  which determines their chance of contributing to the same slide.\nIdeally, this probability is high when they actually contribute to the same slide and the probability is low when they do not contribute to the same slide.\nWith this intuition, we aim to form a graph  using these pairwise probabilities, where  is the set of nodes,  is the set of edges (undirected and unweighted) and  is a node feature matrix.\nAs a simple heuristic, initially we create a node for each paragraph of the input document . We connect two nodes  and  by an edge if the probability of them contributing to the same slide , where  is a hyperparameter. It is well-understood that not all the paragraphs in a long document are covered in a presentation. To match this intuition and keep the graph small, we remove the isolated nodes from the graph. Each node (paragraph) is also associated with a vector (node feature)  which is the corresponding paragraph embedding as discussed in Section 3.1  ###reference_###. Thus, the structure of the graph is heavily dependent of the trained classifier above. Next, we use a graph neural network to cluster the nodes of this graph so that each cluster can contribute to a slide."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Slide Attribution via GNN and Clustering",
            "text": "Given the graph  from the document , we want to develop an unsupervised graph neural network which can obtain the vector representations (embeddings) of the nodes in such a way that when two nodes are directly connected in the graph, they have similar embeddings than two nodes which are far apart. Subsequently, a clustering algorithm is used on the generated node embeddings to find the clusters. Let us use  to denote the binary adjacency matrix of , where  if there is an edge between the nodes  and , otherwise . We use a 2-layered graph convolution encoder (Kipf and Welling, 2017  ###reference_b7###) to obtain representation of each node as shown below:\nwhere each row of  is the corresponding node embedding. We compute , where  is the identity matrix and the degree diagonal matrix  with , . We set .\n and  are the trainable parameters of this GCN encoder.\nSince the number of slides required for the same document can vary during the inference time depending on the need of a user, we cannot rely on any dataset to give a direct supervision to generate a presentation from a document. So,\nWe use an unsupervised loss function to train the parameters of the proposed GNN architecture. As our aim is to generate similar embeddings for the node pairs which are connected in the graph than any random pairs of nodes, we use the following strategy. For a given graph , node embeddings are obtained by passing node feature matrix  and the graph structure  through the GCN encoder. Next, we randomly add a set of negative edges , with  in the graph. We pose the training task as to minimize the following binary cross entropy loss on positive and negative edges of the graph as shown below:\nHere  is the sigmoid function and  is the -th row of , i.e., the node embedding of the  node in the graph. We use standard ADAM optimization technique (Kingma and Ba, 2014  ###reference_b6###) with a learning rate  to minimize the loss function above.\nOnce the unsupervised training is complete, we obtain the node embedding matrix  from the graph where each row is a paragraph embedding of dimension  from the given document. Since our main goal is to cluster the paragraphs in such a way that each cluster can correspond to a slide, we use spectral clustering (Ng et al., 2001  ###reference_b16###) on these paragraph embeddings from GNN. The number of clusters is kept as the number of slides  required for the document , and this number varies over the documents during inference. We have observed empirically that spectral clustering is able produce more balanced clusters compared to other algorithms such as KMeans on these node embeddings. At the end of this step, we obtain a clustering of paragraphs (nodes) of the current document as ."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Generating the Presentation",
            "text": "Please note that the clusters obtained above are unordered. To be able to generate slides from the clusters, we first order them using a simple heuristic. For any cluster , where , we consider all the paragraphs that belong to that cluster and take the minimum of their indices (please note that paragraph indices follow the reading order in the document as mentioned in Section 2  ###reference_###). Mathematically, . We use this  number to sort the clusters in increasing order and then associate the first cluster (with the smallest  number) as the one corresponding to the first slide, and so on. Since, paragraph indices follow the reading order of the document, we wanted to roughly follow that in the generated presentation. One can see that non-linearity is there in mapping the paragraphs to slides since paragraphs from any part of the document can contribute to any slide of the presentation. Let us reorder the clusters and denote the clustering as , where they are sorted according to the  discussed above.\nNow, let us discuss the generation of the presentation  for the given document . For a slide , we know the corresponding cluster , and the paragraphs forming that cluster. We use GPT-3.5 ***Please note that GDP can support any LLMs even with lesser context length since we feed only a few paragraphs at a time. The choice of GPT-3.5 was to support some of the baselines in Section 4.2  ###reference_### which need to see the entire document within a single prompt. to generate the slides in sequence. To generate a slide , we provide the texts present in the paragraphs , along with the titles of the previous slides . Experimentally, we found that providing information about the previous slides help GPT to maintain a good flow in the presentation. The prompt for the generation of th slide of the presentation is shown in Appendix E  ###reference_###. To generate the whole presentation , we made  such calls in sequence where  is the required number of slides."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "Anonymous link to the selected documents for human evaluation and the corresponding generated presentation can be found in the Appendix. We show the average and standard deviation of ratings by 2 reviewers for five research papers in Table 3  ###reference_###. GDP significantly lags behind baselines and its variant across all metrics. For the GPT based algorithms, a few common concerns were \u201ctitle matches the text in the slide, but the slides go off topic often\u201d, \u201cThere are several details that have not been touched at all, like data collection, annotation, unigram, part-of-speech tag..\u201d and \u201cthere was no significant narration that was conveyed in the ppt\u201d. This aligns with our intuition from Section 1  ###reference_### that GPT struggles with lengthy input contexts. Particularly for research papers, where discussions focus on a single topic with repeated words and concepts, GPT-based algorithms struggle to produce quality output despite various prompting techniques. Whereas for GDP, reviewers appreciate the coverage (\u201cThe reason is simply because all the data was covered by the slides\u201d), non-repetition (\u201cdata provided in the slides wasn\u2019t repeated), consistency and attribution (\u201cno hallucination \u201d). There was also some concern on GDP about the depth of the generated presentation (\u201cThe deck covers a lot of content but doesn\u2019t deep dive\u201d). The human evaluation results for business documents are presented in Table 4  ###reference_###. The results highlight GDP\u2019s ability to generalize to a new domain, outperforming all algorithms in all metrics except slide uniformity. Unlike research papers, business documents have shorter text on average. All the algorithms perform good on building narratives and maintaining information consistency in presentations. However, the reviewers are not satisfied with the language, coverage and utility of the presentations generated by the GPT based algorithms (\u201cThe presentation is not an ideal first draft as it very briefly summarizes the content of the input document with limited accuracy and consistency\u201d). But they do appreciate GDP for these metrics (\u201cThe presentation is an efficient first draft \u201d)."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Datasets",
            "text": "We use the SciDuet dataset proposed in Sun et al. (2021  ###reference_b21###), which has research papers and their presentations. The papers are from ICML, NeurIPS, and ACL. We use papers from ICML and NeurIPS as their PDFs are available. We split 500 papers for training, 80 for validation, and 100 for testing. This dataset is used to train the classifier (\u00a73.1  ###reference_###), find the right hyperparameters, and perform final testing. GDP marginally outperforms baselines and its variant across all metrics."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Baseline Algorithms and Model Ablation",
            "text": "We conducted experiments using the D2S model (Sun et al., 2021 ###reference_b21###) and various prompting methods for GPT as baseline algorithms. The prompts for the baseline models are detailed in the Appendix. All baseline experiments employ GPT3.5-turbo-1106 with a 16K context length. \n\n1. D2S: We employed the D2S model (Sun et al., 2021 ###reference_b21###) as a semi-automatic baseline. D2S utilizes ground truth slide titles from the test set to extract content and generate presentations. Due to the absence of checkpoints, training scripts, or datasets for their BERT-based IR model ***https://github.com/IBM/document2slides/issues/3 ###reference_ues/3###, we used a pre-trained BERT model to encode queries. \n\n2. GPT-Flat: In this model, a simple prompt delivers the full input text from the document to GPT to generate the presentation.\n\n3. GPT-COT: Citing Wei et al. (2022 ###reference_b26###), chain-of-thought (COT) prompting enhances LLM performance. This method uses a COT prompt for GPT-3.5 to generate presentations.\n\n4. GPT-Constrained: To optimize text per slide, this method uses a modified COT prompt and includes precise instructions on bullets and word count for slides.\n\n5. GDP-KMeans: This serves as a model ablation for our suggested method. Here, KMeans replaces the graph learning and clustering section on paragraph embeddings (all-mpnet-base-v2) according to Reimers and Gurevych (2019 ###reference_b18###), with the remainder of the pipeline unaltered.\n\n6. GDP-Agglo: Identical to the model ablation study above but uses agglomerative clustering rather than KMeans.\n\n7. GDP-GPT: Another model ablation of GDP, replacing the GDP process which classifies paragraph pairs, constructs a graph, and performs node clustering, with GPT-3.5. This model has GPT-3.5 directly determine which paragraphs contribute to each slide, followed by final presentation generation using the prompts in Section 3.4 ###reference_###.\n\nGDP performs comparably to its baselines across all metrics."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Experimental Setup",
            "text": "We use a RoBERTa base model for a classifier with batch size , a learning rate of , and a dropout of . RoBERTa was finetuned on Nvidia A10 G for 3 hours. We use the all-mpnet-base-v2 sentence transformer model for all our experiments. We use the gpt-3.5-turbo-1106 model for all our experiments with a temperature of  and top_p of . For G-Eval-based evaluation, we use the gpt-4 model with a temperature of , top_p of , and the number of generations as . GDP significantly underperforms baselines and its variant across all metrics."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "Automatic Evaluation Metrics",
            "text": "GDP marginally outperforms baselines and its variant across all metrics."
        },
        {
            "section_id": "4.5",
            "parent_section_id": "4",
            "section_name": "Results and Analysis",
            "text": "We have presented the results of the baseline algorithms and GDP with its model variant on the test set (discussed in \u00a74.1 ###reference_###) in Table 2 ###reference_###. We can make the following observations: (1) We can see that recall of GDP for ROUGE-1 is significantly less compared to GPT based baselines. However, GDP is able to achieve very high ROUGE-1 Precision, beating all baselines but GDP-KMeans. As also discussed in Sun et al. (2021 ###reference_b21###), ROUGE is not the best metric to evaluate presentations as multiple correct presentations differ at the lexical level, thus having different ROUGE1 scores. Our results built trust that GDP outputs important words in the final presentation. (2) GDP performs the best in terms of both paragraph-level and sentence-level coverage. This shows that GDP covers the entire document and does not miss out on some sections, a problem that human annotators also identified with the baselines. (3) GDP and its variant GDP-KMeans and GDP-GPT achieve a very low score of PPL (which indicates better performance) compared to baselines. This means clustering the paragraphs, generating a slide from each cluster, and using suitable prompts ensures a smooth flow of text and information in the presentations generated by GDP. (4) Finally for G-Eval, performance of all the GPT based algorithms, GDP-GPT and GDP are very close. GDP-KMeans perform poorly on G-Eval, providing trust in our algorithm of clustering paragraphs. However, contrary to our expectations, GDP significantly underperforms baselines and its variant across all metrics. Appendix A ###reference_### shows some qualitative analysis of a presentation generated by our proposed approach and compare that with the one generated by a baseline from the same input document."
        },
        {
            "section_id": "4.6",
            "parent_section_id": "4",
            "section_name": "Evaluation of Non-linearity",
            "text": "Following are the observations from this study:\n(1) Human generated presentations are highly non-linear () in nature.\n(2) GDP-KMeans had a very high non-linearity of , even higher than human-generated presentations. On manual inspection, we found that it is clustering some very random paragraphs together, which is undesirable.\n(3) Since, GDP-GPT uses GPT-3.5 to cluster the paragraphs and it is known that GPT tends to follow the ordering of the text present in the context (Liu et al., 2023a  ###reference_b12###), GPT based approaches are inherently quite linear in nature (with a Non-linearity of  for GDP-GPT).\n(3) The construction of graph using the results of the classifier and the subsequent use of GNN and clustering makes GDP quite non-linear () in nature. Graphs are indeed very good to handle non-linearity. Thus, the presentations generated by GDP is less close to human made presentations."
        },
        {
            "section_id": "4.7",
            "parent_section_id": "4",
            "section_name": "Human Evaluation",
            "text": "Presentation quality is subjective, and there is no universally defined best presentation for a given document (Sun et al., 2021  ###reference_b21###). We conduct a comprehensive human evaluation to further understand the presentations generated by our approach and by some selected baselines based on their performance on manual inspection and the available budget. For this task, we discussed with subject matter experts and selected two sets of documents: (1) Five research papers (2) Seven business documents comprising of technical manuals, reports, and news articles. This is a domain shift from the training set. Following are the metrics we have used for human evaluation: 1. Quality of Language; 2. Slide Uniformity to check the alignment between the title and main text, as well as coherence and uniformity within the slide\u2019s content; 3. Coverage of the content; 4. Non-repetition of content across the slides; 5. Quality of Narrative (the flow of information) in the presentation; 6. Consistency by not including any content (or / and hallucination) outside of the given document; 7. Attribution Quality; and 8. Utility to check how easily a user can use / update a generated presentation. More details can be found in the Appendix. We use a Likert scale from 1 to 5 for all the metrics. We hired professional human reviewers ***https://www.upwork.com/, two with research backgrounds for evaluating presentations on research papers and two with experience in professional writing for business documents. We explained the metrics and the evaluation process to them over multiple sessions. They had no knowledge of the algorithms used to prevent preconceived bias. Each reviewer rated each presentation on a scale of 1 to 5 for each metric while also providing explanations. The cohen kappa score for inter annotator agreement is 0.386. Anonymous link to the selected documents for human evaluation and the corresponding generated presentation can be found in the Appendix. We show the average and standard deviation of ratings by 2 reviewers for five research papers in Table 3  ###reference_###  ###reference_###. GDP significantly outperforms baselines across most metrics but not all. For the GPT based algorithms, a few common concerns were \u201ctitle matches the text in the slide, but the slides go off topic often\u201d, \u201cThere are several details that have not been touched at all, like data collection, annotation, unigram, part-of-speech tag..\u201d and \u201cthere was no significant narration that was conveyed in the ppt\u201d. This aligns with our intuition from Section 1  ###reference_###  ###reference_### that GPT struggles with lengthy input contexts. Particularly for research papers, where discussions focus on a single topic with repeated words and concepts, GPT-based algorithms struggle to produce quality output despite various prompting techniques. Whereas for GDP, reviewers appreciate the coverage (\u201cThe reason is simply because all the data was covered by the slides\u201d), non-repetition (\u201cdata provided in the slides wasn\u2019t repeated), consistency and attribution (\u201cno hallucination \u201d). There was also some concern on GDP about the depth of the generated presentation (\u201cThe deck covers a lot of content but doesn\u2019t deep dive\u201d). The human evaluation results for business documents are presented in Table 4  ###reference_###  ###reference_###. The results highlight GDP\u2019s ability to generalize to a new domain, outperforming all algorithms in all metrics except slide uniformity. Unlike research papers, business documents have shorter text on average. All the algorithms perform good on building narratives and maintaining information consistency in presentations. However, the reviewers are not satisfied with the language, coverage and utility of the presentations generated by the GPT based algorithms (\u201cThe presentation is not an ideal first draft as it very briefly summarizes the content of the input document with limited accuracy and consistency\u201d). But they do appreciate GDP for these metrics (\u201cThe presentation is an efficient first draft \u201d)."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Discussions and Conclusion",
            "text": "This paper presents an end-to-end novel approach, GDP, for transforming a long document into a text presentations. GDP employs a classifier to build a document graph, followed by graph neural networks and clustering. It then uses an LLM to generate slides from each paragraph cluster. We propose evaluation frameworks, and the results indicate several drawbacks of directly using GPT-based approaches with different prompting techniques. The evaluation shows that GDP can automatically generate a presentation that serves good as a first draft."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Limitations",
            "text": "In this work, we focus only on the text part of an input document and generate only text presentation. Multimodal content such as images, diagrams and tables carry important information present in a document. Handling such multimodal content and also extract or generate more of them in the output presentation is an interesting problem. We seek to use a vision language model such as CLIP (Radford et al., 2021  ###reference_b17###) or a large multimodal model such as LLaVA (Liu et al., 2024  ###reference_b11###) in our pipeline for this task in some future work.\nAnother important aspect of a presentation is the selection of a relevant template and layout that goes well with the content. For example, a presentation with a formal content should have a different background and colours than the one with a very casual content. Currently in our implementation, we use a default vanilla template for all the generated presentations. Selection or recommendation of a suitable template and layout for a presentation is out of scope for this work and can be addressed in future."
        }
    ],
    "url": "http://arxiv.org/html/2405.13095v1",
    "segmentation": {
        "research_background_sections": [
            "1"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3",
            "3.4"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.2",
            "4.3",
            "4.4",
            "4.5",
            "4.6",
            "4.7"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4.2",
            "4.5",
            "4.6"
        ]
    },
    "research_context": {
        "paper_id": "2405.13095v1",
        "paper_title": "Presentations are not always linear! GNN meets LLM for Document-to-Presentation Transformation with Attribution",
        "research_background": "### Paper's Motivation\nThe paper is motivated by the intrinsic complexity and importance of generating presentations from documents. Unlike simple summaries, presentations need to maintain a coherent narrative and effectively convey core ideas. This is typically a labor-intensive task for humans, and existing automated methods are limited either by reliance on pre-defined heuristics or the need for user-defined agendas, which are challenging to create, especially for lengthy documents.\n\n### Research Problem\nThe research problem addressed by this paper is the development of an automatic method for generating non-linear presentations from long documents, integrating content attribution to enhance reliability and facilitate editing. The paper identifies that current methods tend to produce overly linear summaries and often overlook substantial parts of the document. Additionally, existing large language models (LLMs), despite their capabilities, face significant issues such as hallucinations and context limitations, which inhibit their effectiveness in this task.\n\n### Relevant Prior Work\n\n1. **Heuristic and Schema-Based Approaches**: Prior methods have employed handcrafted and pre-defined heuristics or web schemas for document-to-slide generation (Al Masum et al., 2005; Winters and Mathewson, 2019). These approaches are limited in flexibility and adaptability.\n  \n2. **Agenda-Based Generation**: Previous approaches either automatically generate the agenda of a presentation based on document sections (Hu and Wan, 2013; Wang et al., 2017a) or require users to provide the agenda (Sun et al., 2021; Li et al., 2021). These methods simplify the task but still heavily depend on user input for generating coherent slides.\n\n3. **Single-Document Query-Based Summarization**: Such methods typically generate content based on a pre-defined agenda, but they struggle with longer documents and lack the ability to produce non-linear narratives essential for presentations.\n\n4. **Advancements in Generative Language Models**: Recent advances have increased the potential of LLMs in these tasks (Brown et al., 2020; Touvron et al., 2023). However, LLMs still face challenges like hallucinating facts and ignoring portions of long contexts (Liu et al., 2023a), which undermines their reliability for creating presentations from long documents.\n\n5. **Non-Linear Narratives and Attribution Needs**: Presentations often require a non-linear narrative structure, where content from various sections contributes to a single slide. Existing methods typically fail to capture this non-linearity, and they also do not provide source attribution for the generated presentation content, which is important for reliability and editing purposes.\n\n### Contribution and Novelty\nTo address these limitations, the paper proposes a novel method called Graph based automated transformation of Documents to Presentation (GDP). This method leverages the strengths of Graph Neural Networks (GNNs) combined with LLMs to capture the non-linear relationships between text elements and generate presentations with attributed source content. This approach is designed to provide better coverage, coherence, and reliability in the generated presentations compared to state-of-the-art LLM-based methods. Additionally, the paper introduces an evaluation framework incorporating both automated and human-evaluated metrics for assessing the effectiveness of document-to-presentation transformations.",
        "methodology": "Methodology: Following are the details of different components of our proposed approach GDP. \n\nWe assume the input documents are in pdf format. We use a publicly available PDF Extract API ***https://developer.adobe.com/document-services/apis/pdf-extract/ to extract the text content from the documents. The output of extract is processed in such a way that we have the section and subsection titles and the text in the form of paragraphs within each section or subsection. The sequence of text elements is the same as the reading order of text in the pdf. We are not considering images, tables and other multimodal information present in the document in this work.\n\n### Text Preprocessing and Parsing:\n1. **Text Extraction**: The PDF Extract API is used to retrieve the document's textual content, structured in a manner where section and subsection titles, along with the corresponding paragraph texts, are identified and maintained in their original reading sequence.\n2. **Structure Maintenance**: The extracted text retains the hierarchical structure of sections and subsections, ensuring that the contextual integrity of the document is preserved for further processing.\n\n### Presentation Generation:\nThe methodology relies on a combination of Graph Neural Networks (GNN) and Large Language Models (LLM) to transform the document text into presentation slides. The key components include:\n1. **Text Segmentation**: The continuous document text is segmented into manageable units that can be represented as individual slides.\n2. **Content Attribution**: Ensuring the attributed content from the original document is correctly assigned to corresponding slides in terms of text relevance and context.\n\n### Key Innovations:\n1. **Integration of GNN and LLM**: This unique combination leverages the strengths of GNNs in handling relationships and structures within data, and the LLM's capability in generating coherent and contextually appropriate text suitable for presentation slides.\n2. **Text-to-Slide Transformation**: A novel approach that systematically converts document text into structured presentation slides, preserving the document\u2019s flow and logical progression.\n\nThis pipeline aims to robustly automate the conversion process from extensive text documents to concise, coherent, and structured presentation slides, streamlining knowledge dissemination.\n\nIn summary, the proposed approach uses advanced text extraction tools to process document text and applies a hybrid GNN and LLM model to effectively transform this text into presentation slides. The methodology ensures that the logical sequence and contextual relevance of the document are maintained throughout the transformation process.",
        "main_experiment_and_results": "### Main Experiment Setup and Results:\n\n**Datasets:**\n1. Research Papers - A set of five research papers.\n2. Business Documents - A collection of business-related documents.\n\n**Baselines:**\n1. GPT-based algorithms - Various versions of GPT-models adapted for document-to-presentation tasks.\n\n**Evaluation Metrics:**\n1. Title relevance.\n2. Topic consistency and relevance.\n3. Coverage of details (e.g., data collection, annotation, specific terms).\n4. Non-repetition of content.\n5. Consistency and attribution in the generated presentation.\n6. Depth of content.\n\n**Review Process:**\n- Two reviewers rated the generated presentations for both research papers and business documents categories.\n- Reviewers provided concerns and commendations based on specified metrics.\n- Ratings were expressed in terms of average and standard deviation.\n\n**Main Experimental Results:**\n\n1. **Research Papers:**\n   - **GDP Performance:**\n     - Significantly better than GPT-based baselines across all metrics.\n     - Positive aspects included comprehensive coverage of content, non-repetition, and consistency without hallucinations.\n     - Some reviewers mentioned a lack of depth in the generated presentations.\n   \n   - **GPT-based Algorithms:**\n     - Struggled with maintaining topic relevance and often went off-topic.\n     - Lacked details and significant aspects such as data collection, annotation, and specific linguistic information.\n     - Inability to produce coherent narratives due to lengthy input contexts.\n\n2. **Business Documents:**\n   - **GDP Performance:**\n     - Generally outperformed GPT-based models in most metrics (language, coverage, and utility).\n     - Appreciated as an efficient first draft suitable for the business context.\n     - Did not excel in slide uniformity but addressed other aspects satisfactorily.\n   \n   - **GPT-based Algorithms:**\n     - Did reasonably well in building narratives and maintaining information consistency.\n     - Fell short in producing effective, accurate, and consistent summaries.\n     - Generated presentations were deemed as brief and not ideal for initial drafts by reviewers.\n\nOverall, GDP demonstrated superior performance in both research and business document domains, particularly in terms of maintaining detail, coverage, and overall utility of the presentations. The human evaluators expressed a notable preference for GDP-generated presentations over those created by the GPT-based baselines."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To compare the proposed GDP approach's effectiveness against baseline algorithms using different configurations, particularly focusing on the utility of the graph learning component.",
            "experiment_process": "The study uses the D2S model and various prompting strategies for GPT as baseline algorithms. Experiment groups include: 1) D2S: Semi-automatic generation using ground truth slide titles. 2) GPT-Flat: Simple prompt with full text input. 3) GPT-COT: Chain-of-thought prompting for enhanced performance. 4) GPT-Constrained: Modified COT prompt specifying formatting constraints. 5) GDP-KMeans: Replaces graph learning with KMeans clustering of paragraph embeddings. 6) GDP-Agglo: Uses agglomerative clustering instead of KMeans. 7) GDP-GPT: Replaces the core graph construction and clustering with GPT-3.5 driven paragraph-to-slide mapping. All models utilize GPT3.5-turbo-1106 with a 16K context length and pre-trained BERT models for encoding queries.",
            "result_discussion": "The results show that GDP achieves high ROUGE-1 Precision, indicating significant recall of important words, though overall ROUGE-1 recall is lower than that of GPT-based models. GDP excels in paragraph-level and sentence-level coverage, addressing gaps identified by human annotators in other models. Clustering approaches (GDP-KMeans, GDP-GPT) and GDP produce smoother text flows, reflected in their low PPL scores. GDP outperforms others closely in G-Eval, though D2S shows suboptimal performance across metrics, underscoring LLMs' importance in content generation.",
            "ablation_id": "2405.13095v1.No1"
        },
        {
            "research_objective": "Quantify and evaluate the non-linearity present in presentations generated by GDP and its variants compared to human-created presentations.",
            "experiment_process": "A metric is proposed to quantify non-linearity by analyzing the order of source paragraphs for each slide in the generated presentation. The sequence of paragraph indices is examined for natural ordering, and deviations indicate non-linearity. The process calculates non-linearity values for presentations generated by GDP, GDP-KMeans, and GDP-GPT based on their attribution mechanisms. The study uses the SciDuet dataset from ICML, NeurIPS, and ACL for ground truth comparisons.",
            "result_discussion": "The findings reveal that human-generated presentations exhibit a high degree of non-linearity. Among the models, GDP-KMeans displays excessive non-linearity due to random paragraph clustering, while GDP-GPT shows more linearity, adhering to text order. GDP, utilizing graph construction and GNN, achieves non-linearity close to human presentations, demonstrating the effectiveness of graphs in handling non-linear narrative flows.",
            "ablation_id": "2405.13095v1.No2"
        }
    ]
}