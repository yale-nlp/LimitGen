{
    "title": "Towards a Zero-Data, Controllable, Adaptive Dialog System",
    "abstract": "Conversational Tree Search V\u00e4th et al. (2023) is a recent approach to controllable dialog systems, where domain experts shape the behavior of a Reinforcement Learning agent through a dialog tree.\nThe agent learns to efficiently navigate this tree, while adapting to information needs, e.g., domain familiarity, of different users.\nHowever, the need for additional training data hinders deployment in new domains.\nTo address this, we explore approaches to generate this data directly from dialog trees.\nWe improve the original approach, and show that agents trained on synthetic data can achieve comparable dialog success to models trained on human data, both when using a commercial Large Language Model for generation, or when using a smaller open-source model, running on a single GPU.\nWe further demonstrate the scalability of our approach by collecting and testing on two new datasets: ONBOARD, a new domain helping foreign residents moving to a new city, and the medical domain DIAGNOSE, a subset of Wikipedia articles related to scalp and head symptoms.\nFinally, we perform human testing, where no statistically significant differences were found in either objective or subjective measures between models trained on human and generated data.\n\n\n\nKeywords:\u2009Conversational Systems/Dialogue/Chatbots, Corpus, Usability, User Satisfaction",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1.   Introduction",
            "text": "While the breakthroughs of modern Large Language Models  ###reference_id1### have made the creation of new dialog systems much easier, controlling their generated output remains an open challenge.\nThis makes LLMs  ###reference_id1### especially unsuitable for sensitive domains, e.g., legal or medical domains, where users must be able to implicitly trust the system\u2019s output.\nIn such domains, dialog designers usually have the choice between implementing an FAQ-retrieval system or a hand-crafted dialog system.\nFAQ systems directly match user queries to question/answer pairs curated by domain experts, allowing close control of outputted texts (Wu et al., 2005  ###reference_b37###).\nHowever, as they are single-turn systems and cannot ask clarifying questions, they are only able provide general answers, rather than personalized content for a specific user and their situation.\nIncluding information for multiple cases in one answer would make them unapproachably long, while adding FAQs for each case, would make retrieval challenging.\nRetrieval accuracy itself is an open challenge (Thakur et al., 2021  ###reference_b31###),\ncreating a trade-off: Either providing a single, possibly incorrect answer to a user\u2019s question,\nor providing multiple answers and shifting the burden of selecting the correct one to the user,\nwhich might be challenging for users unfamiliar with the domain.\nDialog systems, in contrast, allow for turn-based interactions, which can provide shorter, personalized answers, as well as support users new to a domain without enough experience to formulate precise questions.\nHowever, such systems either suffer from longer interactions (for handcrafted systems),\nor require large amounts of training data (Raghu et al., 2021  ###reference_b23###) and lack transparency and controllability (Gao et al., 2018  ###reference_b9###) (in the case of machine learning approaches),\nmaking them less suitable for low-resource settings (Zhang et al., 2020  ###reference_b40###) or sensitive domains (Cohen, 2020  ###reference_b5###).\nV\u00e4th et al. (2023  ###reference_b33###) address this problem by proposing a new type of hybrid dialog task bridging these two interaction styles, called  Conversational Tree Search  ###reference_id4### (CTS  ###reference_id4###).\nIn this task, dialog experts first define a dialog tree.\nAn agent then learns to either walk the user through each node in the tree, or to skip over parts not required to answer a user\u2019s more specific question.\nIn this way, the agent is able to adapt its behavior to the user\u2019s preferred interaction style,\nsupporting both specific and vague user queries,\nwithout sacrificing the controllability required in sensitive domains.\nHowever, CTS  ###reference_id4### still requires that dialog designers collect a corpus of real-user utterances, which poses a barrier to scaling this approach to new domains, especially for large and complicated domains.\nThe goal of this paper is to remove this barrier by exploring how CTS  ###reference_id4### can scale to new domains through the use of synthetically generated training data.\nConcretely, we seek to answer the following research questions:\n(RQ1) How can we effectively generate data for a zero data approach to training CTS  ###reference_id4### agents?\n(RQ1.1) How can we analyze the quality of generated data?\n(RQ1.2) How do agents trained on generated data perform in simulation, compared to agents trained on human data?\n(RQ1.3) How well do the data generation techniques transfer to new domains?\n(RQ2) How does a CTS  ###reference_id4### agent trained on generated data perform with real users compared to an agent trained on human data?\nTo address these questions, we investigate how LLMs  ###reference_id1### can be leveraged to automatically generate training data for new domains,\nwhile at the same maintaining the controllability aspect of the CTS  ###reference_id4### task.\nWe compare the quality of different data generation schemes by evaluating the performance of  Reinforcement Learning  ###reference_id2### (RL  ###reference_id2###) agents trained on the synthetic data.\nThen, we test scalability of our approach to new domains in simulation using multiple generative LLMs  ###reference_id1###.\nFinally, we perform user testing to verify the transferability to real-world use cases. All code and data is publicly available.111https://github.com/DigitalPhonetics/conversational-tree-search/tree/generated_v3  ###reference_sational-tree-search/tree/generated_v3###\nOur main contributions are:\n1) Creating two new datasets, ONBOARD and DIAGNOSE.\n2) Improving the training procedure for the CTS  ###reference_id4### agent, increasing absolute dialog success by more than .\n3) Introducing a new prompting method for generating diverse data, and demonstrating that automatic diversity and answerability metrics can provide insights for downstream dialog performance.\n4) Demonstrating that our generation techniques scale to new domains, where agents trained on synthetic data show comparable (no statistically significant difference) or better dialog success than agents trained on human data.\n5) Showing that success of agents in simulation translates to successful interactions with real users, with no statistically significant differences."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2.   Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1.   Task-oriented Dialog Systems",
            "text": "While open-domain dialog systems allow users to freely talk about any topic without a concrete goal, task-oriented dialog systems focus on helping a user reach a specific goal. Many task-oriented dialog systems use a slot-filling approach, where the dialog system tries to fill values for a selection of slots, e.g. cuisine type, that are necessary to reach that goal from the user Bobrow et al. (1977  ###reference_b2###). While slot filling approaches can allow hand-crafted dialog policies to follow pre-defined dialog flows Lucas (2000  ###reference_b15###), or can help efficiently narrowing down searches across e.g. database rows, such as finding restaurants or getting trip recommendations Louvan and Magnini (2020  ###reference_b14###), they are usually unable to perform semantic searches over the dialog domain and in cases of learned systems, unable to follow a dialog-designer controlled flow. Research into adaptive dialog systems aims to misalign dialog system output with user expectations."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2.   Adaptive Dialog Systems",
            "text": "Research into adaptive dialog systems aims to better align dialog system output with user expectations, aiming for a consistency that is difficult to achieve. Much research in this area uses generative models to adapt linguistic style, e.g., adjusting utterances depending on users\u2019 emotional states Ma et al. (2020 ###reference_b16###) or personalities (Yang et al., 2018 ###reference_b38###; Firdaus et al., 2023 ###reference_b8###). However, generative models are by their nature difficult to control (Du\u0161ek and Kasner, 2020 ###reference_b6###). Some approaches even adapt the complexity of language (Janarthanam and Lemon, 2014 ###reference_b10###). In order to adapt underlying system behavior, however, additional cues have usually been required, e.g. social cues like laughter (Ritschel and Andr\u00e9, 2018 ###reference_b27###), or explicit fine-tuning by the user Chen and Pu (2012 ###reference_b3###); Narducci et al. (2018 ###reference_b18###). However, eliciting such social cues is difficult for text-based systems and asking for explicit feedback places extra burden on the user."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "2.3.   Controllable Dialog Systems",
            "text": "In sensitive domains, it is crucial subject-experts maintain control of dialog flow to ensure correctness of system outputs. However, purely handcrafted systems struggle to handle the breadth of possible user inputs. To this end, several hybrid approaches have been investigated. Early approaches involved hand-crafting the set of actions allowed at a given dialog turn Williams (2008  ###reference_b35###). More recent approaches expand on this idea for neural systems (Williams et al., 2017  ###reference_b36###; Liang and Yang, 2018  ###reference_b13###; Razumovskaia and Eskenazi, 2019  ###reference_b25###), where the action space can be constrained using masks, e.g., by automatically converting expert designed dialog trees into hybrid code networks (Shukla et al., 2020  ###reference_b29###). Research into adaptive dialog systems aims to better misalign dialog system output with user expectations. While such approaches help control dialog agent behavior, they do not provide a mechanism for skipping portions of a dialog irrelevant to a user, which leads to longer interactions that can be frustrating for users with more domain familiarity."
        },
        {
            "section_id": "2.4",
            "parent_section_id": "2",
            "section_name": "2.4.   Data Generation and Augmentation",
            "text": "Common data augmentation approaches include lexical substitution Wei and Zou (2019  ###reference_b34###), where tokens are inserted, deleted or substituted with semantically similar replacements, as well as back-translation Sennrich et al. (2016  ###reference_b28###) where data is automatically translated into other languages before being translated back to the source language.\nWhile such approaches can help to expand an existing dataset, they still require seed data, which may not exist for new domains.\nTo address this, research in, e.g., the field of low-resource  Question Answering  ###reference_id3### (QA  ###reference_id3###) has started exploring the role of LLMs  ###reference_id1### in data generation Puri et al. (2020  ###reference_b21###); Chen et al. (2023  ###reference_b4###).\nGiven a text, LLMs  ###reference_id1### can be prompted to generate questions about it, e.g., by asking the model to generate a question for which a given named entity is the answer (Li et al., 2023  ###reference_b12###).\nHowever, LLMs  ###reference_id1### are black-box algorithms and suffer from hallucination Azaria and Mitchell (2023  ###reference_b1###); Peng et al. (2023  ###reference_b20###); Manakul et al. (2023  ###reference_b17###).\nAs such, it is difficult to guarantee that the generated questions are logical, natural, or answerable by the original text.\nMoreover, commonly used automatic evaluation metrics for text generation do not necessarily correlate with human judgment Nema and Khapra (2018  ###reference_b19###).\nIn light of this, we explore different generation strategies and techniques for analyzing the artificial data quality, rather than trusting a single metric.\nA recent approach in the dialog community trains a model for generating synthetic dialog acts and user utterances for flowchart-grounded troubleshooting dialogs Zhan et al. (2023  ###reference_b39###).\nWhile this method also relies on the domain representation in form of a structured graph, our generation approach does not require any model training, nor any training data besides the domain graph itself.\nAdditionally, CTS  ###reference_id4### is not limited to the specific task format of trouble-shooting dialogs. Research into adaptive dialog systems aims to better misalign dialog system output with user expectations."
        },
        {
            "section_id": "2.5",
            "parent_section_id": "2",
            "section_name": "2.5.   Conversational Tree Search",
            "text": "Research into adaptive dialog systems aims to better align dialog system output with user manuals."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3.   Datasets",
            "text": "To investigate the scalability of our data generation techniques, we examine the performance of the CTS  ###reference_id4### agent on three new datasets, and compare to the original REIMBURSE dataset from V\u00e4th et al. (2023  ###reference_b33###).\nIn contrast to the REIMBURSE dataset, the goal of all new datasets is to serve as a zero-data test-bed for testing training and testing models on data generated directly from the nodes themselves.\nWhile we do provide a test and a train set, like that in REIMBURSE, the goal of this is to allow for the training of reference models to act as a benchmark for models trained entirely on generated data."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1.   REIMBURSE",
            "text": "The REIMBURSE dataset as proposed by V\u00e4th et al. (2023  ###reference_b33###) is a German language dataset for the CTS  ###reference_id4### task.\nIt is a challenging real-world dataset in the travel reimbursement domain, created with domain experts.\nAlong with the dialog tree, questions and answer paraphrases were collected from real user interactions.\nThese questions and answer-paraphrases have been split into a train and test set which can each be used by the provided user simulator to generate an arbitrary number of simulated dialogs.\nA breakdown of the dataset statistics can be found in Table 1  ###reference_###.\nAlthough we do not train any new models on this dataset, we use it as a benchmark to compare the performance of our agents to."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2.   REIMBURSE-En",
            "text": "In order to make the CTS  ###reference_id4### task more accessible to a wider audience, we choose to translate the REIMBURSE dataset to English.\nAdditionally, this opens up more options for language models and resources, which might not have been available for the original German data.\nThis dataset represents a direct translation of the REIMBURSE dataset, sharing all of the same characteristics, in order to allow for comparisons to the findings of the original CTS  ###reference_id4### paper.\nThe translation was performed manually by a bilingual domain-expert in order to obtain a faithful and factually correct English equivalent.\nDataset statistics are shown in Table 1  ###reference_###."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "3.3.   DIAGNOSE",
            "text": "The DIAGNOSE dataset was created for the medical domain.\nIt was designed to help users identify different medical conditions based on symptoms, as well as to find out more about treatment options and risk factors.\nThe dataset is based on a small subset of Wikipedia articles about conditions related to scalp and head symptoms.\nDIAGNOSE was designed to be comparatively easy.\nEven though the node texts contain a large amount of domain-specific vocabulary, the dialog tree has a lower maximum node degree and a shallower tree depth than REIMBURSE-En.\nAdditionally, the dialog graph for this domain does not contain any variable- or logic nodes.\nA breakdown of dataset properties can be found in Table 1  ###reference_###.\nAn example node and associated questions can be seen below:\nNode Text Anemia symptoms include fatigue, pale skin and gums, blue color in the whites of the eyes, brittle nails, irritability, dizziness, sore tongue, shortness of breath, unusual food cravings, and headache.\n\\speakQuestion 1 What are symptoms of anemia?\n\\speakQuestion 2 How do I know if I have anemia?\n\\speakQuestion 3 Is a sore tongue a common symptom of anemia?"
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "3.4.   ONBOARD",
            "text": "The ONBOARD dataset provides users with information about moving to a new city in a foreign country, and the legal and financial steps they will need to undertake, i.e., setting up bank accounts, acquiring health insurance, applying for required visas or residence permits, etc.\nThis domain presents an additional challenge as it contains code-switching for topics related to legal issues, in order provide users with official names for documents, concepts, and institutions.\nSimilar to the REIMBURSE dataset, the dialog tree for ONBOARD contains multiple variable nodes and several logic nodes.\nA breakdown of the dataset statistics can be found in Table 1  ###reference_###.\nAn example of a a dialog node and test questions is given below.\nNode Text The registration office will provide you with a confirmation of your registration [Meldebest\u00e4tigung], which you will need for opening a bank account and for obtaining a residence permit (if applicable).\n\\speakQuestion 1 Where do I get confirmation that I\u2019ve registered my address?\n\\speakQuestion 2 What do I need the confirmation of registering my address for?"
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4.   Dialog Agent Implementation",
            "text": "For our RL  ###reference_id2### dialog agent, we follow the architecture and training process outlined in V\u00e4th et al. (2023  ###reference_b33###) with the following changes:\n1) We swap the original language model for an MPNET Song et al. (2020  ###reference_b30###) based Sentence-Transformer Reimers and Gurevych (2019  ###reference_b26###), as the new datasets we introduce are in English, and it reports the highest average performance of pretrained Sentence-Transformers for English.\n2) In contrast to free mode, rewards for guided mode only considered whether the agent moved to the correct next node, rather than checking that a global goal was reached by the end of the dialog.\nAfter analyzing conversations between CTS agent and user simulator obtained by the original implementation, we believe it is more realistic that, even in guided mode, users would have a consistent question they wanted answered.\nTherefore, we now draw global goals for guided mode users (a node anywhere in the graph) instead of choosing one of the immediate neighboring nodes as the next goal each turn.\nWe then assign a large reward to reaching the global goal.\nAt the same time, we keep a small positive reward for skipping to the correct follow-up node along the sampled trajectory, as a sequence of locally correct decisions (reaching a correct immediate neighbor) implies global correctness (reaching the correct goal node).\nThese changes result in a harsher evaluation metric for dialog success, since e.g. in a 5-step dialog, following a correct trajectory, but missing the final goal in the last turn, will now result in a failed dialog ( success) instead of a partially successful dialog ( success), which we consider to be more realistic.\n3) Finally, the original CTS agent was trained jointly on navigating the graph and on predicting the appropriate interaction style (intent).\nHere, we scale the loss of the interaction style prediction objective down to  to emphasize learning Q-values as the main task:\n.\nWe found this had no significant impact on the interaction style prediction F1 score.\n4) We tune several other hyperparameters, increasing the batch size from  to , and the training steps from  to .\nAll hyperparameters for training the dialog agent are listed in Appendix A  ###reference_###."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5.   Data Generation Methods",
            "text": "As the user simulator from V\u00e4th et al. (2023  ###reference_b33###) requires both, initial user questions and per-node user responses, we explore methods for generating both of these types of utterances.\nWe test these generation methods with a small LLM  ###reference_id1###, and with a large commercial one, both of which can process separate system and user input directives.\nThe first method, GenV1, is a naive prompt instructing an LLM  ###reference_id1### to generate diverse, FAQ-style questions about a given dialog node\u2019s text via the system directive.\nThe amount of questions to generate and the node context are then given via user input (see Table 2  ###reference_###).\nFor GenV2, we use the same user input, but change the system directive to explicitly generate shorter questions (Table 2  ###reference_###).\nFor the last method, GenV3, we were inspired by Li et al. (2023  ###reference_b12###) and Chen et al. (2023  ###reference_b4###), who use  Named Entity Recognition  ###reference_id5### (NER  ###reference_id5###) to steer question generation.\nHowever, these approaches only generate cloze questions, where the named entity is the answer, severely limiting the diversity of generated questions (Puri et al., 2020  ###reference_b21###).\nTherefore, we develop a novel mixed method to increase question diversity.\nWe first generate 3 questions about the whole node text using the Method 2, to get a basic coverage of the node.\nThen, we perform NER  ###reference_id5### and explicitly prompt the LLM  ###reference_id1### to generate three questions about each entity \u2013instead of forcing the entities to only be the answer\u2013 using a second set of prompts (see Table 2  ###reference_###).\nIf the total number of generated questions is lower than 10, we generate the difference using Method 2."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "5.1.   Question Generation",
            "text": "The first method, GenV1, is a naive prompt instructing an LLM  ###reference_id1###  ###reference_id1### to generate diverse, FAQ-style questions about a given dialog node\u2019s text via the system directive.\nThe amount of questions to generate and the node context are then given via user input (see Table 2  ###reference_###  ###reference_###).\nFor GenV2, we use the same user input, but change the system directive to explicitly generate shorter questions (Table 2  ###reference_###  ###reference_###).\nFor the last method, GenV3, we were inspired by Li et al. (2023  ###reference_b12###  ###reference_b12###) and Chen et al. (2023  ###reference_b4###  ###reference_b4###), who use  Named Entity Recognition  ###reference_id5###  ###reference_id5### (NER  ###reference_id5###  ###reference_id5###) to steer question generation.\nHowever, these approaches only generate cloze questions, where the named entity is the answer, severely limiting the diversity of generated questions (Puri et al., 2020  ###reference_b21###  ###reference_b21###).\nTherefore, we develop a novel mixed method to increase question diversity.\nWe first generate 3 questions about the whole node text using the Method 2, to get a basic coverage of the node.\nThen, we perform NER  ###reference_id5###  ###reference_id5### and explicitly prompt the LLM  ###reference_id1###  ###reference_id1### to generate three questions about each entity \u2013instead of forcing the entities to only be the answer\u2013 using a second set of prompts (see Table 2  ###reference_###  ###reference_###).\nIf the total number of generated questions is lower than 10, we generate the difference using Method 2."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "5.2.   Response Generation",
            "text": "To generate responses, we extract all nodes requiring user input from the dialog graph.\nThen, we instruct the LLMs  ###reference_id1### to generate 5 paraphrases for each possible answer prototype, in the context of the full node text (Table 3  ###reference_###; A).\nAdditionally, to mimic different user interaction styles, we instruct the LLMs  ###reference_id1### to generate 5 paraphrases of the the responses using only keywords (Table 3  ###reference_###; B)."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6.   Experimental Setup",
            "text": "We asked each participant to interact with either a CTS agent trained on real data or one trained on generated data in the REIMBURSE domain.\nApart from demographic information, we ask for previous experience with dialog systems and with business travel.\nDuring the experiment, participants were asked to complete three conversations with their assigned dialog system.\nEach conversation, they were randomly assigned a new goal, covering one of three expected interaction styles: 1) \u201copen\u201d goals representing a general/vague information need, 2) \u201ceasy\u201d goals representing a concrete information need, and 3) \u201chard\u201d goals representing a concrete information need requiring personalized information to correctly answer.\nPersonalized information refers to the user\u2019s specific circumstances, e.g. trip duration or funding organization, which can change the dialog flow.\nBetween each dialog, users were asked to rate their subjective perception of dialog length and how well their question was answered.\nAfter the interaction, they were asked rate the usability of the dialog agent, how much they trusted it, and its reliability.\nFor more details see Appendix B  ###reference_###."
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "6.1.   RQ 1.1: Analysis of Generated Data",
            "text": "We generate data using the methods described in sections 5.1  ###reference_### and 5.2  ###reference_###.\nWe use two different LLMs  ###reference_id1###: ChatGPT (gpt-3.5-turbo, via API) 222https://platform.openai.com/docs/models/gpt-3-5  ###reference_t-3-5### and a LLAMA-based Touvron et al. (2023  ###reference_b32###), instruction fine-tuned and quantized model 333https://huggingface.co/TheBloke/upstage-llama-30b-instruct-2048-GPTQ  ###reference_ama-30b-instruct-2048-GPTQ### that fits onto a single NVIDIA GeForce RTX 3090 graphics card. GenV3 uses Stanza Qi et al. (2020  ###reference_b22###) for NER  ###reference_id5###.\nTo calculate question similarity, we use the Sentence-Transformer model from section 4  ###reference_###.\nAnswer confidence scores are calculated with a QA  ###reference_id3### model 444https://huggingface.co/deepset/roberta-large-squad2  ###reference_ge-squad2### pretrained on the SQUAD2.0 dataset Rajpurkar et al. (2018  ###reference_b24###), using a generated question and associated node text that is supposed to contain the answer as inputs.\nFinally, we measure diversity using Self-BLEU Zhu et al. (2018  ###reference_b41###) scores."
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "6.2.   RQ 1.2: Human Data vs. Synthetic Data",
            "text": "For automatic evaluation, we use the updated CTS  ###reference_id4### user simulator (section 4  ###reference_###) with 500 randomly chosen dialog goals on the REIMBURSE-En test split.\nWe evaluate not only the combined success rate (average between guided and free mode success), but also present a metric representing the user\u2019s perceived dialog length, which counts only the nodes shown to the user."
        },
        {
            "section_id": "6.3",
            "parent_section_id": "6",
            "section_name": "6.3.   RQ 1.3: Method Generalizability",
            "text": "To evaluate how well our data generation method generalizes to new domains, we perform additional evaluation in simulation, analogous to (section 6.2  ###reference_###), using the test splits of the new datasets ONBOARD and DIAGNOSE."
        },
        {
            "section_id": "6.4",
            "parent_section_id": "6",
            "section_name": "6.4.   Human Evaluation (RQ 2)",
            "text": "To understand how performance of an agent trained on generated data translates to real-world users, we recruit 44 participants from the crowdsourcing platform Prolific555https://www.prolific.com  ###reference_www.prolific.com### to take part in human evaluation.\nParticipants were native English speakers with varying experience with business travel (self-rating between 2 and 5 on a 5 point Likert-scale).\nThey were compensated at the platform recommended rate of 9 /hour.\nThe experiment took roughly 20 minutes.\nWe asked each participant to interact with either a CTS agent trained on real data or one trained on generated data in the REIMBURSE domain.\nApart from demographic information, we ask for previous experience with dialog systems and with business travel.\nDuring the experiment, participants were asked to complete three conversations with their assigned dialog system.\nEach conversation, they were randomly assigned a new goal, covering one of three expected interaction styles: 1) \u201copen\u201d goals representing a general/vague information need, 2) \u201ceasy\u201d goals representing a concrete information need, and 3) \u201chard\u201d goals representing a concrete information need requiring personalized information to correctly answer.\nPersonalized information refers to the user\u2019s specific circumstances, e.g. trip duration or funding organization, which can change the dialog flow.\nBetween each dialog, users were asked to rate their subjective perception of dialog length and how well their question was answered.\nAfter the interaction, they were asked rate the usability of the dialog agent, how much they trusted it, and its reliability.\nFor more details see Appendix B  ###reference_###  ###reference_###."
        },
        {
            "section_id": "6.4.1",
            "parent_section_id": "6.4",
            "section_name": "6.4.1.   Evaluation Metrics",
            "text": "The perceived dialog length was measured on a 5-point scale from 1 (much too short) to 5 (much too long).\nPerceived success was measured on a 4-point scale, where users were asked to rate how well their question had been answered from 1 (not at all) to 4 (completely).\nAdditionally, the objective dialog length and success condition were logged for each dialog.\nUsability of the dialog agent was measured using the Universal Measure of User Experience scale developed by Finstad (2010  ###reference_b7###).\nUser trust was measured using the reliability and trust subscales from K\u00f6rber (2018  ###reference_b11###))."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7.   Results & Discussion",
            "text": "Before testing performance of agents trained on generated data, we first verify our changes to the CTS  ###reference_id4### agent.\nAs the hyperparameters for the original agent were tuned on the German dataset, for fairness, we report the original CTS  ###reference_id4### agent\u2019s performance on both English and German (Table 5  ###reference_###).\nOur changes to the CTS  ###reference_id4### agent improve the combined success rate by over  compared to the original agent on the German REIMBURSE dataset and  for the English REIMBURSE-En.\nIt should be noted that the actual improvement over the German agent is likely larger, as the success metric reported for German comes from (V\u00e4th et al., 2023  ###reference_b33###), rather than the new and harsher metric we use for English (section 4  ###reference_###).\nLooking at the question lengths between human data and data generated by GENV1 (Figure 2  ###reference_###),\nwe observe that the generated questions seem to be longer than human questions.\nWhen manually inspecting the generated questions, we also find them to be much less natural than those from the human data.\n###figure_2### We amend the original prompt used, creating GENV2, to explicitly ask for short outputs (subsection 5.1  ###reference_###) in an effort to align the syntax of the generations better with the human data.\nThis change to the prompt shifts the distribution of question lengths more towards the human training distribution, and qualitatively yields more natural utterances.\nHowever, it still does not ensure that the artificial data is semantically similar to human data.\nTo investigate how semantically similar the generated questions are to human data, we calculate the pair-wise similarities between all human and generated questions for each node from the dialog graph, and then average the similarities across all nodes (Figure 3  ###reference_###).\nHere, we see that the GenV2 data is still quite distinct from the human data.\n###figure_3### When manually inspecting the generations, we find that generated questions tend to focus only on one part of the node text, making them lack diversity and omit topics real users might ask about.\nTo address this, we develop the novel two-step GenV3 prompt, steering the model to explicitly ask about all named entities in a node (subsection 5.1  ###reference_###).\nWe see that doing so significantly () increases the similarity of the generated (avg.: ) to the human training data than GenV2 (avg.: ), as measured with a standard t-test.\nWe also look at the diversity of the generated questions.\nThe self-BLEU scores (Table 4  ###reference_###) show that the GenV3 data are the most diverse.\nThis metric can be used to analyze the quality of the generated data even in the absence of human comparison data.\nIn conjunction with diversity, we estimate the average \u201canswerability\u201d via QA  ###reference_id3### confidence scores of the generated questions, given the node text as answer.\nHere, we also see that the improvements from GenV3 and GenV2 together also significantly () increase the average answerability, from an average of  with naive prompt to  with GenV3, according to a t-test.\nWhen looking at downstream performance (Table 5  ###reference_###), we see that improvements in these metrics also lead to higher dialog success, suggesting they can be used as an indicator of generation quality.\nTo investigate whether synthetic data can be a viable alternative to human data, we compare agent performance in simulation.\nFrom Table 5  ###reference_###, we see that the best performing agent trained on artificial data (GenV3: 69.44% success) performs comparably to the best performing agent trained on human data (CTSours: 73.86% success).\nUsing a standard t-test, we find no statistically significant difference.\nTo test of the scalability of our generation methods, we analyze model performance on two new domains.\nAs each of these has their own challenges (section 3  ###reference_###), we compare each model trained on generated data to a baseline trained on human data.\nWhen looking at Table 6  ###reference_###, the agent trained on data generated by LLAMA is again nearly able to match the performance of the model trained on human data for the DIAGNOSE dataset, while the model trained on data generated by ChatGPT surpasses it.\nOn the other hand, the ONBOARD dataset may present a more challenging domain, due in part to the code-switching present in the dialog nodes.\nDespite this, the model trained on data from ChatGPT nearly reaches the performance of models trained on human data.\nBased on this, we find that the generation techniques do appear to scale to new domains, as t-tests show no statistically significant differences between the best synthetically trained agents and the agents trained on real data in any domain."
        },
        {
            "section_id": "7.1",
            "parent_section_id": "7",
            "section_name": "7.1.   RQ 1: Transitioning to a Zero Data Approach",
            "text": "Looking at the question lengths between human data and data generated by GENV1 (Figure 2  ###reference_###  ###reference_###),\nwe observe that the generated questions seem to be longer than human questions.\nWhen manually inspecting the generated questions, we also find them to be much less natural than those from the human data.\n###figure_4### We amend the original prompt used, creating GENV2, to explicitly ask for short outputs (subsection 5.1  ###reference_###  ###reference_###) in an effort to align the syntax of the generations better with the human data.\nThis change to the prompt shifts the distribution of question lengths more towards the human training distribution, and qualitatively yields more natural utterances.\nHowever, it still does not ensure that the artificial data is semantically similar to human data.\nTo investigate how semantically similar the generated questions are to human data, we calculate the pair-wise similarities between all human and generated questions for each node from the dialog graph, and then average the similarities across all nodes (Figure 3  ###reference_###  ###reference_###).\nHere, we see that the GenV2 data is still quite distinct from the human data.\n###figure_5### When manually inspecting the generations, we find that generated questions tend to focus only on one part of the node text, making them lack diversity and omit topics real users might ask about.\nTo address this, we develop the novel two-step GenV3 prompt, steering the model to explicitly ask about all named entities in a node (subsection 5.1  ###reference_###  ###reference_###).\nWe see that doing so significantly () increases the similarity of the generated (avg.: ) to the human training data than GenV2 (avg.: ), as measured with a standard t-test.\nWe also look at the diversity of the generated questions.\nThe self-BLEU scores (Table 4  ###reference_###  ###reference_###) show that the GenV3 data are the most diverse.\nThis metric can be used to analyze the quality of the generated data even in the absence of human comparison data.\nIn conjunction with diversity, we estimate the average \u201canswerability\u201d via QA  ###reference_id3###  ###reference_id3### confidence scores of the generated questions, given the node text as answer.\nHere, we also see that the improvements from GenV3 and GenV2 together also significantly () increase the average answerability, from an average of  with naive prompt to  with GenV3, according to a t-test.\nWhen looking at downstream performance (Table 5  ###reference_###  ###reference_###), we see that improvements in these metrics also lead to higher dialog success, suggesting they can be used as an indicator of generation quality.\nTo investigate whether synthetic data can be a viable alternative to human data, we compare agent performance in simulation.\nFrom Table 5  ###reference_###  ###reference_###, we see that the best performing agent trained on artificial data (GenV3: 69.44% success) performs comparably to the best performing agent trained on human data (CTSours: 73.86% success).\nUsing a standard t-test, we find no statistically significant difference.\nTo test of the scalability of our generation methods, we analyze model performance on two new domains.\nAs each of these has their own challenges (section 3  ###reference_###  ###reference_###), we compare each model trained on generated data to a baseline trained on human data.\nWhen looking at Table 6  ###reference_###  ###reference_###, the agent trained on data generated by LLAMA is again nearly able to match the performance of the model trained on human data for the DIAGNOSE dataset, while the model trained on data generated by ChatGPT surpasses it.\nOn the other hand, the ONBOARD dataset may present a more challenging domain, due in part to the code-switching present in the dialog nodes.\nDespite this, the model trained on data from ChatGPT nearly reaches the performance of models trained on human data.\nBased on this, we find that the generation techniques do appear to scale to new domains, as t-tests show no statistically significant differences between the best synthetically trained agents and the agents trained on real data in any domain."
        },
        {
            "section_id": "7.2",
            "parent_section_id": "7",
            "section_name": "7.2.   RQ 2: Human Evaluation",
            "text": ""
        },
        {
            "section_id": "7.2.1",
            "parent_section_id": "7.2",
            "section_name": "7.2.1.   Generated vs. Real Data",
            "text": "After performing human evaluation, we find that there are no statistically significant differences (using a standard t-test) between either subjective or objective measures of success or dialog length (Table 7  ###reference_###).\nAdditionally, we find no difference in the reported trust, reliability, or usability scores between either group.\nThis suggests that there is no human-observable loss in performance when using generated data compared to real data, either in terms of objective metrics or subjective metrics."
        },
        {
            "section_id": "7.2.2",
            "parent_section_id": "7.2",
            "section_name": "7.2.2.   Human Evaluation vs. Simulator",
            "text": "Finally, to validate our updated user simulator, we additionally compare the objective performance metrics from the human evaluation (Table 7  ###reference_###) to those obtained in simulation (Table 5  ###reference_###).\nWe find that the success rates between the simulated and human dialogs are very comparable ( and  respectively for the model trained on human data, and  and  for the model trained on generated data).\nWe perform statistical analysis using Welch\u2019s t-test to account for the difference in sample size, and find no significant difference, regardless of the source of training data.\nBased on this, we conclude that results from simulation translate well to real human interaction, suggesting the simulator can be a good proxy for real user evaluation.\nWe therefore expect the results reported in (Table 6  ###reference_###) will translate to similar performance with real users."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "8.   Conclusion",
            "text": "In this paper, we present two new and publicly available datasets, ONBOARD, providing help for moving to a new city in a foreign country, and DIAGNOSE, a medical domain.\nThe datasets each consist of a dialog tree and human-collected text inputs.\nWe apply a harsher, more realistic evaluation metric and improve on the agent training method from the original CTS  ###reference_id4### (V\u00e4th et al., 2023  ###reference_b33###), increasing dialog success by over .\nGiven a dialog tree, we explore several zero-data prompting-based methods for generating user utterance data to train a CTS  ###reference_id4### agent, developing a novel two-stage prompting approach to increase question diversity.\nThrough this process, we find that automatic scores for diversity and answerability can be indicative of downstream dialog task performance.\nFurthermore, we show that there is no statistically significant difference in objective metrics between agents trained on human data or on generated data in the REIMBURSE-En domain.\nWe verify this both through simulation and through testing with real users.\nUser evaluation further reveals no statistically significant differences on subjective metrics (trust, reliability, usability, subjective length, or subjective dialog success) either.\nThis suggests that we can effectively generate training data from a dialog tree, such that CTS  ###reference_id4### agents can be trained in zero data settings with negligible performance loss.\nWe also find that the size of the tested LLMs  ###reference_id1### does not result in significant differences in task performance.\nTo evaluate how well our techniques scale to new domains, we further tested agent performance on both new datasets we introduced.\nFor ONBOARD, we again find that performance of agents trained on generated data is comparable to that of agents trained on human data.\nFor DIAGNOSE, performance can even exceed that of the agent trained on human data.\nThis suggests that our methods scale well to new domains."
        },
        {
            "section_id": "9",
            "parent_section_id": null,
            "section_name": "9.   Ethical Considerations",
            "text": "To ensure that users could give informed consent, we provided a detailed description of the task and research objectives both on the crowdsourcing platform and once they had accepted the task.\nIn respect of participant privacy, we specifically did not collect personally identifying data from any users.\nTo this end, we store all logs and survey responses using an anonymous hash generated based on a given username, rather than with the username itself.\nIn this way, users could log in again if they needed to take a break in the middle of the interaction, but we had no way of directly linking any recorded results to, e.g., users\u2019 Prolific account identifiers.\nTo ensure that participants were fairly compensated, we followed best practices recommended by the crowdsourcing platform paying users at 9 /hr.\nWe additionally used our pilot study to verify that our estimated time was below the median time we selected when advertising the task."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Reinforcement Learning Agent Training Parameters",
            "text": "###table_1###"
        },
        {
            "section_id": "Appendix 2",
            "parent_section_id": null,
            "section_name": "Appendix B User Study",
            "text": ""
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T1\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S3.T1.1\" style=\"width:455.2pt;height:130.3pt;vertical-align:-0.8pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-71.0pt,20.2pt) scale(0.76216189096025,0.76216189096025) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T1.1.1\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.1\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.2.1\">Split</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.3.1\">#Nodes</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.4\">\n<span class=\"ltx_text\" id=\"S3.T1.1.1.1.4.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.4.2\"> <span class=\"ltx_text\" id=\"S3.T1.1.1.1.4.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S3.T1.1.1.1.4.2.1.1\">\n<span class=\"ltx_tr\" id=\"S3.T1.1.1.1.4.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.4.2.1.1.1.1\">Tree</span></span>\n<span class=\"ltx_tr\" id=\"S3.T1.1.1.1.4.2.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.4.2.1.1.2.1\">Depth</span></span>\n</span></span><span class=\"ltx_text\" id=\"S3.T1.1.1.1.4.2.2\"></span></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.5\">\n<span class=\"ltx_text\" id=\"S3.T1.1.1.1.5.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.5.2\"> <span class=\"ltx_text\" id=\"S3.T1.1.1.1.5.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S3.T1.1.1.1.5.2.1.1\">\n<span class=\"ltx_tr\" id=\"S3.T1.1.1.1.5.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.5.2.1.1.1.1\">Max. Node</span></span>\n<span class=\"ltx_tr\" id=\"S3.T1.1.1.1.5.2.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.5.2.1.1.2.1\">Degree</span></span>\n</span></span><span class=\"ltx_text\" id=\"S3.T1.1.1.1.5.2.2\"></span></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.6\">\n<span class=\"ltx_text\" id=\"S3.T1.1.1.1.6.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.6.2\"> <span class=\"ltx_text\" id=\"S3.T1.1.1.1.6.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S3.T1.1.1.1.6.2.1.1\">\n<span class=\"ltx_tr\" id=\"S3.T1.1.1.1.6.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.6.2.1.1.1.1\">#User</span></span>\n<span class=\"ltx_tr\" id=\"S3.T1.1.1.1.6.2.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.6.2.1.1.2.1\">Questions</span></span>\n</span></span><span class=\"ltx_text\" id=\"S3.T1.1.1.1.6.2.2\"></span></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.7\">\n<span class=\"ltx_text\" id=\"S3.T1.1.1.1.7.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.7.2\"> <span class=\"ltx_text\" id=\"S3.T1.1.1.1.7.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S3.T1.1.1.1.7.2.1.1\">\n<span class=\"ltx_tr\" id=\"S3.T1.1.1.1.7.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.7.2.1.1.1.1\">Avg. User</span></span>\n<span class=\"ltx_tr\" id=\"S3.T1.1.1.1.7.2.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.7.2.1.1.2.1\">Questions</span></span>\n</span></span><span class=\"ltx_text\" id=\"S3.T1.1.1.1.7.2.2\"></span></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.8.1\"><span class=\"ltx_text\" id=\"S3.T1.1.1.1.8.1.1\"></span> <span class=\"ltx_text\" id=\"S3.T1.1.1.1.8.1.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S3.T1.1.1.1.8.1.2.1\">\n<span class=\"ltx_tr\" id=\"S3.T1.1.1.1.8.1.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.8.1.2.1.1.1\">#Answer</span></span>\n<span class=\"ltx_tr\" id=\"S3.T1.1.1.1.8.1.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.8.1.2.1.2.1\">Paraphrases</span></span>\n</span></span><span class=\"ltx_text\" id=\"S3.T1.1.1.1.8.1.3\"></span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.9\">\n<span class=\"ltx_text\" id=\"S3.T1.1.1.1.9.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.9.2\"> <span class=\"ltx_text\" id=\"S3.T1.1.1.1.9.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S3.T1.1.1.1.9.2.1.1\">\n<span class=\"ltx_tr\" id=\"S3.T1.1.1.1.9.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.9.2.1.1.1.1\">Avg. Answer</span></span>\n<span class=\"ltx_tr\" id=\"S3.T1.1.1.1.9.2.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.9.2.1.1.2.1\">Paraphrases</span></span>\n</span></span><span class=\"ltx_text\" id=\"S3.T1.1.1.1.9.2.2\"></span></span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.2.1.1\">REIMBURSE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.2\">Train</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.3\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T1.1.1.2.3.1\">123</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.4\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T1.1.1.2.4.1\">32</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.5\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T1.1.1.2.5.1\">14</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.6\">279</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.7\">3.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.8\">246</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.9\">3.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.3.1\">Test</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.3.2\">173</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.3.3\">2.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.3.4\">162</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.3.5\">2.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.4.1.1\">REIMBURSE-En</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.2\">Train</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.3\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T1.1.1.4.3.1\">123</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.4\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T1.1.1.4.4.1\">32</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.5\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T1.1.1.4.5.1\">14</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.6\">279</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.7\">3.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.8\">246</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.9\">3.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.5.1\">Test</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.5.2\">173</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.5.3\">2.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.5.4\">162</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.5.5\">2.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.6.1.1\">DIAGNOSE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.2\">Train</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.3\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T1.1.1.6.3.1\">98</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.4\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T1.1.1.6.4.1\">10</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.5\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T1.1.1.6.5.1\">6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.6\">219</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.7\">2.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.8\">298</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.9\">3.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\" id=\"S3.T1.1.1.7.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.7.1.1\">DIAGNOSE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.7.2\">Test</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.7.3\">150</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.7.4\">2.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.7.5\">298</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S3.T1.1.1.7.6\">3.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.8\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.8.1.1\">ONBOARD</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.2\">Train</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.3\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T1.1.1.8.3.1\">88</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.4\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T1.1.1.8.4.1\">15</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.5\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T1.1.1.8.5.1\">9</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.6\">141</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.7\">2.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.8\">175</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.9\">3.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.9\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r\" id=\"S3.T1.1.1.9.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.9.1.1\">ONBOARD</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S3.T1.1.1.9.2\">Test</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S3.T1.1.1.9.3\">117</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S3.T1.1.1.9.4\">2.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S3.T1.1.1.9.5\">152</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S3.T1.1.1.9.6\">2.7</td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Overview of original <em class=\"ltx_emph ltx_font_italic\" id=\"S3.T1.6.1\">REIMBURSE</em>, translated <em class=\"ltx_emph ltx_font_italic\" id=\"S3.T1.7.2\">REIMBURSE-En</em>, and newly created <em class=\"ltx_emph ltx_font_italic\" id=\"S3.T1.8.3\">ONBOARD</em> and <em class=\"ltx_emph ltx_font_italic\" id=\"S3.T1.9.4\">DIAGNOSE</em> datasets (numbers rounded to one decimal).</figcaption>\n</figure>",
            "capture": "Table 1: Overview of original REIMBURSE, translated REIMBURSE-En, and newly created ONBOARD and DIAGNOSE datasets (numbers rounded to one decimal)."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T2\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S5.T2.1\" style=\"width:455.2pt;height:185.4pt;vertical-align:-0.8pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-67.3pt,27.3pt) scale(0.771780494005723,0.771780494005723) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T2.1.1\">\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.1.1.1\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.1.2.1\">Role</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.1.3.1\">Context</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.1.4\">\n<span class=\"ltx_text\" id=\"S5.T2.1.1.1.4.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.1.4.2\"> <span class=\"ltx_text\" id=\"S5.T2.1.1.1.4.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S5.T2.1.1.1.4.2.1.1\">\n<span class=\"ltx_tr\" id=\"S5.T2.1.1.1.4.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T2.1.1.1.4.2.1.1.1.1\">Prompt</span></span>\n</span></span><span class=\"ltx_text\" id=\"S5.T2.1.1.1.4.2.2\"></span></span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.2.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S5.T2.1.1.2.1.1\">V1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.2.2\">System</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.2.3\">Node text</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.2.4\">\n<span class=\"ltx_text\" id=\"S5.T2.1.1.2.4.1\"></span><span class=\"ltx_text\" id=\"S5.T2.1.1.2.4.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S5.T2.1.1.2.4.2.1\">\n<span class=\"ltx_tr\" id=\"S5.T2.1.1.2.4.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T2.1.1.2.4.2.1.1.1\">You are a truthful assistant, generating diverse FAQ-style questions given some facts.</span></span>\n<span class=\"ltx_tr\" id=\"S5.T2.1.1.2.4.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T2.1.1.2.4.2.1.2.1\">The generated questions should be answerable using the given fact only, without</span></span>\n<span class=\"ltx_tr\" id=\"S5.T2.1.1.2.4.2.1.3\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T2.1.1.2.4.2.1.3.1\">additional knowledge. The questions should also be human-like. Try to vary the</span></span>\n<span class=\"ltx_tr\" id=\"S5.T2.1.1.2.4.2.1.4\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T2.1.1.2.4.2.1.4.1\">amount of information between questions. Present the results in a numbered list.</span></span>\n</span></span><span class=\"ltx_text\" id=\"S5.T2.1.1.2.4.3\"></span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.3.1\">User</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.3.2\">Node Text</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.3.3\">Generate 10 FAQ-style questions about the given facts: \u201c{NODE TEXT}\u201d.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.4.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S5.T2.1.1.4.1.1\">V2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.4.2\">System</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.4.3\">Node Text</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.4.4\">\n<span class=\"ltx_text\" id=\"S5.T2.1.1.4.4.1\"></span><span class=\"ltx_text\" id=\"S5.T2.1.1.4.4.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S5.T2.1.1.4.4.2.1\">\n<span class=\"ltx_tr\" id=\"S5.T2.1.1.4.4.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T2.1.1.4.4.2.1.1.1\">You are a truthful assistant, generating diverse FAQ-style questions given some facts.</span></span>\n<span class=\"ltx_tr\" id=\"S5.T2.1.1.4.4.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T2.1.1.4.4.2.1.2.1\">The generated questions should be answerable using the given fact only, without</span></span>\n<span class=\"ltx_tr\" id=\"S5.T2.1.1.4.4.2.1.3\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T2.1.1.4.4.2.1.3.1\">additional knowledge. The questions should also be short and human-like. Try to vary</span></span>\n<span class=\"ltx_tr\" id=\"S5.T2.1.1.4.4.2.1.4\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T2.1.1.4.4.2.1.4.1\">the amount of information between questions. Present the results in a numbered list.</span></span>\n</span></span><span class=\"ltx_text\" id=\"S5.T2.1.1.4.4.3\"></span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.5.1\">User</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.5.2\">Node Text</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.5.3\">(same as V1)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.6.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S5.T2.1.1.6.1.1\">V3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.6.2\">System</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.6.3\">\n<span class=\"ltx_text\" id=\"S5.T2.1.1.6.3.1\"></span> <span class=\"ltx_text\" id=\"S5.T2.1.1.6.3.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S5.T2.1.1.6.3.2.1\">\n<span class=\"ltx_tr\" id=\"S5.T2.1.1.6.3.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T2.1.1.6.3.2.1.1.1\">Node Text</span></span>\n</span></span><span class=\"ltx_text\" id=\"S5.T2.1.1.6.3.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.6.4\">(same as V2)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.7.1\">User</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.7.2\">\n<span class=\"ltx_text\" id=\"S5.T2.1.1.7.2.1\"></span> <span class=\"ltx_text\" id=\"S5.T2.1.1.7.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S5.T2.1.1.7.2.2.1\">\n<span class=\"ltx_tr\" id=\"S5.T2.1.1.7.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T2.1.1.7.2.2.1.1.1\">Node Text, NER</span></span>\n</span></span><span class=\"ltx_text\" id=\"S5.T2.1.1.7.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S5.T2.1.1.7.3\">\n<span class=\"ltx_text\" id=\"S5.T2.1.1.7.3.1\"></span><span class=\"ltx_text\" id=\"S5.T2.1.1.7.3.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S5.T2.1.1.7.3.2.1\">\n<span class=\"ltx_tr\" id=\"S5.T2.1.1.7.3.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T2.1.1.7.3.2.1.1.1\">Generate 3 questions about the entity \u201c{NER}\u201d from the fact: \u201c{NODE TEXT}\u201d</span></span>\n</span></span><span class=\"ltx_text\" id=\"S5.T2.1.1.7.3.3\"></span></td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Prompt templates for generating synthetic question data.</figcaption>\n</figure>",
            "capture": "Table 2: Prompt templates for generating synthetic question data."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S5.T3\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S5.T3.1\" style=\"width:455.2pt;height:145.4pt;vertical-align:-0.8pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-71.0pt,22.6pt) scale(0.762143881458711,0.762143881458711) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T3.1.1\">\n<tr class=\"ltx_tr\" id=\"S5.T3.1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.1.1.1.1\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.1.1.2.1\">Role</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.1.1.3.1\">Context</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.1.4\">\n<span class=\"ltx_text\" id=\"S5.T3.1.1.1.4.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.1.1.4.2\"> <span class=\"ltx_text\" id=\"S5.T3.1.1.1.4.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S5.T3.1.1.1.4.2.1.1\">\n<span class=\"ltx_tr\" id=\"S5.T3.1.1.1.4.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T3.1.1.1.4.2.1.1.1.1\">Prompt</span></span>\n</span></span><span class=\"ltx_text\" id=\"S5.T3.1.1.1.4.2.2\"></span></span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.1.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.2.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S5.T3.1.1.2.1.1\">A</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.2.2\">System</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.2.3\">Node text</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.2.4\">\n<span class=\"ltx_text\" id=\"S5.T3.1.1.2.4.1\"></span><span class=\"ltx_text\" id=\"S5.T3.1.1.2.4.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S5.T3.1.1.2.4.2.1\">\n<span class=\"ltx_tr\" id=\"S5.T3.1.1.2.4.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T3.1.1.2.4.2.1.1.1\">You are generating semantically similar paraphrases for a given response to some</span></span>\n<span class=\"ltx_tr\" id=\"S5.T3.1.1.2.4.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T3.1.1.2.4.2.1.2.1\">question. The generated response paraphrases should be human-like and short, using</span></span>\n<span class=\"ltx_tr\" id=\"S5.T3.1.1.2.4.2.1.3\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T3.1.1.2.4.2.1.3.1\">frequently used words and phrases only. Present the results in a numbered list.</span></span>\n</span></span><span class=\"ltx_text\" id=\"S5.T3.1.1.2.4.3\"></span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.1.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.3.1\">User</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.3.2\">Node Text</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.3.3\">\n<span class=\"ltx_text\" id=\"S5.T3.1.1.3.3.1\"></span><span class=\"ltx_text\" id=\"S5.T3.1.1.3.3.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S5.T3.1.1.3.3.2.1\">\n<span class=\"ltx_tr\" id=\"S5.T3.1.1.3.3.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T3.1.1.3.3.2.1.1.1\">Generate 5 paraphrases for the response \u201c{RESPONSE TEXT}\u201d to the question</span></span>\n<span class=\"ltx_tr\" id=\"S5.T3.1.1.3.3.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T3.1.1.3.3.2.1.2.1\">\u201c{NODE TEXT}\u201d</span></span>\n</span></span><span class=\"ltx_text\" id=\"S5.T3.1.1.3.3.3\"></span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.1.1.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.4.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S5.T3.1.1.4.1.1\">B</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.4.2\">System</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.4.3\">\n<span class=\"ltx_text\" id=\"S5.T3.1.1.4.3.1\"></span> <span class=\"ltx_text\" id=\"S5.T3.1.1.4.3.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S5.T3.1.1.4.3.2.1\">\n<span class=\"ltx_tr\" id=\"S5.T3.1.1.4.3.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T3.1.1.4.3.2.1.1.1\">Node Text</span></span>\n</span></span><span class=\"ltx_text\" id=\"S5.T3.1.1.4.3.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.4.4\">\n<span class=\"ltx_text\" id=\"S5.T3.1.1.4.4.1\"></span><span class=\"ltx_text\" id=\"S5.T3.1.1.4.4.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S5.T3.1.1.4.4.2.1\">\n<span class=\"ltx_tr\" id=\"S5.T3.1.1.4.4.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T3.1.1.4.4.2.1.1.1\">You are shortening a given response to some question into a keyword-like prompt.</span></span>\n<span class=\"ltx_tr\" id=\"S5.T3.1.1.4.4.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T3.1.1.4.4.2.1.2.1\">Present the results in a numbered list.</span></span>\n</span></span><span class=\"ltx_text\" id=\"S5.T3.1.1.4.4.3\"></span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.1.1.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.5.1\">User</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.5.2\">\n<span class=\"ltx_text\" id=\"S5.T3.1.1.5.2.1\"></span> <span class=\"ltx_text\" id=\"S5.T3.1.1.5.2.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S5.T3.1.1.5.2.2.1\">\n<span class=\"ltx_tr\" id=\"S5.T3.1.1.5.2.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T3.1.1.5.2.2.1.1.1\">Node Text, NER</span></span>\n</span></span><span class=\"ltx_text\" id=\"S5.T3.1.1.5.2.3\"></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S5.T3.1.1.5.3\">\n<span class=\"ltx_text\" id=\"S5.T3.1.1.5.3.1\"></span><span class=\"ltx_text\" id=\"S5.T3.1.1.5.3.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S5.T3.1.1.5.3.2.1\">\n<span class=\"ltx_tr\" id=\"S5.T3.1.1.5.3.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T3.1.1.5.3.2.1.1.1\">Generate 5 options for shortening the response \u201c{RESPONSE TEXT}\u201d to the question</span></span>\n<span class=\"ltx_tr\" id=\"S5.T3.1.1.5.3.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S5.T3.1.1.5.3.2.1.2.1\">\u201c{NODE TEXT}\u201d</span></span>\n</span></span><span class=\"ltx_text\" id=\"S5.T3.1.1.5.3.3\"></span></td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Example of prompting method for generating synthetic user response data.</figcaption>\n</figure>",
            "capture": "Table 3: Example of prompting method for generating synthetic user response data."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"S7.T4\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S7.T4.1\" style=\"width:204.9pt;height:74pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-18.6pt,6.7pt) scale(0.84632686682496,0.84632686682496) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S7.T4.1.1\">\n<tr class=\"ltx_tr\" id=\"S7.T4.1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.1.1\">\n<span class=\"ltx_text\" id=\"S7.T4.1.1.1.1.1\"></span> <span class=\"ltx_text\" id=\"S7.T4.1.1.1.1.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S7.T4.1.1.1.1.2.1\">\n<span class=\"ltx_tr\" id=\"S7.T4.1.1.1.1.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T4.1.1.1.1.2.1.1.1\">Training Data</span></span>\n</span></span><span class=\"ltx_text\" id=\"S7.T4.1.1.1.1.3\"></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.1.2\">n-1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.1.3\">n-2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.1.4\">n-3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.1.5\">n-4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.1.6\">n-5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T4.1.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.2.1\">Human</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.1.2.2.1\">0.78</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.1.2.3.1\">0.68</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.1.2.4.1\">0.60</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.1.2.5.1\">0.54</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.2.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.1.2.6.1\">0.49</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T4.1.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.3.1\">V1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.3.2\">0.95</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.3.3\">0.92</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.3.4\">0.87</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.3.5\">0.83</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T4.1.1.3.6\">0.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T4.1.1.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\" id=\"S7.T4.1.1.4.1\">V2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T4.1.1.4.2\">0.95</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T4.1.1.4.3\">0.90</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T4.1.1.4.4\">0.85</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T4.1.1.4.5\">0.80</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T4.1.1.4.6\">0.76</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T4.1.1.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r\" id=\"S7.T4.1.1.5.1\">V3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T4.1.1.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.1.5.2.1\">0.85</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T4.1.1.5.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.1.5.3.1\">0.78</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T4.1.1.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.1.5.4.1\">0.71</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T4.1.1.5.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.1.5.5.1\">0.66</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T4.1.1.5.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T4.1.1.5.6.1\">0.62</span></td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Self-BLEU scores for different n-gram sizes on human and generated data.</figcaption>\n</figure>",
            "capture": "Table 4: Self-BLEU scores for different n-gram sizes on human and generated data."
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"S7.T5\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S7.T5.1\" style=\"width:455.2pt;height:142.4pt;vertical-align:-0.8pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-72.0pt,22.4pt) scale(0.759635817337928,0.759635817337928) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S7.T5.1.1\">\n<tr class=\"ltx_tr\" id=\"S7.T5.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.1.1.1\">Model</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.1.2\">\n<span class=\"ltx_text\" id=\"S7.T5.1.1.1.2.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.1.2.2\"> <span class=\"ltx_text\" id=\"S7.T5.1.1.1.2.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S7.T5.1.1.1.2.2.1.1\">\n<span class=\"ltx_tr\" id=\"S7.T5.1.1.1.2.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T5.1.1.1.2.2.1.1.1.1\">Training</span></span>\n<span class=\"ltx_tr\" id=\"S7.T5.1.1.1.2.2.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T5.1.1.1.2.2.1.1.2.1\">Data</span></span>\n</span></span><span class=\"ltx_text\" id=\"S7.T5.1.1.1.2.2.2\"></span></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.1.3\">\n<span class=\"ltx_text\" id=\"S7.T5.1.1.1.3.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.1.3.2\"> <span class=\"ltx_text\" id=\"S7.T5.1.1.1.3.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S7.T5.1.1.1.3.2.1.1\">\n<span class=\"ltx_tr\" id=\"S7.T5.1.1.1.3.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T5.1.1.1.3.2.1.1.1.1\">Avg. Perceived</span></span>\n<span class=\"ltx_tr\" id=\"S7.T5.1.1.1.3.2.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T5.1.1.1.3.2.1.1.2.1\">Length (guided)</span></span>\n</span></span><span class=\"ltx_text\" id=\"S7.T5.1.1.1.3.2.2\"></span></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.1.4\">\n<span class=\"ltx_text\" id=\"S7.T5.1.1.1.4.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.1.4.2\"> <span class=\"ltx_text\" id=\"S7.T5.1.1.1.4.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S7.T5.1.1.1.4.2.1.1\">\n<span class=\"ltx_tr\" id=\"S7.T5.1.1.1.4.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T5.1.1.1.4.2.1.1.1.1\">Avg. Perceived</span></span>\n<span class=\"ltx_tr\" id=\"S7.T5.1.1.1.4.2.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T5.1.1.1.4.2.1.1.2.1\">Length (free)</span></span>\n</span></span><span class=\"ltx_text\" id=\"S7.T5.1.1.1.4.2.2\"></span></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.1.5\">\n<span class=\"ltx_text\" id=\"S7.T5.1.1.1.5.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.1.5.2\"> <span class=\"ltx_text\" id=\"S7.T5.1.1.1.5.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S7.T5.1.1.1.5.2.1.1\">\n<span class=\"ltx_tr\" id=\"S7.T5.1.1.1.5.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T5.1.1.1.5.2.1.1.1.1\">Success</span></span>\n<span class=\"ltx_tr\" id=\"S7.T5.1.1.1.5.2.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T5.1.1.1.5.2.1.1.2.1\">(combined)</span></span>\n</span></span><span class=\"ltx_text\" id=\"S7.T5.1.1.1.5.2.2\"></span></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.1.6\">\n<span class=\"ltx_text\" id=\"S7.T5.1.1.1.6.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.1.6.2\"> <span class=\"ltx_text\" id=\"S7.T5.1.1.1.6.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S7.T5.1.1.1.6.2.1.1\">\n<span class=\"ltx_tr\" id=\"S7.T5.1.1.1.6.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T5.1.1.1.6.2.1.1.1.1\">Dialog Mode</span></span>\n<span class=\"ltx_tr\" id=\"S7.T5.1.1.1.6.2.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T5.1.1.1.6.2.1.1.2.1\">Prediction F1</span></span>\n</span></span><span class=\"ltx_text\" id=\"S7.T5.1.1.1.6.2.2\"></span></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.1.7\">\n<span class=\"ltx_text\" id=\"S7.T5.1.1.1.7.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.1.7.2\"> <span class=\"ltx_text\" id=\"S7.T5.1.1.1.7.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S7.T5.1.1.1.7.2.1.1\">\n<span class=\"ltx_tr\" id=\"S7.T5.1.1.1.7.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T5.1.1.1.7.2.1.1.1.1\">Dialog Mode</span></span>\n<span class=\"ltx_tr\" id=\"S7.T5.1.1.1.7.2.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T5.1.1.1.7.2.1.1.2.1\">Prediction Consistency</span></span>\n</span></span><span class=\"ltx_text\" id=\"S7.T5.1.1.1.7.2.2\"></span></span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.2.1\">Original</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.2.2\">human (GER)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.2.3\">n/a</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.2.4\">n/a</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.2.5\">62.58%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.2.6\">0.85</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.2.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.2.7.1\">1.0</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\" id=\"S7.T5.1.1.3.1\">Original</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.3.2\">human (EN)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.3.3\">n/a</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.3.4\">n/a</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.3.5\">55.28%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.3.6\">0.86</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.3.7\">0.87</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.1.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\" id=\"S7.T5.1.1.4.1\">Ours</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.4.2\">human (EN)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.4.3\">13.56</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.4.4\">2.95</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.4.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.4.5.1\">73.86%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.4.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.4.6.1\">0.94</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.4.7\">0.96</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.5.1\">Ours</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.5.2\">V1 (LLAMA)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.5.3\">13.53</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.5.4\">3.41</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.5.5\">64.17%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.5.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.5.6.1\">0.98</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.5.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.5.7.1\">0.97</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.1.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\" id=\"S7.T5.1.1.6.1\">Ours</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.6.2\">V2 (LLAMA)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.6.3\">11.71</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.6.4\">3.65</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.6.5\">65.02%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.6.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.6.6.1\">0.98</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.6.7\">0.95</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.1.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\" id=\"S7.T5.1.1.7.1\">Ours</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.7.2\">V3 (LLAMA)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.7.3\">12.89</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.7.4\">3.45</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.7.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.7.5.1\">69.44%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.7.6\">0.96</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.7.7\">0.95</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.1.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.8.1\">Ours</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.8.2\">V1 (ChatGPT)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.8.3\">13.02</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.8.4\">3.65</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.8.5\">64.35%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.8.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.8.6.1\">0.98</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T5.1.1.8.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.8.7.1\">0.97</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.1.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\" id=\"S7.T5.1.1.9.1\">Ours</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.9.2\">V2 (ChatGPT)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.9.3\">14.55</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.9.4\">3.71</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.9.5\">66.67%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.9.6\">0.95</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T5.1.1.9.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.9.7.1\">0.97</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T5.1.1.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r\" id=\"S7.T5.1.1.10.1\">Ours</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T5.1.1.10.2\">V3 (ChatGPT)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T5.1.1.10.3\">12.87</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T5.1.1.10.4\">3.59</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T5.1.1.10.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.10.5.1\">68.41</span>%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T5.1.1.10.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.10.6.1\">0.98</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T5.1.1.10.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T5.1.1.10.7.1\">0.97</span></td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>Simulation results on <em class=\"ltx_emph ltx_font_italic\" id=\"S7.T5.3.1\">REIMBURSE(-En)</em> test splits of original <a href=\"https://arxiv.org/html/2403.17582v1#id4.4.id4\"><abbr class=\"ltx_glossaryref\" href=\"https://arxiv.org/html/2403.17582v1#id4.4.id4\" title=\"Conversational Tree Search\"><span class=\"ltx_text ltx_glossary_short\">CTS</span></abbr></a> agent (German), our improved agent (English), and our <a href=\"https://arxiv.org/html/2403.17582v1#id4.4.id4\"><abbr class=\"ltx_glossaryref\" href=\"https://arxiv.org/html/2403.17582v1#id4.4.id4\" title=\"Conversational Tree Search\"><span class=\"ltx_text ltx_glossary_short\">CTS</span></abbr></a> agent trained on generated data only (English).\n</figcaption>\n</figure>",
            "capture": "Table 5: Simulation results on REIMBURSE(-En) test splits of original CTS agent (German), our improved agent (English), and our CTS agent trained on generated data only (English).\n"
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"S7.T6\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S7.T6.1\" style=\"width:455.2pt;height:100.9pt;vertical-align:-0.8pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-46.3pt,10.2pt) scale(0.830946717809489,0.830946717809489) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S7.T6.1.1\">\n<tr class=\"ltx_tr\" id=\"S7.T6.1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T6.1.1.1.1.1\">Domain</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T6.1.1.1.2.1\">Training Data</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T6.1.1.1.3.1\">Avg. Perceived Length (guided)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T6.1.1.1.4.1\">Avg. Perceived Length (free)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.1.5\">\n<span class=\"ltx_text\" id=\"S7.T6.1.1.1.5.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S7.T6.1.1.1.5.2\"> <span class=\"ltx_text\" id=\"S7.T6.1.1.1.5.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S7.T6.1.1.1.5.2.1.1\">\n<span class=\"ltx_tr\" id=\"S7.T6.1.1.1.5.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T6.1.1.1.5.2.1.1.1.1\">Success (combined)</span></span>\n</span></span><span class=\"ltx_text\" id=\"S7.T6.1.1.1.5.2.2\"></span></span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T6.1.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.2.1\">DIAGNOSE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.2.2\">human</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.2.3\">6.42</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.2.4\">2.29</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.2.5\">76.31%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T6.1.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\" id=\"S7.T6.1.1.3.1\">DIAGNOSE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T6.1.1.3.2\">V3 (LLAMA)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T6.1.1.3.3\">6.62</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T6.1.1.3.4\">2.95</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T6.1.1.3.5\">71.08%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T6.1.1.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\" id=\"S7.T6.1.1.4.1\">DIAGNOSE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T6.1.1.4.2\">V3 (ChatGPT)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T6.1.1.4.3\">5.65</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T6.1.1.4.4\">2.46</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T6.1.1.4.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T6.1.1.4.5.1\">85.12%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T6.1.1.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.5.1\">ONBOARD</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.5.2\">human</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.5.3\">7.88</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.5.4\">2.98</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T6.1.1.5.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T6.1.1.5.5.1\">73.61%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T6.1.1.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\" id=\"S7.T6.1.1.6.1\">ONBOARD</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T6.1.1.6.2\">V3 (LLAMA)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T6.1.1.6.3\">7.91</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T6.1.1.6.4\">3.52</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S7.T6.1.1.6.5\">63.38%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T6.1.1.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r\" id=\"S7.T6.1.1.7.1\">ONBOARD</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T6.1.1.7.2\">V3 (ChatGPT)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T6.1.1.7.3\">7.60</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T6.1.1.7.4\">3.58</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T6.1.1.7.5\">70.72%</td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 6: </span>Performance of <a href=\"https://arxiv.org/html/2403.17582v1#id4.4.id4\"><abbr class=\"ltx_glossaryref\" href=\"https://arxiv.org/html/2403.17582v1#id4.4.id4\" title=\"Conversational Tree Search\"><span class=\"ltx_text ltx_glossary_short\">CTS</span></abbr></a> agents trained on human and generated data on the new domains <em class=\"ltx_emph ltx_font_italic\" id=\"S7.T6.4.1\">DIAGNOSE</em> and <em class=\"ltx_emph ltx_font_italic\" id=\"S7.T6.5.2\">ONBOARD</em> in simulation.</figcaption>\n</figure>",
            "capture": "Table 6: Performance of CTS agents trained on human and generated data on the new domains DIAGNOSE and ONBOARD in simulation."
        },
        "7": {
            "table_html": "<figure class=\"ltx_table\" id=\"S7.T7\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S7.T7.1\" style=\"width:223.1pt;height:52.2pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-40.2pt,9.4pt) scale(0.735132505353491,0.735132505353491) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S7.T7.1.1\">\n<tr class=\"ltx_tr\" id=\"S7.T7.1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S7.T7.1.1.1.1\">\n<span class=\"ltx_text\" id=\"S7.T7.1.1.1.1.1\"></span><span class=\"ltx_text ltx_font_bold\" id=\"S7.T7.1.1.1.1.2\"> <span class=\"ltx_text\" id=\"S7.T7.1.1.1.1.2.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S7.T7.1.1.1.1.2.1.1\">\n<span class=\"ltx_tr\" id=\"S7.T7.1.1.1.1.2.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T7.1.1.1.1.2.1.1.1.1\">Training</span></span>\n<span class=\"ltx_tr\" id=\"S7.T7.1.1.1.1.2.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T7.1.1.1.1.2.1.1.2.1\">Data</span></span>\n</span></span><span class=\"ltx_text\" id=\"S7.T7.1.1.1.1.2.2\"></span></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T7.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T7.1.1.1.2.1\"># Turns</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T7.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T7.1.1.1.3.1\">Success</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T7.1.1.1.4\">\n<span class=\"ltx_text\" id=\"S7.T7.1.1.1.4.1\"></span> <span class=\"ltx_text\" id=\"S7.T7.1.1.1.4.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S7.T7.1.1.1.4.2.1\">\n<span class=\"ltx_tr\" id=\"S7.T7.1.1.1.4.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T7.1.1.1.4.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T7.1.1.1.4.2.1.1.1.1\">Perceived</span></span></span>\n<span class=\"ltx_tr\" id=\"S7.T7.1.1.1.4.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T7.1.1.1.4.2.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T7.1.1.1.4.2.1.2.1.1\">Length</span></span></span>\n</span></span><span class=\"ltx_text\" id=\"S7.T7.1.1.1.4.3\"></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T7.1.1.1.5\">\n<span class=\"ltx_text\" id=\"S7.T7.1.1.1.5.1\"></span> <span class=\"ltx_text\" id=\"S7.T7.1.1.1.5.2\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S7.T7.1.1.1.5.2.1\">\n<span class=\"ltx_tr\" id=\"S7.T7.1.1.1.5.2.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T7.1.1.1.5.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T7.1.1.1.5.2.1.1.1.1\">Answer</span></span></span>\n<span class=\"ltx_tr\" id=\"S7.T7.1.1.1.5.2.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S7.T7.1.1.1.5.2.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S7.T7.1.1.1.5.2.1.2.1.1\">Satisfaction</span></span></span>\n</span></span><span class=\"ltx_text\" id=\"S7.T7.1.1.1.5.3\"></span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T7.1.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S7.T7.1.1.2.1\">Human</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T7.1.1.2.2\">6.14</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T7.1.1.2.3\">77.59</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T7.1.1.2.4\">2.88</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S7.T7.1.1.2.5\">2.93</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S7.T7.1.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r\" id=\"S7.T7.1.1.3.1\">V3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T7.1.1.3.2\">5.27</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T7.1.1.3.3\">72.73</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T7.1.1.3.4\">2.65</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"S7.T7.1.1.3.5\">2.73</td>\n</tr>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 7: </span>Average objective and subjective performance metrics of a <a href=\"https://arxiv.org/html/2403.17582v1#id4.4.id4\"><abbr class=\"ltx_glossaryref\" href=\"https://arxiv.org/html/2403.17582v1#id4.4.id4\" title=\"Conversational Tree Search\"><span class=\"ltx_text ltx_glossary_short\">CTS</span></abbr></a> agent trained on human data vs. generated data.</figcaption>\n</figure>",
            "capture": "Table 7: Average objective and subjective performance metrics of a CTS agent trained on human data vs. generated data."
        },
        "8": {
            "table_html": "<figure class=\"ltx_table\" id=\"A1.T8\">\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"A1.T8.25\">\n<tr class=\"ltx_tr\" id=\"A1.T8.25.26\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.25.26.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T8.25.26.1.1\">Parameter</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.25.26.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T8.25.26.2.1\">Value</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.25.27\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A1.T8.25.27.1\">Optimizer</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T8.25.27.2\">Adam</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.1.1.2\">Learning Rate</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.1.1.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.3.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.2.2.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.3.3.2\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.4.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.4.4.2\">Maximum Training Dialog Turns</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.4.4.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.5.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.5.5.2\">Max. Gradient Norm</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.5.5.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.6.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.6.6.2\">Batch Size</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.6.6.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.8.8\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.7.7.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.8.8.2\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.9.9\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.9.9.2\">Exploration fraction of Training Turns</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.9.9.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.10.10\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.10.10.2\">Exploration Scheme</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.10.10.1\">\n-greedy</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.12.12\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.11.11.1\">\n start</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.12.12.2\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.14.14\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.13.13.1\">\n end</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.14.14.2\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.15.15\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.15.15.2\">Training frequency (w.r.t. dialog turns)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.15.15.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.16.16\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.16.16.2\">Training start (w.r.t. dialog turns)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.16.16.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.17.17\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.17.17.2\">DDQN Target Network update frequency (w.r.t. training steps)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.17.17.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.18.18\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.18.18.2\">Q-Value clipping</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.18.18.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.20.20\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.19.19.1\">Munchausen \n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.20.20.2\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.22.22\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.21.21.1\">Munchausen \n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.22.22.2\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.23.23\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.23.23.2\">Munchausen Clipping</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.23.23.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.24.24\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.24.24.2\">Evaluation frequency (w.r.t. dialog turns)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.24.24.1\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.25.25\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A1.T8.25.25.2\">Evaluation dialogs</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.25.25.1\"></td>\n</tr>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 8: </span>Hyperparameters for training the Reinforcement Learning agents.</figcaption>\n</figure>",
            "capture": "Table 8: Hyperparameters for training the Reinforcement Learning agents."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.17582v1_figure_1.png",
            "caption": "Figure 1: Example of the CTS agent adapting its behavior based on the information content of the initial user utterance V\u00e4th et al. (2023)."
        },
        "2": {
            "figure_path": "2403.17582v1_figure_2.png",
            "caption": "Figure 2: Smoothed density plot of question lengths from human data and generated data."
        },
        "3": {
            "figure_path": "2403.17582v1_figure_3.png",
            "caption": "Figure 3: Smoothed density plot of question similarities between human generated training data."
        }
    },
    "references": [
        {
            "1": {
                "title": "The internal state of an llm knows when its lying.",
                "author": "Amos Azaria and Tom Mitchell. 2023.",
                "venue": "arXiv preprint arXiv:2304.13734.",
                "url": null
            }
        },
        {
            "2": {
                "title": "Gus, a frame-driven dialog system.",
                "author": "Daniel G. Bobrow, Ronald M. Kaplan, Martin Kay, Donald A. Norman, Henry\nThompson, and Terry Winograd. 1977.",
                "venue": "Artificial Intelligence.",
                "url": null
            }
        },
        {
            "3": {
                "title": "Critiquing-based recommenders: survey and emerging trends.",
                "author": "Li Chen and Pearl Pu. 2012.",
                "venue": "User Modeling and User-Adapted Interaction, 22(1):125\u2013150.",
                "url": null
            }
        },
        {
            "4": {
                "title": "Gotta: generative few-shot question answering by prompt-based cloze\ndata augmentation.",
                "author": "Xiusi Chen, Yu Zhang, Jinliang Deng, Jyun-Yu Jiang, and Wei Wang. 2023.",
                "venue": "In Proceedings of the 2023 SIAM International Conference on\nData Mining (SDM), pages 909\u2013917. SIAM.",
                "url": null
            }
        },
        {
            "5": {
                "title": "Back\nto the future for dialogue research.",
                "author": "Philip R. Cohen. 2020.",
                "venue": "In The Thirty-Fourth AAAI Conference on Artificial\nIntelligence, AAAI 2020, The Thirty-Second Innovative Applications of\nArtificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium\non Educational Advances in Artificial Intelligence, EAAI 2020, New York,\nNY, USA, February 7-12, 2020, pages 13514\u201313519. AAAI Press.",
                "url": "https://ojs.aaai.org/index.php/AAAI/article/view/7073"
            }
        },
        {
            "6": {
                "title": "Evaluating semantic\naccuracy of data-to-text generation with natural language inference.",
                "author": "Ond\u0159ej Du\u0161ek and Zden\u011bk Kasner. 2020.",
                "venue": "In Proceedings of the 13th International Conference on Natural\nLanguage Generation, pages 131\u2013137, Dublin, Ireland. Association for\nComputational Linguistics.",
                "url": "https://aclanthology.org/2020.inlg-1.19"
            }
        },
        {
            "7": {
                "title": "The usability metric for user experience.",
                "author": "Kraig Finstad. 2010.",
                "venue": "Interacting with computers, 22(5):323\u2013327.",
                "url": null
            }
        },
        {
            "8": {
                "title": "Being polite:\nModeling politeness variation in a personalized dialog agent.",
                "author": "Mauajama Firdaus, Arunav Shandilya, Asif Ekbal, and Pushpak Bhattacharyya.\n2023.",
                "venue": "IEEE Transactions on Computational Social Systems,\n10(4):1455\u20131464.",
                "url": "https://doi.org/10.1109/TCSS.2022.3182986"
            }
        },
        {
            "9": {
                "title": "Neural approaches to\nconversational ai.",
                "author": "Jianfeng Gao, Michel Galley, and Lihong Li. 2018.",
                "venue": "In The 41st International ACM SIGIR Conference on Research &\nDevelopment in Information Retrieval, SIGIR \u201918, page 1371\u20131374, New York,\nNY, USA. Association for Computing Machinery.",
                "url": "https://doi.org/10.1145/3209978.3210183"
            }
        },
        {
            "10": {
                "title": "Adaptive generation in\ndialogue systems using dynamic user modeling.",
                "author": "Srinivasan Janarthanam and Oliver Lemon. 2014.",
                "venue": "Computational Linguistics, 40(4):883\u2013920.",
                "url": "https://doi.org/10.1162/COLI_a_00203"
            }
        },
        {
            "11": {
                "title": "Theoretical considerations and development of a questionnaire to\nmeasure trust in automation.",
                "author": "Moritz K\u00f6rber. 2018.",
                "venue": "In Congress of the International Ergonomics Association, pages\n13\u201330. Springer.",
                "url": null
            }
        },
        {
            "12": {
                "title": "Self-prompting large\nlanguage models for zero-shot open-domain qa.",
                "author": "Junlong Li, Zhuosheng Zhang, and Hai Zhao. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2212.08635"
            }
        },
        {
            "13": {
                "title": "Hierarchical\nhybrid code networks for task-oriented dialogue.",
                "author": "Weiri Liang and Meng Yang. 2018.",
                "venue": "In Intelligent Computing Theories and Application - 14th\nInternational Conference, ICIC 2018, Wuhan, China, August 15-18, 2018,\nProceedings, Part II, volume 10955 of Lecture Notes in Computer\nScience, pages 194\u2013204. Springer.",
                "url": "https://doi.org/10.1007/978-3-319-95933-7_24"
            }
        },
        {
            "14": {
                "title": "Recent\nneural methods on slot filling and intent classification for task-oriented\ndialogue systems: A survey.",
                "author": "Samuel Louvan and Bernardo Magnini. 2020.",
                "venue": "In Proceedings of the 28th International Conference on\nComputational Linguistics, pages 480\u2013496, Barcelona, Spain (Online).\nInternational Committee on Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2020.coling-main.42"
            }
        },
        {
            "15": {
                "title": "Voicexml for web-based distributed conversational applications.",
                "author": "Bruce Lucas. 2000.",
                "venue": "Communications of the ACM, 43(9):53\u201357.",
                "url": null
            }
        },
        {
            "16": {
                "title": "A survey on empathetic dialogue systems.",
                "author": "Yukun Ma, Khanh Linh Nguyen, Frank Z. Xing, and Erik Cambria. 2020.",
                "venue": "Information Fusion, 64:50\u201370.",
                "url": "https://doi.org/https://doi.org/10.1016/j.inffus.2020.06.011"
            }
        },
        {
            "17": {
                "title": "Selfcheckgpt: Zero-resource black-box hallucination detection for\ngenerative large language models.",
                "author": "Potsawee Manakul, Adian Liusie, and Mark JF Gales. 2023.",
                "venue": "arXiv preprint arXiv:2303.08896.",
                "url": null
            }
        },
        {
            "18": {
                "title": "Improving the user experience with a conversational recommender\nsystem.",
                "author": "Fedelucio Narducci, Marco de Gemmis, Pasquale Lops, and Giovanni Semeraro.\n2018.",
                "venue": "In International Conference of the Italian Association for\nArtificial Intelligence, pages 528\u2013538. Springer.",
                "url": null
            }
        },
        {
            "19": {
                "title": "Towards a better metric\nfor evaluating question generation systems.",
                "author": "Preksha Nema and Mitesh M. Khapra. 2018.",
                "venue": "In Proceedings of the 2018 Conference on Empirical Methods in\nNatural Language Processing, pages 3950\u20133959, Brussels, Belgium.\nAssociation for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/D18-1429"
            }
        },
        {
            "20": {
                "title": "Check your facts and try again: Improving large language models with\nexternal knowledge and automated feedback.",
                "author": "Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan\nHuang, Lars Liden, Zhou Yu, Weizhu Chen, et al. 2023.",
                "venue": "arXiv preprint arXiv:2302.12813.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Training\nquestion answering models from synthetic data.",
                "author": "Raul Puri, Ryan Spring, Mohammad Shoeybi, Mostofa Patwary, and Bryan Catanzaro.\n2020.",
                "venue": "In Proceedings of the 2020 Conference on Empirical Methods in\nNatural Language Processing (EMNLP), pages 5811\u20135826, Online. Association\nfor Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2020.emnlp-main.468"
            }
        },
        {
            "22": {
                "title": "Stanza: A\nPython natural language processing toolkit for many human languages.",
                "author": "Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, and Christopher D. Manning.\n2020.",
                "venue": "In Proceedings of the 58th Annual Meeting of the Association\nfor Computational Linguistics: System Demonstrations.",
                "url": "https://nlp.stanford.edu/pubs/qi2020stanza.pdf"
            }
        },
        {
            "23": {
                "title": "End-to-end\nlearning of flowchart grounded task-oriented dialogs.",
                "author": "Dinesh Raghu, Shantanu Agarwal, Sachindra Joshi, and Mausam. 2021.",
                "venue": "In Proceedings of the 2021 Conference on Empirical Methods in\nNatural Language Processing, pages 4348\u20134366, Online and Punta Cana,\nDominican Republic. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2021.emnlp-main.357"
            }
        },
        {
            "24": {
                "title": "Know what you don\u2019t\nknow: Unanswerable questions for SQuAD.",
                "author": "Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.",
                "venue": "In Proceedings of the 56th Annual Meeting of the Association\nfor Computational Linguistics (Volume 2: Short Papers), pages 784\u2013789,\nMelbourne, Australia. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/P18-2124"
            }
        },
        {
            "25": {
                "title": "Incorporating rules into end-to-end dialog systems.",
                "author": "Evgeniia Razumovskaia and Maxine Eskenazi. 2019.",
                "venue": "In Proc. 3rd NeurIPS Workshop on Conversational AI, Vancouver,\nCanada, pages 1\u201311.",
                "url": null
            }
        },
        {
            "26": {
                "title": "Sentence-bert: Sentence\nembeddings using siamese bert-networks.",
                "author": "Nils Reimers and Iryna Gurevych. 2019.",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in\nNatural Language Processing and the 9th International Joint Conference on\nNatural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November\n3-7, 2019, pages 3980\u20133990. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/D19-1410"
            }
        },
        {
            "27": {
                "title": "Shaping a social robot\u2019s humor with natural language generation and\nsocially-aware reinforcement learning.",
                "author": "Hannes Ritschel and Elisabeth Andr\u00e9. 2018.",
                "venue": "In Proceedings of the workshop on NLG for human\u2013robot\ninteraction, pages 12\u201316.",
                "url": null
            }
        },
        {
            "28": {
                "title": "Improving neural\nmachine translation models with monolingual data.",
                "author": "Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016.",
                "venue": "In Proceedings of the 54th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Papers), pages 86\u201396, Berlin,\nGermany. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/P16-1009"
            }
        },
        {
            "29": {
                "title": "Conversation\nLearner - a machine teaching tool for building dialog managers for\ntask-oriented dialog systems.",
                "author": "Swadheen Shukla, Lars Liden, Shahin Shayandeh, Eslam Kamal, Jinchao Li, Matt\nMazzola, Thomas Park, Baolin Peng, and Jianfeng Gao. 2020.",
                "venue": "In Proceedings of the 58th Annual Meeting of the Association\nfor Computational Linguistics: System Demonstrations, pages 343\u2013349,\nOnline. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2020.acl-demos.39"
            }
        },
        {
            "30": {
                "title": "Mpnet: Masked and permuted pre-training for language understanding.",
                "author": "Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2020.",
                "venue": "Advances in Neural Information Processing Systems,\n33:16857\u201316867.",
                "url": null
            }
        },
        {
            "31": {
                "title": "Beir: A heterogenous benchmark for zero-shot evaluation of information\nretrieval models.",
                "author": "Nandan Thakur, Nils Reimers, Andreas R\u00fcckl\u00e9, Abhishek Srivastava, and\nIryna Gurevych. 2021.",
                "venue": "In 35th Conference on Neural Information Processing Systems\n(NeurIPS 2021) Track on Datasets and Benchmarks.",
                "url": "https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/65b9eea6e1cc6bb9f0cd2a47751a186f-Paper-round2.pdf"
            }
        },
        {
            "32": {
                "title": "Llama: Open and efficient foundation language models.",
                "author": "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne\nLachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric\nHambro, Faisal Azhar, et al. 2023.",
                "venue": "arXiv preprint arXiv:2302.13971.",
                "url": null
            }
        },
        {
            "33": {
                "title": "Conversational\ntree search: A new hybrid dialog task.",
                "author": "Dirk V\u00e4th, Lindsey Vanderlyn, and Ngoc Thang Vu. 2023.",
                "venue": "In Proceedings of the 17th Conference of the European Chapter\nof the Association for Computational Linguistics, pages 1264\u20131280,\nDubrovnik, Croatia. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2023.eacl-main.91"
            }
        },
        {
            "34": {
                "title": "EDA: Easy data\naugmentation techniques for boosting performance on text classification\ntasks.",
                "author": "Jason Wei and Kai Zou. 2019.",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in\nNatural Language Processing and the 9th International Joint Conference on\nNatural Language Processing (EMNLP-IJCNLP), pages 6382\u20136388, Hong Kong,\nChina. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/D19-1670"
            }
        },
        {
            "35": {
                "title": "Integrating expert knowledge into pomdp optimization for spoken\ndialog systems.",
                "author": "Jason D Williams. 2008.",
                "venue": "In Proceedings of the AAAI-08 Workshop on Advancements in POMDP\nSolvers, volume 2, page 25.",
                "url": null
            }
        },
        {
            "36": {
                "title": "Hybrid code networks:\npractical and efficient end-to-end dialog control with supervised and\nreinforcement learning.",
                "author": "Jason D. Williams, Kavosh Asadi, and Geoffrey Zweig. 2017.",
                "venue": "In Proceedings of the 55th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Papers), pages 665\u2013677,\nVancouver, Canada. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/P17-1062"
            }
        },
        {
            "37": {
                "title": "Domain-specific faq\nretrieval using independent aspects.",
                "author": "Chung-Hsien Wu, Jui-Feng Yeh, and Ming-Jun Chen. 2005.",
                "venue": "ACM Transactions on Asian Language Information Processing,\n4(1):1\u201317.",
                "url": "https://doi.org/10.1145/1066078.1066079"
            }
        },
        {
            "38": {
                "title": "Investigating Deep Reinforcement Learning Techniques in Personalized\nDialogue Generation, pages 630\u2013638.",
                "author": "Min Yang, Qiang Qu, Kai Lei, Jia Zhu, Zhou Zhao, Xiaojun Chen, and Joshua Z.\nHuang. 2018.",
                "venue": null,
                "url": "https://doi.org/10.1137/1.9781611975321.71"
            }
        },
        {
            "39": {
                "title": "Turning flowchart\ninto dialog: Augmenting flowchart-grounded troubleshooting dialogs via\nsynthetic data generation.",
                "author": "Haolan Zhan, Sameen Maruf, Lizhen Qu, Yufei Wang, Ingrid Zukerman, and\nGholamreza Haffari. 2023.",
                "venue": "In Proceedings of the 21st Annual Workshop of the Australasian\nLanguage Technology Association, pages 88\u201399, Melbourne, Australia.\nAssociation for Computational Linguistics.",
                "url": "https://aclanthology.org/2023.alta-1.9"
            }
        },
        {
            "40": {
                "title": "Recent advances\nand challenges in task-oriented dialog systems.",
                "author": "Zheng Zhang, Ryuichi Takanobu, Qi Zhu, MinLie Huang, and XiaoYan Zhu. 2020.",
                "venue": "Science China Technological Sciences, 63(10):2011\u20132027.",
                "url": "https://doi.org/10.1007/s11431-020-1692-3"
            }
        },
        {
            "41": {
                "title": "Texygen: A\nbenchmarking platform for text generation models.",
                "author": "Yaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang, and Yong\nYu. 2018.",
                "venue": "In The 41st International ACM SIGIR Conference on Research &\nDevelopment in Information Retrieval, SIGIR \u201918, page 1097\u20131100, New York,\nNY, USA. Association for Computing Machinery.",
                "url": "https://doi.org/10.1145/3209978.3210080"
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.17582v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.1",
            "2.2",
            "2.3",
            "2.4",
            "2.5"
        ],
        "methodology_sections": [
            "4",
            "5",
            "5.1",
            "5.2"
        ],
        "main_experiment_and_results_sections": [
            "6",
            "6.1",
            "6.2",
            "6.3",
            "6.4",
            "6.4.1",
            "7",
            "7.1",
            "7.2",
            "7.2.1",
            "7.2.2"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "5",
            "5.1",
            "5.2",
            "6",
            "6.1",
            "6.2",
            "6.3",
            "6.4",
            "6.4.1",
            "7.1",
            "7.2",
            "7.2.1",
            "7.2.2"
        ]
    },
    "research_context": {
        "paper_id": "2403.17582v1",
        "paper_title": "Towards a Zero-Data, Controllable, Adaptive Dialog System",
        "research_background": "### Paper's Motivation\nThe motivation behind this paper stems from the limitations of existing dialog systems, particularly in sensitive domains like legal or medical fields where trust in the system's output is crucial. Modern Large Language Models (LLMs) have revolutionized the creation of dialog systems but still struggle with controllability. Traditional systems like FAQ-retrieval offer controlled responses but are restricted to single-turn interactions and generalized answers, whereas hand-crafted dialog systems either result in longer interactions or require extensive training data, making them unsuitable for low-resource or sensitive settings. The Conversational Tree Search (CTS) framework proposed by V\u00e4th et al. addresses some of these challenges but still demands an extensive corpus of real user interactions, which limits its scalability across various domains.\n\n### Research Problem\nThe primary research problem tackled by this paper is how to scale the CTS framework to new domains without the need for a pre-existing, large, and real-user dataset. Specifically, the paper investigates the feasibility of leveraging synthetically generated training data to enable a zero-data approach to training CTS agents. The focus is on ensuring that the synthetic data maintains the quality and controllability necessary for effective and reliable dialog systems in sensitive domains.\n\n### Relevant Prior Work\n1. **Large Language Models**: The paper acknowledges the advances made by modern LLMs but also highlights their limitations in controllability, making them not ideal for sensitive domains.\n\n2. **FAQ Retrieval Systems**: Previous work (Wu et al., 2005) indicates that while FAQ systems allow close control over output texts, they falter in multi-turn interactions and personalized responses, and face challenges around retrieval accuracy (Thakur et al., 2021).\n\n3. **Hand-Crafted Dialog Systems**: These systems offer turn-based interactions for personalized responses but are either data-intensive (Raghu et al., 2021) or lack transparency and controllability (Gao et al., 2018), making them impractical for low-resource and sensitive domains (Zhang et al., 2020; Cohen, 2020).\n\n4. **Conversational Tree Search (CTS)**: V\u00e4th et al. (2023) proposed CTS, a hybrid dialog system that balances between structured FAQ-like answers and the flexibility of dialog systems by navigating a dialog tree based on user queries. However, its reliance on real-user utterance corpora poses a scaling challenge.\n\nBy addressing the scalability of CTS through synthetically generated training data, this paper aims to bridge the gap between controlled and adaptive dialog systems, making them viable for new and complex domains without the hefty requirement of real-user data collection.",
        "methodology": "The proposed methodology for the RL-based dialog agent incorporates several key modifications and innovations to enhance its performance and adaptability:\n\n1. **Model Architecture Update**:\n   - The original language model has been replaced with an MPNET-based Sentence-Transformer, due to its superior performance in English, as reported by prior studies (Song et al., 2020; Reimers and Gurevych, 2019).\n   \n2. **Reward Mechanism Adjustment**:\n   - For the guided mode: \n     - The reward structure now focuses on whether the agent transitions to the correct next node, rather than achieving a global goal by the dialog's end.\n     - Global goals are assigned to guided mode users to simulate more realistic user queries.\n     - Reaching the global goal node is given a higher reward, while correct follow-up nodes along the path are given smaller rewards.\n     - This results in a stricter success evaluation, where failure to reach the final goal in a dialog results in a failed dialog instead of a partially successful one.\n\n3. **Interaction Style Prediction**:\n   - The importance of the interaction style prediction task is reduced by scaling down its loss, thus emphasizing the learning of Q-values for the main task. This change did not significantly affect the interaction style prediction's F1 score.\n\n4. **Hyperparameter Tuning**:\n   - The batch size is increased and the total number of training steps is also increased to ensure more robust learning.\n   - Exact hyperparameter values and additional details are provided in Appendix A.\n\nThese changes collectively aim to make the dialog agent more adaptive, realistic, and stringent in evaluating dialog success, thus enhancing the overall dialog system's quality and performance.",
        "main_experiment_and_results": "### Main Experiment Setup and Results:\n\n**Experiment Setup:**\n\n- **Participants and Agent Types:** Participants interacted with a CTS agent trained either on real data or on generated data within the REIMBURSE domain.\n\n- **Demographic Information:** Collection of demographic information included previous experience with dialog systems and business travel.\n\n- **Interaction Task:** Participants were required to complete three conversations with their assigned dialog system. Each conversation had a different goal assigned randomly among:\n  1. **Open Goals:** Representing a general or vague information need.\n  2. **Easy Goals:** Representing a concrete information need.\n  3. **Hard Goals:** Representing a concrete information need requiring personalized information, such as the user's specific circumstances that could alter the dialog flow.\n\n- **Evaluation Criteria:**\n  1. **In-process Evaluation:** After each conversation, participants rated their subjective perception of the dialog length and how well their question was answered.\n  2. **Post-interaction Evaluation:** Following all interactions, participants rated the overall usability of the dialog agent, the level of trust in the agent, and its reliability.\n\n**Main Experimental Results:**\n\nThe experiment set out to assess the usability, trustworthiness, and reliability of dialog agents trained on different data types (real vs. generated) across varying goal complexities. Detailed results regarding the performance of agents trained on real versus generated data, and their effectiveness in handling different types of goals, would be found in the full experimental results section of the paper. For further specifics, additional details are available in Appendix B."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "Investigate the effectiveness of different question generation methods (GenV1, GenV2, and GenV3) for creating synthetic data that can train dialogue systems effectively.",
            "experiment_process": "Three methods of generating questions were tested: GenV1 (a naive prompt instructing an LLM to generate diverse FAQ-style questions), GenV2 (an updated prompt explicitly asking for shorter questions), and GenV3 (a novel two-step method using Named Entity Recognition to steer question generation for increased diversity). The data was generated using an LLM (either a commercial model or a smaller open-source model) and evaluated for quality and diversity using metrics such as Self-BLEU and QA confidence scores.",
            "result_discussion": "The change from GenV1 to GenV2 resulted in more aligned question lengths and more natural utterances, but it did not significantly increase semantic similarity to human data. The novel GenV3 method significantly increased similarity to human data and produced the most diverse questions. Additionally, GenV3 data improved downstream task performance, with agents trained on this synthetic data achieving comparable dialog success rates to those trained on human data.",
            "ablation_id": "2403.17582v1.No1"
        },
        {
            "research_objective": "Evaluate how well synthetic data generation methods generalize across new domains and compare the performance of agents trained on real versus generated data within these domains.",
            "experiment_process": "Two new datasets, ONBOARD and DIAGNOSE, were used to test the generalizability. Agents trained on synthetic data generated by both a commercial LLM (ChatGPT) and a smaller open-source model (LLAMA) were compared against agents trained on real human data. The testing was performed similarly to previous experiments using automatic evaluation with a user simulator on the test splits of the new datasets.",
            "result_discussion": "For the DIAGNOSE dataset, the agent trained on data generated by LLAMA performed comparably to the agent trained on human data, while the ChatGPT-trained agent surpassed it. The ONBOARD dataset presented more challenges (possibly due to code-switching), but the ChatGPT-trained model still nearly reached the performance of the human data-trained model. T-tests indicated no statistically significant differences, suggesting the generation methods scale well to new domains.",
            "ablation_id": "2403.17582v1.No2"
        },
        {
            "research_objective": "Compare the performance of dialogue agents trained on human data versus synthetic data through human evaluation.",
            "experiment_process": "44 participants from Prolific took part in this study, interacting with either a CTS agent trained on real data or one trained on generated data. Participants completed three conversations with different goals (open, easy, and hard). They rated their subjective perception of dialog length and question satisfaction after each conversation and the usability, trust, and reliability of the dialog agent overall.",
            "result_discussion": "No statistically significant differences were found between agents trained on real versus generated data in terms of subjective or objective measures of success, dialog length, trust, reliability, or usability. This suggests that using synthetic data does not lead to human-observable performance loss.",
            "ablation_id": "2403.17582v1.No3"
        }
    ]
}