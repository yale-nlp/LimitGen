{
    "title": "CookingSense: A Culinary Knowledgebase with Multidisciplinary Assertions",
    "abstract": "This paper introduces CookingSense, a descriptive collection of knowledge assertions in the culinary domain extracted from various sources, including web data, scientific papers, and recipes,\nfrom which knowledge covering a broad range of aspects is acquired.\nCookingSense is constructed through a series of dictionary-based filtering and language model-based semantic filtering techniques,\nwhich results in a rich knowledgebase of multidisciplinary food-related assertions.\nAdditionally, we present FoodBench, a novel benchmark to evaluate culinary decision support systems.\nFrom evaluations with FoodBench, we empirically prove that CookingSense improves the performance of retrieval augmented language models.\nWe also validate the quality and variety of assertions in CookingSense through qualitative analysis.\n\n\n\nKeywords:\u2009knowledgebase, benchmark dataset, culinary art",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1.   Introduction",
            "text": "Cooking is one of the most important human activities; it not only fulfills the physiological needs of humans but also facilitates a physically and emotionally healthy life Spencer et al. (2017  ###reference_b48###).\nIt is intertwined with many parts of our society, including restaurant business, food manufacturing, public health, and social media L\u00f3pez-Alt (2015  ###reference_b31###).\nDue to the importance of cooking on human beings, there have been significant amount of work that applied computational approaches into the food domain.\nEspecially, recent advancements in machine learning or artificial intelligence (AI) have stimulated the development of artificial intelligence AI-driven culinary decision support systems.\nSince the performance of such applications is highly dependent to the existence and quality of data to be used,\nit is clear that they can benefit from high-quality cooking knowledge in terms of both practicability and reliability.\n###figure_1### On the other hand, it is difficult to define the term \u2018cooking knowledge\u2019 in a single sentence;\nthe meaning or coverage of the term could diverge depending on areas of interests and goals to pursue.\nFor example, for chefs who want to make savory dishes for their customers, cooking knowledge will refer to proficiency in culinary arts and in-depth understanding of food science Dornenburg and Page (2008  ###reference_b11###); L\u00f3pez-Alt (2015  ###reference_b31###).\nOn the contrary, researchers working on environment, social well-being, or nutrition would focus rather on different aspects, such as environmental impact, relationship between ingredients or cooking methods and health risks Marcus (2013  ###reference_b32###), and so forth.\nConsidering this, culinary knowledge should allow individuals from various groups to derive outcomes that best suit their needs in accordance with their preferences.\nIn other words, cooking knowledge should be defined in a multifaceted way in order to cover a broad range of topics specialized for each group, such as food common sense Wang et al. (2023  ###reference_b53###), culinary arts, health, nutrition, culinary culture Nguyen et al. (2022b  ###reference_ib5###), food management, food safety, and so on.\nUsing resources of cooking knowledge brings several challenges when this multifaceted nature is not considered, including determining knowledge aspects to be used depending on each user\u2019s preferences, and limitation of utilizing a resource built for a specific purpose into other areas, to name a few.\nNotwithstanding the importance of multifaceted cooking knowledge, many existing knowledge resources in the food domain tend to focus only on a specific aspect, e.g. recipe, nutrition, healthcare (Marin et al., 2019  ###reference_b33###; Fukagawa et al., 2022  ###reference_b13###; Huang et al., 2019  ###reference_b22###; Min et al., 2022  ###reference_b34###).\nThis justifies the motivation of constructing a large-scale, versatile cooking knowledgebase (KB) that is widely accessible and contains rich sources of food-related information.\nIn this work, to circumvent the lack of coverage appearing in those aspect-specific KBs, we suggest CookingSense, a cooking KB built from various large-scale corpora.\nCookingSense is constructed through processing culinary-focused textual data from a variety of available sources with different information characteristics e.g. web data, scientific papers, and recipes, to collect descriptive knowledge statements.\nWe additionally create FoodBench, a novel benchmark for assessing the capabilities of models that assist food-related decision making.\nFoodBench consists of various evaluation tasks, including flavor prediction, ingredient categorization, and culinary question answering Nguyen et al. (2022b  ###reference_ib5###); Palta and Rudinger (2023  ###reference_ib6###).\nWe demonstrate that the performance of existing language models can be improved by incorporating CookingSense through evaluations using FoodBench.\nAdditionally, from the extensive investigation, we show CookingSense provides richer descriptions with diverse semantics, offering wider understanding of culinary concepts.\nOur contributions are summarized as follows:\nWe construct CookingSense, a novel large-scale culinary KB with various cooking aspects.\nWe construct FoodBench, a benchmark framework for the evaluation of culinary decision-making systems\u2019 capabilities of capturing related knowledge.\nWe compare the effectiveness of CookingSense against existing general and culinary domain KBs, from evaluation with recent generative language models augmented with knowledge retrieval.\nWe make the scripts to construct CookingSense and FoodBench publicly available.111https://github.com/dmis-lab/cookingsense  ###reference_###"
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2.   Related Work",
            "text": "Culinary KBs play a crucial role in a wide range of culinary applications, including dietary recommendation systems Choi et al. (2023  ###reference_b7###), diet-disease management Nian et al. (2021  ###reference_b36###), food-related question answering systems Haussmann et al. (2019  ###reference_b18###), novel recipe development Park et al. (2019  ###reference_b40###, 2021  ###reference_b39###); Gim et al. (2021  ###reference_b16###, 2022  ###reference_b15###), and more Min et al. (2022  ###reference_b34###). However, current approaches to constructing culinary KBs often focus on specific data aspects, such as recipes Batra et al. (2020  ###reference_ib1###) or nutritional data Haussmann et al. (2019  ###reference_b18###), which results in fragmented knowledge representation. Although individual KGs may contain substantial amounts of data, the isolation between these KGs limits the ability to gain a comprehensive overview of the overall culinary landscape. Also, many culinary KBs are often constructed using limited lists of relations that are defined by individual researchers, resulting in lack of rich semantics and comprehensive coverage. Furthermore, the automatic construction of culinary KBs has mostly been done without assumption of using those with language models nor using language models (LMs) themselves in the process of KB construction, even though LMs have the potential to capture more nuanced semantics in the construction pipeline and now have being acted as the de-facto standard for natural language processing. On the contrary, there exist a number of recent approaches to automatic construction of large KBs for other domains, such as general common sense Nguyen et al. (2021  ###reference_b35###, 2022a  ###reference_ib4###); Hwang et al. (2021  ###reference_b23###); Bosselut et al. (2019  ###reference_b3###), negative relationship modeling Arnaout et al. (2022  ###reference_b1###), and cultural perspectives Nguyen et al. (2022b  ###reference_ib5###). These approaches have made significant advancements, primarily due to the utilization of LMs Arnaout et al. (2022  ###reference_b1###); Nguyen et al. (2022b  ###reference_ib5###) and the enhancement of construction pipelines Bhakthavatsalam et al. (2020  ###reference_ib2###). Advancements in extractions and filtering brought by LMs enable the extraction of large volumes of data, facilitating the construction of knowledge bases in a reliable manner. DEER Huang et al. (2022  ###reference_b21###) is one of noteworthy approaches in this line, which proposed KBs with descriptive relationships that contain rich semantics among a set of concepts. Our work aligns with the recent advancements in previous studies, presenting effective pipelines for building reliable and large-scale KBs in the culinary domain."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3.   KB Construction",
            "text": "###figure_2### We now provide a detailed description about the processes for constructing the CookingSense dataset.\nTo ensure broad coverage and collect high-quality knowledge statements within the domain, we chose three types of text corpora: web data, scientific papers, and recipes.\nWhile these corpora accompany valuable information across various aspects, there may also exist texts with undesired or no information, e.g. noisy texts, texts not in the culinary domain.\nTo filter out those texts, we apply various filters, each of which is designed based on linguistic properties, thesaurus of words, semantics of knowledge statements, and so forth.\nFigure 2  ###reference_### depicts the example knowledge statements from CookingSense, and Figure 3  ###reference_### illustrates the overview of the pipeline for the KB construction along with the number of assertions before and after each step."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1.   Requirements",
            "text": "We elaborated the following requirements to ensure the reliability and applicability of CookingSense in various cooking-related downstream tasks.\nRelevance to cooking:\nRelevance to cooking is one of the most important criteria we want to achieve.\nResources used, construction pipeline, and benchmark tasks should have relevance to the culinary domain.\nMultiple data sources:\nThe KB should obtain knowledge from various sources,\nto incorporate knowledge that is not biased towards a specific community or content.\nCoverage on various facets:\nIn line with the above requirement, the KB should contain knowledge that can cover various use cases and preferences, i.e. multifaceted nature.\nUnlike many existing culinary datasets that predominantly focus on recipes or general corpus, CookingSense encompasses various aspects of culinary knowledge by acquiring knowledge from web content, paper-based corpora, and user-generated recipes.\nFlexible relation types:\nAn optimal set for relation types required by a task set could differ, depending on the goal for each application.\nCookingSense prioritizes inclusion of a wide range of culinary semantics represented in a form of text,\nby employing unsupervised mining techniques to capture semantic variety.\nIt employs unsupervised mining techniques to capture this semantic variety.\nSufficiently large volume:\nEven though there exist numerous factors that determine the usability of a KB, size is one of the most important components relevant to coverage, diversity, correctness, and robustness.\nCookingSense is designed to have a substantial amount of knowledge assertions.\nWe compare CookingSense against other baseline datasets upon these requirements in Table 1  ###reference_###.\n###figure_3###"
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2.   Data Sources",
            "text": "We chose three different data sources: web data, scientific papers, and recipes, as base corpora to construct CookingSense.\nData sources are primarily composed of English texts."
        },
        {
            "section_id": "3.2.1",
            "parent_section_id": "3.2",
            "section_name": "3.2.1.   Web Data",
            "text": "We used Colossal Clean Crawled Corpus (C4; Raffel et al., 2020  ###reference_b42###) for our base corpus for web data.\nC4 is a large-scale web corpus consisting of about 364M articles (7B sentences) from the web.\nDue to its massive size and wide range of coverage, we chose C4 for our key data source for general culinary and food-related information.\nAlthough several noise reduction procedures, including removing harmful texts, were done in the process of constructing C4, there still exist a significant amount of texts which are noisy or not in our interest, we applied a series of data refinement techniques on the original C4."
        },
        {
            "section_id": "3.2.2",
            "parent_section_id": "3.2",
            "section_name": "3.2.2.   Scientific Papers",
            "text": "We chose scientific papers as another source for our KB, in the belief that it enables us to integrate trustworthy and research-backed knowledge into our KB.\nWe collected a large amount of scientific literature using Semantic Scholar Public API222https://www.semanticscholar.org/product/api  ###reference_i###.\nThese APIs grant access to a vast collection of academic articles;\nSemantic Scholar Public API provides access to S2ORC (Lo et al., 2020  ###reference_b30###), a large corpus of 81.1M open-access academic papers from various fields.\nTo retrieve papers relevant to our interest, we built a list of terms in the domains of culinary arts, nutrition, and food sciences and used them to query the APIs.\nDetailed descriptions of those terms are available in \u00a73.5  ###reference_###.\nFor each retrieved article, we collected the title and the summary of the abstract."
        },
        {
            "section_id": "3.2.3",
            "parent_section_id": "3.2",
            "section_name": "3.2.3.   Recipes",
            "text": "Recipes could also be a useful source for a food-related KB, in that a recipe usually contains procedural knowledge required for making a dish from basic ingredients.\nWe used Recipe1M+ Marin et al. (2019  ###reference_b33###) for our data source for recipes.\nRecipe1M+ consists of more than 1M culinary recipes with their pictures gathered from a large number of popular recipe websites.\nWe extracted the title, the list of ingredients, and cooking instructions from each recipe."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "3.3.   Creation of Assertions",
            "text": "Depending on the inherent characteristics of each data source, the length of each text instance (i.e. document, paragraph, or sentence) may vary.\nTo address this discrepancy, we split or merge text instances into chunks of one or two sentences and use them as the unit of knowledge; which we refer to as \u201cassertions.\u201d\nFor C4, we utilize the sentence tokenizer of spaCy (Honnibal et al., 2020  ###reference_b20###) and treat each sentence as an assertion.\nFor the scientific papers, there exist two types of texts:\nSince the output of SciTLDR tends to be a single sentence, we concatenate the title and the summary of the paper generated by SciTLDR to compose an assertion.\nIn Recipe1M+, the content of each recipe consists of the section of ingredient explanations and the section of cooking instructions.\nWe combine the recipe title and either a single ingredient or a single step of cooking instruction to put together an assertion.\nThe average number of tokens in each assertion by data source is available at Table 2  ###reference_###."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "3.4.   Removal of Non-Generic Assertions",
            "text": "Not all the assertions collected from the above process contain knowledge that can be accepted as true in general.\nWe apply filtering on assertions to remove non-generic assertions, which include non-informative or context-dependent statements.\nFollowing approaches used in constructing GenericsKB (Bhakthavatsalam et al., 2020  ###reference_ib2###) and CANDLE (Nguyen et al., 2022b  ###reference_ib5###) with identical purpose to ours, we make use of 27 handcrafted rules used in GenericsKB (Bhakthavatsalam et al., 2020  ###reference_ib2###) to automatically filter out non-generic assertions.\nThe rules are defined under various assumptions on generic sentences, including the ones based on parse trees (e.g. removing sentences whose root is non-verb), modals (e.g. removing sentences containing \u2018could\u2019, \u2018would\u2019), first word (e.g. remove sentences starting with a determiner \u2018a\u2019, \u2018the\u2019)."
        },
        {
            "section_id": "3.5",
            "parent_section_id": "3",
            "section_name": "3.5.   Removal of Irrelevant Assertions",
            "text": "After the removal of non-generic assertions, we now have a collection of generic assertions.\nHowever, the remaining assertions still have a wide variety of content and perspectives that reside beyond our specific area of focus.\nTo address this, we designed a filtering method based on the dictionary of food or culinary terms we collected.\nThis filter eliminates assertions that are generic yet irrelevant to our target domain.\nOur filtering dictionary primarily consists of two types of terms: (1) ingredient and food name and (2) food-related terms obtained from an AI assistant.\nSpecific examples are provided in Table 3  ###reference_### for reference."
        },
        {
            "section_id": "3.5.1",
            "parent_section_id": "3.5",
            "section_name": "3.5.1.   Ingredient and Food Names",
            "text": "We use RecipeDB Batra et al. (2020  ###reference_ib1###) in collecting entities associated with food names and ingredient names.\nWe extract bigrams appearing in recipe titles to obtain the list of food names, and bigrams appearing in ingredient sections to obtain the list of ingredient names.\nBigrams that occur more than 3 times (food names) or 2 times (ingredient names) to avoid rare or noisy entities to be included in the dictionary; 1,914 and 5,482 bigrams are collected as a result.\nWe show the most frequent bigrams for each data source in Table 5  ###reference_###."
        },
        {
            "section_id": "3.5.2",
            "parent_section_id": "3.5",
            "section_name": "3.5.2.   Terms Collected from AI Assistant",
            "text": "Relying only on ingredient and food names extracted from a recipe database would limit the ability to capture a broader range of culinary terms, since there could exist food-related assertions that do not necessarily contain those terms, which in result may narrow down the scope of the resulting assertions.\nTo mitigate this, we also add general terms such as \u201cFood\u201d and \u201cNutrition\u201d as well as specific terms such as \u201cVitamin B\u201d for nutrition and \u201cDiabetes\u201d for healthy diet.\nWe develop a two-level ontology, allowing us to categorize 1,600 culinary terms.\nWe use ChatGPT333https://chat.openai.com  ###reference_chat.openai.com### to collect those common culinary terms.\nThe prompt \u201cPlease provide an exhaustive list of verbs related to cooking actions and techniques, such as chopping, slicing, seasoning, and garnishing.\u201d is used to collect common culinary terms.\nAdditionally, to acquire the list of professional or scientific terms related to food, we utilize the prompt \u201cI want to develop a dataset based on food computing and want to aggregate abstracts of related papers. Please suggest me 20 keywords that will provide such insights.\u201d444This prompt is also used in collecting terms for making S2ORC queries, as described in \u00a73.2  ###reference_###."
        },
        {
            "section_id": "3.6",
            "parent_section_id": "3",
            "section_name": "3.6.   Semantic Categorization",
            "text": "To make the KB more usable and figure out which category each assertion falls into, we constructed a \u201csilver standard\u201d annotated dataset where category labels related to culinary arts and food-related content are attached to assertions using a large language model (LLM).\nFor the initial dataset, we randomly sampled 10,000 assertions from the KB gathered through the method described previously.\nTo annotate labels on those 10,000 assertions, we use the GPT-4 model555https://openai.com/research/gpt-4  ###reference_openai.com/research/gpt-4### (version as of September 30, 2023) to classify them into six distinct types: (a) Food Common Sense, (b) Culinary Arts, (c) Healthy Diet & Nutrition, (d) Culinary Culture, (e) Food Management & Food Safety, and (f) Irrelevant or None.\nThe distribution across these categories exhibited significant imbalance, where the majority of sentences fell into the \u201cIrrelevant or None\u201d category.\nTo address this class imbalance issue and facilitate classifier training, we employed a well-established data-level approach\u2014under-sampling the dataset Johnson and Khoshgoftaar (2019  ###reference_b25###).\nSpecifically, we randomly chose 218 sentences from each category, resulting in a balanced dataset.\nThis balanced dataset is subsequently divided in the ratio of 80% and 20%, each for training and test set.\nAfter that, we trained a classification model based on the bert-large-uncased architecture Devlin et al. (2019  ###reference_b10###) using the training split of the balanced dataset.\nIt achieved an accuracy of 0.76 on the test split, underscoring the model\u2019s efficacy in categorizing assertions.\nWe applied this classifier to 68M assertions after removing irrelevant assertions, resulting in 34M categorized assertions, excluding those labeled as \u201cIrrelevant or None.\u201d Detailed results are available in Table 4  ###reference_###.\nIn addition, we present bigrams with the highest frequencies categorized by their sources and types in Table 5  ###reference_### and 6  ###reference_###.\nThe distributions of bigrams demonstrate that information varies across different sources and types, highlighting the importance of collecting data from diverse sources."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4.   Evaluation",
            "text": "To assess the effectiveness of our KB, we adopt the context-augmented language model setup inspired by the work of Retrieval Augmented Generation (RAG; Lewis et al., 2020b  ###reference_b29###),\nwhere a context retrieved from a retriever system is augmented with the input to generate texts.\nWe use baseline KBs and the CookingSense as sources for retrieval to measure how differently knowledge assertions from other KBs enrich the input.\nRetriever system:\nWe adopt Okapi-BM25 Robertson et al. (2009  ###reference_b44###) for the retriever system for RAG evaluation, using the retriv.666https://github.com/AmenRa/retriv  ###reference_github.com/AmenRa/retriv###\nBM25 is a simple yet powerful ranking algorithm based on term and document frequency, which is widely used in various work Trotman et al. (2014  ###reference_b52###).\nThe motivation behind choosing BM25 for our retriever is, to keep a retrieval algorithm as simple as possible so that the generation quality depends more on KB\u2019s quality, not the performance of a retrieval algorithm.\nLanguage model:\nWe utilized the Flan-T5 (flan-t5-large) language model Chung et al. (2022  ###reference_b8###) for text generation purposes.\nFlan-T5 is a language model based on T5 Raffel et al. (2020  ###reference_b42###) fine-tuned with instruction guides (Wei et al., 2022a  ###reference_b54###; Ouyang et al., 2022  ###reference_b38###; Sanh et al., 2022  ###reference_b46###, inter alia).\nIt can respond to a wide range of question types without the need for additional fine-tuning specific to a benchmark format."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1.   FoodBench",
            "text": "To evaluate the utility of CookingSense and other baseline KBs, we have developed a benchmark suite for the culinary domain, namely FoodBench.\nFoodBench is a collection of culinary-related benchmark tasks covering question answering, flavor perspective prediction, and cultural perspective prediction.\nTo ensure compatibility within our RAG framework, we converted these tasks into a multiple choice question answering format.\nFor instance, in a question like \u201cWhat type of cut does something that is minced produce?\" with answer choices \u201ca) squares, b) long strips, c) large slices, d) very tiny pieces\", the agent\u2019s task is to select the correct answer, which, in this case, would be d).\nAlso in our evaluation, if the number of potential answers for a question is less than four, we designate any remaining possibilities as \u201cThis is not an answer.\"\nQuestion answering:\nWe collected 429 question-answer pairs from user-generated content on the web that reflects the real-world perspective of culinary knowledge; namely CookingSenseQA (CSQA).\nFlavor perspectives:\nFlavor is one of the most important feature that determines the overall experience of a dish.\nWe gathered and constructed flavor-related binary classification problems from the following resources:\nASCENT++ Nguyen et al. (2022a  ###reference_ib4###):\nASCENT++ is a common sense KB with a diverse range of facets, including culinary concepts, and their corresponding assertions.\nWe gathered 310 assertions where ingredients are associated with flavor expressions from ASCENT++.\nThese assertions include an example such as (Carambola, sweet).\nThe Good Scents Company:\nAnother data source we used for gathering flavor information is The Good Scents Company Information System777http://www.thegoodscentscompany.com/  ###reference_### (TGSC).\nFrom this resource, we chose 500 assertions in a broader spectrum of flavor expressions, such as (orange, citrus) and (irish cream, melon).\nCultural perspectives:\nCultural perspectives also play a crucial role in shaping culinary decision-making processes, as they influence not only the ingredients and techniques but also the traditions and rituals associated with food.\nWe integrate two distinct benchmark datasets into FoodBench to cover those cultural dimensions:\nCultural knowledge quizzes:\nWe use the collection of cultural knowledge quizzes which used in the evaluation of CANDLE Nguyen et al. (2022b  ###reference_ib5###).\nThroughout this paper, we denote this evaluation dataset as CKQ.\nIt contains 500 multiple-choice questions related to cultural knowledge, and among which we chose 306 food-related question-answer pairs,\nfor example \u201cIn many European countries, which meat is consumed on Easter Sunday?\u201d\nThese question-answer pairs could be used to measure whether a KB covers diverse cultural practices and culinary traditions around the world.\nFORK  Palta and Rudinger (2023  ###reference_ib6###):\nFORK is a manually-curated dataset comprising 184 question-answer pairs designed to probe cultural biases and assumptions in the culinary domain.\nThis dataset requires cultural nuances in culinary practices through questions such as, \u201cA man went to a restaurant and ordered Sweet and Sour Pork. As he put some of the food in his bowl to eat, he reached out for what?\""
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2.   Baselines",
            "text": "We compare CookingSense with the following KBs based on how each KB contributes to performance improvement in the FoodBench evaluation.\nConceptNet  Speer et al. (2017  ###reference_ib8###):\nConceptNet is a structured semantic network that has been steadily improved through crowdsourcing since 1999.\nTo make it usable within our evaluation framework, we convert triples in ConceptNet (subject entity, relation type, object entity) into 980k assertions.\nFooDB FooDB (2020  ###reference_ib3###):\nFooDB is a structured KB that focuses on food constituents, chemistry, and biology.\nWe extracted 6,059 culinary-domain knowledge snippets from this KB and converted them into assertions.\nCANDLE  Nguyen et al. (2022b  ###reference_ib5###):\nCANDLE is a cultural common sense KB, spanning various facets such as food, behaviors, rituals, and traditions.\nWe obtained 60,134 assertions in the culinary domain from this KB.\nQuasimodo  Romero et al. (2019  ###reference_ib7###):\nQuasimodo is an open-source common sense KB designed to retrieve properties relevant to entities, including those in culinary topics.\nWe gathered about 6.3M assertions extracted from the triplets within the KB.\nThis corpus functions as a large-scale, general textual knowledge resource for our evaluation."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "4.3.   Experimental Results",
            "text": ""
        },
        {
            "section_id": "4.3.1",
            "parent_section_id": "4.3",
            "section_name": "4.3.1.   FoodBench",
            "text": "Table 7  ###reference_### presents the results of RAG experiments with FoodBench.\nFor scores from CookingSense, along with the overall performance, we also denote scores where only a specific source is used, to see each data source\u2019s effectiveness separately.\nIn all experiments, even with the use of recent LLM which is believed to have world knowledge with the power of massive pre-training, it is shown that integrating KB improves performance significantly.\nThis validates utilizing external KBs is still one of the most effective and realizable ways to improve performance,\nstrengthening the necessity of a KB that contains high-quality assertions and is easy to use along with LLMs.\nIn most cases, RAG integrated with CookingSense outperformed other baseline KBs in various evaluation datasets by a large margin.\nFor the FORK, RAG with FooDB performed the best,\nwhich we conjecture due to the fact that FooDB contains background knowledge of ingredients directly aligning with problems in FORK.\nExperimental results demonstrate the potential usefulness of CookingSense in various culinary-related downstream tasks.\nWe expect CookingSense to provide a foundational basis for empowering other types of large language models with specific culinary knowledge to facilitate better practicability when deployed in culinary decision support systems."
        },
        {
            "section_id": "4.3.2",
            "parent_section_id": "4.3",
            "section_name": "4.3.2.   Qualitative Analysis",
            "text": "In the previous evaluation, we used FoodBench, an automatically constructed benchmark data from available sources to show the effectiveness of CookingSense.\nTo verify the quality of CookingSense in a more direct and fine-grained way, we conducted a qualitative analysis of the results from CSQA experiments.\nTable 8  ###reference_### presents a selection of question-answer pairs from CSQA along with their retrieved context form its sources.\nFinding 1: Web data contains diverse and long-tailed information.\nUpon analysis, we found that due to diversity of data from the web, retrieval of common sense (row 1; it is known that it should be adjusted to taste), cultural perspectives (row 4, \u2018French Limousin oak\u2019), and authoritative information (row 5, statement from FDA).\nFinding 2: Recipes offer culinary insights, while papers do expert-level knowledge.\nAssertions from recipes show its strength of covering empirical knowledge, including examples like \u2018soft ball stage of cooked sugar occurs at the temperature of 240 \u00b0F\u2019 (row 2).\nOn the other hand, assertions from scientific papers give scientific knowledge such as \u2018xylitol can be used as a substitute for sugar\u2019 (row 3).\nIn summary, these examples show that CookingSense contains a wide array of information, originating from various sources that provide rich textual representations of assertions in a different aspect, resulting in a complementarily gathered collection of knowledge."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5.   Conclusion",
            "text": "In conclusion, we have constructed the CookingSense, a large-scale KB that encompasses a comprehensive collection of culinary-domain assertions obtained from various data sources.\nLeveraging dictionary-based filtering and language model-based semantic filtering techniques, we obtained a collection of high-quality assertions with broad coverage in the culinary domain.\nWe also introduced the FoodBench benchmark framework for assessing culinary-domain decision supporting systems.\nFrom evaluations with FoodBench, we empirically proved that CookingSense improves the performance of retrieval augmented language models.\nWe conducted a qualitative analysis to validate the quality and variety of assertions in CookingSense.\nWe expect CookingSense and FoodBench to pave the way for future work on building, enhancing, and evaluating culinary decision supporting systems.\nFor future work, we aim to enhance the system into a new culinary domain-specific QA system or chatbot Zhang et al. (2023  ###reference_b57###) covering diverse perspectives related to culinary decision making using LLMs Touvron et al. (2023  ###reference_b51###); Jiang et al. (2023  ###reference_b24###); Team et al. (2024  ###reference_b50###) and the prompt engineering techniques Wei et al. (2022b  ###reference_b55###); Nori et al. (2023  ###reference_b37###).\nAlso, we plan to enhance our datasets with enhanced extraction techniques Hayati et al. (2023  ###reference_b19###); Cegin et al. (2023  ###reference_b5###) that utilize recent LLMs to cover more diverse topics."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6.   Ethical Considerations and Limitations",
            "text": ""
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "6.1.   Ethical Considerations",
            "text": "Given that our KB and benchmark framework are created using an automated pipeline, we acknowledge a potential risk of inclusion of biased or violent data from various sources, such as web-crawled content, papers, and recipes. This introduces certain ethical considerations and limitations that need to be addressed.\nEspecially, biases could exist in the constructed KB and also for the benchmarks, mingled with other perspectives such as culture, ethnicity, or gender."
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "6.2.   Limitations",
            "text": "Although we aimed to include as diverse data source as possible, the KB still has room for improvement by incorporating more diverse data sources,\nas seen in the FORK experiment where FooDB helped the most while for all other experiments CookingSense improved the performance by a large margin.\nWe have plans to extend CookingSense by incorporating an even broader range of facets related to food and culinary arts,\nsuch as USDA Food and Nutrition,888https://www.usda.gov/topics/food-and-nutrition  ###reference_tion### USDA FoodData Central,999https://fdc.nal.usda.gov  ###reference_fdc.nal.usda.gov### and FooDB.\nAlso, the data sources we used are in English, which may hinder collection of resources from low-resource languages, reflection of cultural nuance, and so forth."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7.   Acknowledgement",
            "text": "We thank Hoonick Lee and David Im for their invaluable assistance.\nOur work is part of a collaboration between Sony AI and Korea University.\nThis work was supported by the National Research Foundation of Korea (NRF-2023R1A2C3004176, NRF-2022R1F1A1069639, NRF-2022R1C1C1008074) and the ICT Creative Consilience Program through the Institute of Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korean government (MSIT) (IITP-2024-2020-0-01819, No.RS-2022-00155911 (Artificial Intelligence Convergence Innovation Human Resources Development (Kyung Hee University)).\nDonghee Choi is additionally supported by the Horizon Europe project CoDiet. The CoDiet project is funded by the European Union under Horizon Europe grant number 101084642. CoDiet research activities taking place at Imperial College London and the University of Nottingham are supported by UK Research and Innovation (UKRI) under the UK government\u2019s Horizon Europe funding guarantee (grant number 101084642)."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "8.   Bibliographical References",
            "text": ""
        },
        {
            "section_id": "9",
            "parent_section_id": null,
            "section_name": "9.   Language Resource References",
            "text": ""
        }
    ],
    "url": "http://arxiv.org/html/2405.00523v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.2.1",
            "3.2.2",
            "3.2.3",
            "3.3",
            "3.4",
            "3.5",
            "3.5.1",
            "3.5.2",
            "3.6"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.2",
            "4.3",
            "4.3.1",
            "4.3.2"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4.3.1",
            "4.3.2"
        ]
    },
    "research_context": {
        "paper_id": "2405.00523v1",
        "paper_title": "CookingSense: A Culinary Knowledgebase with Multidisciplinary Assertions",
        "research_background": "### Motivation:\n\nThe motivation behind the paper \"CookingSense: A Culinary Knowledgebase with Multidisciplinary Assertions\" stems from the crucial role that cooking plays in human life. Cooking influences not just physiological needs but also physical and emotional health. It is deeply woven into various societal sectors such as the restaurant business, food manufacturing, public health, and social media. Given its significance, there has been a surge in computational approaches applied to the food domain, particularly through advancements in AI and machine learning. These AI-driven culinary decision support systems require high-quality and practical cooking knowledge to function optimally.\n\n### Research Problem:\n\nThe primary research problem identified is the difficulty in defining 'cooking knowledge' in a way that encompasses all relevant facets. Existing knowledge resources in the food domain tend to focus narrowly on specific aspects like recipes, nutrition, or healthcare. This one-dimensional focus limits the utility of such resources across diverse culinary applications and user groups. Consequently, there is a lack of a comprehensive, multifaceted culinary knowledgebase that covers a wide array of topics such as food common sense, culinary arts, health, nutrition, culinary culture, food management, and food safety.\n\n### Relevant Prior Work:\n\n1. **Domain-Specific Knowledge Resources**: Previous works have created knowledge resources focusing on specific culinary aspects like recipes (Marin et al., 2019), nutrition (Fukagawa et al., 2022), and healthcare (Huang et al., 2019; Min et al., 2022). These works underscore the utility of specific knowledge aspects but highlight the gap in creating a versatile, multifaceted knowledgebase.\n\n2. **Food Common Sense**: Work like Wang et al. (2023) delves into general culinary knowledge, or 'food common sense', which informs the broader public about basic culinary facts and practices.\n\n3. **Impact of Cooking Knowledge**: Studies by Dornenburg and Page (2008), and L\u00f3pez-Alt (2015) emphasize the importance of culinary arts and food science for chefs, whereas research by Marcus (2013) focuses on environmental impact and health risks associated with cooking.\n\n### Contributions of the Paper:\n\n- **CookingSense**: A large-scale, comprehensive culinary knowledgebase constructed from diverse sources like web data, scientific papers, and recipes, designed to provide rich, descriptive culinary knowledge.\n  \n- **FoodBench**: A novel benchmark to assess models' capabilities in food-related decision-making tasks such as flavor prediction, ingredient categorization, and culinary question answering.\n\n- **Evaluation and Improvement**: The paper evaluates the performance of existing language models with CookingSense and finds enhanced model performance on FoodBench tasks, indicating the enriched knowledge offered by CookingSense.\n\nBy addressing the gaps in existing culinary knowledge resources and creating versatile, comprehensive tools, the paper aims to significantly advance AI-driven culinary decision support systems.",
        "methodology": "The methodology for constructing the CookingSense dataset involves several key steps aimed at ensuring the collection of high-quality culinary knowledge statements from diverse corpora. The process begins by selecting three types of text sources: web data, scientific papers, and recipes, to ensure broad domain coverage.\n\nHowever, these sources may contain irrelevant or noisy texts. To address this, a series of filters are employed to remove undesired texts. These filters are designed based on various criteria including:\n\n1. **Linguistic Properties**: Texts are analyzed for their linguistic structure to detect and filter out irrelevant content.\n2. **Thesaurus of Words**: Specific culinary-related vocabularies are used to identify and retain relevant texts.\n3. **Semantics of Knowledge Statements**: The meanings and contexts of statements are assessed to ensure they pertain to the culinary domain.\n\nThis approach ensures that the resulting CookingSense dataset is comprehensive, relevant, and useful for culinary knowledge applications.",
        "main_experiment_and_results": "### Main Experiment Setup and Results:\n\n#### Experiment Setup\n\n**Retriever System:**\n- **Algorithm:** Okapi-BM25 (Robertson et al., 2009  ###reference_b44###)\n- **Implementation:** retriv.666 (https://github.com/AmenRa/retriv  ###reference_github.com/AmenRa/retriv###)\n- **Rationale:** BM25 is a robust ranking algorithm based on term and document frequency, frequently used in information retrieval tasks (Trotman et al., 2014  ###reference_b52###). The simplicity of BM25 ensures that any variation in generated text quality can be attributed more to the quality of the knowledge base (KB) than to the retrieval algorithm's performance.\n\n**Language Model:**\n- **Model:** Flan-T5 Large (Chung et al., 2022  ###reference_b8###)\n- **Based on:** T5 (Raffel et al., 2020  ###reference_b42###)\n- **Specialty:** Flan-T5 is fine-tuned with instructional guides to cater to a diverse range of queries without requiring additional fine-tuning for specific benchmarks (Wei et al., 2022a  ###reference_b54###; Ouyang et al., 2022  ###reference_b38###; Sanh et al., 2022  ###reference_b46###).\n\n#### Datasets\n\n**Sources for Retrieval:**\n- **Baseline KBs**: Utilized various existing knowledge bases.\n- **CookingSense KB**: Specifically created culinary knowledge base formulated for this experiment.\n\n#### Evaluation Metrics\n\n**Metrics:**\n- Although the specific metrics used in the evaluation are not detailed in the provided text, common metrics for such experiments typically include:\n  - **Precision/Recall:** To assess the accuracy of the retrieved information.\n  - **BLEU Score:** To measure the quality of the generated text by comparing it to human-generated references.\n  - **ROUGE Score:** To evaluate the recall-oriented aspects of text generation, especially useful in summarization tasks.\n\n#### Main Experimental Results\n\nThe main results gauge the effectiveness of the CookingSense KB by comparing its impact on the generated text against other baseline KBs. Here are the high-level outcomes:\n\n- **Knowledge Enrichment:** The use of CookingSense KB significantly enriched the input context, leading to better text generation outcomes compared to baseline KBs.\n- **Quality of Generated Texts:** The simplicity of the BM25 retrieval algorithm ensured that any improvements in generation were more attributable to the higher quality of the CookingSense KB rather than the retrieval mechanics.\n\nOverall, the findings demonstrate that CookingSense KB offers a robust enrichment to culinary-related inputs, substantiating its effectiveness vis-\u00e0-vis baseline knowledge bases, and thus validating our approach."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To evaluate the effectiveness of CookingSense in improving the performance of retrieval-augmented language models, and to assess the individual contributions of different data sources within CookingSense.",
            "experiment_process": "RAG experiments were conducted using FoodBench, where performance scores were recorded for models integrated with CookingSense. Additionally, performance scores were noted for scenarios where only a specific data source (such as web data, scientific papers, or recipes) was used. Various baseline knowledge bases (KBs) were compared with CookingSense in different evaluation datasets.",
            "result_discussion": "Integrating CookingSense significantly improved performance, even when recent large language models (LLMs) were used. This underscores the importance of using external KBs to enhance model performance. CookingSense outperformed other baseline KBs in most evaluations. In particular, RAG integrated with FooDB performed best for the FORK dataset, likely due to FooDB's alignment with ingredient-related problems. The experimental results suggest CookingSense's potential usefulness for culinary-related tasks and its role in empowering LLMs with specific culinary knowledge for better decision support.",
            "ablation_id": "2405.00523v1.No1"
        },
        {
            "research_objective": "To qualitatively verify the quality and variety of knowledge assertions in CookingSense beyond automated benchmark evaluations.",
            "experiment_process": "A qualitative analysis was conducted on the results from CSQA (Common Sense Question Answering) experiments. Specific question-answer pairs were selected from CSQA and their retrieved context from various sources (web data, recipes, scientific papers) was analyzed.",
            "result_discussion": "The analysis revealed that web data contributes diverse and detailed information, including common sense, cultural perspectives, and authoritative information. Recipes provided empirical culinary insights, such as cooking techniques and examples, while scientific papers offered expert-level knowledge, like substituting ingredients. These findings indicate that CookingSense encompasses a comprehensive array of information from different sources, resulting in a rich and complementary knowledge collection.",
            "ablation_id": "2405.00523v1.No2"
        }
    ]
}