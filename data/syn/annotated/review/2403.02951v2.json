{
    "title": "Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation",
    "abstract": "Large Language Models (LLMs) have emerged as a powerful tool in advancing the Text-to-SQL task,\nsignificantly outperforming traditional methods.\nNevertheless, as a nascent research field, there is still no consensus on the optimal prompt templates and design frameworks.\nAdditionally, existing benchmarks inadequately explore the performance of LLMs across the various sub-tasks of the Text-to-SQL process,\nwhich hinders the assessment of LLMs\u2019 cognitive capabilities and the optimization of LLM-based solutions.\nTo address the aforementioned issues, we firstly construct a new dataset designed to mitigate the risk of overfitting in LLMs.\nThen we formulate five evaluation tasks to comprehensively assess the performance of diverse methods across various LLMs throughout the Text-to-SQL process.\nOur study highlights the performance disparities among LLMs and proposes optimal in-context learning solutions tailored to each task.\nThese findings offer valuable insights for facilitating the development of LLM-based Text-to-SQL systems.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Text-to-SQL, which involves the automatic transformation of natural language (NL) questions into structured SQL statements, is a pivotal component in facilitating seamless user interaction with databases Qin et al. (2022  ###reference_b35###).\nPrevious approaches to this task primarily focus on pattern matching between natural language and SQL statements, utilizing machine learning models to acquire the mapping between the two Zhong et al. (2017  ###reference_b60###); Li et al. (2023a  ###reference_b21###).\nHowever, the introduction and rapid advancement of Large Language Models (LLMs) have brought about a substantial transformation in this field Dong et al. (2023  ###reference_b9###); Pourreza and Rafiei (2024  ###reference_b33###).\nLLMs have emerged as powerful tools Ruan et al. (2023  ###reference_b38###); Kong et al. (2023  ###reference_b18###); Sui et al. (2023  ###reference_b43###), showcasing tremendous potential in comprehending complex NL questions and generating accurate SQL statements.\nBy combining advanced reasoning techniques and in-context learning capabilities, LLMs have significantly pushed the boundaries of the state-of-the-art in this domain, outperforming traditional methods by a considerable margin.\nDespite the continuous improvement of LLM-based methods in various benchmarks such as Spider Yu et al. (2018  ###reference_b56###) and BIRD Li et al. (2024  ###reference_b24###), there remains a critical gap in the systematic benchmarking of these solutions Katsogiannis-Meimarakis and Koutrika (2023  ###reference_b17###); Qin et al. (2022  ###reference_b35###); Kumar et al. (2022  ###reference_b19###).\nThe absence of a comprehensive framework for evaluating LLMs in Text-to-SQL complicates the design and assessment of effective systems.\nThe risk of overfitting, particularly for LLMs trained on coding tasks and open-source datasets, poses a significant challenge to the reliability of benchmark evaluations Roziere et al. (2023  ###reference_b37###).\nAdditionally, the optimal prompt engineering strategies that play a crucial role in guiding LLMs to generate accurate SQL queries are yet to be determined.\nAlthough various design schemes are explored in different methods Gao et al. (2023  ###reference_b13###), there is no consensus on the most effective prompt template.\nFurthermore, the current benchmarks, while comprehensive in their assessment of end-to-end Text-to-SQL tasks, have not yet provided a detailed exploration of the models\u2019 performance across the various sub-tasks and components of the Text-to-SQL process Pourreza and Rafiei (2023  ###reference_b32###); Liu et al. (2023  ###reference_b27###).\nA detailed exploration of these sub-tasks is crucial for a thorough evaluation of LLMs\u2019 cognitive capabilities and their role in facilitating the Text-to-SQL process.\nTherefore, it is necessary to develop a more granular benchmarking approach that can accurately reflect the multifaceted nature of Text-to-SQL and inform the creation of more effective LLM-based solutions.\nTo address the aforementioned challenges and fill the gap in the systematic benchmarking of LLMs in Text-to-SQL, we construct a comprehensive testing benchmark that provides a holistic assessment of LLM capabilities in this domain.\nOur approach begins with the construction of a Text-to-SQL dataset, designed to mitigate the risk of overfitting by considering question complexities, database sizes, and prerequisite knowledge.\nFormally, we devise five distinct tasks\u2014Text-to-SQL, SQL Debugging, SQL Optimization, Schema Linking and SQL-to-Text\u2014to comprehensively evaluate the capabilities of LLMs across the full spectrum of the Text-to-SQL process (see Figure 1  ###reference_###).\nSubsequently, we perform an extensive analysis of various techniques that are essential for improving the in-context learning abilities of LLMs and their precision in generating SQL queries. Specifically, our evaluations are summarized as follows:\nTo determine the optimal prompt template, we partition the prompt text into distinct components and perform thorough testing of LLMs\u2019 performance on end-to-end Text-to-SQL tasks across all possible combination patterns.\nOur benchmarking approach encompasses a range of LLMs, including both general-purpose and coding-specific models with varying parameter sizes. We determine the performance boundaries of these models and identify their performance disparities (see Figure 2  ###reference_###).\nFor each task, we systematically assess the impact of information granularity on model performance and identify the optimal context learning strategies, such as zero-shot and few-shot, to maximize the performance of the models.\n###figure_1###"
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": ""
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "LLM-based Text-to-SQL Methods",
            "text": "With the advancements in LLMs, researchers are increasingly interest in creating a natural language interface for relational databases through the powerful linguistic and coding capabilities of LLMs, forge a new trend of LLM-based Text-to-SQL.\nGiven the powerful zero-shot reasoning and domain generalization abilities of LLMs, these methods successively refresh the record on the cross-domain Spider leaderboard.\nC3 Dong et al. (2023  ###reference_b9###), a zero-shot Text-to-SQL method built upon ChatGPT, provides treatment in terms of model input, bias and output, reaching an 82.3% execution accuracy on Spider leaderboard. DIN-SQL Pourreza and Rafiei (2024  ###reference_b33###) proposes decomposing the Text-to-SQL task into smaller sub-tasks effectively\nand achieves an accuracy of 85.3% on Spider. DAIL-SQL Gao et al. (2023  ###reference_b13###)\nrefreshes the accuracy of Spider with 86.6% through both supervised fine-tuning and a systematic study of in-context learning. It explores how to select the most helpful example and organize them properly in prompts in a few-shot scenario. Similarly, other studies investigate the selection of few-shot demonstrations by synthesising in-domain examples Chang and Fosler-Lussier (2023  ###reference_b3###) and retrieving question skeletons Guo et al. (2023  ###reference_b14###).\nMAC-SQL Wang et al. (2023a  ###reference_b47###) utilizes multi-agent collaboration for Text-to-SQL tasks and reach an accuracy of 59.6% on more challenging BIRD.\nSeveral other studies focus on special yet non-trivial scenarios, aiming to expand the scope of the Text-to-SQL task.\nDBCopilot Wang et al. (2023b  ###reference_b48###) considers a more realistic problem, wherein it deals with large-scale schemas, characterized by massive databases and a large number of tables. It proposes the use of a lightweight seq2seq copilot model for schema-routing, increasing scalability in comparison to traditional schema-linking.\nACT-SQL Zhang et al. (2023b  ###reference_b58###) designs a chain-of-thought (CoT) Wei et al. (2022  ###reference_b49###) prompt to improve the reasoning ability when generating SQLs, and extended to the multi-turn Text-to-SQL task Li et al. (2023b  ###reference_b22###).\nIn summary, these methods primarily focus on improving the performance of the overall Text-to-SQL task through several aspects of the sub-tasks of interest in this paper. However, these methods 1) do not individually and systematically study the performance of sub-tasks, and 2) typically rely on experiments using only OpenAI LLMs (ChatGPT, GPT4, etc.), without verifying the robustness of their approaches when apply to other open-source LLMs.\n###figure_2###"
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "Datasets and Evaluation Metrics",
            "text": "WikiSQL Zhong et al. (2017  ###reference_b60###) is considered the first large-scale dataset enabling the training and evaluation of learning-based Text-to-SQL methods, as well as offering a standardized benchmark for straightforward comparison across various methods.\nIt is also known as a cross-domain dataset, featuring over 25,000 tables and 80,000 question-SQL pairs comprising various domains derived from Wikipedia.\nHowever, the SQL queries in WikiSQL exhibit low complexity.\nSubsequently, most of the recent Text-to-SQL works are done on Spider Yu et al. (2018  ###reference_b56###) because it is widely acknowledged as the most challenging cross-domain benchmark. It comprises 10,181 queries covering 138 different domains, involves multi-table queries (embodied by JOIN), complex SQL clauses (ORDER BY, GROUP BY, and HAVING, etc.) and nested SQLs.\nSeveral variants of Spider have been designed to evaluate the adaptability of Text-to-SQL methods Shaw et al. (2020  ###reference_b40###); Gan et al. (2022  ###reference_b12###).\nSpider-Realistic Deng et al. (2020  ###reference_b6###) removes the explicit mention of column names in the NL questions while keeping the SQL queries unchanged, which is more aligned with the use-case of Text-to-SQL in practice.\nSpider-Syn Gan et al. (2021a  ###reference_b10###) replaces some schema words in the NL question with their synonyms that reflect real-world question paraphrases. Eliminating such explicit correspondence between NL questions and table schemas poses a greater challenge of Text-to-SQL methods.\nSpider-DK Gan et al. (2021b  ###reference_b11###) integrates artificial domain knowledge, aiming to investigate the robustness of text-to-SQL models when the questions require rarely observed domain knowledge.\nGiven that Spider is specifically designed for benchmarking Text-to-SQL methods while diverging from practical scenarios, KaggleDBQA Lee et al. (2021  ###reference_b20###) constructs a small-scale cross-domain dataset from Kaggle, highlighting the diversity of actual web-sourced databases.\nIt comprises knowledge such as documentation and metadata of databases, raising an question of how this extra information could be used to improve the performance.\nThe newest seminal benchmark is BIRD Li et al. (2024  ###reference_b24###), involving 12,751 Text-to-SQL pairs and 95 databases with a size of 33.4 GB. It incorporates the advantages of previous datasets, such as Spider (which is cross-domain with complex SQLs) and KaggleDBQA (which requires the ability to use external knowledge evidence).\nIt is the first to be curated for evaluating SQL execution efficiency in large-scale databases, thereby further bridging the gap between academic setups and real-world applications.\nIn this paper, we construct a novel dataset built upon BIRD and use it in the evaluation (see Section 3.3  ###reference_###).\nTwo primary evaluation metrics for assessing the accuracy of SQLs on Spider are Exact Matching(EM) and Execution Accuracy(EX). EM measures whether the predicted query as a whole is equivalent to the gold query. It is possible to encounter false negative evaluations since a question might be solvable by multiple syntactically different but semantically identical SQL statements. EX is a more widely used metric, measures whether the result of executing the predicted query matches the gold value. We use EX to evaluate the accuracy of SQLs in this paper.\nAdditionally, BIRD further proposes Valid Efficiency Score (VES), an integrated metric assessing both accuracy of execution results (i.e., EX) and the execution efficiency of SQL queries. To increase the VES, methods are required to enhance both execution accuracy and efficiency of SQL queries. We use this metric to assess the SQL optimization in Section 4.3  ###reference_###. Refer to Appendix C.1  ###reference_### for detailed definitions of evaluation metrics."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Settings",
            "text": ""
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Task Formulation",
            "text": "In an LLM-based Text-to-SQL system, LLMs are employed to facilitate the transformation of natural language questions into executable SQL queries. Specifically, Let  be a natural language question and  be the database schema.  is defined by a tuple , where  represents multiple tables,  represents columns, and  represents foreign key relationships. The goal is to produce a SQL query  such that  is executable and accurately represents the intent of .\nGiven the prompt template , the generation process of the SQL query  by an LLM  can be formally defined as a conditional probability distribution:\nHere, LLM autoregressively generates each token,  denotes the -th token of the SQL query , and  denotes the length of the query ."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Evaluation Models",
            "text": "Our benchmarking study evaluates the performance of two distinct categories of LLMs with varying parameter sizes: general-purpose and coding-specific. General-purpose LLMs are designed for versatile text generation and comprehension across diverse domains, trained on extensive internet text datasets. Specifically, ChatGPT (gpt-35-turbo-16k) 111https://chat.openai.com, LLaMa2-Chat-70B Touvron et al. (2023  ###reference_b44###), InternLM-70B 222https://internlm.intern-ai.org.cnand InternLM2-20B are selected as the main baseline models. Coding-specific LLMs are fine-tuned and optimized for programming scenarios, excelling in code generation and technical language understanding. In this paper, the performance analysis of Codellama-34B Roziere et al. (2023  ###reference_b37###) and SQLCoder-34B 333https://github.com/defog-ai/sqlcoder are provided."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Dataset Construction",
            "text": "We conduct a preliminary assessment of the performance of various LLMs on multiple open-source datasets. As depicted in Table 1  ###reference_###, the performance of LLMs varies inconsistently across different datasets. Specifically, on the Spider dataset, Codellama-34B outperforms InternLM-70B and SQLCoder-34B, while on the Bird dataset, SQLCoder-34B surpasses InternLM-70B and Codellama-34B.\nOn the one hand, there may be differences in the problem types that different LLMs excel at handling. On the other hand, considering that LLMs learn and train from large corpora, these findings suggest that the performance discrepancies observed could be attributed to the potential utilization of open source datasets during the fine-tuning process for coding-specific LLMs. This poses challenges in ensuring the reliability of evaluation results obtained on these datasets.\nTo address the potential overfitting of LLMs, particularly those specialized in coding tasks, and to ensure a reliable and accurate assessment of their capabilities, we construct a novel dataset, termed \u201cBigTable-0.2k\u201d. This dataset is an extension and augmentation of the BIRD dataset, which is a recently released and widely acknowledged benchmark for evaluating Text-to-SQL parsing.\n###table_1### Specifically, our construction process involves a systematic analysis of the original BIRD dataset, identifying queries of varying difficulty levels and involving different numbers of tables (1, 2, 3, and more than 3). We modify and expand these queries by altering table and column names, as well as filtering conditions, to create a more diverse set of challenges. In cases where the original dataset lacks sufficient examples with four or more tables (there are only 20 instances in BIRD-Dev dataset), queries that involved three tables are expanded to four. As shown in Table 2  ###reference_###, this process generates 50 new instances for each category, resulting in the \u201cBigTable-0.2k\u201d dataset. Moreover, each item in the dataset underwent mutual verification by at least two individuals to ensure the accuracy.\nAlthough the prevalence of queries involving more than three tables may not align with common real-world applications,\nthis approach allows for a more nuanced evaluation of LLMs\u2019 cognitive abilities across a spectrum of sub-tasks.\nAdditionally, the \u201cBigTable-0.2k\u201d dataset retains the original BIRD dataset\u2019s attributes, such as its large-scale and complexity, diversity of data sources, cross-domain applicability, and the requirement for external knowledge reasoning. Moreover, we standardize the dataset format to align with other benchmarks, by combining user NL questions  with external knowledge  to form new, contextually rich questions."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Evaluation",
            "text": "In this section, we formally evaluate the different sub-tasks within the Text-to-SQL process to determine the performance differences among various LLMs and provide recommendations for addressing specific task requirements."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Text2SQL",
            "text": ""
        },
        {
            "section_id": "4.1.1",
            "parent_section_id": "4.1",
            "section_name": "4.1.1 Zero-shot Prompting Optimization.",
            "text": "Unlike previous learning-based studies, the primary challenge in LLM-based Text-to-SQL is the design of an effective prompt template  (as introduced in Section 3.1  ###reference_###) for LLMs to generate accurate SQL queries, known as prompt engineering. Researchers have evaluated a variety of prompt templates Gao et al. (2023  ###reference_b13###). However, these representations lack uniformity in their structure, making it difficult to find out how a specific feature within a prompt template impact performance.\nTo address this issue, we investigate a more unified series of prompt templates. As shown in Listing LABEL:lst:DDL/SimpleDDL_prefix- LABEL:lst:Complete/Chat_postfix, these templates differ across three features:\nDDL/SimpleDDL prefix affects the representation of the database schema .\n\u201cDDL\u201d (Data Definition Language) encompasses the standardized language that includes commands for defining the structure and properties of a database, providing detailed information necessary for database creation, including column types and primary/foreign keys.\n\u201cSimpleDDL\u201d is simplified by only supplying table and column names.\nMD/HTML/Coding infix wraps the entire prompt template with Markdown syntax, HTML snippets and code comment blocks.\nComplete/Chat postfix indicates the task of either completing SQL statements based on the \"SELECT\" clause or directly answering questions.\nThese features are combined to form a complete prompt template , and more details of these representations can be found in Appendix A.1  ###reference_###.\nWe test these templates on Spider dev set. As shown in Table 3  ###reference_###, \u201cSimpleDDL-MD-Chat\u201d (see Listing LABEL:lst:SimpleDDL-MD-Chat) consistently outperforms all other prompts when applied to all 5 backbone LLMs.\nTo this end, we consistently utilize the prompt template \u201cSimpleDDL-MD-Chat\u201d throughout the subsequent evaluations in this paper.\nThe prompt template \u201cSimpleDDL-MD-Chat\u201d achieves optimal performance in the Text-to-SQL task."
        },
        {
            "section_id": "4.1.2",
            "parent_section_id": "4.1",
            "section_name": "4.1.2 End-to-End Text2SQL evaluation.",
            "text": "This research conducts an end-to-end evaluation of the Text-to-SQL capabilities of various LLMs using the \"SimpleDDL-MD-Chat\" prompt template on the \"BigTable-0.2k\" dataset, with results depicted in Table 4  ###reference_###.\nComparison of Performance Across Different Models. The results demonstrate a clear performance hierarchy among the models, with SQLCoder, CodeLlama, InternLM, and InternLM2 consistently outperforming Llama2-Chat. This finding highlights the effectiveness of coding-specific models, such as SQLCoder and CodeLlama, in the Text-to-SQL domain. Additionally, certain general-purpose models, like InternLM and InternLM2, can achieve performance levels comparable to specialized models, even without fine-tuning for coding tasks.\nDifficulty Comparison Across Different Numbers of GT Tables.\nWe examine the query difficulty based on the number of GT tables involved. The results reveal a decrease in EX as the number of GT tables increases. Notably, the EX for models on queries with two GT tables is unexpectedly lower compared to those with three or more GT tables. This observation can be attributed to the fact that queries involving two GT tables have the highest average number of columns (see Table 2  ###reference_###).\nAs the number of tables and columns involved in user queries increases, the Text-to-SQL challenge for LLMs significantly escalates.\n###figure_3###"
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "SQL Debugging",
            "text": "In recent studies, researchers have demonstrated that LLMs possess self-reflection and self-correction capabilities similar to those of humans Yao et al. (2022  ###reference_b53###); Shinn et al. (2023  ###reference_b41###); Zhang et al. (2023a  ###reference_b57###).\nAdditionally, previous studies also investigate the potential of LLMs to debug the code they generate Chen et al. (2023  ###reference_b4###); Pourreza and Rafiei (2024  ###reference_b33###). In this section, we provide a comprehensive analysis of the performance of numerous SQL debugging methods across LLMs."
        },
        {
            "section_id": "4.2.1",
            "parent_section_id": "4.2",
            "section_name": "4.2.1 Debugging Dataset",
            "text": "We collect incorrect SQL queries generated by various LLMs in Section 4.1.2  ###reference_.SSS2### and visualize the distribution of their error information, as shown in Figure 3  ###reference_###.\nThe error information can be divided into two categories:\nSystem Error refers to syntax errors in the SQL statement, and the detailed system error information is generated by the Database Management System (DBMS), e.g., \u201csyntax error\u201d and \u201cno such column\u201d.\nResult Error indicates that the syntax of the SQL statement is correct, but the execution result does not match the ground truth.\nThe word cloud distribution reveals that \u201cno such column\u201d and Result Error are the primary areas of error concentration for all models. Additionally, more advanced models exhibit a greater proportion of the Result Error. This aligns with expectations, as powerful models are less prone to low-level System Errors.\nHowever, the concise nature of the error information in the Result Error category significantly hampers the debugging performance. Therefore, we propose a further detailed classification method.\nSpecifically, in addressing the Result Error category, we categorize these errors based on the logical construction of SQL statements. This classification is prioritized according to the logical structure within the SQL query. It is delineated in order into the following five subcategories:\nTable Query Error pertains to issues related to the selection of tables in the SQL query. It is further subdivided into three types: Excessive/Missing/Incorrect Tables, which respectively address scenarios where unnecessary tables are included, required tables are omitted, or the wrong tables are referenced.\nColumn Selection Error focuses on the appropriateness of column selection. Similar to the Table Query Error, it is broken down into Excessive/Missing/Incorrect Columns.\nJoin Columns Error examines the errors associated with JOIN operations.\nCondition Filter Error encompasses errors that occur in the conditions used to filter the data, including incorrect comparisons or misapplied filters.\nData Processing Error pertains to errors in the data processing stage, which includes aggregations, calculations, etc. applied to the data within the SQL query.\nDuring the categorization process, we employ rules to determine the first three error types and utilize LLMs to perform binary classification for the last two error types (see Appendix A.2  ###reference_###). The distribution of different subcategories within Result Error is shown in the bottom section of Figure 3  ###reference_###.\n###figure_4### ###figure_5###"
        },
        {
            "section_id": "4.2.2",
            "parent_section_id": "4.2",
            "section_name": "4.2.2 Debug Evaluation",
            "text": "To assess the impact of different levels of information granularity on performance, we propose 5 distinct strategies for self-debugging, progressively incorporating more detailed information:\nRegenerate. Simply regenerate the SQL query with the same prompt in Section 4.1  ###reference_###. This setting acts as a baseline to eliminate the impact of model randomness.\nw/ Wrong SQL. Let LLMs generate a new SQL query based on the wrong SQL statement.\nw/ Wrong SQL + System_error_info. Provide the wrong SQL statement, the corresponding System Error information and the rough Result Error information.\nw/ Wrong SQL + All_error_info. Add detailed Result Error information for those SQL queries that are syntactically correct but semantically wrong.\nw/ Wrong SQL + All_error_info + Comment. Add manual annotations for all error information. See Appendix A.2  ###reference_### for a detailed prompt template.\nWhat is the most powerful information organization of self debug?\nAs shown in Figure 4  ###reference_###, it is evident that the self-debugging performance of LLMs exhibits an upward trend with the introduction of more granular error information.\nIn the absence of additional information, LLM does not possess the capability to regenerate correct answers. However, all models are able to comprehend fine-grained error information, whether it includes comments or not, and rectify their own mistakes.\nDetailed error information and corresponding annotations greatly enhance the capabilities of LLMs, enabling them to effectively correct errors.\nCan LLMs benefit from multi-round self debug? As shown in Figure 5  ###reference_###, substantial improvements in EX are achieved in the initial rounds of debugging, yet the performance gain become marginal later. This indicates that conducting 1-2 debugging rounds might strikes a favorable balance between performance improvement and economic efficiency. In addition, we analyze the distribution of detailed error types during the multi-round self-debugging process. As the debugging rounds advance, we observe a reduction in System Error and a slight rise in Result Error. This suggests that although syntax errors are fixed, the regenerated SQL statements may still have semantic errors. With each round of debugging, the generated statements tend to transition from System Error to Result Error before eventually converging towards correct SQL statements.\nMulti-round self-debugging aids in error correction for LLMs, but there exists a performance boundary, with 1-2 rounds of debugging being the optimal choice.\nCan an LLM debug the error incurred by other LLMs (general debugging)?\nAs depicted in Table 5  ###reference_###, we select two representative LLMs, SQLCoder and InternLM, to assess their general debugging capabilities.\nWhen debugging erroneous SQL statements generated by other LLMs, additional error information can potentially impair the performance.\nConversely, the most naive approach of simply regenerating the SQL statements often yields the best results. This highlights the differences between different LLMs.\nThe debugger LLMs may not encounter errors caused by other LLMs, and these error type informations might confuse them. Consequently, it is unlikely to achieve performance improvement through general debugging. However, the integration of results generated by different LLMs holds promise as a future research direction.\nThe performance of cross-LLM SQL debugging is inferior to the direct regeneration. A multi-agent approach that integrates outputs from different models shows great potential."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "SQL Optimization",
            "text": "Execution efficiency of SQL queries is a critical aspect, particularly in real-time systems that utilize large-scale databases.\nIn this section, we further explore whether LLMs are able to enhance the execution efficiency of correct SQL queries.\nFormally, the SQL optimization process Pirahesh et al. (1992  ###reference_b31###) involves transforming the initial SQL queries  into an optimized form, denoted as , with the goal of improving efficiency while maintaining identical results:\nwhere  and  are the\ncorresponding prompt template and the additional information used for SQL optimization,  represents the mapping function of the LLM .\nVES is commonly employed to evaluate the efficiency of SQL query execution. However, in practice, LLMs can sometimes rewrite a correct SQL query into an incorrect one, making it challenging to figure out if the main reason for the decline in VES is due to these incorrect rewrites or a decrease in the SQL execution efficiency.\nTo this end, we suggest adopting a complementary metric C-VES (Correct-VES):\nHere,  represent the set of accurate SQLs (see Appendix C.1  ###reference_### for detailed notations). C-VES is designed exclusively to validate the capability of LLMs to generate more efficient SQL queries, regardless of the potential drawback of rewriting correct SQLs into erroneous ones.\nDo LLMs have the capability for SQL self-optimization?\nTo the best of our knowledge, we are the first to consider utilizing LLMs for SQL optimization.\nSpecifically, we devise an extensive suite of prompts  curated to SQL optimization:\nwith : In this basic form, only original SQL statements are provided.\nw/ : Further incorporates the database schema  and the user question .\nw/ demo: Introduce few-shot demonstrations without explanations. Demonstrations are intuitively designed, incorporating common optimization rules, such as substituting \u201cCOUNT(*)\u201d with \u201cCOUNT(<column_name>)\u201d.\nw/ demo + comments: Add an explanation for the few-shot demonstrations. See Appendix A.3  ###reference_### for a detailed prompt template.\nSimpleDDL-MD-Chat-Efficiency: To avoid the accumulation of errors caused by multiple generations, this prompt template require LLMs to directly generate the most efficient SQL query statement based on user query.\nThe effectiveness of these SQL optimization methods are demonstrated in Table 6  ###reference_###.\nAlmost all two-stage methods experience a significant decrease in VES.\nIt can be attributed to the possibility of LLMs optimizing the correct SQL statements into incorrect ones, thereby resulting in a further decrease in accuracy. Even when considering only the correct results, the performance improvement in terms of execution efficiency brought by the optimized SQL statements is almost negligible.\nFurthermore, it is intriguing to note that directly instructing the LLM to generate efficient SQL statements appears to achieve improved accuracy. This suggests that placing higher demands on the LLM could yield surprisingly positive outcomes.\nIn-context learning methods present challenges in achieving effective SQL optimization with LLMs."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "SQL-to-Text",
            "text": "The goal of SQL-to-Text is to transform the SQL query back into its original natural language question Xu et al. (2018  ###reference_b51###); Ma et al. (2021  ###reference_b30###); Shu et al. (2021  ###reference_b42###).\nWhile it seems that SQL-to-Text cannot serve as a sub-task within the Text-to-SQL pipeline to improve the performance of End-to-End Text-to-SQL systems, employing this conversion as a supplementary step within the pipeline can indeed provide valuable insights. By converting the generated SQL statements back into text and juxtaposing these with the semantics of the original user questions, we can assess the accuracy of the SQL statements produced.\nIn addition, it can assist researchers in evaluating the semantic comprehension capabilities of different LLMs, thus facilitating the development of more effective Text-to-SQL methodologies.\nTo this end, we assess the performance of SQL-to-Text across different LLMs (See Appendix A.4  ###reference_### for prompt templates).\nThe selected metrics for evaluation encompass the F1 values of Rouge-1/2/L and BertScore, along with the application of LLM to assess the semantic coherence between the two texts.\nThe evaluation results are depicted in Table 7  ###reference_###. ChatGPT and InternLM2 demonstrate the highest performance, followed by InternLM, while Codellama and SQLCoder exhibit comparatively lower performance. This highlights that even in regards to semantic description of code, general-purpose models exhibit significantly stronger descriptive capabilities compared to coding-specific models.\nUtilizing a general-purpose model for semantic description of SQL statements is a better choice."
        },
        {
            "section_id": "4.5",
            "parent_section_id": "4",
            "section_name": "Schema Linking",
            "text": "Schema linking is recognized as a crucial prerequisite of generating correct SQL queries.\nIt involves aligning entity references in the question with the corresponding schema tables or columns, requiring the model to understand both structure and value of the database, as well as the the semantics of user questions.\nIn LLM-based Text-to-SQL, prior studies Dong et al. (2023  ###reference_b9###); Pourreza and Rafiei (2024  ###reference_b33###) design prompt instructions with in-context learning examples to enable LLMs to retrieve linked tables and columns, which are then used for the downstream Text-to-SQL task.\nHowever, none of these methods individually evaluate the performance of schema linking, and explicit evaluation metrics have yet to be established.\nMoreover, despite considerable advancements in semantic comprehension and generalization brought by LLMs, the performance of schema linking is still far from promising.\nIn this section, we aim to bridge these gaps by: (1) introducing a elaborately designed metrics to assess schema linking methods, (2) presenting a novel schema linking method \u201cPreSQL\u201d, which demonstrates superior performance, (3) conducting a comprehensive evaluation of a range of schema linking methods across various LLMs."
        },
        {
            "section_id": "4.5.1",
            "parent_section_id": "4.5",
            "section_name": "4.5.1 Evaluation Metric for Schema Linking: RES",
            "text": "What schema linking method is considered good? A straightforward goal of schema linking is that the GT tables should be retrieved as much as possible.\nHowever, due to the ambiguity inherent in natural language and the potential semantic similarities between candidate tables, retrieving more GT tables typically comes at the cost of a higher redundancy, known as the precision-recall trade-off.\nAs discussed in Pourreza and Rafiei (2024  ###reference_b33###), excessive table retrieval can introduce redundant joins between tables, potentially impairing the EX of Text-to-SQL generation.\nTherefore, the objective of schema linking is to retrieve all GT tables while avoiding the retrieval of excessive tables (with minimal redundancy).\nTo evaluate this, we design a comprehensive metric called Retrieval Efficiency Score (RES), defined as:\nwhere  and  denote the set of GT tables and retrieved tables for the -th instance, respectively,  refers to the scale of a set.\nWe emphasize that the RES serves as a more appropriate metric for evaluating schema linking than the F1-score. This is because it aligns the principle that recalling all GT tables is more important than increasing the precision of retrieval, as the former constitutes a prerequisite for generating correct SQL queries."
        },
        {
            "section_id": "4.5.2",
            "parent_section_id": "4.5",
            "section_name": "4.5.2 Schema Linking Evaluation",
            "text": "The methods we evaluated are as follows (see Appendix A.5  ###reference_### for the full prompt of these methods):\nZero Shot: A schema linking prompt proposed in C3 Dong et al. (2023  ###reference_b9###), which instructs the LLM to rank all the tables from relevant to irrelevant in a zero-shot manner.\nFew Shot: Instructing the LLM to retrieve only the most important tables with few-shot demonstration, presented in DIN-SQL Pourreza and Rafiei (2024  ###reference_b33###).\nPreSQL: First, we employ the zero-shot Text-to-SQL described in Section 4.1  ###reference_### to generate a preliminary SQL query. From this preliminary SQL, table and column entities are parsed to serve as the retrieval results for schema linking.\nFew Shot + PreSQL: This approach takes the union of the retrieval results from both the Few Shot and PreSQL methods, aiming to leverage the strengths of each.\nNote that we organize the information of the database schema in a way similar to \"SimpleDDL-\" in the prompt of all the methods mentioned above, which ignores the information about foreign keys.\nHowever, as argued in Wang et al. (2019  ###reference_b46###), foreign keys embody features of known schema relations and provide importance clues for understanding the database structure.\nTo this end, we conduct experiments under both settings, w/ and w/o foreign keys, to investigate how incorporating foreign keys in the prompt influences the performance of schema linking. Results are demonstrated in Table 8  ###reference_### (refer to Appendix B  ###reference_### for results on detailed metrics like Exact Match & Subset Match).\nWhich method achieved the best performance in schema linking?\nIt can be seen that code-specific models excel in performance when utilizing the PreSQL approach, whereas general-purpose models yield optimal results through the Few-Shot + PreSQL method. This aligns with our expectations, as these two types of models excel in coding tasks (see Section 4.1  ###reference_###) and semantic understanding tasks (see Section 4.4  ###reference_###), respectively.\nCan foreign key information facilitate schema linking?\nThe introduction of foreign key information yield improved performance across all methods and all LLMs. This is evident since a valid JOIN operation in SQL queries is typically based on foreign keys. The foreign key information helps the model retrieve more ground truth tables by indicating all potential table pairs involved in a JOIN operation.\nForeign key information is capable of advance the performance of schema linking. PreSQL yields the highest performance on coding-specific models, and integrating the results from Few Shot can further enhance performance on general-purpose models."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this study, we conduct a systematic benchmarking of the various sub-tasks within the Text-to-SQL pipeline, encompassing Text-to-SQL, SQL-Debugging, SQL-Optimization, SQL-to-Text, and Schema-Linking.\nOur comprehensive evaluation involves six distinct LLMs, spanning both general-purpose and coding-specific models.\nWe focus on determining the optimal prompt templates for each task, assessing performance variations among different approaches, and identifying the distinct capabilities and limitations of each LLM.\nThe results of the study demonstrate notable performance variations across the LLMs, underscoring the significance of careful model selection and prompt engineering in attaining optimal outcomes in text-to-SQL tasks.\nOur benchmarking provides a meticulous perspective on the pipeline, equipping the research community with strategies to improve the semantic understanding and computational performance of LLMs. This advancement contributes to the development of more reliable Text-to-SQL systems."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Prompt Template",
            "text": ""
        },
        {
            "section_id": "Appendix 2",
            "parent_section_id": null,
            "section_name": "Appendix B Supplemental Evaluation Results",
            "text": ""
        },
        {
            "section_id": "Appendix 3",
            "parent_section_id": null,
            "section_name": "Appendix C Details for Sub-tasks",
            "text": ""
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T1\">\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:70%;\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>EX (%) of different LLMs on open source datasets.</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T1.3\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T1.3.1.1\">\n<td class=\"ltx_td ltx_border_tt\" id=\"S3.T1.3.1.1.1\"></td>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.3.1.1.2\"><span class=\"ltx_text\" id=\"S3.T1.3.1.1.2.1\" style=\"font-size:70%;color:#333333;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.3.1.1.2.1.1\">SQLCoder-34B</span></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.3.1.1.3\"><span class=\"ltx_text\" id=\"S3.T1.3.1.1.3.1\" style=\"font-size:70%;color:#333333;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.3.1.1.3.1.1\">InternLM-70B</span></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.3.1.1.4\"><span class=\"ltx_text\" id=\"S3.T1.3.1.1.4.1\" style=\"font-size:70%;color:#333333;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.3.1.1.4.1.1\">Codellama-34B</span></span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.3.1.1.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.3.1.1.5.1\" style=\"font-size:70%;\">LLama2-Chat-70B</span><span class=\"ltx_text\" id=\"S3.T1.3.1.1.5.2\" style=\"font-size:70%;\"></span>\n</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.3.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T1.3.2.2.1\"><span class=\"ltx_text\" id=\"S3.T1.3.2.2.1.1\" style=\"font-size:70%;color:#333333;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.3.2.2.1.1.1\">Spider Dev</span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.3.2.2.2\"><span class=\"ltx_text\" id=\"S3.T1.3.2.2.2.1\" style=\"font-size:70%;\">65.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.3.2.2.3\"><span class=\"ltx_text\" id=\"S3.T1.3.2.2.3.1\" style=\"font-size:70%;\">67.40</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.3.2.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.3.2.2.4.1\" style=\"font-size:70%;\">71.60</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.3.2.2.5\"><span class=\"ltx_text\" id=\"S3.T1.3.2.2.5.1\" style=\"font-size:70%;\">54.70</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.3.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S3.T1.3.3.3.1\"><span class=\"ltx_text\" id=\"S3.T1.3.3.3.1.1\" style=\"font-size:70%;color:#333333;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.3.3.3.1.1.1\">BIRD Dev</span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.3.3.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.3.3.3.2.1\" style=\"font-size:70%;\">32.07</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.3.3.3.3\"><span class=\"ltx_text\" id=\"S3.T1.3.3.3.3.1\" style=\"font-size:70%;\">29.60</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.3.3.3.4\"><span class=\"ltx_text\" id=\"S3.T1.3.3.3.4.1\" style=\"font-size:70%;\">28.29</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.3.3.3.5\"><span class=\"ltx_text\" id=\"S3.T1.3.3.3.5.1\" style=\"font-size:70%;\">20.60</span></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 1: EX (%) of different LLMs on open source datasets."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T2\">\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:70%;\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>The data distribution of \u201cBigTable-0.2k\u201d includes the average number of ground truth (GT) tables and columns involved in the instances.</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S3.T2.3\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T2.3.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.3.1.1.1\"><span class=\"ltx_text\" id=\"S3.T2.3.1.1.1.1\" style=\"font-size:70%;color:#333333;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.3.1.1.1.1.1\">No. of GT Tables</span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.3.1.1.2\"><span class=\"ltx_text\" id=\"S3.T2.3.1.1.2.1\" style=\"font-size:70%;color:#333333;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.3.1.1.2.1.1\">No. of Instances</span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T2.3.1.1.3\"><span class=\"ltx_text\" id=\"S3.T2.3.1.1.3.1\" style=\"font-size:70%;color:#333333;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.3.1.1.3.1.1\">Avg. No. of Columns</span></span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.3.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.3.2.2.1\"><span class=\"ltx_text\" id=\"S3.T2.3.2.2.1.1\" style=\"font-size:70%;color:#333333;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.3.2.2.1.1.1\">1</span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.3.2.2.2\"><span class=\"ltx_text\" id=\"S3.T2.3.2.2.2.1\" style=\"font-size:70%;\">50</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.3.2.2.3\"><span class=\"ltx_text\" id=\"S3.T2.3.2.2.3.1\" style=\"font-size:70%;\">23.30</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.3.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.3.3.3.1\"><span class=\"ltx_text\" id=\"S3.T2.3.3.3.1.1\" style=\"font-size:70%;color:#333333;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.3.3.3.1.1.1\">2</span></span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.3.3.3.2\"><span class=\"ltx_text\" id=\"S3.T2.3.3.3.2.1\" style=\"font-size:70%;\">50</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.3.3.3.3\"><span class=\"ltx_text\" id=\"S3.T2.3.3.3.3.1\" style=\"font-size:70%;\">56.94</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.3.4.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.3.4.4.1\"><span class=\"ltx_text\" id=\"S3.T2.3.4.4.1.1\" style=\"font-size:70%;color:#333333;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.3.4.4.1.1.1\">3</span></span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.3.4.4.2\"><span class=\"ltx_text\" id=\"S3.T2.3.4.4.2.1\" style=\"font-size:70%;\">50</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.3.4.4.3\"><span class=\"ltx_text\" id=\"S3.T2.3.4.4.3.1\" style=\"font-size:70%;\">31.73</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.3.5.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T2.3.5.5.1\"><span class=\"ltx_text\" id=\"S3.T2.3.5.5.1.1\" style=\"font-size:70%;color:#333333;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.3.5.5.1.1.1\">&gt;3</span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T2.3.5.5.2\"><span class=\"ltx_text\" id=\"S3.T2.3.5.5.2.1\" style=\"font-size:70%;\">50</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T2.3.5.5.3\"><span class=\"ltx_text\" id=\"S3.T2.3.5.5.3.1\" style=\"font-size:70%;\">29.04</span></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 2: The data distribution of \u201cBigTable-0.2k\u201d includes the average number of ground truth (GT) tables and columns involved in the instances."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T3\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>EX (%) of 8 zero-shot prompt templates on Spider dev set.</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T3.1\" style=\"width:433.6pt;height:180.3pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(22.0pt,-9.1pt) scale(1.11287410813626,1.11287410813626) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T3.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.1.1\">prompt template</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.2.1\">SQLCoder-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.3.1\">Codellama-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.4.1\">InternLM-70B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.5.1\">Llama2-Chat-70B</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.1.1.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.2.1.1.1\">DDL-HTML-Chat</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.1.2\">57.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.1.3\">63.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.2.1.4.1\">65.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.1.5\">49.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.1.1.3.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.3.2.1.1\">DDL-HTML-Complete</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.3.2.2\">61.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.3.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.3.2.3.1\">65.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.3.2.4\">53.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.3.2.5\">50.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.1.1.4.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.4.3.1.1\">DDL-MD-Chat</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.4.3.2\">63.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.4.3.3.1\">68.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.4.3.4\">66.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.4.3.5\">48.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.1.1.5.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.5.4.1.1\">DDL-MD-Complete</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.5.4.2\">62.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.5.4.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.5.4.3.1\">69.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.5.4.4\">64.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.5.4.5\">46.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.1.1.6.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.6.5.1.1\">DDL-Coding-Chat</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.6.5.2\">60.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.6.5.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.6.5.3.1\">67.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.6.5.4\">66.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.6.5.5\">48.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.1.1.7.6.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.7.6.1.1\">DDL-Coding-Complete</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.7.6.2\">59.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.7.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.7.6.3.1\">66.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.7.6.4\">62.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.7.6.5\">53.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.1.1.8.7.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.8.7.1.1\">SimpleDDL-MD-Chat</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.8.7.2\" style=\"background-color:#EAF6F6;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.8.7.2.1\" style=\"background-color:#EAF6F6;\">65.0</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.8.7.3\" style=\"background-color:#EAF6F6;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.8.7.3.1\" style=\"background-color:#EAF6F6;\">71.6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.8.7.4\" style=\"background-color:#EAF6F6;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.8.7.4.1\" style=\"background-color:#EAF6F6;\">67.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.8.7.5\" style=\"background-color:#EAF6F6;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.8.7.5.1\" style=\"background-color:#EAF6F6;\">54.7</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T3.1.1.9.8.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.9.8.1.1\">SimpleDDL-MD-Complete</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.1.1.9.8.2\">63.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.1.1.9.8.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.9.8.3.1\">66.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.1.1.9.8.4\">61.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.1.1.9.8.5\">50.2</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 3: EX (%) of 8 zero-shot prompt templates on Spider dev set."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T4\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>EX (%) of different LLMs on \u201cBigTable-0.2k\u201d. Prompt template is \u201cSimpleDDL-MD-Chat\".</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T4.1\" style=\"width:433.6pt;height:101.6pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-13.7pt,3.2pt) scale(0.940378713809474,0.940378713809474) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T4.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.1.1.1.1\">No. of GT Tables</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.1.1.2.1\">ChatGPT</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.1.1.3.1\">SQLCoder-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.1.1.4.1\">Codellama-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.1.1.5.1\">InternLM-70B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.1.1.6.1\">Llama2-Chat-70B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.1.1.7.1\">InternLM2-20B</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.1.1.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.2.1.1.1\">1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.2.1.2.1\">60.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.1.3\">44.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.1.4\">32.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.1.5\">44.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.1.6\">22.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.1.7\">40.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T4.1.1.3.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.3.2.1.1\">2</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.3.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.3.2.2.1\">20.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.3.2.3\">8.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.3.2.4\">10.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.3.2.5\">10.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.3.2.6\">10.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.3.2.7\">6.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T4.1.1.4.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.4.3.1.1\">3</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.4.3.2.1\">38.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.3.3\">24.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.3.4\">22.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.3.5\">20.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.3.6\">8.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.4.3.7\">18.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T4.1.1.5.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.5.4.1.1\">&gt;3</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.5.4.2.1\">30.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.4.3\">20.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.4.4\">12.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.4.5\">10.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.4.6\">8.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.5.4.7\">20.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T4.1.1.6.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.6.5.1.1\">Total</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.1.1.6.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.6.5.2.1\">37.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.1.1.6.5.3\">24.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.1.1.6.5.4\">19.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.1.1.6.5.5\">21.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.1.1.6.5.6\">12.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.1.1.6.5.7\">21.00</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 4: EX (%) of different LLMs on \u201cBigTable-0.2k\u201d. Prompt template is \u201cSimpleDDL-MD-Chat\"."
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T5\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>EX (%) results of general debug. Each column demonstrates the debugging results of SQLCoder or InternLM for the wrong SQL statements generated by the corresponding model.</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T5.1\" style=\"width:433.6pt;height:193.9pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-4.6pt,2.0pt) scale(0.979438212308094,0.979438212308094) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T5.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T5.1.1.1.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.1.1.1\">Dataset </span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.1.2.1\">SQLCoder-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.1.3.1\">Codellama-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.1.4.1\">InternLM-70B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.1.5.1\">Llama2-Chat-70B</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.2.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" colspan=\"5\" id=\"S4.T5.1.1.2.1.1\" style=\"background-color:#E6E6E6;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.2.1.1.1\" style=\"background-color:#E6E6E6;\">SQLCoder Debugs All Errors<span class=\"ltx_text ltx_font_medium\" id=\"S4.T5.1.1.2.1.1.1.1\"></span></span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T5.1.1.3.1.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.3.1.1.1\">Regenerate</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.3.1.2\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.3.1.2.1\" style=\"background-color:#ECF4FF;\">0.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.3.1.3\">12.42</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.3.1.4\">13.21</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.3.1.5\">18.75</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T5.1.1.4.2.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.4.2.1.1\">w/ Wrong SQL</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.4.2.2\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.4.2.2.1\" style=\"background-color:#ECF4FF;\">0.66</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.4.2.3\">2.48</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.4.2.4\">6.92</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.4.2.5\">7.95</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T5.1.1.5.3.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.5.3.1.1\">w/ Wrong SQL + System_error_info</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.5.3.2\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.5.3.2.1\" style=\"background-color:#ECF4FF;\">4.64</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.5.3.3\">11.18</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.5.3.4\">9.43</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.5.3.5\">11.36</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T5.1.1.6.4.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.6.4.1.1\">w/ Wrong SQL + All_error_info</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.6.4.2\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.6.4.2.1\" style=\"background-color:#ECF4FF;\">4.64</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.6.4.3\">11.80</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.6.4.4\">8.81</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.6.4.5\">10.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.7.5\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" colspan=\"5\" id=\"S4.T5.1.1.7.5.1\" style=\"background-color:#E6E6E6;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.7.5.1.1\" style=\"background-color:#E6E6E6;\">InternLM Debugs All Errors<span class=\"ltx_text ltx_font_medium\" id=\"S4.T5.1.1.7.5.1.1.1\"></span></span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.8.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T5.1.1.8.6.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.8.6.1.1\">Regenerate</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.8.6.2\">9.27</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.8.6.3\">11.80</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.8.6.4\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.8.6.4.1\" style=\"background-color:#ECF4FF;\">0.63</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.8.6.5\">15.34</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.9.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T5.1.1.9.7.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.9.7.1.1\">w/ Wrong SQL</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.9.7.2\">7.95</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.9.7.3\">10.56</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.9.7.4\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.9.7.4.1\" style=\"background-color:#ECF4FF;\">5.66</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.9.7.5\">9.66</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.10.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T5.1.1.10.8.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.10.8.1.1\">w/ Wrong SQL + System_error_info</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.10.8.2\">10.60</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.10.8.3\">10.56</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.10.8.4\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.10.8.4.1\" style=\"background-color:#ECF4FF;\">8.81</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.10.8.5\">11.93</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.11.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T5.1.1.11.9.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.11.9.1.1\">w/ Wrong SQL + All_error_info</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T5.1.1.11.9.2\">11.92</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T5.1.1.11.9.3\">11.80</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T5.1.1.11.9.4\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.11.9.4.1\" style=\"background-color:#ECF4FF;\">8.81</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T5.1.1.11.9.5\">13.07</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 5: EX (%) results of general debug. Each column demonstrates the debugging results of SQLCoder or InternLM for the wrong SQL statements generated by the corresponding model."
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T6\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 6: </span>VES and C-VES results of different SQL optimization methods.</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T6.2\" style=\"width:433.6pt;height:171.8pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-78.6pt,31.1pt) scale(0.734014726880575,0.734014726880575) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T6.2.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T6.2.2.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T6.2.2.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.3.1.1.1\">Methods</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" colspan=\"2\" id=\"S4.T6.2.2.3.1.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.3.1.2.1\">Prompt Template</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T6.2.2.3.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.3.1.3.1\">Metrics</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T6.2.2.3.1.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.3.1.4.1\">ChatGPT</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T6.2.2.3.1.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.3.1.5.1\">SQLCoder-34B</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T6.2.2.3.1.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.3.1.6.1\">Codellama-34B</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T6.2.2.3.1.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.3.1.7.1\">InternLM-70B</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T6.2.2.3.1.8\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.3.1.8.1\">InternLM2-20B</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T6.2.2.4.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T6.2.2.4.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.4.1.1.1\">Baseline</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"2\" id=\"S4.T6.2.2.4.1.2\" rowspan=\"2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.4.1.2.1\">SimpleDDL-MD-Chat</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T6.2.2.4.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.4.1.3.1\">VES</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.4.1.4\">36.90</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.4.1.5\">24.28</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.4.1.6\">18.94</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.4.1.7\">22.63</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.4.1.8\">19.81</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.2.5.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T6.2.2.5.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.5.2.1.1\">C-VES</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.5.2.2\">102.50</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.5.2.3\">101.17</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.5.2.4\">99.68</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.5.2.5\">110.39</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.5.2.6\">94.33</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T6.1.1.1.2\" rowspan=\"8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.1.1.2.1\">Two-Stage Generation</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T6.1.1.1.3\" rowspan=\"4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.1.1.3.1\">zero-shot</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T6.1.1.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.1.1.1.1\">with </span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T6.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.1.1.4.1\">VES</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.1.1.1.5\">30.73</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.1.1.1.6\">16.86</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.1.1.1.7\">17.34</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.1.1.1.8\">15.33</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.1.1.1.9\">20.28</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.2.6.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T6.2.2.6.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.6.3.1.1\">C-VES</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.6.3.2\">102.43</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.6.3.3\">102.19</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.6.3.4\">102.08</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.6.3.5\">102.17</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.6.3.6\">101.42</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T6.2.2.2.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.2.1.1\">w/ </span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T6.2.2.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.2.2.1\">VES</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.2.3\">32.21</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.2.4\">18.90</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.2.5\">19.28</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.2.6\">18.44</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.2.7\">20.77</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.2.7.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T6.2.2.7.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.7.4.1.1\">C-VES</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.7.4.2\">102.24</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.7.4.3\">102.14</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.7.4.4\">101.47</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.7.4.5\">102.43</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.7.4.6\">101.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.2.8.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T6.2.2.8.5.1\" rowspan=\"4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.8.5.1.1\">few-shot</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T6.2.2.8.5.2\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.8.5.2.1\">w/ demo</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T6.2.2.8.5.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.8.5.3.1\">VES</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.8.5.4\">32.19</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.8.5.5\">18.84</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.8.5.6\">18.34</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.8.5.7\">17.97</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.8.5.8\">20.86</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.2.9.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T6.2.2.9.6.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.9.6.1.1\">C-VES</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.9.6.2\">102.18</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.9.6.3\">101.84</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.9.6.4\">101.88</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.9.6.5\">102.68</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.9.6.6\">101.75</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.2.10.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T6.2.2.10.7.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.10.7.1.1\">w/ demo + comments</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T6.2.2.10.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.10.7.2.1\">VES</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.10.7.3\">32.65</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.10.7.4\">18.28</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.10.7.5\">18.52</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.10.7.6\">17.45</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.10.7.7\">20.92</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.2.11.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T6.2.2.11.8.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.11.8.1.1\">C-VES</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.11.8.2\">102.03</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.11.8.3\">101.54</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.11.8.4\">102.86</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.11.8.5\">102.66</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T6.2.2.11.8.6\">102.06</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.2.12.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\" id=\"S4.T6.2.2.12.9.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.12.9.1.1\">Direct Generation</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\" colspan=\"2\" id=\"S4.T6.2.2.12.9.2\" rowspan=\"2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.12.9.2.1\">SimpleDDL-MD-Chat-Efficiency</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T6.2.2.12.9.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.12.9.3.1\">VES</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.12.9.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.12.9.4.1\">39.26</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.12.9.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.12.9.5.1\">27.77</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.12.9.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.12.9.6.1\">20.75</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.12.9.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.12.9.7.1\">25.23</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T6.2.2.12.9.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.12.9.8.1\">25.93</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.2.13.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T6.2.2.13.10.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.13.10.1.1\">C-VES</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T6.2.2.13.10.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.13.10.2.1\">103.31</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T6.2.2.13.10.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.13.10.3.1\">102.84</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T6.2.2.13.10.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.13.10.4.1\">103.75</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T6.2.2.13.10.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.13.10.5.1\">102.98</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T6.2.2.13.10.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.2.13.10.6.1\">101.70</span></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 6: VES and C-VES results of different SQL optimization methods."
        },
        "7": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T7\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 7: </span>SQL-to-Text performance of different LLMs, including the F1 scores of Rouge and BertScore, as well as the accuracy rate assessed by LLM.</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T7.1\" style=\"width:433.6pt;height:114.4pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-22.0pt,5.8pt) scale(0.907706590488152,0.907706590488152) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T7.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T7.1.1.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T7.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.1.1.2.1\">ChatGPT</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T7.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.1.1.3.1\">SQLCoder-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T7.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.1.1.4.1\">Codellama-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T7.1.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.1.1.5.1\">InternLM-70B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T7.1.1.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.1.1.6.1\">InternLM2-20B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T7.1.1.1.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.1.1.7.1\">Llama2-Chat-70B</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T7.1.1.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.2.1.1.1\">Rouge-1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.2.1.2\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.2.1.2.1\" style=\"background-color:#ECF4FF;\">0.428</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.2.1.3\">0.118</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.2.1.4\">0.359</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.2.1.5\">0.408</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.2.1.6\">0.410</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.2.1.7\">0.368</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.1.1.3.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.3.2.1.1\">Rouge-2</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.3.2.2\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.3.2.2.1\" style=\"background-color:#ECF4FF;\">0.384</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.3.2.3\">0.039</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.3.2.4\">0.167</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.3.2.5\">0.198</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.3.2.6\">0.294</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.3.2.7\">0.159</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.1.1.4.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.4.3.1.1\">Rouge-L</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.4.3.2\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.4.3.2.1\" style=\"background-color:#ECF4FF;\">0.545</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.4.3.3\">0.108</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.4.3.4\">0.320</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.4.3.5\">0.372</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.4.3.6\">0.358</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.4.3.7\">0.325</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.1.1.5.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.5.4.1.1\">BertScore</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.5.4.2\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.5.4.2.1\" style=\"background-color:#ECF4FF;\">0.887</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.5.4.3\">0.779</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.5.4.4\">0.856</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.5.4.5\">0.886</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.5.4.6\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.5.4.6.1\" style=\"background-color:#ECF4FF;\">0.887</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.5.4.7\">0.885</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.1.1.6.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.6.5.1.1\">ChatGPT Evaluator</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.6.5.2\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.6.5.2.1\" style=\"background-color:#ECF4FF;\">70.5%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.6.5.3\">8.5%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.6.5.4\">47.0%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.6.5.5\">63.5%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.6.5.6\">66.5%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.6.5.7\">50.0%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T7.1.1.7.6.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.7.6.1.1\">InternLM2 Evaluator</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T7.1.1.7.6.2\">62%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T7.1.1.7.6.3\">22.5%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T7.1.1.7.6.4\">49.8%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T7.1.1.7.6.5\">65.8%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T7.1.1.7.6.6\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.1.1.7.6.6.1\" style=\"background-color:#ECF4FF;\">71.3%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T7.1.1.7.6.7\">60.0%</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 7: SQL-to-Text performance of different LLMs, including the F1 scores of Rouge and BertScore, as well as the accuracy rate assessed by LLM."
        },
        "8": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T8\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 8: </span>RES results of different Schema Linking methods.</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T8.1\" style=\"width:433.6pt;height:108.9pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(1.9pt,-0.5pt) scale(1.0086766282836,1.0086766282836) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T8.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T8.1.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T8.1.1.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T8.1.1.1.1.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.1.1.2.1\">ChatGPT</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T8.1.1.1.1.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.1.1.3.1\">SQLCoder-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T8.1.1.1.1.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.1.1.4.1\">InternLM-70B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T8.1.1.1.1.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.1.1.5.1\">Codellama-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T8.1.1.1.1.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.1.1.6.1\">InternLM2-20B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T8.1.1.1.1.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.1.1.7.1\">Llama2-Chat-70B</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.1.1.2.2\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S4.T8.1.1.2.2.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.1.2.2.2\">w/o fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.1.2.2.3\">w/ fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.1.2.2.4\">w/o fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.1.2.2.5\">w/ fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.1.2.2.6\">w/o fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.1.2.2.7\">w/ fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.1.2.2.8\">w/o fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.1.2.2.9\">w/ fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.1.2.2.10\">w/o fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.1.2.2.11\">w/ fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.1.2.2.12\">w/o fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.1.2.2.13\">w/ fk</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T8.1.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T8.1.1.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.3.1.1.1\">Zero Shot</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.3.1.2\">0.6384</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.3.1.3\">0.6399</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.3.1.4\">0.2278</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.3.1.5\">0.4686</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.3.1.6\">0.5745</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.3.1.7\">0.5652</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.3.1.8\">0.3675</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.3.1.9\">0.4835</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.3.1.10\">0.5687</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.3.1.11\">0.5811</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.3.1.12\">0.4759</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T8.1.1.3.1.13\">0.5566</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.1.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T8.1.1.4.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.4.2.1.1\">Few Shot</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.4.2.2\">0.6222</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.4.2.3\">0.6402</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.4.2.4\">0.3657</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.4.2.5\">0.3919</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.4.2.6\">0.5302</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.4.2.7\">0.4961</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.4.2.8\">0.4401</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.4.2.9\">0.4745</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.4.2.10\">0.464</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.4.2.11\">0.4829</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.4.2.12\">0.4123</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.4.2.13\">0.5375</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.1.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T8.1.1.5.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.5.3.1.1\">PreSQL</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.5.3.2\">0.6888</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.5.3.3\">0.6610</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.5.3.4\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.5.3.4.1\" style=\"background-color:#ECF4FF;\">0.5661</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.5.3.5\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.5.3.5.1\" style=\"background-color:#ECF4FF;\">0.6417</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.5.3.6\">0.4632</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.5.3.7\">0.4881</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.5.3.8\">0.5085</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.5.3.9\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.5.3.9.1\" style=\"background-color:#ECF4FF;\">0.597</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.5.3.10\">0.5649</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.5.3.11\">0.6267</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.5.3.12\">0.4478</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T8.1.1.5.3.13\">0.5273</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.1.1.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T8.1.1.6.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.6.4.1.1\">Few Shot + PreSQL</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.1.1.6.4.2\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.6.4.2.1\" style=\"background-color:#ECF4FF;\">0.7340</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.1.1.6.4.3\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.6.4.3.1\" style=\"background-color:#ECF4FF;\">0.7469</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.1.1.6.4.4\">0.5354</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.1.1.6.4.5\">0.6336</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.1.1.6.4.6\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.6.4.6.1\" style=\"background-color:#ECF4FF;\">0.5999</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.1.1.6.4.7\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.6.4.7.1\" style=\"background-color:#ECF4FF;\">0.6054</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.1.1.6.4.8\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.6.4.8.1\" style=\"background-color:#ECF4FF;\">0.5576</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.1.1.6.4.9\">0.5646</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.1.1.6.4.10\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.6.4.10.1\" style=\"background-color:#ECF4FF;\">0.6594</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.1.1.6.4.11\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.6.4.11.1\" style=\"background-color:#ECF4FF;\">0.7016</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.1.1.6.4.12\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.6.4.12.1\" style=\"background-color:#ECF4FF;\">0.6105</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T8.1.1.6.4.13\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.1.6.4.13.1\" style=\"background-color:#ECF4FF;\">0.6418</span></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 8: RES results of different Schema Linking methods."
        },
        "9": {
            "table_html": "<figure class=\"ltx_table\" id=\"A2.T9\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 9: </span>The results of table linking include the metrics of exact match and subset match.</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"A2.T9.1\" style=\"width:433.6pt;height:174.5pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-6.8pt,2.7pt) scale(0.969703645436438,0.969703645436438) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A2.T9.1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T9.1.1.1.1\">\n<td class=\"ltx_td ltx_border_tt\" id=\"A2.T9.1.1.1.1.1\"></td>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T9.1.1.1.1.2\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"A2.T9.1.1.1.1.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.1.1.3.1\">SQLCoder-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"A2.T9.1.1.1.1.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.1.1.4.1\">InternLM-70B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"A2.T9.1.1.1.1.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.1.1.5.1\">Codellama-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"A2.T9.1.1.1.1.6\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.1.1.6.1\">InternLM2-20B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"A2.T9.1.1.1.1.7\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.1.1.7.1\">Llama2-Chat-70B</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T9.1.1.2.2\">\n<td class=\"ltx_td\" id=\"A2.T9.1.1.2.2.1\"></td>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"A2.T9.1.1.2.2.2\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T9.1.1.2.2.3\">w/o fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T9.1.1.2.2.4\">w/ fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T9.1.1.2.2.5\">w/o fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T9.1.1.2.2.6\">w/ fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T9.1.1.2.2.7\">w/o fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T9.1.1.2.2.8\">w/ fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T9.1.1.2.2.9\">w/o fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T9.1.1.2.2.10\">w/ fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T9.1.1.2.2.11\">w/o fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T9.1.1.2.2.12\">w/ fk</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T9.1.1.3.3\">\n<td class=\"ltx_td ltx_border_t\" id=\"A2.T9.1.1.3.3.1\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.3.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.3.3.2.1\">Subset Match</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.3.3.3\">0.28</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.3.3.4\">0.55</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.3.3.5\">0.66</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.3.3.6\">0.645</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.3.3.7\">0.495</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.3.3.8\">0.655</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.3.3.9\">0.605</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.3.3.10\">0.67</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.3.3.11\">0.655</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.3.3.12\">0.76</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T9.1.1.4.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.4.4.1\" rowspan=\"-2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.4.4.1.1\">Zero Shot</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.4.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.4.4.2.1\">Exact Match</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.4.4.3\">0.135</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.4.4.4\">0.295</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.4.4.5\">0.355</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.4.4.6\">0.34</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.4.4.7\">0.19</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.4.4.8\">0.27</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.4.4.9\">0.235</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.4.4.10\">0.415</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.4.4.11\">0.12</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.4.4.12\">0.135</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T9.1.1.5.5\">\n<td class=\"ltx_td ltx_border_t\" id=\"A2.T9.1.1.5.5.1\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.5.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.5.5.2.1\">Subset Match</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.5.5.3\">0.5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.5.5.4\">0.475</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.5.5.5\">0.595</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.5.5.6\">0.555</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.5.5.7\">0.645</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.5.5.8\">0.7</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.5.5.9\">0.53</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.5.5.10\">0.545</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.5.5.11\">0.57</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.5.5.12\">0.72</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T9.1.1.6.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.6.6.1\" rowspan=\"-2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.6.6.1.1\">Few Shot</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.6.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.6.6.2.1\">Exact Match</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.6.6.3\">0.155</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.6.6.4\">0.22</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.6.6.5\">0.355</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.6.6.6\">0.34</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.6.6.7\">0.19</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.6.6.8\">0.155</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.6.6.9\">0.33</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.6.6.10\">0.355</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.6.6.11\">0.125</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.6.6.12\">0.18</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T9.1.1.7.7\">\n<td class=\"ltx_td ltx_border_t\" id=\"A2.T9.1.1.7.7.1\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.7.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.7.7.2.1\">Subset Match</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.7.7.3\">0.6</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.7.7.4\">0.675</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.7.7.5\">0.475</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.7.7.6\">0.505</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.7.7.7\">0.525</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.7.7.8\">0.62</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.7.7.9\">0.6</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.7.7.10\">0.67</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.7.7.11\">0.51</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.7.7.12\">0.65</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T9.1.1.8.8\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.8.8.1\" rowspan=\"-2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.8.8.1.1\">PreSQL</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.8.8.2\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.8.8.2.1\" style=\"background-color:#EFEFEF;\">Exact Match</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.8.8.3\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.8.8.3.1\" style=\"background-color:#EFEFEF;\">0.465</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.8.8.4\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.8.8.4.1\" style=\"background-color:#EFEFEF;\">0.55</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.8.8.5\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.8.8.5.1\" style=\"background-color:#EFEFEF;\">0.43</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.8.8.6\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.8.8.6.1\" style=\"background-color:#EFEFEF;\">0.435</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.8.8.7\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.8.8.7.1\" style=\"background-color:#EFEFEF;\">0.45</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.8.8.8\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.8.8.8.1\" style=\"background-color:#EFEFEF;\">0.525</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.8.8.9\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.8.8.9.1\" style=\"background-color:#EFEFEF;\">0.5</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.8.8.10\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.8.8.10.1\" style=\"background-color:#EFEFEF;\">0.525</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.8.8.11\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.8.8.11.1\" style=\"background-color:#EFEFEF;\">0.3</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T9.1.1.8.8.12\" style=\"background-color:#EFEFEF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.8.8.12.1\" style=\"background-color:#EFEFEF;\">0.23</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T9.1.1.9.9\">\n<td class=\"ltx_td ltx_border_t\" id=\"A2.T9.1.1.9.9.1\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.9.9.2\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.9.9.2.1\" style=\"background-color:#ECF4FF;\">Subset Match</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.9.9.3\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.9.9.3.1\" style=\"background-color:#ECF4FF;\">0.715</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.9.9.4\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.9.9.4.1\" style=\"background-color:#ECF4FF;\">0.77</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.9.9.5\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.9.9.5.1\" style=\"background-color:#ECF4FF;\">0.67</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.9.9.6\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.9.9.6.1\" style=\"background-color:#ECF4FF;\">0.675</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.9.9.7\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.9.9.7.1\" style=\"background-color:#ECF4FF;\">0.755</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.9.9.8\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.9.9.8.1\" style=\"background-color:#ECF4FF;\">0.785</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.9.9.9\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.9.9.9.1\" style=\"background-color:#ECF4FF;\">0.74</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.9.9.10\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.9.9.10.1\" style=\"background-color:#ECF4FF;\">0.78</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.9.9.11\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.9.9.11.1\" style=\"background-color:#ECF4FF;\">0.815</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T9.1.1.9.9.12\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.9.9.12.1\" style=\"background-color:#ECF4FF;\">0.86</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T9.1.1.10.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T9.1.1.10.10.1\" rowspan=\"-2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.10.10.1.1\">Few Shot + PreSQL</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T9.1.1.10.10.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T9.1.1.10.10.2.1\">Exact Match</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T9.1.1.10.10.3\">0.195</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T9.1.1.10.10.4\">0.345</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T9.1.1.10.10.5\">0.395</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T9.1.1.10.10.6\">0.405</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T9.1.1.10.10.7\">0.2</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T9.1.1.10.10.8\">0.185</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T9.1.1.10.10.9\">0.42</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T9.1.1.10.10.10\">0.46</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T9.1.1.10.10.11\">0.19</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T9.1.1.10.10.12\">0.165</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 9: The results of table linking include the metrics of exact match and subset match."
        },
        "10": {
            "table_html": "<figure class=\"ltx_table\" id=\"A2.T10\">\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\">Table 10: </span>EX (%) of different LLMs on BIRD dev set. prompt template is \u201cSimpleDDL-MD-Chat\".</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"A2.T10.3\" style=\"width:346.9pt;height:137.8pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(37.5pt,-14.9pt) scale(1.27613628511432,1.27613628511432) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A2.T10.3.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T10.3.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A2.T10.3.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.1.1.1.1\" style=\"font-size:80%;\">No. of GT Tables</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T10.3.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.1.1.2.1\" style=\"font-size:80%;\">SQLCoder-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T10.3.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.1.1.3.1\" style=\"font-size:80%;\">InternLM-70B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T10.3.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.1.1.4.1\" style=\"font-size:80%;\">Codellama-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T10.3.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.1.1.5.1\" style=\"font-size:80%;\">InternLM2-20B</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T10.3.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T10.3.1.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.2.1.1.1\" style=\"font-size:80%;\">1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T10.3.1.2.1.2\"><span class=\"ltx_text\" id=\"A2.T10.3.1.2.1.2.1\" style=\"font-size:80%;\">40.33</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T10.3.1.2.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.2.1.3.1\" style=\"font-size:80%;\">43.37</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T10.3.1.2.1.4\"><span class=\"ltx_text\" id=\"A2.T10.3.1.2.1.4.1\" style=\"font-size:80%;\">40.88</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T10.3.1.2.1.5\"><span class=\"ltx_text\" id=\"A2.T10.3.1.2.1.5.1\" style=\"font-size:80%;\">40.33</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T10.3.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T10.3.1.3.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.3.2.1.1\" style=\"font-size:80%;\">2</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T10.3.1.3.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.3.2.2.1\" style=\"font-size:80%;\">28.42</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T10.3.1.3.2.3\"><span class=\"ltx_text\" id=\"A2.T10.3.1.3.2.3.1\" style=\"font-size:80%;\">25.24</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T10.3.1.3.2.4\"><span class=\"ltx_text\" id=\"A2.T10.3.1.3.2.4.1\" style=\"font-size:80%;\">27.57</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T10.3.1.3.2.5\"><span class=\"ltx_text\" id=\"A2.T10.3.1.3.2.5.1\" style=\"font-size:80%;\">28.31</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T10.3.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T10.3.1.4.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.4.3.1.1\" style=\"font-size:80%;\">3</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T10.3.1.4.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.4.3.2.1\" style=\"font-size:80%;\">21.05</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T10.3.1.4.3.3\"><span class=\"ltx_text\" id=\"A2.T10.3.1.4.3.3.1\" style=\"font-size:80%;\">15.79</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T10.3.1.4.3.4\"><span class=\"ltx_text\" id=\"A2.T10.3.1.4.3.4.1\" style=\"font-size:80%;\">16.75</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T10.3.1.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.4.3.5.1\" style=\"font-size:80%;\">21.05</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T10.3.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T10.3.1.5.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.5.4.1.1\" style=\"font-size:80%;\">&gt;3</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T10.3.1.5.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.5.4.2.1\" style=\"font-size:80%;\">30.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T10.3.1.5.4.3\"><span class=\"ltx_text\" id=\"A2.T10.3.1.5.4.3.1\" style=\"font-size:80%;\">5.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T10.3.1.5.4.4\"><span class=\"ltx_text\" id=\"A2.T10.3.1.5.4.4.1\" style=\"font-size:80%;\">15.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T10.3.1.5.4.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.5.4.5.1\" style=\"font-size:80%;\">30.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T10.3.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"A2.T10.3.1.6.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.6.5.1.1\" style=\"font-size:80%;\">Total</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T10.3.1.6.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T10.3.1.6.5.2.1\" style=\"font-size:80%;\">30.25</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T10.3.1.6.5.3\"><span class=\"ltx_text\" id=\"A2.T10.3.1.6.5.3.1\" style=\"font-size:80%;\">27.97</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T10.3.1.6.5.4\"><span class=\"ltx_text\" id=\"A2.T10.3.1.6.5.4.1\" style=\"font-size:80%;\">29.07</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T10.3.1.6.5.5\"><span class=\"ltx_text\" id=\"A2.T10.3.1.6.5.5.1\" style=\"font-size:80%;\">30.18</span></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 10: EX (%) of different LLMs on BIRD dev set. prompt template is \u201cSimpleDDL-MD-Chat\"."
        },
        "11": {
            "table_html": "<figure class=\"ltx_table\" id=\"A2.T11\">\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:80%;\"><span class=\"ltx_tag ltx_tag_table\">Table 11: </span>VES results of SQL Optimization on BIRD dev set.</figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A2.T11.3\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T11.3.4.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A2.T11.3.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T11.3.4.1.1.1\" style=\"font-size:80%;\">Prompt Template</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T11.3.4.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T11.3.4.1.2.1\" style=\"font-size:80%;\">SQLCoder-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T11.3.4.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T11.3.4.1.3.1\" style=\"font-size:80%;\">InternLM-70B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T11.3.4.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T11.3.4.1.4.1\" style=\"font-size:80%;\">Codellama-34B</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T11.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T11.1.1.1\">\n<span class=\"ltx_text\" id=\"A2.T11.1.1.1.1\" style=\"font-size:80%;\">with </span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T11.1.1.2\"><span class=\"ltx_text\" id=\"A2.T11.1.1.2.1\" style=\"font-size:80%;\">99.68</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T11.1.1.3\"><span class=\"ltx_text\" id=\"A2.T11.1.1.3.1\" style=\"font-size:80%;\">99.99</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T11.1.1.4\"><span class=\"ltx_text\" id=\"A2.T11.1.1.4.1\" style=\"font-size:80%;\">99.04</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T11.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T11.2.2.1\">\n<span class=\"ltx_text\" id=\"A2.T11.2.2.1.1\" style=\"font-size:80%;\">w/ </span>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T11.2.2.2\"><span class=\"ltx_text\" id=\"A2.T11.2.2.2.1\" style=\"font-size:80%;\">102.65</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T11.2.2.3\"><span class=\"ltx_text\" id=\"A2.T11.2.2.3.1\" style=\"font-size:80%;\">100.10</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T11.2.2.4\"><span class=\"ltx_text\" id=\"A2.T11.2.2.4.1\" style=\"font-size:80%;\">101.48</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T11.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T11.3.3.1\">\n<span class=\"ltx_text\" id=\"A2.T11.3.3.1.1\" style=\"font-size:80%;\">w/ </span>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T11.3.3.2\"><span class=\"ltx_text\" id=\"A2.T11.3.3.2.1\" style=\"font-size:80%;\">102.92</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T11.3.3.3\"><span class=\"ltx_text\" id=\"A2.T11.3.3.3.1\" style=\"font-size:80%;\">100.69</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T11.3.3.4\"><span class=\"ltx_text\" id=\"A2.T11.3.3.4.1\" style=\"font-size:80%;\">101.78</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T11.3.5.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"A2.T11.3.5.1.1\"><span class=\"ltx_text\" id=\"A2.T11.3.5.1.1.1\" style=\"font-size:80%;\">SimpleDDL-MD-Chat-Efficiency</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T11.3.5.1.2\"><span class=\"ltx_text\" id=\"A2.T11.3.5.1.2.1\" style=\"font-size:80%;\">101.26</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T11.3.5.1.3\"><span class=\"ltx_text\" id=\"A2.T11.3.5.1.3.1\" style=\"font-size:80%;\">100.51</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T11.3.5.1.4\"><span class=\"ltx_text\" id=\"A2.T11.3.5.1.4.1\" style=\"font-size:80%;\">100.34</span></td>\n</tr>\n</tbody>\n</table>\n</figure>",
            "capture": "Table 11: VES results of SQL Optimization on BIRD dev set."
        },
        "12": {
            "table_html": "<figure class=\"ltx_table\" id=\"A2.T12\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 12: </span>SQL-to-Text performance on BIRD dev set, including the F1 scores of Rouge and BertScore, as well as the accuracy rate assessed by LLM. </figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"A2.T12.1\" style=\"width:346.9pt;height:136.3pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(36.1pt,-14.2pt) scale(1.26246187780016,1.26246187780016) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A2.T12.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T12.1.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"A2.T12.1.1.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T12.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T12.1.1.1.1.2.1\">Codellama-34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T12.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T12.1.1.1.1.3.1\">InternLM-70B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T12.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T12.1.1.1.1.4.1\">Llama2-Chat-70B</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T12.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T12.1.1.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T12.1.1.2.1.1.1\">Rouge-1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T12.1.1.2.1.2\">0.423</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T12.1.1.2.1.3\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T12.1.1.2.1.3.1\" style=\"background-color:#ECF4FF;\">0.495</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T12.1.1.2.1.4\">0.454</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T12.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T12.1.1.3.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T12.1.1.3.2.1.1\">Rouge-2</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T12.1.1.3.2.2\">0.231</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T12.1.1.3.2.3\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T12.1.1.3.2.3.1\" style=\"background-color:#ECF4FF;\">0.273</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T12.1.1.3.2.4\">0.230</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T12.1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T12.1.1.4.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T12.1.1.4.3.1.1\">Rouge-L</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T12.1.1.4.3.2\">0.423</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T12.1.1.4.3.3\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T12.1.1.4.3.3.1\" style=\"background-color:#ECF4FF;\">0.449</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T12.1.1.4.3.4\">0.408</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T12.1.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T12.1.1.5.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T12.1.1.5.4.1.1\">BertScore</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T12.1.1.5.4.2\">0.908</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T12.1.1.5.4.3\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T12.1.1.5.4.3.1\" style=\"background-color:#ECF4FF;\">0.924</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T12.1.1.5.4.4\">0.919</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T12.1.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"A2.T12.1.1.6.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T12.1.1.6.5.1.1\">LLM Evaluator</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T12.1.1.6.5.2\">64.0%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T12.1.1.6.5.3\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T12.1.1.6.5.3.1\" style=\"background-color:#ECF4FF;\">80.8<span class=\"ltx_text ltx_font_medium\" id=\"A2.T12.1.1.6.5.3.1.1\" style=\"background-color:#ECF4FF;\">%</span></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T12.1.1.6.5.4\">75.3%</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 12: SQL-to-Text performance on BIRD dev set, including the F1 scores of Rouge and BertScore, as well as the accuracy rate assessed by LLM. "
        },
        "13": {
            "table_html": "<figure class=\"ltx_table\" id=\"A2.T13\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 13: </span>RES results of Schema Linking on BIRD dev set.</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"A2.T13.1\" style=\"width:346.9pt;height:144.2pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(43.5pt,-18.1pt) scale(1.33478756608103,1.33478756608103) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A2.T13.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T13.1.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"A2.T13.1.1.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"A2.T13.1.1.1.1.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A2.T13.1.1.1.1.2.1\">SQLCoder 34B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"A2.T13.1.1.1.1.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A2.T13.1.1.1.1.3.1\">InternLM-70B</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"A2.T13.1.1.1.1.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A2.T13.1.1.1.1.4.1\">Codellama-34B</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T13.1.1.2.2\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"A2.T13.1.1.2.2.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T13.1.1.2.2.2\">w/o fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T13.1.1.2.2.3\">w/ fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T13.1.1.2.2.4\">w/o fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T13.1.1.2.2.5\">w/ fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T13.1.1.2.2.6\">w/o fk</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T13.1.1.2.2.7\">w/ fk</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T13.1.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T13.1.1.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T13.1.1.3.1.1.1\">Zero Shot</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T13.1.1.3.1.2\">0.7034</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T13.1.1.3.1.3\">0.7138</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T13.1.1.3.1.4\">0.7505</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T13.1.1.3.1.5\">0.7739</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T13.1.1.3.1.6\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T13.1.1.3.1.6.1\" style=\"background-color:#ECF4FF;\">0.7130</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T13.1.1.3.1.7\">0.6564</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T13.1.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T13.1.1.4.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T13.1.1.4.2.1.1\">Few Shot</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T13.1.1.4.2.2\">0.4343</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T13.1.1.4.2.3\">0.4078</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T13.1.1.4.2.4\">0.7365</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T13.1.1.4.2.5\">0.7574</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T13.1.1.4.2.6\">0.5712</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T13.1.1.4.2.7\">0.5822</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T13.1.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T13.1.1.5.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T13.1.1.5.3.1.1\">PreSQL</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T13.1.1.5.3.2\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T13.1.1.5.3.2.1\" style=\"background-color:#ECF4FF;\">0.7274</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T13.1.1.5.3.3\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T13.1.1.5.3.3.1\" style=\"background-color:#ECF4FF;\">0.7715</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T13.1.1.5.3.4\">0.5563</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T13.1.1.5.3.5\">0.5958</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T13.1.1.5.3.6\">0.6389</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T13.1.1.5.3.7\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T13.1.1.5.3.7.1\" style=\"background-color:#ECF4FF;\">0.6615</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T13.1.1.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"A2.T13.1.1.6.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T13.1.1.6.4.1.1\">Few Shot + PreSQL</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T13.1.1.6.4.2\">0.6621</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T13.1.1.6.4.3\">0.7296</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T13.1.1.6.4.4\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T13.1.1.6.4.4.1\" style=\"background-color:#ECF4FF;\">0.7686</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T13.1.1.6.4.5\" style=\"background-color:#ECF4FF;\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T13.1.1.6.4.5.1\" style=\"background-color:#ECF4FF;\">0.7936</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T13.1.1.6.4.6\">0.6551</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T13.1.1.6.4.7\">0.6417</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 13: RES results of Schema Linking on BIRD dev set."
        },
        "14": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T14\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 14: </span>Comments for different categories of Result Error used in SQL debugging.</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"A3.T14.1\" style=\"width:433.6pt;height:430.7pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-25.1pt,25.0pt) scale(0.89611313954525,0.89611313954525) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A3.T14.1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A3.T14.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.1.1.1.1\">Error Type</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A3.T14.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.1.1.2.1\">Subcategory</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T14.1.1.1.1.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.1.1.3.1\">comments prompt</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.2.2.1\" rowspan=\"3\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.2.2.1.1\">Table Query Error</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.2.2.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A3.T14.1.1.2.2.2.1\">\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.2.2.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.2.2.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.2.2.2.1.1.1.1\">Excessive</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.2.2.2.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.2.2.2.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.2.2.2.1.2.1.1\">Tables</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.2.2.3\">The tables you inquired about is incorrect, you query too much tables.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.3.3.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A3.T14.1.1.3.3.1.1\">\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.3.3.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.3.3.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.3.3.1.1.1.1.1\">Missing</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.3.3.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.3.3.1.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.3.3.1.1.2.1.1\">Tables</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.3.3.2\">The tables you inquired about is incorrect, you need to query more tables.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.4.4.1\"><span class=\"ltx_text\" id=\"A3.T14.1.1.4.4.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A3.T14.1.1.4.4.1.1.1\">\n<span class=\"ltx_tr\" id=\"A3.T14.1.1.4.4.1.1.1.1\">\n<span class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.4.4.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.4.4.1.1.1.1.1.1\">Incorrect</span></span></span>\n<span class=\"ltx_tr\" id=\"A3.T14.1.1.4.4.1.1.1.2\">\n<span class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.4.4.1.1.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.4.4.1.1.1.2.1.1\">Tables</span></span></span>\n</span></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.4.4.2\"><span class=\"ltx_text\" id=\"A3.T14.1.1.4.4.2.1\">The tables you inquired about is incorrect.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.5.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.5.5.1\" rowspan=\"3\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.5.5.1.1\">Column Selection Error</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.5.5.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A3.T14.1.1.5.5.2.1\">\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.5.5.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.5.5.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.5.5.2.1.1.1.1\">Excessive</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.5.5.2.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.5.5.2.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.5.5.2.1.2.1.1\">Columns</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.5.5.3\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A3.T14.1.1.5.5.3.1\">\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.5.5.3.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.5.5.3.1.1.1\">You have found the correct tables.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.5.5.3.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.5.5.3.1.2.1\">But you select wrong columns,you select too much Columns.</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.6.6.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A3.T14.1.1.6.6.1.1\">\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.6.6.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.6.6.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.6.6.1.1.1.1.1\">Missing</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.6.6.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.6.6.1.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.6.6.1.1.2.1.1\">Columns</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.6.6.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A3.T14.1.1.6.6.2.1\">\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.6.6.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.6.6.2.1.1.1\">You have found the correct tables.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.6.6.2.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.6.6.2.1.2.1\">But you select wrong columns,you need to select more Columns.</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.7.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.7.7.1\"><span class=\"ltx_text\" id=\"A3.T14.1.1.7.7.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"A3.T14.1.1.7.7.1.1.1\">\n<span class=\"ltx_tr\" id=\"A3.T14.1.1.7.7.1.1.1.1\">\n<span class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.7.7.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.7.7.1.1.1.1.1.1\">Incorrect</span></span></span>\n<span class=\"ltx_tr\" id=\"A3.T14.1.1.7.7.1.1.1.2\">\n<span class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.7.7.1.1.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.7.7.1.1.1.2.1.1\">Columns</span></span></span>\n</span></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.7.7.2\"><span class=\"ltx_text\" id=\"A3.T14.1.1.7.7.2.1\">You have found the correct tables.But you select wrong columns.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"2\" id=\"A3.T14.1.1.8.8.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.8.8.1.1\">Join Columns Error</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.8.8.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A3.T14.1.1.8.8.2.1\">\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.8.8.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.8.8.2.1.1.1\">You have found the correct tables.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.8.8.2.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.8.8.2.1.2.1\">You have selected the correct Columns.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.8.8.2.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.8.8.2.1.3.1\">But you combine wrong rows when JOIN two tables.</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"2\" id=\"A3.T14.1.1.9.9.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.9.9.1.1\">Condition Filter Error</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A3.T14.1.1.9.9.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A3.T14.1.1.9.9.2.1\">\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.9.9.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.9.9.2.1.1.1\">You have found the correct tables.You have selected the correct Columns.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.9.9.2.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.9.9.2.1.2.1\">You have combined (JOIN) the correct tables.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.9.9.2.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.9.9.2.1.3.1\">But an error occurred in the conditional filter.</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.10.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" colspan=\"2\" id=\"A3.T14.1.1.10.10.1\">\n<span class=\"ltx_text ltx_font_bold\" id=\"A3.T14.1.1.10.10.1.1\">Data Processing Error</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"A3.T14.1.1.10.10.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"A3.T14.1.1.10.10.2.1\">\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.10.10.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.10.10.2.1.1.1\">You have found the correct tables.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.10.10.2.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.10.10.2.1.2.1\">You have selected the correct Columns.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.10.10.2.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.10.10.2.1.3.1\">You have combined (JOIN) the correct tables.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.10.10.2.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.10.10.2.1.4.1\">You have used the correct conditional filtering.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T14.1.1.10.10.2.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"A3.T14.1.1.10.10.2.1.5.1\">But there was an error in your processing of the data.</td>\n</tr>\n</table>\n</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>",
            "capture": "Table 14: Comments for different categories of Result Error used in SQL debugging."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.02951v2_figure_1.png",
            "caption": "Figure 1: Benchmarking tasks in Text-to-SQL pipeline."
        },
        "2": {
            "figure_path": "2403.02951v2_figure_2.png",
            "caption": "Figure 2: Overall performance of different LLMs in various sub-tasks."
        },
        "3": {
            "figure_path": "2403.02951v2_figure_3.png",
            "caption": "Figure 3: Word cloud representation of error information for incorrect SQL queries generated by LLMs. Top: System Error and Result Error. Bottom: Detailed classification of Result Error."
        },
        "4": {
            "figure_path": "2403.02951v2_figure_4.png",
            "caption": "Figure 4: EX (%) improvement brought by self debug."
        },
        "5": {
            "figure_path": "2403.02951v2_figure_5.png",
            "caption": "Figure 5: Left: EX (%) improvement brought by multi-round self debug. Right: Numbers of wrong SQL queries of detailed error type during the process of multi-round self debug."
        },
        "6": {
            "figure_path": "2403.02951v2_figure_6.png",
            "caption": "Figure 6: EX (%) improvement brought by self debug on BIRD dev set."
        }
    },
    "references": [
        {
            "1": {
                "title": "Sadga: Structure-aware dual graph aggregation network for text-to-sql.",
                "author": "Ruichu Cai, Jinjie Yuan, Boyan Xu, and Zhifeng Hao.",
                "venue": "Advances in Neural Information Processing Systems, 34:7664\u20137676, 2021.",
                "url": null
            }
        },
        {
            "2": {
                "title": "Lgesql: line graph enhanced text-to-sql model with mixed local and non-local relations.",
                "author": "Ruisheng Cao, Lu Chen, Zhi Chen, Yanbin Zhao, Su Zhu, and Kai Yu.",
                "venue": "arXiv preprint arXiv:2106.01093, 2021.",
                "url": null
            }
        },
        {
            "3": {
                "title": "Selective demonstrations for cross-domain text-to-sql.",
                "author": "Shuaichen Chang and Eric Fosler-Lussier.",
                "venue": "arXiv preprint arXiv:2310.06302, 2023.",
                "url": null
            }
        },
        {
            "4": {
                "title": "Teaching large language models to self-debug.",
                "author": "Xinyun Chen, Maxwell Lin, Nathanael Sch\u00e4rli, and Denny Zhou.",
                "venue": "arXiv preprint arXiv:2304.05128, 2023.",
                "url": null
            }
        },
        {
            "5": {
                "title": "Ryansql: Recursively applying sketch-based slot fillings for complex text-to-sql in cross-domain databases.",
                "author": "DongHyun Choi, Myeong Cheol Shin, EungGyun Kim, and Dong Ryeol Shin.",
                "venue": "Computational Linguistics, 47(2):309\u2013332, 2021.",
                "url": null
            }
        },
        {
            "6": {
                "title": "Structure-grounded pretraining for text-to-sql.",
                "author": "Xiang Deng, Ahmed Hassan Awadallah, Christopher Meek, Oleksandr Polozov, Huan Sun, and Matthew Richardson.",
                "venue": "arXiv preprint arXiv:2010.12773, 2020.",
                "url": null
            }
        },
        {
            "7": {
                "title": "Bert: Pre-training of deep bidirectional transformers for language understanding.",
                "author": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.",
                "venue": "arXiv preprint arXiv:1810.04805, 2018.",
                "url": null
            }
        },
        {
            "8": {
                "title": "Coarse-to-fine decoding for neural semantic parsing.",
                "author": "Li Dong and Mirella Lapata.",
                "venue": "arXiv preprint arXiv:1805.04793, 2018.",
                "url": null
            }
        },
        {
            "9": {
                "title": "C3: Zero-shot text-to-sql with chatgpt.",
                "author": "Xuemei Dong, Chao Zhang, Yuhang Ge, Yuren Mao, Yunjun Gao, Jinshu Lin, Dongfang Lou, et al.",
                "venue": "arXiv preprint arXiv:2307.07306, 2023.",
                "url": null
            }
        },
        {
            "10": {
                "title": "Towards robustness of text-to-sql models against synonym substitution.",
                "author": "Yujian Gan, Xinyun Chen, Qiuping Huang, Matthew Purver, John R Woodward, Jinxia Xie, and Pengsheng Huang.",
                "venue": "arXiv preprint arXiv:2106.01065, 2021a.",
                "url": null
            }
        },
        {
            "11": {
                "title": "Exploring underexplored limitations of cross-domain text-to-sql generalization.",
                "author": "Yujian Gan, Xinyun Chen, and Matthew Purver.",
                "venue": "arXiv preprint arXiv:2109.05157, 2021b.",
                "url": null
            }
        },
        {
            "12": {
                "title": "Measuring and improving compositional generalization in text-to-sql via component alignment.",
                "author": "Yujian Gan, Xinyun Chen, Qiuping Huang, and Matthew Purver.",
                "venue": "arXiv preprint arXiv:2205.02054, 2022.",
                "url": null
            }
        },
        {
            "13": {
                "title": "Text-to-sql empowered by large language models: A benchmark evaluation.",
                "author": "Dawei Gao, Haibin Wang, Yaliang Li, Xiuyu Sun, Yichen Qian, Bolin Ding, and Jingren Zhou.",
                "venue": "arXiv preprint arXiv:2308.15363, 2023.",
                "url": null
            }
        },
        {
            "14": {
                "title": "Prompting gpt-3.5 for text-to-sql with de-semanticization and skeleton retrieval.",
                "author": "Chunxi Guo, Zhiliang Tian, Jintao Tang, Pancheng Wang, Zhihua Wen, Kang Yang, and Ting Wang.",
                "venue": "In Pacific Rim International Conference on Artificial Intelligence, pages 262\u2013274. Springer, 2023.",
                "url": null
            }
        },
        {
            "15": {
                "title": "Ssql: Injecting syntax to question-schema interaction graph encoder for text-to-sql parsers.",
                "author": "Binyuan Hui, Ruiying Geng, Lihan Wang, Bowen Qin, Bowen Li, Jian Sun, and Yongbin Li.",
                "venue": "arXiv preprint arXiv:2203.06958, 2022.",
                "url": null
            }
        },
        {
            "16": {
                "title": "A comprehensive exploration on wikisql with table-aware word contextualization.",
                "author": "Wonseok Hwang, Jinyeong Yim, Seunghyun Park, and Minjoon Seo.",
                "venue": "arXiv preprint arXiv:1902.01069, 2019.",
                "url": null
            }
        },
        {
            "17": {
                "title": "A survey on deep learning approaches for text-to-sql.",
                "author": "George Katsogiannis-Meimarakis and Georgia Koutrika.",
                "venue": "The VLDB Journal, pages 1\u201332, 2023.",
                "url": null
            }
        },
        {
            "18": {
                "title": "Tptu-v2: Boosting task planning and tool usage of large language model-based agents in real-world systems.",
                "author": "Yilun Kong, Jingqing Ruan, Yihong Chen, Bin Zhang, Tianpeng Bao, Shiwei Shi, Guoqing Du, Xiaoru Hu, Hangyu Mao, Ziyue Li, et al.",
                "venue": "arXiv preprint arXiv:2311.11315, 2023.",
                "url": null
            }
        },
        {
            "19": {
                "title": "Deep learning driven natural languages text to sql query conversion: A survey.",
                "author": "Ayush Kumar, Parth Nagarkar, Prabhav Nalhe, and Sanjeev Vijayakumar.",
                "venue": "arXiv preprint arXiv:2208.04415, 2022.",
                "url": null
            }
        },
        {
            "20": {
                "title": "Kaggledbqa: Realistic evaluation of text-to-sql parsers.",
                "author": "Chia-Hsuan Lee, Oleksandr Polozov, and Matthew Richardson.",
                "venue": "arXiv preprint arXiv:2106.11455, 2021.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Resdsql: Decoupling schema linking and skeleton parsing for text-to-sql.",
                "author": "Haoyang Li, Jing Zhang, Cuiping Li, and Hong Chen.",
                "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 13067\u201313075, 2023a.",
                "url": null
            }
        },
        {
            "22": {
                "title": "Dir: A large-scale dialogue rewrite dataset for cross-domain conversational text-to-sql.",
                "author": "Jieyu Li, Zhi Chen, Lu Chen, Zichen Zhu, Hanqi Li, Ruisheng Cao, and Kai Yu.",
                "venue": "Applied Sciences, 13(4):2262, 2023b.",
                "url": null
            }
        },
        {
            "23": {
                "title": "Graphix-t5: Mixing pre-trained transformers with graph-aware layers for text-to-sql parsing.",
                "author": "Jinyang Li, Binyuan Hui, Reynold Cheng, Bowen Qin, Chenhao Ma, Nan Huo, Fei Huang, Wenyu Du, Luo Si, and Yongbin Li.",
                "venue": "arXiv preprint arXiv:2301.07507, 2023c.",
                "url": null
            }
        },
        {
            "24": {
                "title": "Can llm already serve as a database interface? a big bench for large-scale database grounded text-to-sqls.",
                "author": "Jinyang Li, Binyuan Hui, Ge Qu, Jiaxi Yang, Binhua Li, Bowen Li, Bailin Wang, Bowen Qin, Ruiying Geng, Nan Huo, et al.",
                "venue": "Advances in Neural Information Processing Systems, 36, 2024.",
                "url": null
            }
        },
        {
            "25": {
                "title": "Rouge: A package for automatic evaluation of summaries.",
                "author": "Chin-Yew Lin.",
                "venue": "In Text summarization branches out, pages 74\u201381, 2004.",
                "url": null
            }
        },
        {
            "26": {
                "title": "Bridging textual and tabular data for cross-domain text-to-sql semantic parsing.",
                "author": "Xi Victoria Lin, Richard Socher, and Caiming Xiong.",
                "venue": "arXiv preprint arXiv:2012.12627, 2020.",
                "url": null
            }
        },
        {
            "27": {
                "title": "A comprehensive evaluation of chatgpt\u2019s zero-shot text-to-sql capability.",
                "author": "Aiwei Liu, Xuming Hu, Lijie Wen, and Philip S Yu.",
                "venue": "arXiv preprint arXiv:2303.13547, 2023.",
                "url": null
            }
        },
        {
            "28": {
                "title": "Roberta: A robustly optimized bert pretraining approach.",
                "author": "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.",
                "venue": "arXiv preprint arXiv:1907.11692, 2019.",
                "url": null
            }
        },
        {
            "29": {
                "title": "Hybrid ranking network for text-to-sql.",
                "author": "Qin Lyu, Kaushik Chakrabarti, Shobhit Hathi, Souvik Kundu, Jianwen Zhang, and Zheng Chen.",
                "venue": "arXiv preprint arXiv:2008.04759, 2020.",
                "url": null
            }
        },
        {
            "30": {
                "title": "Relation-aware graph transformer for sql-to-text generation.",
                "author": "Da Ma, Xingyu Chen, Ruisheng Cao, Zhi Chen, Lu Chen, and Kai Yu.",
                "venue": "Applied Sciences, 12(1):369, 2021.",
                "url": null
            }
        },
        {
            "31": {
                "title": "Extensible/rule based query rewrite optimization in starburst.",
                "author": "Hamid Pirahesh, Joseph M Hellerstein, and Waqar Hasan.",
                "venue": "ACM Sigmod Record, 21(2):39\u201348, 1992.",
                "url": null
            }
        },
        {
            "32": {
                "title": "Evaluating cross-domain text-to-sql models and benchmarks.",
                "author": "Mohammadreza Pourreza and Davood Rafiei.",
                "venue": "arXiv preprint arXiv:2310.18538, 2023.",
                "url": null
            }
        },
        {
            "33": {
                "title": "Din-sql: Decomposed in-context learning of text-to-sql with self-correction.",
                "author": "Mohammadreza Pourreza and Davood Rafiei.",
                "venue": "Advances in Neural Information Processing Systems, 36, 2024.",
                "url": null
            }
        },
        {
            "34": {
                "title": "Rasat: Integrating relational structures into pretrained seq2seq model for text-to-sql.",
                "author": "Jiexing Qi, Jingyao Tang, Ziwei He, Xiangpeng Wan, Yu Cheng, Chenghu Zhou, Xinbing Wang, Quanshi Zhang, and Zhouhan Lin.",
                "venue": "arXiv preprint arXiv:2205.06983, 2022.",
                "url": null
            }
        },
        {
            "35": {
                "title": "A survey on text-to-sql parsing: Concepts, methods, and future directions.",
                "author": "Bowen Qin, Binyuan Hui, Lihan Wang, Min Yang, Jinyang Li, Binhua Li, Ruiying Geng, Rongyu Cao, Jian Sun, Luo Si, et al.",
                "venue": "arXiv preprint arXiv:2208.13629, 2022.",
                "url": null
            }
        },
        {
            "36": {
                "title": "Exploring the limits of transfer learning with a unified text-to-text transformer.",
                "author": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu.",
                "venue": "The Journal of Machine Learning Research, 21(1):5485\u20135551, 2020.",
                "url": null
            }
        },
        {
            "37": {
                "title": "Code llama: Open foundation models for code.",
                "author": "Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, J\u00e9r\u00e9my Rapin, et al.",
                "venue": "arXiv preprint arXiv:2308.12950, 2023.",
                "url": null
            }
        },
        {
            "38": {
                "title": "Tptu: Task planning and tool usage of large language model-based ai agents.",
                "author": "Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du, Shiwei Shi, Hangyu Mao, Xingyu Zeng, and Rui Zhao.",
                "venue": "arXiv preprint arXiv:2308.03427, 2023.",
                "url": null
            }
        },
        {
            "39": {
                "title": "Picard: Parsing incrementally for constrained auto-regressive decoding from language models.",
                "author": "Torsten Scholak, Nathan Schucher, and Dzmitry Bahdanau.",
                "venue": "arXiv preprint arXiv:2109.05093, 2021.",
                "url": null
            }
        },
        {
            "40": {
                "title": "Compositional generalization and natural language variation: Can a semantic parsing approach handle both?",
                "author": "Peter Shaw, Ming-Wei Chang, Panupong Pasupat, and Kristina Toutanova.",
                "venue": "arXiv preprint arXiv:2010.12725, 2020.",
                "url": null
            }
        },
        {
            "41": {
                "title": "Reflexion: an autonomous agent with dynamic memory and self-reflection.",
                "author": "Noah Shinn, Beck Labash, and Ashwin Gopinath.",
                "venue": "arXiv e-prints, pages arXiv\u20132303, 2023.",
                "url": null
            }
        },
        {
            "42": {
                "title": "Logic-consistency text generation from semantic parses.",
                "author": "Chang Shu, Yusen Zhang, Xiangyu Dong, Peng Shi, Tao Yu, and Rui Zhang.",
                "venue": "arXiv preprint arXiv:2108.00577, 2021.",
                "url": null
            }
        },
        {
            "43": {
                "title": "Reboost large language model-based text-to-sql, text-to-python, and text-to-function\u2013with real applications in traffic domain.",
                "author": "Guanghu Sui, Zhishuai Li, Ziyue Li, Sun Yang, Jingqing Ruan, Hangyu Mao, and Rui Zhao.",
                "venue": "arXiv preprint arXiv:2310.18752, 2023.",
                "url": null
            }
        },
        {
            "44": {
                "title": "Llama 2: Open foundation and fine-tuned chat models.",
                "author": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al.",
                "venue": "arXiv preprint arXiv:2307.09288, 2023.",
                "url": null
            }
        },
        {
            "45": {
                "title": "Attention is all you need.",
                "author": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin.",
                "venue": "Advances in neural information processing systems, 30, 2017.",
                "url": null
            }
        },
        {
            "46": {
                "title": "Rat-sql: Relation-aware schema encoding and linking for text-to-sql parsers.",
                "author": "Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, and Matthew Richardson.",
                "venue": "arXiv preprint arXiv:1911.04942, 2019.",
                "url": null
            }
        },
        {
            "47": {
                "title": "Mac-sql: Multi-agent collaboration for text-to-sql.",
                "author": "Bing Wang, Changyu Ren, Jian Yang, Xinnian Liang, Jiaqi Bai, Qian-Wen Zhang, Zhao Yan, and Zhoujun Li.",
                "venue": "arXiv preprint arXiv:2312.11242, 2023a.",
                "url": null
            }
        },
        {
            "48": {
                "title": "Dbcopilot: Scaling natural language querying to massive databases.",
                "author": "Tianshu Wang, Hongyu Lin, Xianpei Han, Le Sun, Xiaoyang Chen, Hao Wang, and Zhenyu Zeng.",
                "venue": "arXiv preprint arXiv:2312.03463, 2023b.",
                "url": null
            }
        },
        {
            "49": {
                "title": "Chain-of-thought prompting elicits reasoning in large language models.",
                "author": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al.",
                "venue": "Advances in Neural Information Processing Systems, 35:24824\u201324837, 2022.",
                "url": null
            }
        },
        {
            "50": {
                "title": "Sead: End-to-end text-to-sql generation with schema-aware denoising.",
                "author": "Kuan Xu, Yongbo Wang, Yongliang Wang, Zujie Wen, and Yang Dong.",
                "venue": "arXiv preprint arXiv:2105.07911, 2021.",
                "url": null
            }
        },
        {
            "51": {
                "title": "Sql-to-text generation with graph-to-sequence model.",
                "author": "Kun Xu, Lingfei Wu, Zhiguo Wang, Yansong Feng, and Vadim Sheinin.",
                "venue": "arXiv preprint arXiv:1809.05255, 2018.",
                "url": null
            }
        },
        {
            "52": {
                "title": "Sqlnet: Generating structured queries from natural language without reinforcement learning.",
                "author": "Xiaojun Xu, Chang Liu, and Dawn Song.",
                "venue": "arXiv preprint arXiv:1711.04436, 2017.",
                "url": null
            }
        },
        {
            "53": {
                "title": "React: Synergizing reasoning and acting in language models.",
                "author": "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.",
                "venue": "arXiv preprint arXiv:2210.03629, 2022.",
                "url": null
            }
        },
        {
            "54": {
                "title": "A syntactic neural model for general-purpose code generation.",
                "author": "Pengcheng Yin and Graham Neubig.",
                "venue": "arXiv preprint arXiv:1704.01696, 2017.",
                "url": null
            }
        },
        {
            "55": {
                "title": "Tabert: Pretraining for joint understanding of textual and tabular data.",
                "author": "Pengcheng Yin, Graham Neubig, Wen-tau Yih, and Sebastian Riedel.",
                "venue": "arXiv preprint arXiv:2005.08314, 2020.",
                "url": null
            }
        },
        {
            "56": {
                "title": "Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task.",
                "author": "Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, et al.",
                "venue": "arXiv preprint arXiv:1809.08887, 2018.",
                "url": null
            }
        },
        {
            "57": {
                "title": "Controlling large language model-based agents for large-scale decision-making: An actor-critic approach.",
                "author": "Bin Zhang, Hangyu Mao, Jingqing Ruan, Ying Wen, Yang Li, Shao Zhang, Zhiwei Xu, Dapeng Li, Ziyue Li, Rui Zhao, et al.",
                "venue": "arXiv preprint arXiv:2311.13884, 2023a.",
                "url": null
            }
        },
        {
            "58": {
                "title": "Act-sql: In-context learning for text-to-sql with automatically-generated chain-of-thought.",
                "author": "Hanchong Zhang, Ruisheng Cao, Lu Chen, Hongshen Xu, and Kai Yu.",
                "venue": "arXiv preprint arXiv:2310.17342, 2023b.",
                "url": null
            }
        },
        {
            "59": {
                "title": "Bertscore: Evaluating text generation with bert.",
                "author": "Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi.",
                "venue": "arXiv preprint arXiv:1904.09675, 2019.",
                "url": null
            }
        },
        {
            "60": {
                "title": "Seq2sql: Generating structured queries from natural language using reinforcement learning.",
                "author": "Victor Zhong, Caiming Xiong, and Richard Socher.",
                "venue": "arXiv preprint arXiv:1709.00103, 2017.",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.02951v2",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.1",
            "2.2",
            "2.3"
        ],
        "methodology_sections": [
            "3.1",
            "3.2",
            "3.3"
        ],
        "main_experiment_and_results_sections": [
            "4.1.1",
            "4.1.2",
            "4.2",
            "4.2.1",
            "4.2.2",
            "4.3",
            "4.4",
            "4.5"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "1",
            "3.1",
            "3.3",
            "4.1.1",
            "4.1.2",
            "4.2.1",
            "4.2.2",
            "4.3",
            "4.4",
            "4.5.2"
        ]
    },
    "research_context": {
        "paper_id": "2403.02951v2",
        "paper_title": "Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation",
        "research_background": "### Motivation\nThe motivation behind this paper is grounded in the transformative impact that Large Language Models (LLMs) have had on the field of Text-to-SQL, which automates the conversion of natural language (NL) questions into SQL queries. Such automation is crucial for enhancing user interaction with databases. The paper acknowledges the progression from traditional pattern matching and machine learning approaches to the more sophisticated and highly capable LLMs. LLMs have demonstrated substantial improvements in understanding complex NL queries and generating precise SQL statements, significantly advancing the state-of-the-art. Despite these advancements, there is a noteworthy gap in the systematic evaluation of LLMs in Text-to-SQL tasks. Comprehensive benchmarking is essential to address the challenges like overfitting, suboptimal prompt engineering strategies, and the need for detailed performance assessment across various sub-tasks of the Text-to-SQL process. This paper aims to fill this gap by developing a holistic and granular benchmarking framework.\n\n### Research Problem\nThe research problem this paper tackles is the absence of a comprehensive and systematic benchmarking approach for evaluating the capabilities of LLMs in Text-to-SQL tasks. Specifically, the paper identifies the following key challenges:\n1. The risk of overfitting in LLMs trained on coding tasks and open-source datasets.\n2. The lack of consensus on optimal prompt engineering strategies for guiding LLMs.\n3. The need for a detailed evaluation of not only end-to-end Text-to-SQL performance but also the performance across various sub-tasks and components of the process.\n\n### Relevant Prior Work\nThe paper builds upon several previous research efforts and advancements:\n- Early efforts in Text-to-SQL primarily focused on pattern matching and machine learning models for mapping NL to SQL (Zhong et al., 2017; Li et al., 2023a).\n- The introduction of powerful LLMs has significantly transformed this field, showcasing advanced reasoning and in-context learning capabilities (Dong et al., 2023; Pourreza and Rafiei, 2024).\n- Existing benchmarks like Spider (Yu et al., 2018) and BIRD (Li et al., 2024) have driven improvements but lack a comprehensive evaluation framework (Katsogiannis-Meimarakis and Koutrika, 2023; Qin et al., 2022).\n- The issues of overfitting and standardizing prompt engineering strategies remain unaddressed (Roziere et al., 2023; Gao et al., 2023).\n\nIn summary, this paper aims to establish a more granular and comprehensive benchmarking approach to evaluate LLMs for Text-to-SQL tasks across multiple dimensions, thereby contributing to the development of more effective and reliable solutions in this domain.",
        "methodology": "The proposed method in this study involves using Large Language Models (LLMs) to convert natural language questions into executable SQL queries. To elaborate:\n\n1. **System and Inputs**:\n   - **Natural Language Question (Q)**: This represents the query in plain language that needs to be converted into an SQL query.\n   - **Database Schema (D)**: This is detailed as a tuple \\( D = (T, C, F) \\), where:\n     - \\( T \\) represents the tables in the database.\n     - \\( C \\) represents the columns within those tables.\n     - \\( F \\) represents the foreign key relationships among tables.\n\n2. **Objective**:\n   - The main goal is to generate a SQL query \\( S \\) such that it is executable and correctly reflects the intent of the natural language question \\( Q \\).\n\n3. **Generation Process**:\n   - **Prompt Template (P)**: A predefined template used as an initial input for the LLM.\n   - The LLM generates the SQL query \\( S \\) as a sequence of tokens based on the template \\( P \\) and given the question \\( Q \\) and schema \\( D \\).\n\n4. **Formal Definition**:\n   - The generation of the SQL query \\( S \\) by an LLM (denoted as \\( \\mathcal{M} \\)) is formulated as a conditional probability distribution. This is expressed as:\n     \\[\n     P(S|P,Q,D)\n     \\]\n     where the LLM generates each token \\( s_i \\) (the \\( i \\)-th token of the SQL query \\( S \\)) in an autoregressive manner, considering all previous tokens up to \\( s_{i-1} \\). \n   - The length of the query \\( S \\) is denoted as \\( l \\), hence the sequence of tokens \\( s_1, s_2, \\ldots, s_l \\) is produced.\n\nIn summary, the method leverages the powerful capabilities of LLMs to sequentially generate SQL query tokens by conditioning on the natural language question, the database schema, and a predefined prompt template, ensuring the generated SQL query is both executable and true to the user's intent.",
        "main_experiment_and_results": "### Main Experiment Setup\n\nThe main experiment aims to benchmark the Text-to-SQL capability of Large Language Models (LLMs) through the design and evaluation of various prompt templates, a process referred to as prompt engineering. The primary aspects of the main experiment setup include:\n\n1. **Datasets**:\n   - **Spider Dev Set**: The primary dataset used to evaluate the performance of the LLMs with different prompt templates.\n\n2. **Baselines**:\n   - **Prompt Templates**: The experiment tests a series of unified prompt templates that vary across three specific features:\n     - **DDL/SimpleDDL Prefix**: \n       - \"DDL\" includes detailed information necessary for database creation (column types, primary/foreign keys).\n       - \"SimpleDDL\" is simplified by only including table and column names.\n     - **MD/HTML/Coding Infix**:\n       - Wrapping the entire prompt template with Markdown syntax, HTML snippets, or code comment blocks.\n     - **Complete/Chat Postfix**:\n       - Indicates the task of either completing SQL statements based on the \"SELECT\" clause (Complete) or directly answering questions (Chat).\n\n3. **Evaluation Metrics**:\n   - **Performance on the Spider Dev Set**: The templates are evaluated based on their ability to generate accurate SQL queries when applied to the Spider dev set.\n\n### Main Experimental Results\n\nThe results indicate that the \"SimpleDDL-MD-Chat\" prompt template outperforms all other tested templates. Specifically:\n\n- **Performance**:\n  - The \"SimpleDDL-MD-Chat\" prompt template consistently yielded the best performance across all 5 backbone LLMs tested.\n  - This template was subsequently used for all further evaluations within the paper due to its superior results.\n\nOverall, the main experiment concludes that the \"SimpleDDL-MD-Chat\" prompt template is the most effective for the Text-to-SQL task among the ones evaluated."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To determine the optimal prompt template for LLM-based Text-to-SQL tasks and analyze the performance impacts of different prompt features.",
            "experiment_process": "Researchers tested various prompt templates on the Spider dev set, combining features such as DDL/SimpleDDL prefix, MD/HTML/Coding infix, and Complete/Chat postfix. The performance of LLMs was assessed to identify the best combination.",
            "result_discussion": "The prompt template 'SimpleDDL-MD-Chat' consistently outperformed other combinations across all 5 backbone LLMs, establishing it as the optimal choice for generating accurate SQL queries.",
            "ablation_id": "2403.02951v2.No1"
        },
        {
            "research_objective": "To evaluate the end-to-end Text-to-SQL capabilities of various LLMs using an optimal prompt template on a novel dataset.",
            "experiment_process": "The study employed the 'SimpleDDL-MD-Chat' prompt template on the 'BigTable-0.2k' dataset. The performance of various LLMs, including SQLCoder, CodeLlama, InternLM, and Llama2-Chat, was compared based on the execution accuracy (EX) metric.",
            "result_discussion": "The results highlighted a performance hierarchy among the models, with SQLCoder and CodeLlama leading, followed by InternLM and Llama2-Chat. Performance decreased as the complexity of queries, measured by the number of GT tables, increased.",
            "ablation_id": "2403.02951v2.No2"
        },
        {
            "research_objective": "To improve the debugging capabilities of LLMs for Text-to-SQL systems by utilizing granular error information.",
            "experiment_process": "The study proposed five self-debugging strategies, progressively incorporating detailed error information, and assessed their performance on error datasets. Strategies ranged from simply regenerating the SQL query to providing detailed error information and comments.",
            "result_discussion": "More granular error information improved self-debugging performance, with 1-2 rounds of debugging being most efficient. However, cross-LLM error debugging showed limited success, highlighting the potential for a multi-agent approach in future research.",
            "ablation_id": "2403.02951v2.No3"
        },
        {
            "research_objective": "To evaluate the SQL optimization capabilities of LLMs for improving query execution efficiency.",
            "experiment_process": "Various prompt templates, including basic forms and ones with additional information, few-shot demonstrations, and comments, were used to optimize SQL queries. The effectiveness of these methods was evaluated using VES and C-VES metrics.",
            "result_discussion": "Two-stage methods showed a decrease in VES due to incorrect optimizations. Directly instructing LLMs to generate efficient SQL queries surprisingly yielded better accuracy and suggested higher expectations could improve LLM outcomes in SQL optimization.",
            "ablation_id": "2403.02951v2.No4"
        },
        {
            "research_objective": "To transform SQL queries back into natural language questions and assess the semantic comprehension capabilities of LLMs.",
            "experiment_process": "Various LLMs were tested on SQL-to-Text tasks, using F1 values of Rouge-1/2/L and BertScore, along with LLM assessments for semantic coherence between generated text and original questions.",
            "result_discussion": "General-purpose models like ChatGPT and InternLM2 performed better in semantic descriptions compared to coding-specific models like Codellama and SQLCoder, indicating the former's superiority for SQL-to-text tasks.",
            "ablation_id": "2403.02951v2.No5"
        },
        {
            "research_objective": "To evaluate different schema linking methods and measure the impact of incorporating foreign key information.",
            "experiment_process": "The study assessed various schema linking prompts, including Zero Shot, Few Shot, PreSQL, and Few Shot + PreSQL, with and without foreign key information. Performance was evaluated based on schema retrieval accuracy.",
            "result_discussion": "Foreign keys improved performance across all methods and LLMs. Code-specific models excelled with PreSQL, while the Few Shot + PreSQL method worked best for general-purpose models, highlighting the benefits of combining semantic understanding and structured information.",
            "ablation_id": "2403.02951v2.No6"
        }
    ]
}