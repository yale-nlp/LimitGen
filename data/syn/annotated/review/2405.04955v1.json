{
    "title": "Improving Long Text Understanding with Knowledge Distilled from Summarization Model",
    "abstract": "Long text understanding is important yet challenging for natural language processing. A long article or document usually contains many redundant words that are not pertinent to its gist and sometimes can be regarded as noise.\nWith recent advances of abstractive summarization, we propose our Gist Detector to leverage the gist detection ability of a summarization model and integrate the extracted gist into downstream models to enhance their long text understanding ability.\nSpecifically, Gist Detector first learns the gist detection knowledge distilled from a summarization model, and then produces gist-aware representations to augment downstream models.\nWe evaluate our method on three different tasks: long document classification, distantly supervised open-domain question answering, and non-parallel text style transfer. The experimental results show that our method can significantly improve the performance of baseline models on all tasks.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Recently, deep learning has developed rapidly [1  ###reference_b1###, 2  ###reference_b2###, 3  ###reference_b3###, 4  ###reference_b4###, 5  ###reference_b5###, 6  ###reference_b6###, 7  ###reference_b7###, 8  ###reference_b8###, 9  ###reference_b9###, 10  ###reference_b10###, 11  ###reference_b11###, 12  ###reference_b12###]. Transformer-based models are prevalent [13  ###reference_b13###, 14  ###reference_b14###, 15  ###reference_b15###, 16  ###reference_b16###, 17  ###reference_b17###, 18  ###reference_b18###] across numerous NLP tasks[19  ###reference_b19###], but have difficulty in processing long texts due to the quadratic complexity of input text length[20  ###reference_b20###].\nUnlike short texts, long texts intrinsically contain many noisy words irrelevant to their gist.\nAlthough recent works have achieved promising results, few of them pay attention to measuring whether each part of the text is salient or negligible.\nAbstractive summarization is a classic NLP task which aims to compress and rewrite a source text into a short version while retaining its main information [21  ###reference_b21###, 22  ###reference_b22###].\nWith this optimization objective, a well-trained summarization model has the potential to detect the gist of long texts.\nFigure 1  ###reference_### shows an example from the CNN/Daily Mail [23  ###reference_b23###] dataset, where the blue shading intensity represents the importance weight extracted from a well-trained summarization model. As we can see, the summarization model learns to focus on gist-relevant parts while neglecting irrelevant ones.\nIntuitively, the gist detection ability can improve long text understanding through making models aware of salient parts of long texts.\n###figure_1### In this paper, we propose to leverage the gist detection ability of a summarization model and integrate the distilled gist information into downstream models to enhance their long text understanding ability.\nHowever, there remain two challenges:\nFirst, it is time-consuming to extract salient information from a large summarization model for each training sample.\nSecond, the summarization model produces salient information at each decoding step, while long text understanding models produce a single representation.\nTo solve these challenges, we propose our Gist Detector to transfer the gist information from a summarization model to downstream long text understanding models.\nSpecifically, Gist Detector is first trained to reproduce the gist information from the summarization model, then provides the gist-aware representation as supplementary to augment long text understanding models.\nWe train our Gist Detector with knowledge distillation mechanism, where a summarization model with an encoder-decoder architecture is the teacher model and Gist Detector with a fewer-layers\u2019 encoder is the student model.\nThe student model is trained with the average attention distribution over all decoding steps produced by the teacher model as \u201dsoft target\u201d.\nSince Gist Detector is a non-autogressive model and much smaller than the summarization model, the process of gist extraction can be significantly efficient.\nThen, we integrate the gist information extracted by our distilled Gist Detector into downstream models with a fuse module, effectively enhancing their long text understanding ability.\nTo evaluate the effectiveness of our method, we conduct extensive experiments on three tasks: long document classification, distantly supervised open-domain question answering (DS-QA) and non-parallel text style transfer. Experimental results reveal that our method effectively augments different baseline models with better long text understanding ability, thus achieving significant performance improvement on all downstream tasks.\n###figure_2###"
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Methodology",
            "text": "In this paper, we propose our Gist Detector to leverage the gist detection ability of summarization model, and transfer gist information into downstream long text understanding models.\nWe first introduce the architecture of Gist Detector ( \u00a7 4.1  ###reference_###).\nDuring training, we use the knowledge distillation mechanism to transfer the gist detection ability from a well-trained summarization model (teacher model) to Gist Detector (student model) (\u00a7 2.2  ###reference_###).\nThen, we integrate gist information extracted by Gist Detector into downstream models (\u00a7 2.3  ###reference_###).\nThe much smaller model size and the non-autogressive architecture reduce the time-consuming problem, and the generated single gist-aware representation overcomes the mismatch problem."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Gist Detector Architecture",
            "text": "As shown in middle part of Figure 2  ###reference_###, Gist Detector has an encoder architecture, which learns the importance weight of each word in the source sequence from the summarization model, and produces this information for downstream models.\nThere are many possible network architectures for Gist Detector.\nWe implement our Gist Detector with several Transformer encoder layers [24  ###reference_b24###], and show that the a simple distilled Gist Detector can successfully benefit the long document understanding models.\nSpecifically, the input  is firstly mapped into embeddings , then fed into a four-layer transformer encoder and obtain the representations .\nThen, a two-layer MLP followed by a softmax function is applied to produce the the probability distribution over the input text , which reveals the importance of each word in the source sequence."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Training with knowledge distillation",
            "text": "We leverage the knowledge distillation mechanism to train Gist Detector (student model) with the salient information extracted from the abstractive summarization model (teacher model).\nDifferent from the typical knowledge distillation, which uses the teacher\u2019s predictive distribution over the target classes as the soft target, we assume the attention distribution extracted from the decoding process reveals the salient information of the source text, and use the teacher\u2019s attention distribution as the soft target. The student model learns to reproduce the attention distribution for each training sample.\nSpecifically, the soft target  is calculated as the geometric mean of the attention distribution over all decoding steps:\n, where  is the total decoding steps.\nFinally, the optimization objective is the cross entropy between the predicted probability distribution  of the student model and the soft target  from the teacher model:"
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "Integration of salient information",
            "text": "To enhance the long document understanding ability of the downstream model, we extract the salient information from the well-trained Gist Detector, and integrate it into the downstream model with a fuse module.\nSpecifically, for each long text  as the input, the Gist Detector produces the probability distribution  over the input text, revealing the importance weights of each word.\nGiven the context representation of the long document understanding model , we fuse the context representation  with the importance weights  as:\n, where  is a tunable hyperparameter.\nAs for the downstream model that predict scores for each word of the input text, such as extractive QA models, we fuse the prediction scores  with the importance weights :\nNote that we use the importance weight rather than the context representation as the salient information, since it contains much less parameters and alleviates the impact of domain-specific information."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": ""
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Distillation",
            "text": "Firstly, We train an ensemble of  abstractive summarization models with Transformer-based encoder-decoder architecture as the teacher model on CNN/Daily Mail. The average ROUGE  scores [25  ###reference_b25###] of the teacher model are ,  and  for ROUGE-1, ROUGE-2 and ROUGE-L respectively.\nWe follow the same setup and use the scripts provided by [26  ###reference_b26###] to pre-process the CNN/Daily Mail dataset.\nWe use the  dimensional filters with width of  for CNN to capture the character embeddings.\nWe select the d GloVe pre-trained word embedding and share the same word embedding weight between encoder and decoder.\nThe hidden size of Transformer is . We use the Adam optimizer [27  ###reference_b27###] with learning rate of ,  = ,  = . The dropout rate and batch size are set to  and , respectively. To avoid the gradient explosion problem, we apply the gradient norm clipping with a maximum gradient norm of .\nThen we train Gist Detector with Transformer-based encoder architecture using knowledge distillation mechanism. We use 100d GloVe for word embedding, d for character embedding, the hidden size for the Transformer encoder is . We take the same optimization setting as that of the teacher model."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Integration into Downstream Tasks",
            "text": "Finally, we transfer the salient information from the well-trained Gist Detector to downstream models of three long text understanding tasks: document classification, distantly supervised open-domain question answering (DS-QA) and non-parallel text style transfer."
        },
        {
            "section_id": "3.2.1",
            "parent_section_id": "3.2",
            "section_name": "3.2.1 Document Classification:",
            "text": "We take the BiLSTM model as our baseline model for document classification task that concatenates the final state values of forward and backward pass as the context representation vector, then feeds it into a MLP to predict the label.\nWe initialize the word embedding with the d GloVe.\nThe hidden size of BiLSTM is set as . The layer number of BiLSTM and MLP are both set to . We take the Adam as optimizer with lr = ,  = ,  = ,  dropout and train for  epochs.\nThe  in \u00a7 2.3  ###reference_### is set to be  while integrating the BiLSTM model with our Gist Detector."
        },
        {
            "section_id": "3.2.2",
            "parent_section_id": "3.2",
            "section_name": "3.2.2 Distantly Supervised Open-Domain QA:",
            "text": "We use the OpenQA model[28  ###reference_b28###] as our baseline model for distantly supervised open-domain question answering task, which applies a selector to filter passages, then a precise reader to extract the potential answers, finally aggregates these results to predict the final answer.\nWe evaluate our method on two high-quality datasets, TriviaQA (open-domain setting)[29  ###reference_b29###] and SearchQA[30  ###reference_b30###] with two metrics including ExactMatch (EM) and F1 scores.\nWe keep the same setup of hyper-parameters and training settings as that in OpenQA while some important details are as follow. We combine the passage selector with Gist Detector as introduced in \u00a7 2.3  ###reference_### and the  is set as 0.5. We feed the  through a linear function followed by multiplication with the question vector to produce the score for filtering passages and add it to the original score produced by the OpenQA selector to predict the final passage score. For the reader, we directly add the predicted score of answer span with the probability distribution  produced by Gist Detector as introduced in \u00a7 2.3  ###reference_### to produce the final score, where the  is set as ."
        },
        {
            "section_id": "3.2.3",
            "parent_section_id": "3.2",
            "section_name": "3.2.3 Text Style Transfer:",
            "text": "As for the non-parallel text style transfer task, the model aims to compress gist of texts into fixed-size vectors separated from pure style information.\nWe select Cross-aligned AE[31  ###reference_b31###] and Adversarially Regularized Autoencoder (ARAE)[32  ###reference_b32###] as our baseline models.\nWe follow the setup of [31  ###reference_b31###] but remain reviews whose length are between  and  rather than not exceeding , and eventually obtain K, K non-parallel data from Amazon and Yelp reviews respectively. We keep the same setup of hyper-parameters and training settings as that of Cross-aligned AE and ARAE. We combine the content vector with our Gist Detector as introduced in \u00a7 2.3  ###reference_###, and the  is set to be .\nTo evaluate the model, we use  automatic metrics: (i) Acc: the accuracy of successfully changing the style into the target style measured by a pre-trained classifier. Following [31  ###reference_b31###], we use the TextCNN model as the classifier that achieves the accuracy of  and  on Amazon and Yelp respectively. (ii) Cosine: we follow the setup of [33  ###reference_b33###] to measure the content preservation with cosine similarity.\n(iii) Entity: we use the proportion of noun entities to measure the content consistency between source and generated texts. (iv) PPL: the fluency of generated texts measured by a pre-trained language model on corresponding datasets."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Results and Analysis",
            "text": ""
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Results on DS-QA",
            "text": "We evaluate our method on TriviaQA (open-domain setting) [29  ###reference_b29###] and SearchQA [30  ###reference_b30###] datasets with ExactMatch (EM) and F1 score metrics.\nAs shown in Table 2  ###reference_###,\nAugumented with our Gist Detector, the baseline OpenQA model performs much better on both two datasets.\nAn ablation study shows that integration of salient information into both the selector and the reader leads to the best performance.\nTable 3  ###reference_### shows the passage selection performance of our method.\nWe find that with Gist Detector, the selector filters passages much more precisely, thus our QA system can aggregate information among fewer passages and make faster answer predictions."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Results on Text Style Transfer",
            "text": "We further evaluate our method on the Amazon and Yelp text style transfer dataset [31  ###reference_b31###].\nThe automatic evaluation results from Table 4  ###reference_### shows that with our Gist Detector, the baseline model ARAE[32  ###reference_b32###] can achieve significantly higher transfer accuracy, better content preservation, better noun entity preservation and much more fluency.\nIt indicates that the Gist Detector helps the model detect and compress more important information from long texts.\nMoreover, we conduct human evaluation to further evaluate the quality of the style transfer models.\nWe randomly select  examples ( positive/negative), and employ people to judge whether texts are converted to the target style, and to evaluate content correlation (,  for the most correlative) and fluency (,  for the most fluent).\nAs shown in Table 5  ###reference_###, Gist Detector can significantly improve the baseline model\u2019s performance on all evaluation metrics."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we propose Gist Detector to learn gist detection ability from a summarization model with knowledge distillation mechanism. We integrate the gist information detected by distilled Gist Detector into different downstream models to enhance their long document understanding ability.\nExperimental results show that our method significantly improves the performance of all baseline models for different tasks that require long text understanding.\nFuture work will involve finding better strategies to integrate our gist detector into more tasks and processing longer sequences."
        }
    ],
    "url": "http://arxiv.org/html/2405.04955v1",
    "segmentation": {
        "research_background_sections": [
            "1"
        ],
        "methodology_sections": [
            "2",
            "2.1",
            "2.2",
            "2.3"
        ],
        "main_experiment_and_results_sections": [
            "3.1",
            "3.2",
            "3.2.1",
            "3.2.2",
            "3.2.3",
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "research_context": {
        "paper_id": "2405.04955v1",
        "paper_title": "Improving Long Text Understanding with Knowledge Distilled from Summarization Model",
        "research_background": "### Paper's Motivation, Research Problem, and Relevant Prior Work\n\n#### Motivation:\nThe primary motivation behind this paper is the challenge of effectively understanding long texts using Transformer-based models, which are common in numerous NLP tasks. Despite these models\u2019 prevalence, they struggle with long text processing due to the quadratic complexity regarding input text length. Long texts often contain extraneous noise that does not contribute to their main content, necessitating a way to discern important information from the noise. The authors aim to leverage the gist detection capabilities of summarization models to help downstream models better understand and process long texts.\n\n#### Research Problem:\nThe paper addresses two main challenges:\n1. **Time-Consumption**: Extracting salient information from a large summarization model for each training sample is time-consuming.\n2. **Representation Discrepancy**: While summarization models produce salient information at each decoding step, long text understanding models generate a single representation, posing a challenge for integration.\n\nTo tackle these challenges, the paper proposes the development of a Gist Detector that can efficiently transfer the gist information from a summarization model to downstream long text understanding models.\n\n#### Relevant Prior Work:\n1. **Deep Learning and Transformer-based Models**: References in the first section ([1-12]) indicate the rapid development of deep learning. Transformer-based models are highlighted ([13-18]) for their widespread use across NLP tasks ([19]).\n2. **Challenges of Processing Long Texts**: The difficulty of processing long texts due to their quadratic complexity ([20]) is noted.\n3. **Abstractive Summarization Models**: References ([21-22]) provide background on abstractive summarization models that aim to compress and maintain the main information of the source text. These models have the potential to identify the gist of long texts, implied by their intrinsic design ([23]).\n\nBy incorporating distilled gist information from summarization models, the authors propose a method to overcome the two highlighted challenges and improve the understanding of long texts in various downstream tasks.",
        "methodology": "In this paper, we propose our Gist Detector to leverage the gist detection ability of a summarization model and transfer gist information into downstream long text understanding models. \n\n**Training Process**: \n2. **Knowledge Distillation Mechanism (\u00a7 2.2)**: \n    - **Teacher Model**: A well-trained summarization model that possesses strong gist detection ability.\n    - **Student Model**: Gist Detector, which learns from the teacher model using the knowledge distillation process. Through this process, the Gist Detector acquires the capability to detect the gist from long texts effectively.\n\n**Integration into Downstream Models**: \n3. **Gist Information Integration (\u00a7 2.3)**: The essence of the text, captured by the Gist Detector, is integrated into downstream models to improve their understanding and processing of long texts.\n\n**Advantages and Innovations**:\n- **Reduced Model Size**: The Gist Detector has a smaller model size compared to traditional summarization models, which helps in mitigating computational demands.\n- **Non-Autoregressive Architecture**: This architecture reduces processing time by not relying on sequential steps.\n- **Single Gist-Aware Representation**: The generated single gist-aware representation helps in overcoming the mismatch problem often encountered with traditional approaches.\n\nBy leveraging these key components and innovations, the Gist Detector enhances the efficiency and effectiveness of long text understanding models.",
        "main_experiment_and_results": "**Main Experiment Setup and Results:**\n\n**Experiment Setup:**\n1. **Teacher Model Setup:**\n   - **Model Architecture:** An ensemble of abstractive summarization models with a Transformer-based encoder-decoder architecture.\n   - **Dataset:** CNN/Daily Mail dataset.\n   - **Metrics:** Average ROUGE scores (specifically ROUGE-1, ROUGE-2, ROUGE-L).\n   \n2. **Pre-processing:**\n   - **Scripts:** Followed the same setup and scripts provided by [reference 26] to pre-process the CNN/Daily Mail dataset.\n\n3. **Model Configurations:**\n   - **Filters:** CNN with dimensional filters of width  for capturing character embeddings.\n   - **Embeddings:** \n     - Used a d GloVe pre-trained word embedding.\n     - Shared the same word embedding weight between the encoder and decoder.\n   - **Transformer Settings:**\n     - Hidden size: \n   - **Optimization Setup:**\n     - Optimizer: Adam optimizer [reference 27].\n     - Learning Rate: .\n     - Parameters:  = ,  = .\n   - **Regularization:** \n     - Dropout rate: .\n     - Batch size: .\n   - **Gradient Clipping:** Applied gradient norm clipping with a maximum gradient norm of .\n\n4. **Student Model (Gist Detector):**\n   - **Architecture:** Transformer-based encoder architecture.\n   - **Knowledge Distillation:** \n     - Used knowledge distillation mechanism from the trained teacher model.\n   - **Embeddings:**\n     - Word embedding: 100d GloVe.\n     - Character embedding: d.\n   - **Transformer Settings:**\n     - Hidden size: .\n   - **Optimization:** Same optimization settings as the teacher model.\n\n**Evaluation Metrics:**\n- **ROUGE Scores:**\n  - ROUGE-1\n  - ROUGE-2\n  - ROUGE-L\n\n**Main Experimental Results:**\n- The average ROUGE scores for the teacher model on the CNN/Daily Mail dataset are , , and  for ROUGE-1, ROUGE-2, and ROUGE-L respectively. (Specific numerical values for these scores are missing from the provided text).\n\nNote: The main experimental results section is focused on the performance of the ensemble of abstractive summarization models indicated by the average ROUGE scores on the CNN/Daily Mail dataset. \n\nEnsure the specific numerical values for the ROUGE scores are inserted where indicated to complete the main experimental results accurately."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To evaluate the impact of the Gist Detector on improving long document classification.",
            "experiment_process": "The BiLSTM model is augmented with the Gist Detector and evaluated on the FDU-MTL datasets. The performance is compared across different domains against prior approaches (ASP-MTL, S-LSTM, Meta-MTL) using overall accuracy as a metric. An ablation is conducted where the Gist Detector is initialized with random parameters to assess its contribution.",
            "result_discussion": "The BiLSTM model augmented with the Gist Detector shows significant performance improvements across all domains, outperforming prior approaches. The ablation study indicates that both the additional parameters from the Gist Detector and the gist detection ability from the summarization model contribute to this performance enhancement.",
            "ablation_id": "2405.04955v1.No1"
        },
        {
            "research_objective": "To determine the effect of integrating Gist Detector on the performance of open-domain question answering (OpenQA).",
            "experiment_process": "The OpenQA baseline model is enhanced with the Gist Detector and evaluated on TriviaQA and SearchQA datasets using ExactMatch (EM) and F1 score metrics. An ablation study examines the impact of incorporating salient information into both the selector and the reader components of the model.",
            "result_discussion": "The enhanced OpenQA model performs significantly better on both datasets. The integration of salient information into both selector and reader components leads to the best performance. Additionally, the passage selection performance improves, enabling the QA system to aggregate information more efficiently and make faster predictions.",
            "ablation_id": "2405.04955v1.No2"
        },
        {
            "research_objective": "To assess the effectiveness of the Gist Detector in enhancing text style transfer capabilities.",
            "experiment_process": "The baseline model ARAE is augmented with the Gist Detector and evaluated on Amazon and Yelp text style transfer datasets. The evaluation includes automatic metrics such as transfer accuracy, content preservation, noun entity preservation, and fluency. Human evaluation is also conducted by randomly selecting examples and having evaluators judge the quality, content correlation, and fluency of the transferred texts.",
            "result_discussion": "The model augmented with Gist Detector achieves significantly higher scores in transfer accuracy, content preservation, noun entity preservation, and fluency. Human evaluations further indicate substantial improvements in style transfer quality, content correlation, and fluency metrics.",
            "ablation_id": "2405.04955v1.No3"
        }
    ]
}