{
    "title": "A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation",
    "abstract": "Knowledge-based, open-domain dialogue generation aims to build chit-chat systems that talk to humans using mined support knowledge. Many types and sources of knowledge have previously been shown to be useful as support knowledge. Even in the era of large language models, response generation grounded in knowledge retrieved from additional up-to-date sources remains a practically important approach. While prior work using single-source knowledge has shown a clear positive correlation between the performances of knowledge selection and response generation, there are no existing multi-source datasets for evaluating support knowledge retrieval. Further, prior work has assumed that the knowledge sources available at test time are the same as during training. This unrealistic assumption unnecessarily handicaps models, as new knowledge sources can become available after a model is trained. In this paper, we present a high-quality benchmark named multi-source Wizard of Wikipedia (Ms.WoW) for evaluating multi-source dialogue knowledge selection and response generation. Unlike existing datasets, it contains clean support knowledge, grounded at the utterance level and partitioned into multiple knowledge sources. We further propose a new challenge, dialogue knowledge plug-and-play, which aims to test an already trained dialogue model on using new support knowledge from previously unseen sources in a zero-shot fashion.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1.   Introduction",
            "text": "Knowledge-based open-domain dialogue generation aims to build chit-chat systems that talk to humans on various domains with mined support knowledge.\nMany types of knowledge have been shown to be useful as support knowledge, such as encyclopedias Dinan et al. (2019  ###reference_b6###), knowledge graphs Wu et al. (2019  ###reference_b27###); Zhou et al. (2020  ###reference_b32###); Liu et al. (2021  ###reference_b14###), personas Zhang et al. (2018  ###reference_b30###), and commonsense knowledge Zhou et al. (2018  ###reference_b31###); Zhang et al. (2020  ###reference_b29###); Wu et al. (2021  ###reference_b26###); Varshney et al. (2022  ###reference_b23###).\nFurther, Shuster et al. (2022  ###reference_b20###) have demonstrated that multiple knowledge sources are helpful on top of large-scale, pre-trained language models. Even in the era of large language models (LLMs; Brown et al., 2020  ###reference_b1###; OpenAI, 2023  ###reference_b17###; Touvron et al., 2023  ###reference_b22###), which use internally learned knowledge from their pretraining corpora for zero- or few-shot predictions, knowledge can become outdated. Thus, response generation grounded in knowledge retrieved from additional up-to-date sources is still a practically important approach.\nPrevious studies using single-source knowledge for response generation have shown a clear positive correlation between the performances of knowledge selection and response generation Dinan et al. (2019  ###reference_b6###); Li et al. (2022  ###reference_b11###). In this work, we aim to extend these results to multi-source knowledge and further propose a new challenge task, dialogue knowledge plug-and-play. We address two major challenges facing multi-source knowledge-based dialogue generation. First, there are no existing multi-source datasets for evaluating support knowledge retrieval. Prior work used non-knowledge-based dialogue datasets with silver support knowledge labeled using unsupervised approaches Liu et al. (2019b  ###reference_b15###); Wu et al. (2021  ###reference_b26###); they could only measure the final response generation performance, without being able to evaluate the support knowledge selection module.\nAs a result, results achieved on these datasets lack interpretability: the relationship between the quality of knowledge selection and response generation is unclear, adding an extra layer of difficulty in improving models\u2019 performance.\nSecond, prior work has assumed that the knowledge sources available at test time are the same as during training. We argue that this is an unrealistic assumption that unnecessarily handicaps models. New knowledge sources can become available after a model is trained: new knowledge graphs are published, or new types of knowledge are shown to be useful for dialogue generation. Information present only in a new knowledge source (for example, about a recent newsworthy event) may be crucial in a conversation with a real user. To make use of such information, it is necessary to ensure that trained dialogue generation models are robust to the addition of new knowledge sources at inference time: the new source should improve, or at the very least not harm, a model\u2019s performance.\nTo overcome these challenge, we present a high-quality benchmark named multi-source Wizard of Wikipedia (Ms.WoW)111https://github.com/jacklxc/Ms.WoW  ###reference_github.com/jacklxc/Ms.WoW### for evaluating multi-source dialogue knowledge selection and response generation. Unlike existing datasets, it contains clean, gold support knowledge, grounded at the utterance level and partitioned into multiple knowledge \u201csources.\" We build Ms.WoW on top of the Wizard of Wikipedia (WoW, Dinan et al. 2019  ###reference_b6###), which annotates utterance-level, grounded support knowledge sentences. We partition the knowledge in WoW into different \u201csources,\" including OPIEC Gashteovski et al. (2019  ###reference_b7###), semantic frames, and Wikidata, to simulate multiple knowledge sources containing complementary information.\nUsing the Ms.WoW dataset, we introduce the dialogue knowledge plug-and-play challenge task, which aims to test an already trained dialogue model on using new support knowledge from previously unseen sources in a zero-shot fashion. The plug-and-play task extends WoW to the real-world scenario where the knowledge sources available at inference time are different from those available during training. Thus, Ms.WoW is a test bed for both evaluating the effect of multi-source knowledge selection on dialogue response generation, as well as simulating the challenging zero-shot knowledge source adaptation scenario.\nPepsiCo was formed in 1965 with the merger of the Pepsi-Cola Company and Frito-Lay, Inc. PepsiCo has since expanded from its namesake product Pepsi to a broader range of food and beverage brands, the largest of which included an acquisition of Tropicana Products in 1998 and the Quaker Oats Company in 2001, which added the Gatorade brand to its portfolio.\n(\u2018\u2019, \u2018formed\u2019, \u2018PepsiCo\u2019, \u2018in 1965\u2019, \u2018\u2019)\n(\u2018its\u2019, \u2018\u2019, \u2018has\u2019, \u2018namesake product Pepsi\u2019, \u2018\u2019, \u2018\u2019)\n(\u2018largest of which\u2019, \u2018\u2019, \u2018have included acquisition of Tropicana Products in 1998\u2019, \u2018beverage brands\u2019, \u2018\u2019, \u2018\u2019)\n(\u2018largest of which\u2019, \u2018\u2019, \u2018have included Quaker Oats Company in 2001\u2019, \u2018food brands\u2019, \u2018\u2019, \u2018\u2019)\n(\u2018Quaker Oats Company in 2001\u2019, \u2018\u2019, \u2018added Gatorade brand to\u2019, \u2018portfolio\u2019, \u2018\u2019, \u2018\u2019)\n(\u2018Frito-Lay\u2019, \u2018parent organization\u2019, \u2018PepsiCo\u2019)\n(\u2018Pepsi\u2019, \u2018instance of\u2019, \u2018cola\u2019)"
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2.   Background & Related Work",
            "text": ""
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2.   Plug-and-play",
            "text": "The concept of plug-and-play has been introduced in the context of studying language models\u2019 ability to adapt to new knowledge. Dathathri et al. (2020  ###reference_b5###) proposed a Plug and Play Language Model (PPLM) for controllable language generation. Xu et al. (2021  ###reference_b28###) proposed K-PLUG, a knowledge-injected, pre-trained language model for e-commerce that handles information such as item category and attributes in key-value pairs, as well as item summaries and descriptions in plain text. In this work, we use our new Ms.WoW dataset and the task of multi-source dialogue knowledge selection and response generation to study the problem of dialogue knowledge plug-and-play."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3.   Multi-Source Wizard of Wikipedia Dataset",
            "text": "We use spaCy to extract entities and noun phrases from each sentence, filtered with NLTK555https://www.nltk.org/  ###reference_www.nltk.org/### stop words.\nWe pass each extracted entity or noun phrase, along with its original sentence as context, to a dense retrieval-based entity linker Wu et al. (2020  ###reference_b25###) to obtain the corresponding Wikidata entities. We take the top-1 Wikidata entity candidate for each extracted entity or noun phrase.\nWe retrieve all Wikidata triplets that contain at least one of the linked entities.\nWe keep only triplets whose subjects and objects both match the corresponding WoW knowledge sentence, requiring one of the following conditions:\nboth the subject and object entities in the triplet appear in the set of linked Wikidata entities extracted from the WoW sentence, or\nthe subject and object both match the WoW sentence using a fuzzy matcher666https://spacy.io/universe/project/spaczz  ###reference_### with score higher than .\nFor each WoW knowledge sentence, we keep only triplets whose entities cover more than 75% of the extracted entity set of the sentence.\nIn order to minimize information loss when we replace each WoW sentence with the retrieved tuples, we filter out those sentences whose retrieved tuples can only partially cover their semantics. We tokenize and lemmatize each WoW knowledge sentence and remove punctuation and stop words to create a bag of words  for each sentence. Then we concatenate all retrieved tuple elements from the three sources to create a pseudo-sentence and its corresponding bag of words . We only keep those sets of tuples whose  covers more than 60% of .\nThis filtering step results in the creation of a fourth, supplementary knowledge source: Wikipedia sentences (w.p.) from the original WoW that could not be adequately captured by tuples from the other three sources.\nSince the knowledge tuples are retrieved independently from the three sources, some are redundant with each other. Since our goal is to partition the knowledge into complementary sources, we perform deduplication to remove redundant tuples. Given the full-coverage bag of words , we want to select the minimum number of tuples that maximally cover . We formulate this goal as a set-cover problem, which is NP-Complete, and apply its 2-approximation algorithm to select the minimum set of tuples that covers the semantics of the original WoW sentence to the same extent as the full set of retrieved tuples."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1.   Knowledge Tuple Retrieval or Extraction",
            "text": "We create Ms.WoW by replacing the Wikipedia knowledge sentences in WoW Dinan et al. (2019  ###reference_b6###) with tuples retrieved or extracted from three sources with different emphases. The three sources, described in detail below, provide disjoint partitions that cover the semantics of the original WoW sentences222All filtering thresholds in this section are empirically determined..\nWe use spaCy to extract entities and noun phrases from each sentence, filtered with NLTK555https://www.nltk.org/  ###reference_www.nltk.org/###  ###reference_www.nltk.org/### stop words.\nWe pass each extracted entity or noun phrase, along with its original sentence as context, to a dense retrieval-based entity linker Wu et al. (2020  ###reference_b25###  ###reference_b25###) to obtain the corresponding Wikidata entities. We take the top-1 Wikidata entity candidate for each extracted entity or noun phrase.\nWe retrieve all Wikidata triplets that contain at least one of the linked entities.\nWe keep only triplets whose subjects and objects both match the corresponding WoW knowledge sentence, requiring one of the following conditions:\nboth the subject and object entities in the triplet appear in the set of linked Wikidata entities extracted from the WoW sentence, or\nthe subject and object both match the WoW sentence using a fuzzy matcher666https://spacy.io/universe/project/spaczz  ###reference_###  ###reference_### with score higher than .\nFor each WoW knowledge sentence, we keep only triplets whose entities cover more than 75% of the extracted entity set of the sentence."
        },
        {
            "section_id": "3.1.1",
            "parent_section_id": "3.1",
            "section_name": "3.1.1.   OPIEC",
            "text": "OPIEC Gashteovski et al. (2019  ###reference_b7###) is a large-scale dataset generated using an open information extraction (OIE) system applied to the text of Wikipedia. For each sentence in Wikipedia, OPIEC extracts one or more (subject, negation, relation, object, time, space) tuples. The tuples are dense, structured versions of the original Wikipedia sentences.\nWe retrieve OPIEC tuples by performing soft sentence matching between the knowledge sentences in WoW and OPIEC\u2019s source sentences. There are some mismatches between sentences in these two datasets because the Wikipedia dumps used are not exactly the same, due to the continuous editing of Wikipedia contributors. We use Sentence-BERT 333all-MiniLM-L6-v2 checkpoint from https://www.sbert.net/  ###reference_www.sbert.net/###. Reimers and Gurevych (2019  ###reference_b18###) to encode sentences from WoW and OPIEC that appear in the same Wikipedia article and consider sentence pairs with cosine similarity larger than  as a match."
        },
        {
            "section_id": "3.1.2",
            "parent_section_id": "3.1",
            "section_name": "3.1.2.   Semantic frames",
            "text": "Semantic frames (sem. frm. or s.f.) capture the core semantics of sentences, such as who did what, when, and where. Previous work on OIE has studied the use of semantic role labeling (SRL)-based knowledge tuples Christensen et al. (2011  ###reference_b4###). Therefore, we use SRL results as complementary structural knowledge to the OPIEC tuples. We use the semantic roles parsed by spaCy\u2019s444https://spacy.io/  ###reference_spacy.io/### SRL pipeline for each WoW knowledge sentence and use templates to map the results into (subject, relation, object, time, space) tuples."
        },
        {
            "section_id": "3.1.3",
            "parent_section_id": "3.1",
            "section_name": "3.1.3.   Wikidata",
            "text": "Wikidata (w.d.) is a large-scale knowledge base containing triplets grounded in Wikipedia articles. It contains (subject, relation, object) triplets that relate one Wikipedia concept to another. We retrieve triplets from Wikidata using the following steps:\nWe use spaCy to extract entities and noun phrases from each sentence, filtered with NLTK555https://www.nltk.org/  ###reference_www.nltk.org/###  ###reference_www.nltk.org/###  ###reference_www.nltk.org/### stop words.\nWe pass each extracted entity or noun phrase, along with its original sentence as context, to a dense retrieval-based entity linker Wu et al. (2020  ###reference_b25###  ###reference_b25###  ###reference_b25###) to obtain the corresponding Wikidata entities. We take the top-1 Wikidata entity candidate for each extracted entity or noun phrase.\nWe retrieve all Wikidata triplets that contain at least one of the linked entities.\nWe keep only triplets whose subjects and objects both match the corresponding WoW knowledge sentence, requiring one of the following conditions:\nboth the subject and object entities in the triplet appear in the set of linked Wikidata entities extracted from the WoW sentence, or\nthe subject and object both match the WoW sentence using a fuzzy matcher666https://spacy.io/universe/project/spaczz  ###reference_###  ###reference_###  ###reference_### with score higher than .\nFor each WoW knowledge sentence, we keep only triplets whose entities cover more than 75% of the extracted entity set of the sentence."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2.   Post-processing",
            "text": "We perform post-processing to ensure the quality of the retrieved tuples and create complementary and disjoint partitions of knowledge sources by filtering out semantically incomplete and redundant tuples.\nIn order to minimize information loss when we replace each WoW sentence with the retrieved tuples, we filter out those sentences whose retrieved tuples can only partially cover their semantics. We tokenize and lemmatize each WoW knowledge sentence and remove punctuation and stop words to create a bag of words  for each sentence. Then we concatenate all retrieved tuple elements from the three sources to create a pseudo-sentence and its corresponding bag of words . We only keep those sets of tuples whose  covers more than 60% of .\nThis filtering step results in the creation of a fourth, supplementary knowledge source: Wikipedia sentences (w.p.) from the original WoW that could not be adequately captured by tuples from the other three sources.\nSince the knowledge tuples are retrieved independently from the three sources, some are redundant with each other. Since our goal is to partition the knowledge into complementary sources, we perform deduplication to remove redundant tuples. Given the full-coverage bag of words , we want to select the minimum number of tuples that maximally cover . We formulate this goal as a set-cover problem, which is NP-Complete, and apply its 2-approximation algorithm to select the minimum set of tuples that covers the semantics of the original WoW sentence to the same extent as the full set of retrieved tuples."
        },
        {
            "section_id": "3.2.1",
            "parent_section_id": "3.2",
            "section_name": "3.2.1.   Filtering of Retrieved Tuples",
            "text": "In order to minimize information loss when we replace each WoW sentence with the retrieved tuples, we filter out those sentences whose retrieved tuples can only partially cover their semantics. We tokenize and lemmatize each WoW knowledge sentence and remove punctuation and stop words to create a bag of words  for each sentence. Then we concatenate all retrieved tuple elements from the three sources to create a pseudo-sentence and its corresponding bag of words . We only keep those sets of tuples whose  covers more than 60% of .\nThis filtering step results in the creation of a fourth, supplementary knowledge source: Wikipedia sentences (w.p.) from the original WoW that could not be adequately captured by tuples from the other three sources.\nSince the knowledge tuples are retrieved independently from the three sources, some are redundant with each other. Since our goal is to partition the knowledge into complementary sources, we perform deduplication to remove redundant tuples. Given the full-coverage bag of words , we want to select the minimum number of tuples that maximally cover . We formulate this goal as a set-cover problem, which is NP-Complete, and apply its 2-approximation algorithm to select the minimum set of tuples that covers the semantics of the original WoW sentence to the same extent as the full set of retrieved tuples."
        },
        {
            "section_id": "3.2.2",
            "parent_section_id": "3.2",
            "section_name": "3.2.2.   Grounding Gold Knowledge Tuples to Utterances",
            "text": "In the original WoW dataset Dinan et al. (2019  ###reference_b6###), each Wizard utterance has at most one gold support knowledge sentence. However, in our Ms.WoW dataset, each original WoW support knowledge sentence is decomposed into multiple knowledge tuples (see Table 1  ###reference_### for an example). Since the semantics of the sentence is spread among these tuples, some tuples derived from the WoW knowledge sentence may contain extra information not found in the corresponding Wizard utterance. Therefore, we use the same set-cover approach as in Section 3.2.1  ###reference_.SSS1### to select those knowledge tuples that are grounded by their utterances; we refer to these grounded tuples as \u201cgold\" tuples."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "3.3.   Dataset Statistics",
            "text": "Table 2  ###reference_### shows the statistics of our Ms.WoW dataset. OPIEC tuples are parsed from the entire Wikipedia, so they have the most coverage. In contrast, semantic frame tuples are much fewer in number due to our template-based matching rule.\nDespite originating from the same Wikipedia sentences, tuples derived from different sources have significantly different length attributes (see Table 1  ###reference_### for examples). As Table 3  ###reference_### shows, different knowledge sources yield knowledge with different numbers of components: while Wikidata tuples only have (subject, relation, object), OPIEC tuples also have negation, time, and space. The lengths of each knowledge type\u2019s attributes are also significantly different: semantic frame tuples have single-word relations with long subjects and objects, while OPIEC tuples have longer relations with shorter subjects and objects. In addition, while semantic frames retain the original sentence tokens, OPIEC and Wikidata decompose the original sentences into multiple pieces."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "3.4.   Quality assurance via dialogue response generation",
            "text": "Since Ms.WoW is a new dataset derived from WoW but designed for a different purpose, we want to ensure that the knowledge tuples in Ms.WoW sufficiently retain the information in the WoW knowledge sentences. Table 9  ###reference_### shows that response generators using our full Ms.WoW. (all sources) perform comparably to those using the original WoW dataset: our ROUGE scores and utterance F1 are comparable, and our unigram multi-source knowledge F1 is close to that of the original WoW setting (metric descriptions are found in Section 4.1  ###reference_###). This confirms that our Ms.WoW covers the knowledge needed to support a dialogue model to generate high-quality responses with limited information loss compared to WoW."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4.   Dialogue Knowledge Plug-and-Play",
            "text": "Having collected Ms.WoW, we apply it as a test bed to study dialogue knowledge plug-and-play via multi-source dialogue knowledge selection and response generation. We employ a baseline approach to demonstrate the basic characteristics and challenges of dialogue knowledge plug-and-play.\nWe create the input sequences by concatenating up to the last five utterances in the conversation history (), speaker roles (), and the support knowledge sentences and tuples () for each Wizard dialogue turn. Each support knowledge subsequence is prepended with a special token <kg>. We feed the input sequence to a pre-trained language model. The input sequence  can be written as:\nWe use a Roberta-base Liu et al. (2019a  ###reference_b13###) model (), followed by a 2-layer feed-forward network (). We take each support knowledge tuple\u2019s corresponding <kg> token representation  as its knowledge representation for knowledge selection. Utterances without any candidate knowledge are skipped.\nWe use a BART-base Lewis et al. (2019  ###reference_b10###) model () to perform a standard response generation using the same input  from Equation 1  ###reference_###: .\nWe use the Roberta-base (125M parameters) and BART-base (139M parameters) models from Huggingface888https://huggingface.co/models  ###reference_huggingface.co/models###. We mostly use the default hyper-parameters (see Table 8  ###reference_###). We use a single Nvidia Tesla V100S GPU for model training and testing. Each dialogue knowledge selector and dialogue generator takes approximately 3 hours for training and a few minutes for inference.\nWe use the Vicuna-13B-v1.1 LLM from Huggingface. We set the generation temperature to 0.7. It takes approximately 30 hours to perform inference on the test set (seen + unseen) for each configuration using 4 Nvidia Tesla V100S GPUs."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1.   Experimental Design",
            "text": "Retraining a dialogue model each time a new knowledge source becomes available is computationally costly and requires extra engineering effort. Dialogue knowledge plug-and-play examines the ability of a pretrained dialogue model to adapt to support knowledge from new sources in a zero-shot fashion.\nWe use Ms.WoW to simulate the realistic scenario where an additional knowledge source becomes available after the dialogue model has already been trained. We test a model\u2019s adaptability to new knowledge sources by ablating one of the Ms.WoW sources from the available candidate knowledge during training and then test the ablated model with the full-knowledge test set; the missing knowledge source becomes available only at test time (Tables 5  ###reference_### & 9  ###reference_###). The goal of the dialogue knowledge plug-and-play challenge is to reduce the difference between the test performance of each knowledge-ablated model and the test performance of a model trained on the full-knowledge dataset; the challenge prefers models that can quickly adapt to make use of the previously unseen knowledge source.\nFor response generation, we compare the knowledge-ablated models to two upper bounds. First, we train a model on the full set of available knowledge tuples777Note that \u201cfull knowledge\u201d refers to the full set of candidate knowledge tuples available for each turn, derived from the corresponding full set of WoW knowledge sentences, which have already been filtered from a large pool of millions of Wikipedia articles using an information retrieval module described by Dinan et al. (2019  ###reference_b6###) (Ms.WoW full knowledge), simulating a model that is retrained when the new knowledge source becomes available. Second, we experiment with using gold (i.e. utterance-grounded) knowledge tuples only, simulating the scenario where a \u201cperfect\" knowledge selector is available (Ms.WoW gold knowledge) and providing an upper bound on the effect of knowledge selection performance on response generation.\nThe following is the conversation between the \u201cWizard\", a knowledgeable speaker who can access Wikipedia knowledge sentences to chat to with the \u201cApprentice\", who does not have access to Wikipedia.\nThe conversation topic is {{topic}} and the persona setting of the Wizard is \u201c{{persona}}\".\n\\hdashlineThis is their conversation history:\n{{speaker 1}}: {{utterance 1.1}}\n{{speaker 2}}: {{utterance 2.1}}\n{{speaker 1}}: {{utterance 1.2}}\n\u2026\n\\hdashlineHere is some retrieved Wikipedia knowledge for the Wizard.\nSome of the knowledge is in the tuple form, such as (subject, negation, relation, object, time, space) or (subject, relation, object).\nThe Wizard can choose any subset of the following knowledge. It\u2019s also allowed to not choose any of them.\n{{(subject 1, relation 1, object 1)}}\n\u2026\n\\hdashlineGiven the knowledge above, make a very brief, such as one sentence, natural response for the Wizard.\nNot all information in the chosen knowledge has to be used in the response.\nThe Wizard\u2019s response is:"
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2.   Baseline Approaches",
            "text": "We create the input sequences by concatenating up to the last five utterances in the conversation history (), speaker roles (), and the support knowledge sentences and tuples () for each Wizard dialogue turn. Each support knowledge subsequence is prepended with a special token <kg>. We feed the input sequence to a pre-trained language model. The input sequence  can be written as:\nWe use a Roberta-base Liu et al. (2019a  ###reference_b13###  ###reference_b13###) model (), followed by a 2-layer feed-forward network (). We take each support knowledge tuple\u2019s corresponding <kg> token representation  as its knowledge representation for knowledge selection. Utterances without any candidate knowledge are skipped.\nWe use a BART-base Lewis et al. (2019  ###reference_b10###  ###reference_b10###) model () to perform a standard response generation using the same input  from Equation 1  ###reference_###  ###reference_###: ."
        },
        {
            "section_id": "4.2.1",
            "parent_section_id": "4.2",
            "section_name": "4.2.1.   Fine-tuned Models",
            "text": "We create the input sequences by concatenating up to the last five utterances in the conversation history (), speaker roles (), and the support knowledge sentences and tuples () for each Wizard dialogue turn. Each support knowledge subsequence is prepended with a special token <kg>. We feed the input sequence to a pre-trained language model. The input sequence  can be written as:\nWe use a Roberta-base Liu et al. (2019a  ###reference_b13###  ###reference_b13###  ###reference_b13###) model (), followed by a 2-layer feed-forward network (). We take each support knowledge tuple\u2019s corresponding <kg> token representation  as its knowledge representation for knowledge selection. Utterances without any candidate knowledge are skipped.\nWe use a BART-base Lewis et al. (2019  ###reference_b10###  ###reference_b10###  ###reference_b10###) model () to perform a standard response generation using the same input  from Equation 1  ###reference_###  ###reference_###  ###reference_###: ."
        },
        {
            "section_id": "4.2.2",
            "parent_section_id": "4.2",
            "section_name": "4.2.2.   Large Language Model",
            "text": "We also prompt an LLM in a zero-shot fashion for the response generation task. We use Vicuna-13B Chiang et al. (2023  ###reference_b3###), a 13-billion-parameter LLaMA Touvron et al. (2023  ###reference_b22###) model fined-tuned on 70k user-shared conversation samples. Table 7  ###reference_### shows the prompt we use."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "4.3.   Experimental Details",
            "text": "We use the Roberta-base (125M parameters) and BART-base (139M parameters) models from Huggingface888https://huggingface.co/models  ###reference_huggingface.co/models###  ###reference_huggingface.co/models###. We mostly use the default hyper-parameters (see Table 8  ###reference_###  ###reference_###). We use a single Nvidia Tesla V100S GPU for model training and testing. Each dialogue knowledge selector and dialogue generator takes approximately 3 hours for training and a few minutes for inference.\nWe use the Vicuna-13B-v1.1 LLM from Huggingface. We set the generation temperature to 0.7. It takes approximately 30 hours to perform inference on the test set (seen + unseen) for each configuration using 4 Nvidia Tesla V100S GPUs."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5.   Experimental Results and Analysis",
            "text": "Tables 4  ###reference_###, 5  ###reference_###, and 6  ###reference_### show the performance of our Roberta-based knowledge selector; Tables 9  ###reference_### and 10  ###reference_### show the performance of our BART-based response generator; and Table 11  ###reference_### shows the performance of the LLM response generator.\nTo measure the dialogue response generation performance, in addition to ROUGE scores Lin (2004  ###reference_b12###) compared to the gold response, we follow Dinan et al. (2019  ###reference_b6###) in reporting the unigram F1 of the generated response with the gold response, as well as unigram precision, recall and F1 (K-P, K-R & K-F1) of the generated response with all available (i.e. non-ablated) candidate knowledge."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "5.1.   Full-knowledge vs. Zero-shot Adaptation",
            "text": "Unsurprisingly, there is a significant difference between the full-knowledge model (i.e. retrained with each new knowledge source) and the zero-shot adapted models that have one knowledge source ablated during training (Tables 4  ###reference_### and 9  ###reference_###). This performance gap generally increases as the ablated knowledge source occupies a larger proportion of the overall available knowledge.\nThis trend is clearer when we separately examine the knowledge selectors\u2019 performances on each knowledge source in Table 5  ###reference_### (diagonal entries vs. full knowledge). In general, an ablated model\u2019s recall score on the newly available knowledge source is dramatically lower than that of the full-knowledge model; the distribution of the new knowledge source is not recognized as usable support knowledge. This observation clearly shows the significant performance gap between the full-knowledge model and the zero-shot adapted models, which is exactly the gap that our dialogue knowledge plug-and-play challenge aims to highlight as a target for improvement.\nInterestingly, Table 5  ###reference_### (non-diagonal entries vs. full knowledge) also shows that a new knowledge source becoming available improves the model\u2019s knowledge selection performance on some of the previously available knowledge sources, demonstrating that there is some synergy among knowledge from different sources.\nThe only exception to the observations above is the supplementary Wikipedia sentence source, consisting of WoW sentences that could not be adequately covered by our three other sources. We suspect this is because the pre-trained language model we use, Roberta Liu et al. (2019a  ###reference_b13###), is already extensively trained on Wikipedia articles, which makes zero-shot adaptation back to the Wikipedia sentences trivial."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "5.2.   Differences among Knowledge Sources",
            "text": "There is a clear difference in difficulty among knowledge sources. Since semantic frame tuples are extracted using high-precision, human-engineered templates, all models perform significantly better on semantic frame tuples than other knowledge types (Table 5  ###reference_###).\nDifferent knowledge sources also have different usefulness in response generation. As Table 9  ###reference_### and 11  ###reference_### show, Wikidata knowledge triplets are not as helpful as the other knowledge sources. This may be because Wikidata triplets are generally short (Section 3.3  ###reference_###), making them less informative than the other knowledge sources."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "5.3.   \u201cMore is Better\u201d in Zero-shot Settings",
            "text": "Tables 6  ###reference_### and 10  ###reference_### show the knowledge selection and response generation performance of our models when one knowledge source is ablated from both training and testing, simulating a scenario where that knowledge source never becomes available. Comparing these results with Tables 5  ###reference_### and 9  ###reference_###, respectively, we see that introducing additional knowledge sources, even in a zero-shot fashion, mostly benefits, rather than hurts, knowledge selection and response generation, supporting the claim that \u201cmore (knowledge sources) is better\u201d Wu et al. (2021  ###reference_b26###). This is a promising result for dialogue knowledge plug-and-play, which challenges models to be robust to new knowledge sources. This phenomenon is also relevant to the in-context-learning Brown et al. (2020  ###reference_b1###) of LLMs, where LLMs learn from new inputs in a few-shot manner."
        },
        {
            "section_id": "5.4",
            "parent_section_id": "5",
            "section_name": "5.4.   LLMs for Dialogue Knowledge Plug-and-Play",
            "text": "LLM-based response generation task can be considered an extreme scenario of zero-shot prediction, where no in-domain training is conducted at all. Compared to the fine-tuned models, which have the opportunity to learn the speaking style and statistical distribution of the conversationalists, the Vicuna-generated zero-shot responses are significantly longer: mean token length of 42.5 vs. 21.3 from the BART-based model on the Ms.WoW full knowledge test set; the mean target response length is 24.5 tokens. The Vicuna-generated outputs have less overlap with the corresponding gold responses, but a higher unigram overlap with the input knowledge in the full-knowledge setting (Table 11  ###reference_###), indicating that the LLM is able to generate utterances relevant to the input knowledge when sufficient knowledge is given. Surprisingly, when provided with gold knowledge only, the LLM seems not to use the provided knowledge to the same extent, and we see a decrease in performance, in contrast with the BART-based model that improved with gold knowledge. However, similar to the BART-based model, we still observe that more knowledge sources provided at test time significantly improves the LLM\u2019s response generation performance across all metrics."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6.   Conclusion",
            "text": "We introduce the Ms.WoW dataset of multi-source support knowledge for open-domain dialogue generation, with knowledge tuples partitioned into disjoint sources and grounded at the utterance level. We further introduce the dialogue knowledge plug-and-play challenge, where a trained dialogue system must adapt to a new knowledge source at test time. Our baseline experiments demonstrate how future works can use Ms.WoW to study how dialogue models generalize to new knowledge sources."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7.   Bibliographical References",
            "text": ""
        }
    ],
    "appendix": [],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S1.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S1.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S1.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t\" colspan=\"3\" id=\"S1.T1.1.1.1.1\" style=\"width:359.9pt;padding-left:2.5pt;padding-right:2.5pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S1.T1.1.1.1.1.1\" style=\"font-size:90%;\">Response</span><span class=\"ltx_text\" id=\"S1.T1.1.1.1.1.2\" style=\"font-size:90%;\"></span>\n</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.1.2.2\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row\" colspan=\"3\" id=\"S1.T1.1.2.2.1\" style=\"width:359.9pt;padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.2.2.1.1\" style=\"font-size:90%;\">It was formed in 1965. The Pepsi-Cola company and Frito-Lay merged to form one big company.</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.1.3.3\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_tt\" colspan=\"3\" id=\"S1.T1.1.3.3.1\" style=\"width:359.9pt;padding-left:2.5pt;padding-right:2.5pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S1.T1.1.3.3.1.1\" style=\"font-size:90%;\">Gold WoW sentence</span><span class=\"ltx_text\" id=\"S1.T1.1.3.3.1.2\" style=\"font-size:90%;\"></span>\n</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.1.4.4\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row\" colspan=\"3\" id=\"S1.T1.1.4.4.1\" style=\"width:359.9pt;padding-left:2.5pt;padding-right:2.5pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S1.T1.1.4.4.1.1\"><span class=\"ltx_text\" id=\"S1.T1.1.4.4.1.1.1\" style=\"font-size:90%;\">PepsiCo was formed in 1965 with the merger of the Pepsi-Cola Company and Frito-Lay, Inc. PepsiCo has since expanded from its namesake product Pepsi to a broader range of food and beverage brands, the largest of which included an acquisition of Tropicana Products in 1998 and the Quaker Oats Company in 2001, which added the Gatorade brand to its portfolio.</span></p>\n<span class=\"ltx_text\" id=\"S1.T1.1.4.4.1.2\" style=\"font-size:90%;\"></span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S1.T1.1.5.1\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S1.T1.1.5.1.1\" style=\"width:359.9pt;padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S1.T1.1.5.1.1.1\" style=\"font-size:90%;\">Ms.WoW Knowledge Tuples</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S1.T1.1.5.1.2\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S1.T1.1.5.1.2.1\" style=\"font-size:90%;\">Source</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S1.T1.1.5.1.3\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S1.T1.1.5.1.3.1\" style=\"font-size:90%;\">Gold</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.1.6.2\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S1.T1.1.6.2.1\" style=\"width:359.9pt;padding-left:2.5pt;padding-right:2.5pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S1.T1.1.6.2.1.1\"><span class=\"ltx_text\" id=\"S1.T1.1.6.2.1.1.1\" style=\"font-size:90%;\">(\u2018\u2019, \u2018formed\u2019, \u2018PepsiCo\u2019, \u2018in 1965\u2019, \u2018\u2019)</span></p>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S1.T1.1.6.2.2\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.6.2.2.1\" style=\"font-size:90%;\">Sem. frm.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S1.T1.1.6.2.3\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.6.2.3.1\" style=\"font-size:90%;\">Yes</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.1.7.3\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_r\" id=\"S1.T1.1.7.3.1\" style=\"width:359.9pt;padding-left:2.5pt;padding-right:2.5pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S1.T1.1.7.3.1.1\"><span class=\"ltx_text\" id=\"S1.T1.1.7.3.1.1.1\" style=\"font-size:90%;\">(\u2018its\u2019, \u2018\u2019, \u2018has\u2019, \u2018namesake product Pepsi\u2019, \u2018\u2019, \u2018\u2019)</span></p>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S1.T1.1.7.3.2\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.7.3.2.1\" style=\"font-size:90%;\">OPIEC</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S1.T1.1.7.3.3\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.7.3.3.1\" style=\"font-size:90%;\">No</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.1.8.4\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_r\" id=\"S1.T1.1.8.4.1\" style=\"width:359.9pt;padding-left:2.5pt;padding-right:2.5pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S1.T1.1.8.4.1.1\"><span class=\"ltx_text\" id=\"S1.T1.1.8.4.1.1.1\" style=\"font-size:90%;\">(\u2018largest of which\u2019, \u2018\u2019, \u2018have included acquisition of Tropicana Products in 1998\u2019, \u2018beverage brands\u2019, \u2018\u2019, \u2018\u2019)</span></p>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S1.T1.1.8.4.2\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.8.4.2.1\" style=\"font-size:90%;\">OPIEC</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S1.T1.1.8.4.3\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.8.4.3.1\" style=\"font-size:90%;\">No</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.1.9.5\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_r\" id=\"S1.T1.1.9.5.1\" style=\"width:359.9pt;padding-left:2.5pt;padding-right:2.5pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S1.T1.1.9.5.1.1\"><span class=\"ltx_text\" id=\"S1.T1.1.9.5.1.1.1\" style=\"font-size:90%;\">(\u2018largest of which\u2019, \u2018\u2019, \u2018have included Quaker Oats Company in 2001\u2019, \u2018food brands\u2019, \u2018\u2019, \u2018\u2019)</span></p>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S1.T1.1.9.5.2\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.9.5.2.1\" style=\"font-size:90%;\">OPIEC</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S1.T1.1.9.5.3\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.9.5.3.1\" style=\"font-size:90%;\">No</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.1.10.6\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_r\" id=\"S1.T1.1.10.6.1\" style=\"width:359.9pt;padding-left:2.5pt;padding-right:2.5pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S1.T1.1.10.6.1.1\"><span class=\"ltx_text\" id=\"S1.T1.1.10.6.1.1.1\" style=\"font-size:90%;\">(\u2018Quaker Oats Company in 2001\u2019, \u2018\u2019, \u2018added Gatorade brand to\u2019, \u2018portfolio\u2019, \u2018\u2019, \u2018\u2019)</span></p>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S1.T1.1.10.6.2\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.10.6.2.1\" style=\"font-size:90%;\">OPIEC</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S1.T1.1.10.6.3\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.10.6.3.1\" style=\"font-size:90%;\">Yes</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.1.11.7\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_r\" id=\"S1.T1.1.11.7.1\" style=\"width:359.9pt;padding-left:2.5pt;padding-right:2.5pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S1.T1.1.11.7.1.1\"><span class=\"ltx_text\" id=\"S1.T1.1.11.7.1.1.1\" style=\"font-size:90%;\">(\u2018Frito-Lay\u2019, \u2018parent organization\u2019, \u2018PepsiCo\u2019)</span></p>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S1.T1.1.11.7.2\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.11.7.2.1\" style=\"font-size:90%;\">Wikidata</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S1.T1.1.11.7.3\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.11.7.3.1\" style=\"font-size:90%;\">Yes</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S1.T1.1.12.8\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S1.T1.1.12.8.1\" style=\"width:359.9pt;padding-left:2.5pt;padding-right:2.5pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S1.T1.1.12.8.1.1\"><span class=\"ltx_text\" id=\"S1.T1.1.12.8.1.1.1\" style=\"font-size:90%;\">(\u2018Pepsi\u2019, \u2018instance of\u2019, \u2018cola\u2019)</span></p>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S1.T1.1.12.8.2\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.12.8.2.1\" style=\"font-size:90%;\">Wikidata</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S1.T1.1.12.8.3\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span class=\"ltx_text\" id=\"S1.T1.1.12.8.3.1\" style=\"font-size:90%;\">Yes</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>An example decomposition of a gold knowledge sentence from WoW into tuples from multiple sources in Ms.WoW. Tuples not used in the response are not labeled as gold tuples.</figcaption>\n</figure>",
            "capture": "Table 1: An example decomposition of a gold knowledge sentence from WoW into tuples from multiple sources in Ms.WoW. Tuples not used in the response are not labeled as gold tuples."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T2\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T2.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.1.1.1.1\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.1\" style=\"font-size:90%;\">Multi-Source WoW</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.1.1.1.2\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.1.1.2.1\" style=\"font-size:90%;\">Train</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.1.1.1.3\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.1.1.3.1\" style=\"font-size:90%;\">Valid Seen</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.1.1.1.4\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.1.1.4.1\" style=\"font-size:90%;\">Valid Unseen</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.1.1.1.5\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.1.1.5.1\" style=\"font-size:90%;\">Test Seen</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.1.1.1.6\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.1.1.6.1\" style=\"font-size:90%;\">Test Unseen</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.1.2.2.1\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.2.2.1.1\" style=\"font-size:90%;\">Number of utterances</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.1.2.2.2\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.2.2.2.1\" style=\"font-size:90%;\">166787</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.1.2.2.3\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.2.2.3.1\" style=\"font-size:90%;\">8909</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.1.2.2.4\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.2.2.4.1\" style=\"font-size:90%;\">8806</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.1.2.2.5\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.2.2.5.1\" style=\"font-size:90%;\">8715</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.1.2.2.6\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.2.2.6.1\" style=\"font-size:90%;\">8782</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.3.3.1\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.3.3.1.1\" style=\"font-size:90%;\">Number of dialogues</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.3.3.2\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.3.3.2.1\" style=\"font-size:90%;\">18430</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.3.3.3\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.3.3.3.1\" style=\"font-size:90%;\">981</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.3.3.4\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.3.3.4.1\" style=\"font-size:90%;\">967</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.3.3.5\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.3.3.5.1\" style=\"font-size:90%;\">965</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.3.3.6\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.3.3.6.1\" style=\"font-size:90%;\">968</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.4.4.1\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.4.4.1.1\" style=\"font-size:90%;\">Number of topics</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.4.4.2\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.4.4.2.1\" style=\"font-size:90%;\">1247</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.4.4.3\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.4.4.3.1\" style=\"font-size:90%;\">545</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.4.4.4\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.4.4.4.1\" style=\"font-size:90%;\">54</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.4.4.5\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.4.4.5.1\" style=\"font-size:90%;\">533</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.4.4.6\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.4.4.6.1\" style=\"font-size:90%;\">58</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.5.5.1\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.5.5.1.1\" style=\"font-size:90%;\">Avg turns per dialogue</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.5.5.2\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.5.5.2.1\" style=\"font-size:90%;\">9.05</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.5.5.3\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.5.5.3.1\" style=\"font-size:90%;\">9.08</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.5.5.4\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.5.5.4.1\" style=\"font-size:90%;\">9.13</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.5.5.5\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.5.5.5.1\" style=\"font-size:90%;\">9.03</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.5.5.6\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.5.5.6.1\" style=\"font-size:90%;\">9.07</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.6.6.1\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.6.6.1.1\" style=\"font-size:90%;\">% of Wizard turns with knowledge</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.6.6.2\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.6.6.2.1\" style=\"font-size:90%;\">61.8</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.6.6.3\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.6.6.3.1\" style=\"font-size:90%;\">62.5</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.6.6.4\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.6.6.4.1\" style=\"font-size:90%;\">65.0</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.6.6.5\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.6.6.5.1\" style=\"font-size:90%;\">62.8</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.6.6.6\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.6.6.6.1\" style=\"font-size:90%;\">61.8</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.7.7.1\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.7.7.1.1\" style=\"font-size:90%;\">Avg non-zero # of knowledge per utterance</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.7.7.2\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.7.7.2.1\" style=\"font-size:90%;\">5.0</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.7.7.3\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.7.7.3.1\" style=\"font-size:90%;\">5.0</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.7.7.4\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.7.7.4.1\" style=\"font-size:90%;\">5.1</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.7.7.5\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.7.7.5.1\" style=\"font-size:90%;\">5.0</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.7.7.6\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.7.7.6.1\" style=\"font-size:90%;\">4.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.8.8.1\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.8.8.1.1\" style=\"font-size:90%;\">Avg # of (gold) Knowledge per Utterance</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.8.8.2\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.8.8.2.1\" style=\"font-size:90%;\">13.8 (1.55)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.8.8.3\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.8.8.3.1\" style=\"font-size:90%;\">13.4 (1.49)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.8.8.4\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.8.8.4.1\" style=\"font-size:90%;\">14.1 (1.59)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.8.8.5\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.8.8.5.1\" style=\"font-size:90%;\">13.9 (1.55)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.8.8.6\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.8.8.6.1\" style=\"font-size:90%;\">15.2 (1.59)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.9.9.1\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.9.9.1.1\" style=\"font-size:90%;\">% of (gold) OPIEC</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.9.9.2\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.9.9.2.1\" style=\"font-size:90%;\">64.9 (57.4)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.9.9.3\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.9.9.3.1\" style=\"font-size:90%;\">65.2 (59.2)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.9.9.4\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.9.9.4.1\" style=\"font-size:90%;\">57.9 (51.5)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.9.9.5\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.9.9.5.1\" style=\"font-size:90%;\">65.4 (58.2)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.9.9.6\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.9.9.6.1\" style=\"font-size:90%;\">67.4 (58.7)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.10.10.1\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.10.10.1.1\" style=\"font-size:90%;\">% of (gold) semantic frame</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.10.10.2\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.10.10.2.1\" style=\"font-size:90%;\">4.55 (9.87)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.10.10.3\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.10.10.3.1\" style=\"font-size:90%;\">4.17 (8.73)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.10.10.4\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.10.10.4.1\" style=\"font-size:90%;\">3.82 (8.85)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.10.10.5\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.10.10.5.1\" style=\"font-size:90%;\">4.37 (8.98)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.10.10.6\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.10.10.6.1\" style=\"font-size:90%;\">5.08 (12.1)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.11.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.1.11.11.1\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.11.11.1.1\" style=\"font-size:90%;\">% of (gold) Wikidata</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.11.11.2\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.11.11.2.1\" style=\"font-size:90%;\">17.2 (13.9)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.11.11.3\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.11.11.3.1\" style=\"font-size:90%;\">17.2 (12.9)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.11.11.4\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.11.11.4.1\" style=\"font-size:90%;\">21.7 (16.9)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.11.11.5\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.11.11.5.1\" style=\"font-size:90%;\">17.2 (13.9)</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.11.11.6\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.11.11.6.1\" style=\"font-size:90%;\">16.8 (12.4)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\" id=\"S3.T2.1.12.12.1\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.12.12.1.1\" style=\"font-size:90%;\">% of (gold) Wikipedia</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S3.T2.1.12.12.2\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.12.12.2.1\" style=\"font-size:90%;\">13.4 (18.8)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S3.T2.1.12.12.3\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.12.12.3.1\" style=\"font-size:90%;\">13.5 (19.2)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S3.T2.1.12.12.4\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.12.12.4.1\" style=\"font-size:90%;\">16.6 (22.8)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S3.T2.1.12.12.5\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.12.12.5.1\" style=\"font-size:90%;\">13.0 (18.9)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S3.T2.1.12.12.6\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span class=\"ltx_text\" id=\"S3.T2.1.12.12.6.1\" style=\"font-size:90%;\">10.7 (16.7)</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Statistics of our Multi-Source Wizard of Wikipedia.</figcaption>\n</figure>",
            "capture": "Table 2: Statistics of our Multi-Source Wizard of Wikipedia."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T3\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T3.10\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T3.10.11.1\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S3.T3.10.11.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S3.T3.10.11.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.11.1.2.1\" style=\"font-size:90%;\">sbj</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S3.T3.10.11.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.11.1.3.1\" style=\"font-size:90%;\">neg</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S3.T3.10.11.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.11.1.4.1\" style=\"font-size:90%;\">rel</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S3.T3.10.11.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.11.1.5.1\" style=\"font-size:90%;\">obj</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S3.T3.10.11.1.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.11.1.6.1\" style=\"font-size:90%;\">tmp</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S3.T3.10.11.1.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.11.1.7.1\" style=\"font-size:90%;\">spa</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S3.T3.10.11.1.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.11.1.8.1\" style=\"font-size:90%;\">total</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T3.10.12.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S3.T3.10.12.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.12.1.1.1\" style=\"font-size:90%;\">OPIEC</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T3.10.12.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.12.1.2.1\" style=\"font-size:90%;\">2.2</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T3.10.12.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.12.1.3.1\" style=\"font-size:90%;\">1.0</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T3.10.12.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.12.1.4.1\" style=\"font-size:90%;\">3.3</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T3.10.12.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.12.1.5.1\" style=\"font-size:90%;\">2.8</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T3.10.12.1.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.12.1.6.1\" style=\"font-size:90%;\">2.1</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T3.10.12.1.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.12.1.7.1\" style=\"font-size:90%;\">2.3</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T3.10.12.1.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.12.1.8.1\" style=\"font-size:90%;\">8.7</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S3.T3.1.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.1.1.2.1\" style=\"font-size:90%;\">Sem. frm.</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.1.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.1.1.3.1\" style=\"font-size:90%;\">6.3</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.1.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.1.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.1.1.4.1\" style=\"font-size:90%;\">1.0</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.1.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.1.1.5.1\" style=\"font-size:90%;\">14.3</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.1.1.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.1.1.6.1\" style=\"font-size:90%;\">3.9</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.1.1.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.1.1.7.1\" style=\"font-size:90%;\">8.2</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.1.1.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.1.1.8.1\" style=\"font-size:90%;\">22.1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S3.T3.4.4.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.4.4.4.1\" style=\"font-size:90%;\">Wikidata</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.4.4.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.4.4.5.1\" style=\"font-size:90%;\">1.7</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.2.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.4.4.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.4.4.6.1\" style=\"font-size:90%;\">2.2</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.4.4.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.4.4.7.1\" style=\"font-size:90%;\">1.7</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.3.3.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.4.4.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.4.4.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.4.4.8.1\" style=\"font-size:90%;\">5.6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S3.T3.10.10.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.10.7.1\" style=\"font-size:90%;\">Wikipedia</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S3.T3.5.5.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S3.T3.6.6.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S3.T3.7.7.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S3.T3.8.8.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S3.T3.9.9.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S3.T3.10.10.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S3.T3.10.10.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S3.T3.10.10.8.1\" style=\"font-size:90%;\">24.9</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Average of number of words per non-empty knowledge attribute.</figcaption>\n</figure>",
            "capture": "Table 3: Average of number of words per non-empty knowledge attribute."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T4\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.4\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T4.4.5.1\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T4.4.5.1.1\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" colspan=\"3\" id=\"S4.T4.4.5.1.2\">\n<span class=\"ltx_text ltx_font_italic\" id=\"S4.T4.4.5.1.2.1\" style=\"font-size:90%;\">Test Seen + Unseen</span><span class=\"ltx_text\" id=\"S4.T4.4.5.1.2.2\" style=\"font-size:90%;\"></span>\n</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.4.6.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r\" id=\"S4.T4.4.6.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.4.6.2.1.1\" style=\"font-size:90%;\">Training</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S4.T4.4.6.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.4.6.2.2.1\" style=\"font-size:90%;\">P</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S4.T4.4.6.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.4.6.2.3.1\" style=\"font-size:90%;\">R</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S4.T4.4.6.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.4.6.2.4.1\" style=\"font-size:90%;\">F1</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.4.7.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T4.4.7.3.1\"><span class=\"ltx_text\" id=\"S4.T4.4.7.3.1.1\" style=\"font-size:90%;\">Full Kn.</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.4.7.3.2\"><span class=\"ltx_text\" id=\"S4.T4.4.7.3.2.1\" style=\"font-size:90%;\">0.384</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.4.7.3.3\"><span class=\"ltx_text\" id=\"S4.T4.4.7.3.3.1\" style=\"font-size:90%;\">0.380</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.4.7.3.4\"><span class=\"ltx_text\" id=\"S4.T4.4.7.3.4.1\" style=\"font-size:90%;\">0.382</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T4.1.1.1\">\n<span class=\"ltx_text\" id=\"S4.T4.1.1.1.1\" style=\"font-size:90%;\"> OPIEC</span>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T4.1.1.2\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1\" style=\"font-size:90%;\">0.368</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T4.1.1.3\"><span class=\"ltx_text\" id=\"S4.T4.1.1.3.1\" style=\"font-size:90%;\">0.274</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T4.1.1.4\"><span class=\"ltx_text\" id=\"S4.T4.1.1.4.1\" style=\"font-size:90%;\">0.314</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.2.2.1\">\n<span class=\"ltx_text\" id=\"S4.T4.2.2.1.1\" style=\"font-size:90%;\"> Sem. frm.</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.2.2.2\"><span class=\"ltx_text\" id=\"S4.T4.2.2.2.1\" style=\"font-size:90%;\">0.404</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.2.2.3\"><span class=\"ltx_text\" id=\"S4.T4.2.2.3.1\" style=\"font-size:90%;\">0.333</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.2.2.4\"><span class=\"ltx_text\" id=\"S4.T4.2.2.4.1\" style=\"font-size:90%;\">0.365</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.3.3.1\">\n<span class=\"ltx_text\" id=\"S4.T4.3.3.1.1\" style=\"font-size:90%;\"> Wikidata</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.3.3.2\"><span class=\"ltx_text\" id=\"S4.T4.3.3.2.1\" style=\"font-size:90%;\">0.446</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.3.3.3\"><span class=\"ltx_text\" id=\"S4.T4.3.3.3.1\" style=\"font-size:90%;\">0.303</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.3.3.4\"><span class=\"ltx_text\" id=\"S4.T4.3.3.4.1\" style=\"font-size:90%;\">0.361</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"S4.T4.4.4.1\">\n<span class=\"ltx_text\" id=\"S4.T4.4.4.1.1\" style=\"font-size:90%;\"> Wikipedia</span>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T4.4.4.2\"><span class=\"ltx_text\" id=\"S4.T4.4.4.2.1\" style=\"font-size:90%;\">0.497</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T4.4.4.3\"><span class=\"ltx_text\" id=\"S4.T4.4.4.3.1\" style=\"font-size:90%;\">0.319</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T4.4.4.4\"><span class=\"ltx_text\" id=\"S4.T4.4.4.4.1\" style=\"font-size:90%;\">0.389</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Dialogue knowledge selection performance on Ms.WoW test set (seen + unseen).</figcaption>\n</figure>",
            "capture": "Table 4: Dialogue knowledge selection performance on Ms.WoW test set (seen + unseen)."
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T5\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T5.4\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T5.4.5.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T5.4.5.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"3\" id=\"S4.T5.4.5.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text ltx_font_italic\" id=\"S4.T5.4.5.1.2.1\" style=\"font-size:90%;\">OPIEC</span><span class=\"ltx_text\" id=\"S4.T5.4.5.1.2.2\" style=\"font-size:90%;\"></span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"3\" id=\"S4.T5.4.5.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text ltx_font_italic\" id=\"S4.T5.4.5.1.3.1\" style=\"font-size:90%;\">Sem. frm.</span><span class=\"ltx_text\" id=\"S4.T5.4.5.1.3.2\" style=\"font-size:90%;\"></span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"3\" id=\"S4.T5.4.5.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text ltx_font_italic\" id=\"S4.T5.4.5.1.4.1\" style=\"font-size:90%;\">Wikidata</span><span class=\"ltx_text\" id=\"S4.T5.4.5.1.4.2\" style=\"font-size:90%;\"></span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"3\" id=\"S4.T5.4.5.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text ltx_font_italic\" id=\"S4.T5.4.5.1.5.1\" style=\"font-size:90%;\">Wikipedia</span><span class=\"ltx_text\" id=\"S4.T5.4.5.1.5.2\" style=\"font-size:90%;\"></span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.4.6.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T5.4.6.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.4.6.2.1.1\" style=\"font-size:90%;\">Training</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.4.6.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.4.6.2.2.1\" style=\"font-size:90%;\">P</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.4.6.2.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.4.6.2.3.1\" style=\"font-size:90%;\">R</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T5.4.6.2.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.4.6.2.4.1\" style=\"font-size:90%;\">F1</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.4.6.2.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.4.6.2.5.1\" style=\"font-size:90%;\">P</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.4.6.2.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.4.6.2.6.1\" style=\"font-size:90%;\">R</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T5.4.6.2.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.4.6.2.7.1\" style=\"font-size:90%;\">F1</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.4.6.2.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.4.6.2.8.1\" style=\"font-size:90%;\">P</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.4.6.2.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.4.6.2.9.1\" style=\"font-size:90%;\">R</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T5.4.6.2.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.4.6.2.10.1\" style=\"font-size:90%;\">F1</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.4.6.2.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.4.6.2.11.1\" style=\"font-size:90%;\">P</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.4.6.2.12\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.4.6.2.12.1\" style=\"font-size:90%;\">R</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.4.6.2.13\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.4.6.2.13.1\" style=\"font-size:90%;\">F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.4.7.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T5.4.7.3.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.7.3.1.1\" style=\"font-size:90%;\">Full Knowledge</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.4.7.3.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.7.3.2.1\" style=\"font-size:90%;\">0.340</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.4.7.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.7.3.3.1\" style=\"font-size:90%;\">0.347</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T5.4.7.3.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.7.3.4.1\" style=\"font-size:90%;\">0.343</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.4.7.3.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.7.3.5.1\" style=\"font-size:90%;\">0.591</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.4.7.3.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.7.3.6.1\" style=\"font-size:90%;\">0.639</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T5.4.7.3.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.7.3.7.1\" style=\"font-size:90%;\">0.614</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.4.7.3.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.7.3.8.1\" style=\"font-size:90%;\">0.301</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.4.7.3.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.7.3.9.1\" style=\"font-size:90%;\">0.397</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T5.4.7.3.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.7.3.10.1\" style=\"font-size:90%;\">0.342</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.4.7.3.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.7.3.11.1\" style=\"font-size:90%;\">0.550</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.4.7.3.12\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.7.3.12.1\" style=\"font-size:90%;\">0.321</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.4.7.3.13\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.7.3.13.1\" style=\"font-size:90%;\">0.406</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T5.1.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T5.1.1.1.1\" style=\"font-size:90%;\"> OPIEC</span>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T5.1.1.2.1\" style=\"font-size:90%;\">0.301</em></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T5.1.1.3.1\" style=\"font-size:90%;\">0.194</em></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T5.1.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T5.1.1.4.1\" style=\"font-size:90%;\">0.236</em></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.5.1\" style=\"font-size:90%;\">0.549</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.1.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.6.1\" style=\"font-size:90%;\">0.647</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T5.1.1.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.7.1\" style=\"font-size:90%;\">0.594</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.1.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.8.1\" style=\"font-size:90%;\">0.256</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.1.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.9.1\" style=\"font-size:90%;\">0.180</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T5.1.1.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.10.1\" style=\"font-size:90%;\">0.211</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.1.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.11.1\" style=\"font-size:90%;\">0.459</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.1.12\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.12.1\" style=\"font-size:90%;\">0.384</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.1.13\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.1.1.13.1\" style=\"font-size:90%;\">0.418</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T5.2.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T5.2.2.1.1\" style=\"font-size:90%;\"> Sem. frm.</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.2.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.2.2.2.1\" style=\"font-size:90%;\">0.352</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.2.2.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.2.2.3.1\" style=\"font-size:90%;\">0.275</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T5.2.2.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.2.2.4.1\" style=\"font-size:90%;\">0.309</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.2.2.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T5.2.2.5.1\" style=\"font-size:90%;\">0.580</em></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.2.2.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T5.2.2.6.1\" style=\"font-size:90%;\">0.585</em></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T5.2.2.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T5.2.2.7.1\" style=\"font-size:90%;\">0.583</em></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.2.2.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.2.2.8.1\" style=\"font-size:90%;\">0.360</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.2.2.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.2.2.9.1\" style=\"font-size:90%;\">0.270</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T5.2.2.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.2.2.10.1\" style=\"font-size:90%;\">0.309</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.2.2.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.2.2.11.1\" style=\"font-size:90%;\">0.460</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.2.2.12\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.2.2.12.1\" style=\"font-size:90%;\">0.418</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.2.2.13\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.2.2.13.1\" style=\"font-size:90%;\">0.438</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T5.3.3.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T5.3.3.1.1\" style=\"font-size:90%;\"> Wikidata</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.3.3.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.3.3.2.1\" style=\"font-size:90%;\">0.401</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.3.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.3.3.3.1\" style=\"font-size:90%;\">0.265</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T5.3.3.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.3.3.4.1\" style=\"font-size:90%;\">0.319</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.3.3.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.3.3.5.1\" style=\"font-size:90%;\">0.587</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.3.3.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.3.3.6.1\" style=\"font-size:90%;\">0.640</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T5.3.3.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.3.3.7.1\" style=\"font-size:90%;\">0.612</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.3.3.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T5.3.3.8.1\" style=\"font-size:90%;\">0.277</em></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.3.3.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T5.3.3.9.1\" style=\"font-size:90%;\">0.087</em></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T5.3.3.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T5.3.3.10.1\" style=\"font-size:90%;\">0.133</em></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.3.3.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.3.3.11.1\" style=\"font-size:90%;\">0.505</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.3.3.12\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.3.3.12.1\" style=\"font-size:90%;\">0.391</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.3.3.13\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.3.3.13.1\" style=\"font-size:90%;\">0.441</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T5.4.4.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T5.4.4.1.1\" style=\"font-size:90%;\"> Wikipedia</span>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T5.4.4.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.4.2.1\" style=\"font-size:90%;\">0.473</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T5.4.4.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.4.3.1\" style=\"font-size:90%;\">0.244</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S4.T5.4.4.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.4.4.1\" style=\"font-size:90%;\">0.322</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T5.4.4.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.4.5.1\" style=\"font-size:90%;\">0.569</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T5.4.4.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.4.6.1\" style=\"font-size:90%;\">0.701</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S4.T5.4.4.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.4.7.1\" style=\"font-size:90%;\">0.628</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T5.4.4.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.4.8.1\" style=\"font-size:90%;\">0.436</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T5.4.4.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.4.9.1\" style=\"font-size:90%;\">0.268</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S4.T5.4.4.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T5.4.4.10.1\" style=\"font-size:90%;\">0.332</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T5.4.4.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T5.4.4.11.1\" style=\"font-size:90%;\">0.519</em></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T5.4.4.12\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T5.4.4.12.1\" style=\"font-size:90%;\">0.376</em></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T5.4.4.13\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><em class=\"ltx_emph ltx_font_italic\" id=\"S4.T5.4.4.13.1\" style=\"font-size:90%;\">0.436</em></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>Dialogue knowledge selection performance on Ms.WoW test set (seen + unseen) by knowledge source. All knowledge sources are present during testing, simulating the scenario where a new knowledge source becomes available at test time.</figcaption>\n</figure>",
            "capture": "Table 5: Dialogue knowledge selection performance on Ms.WoW test set (seen + unseen) by knowledge source. All knowledge sources are present during testing, simulating the scenario where a new knowledge source becomes available at test time."
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T6\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T6.16\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T6.16.17.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T6.16.17.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"3\" id=\"S4.T6.16.17.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text ltx_font_italic\" id=\"S4.T6.16.17.1.2.1\" style=\"font-size:90%;\">OPIEC</span><span class=\"ltx_text\" id=\"S4.T6.16.17.1.2.2\" style=\"font-size:90%;\"></span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"3\" id=\"S4.T6.16.17.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text ltx_font_italic\" id=\"S4.T6.16.17.1.3.1\" style=\"font-size:90%;\">Sem. frm.</span><span class=\"ltx_text\" id=\"S4.T6.16.17.1.3.2\" style=\"font-size:90%;\"></span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"3\" id=\"S4.T6.16.17.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text ltx_font_italic\" id=\"S4.T6.16.17.1.4.1\" style=\"font-size:90%;\">Wikidata</span><span class=\"ltx_text\" id=\"S4.T6.16.17.1.4.2\" style=\"font-size:90%;\"></span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"3\" id=\"S4.T6.16.17.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text ltx_font_italic\" id=\"S4.T6.16.17.1.5.1\" style=\"font-size:90%;\">Wikipedia</span><span class=\"ltx_text\" id=\"S4.T6.16.17.1.5.2\" style=\"font-size:90%;\"></span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.16.18.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T6.16.18.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.16.18.2.1.1\" style=\"font-size:90%;\">Training &amp; Testing</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.16.18.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.16.18.2.2.1\" style=\"font-size:90%;\">P</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.16.18.2.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.16.18.2.3.1\" style=\"font-size:90%;\">R</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T6.16.18.2.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.16.18.2.4.1\" style=\"font-size:90%;\">F1</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.16.18.2.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.16.18.2.5.1\" style=\"font-size:90%;\">P</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.16.18.2.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.16.18.2.6.1\" style=\"font-size:90%;\">R</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T6.16.18.2.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.16.18.2.7.1\" style=\"font-size:90%;\">F1</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.16.18.2.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.16.18.2.8.1\" style=\"font-size:90%;\">P</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.16.18.2.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.16.18.2.9.1\" style=\"font-size:90%;\">R</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T6.16.18.2.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.16.18.2.10.1\" style=\"font-size:90%;\">F1</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.16.18.2.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.16.18.2.11.1\" style=\"font-size:90%;\">P</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.16.18.2.12\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.16.18.2.12.1\" style=\"font-size:90%;\">R</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.16.18.2.13\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.16.18.2.13.1\" style=\"font-size:90%;\">F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T6.1.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T6.1.1.1.1\" style=\"font-size:90%;\"> OPIEC</span>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.2.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.3.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T6.4.4.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.4.4.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.4.4.5.1\" style=\"font-size:90%;\">0.584</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.4.4.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.4.4.6.1\" style=\"font-size:90%;\">0.584</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T6.4.4.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.4.4.7.1\" style=\"font-size:90%;\">0.584</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.4.4.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.4.4.8.1\" style=\"font-size:90%;\">0.293</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.4.4.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.4.4.9.1\" style=\"font-size:90%;\">0.199</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T6.4.4.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.4.4.10.1\" style=\"font-size:90%;\">0.237</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.4.4.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.4.4.11.1\" style=\"font-size:90%;\">0.459</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.4.4.12\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.4.4.12.1\" style=\"font-size:90%;\">0.395</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.4.4.13\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.4.4.13.1\" style=\"font-size:90%;\">0.425</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T6.5.5.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T6.5.5.1.1\" style=\"font-size:90%;\"> Sem. frm.</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.8.8.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.8.8.5.1\" style=\"font-size:90%;\">0.349</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.8.8.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.8.8.6.1\" style=\"font-size:90%;\">0.274</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T6.8.8.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.8.8.7.1\" style=\"font-size:90%;\">0.307</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.6.6.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.7.7.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T6.8.8.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.8.8.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.8.8.8.1\" style=\"font-size:90%;\">0.352</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.8.8.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.8.8.9.1\" style=\"font-size:90%;\">0.266</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T6.8.8.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.8.8.10.1\" style=\"font-size:90%;\">0.303</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.8.8.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.8.8.11.1\" style=\"font-size:90%;\">0.452</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.8.8.12\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.8.8.12.1\" style=\"font-size:90%;\">0.413</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.8.8.13\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.8.8.13.1\" style=\"font-size:90%;\">0.431</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T6.9.9.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T6.9.9.1.1\" style=\"font-size:90%;\"> Wikidata</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.12.12.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.12.12.5.1\" style=\"font-size:90%;\">0.389</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.12.12.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.12.12.6.1\" style=\"font-size:90%;\">0.268</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T6.12.12.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.12.12.7.1\" style=\"font-size:90%;\">0.317</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.12.12.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.12.12.8.1\" style=\"font-size:90%;\">0.579</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.12.12.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.12.12.9.1\" style=\"font-size:90%;\">0.623</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T6.12.12.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.12.12.10.1\" style=\"font-size:90%;\">0.600</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.10.10.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.11.11.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T6.12.12.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.12.12.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.12.12.11.1\" style=\"font-size:90%;\">0.431</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.12.12.12\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.12.12.12.1\" style=\"font-size:90%;\">0.322</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.12.12.13\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.12.12.13.1\" style=\"font-size:90%;\">0.368</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.16.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T6.13.13.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T6.13.13.1.1\" style=\"font-size:90%;\"> Wikipedia</span>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T6.16.16.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.16.16.5.1\" style=\"font-size:90%;\">0.472</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T6.16.16.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.16.16.6.1\" style=\"font-size:90%;\">0.226</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S4.T6.16.16.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.16.16.7.1\" style=\"font-size:90%;\">0.306</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T6.16.16.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.16.16.8.1\" style=\"font-size:90%;\">0.575</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T6.16.16.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.16.16.9.1\" style=\"font-size:90%;\">0.687</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S4.T6.16.16.10\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.16.16.10.1\" style=\"font-size:90%;\">0.626</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T6.16.16.11\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.16.16.11.1\" style=\"font-size:90%;\">0.452</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T6.16.16.12\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.16.16.12.1\" style=\"font-size:90%;\">0.245</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S4.T6.16.16.13\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T6.16.16.13.1\" style=\"font-size:90%;\">0.318</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T6.14.14.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T6.15.15.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T6.16.16.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 6: </span>Dialogue knowledge selection performance on the Ms.WoW test set (seen + unseen), excluding the ablated knowledge source for each model; both training and testing are conducted with one knowledge source missing, simulating the scenario where one knowledge source never becomes available.</figcaption>\n</figure>",
            "capture": "Table 6: Dialogue knowledge selection performance on the Ms.WoW test set (seen + unseen), excluding the ablated knowledge source for each model; both training and testing are conducted with one knowledge source missing, simulating the scenario where one knowledge source never becomes available."
        },
        "7": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T7\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T7.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.1\">\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t\" id=\"S4.T7.1.1.1.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_top\" id=\"S4.T7.1.1.1.1.1\" style=\"font-size:90%;\">Prompt</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T7.1.2.1\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" id=\"S4.T7.1.2.1.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S4.T7.1.2.1.1.1\"><span class=\"ltx_text\" id=\"S4.T7.1.2.1.1.1.1\" style=\"font-size:90%;\">The following is the conversation between the \u201cWizard\", a knowledgeable speaker who can access Wikipedia knowledge sentences to chat to with the \u201cApprentice\", who does not have access to Wikipedia.\nThe conversation topic is {{topic}} and the persona setting of the Wizard is \u201c{{persona}}\".</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.3.2\">\n<td class=\"ltx_td ltx_align_justify\" id=\"S4.T7.1.3.2.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S4.T7.1.3.2.1.1\"><span class=\"ltx_ERROR undefined\" id=\"S4.T7.1.3.2.1.1.1\">\\hdashline</span><span class=\"ltx_text\" id=\"S4.T7.1.3.2.1.1.2\" style=\"font-size:90%;\">This is their conversation history:</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.4.3\">\n<td class=\"ltx_td ltx_align_justify\" id=\"S4.T7.1.4.3.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S4.T7.1.4.3.1.1\"><span class=\"ltx_text\" id=\"S4.T7.1.4.3.1.1.1\" style=\"font-size:90%;\">{{speaker 1}}: {{utterance 1.1}}</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.5.4\">\n<td class=\"ltx_td ltx_align_justify\" id=\"S4.T7.1.5.4.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S4.T7.1.5.4.1.1\"><span class=\"ltx_text\" id=\"S4.T7.1.5.4.1.1.1\" style=\"font-size:90%;\">{{speaker 2}}: {{utterance 2.1}}</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.6.5\">\n<td class=\"ltx_td ltx_align_justify\" id=\"S4.T7.1.6.5.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S4.T7.1.6.5.1.1\"><span class=\"ltx_text\" id=\"S4.T7.1.6.5.1.1.1\" style=\"font-size:90%;\">{{speaker 1}}: {{utterance 1.2}}</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.7.6\">\n<td class=\"ltx_td ltx_align_justify\" id=\"S4.T7.1.7.6.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S4.T7.1.7.6.1.1\"><span class=\"ltx_text\" id=\"S4.T7.1.7.6.1.1.1\" style=\"font-size:90%;\">\u2026</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.8.7\">\n<td class=\"ltx_td ltx_align_justify\" id=\"S4.T7.1.8.7.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S4.T7.1.8.7.1.1\"><span class=\"ltx_ERROR undefined\" id=\"S4.T7.1.8.7.1.1.1\">\\hdashline</span><span class=\"ltx_text\" id=\"S4.T7.1.8.7.1.1.2\" style=\"font-size:90%;\">Here is some retrieved Wikipedia knowledge for the Wizard.</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.9.8\">\n<td class=\"ltx_td ltx_align_justify\" id=\"S4.T7.1.9.8.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S4.T7.1.9.8.1.1\"><span class=\"ltx_text\" id=\"S4.T7.1.9.8.1.1.1\" style=\"font-size:90%;\">Some of the knowledge is in the tuple form, such as (subject, negation, relation, object, time, space) or (subject, relation, object).</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.10.9\">\n<td class=\"ltx_td ltx_align_justify\" id=\"S4.T7.1.10.9.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S4.T7.1.10.9.1.1\"><span class=\"ltx_text\" id=\"S4.T7.1.10.9.1.1.1\" style=\"font-size:90%;\">The Wizard can choose any subset of the following knowledge. It\u2019s also allowed to not choose any of them.</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.11.10\">\n<td class=\"ltx_td ltx_align_justify\" id=\"S4.T7.1.11.10.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S4.T7.1.11.10.1.1\"><span class=\"ltx_text\" id=\"S4.T7.1.11.10.1.1.1\" style=\"font-size:90%;\">{{(subject 1, relation 1, object 1)}}</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.12.11\">\n<td class=\"ltx_td ltx_align_justify\" id=\"S4.T7.1.12.11.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S4.T7.1.12.11.1.1\"><span class=\"ltx_text\" id=\"S4.T7.1.12.11.1.1.1\" style=\"font-size:90%;\">\u2026</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.13.12\">\n<td class=\"ltx_td ltx_align_justify\" id=\"S4.T7.1.13.12.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S4.T7.1.13.12.1.1\"><span class=\"ltx_ERROR undefined\" id=\"S4.T7.1.13.12.1.1.1\">\\hdashline</span><span class=\"ltx_text\" id=\"S4.T7.1.13.12.1.1.2\" style=\"font-size:90%;\">Given the knowledge above, make a very brief, such as one sentence, natural response for the Wizard.</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.14.13\">\n<td class=\"ltx_td ltx_align_justify\" id=\"S4.T7.1.14.13.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S4.T7.1.14.13.1.1\"><span class=\"ltx_text\" id=\"S4.T7.1.14.13.1.1.1\" style=\"font-size:90%;\">Not all information in the chosen knowledge has to be used in the response.</span></p>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.15.14\">\n<td class=\"ltx_td ltx_align_justify ltx_border_b\" id=\"S4.T7.1.15.14.1\" style=\"width:390.3pt;padding-left:5.0pt;padding-right:5.0pt;\">\n<p class=\"ltx_p ltx_align_top\" id=\"S4.T7.1.15.14.1.1\"><span class=\"ltx_text\" id=\"S4.T7.1.15.14.1.1.1\" style=\"font-size:90%;\">The Wizard\u2019s response is:</span></p>\n</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 7: </span>Prompt for Vicuna-13B dialogue response generation using Ms.WoW full knowledge.</figcaption>\n</figure>",
            "capture": "Table 7: Prompt for Vicuna-13B dialogue response generation using Ms.WoW full knowledge."
        },
        "8": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T8\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T8.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T8.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S4.T8.1.1.1.1\"><span class=\"ltx_text\" id=\"S4.T8.1.1.1.1.1\" style=\"font-size:90%;\">Hyper-parameter</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.1.1.2\"><span class=\"ltx_text\" id=\"S4.T8.1.1.1.2.1\" style=\"font-size:90%;\">Selector</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.1.1.3\"><span class=\"ltx_text\" id=\"S4.T8.1.1.1.3.1\" style=\"font-size:90%;\">Generator</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S4.T8.1.2.2.1\"><span class=\"ltx_text\" id=\"S4.T8.1.2.2.1.1\" style=\"font-size:90%;\">Learning rate</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.2.2.2\"><span class=\"ltx_text\" id=\"S4.T8.1.2.2.2.1\" style=\"font-size:90%;\">1e-5</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S4.T8.1.2.2.3\"><span class=\"ltx_text\" id=\"S4.T8.1.2.2.3.1\" style=\"font-size:90%;\">5e-5</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T8.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T8.1.3.1.1\"><span class=\"ltx_text\" id=\"S4.T8.1.3.1.1.1\" style=\"font-size:90%;\">Batch size</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T8.1.3.1.2\"><span class=\"ltx_text\" id=\"S4.T8.1.3.1.2.1\" style=\"font-size:90%;\">16</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T8.1.3.1.3\"><span class=\"ltx_text\" id=\"S4.T8.1.3.1.3.1\" style=\"font-size:90%;\">12</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T8.1.4.2.1\"><span class=\"ltx_text\" id=\"S4.T8.1.4.2.1.1\" style=\"font-size:90%;\">Epochs</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T8.1.4.2.2\"><span class=\"ltx_text\" id=\"S4.T8.1.4.2.2.1\" style=\"font-size:90%;\">10</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T8.1.4.2.3\"><span class=\"ltx_text\" id=\"S4.T8.1.4.2.3.1\" style=\"font-size:90%;\">10</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\" id=\"S4.T8.1.5.3.1\"><span class=\"ltx_text\" id=\"S4.T8.1.5.3.1.1\" style=\"font-size:90%;\">Max sequence length</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T8.1.5.3.2\"><span class=\"ltx_text\" id=\"S4.T8.1.5.3.2.1\" style=\"font-size:90%;\">512</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T8.1.5.3.3\"><span class=\"ltx_text\" id=\"S4.T8.1.5.3.3.1\" style=\"font-size:90%;\">512</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 8: </span>Fine-tuned hyper-parameters.</figcaption>\n</figure>",
            "capture": "Table 8: Fine-tuned hyper-parameters."
        },
        "9": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T9\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T9.11\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T9.11.12.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T9.11.12.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T9.11.12.1.1.1\" style=\"font-size:90%;\">Configurations</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T9.11.12.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T9.11.12.1.2.1\" style=\"font-size:90%;\">Training</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.12.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.12.1.3.1\" style=\"font-size:90%;\">R-1</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.12.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.12.1.4.1\" style=\"font-size:90%;\">R-2</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T9.11.12.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.12.1.5.1\" style=\"font-size:90%;\">R-L</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T9.11.12.1.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.12.1.6.1\" style=\"font-size:90%;\">F1</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.12.1.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.12.1.7.1\" style=\"font-size:90%;\">K-P</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.12.1.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.12.1.8.1\" style=\"font-size:90%;\">K-R</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.12.1.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.12.1.9.1\" style=\"font-size:90%;\">K-F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T9.3.3.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.3.3.4.1\" style=\"font-size:90%;\">No knowledge</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T9.3.3.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.3.3.5.1\" style=\"font-size:90%;\">No knowledge</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.3.3.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.3.3.6.1\" style=\"font-size:90%;\">0.189</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.3.3.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.3.3.7.1\" style=\"font-size:90%;\">0.043</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T9.3.3.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.3.3.8.1\" style=\"font-size:90%;\">0.159</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T9.3.3.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.3.3.9.1\" style=\"font-size:90%;\">0.207</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.1.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.2.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.3.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.11.13.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T9.11.13.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.13.2.1.1\" style=\"font-size:90%;\">WoW Full knowledge</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T9.11.13.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.13.2.2.1\" style=\"font-size:90%;\">WoW Full knowledge</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T9.11.13.2.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.13.2.3.1\" style=\"font-size:90%;\">0.261</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T9.11.13.2.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.13.2.4.1\" style=\"font-size:90%;\">0.101</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T9.11.13.2.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.13.2.5.1\" style=\"font-size:90%;\">0.225</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T9.11.13.2.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.13.2.6.1\" style=\"font-size:90%;\">0.265</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T9.11.13.2.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.13.2.7.1\" style=\"font-size:90%;\">0.502</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T9.11.13.2.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.13.2.8.1\" style=\"font-size:90%;\">0.162</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T9.11.13.2.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.13.2.9.1\" style=\"font-size:90%;\">0.245</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.11.14.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T9.11.14.3.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.14.3.1.1\" style=\"font-size:90%;\">Ms.WoW Full knowledge</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T9.11.14.3.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.14.3.2.1\" style=\"font-size:90%;\">Ms.WoW Full knowledge</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.14.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.14.3.3.1\" style=\"font-size:90%;\">0.259</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.14.3.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.14.3.4.1\" style=\"font-size:90%;\">0.094</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T9.11.14.3.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.14.3.5.1\" style=\"font-size:90%;\">0.222</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T9.11.14.3.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.14.3.6.1\" style=\"font-size:90%;\">0.264</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.14.3.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.14.3.7.1\" style=\"font-size:90%;\">0.460</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.14.3.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.14.3.8.1\" style=\"font-size:90%;\">0.159</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.14.3.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.14.3.9.1\" style=\"font-size:90%;\">0.236</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.4.4\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.4.4.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.4.4.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T9.4.4.1.1\" style=\"font-size:90%;\"> OPIEC</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.4.4.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.4.4.3.1\" style=\"font-size:90%;\">0.247</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.4.4.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.4.4.4.1\" style=\"font-size:90%;\">0.084</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T9.4.4.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.4.4.5.1\" style=\"font-size:90%;\">0.212</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T9.4.4.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.4.4.6.1\" style=\"font-size:90%;\">0.251</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.4.4.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.4.4.7.1\" style=\"font-size:90%;\">0.433</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.4.4.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.4.4.8.1\" style=\"font-size:90%;\">0.146</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.4.4.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.4.4.9.1\" style=\"font-size:90%;\">0.219</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.5.5\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.5.5.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.5.5.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T9.5.5.1.1\" style=\"font-size:90%;\"> sem. frm.</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.5.5.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.5.5.3.1\" style=\"font-size:90%;\">0.256</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.5.5.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.5.5.4.1\" style=\"font-size:90%;\">0.093</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T9.5.5.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.5.5.5.1\" style=\"font-size:90%;\">0.219</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T9.5.5.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.5.5.6.1\" style=\"font-size:90%;\">0.260</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.5.5.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.5.5.7.1\" style=\"font-size:90%;\">0.448</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.5.5.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.5.5.8.1\" style=\"font-size:90%;\">0.158</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.5.5.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.5.5.9.1\" style=\"font-size:90%;\">0.234</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.6.6\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.6.6.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.6.6.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T9.6.6.1.1\" style=\"font-size:90%;\"> Wikidata</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.6.6.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.6.6.3.1\" style=\"font-size:90%;\">0.256</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.6.6.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.6.6.4.1\" style=\"font-size:90%;\">0.093</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T9.6.6.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.6.6.5.1\" style=\"font-size:90%;\">0.220</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T9.6.6.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.6.6.6.1\" style=\"font-size:90%;\">0.261</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.6.6.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.6.6.7.1\" style=\"font-size:90%;\">0.440</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.6.6.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.6.6.8.1\" style=\"font-size:90%;\">0.154</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.6.6.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.6.6.9.1\" style=\"font-size:90%;\">0.228</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.7.7\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.7.7.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.7.7.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T9.7.7.1.1\" style=\"font-size:90%;\"> Wikipedia</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.7.7.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.7.7.3.1\" style=\"font-size:90%;\">0.251</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.7.7.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.7.7.4.1\" style=\"font-size:90%;\">0.089</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T9.7.7.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.7.7.5.1\" style=\"font-size:90%;\">0.215</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T9.7.7.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.7.7.6.1\" style=\"font-size:90%;\">0.256</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.7.7.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.7.7.7.1\" style=\"font-size:90%;\">0.459</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.7.7.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.7.7.8.1\" style=\"font-size:90%;\">0.164</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.7.7.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.7.7.9.1\" style=\"font-size:90%;\">0.242</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.11.15.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T9.11.15.4.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.15.4.1.1\" style=\"font-size:90%;\">WoW Gold knowledge</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T9.11.15.4.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.15.4.2.1\" style=\"font-size:90%;\">WoW Gold knowledge</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T9.11.15.4.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.15.4.3.1\" style=\"font-size:90%;\">0.317</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T9.11.15.4.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.15.4.4.1\" style=\"font-size:90%;\">0.150</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T9.11.15.4.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.15.4.5.1\" style=\"font-size:90%;\">0.278</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T9.11.15.4.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.15.4.6.1\" style=\"font-size:90%;\">0.317</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T9.11.15.4.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.15.4.7.1\" style=\"font-size:90%;\">0.387</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T9.11.15.4.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.15.4.8.1\" style=\"font-size:90%;\">0.528</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T9.11.15.4.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.15.4.9.1\" style=\"font-size:90%;\">0.446</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.11.16.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T9.11.16.5.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.16.5.1.1\" style=\"font-size:90%;\">Ms.WoW Gold knowledge</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T9.11.16.5.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.16.5.2.1\" style=\"font-size:90%;\">Ms.WoW Gold knowledge</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.16.5.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.16.5.3.1\" style=\"font-size:90%;\">0.322</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.16.5.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.16.5.4.1\" style=\"font-size:90%;\">0.149</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T9.11.16.5.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.16.5.5.1\" style=\"font-size:90%;\">0.280</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T9.11.16.5.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.16.5.6.1\" style=\"font-size:90%;\">0.321</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.16.5.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.16.5.7.1\" style=\"font-size:90%;\">0.311</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.16.5.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.16.5.8.1\" style=\"font-size:90%;\">0.576</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T9.11.16.5.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.16.5.9.1\" style=\"font-size:90%;\">0.404</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.8.8\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.8.8.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.8.8.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T9.8.8.1.1\" style=\"font-size:90%;\"> OPIEC</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.8.8.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.8.8.3.1\" style=\"font-size:90%;\">0.306</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.8.8.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.8.8.4.1\" style=\"font-size:90%;\">0.133</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T9.8.8.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.8.8.5.1\" style=\"font-size:90%;\">0.265</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T9.8.8.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.8.8.6.1\" style=\"font-size:90%;\">0.302</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.8.8.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.8.8.7.1\" style=\"font-size:90%;\">0.302</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.8.8.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.8.8.8.1\" style=\"font-size:90%;\">0.560</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.8.8.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.8.8.9.1\" style=\"font-size:90%;\">0.392</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.9.9\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.9.9.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.9.9.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T9.9.9.1.1\" style=\"font-size:90%;\"> sem. frm.</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.9.9.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.9.9.3.1\" style=\"font-size:90%;\">0.321</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.9.9.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.9.9.4.1\" style=\"font-size:90%;\">0.147</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T9.9.9.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.9.9.5.1\" style=\"font-size:90%;\">0.280</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T9.9.9.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.9.9.6.1\" style=\"font-size:90%;\">0.321</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.9.9.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.9.9.7.1\" style=\"font-size:90%;\">0.316</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.9.9.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.9.9.8.1\" style=\"font-size:90%;\">0.582</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.9.9.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.9.9.9.1\" style=\"font-size:90%;\">0.409</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.10.10\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.10.10.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T9.10.10.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T9.10.10.1.1\" style=\"font-size:90%;\"> Wikidata</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.10.10.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.10.10.3.1\" style=\"font-size:90%;\">0.320</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.10.10.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.10.10.4.1\" style=\"font-size:90%;\">0.145</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T9.10.10.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.10.10.5.1\" style=\"font-size:90%;\">0.279</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T9.10.10.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.10.10.6.1\" style=\"font-size:90%;\">0.319</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.10.10.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.10.10.7.1\" style=\"font-size:90%;\">0.313</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.10.10.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.10.10.8.1\" style=\"font-size:90%;\">0.580</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T9.10.10.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.10.10.9.1\" style=\"font-size:90%;\">0.406</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T9.11.11\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T9.11.11.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T9.11.11.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T9.11.11.1.1\" style=\"font-size:90%;\"> Wikipedia</span>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T9.11.11.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.11.3.1\" style=\"font-size:90%;\">0.319</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T9.11.11.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.11.4.1\" style=\"font-size:90%;\">0.145</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S4.T9.11.11.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.11.5.1\" style=\"font-size:90%;\">0.277</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S4.T9.11.11.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.11.6.1\" style=\"font-size:90%;\">0.318</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T9.11.11.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.11.7.1\" style=\"font-size:90%;\">0.311</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T9.11.11.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.11.8.1\" style=\"font-size:90%;\">0.585</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T9.11.11.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T9.11.11.9.1\" style=\"font-size:90%;\">0.406</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 9: </span>Response generation performance on test set (seen + unseen). All knowledge sources are present during testing, simulating the scenario where a new knowledge source becomes available at test time. Full knowledge refers to no knowledge selection, where all available candidate knowledge is used; gold knowledge refers to oracle knowledge selection.</figcaption>\n</figure>",
            "capture": "Table 9: Response generation performance on test set (seen + unseen). All knowledge sources are present during testing, simulating the scenario where a new knowledge source becomes available at test time. Full knowledge refers to no knowledge selection, where all available candidate knowledge is used; gold knowledge refers to oracle knowledge selection."
        },
        "10": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T10\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T10.8\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T10.8.9.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T10.8.9.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T10.8.9.1.1.1\" style=\"font-size:90%;\">Configurations</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T10.8.9.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T10.8.9.1.2.1\" style=\"font-size:90%;\">Training &amp; Testing</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S4.T10.8.9.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.9.1.3.1\" style=\"font-size:90%;\">R-1</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S4.T10.8.9.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.9.1.4.1\" style=\"font-size:90%;\">R-2</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S4.T10.8.9.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.9.1.5.1\" style=\"font-size:90%;\">R-L</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S4.T10.8.9.1.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.9.1.6.1\" style=\"font-size:90%;\">F1</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S4.T10.8.9.1.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.9.1.7.1\" style=\"font-size:90%;\">K-P</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S4.T10.8.9.1.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.9.1.8.1\" style=\"font-size:90%;\">K-R</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S4.T10.8.9.1.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.9.1.9.1\" style=\"font-size:90%;\">K-F1</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T10.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T10.1.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.1.1.2.1\" style=\"font-size:90%;\">Ms.WoW Full knowledge</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T10.1.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T10.1.1.1.1\" style=\"font-size:90%;\"> OPIEC</span>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T10.1.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.1.1.3.1\" style=\"font-size:90%;\">0.238</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T10.1.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.1.1.4.1\" style=\"font-size:90%;\">0.077</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T10.1.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.1.1.5.1\" style=\"font-size:90%;\">0.203</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T10.1.1.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.1.1.6.1\" style=\"font-size:90%;\">0.245</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T10.1.1.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.1.1.7.1\" style=\"font-size:90%;\">0.281</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T10.1.1.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.1.1.8.1\" style=\"font-size:90%;\">0.098</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T10.1.1.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.1.1.9.1\" style=\"font-size:90%;\">0.145</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.2.2\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T10.2.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T10.2.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T10.2.2.1.1\" style=\"font-size:90%;\"> sem. frm.</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.2.2.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.2.2.3.1\" style=\"font-size:90%;\">0.251</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.2.2.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.2.2.4.1\" style=\"font-size:90%;\">0.088</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T10.2.2.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.2.2.5.1\" style=\"font-size:90%;\">0.216</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T10.2.2.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.2.2.6.1\" style=\"font-size:90%;\">0.256</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.2.2.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.2.2.7.1\" style=\"font-size:90%;\">0.428</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.2.2.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.2.2.8.1\" style=\"font-size:90%;\">0.150</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.2.2.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.2.2.9.1\" style=\"font-size:90%;\">0.222</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.3.3\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T10.3.3.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T10.3.3.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T10.3.3.1.1\" style=\"font-size:90%;\"> Wikidata</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.3.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.3.3.3.1\" style=\"font-size:90%;\">0.257</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.3.3.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.3.3.4.1\" style=\"font-size:90%;\">0.093</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T10.3.3.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.3.3.5.1\" style=\"font-size:90%;\">0.221</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T10.3.3.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.3.3.6.1\" style=\"font-size:90%;\">0.261</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.3.3.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.3.3.7.1\" style=\"font-size:90%;\">0.331</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.3.3.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.3.3.8.1\" style=\"font-size:90%;\">0.116</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.3.3.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.3.3.9.1\" style=\"font-size:90%;\">0.171</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.4.4\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T10.4.4.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T10.4.4.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T10.4.4.1.1\" style=\"font-size:90%;\"> Wikipedia</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.4.4.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.4.4.3.1\" style=\"font-size:90%;\">0.245</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.4.4.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.4.4.4.1\" style=\"font-size:90%;\">0.083</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T10.4.4.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.4.4.5.1\" style=\"font-size:90%;\">0.209</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T10.4.4.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.4.4.6.1\" style=\"font-size:90%;\">0.250</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.4.4.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.4.4.7.1\" style=\"font-size:90%;\">0.361</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.4.4.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.4.4.8.1\" style=\"font-size:90%;\">0.126</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.4.4.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.4.4.9.1\" style=\"font-size:90%;\">0.186</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T10.5.5.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.5.5.2.1\" style=\"font-size:90%;\">Ms.WoW Gold knowledge</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T10.5.5.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T10.5.5.1.1\" style=\"font-size:90%;\"> OPIEC</span>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T10.5.5.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.5.5.3.1\" style=\"font-size:90%;\">0.253</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T10.5.5.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.5.5.4.1\" style=\"font-size:90%;\">0.094</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T10.5.5.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.5.5.5.1\" style=\"font-size:90%;\">0.217</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T10.5.5.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.5.5.6.1\" style=\"font-size:90%;\">0.260</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T10.5.5.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.5.5.7.1\" style=\"font-size:90%;\">0.198</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T10.5.5.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.5.5.8.1\" style=\"font-size:90%;\">0.378</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T10.5.5.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.5.5.9.1\" style=\"font-size:90%;\">0.260</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.6.6\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T10.6.6.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T10.6.6.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T10.6.6.1.1\" style=\"font-size:90%;\"> sem. frm.</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.6.6.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.6.6.3.1\" style=\"font-size:90%;\">0.306</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.6.6.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.6.6.4.1\" style=\"font-size:90%;\">0.134</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T10.6.6.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.6.6.5.1\" style=\"font-size:90%;\">0.266</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T10.6.6.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.6.6.6.1\" style=\"font-size:90%;\">0.309</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.6.6.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.6.6.7.1\" style=\"font-size:90%;\">0.274</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.6.6.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.6.6.8.1\" style=\"font-size:90%;\">0.500</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.6.6.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.6.6.9.1\" style=\"font-size:90%;\">0.354</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.7.7\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T10.7.7.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T10.7.7.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T10.7.7.1.1\" style=\"font-size:90%;\"> Wikidata</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.7.7.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.7.7.3.1\" style=\"font-size:90%;\">0.317</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.7.7.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.7.7.4.1\" style=\"font-size:90%;\">0.144</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T10.7.7.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.7.7.5.1\" style=\"font-size:90%;\">0.277</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T10.7.7.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.7.7.6.1\" style=\"font-size:90%;\">0.316</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.7.7.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.7.7.7.1\" style=\"font-size:90%;\">0.305</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.7.7.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.7.7.8.1\" style=\"font-size:90%;\">0.562</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T10.7.7.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.7.7.9.1\" style=\"font-size:90%;\">0.396</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T10.8.8\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T10.8.8.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T10.8.8.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T10.8.8.1.1\" style=\"font-size:90%;\"> Wikipedia</span>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T10.8.8.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.8.3.1\" style=\"font-size:90%;\">0.290</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T10.8.8.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.8.4.1\" style=\"font-size:90%;\">0.119</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S4.T10.8.8.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.8.5.1\" style=\"font-size:90%;\">0.250</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S4.T10.8.8.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.8.6.1\" style=\"font-size:90%;\">0.293</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T10.8.8.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.8.7.1\" style=\"font-size:90%;\">0.237</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T10.8.8.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.8.8.1\" style=\"font-size:90%;\">0.440</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T10.8.8.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T10.8.8.9.1\" style=\"font-size:90%;\">0.308</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 10: </span>Response generation performance on the knowledge-ablated test set (seen + unseen). Each model is trained and tested on the same knowledge sources (full or gold), simulating the scenario where one knowledge source never becomes available.</figcaption>\n</figure>",
            "capture": "Table 10: Response generation performance on the knowledge-ablated test set (seen + unseen). Each model is trained and tested on the same knowledge sources (full or gold), simulating the scenario where one knowledge source never becomes available."
        },
        "11": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T11\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T11.11\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T11.11.12.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T11.11.12.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T11.11.12.1.1.1\" style=\"font-size:90%;\">Configurations</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T11.11.12.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T11.11.12.1.2.1\" style=\"font-size:90%;\">Testing</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.12.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.12.1.3.1\" style=\"font-size:90%;\">R-1</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.12.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.12.1.4.1\" style=\"font-size:90%;\">R-2</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T11.11.12.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.12.1.5.1\" style=\"font-size:90%;\">R-L</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T11.11.12.1.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.12.1.6.1\" style=\"font-size:90%;\">F1</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.12.1.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.12.1.7.1\" style=\"font-size:90%;\">K-P</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.12.1.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.12.1.8.1\" style=\"font-size:90%;\">K-R</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.12.1.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.12.1.9.1\" style=\"font-size:90%;\">K-F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T11.3.3.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.3.3.4.1\" style=\"font-size:90%;\">No knowledge</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T11.3.3.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.3.3.5.1\" style=\"font-size:90%;\">No knowledge</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.3.3.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.3.3.6.1\" style=\"font-size:90%;\">0.187</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.3.3.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.3.3.7.1\" style=\"font-size:90%;\">0.031</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T11.3.3.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.3.3.8.1\" style=\"font-size:90%;\">0.147</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T11.3.3.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.3.3.9.1\" style=\"font-size:90%;\">0.202</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.1.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.2.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.3.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.11.13.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T11.11.13.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.13.2.1.1\" style=\"font-size:90%;\">WoW Full knowledge</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T11.11.13.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.13.2.2.1\" style=\"font-size:90%;\">WoW Full knowledge</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T11.11.13.2.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.13.2.3.1\" style=\"font-size:90%;\">0.202</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T11.11.13.2.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.13.2.4.1\" style=\"font-size:90%;\">0.046</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T11.11.13.2.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.13.2.5.1\" style=\"font-size:90%;\">0.153</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T11.11.13.2.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.13.2.6.1\" style=\"font-size:90%;\">0.216</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T11.11.13.2.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.13.2.7.1\" style=\"font-size:90%;\">0.216</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T11.11.13.2.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.13.2.8.1\" style=\"font-size:90%;\">0.184</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T11.11.13.2.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.13.2.9.1\" style=\"font-size:90%;\">0.199</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.11.14.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T11.11.14.3.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.14.3.1.1\" style=\"font-size:90%;\">Ms.WoW Full knowledge</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T11.11.14.3.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.14.3.2.1\" style=\"font-size:90%;\">Ms.WoW Full knowledge</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.14.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.14.3.3.1\" style=\"font-size:90%;\">0.196</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.14.3.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.14.3.4.1\" style=\"font-size:90%;\">0.044</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T11.11.14.3.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.14.3.5.1\" style=\"font-size:90%;\">0.149</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T11.11.14.3.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.14.3.6.1\" style=\"font-size:90%;\">0.212</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.14.3.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.14.3.7.1\" style=\"font-size:90%;\">0.382</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.14.3.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.14.3.8.1\" style=\"font-size:90%;\">0.260</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.14.3.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.14.3.9.1\" style=\"font-size:90%;\">0.310</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.4.4\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T11.4.4.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T11.4.4.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T11.4.4.1.1\" style=\"font-size:90%;\"> OPIEC</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.4.4.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.4.4.3.1\" style=\"font-size:90%;\">0.185</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.4.4.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.4.4.4.1\" style=\"font-size:90%;\">0.034</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T11.4.4.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.4.4.5.1\" style=\"font-size:90%;\">0.141</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T11.4.4.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.4.4.6.1\" style=\"font-size:90%;\">0.199</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.4.4.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.4.4.7.1\" style=\"font-size:90%;\">0.258</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.4.4.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.4.4.8.1\" style=\"font-size:90%;\">0.157</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.4.4.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.4.4.9.1\" style=\"font-size:90%;\">0.195</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.5.5\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T11.5.5.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T11.5.5.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T11.5.5.1.1\" style=\"font-size:90%;\"> sem. frm.</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.5.5.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.5.5.3.1\" style=\"font-size:90%;\">0.189</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.5.5.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.5.5.4.1\" style=\"font-size:90%;\">0.038</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T11.5.5.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.5.5.5.1\" style=\"font-size:90%;\">0.143</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T11.5.5.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.5.5.6.1\" style=\"font-size:90%;\">0.203</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.5.5.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.5.5.7.1\" style=\"font-size:90%;\">0.343</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.5.5.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.5.5.8.1\" style=\"font-size:90%;\">0.225</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.5.5.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.5.5.9.1\" style=\"font-size:90%;\">0.272</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.6.6\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T11.6.6.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T11.6.6.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T11.6.6.1.1\" style=\"font-size:90%;\"> Wikidata</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.6.6.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.6.6.3.1\" style=\"font-size:90%;\">0.196</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.6.6.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.6.6.4.1\" style=\"font-size:90%;\">0.043</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T11.6.6.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.6.6.5.1\" style=\"font-size:90%;\">0.149</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T11.6.6.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.6.6.6.1\" style=\"font-size:90%;\">0.211</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.6.6.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.6.6.7.1\" style=\"font-size:90%;\">0.379</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.6.6.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.6.6.8.1\" style=\"font-size:90%;\">0.256</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.6.6.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.6.6.9.1\" style=\"font-size:90%;\">0.306</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.7.7\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T11.7.7.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T11.7.7.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T11.7.7.1.1\" style=\"font-size:90%;\"> Wikipedia</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.7.7.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.7.7.3.1\" style=\"font-size:90%;\">0.196</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.7.7.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.7.7.4.1\" style=\"font-size:90%;\">0.043</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T11.7.7.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.7.7.5.1\" style=\"font-size:90%;\">0.149</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T11.7.7.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.7.7.6.1\" style=\"font-size:90%;\">0.210</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.7.7.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.7.7.7.1\" style=\"font-size:90%;\">0.373</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.7.7.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.7.7.8.1\" style=\"font-size:90%;\">0.247</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.7.7.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.7.7.9.1\" style=\"font-size:90%;\">0.297</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.11.15.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T11.11.15.4.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.15.4.1.1\" style=\"font-size:90%;\">WoW Gold knowledge</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T11.11.15.4.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.15.4.2.1\" style=\"font-size:90%;\">WoW Gold knowledge</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T11.11.15.4.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.15.4.3.1\" style=\"font-size:90%;\">0.218</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T11.11.15.4.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.15.4.4.1\" style=\"font-size:90%;\">0.053</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T11.11.15.4.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.15.4.5.1\" style=\"font-size:90%;\">0.170</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" id=\"S4.T11.11.15.4.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.15.4.6.1\" style=\"font-size:90%;\">0.226</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T11.11.15.4.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.15.4.7.1\" style=\"font-size:90%;\">0.049</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T11.11.15.4.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.15.4.8.1\" style=\"font-size:90%;\">0.086</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T11.11.15.4.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.15.4.9.1\" style=\"font-size:90%;\">0.062</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.11.16.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T11.11.16.5.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.16.5.1.1\" style=\"font-size:90%;\">Ms.WoW Gold knowledge</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T11.11.16.5.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.16.5.2.1\" style=\"font-size:90%;\">Ms.WoW Gold knowledge</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.16.5.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.16.5.3.1\" style=\"font-size:90%;\">0.230</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.16.5.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.16.5.4.1\" style=\"font-size:90%;\">0.061</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T11.11.16.5.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.16.5.5.1\" style=\"font-size:90%;\">0.176</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T11.11.16.5.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.16.5.6.1\" style=\"font-size:90%;\">0.236</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.16.5.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.16.5.7.1\" style=\"font-size:90%;\">0.114</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.16.5.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.16.5.8.1\" style=\"font-size:90%;\">0.351</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T11.11.16.5.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.16.5.9.1\" style=\"font-size:90%;\">0.172</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.8.8\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T11.8.8.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T11.8.8.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T11.8.8.1.1\" style=\"font-size:90%;\"> OPIEC</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.8.8.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.8.8.3.1\" style=\"font-size:90%;\">0.193</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.8.8.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.8.8.4.1\" style=\"font-size:90%;\">0.038</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T11.8.8.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.8.8.5.1\" style=\"font-size:90%;\">0.147</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T11.8.8.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.8.8.6.1\" style=\"font-size:90%;\">0.205</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.8.8.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.8.8.7.1\" style=\"font-size:90%;\">0.072</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.8.8.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.8.8.8.1\" style=\"font-size:90%;\">0.219</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.8.8.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.8.8.9.1\" style=\"font-size:90%;\">0.109</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.9.9\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T11.9.9.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T11.9.9.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T11.9.9.1.1\" style=\"font-size:90%;\"> sem. frm.</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.9.9.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.9.9.3.1\" style=\"font-size:90%;\">0.215</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.9.9.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.9.9.4.1\" style=\"font-size:90%;\">0.051</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T11.9.9.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.9.9.5.1\" style=\"font-size:90%;\">0.165</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T11.9.9.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.9.9.6.1\" style=\"font-size:90%;\">0.223</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.9.9.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.9.9.7.1\" style=\"font-size:90%;\">0.095</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.9.9.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.9.9.8.1\" style=\"font-size:90%;\">0.289</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.9.9.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.9.9.9.1\" style=\"font-size:90%;\">0.144</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.10.10\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T11.10.10.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T11.10.10.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T11.10.10.1.1\" style=\"font-size:90%;\"> Wikidata</span>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.10.10.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.10.10.3.1\" style=\"font-size:90%;\">0.220</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.10.10.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.10.10.4.1\" style=\"font-size:90%;\">0.056</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T11.10.10.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.10.10.5.1\" style=\"font-size:90%;\">0.170</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T11.10.10.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.10.10.6.1\" style=\"font-size:90%;\">0.226</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.10.10.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.10.10.7.1\" style=\"font-size:90%;\">0.108</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.10.10.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.10.10.8.1\" style=\"font-size:90%;\">0.325</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T11.10.10.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.10.10.9.1\" style=\"font-size:90%;\">0.162</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T11.11.11\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T11.11.11.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T11.11.11.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" id=\"S4.T11.11.11.1.1\" style=\"font-size:90%;\"> Wikipedia</span>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T11.11.11.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.11.3.1\" style=\"font-size:90%;\">0.224</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T11.11.11.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.11.4.1\" style=\"font-size:90%;\">0.057</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S4.T11.11.11.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.11.5.1\" style=\"font-size:90%;\">0.172</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S4.T11.11.11.6\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.11.6.1\" style=\"font-size:90%;\">0.230</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T11.11.11.7\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.11.7.1\" style=\"font-size:90%;\">0.110</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T11.11.11.8\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.11.8.1\" style=\"font-size:90%;\">0.332</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T11.11.11.9\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" id=\"S4.T11.11.11.9.1\" style=\"font-size:90%;\">0.165</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 11: </span>Vicuna-13B response generation performance on the test set (seen + unseen).</figcaption>\n</figure>",
            "capture": "Table 11: Vicuna-13B response generation performance on the test set (seen + unseen)."
        }
    },
    "image_paths": {},
    "references": [
        {
            "1": {
                "title": "Language models are few-shot learners.",
                "author": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020.",
                "venue": "Advances in neural information processing systems, 33:1877\u20131901.",
                "url": null
            }
        },
        {
            "2": {
                "title": "Retrieval-guided dialogue response generation via a matching-to-generation framework.",
                "author": "Deng Cai, Yan Wang, Wei Bi, Zhaopeng Tu, Xiaojiang Liu, and Shuming Shi. 2019.",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 1866\u20131875, Hong Kong, China. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "3": {
                "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality.",
                "author": "Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. 2023.",
                "venue": null,
                "url": null
            }
        },
        {
            "4": {
                "title": "An analysis of open information extraction based on semantic role labeling.",
                "author": "Janara Christensen, Stephen Soderland, and Oren Etzioni. 2011.",
                "venue": "In Proceedings of the sixth international conference on Knowledge capture, pages 113\u2013120.",
                "url": null
            }
        },
        {
            "5": {
                "title": "Plug and play language models: A simple approach to controlled text generation.",
                "author": "Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason Yosinski, and Rosanne Liu. 2020.",
                "venue": "In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.",
                "url": null
            }
        },
        {
            "6": {
                "title": "Wizard of Wikipedia: Knowledge-powered conversational agents.",
                "author": "Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. 2019.",
                "venue": "In Proceedings of the International Conference on Learning Representations (ICLR).",
                "url": null
            }
        },
        {
            "7": {
                "title": "{OPIEC}: An open information extraction corpus.",
                "author": "Kiril Gashteovski, Sebastian Wanner, Sven Hertling, Samuel Broscheit, and Rainer Gemulla. 2019.",
                "venue": "In Automated Knowledge Base Construction (AKBC).",
                "url": null
            }
        },
        {
            "8": {
                "title": "Generating informative responses with controlled sentence function.",
                "author": "Pei Ke, Jian Guan, Minlie Huang, and Xiaoyan Zhu. 2018.",
                "venue": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1499\u20131508, Melbourne, Australia. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "9": {
                "title": "Internet-augmented dialogue generation.",
                "author": "Mojtaba Komeili, Kurt Shuster, and Jason Weston. 2021.",
                "venue": "arXiv preprint arXiv:2107.07566.",
                "url": null
            }
        },
        {
            "10": {
                "title": "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.",
                "author": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019.",
                "venue": "arXiv preprint arXiv:1910.13461.",
                "url": null
            }
        },
        {
            "11": {
                "title": "Enhancing knowledge selection for grounded dialogues via document semantic graphs.",
                "author": "Sha Li, Mahdi Namazifar, Di Jin, Mohit Bansal, Heng Ji, Yang Liu, and Dilek Hakkani-Tur. 2022.",
                "venue": "In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2810\u20132823, Seattle, United States. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "12": {
                "title": "ROUGE: A package for automatic evaluation of summaries.",
                "author": "Chin-Yew Lin. 2004.",
                "venue": "In Text Summarization Branches Out, pages 74\u201381, Barcelona, Spain. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "13": {
                "title": "Roberta: A robustly optimized bert pretraining approach.",
                "author": "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019a.",
                "venue": "arXiv preprint arXiv:1907.11692.",
                "url": null
            }
        },
        {
            "14": {
                "title": "DuRecDial 2.0: A bilingual parallel corpus for conversational recommendation.",
                "author": "Zeming Liu, Haifeng Wang, Zheng-Yu Niu, Hua Wu, and Wanxiang Che. 2021.",
                "venue": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 4335\u20134347, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "15": {
                "title": "Knowledge aware conversation generation with explainable reasoning over augmented graphs.",
                "author": "Zhibin Liu, Zheng-Yu Niu, Hua Wu, and Haifeng Wang. 2019b.",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 1782\u20131792.",
                "url": null
            }
        },
        {
            "16": {
                "title": "Towards exploiting background knowledge for building conversation systems.",
                "author": "Nikita Moghe, Siddhartha Arora, Suman Banerjee, and Mitesh M. Khapra. 2018.",
                "venue": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2322\u20132332, Brussels, Belgium. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "17": {
                "title": "Gpt-4 technical report.",
                "author": "OpenAI. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2303.08774"
            }
        },
        {
            "18": {
                "title": "Sentence-BERT: Sentence embeddings using Siamese BERT-networks.",
                "author": "Nils Reimers and Iryna Gurevych. 2019.",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3982\u20133992, Hong Kong, China. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "19": {
                "title": "Neural responding machine for short-text conversation.",
                "author": "Lifeng Shang, Zhengdong Lu, and Hang Li. 2015.",
                "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1577\u20131586, Beijing, China. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "20": {
                "title": "Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage.",
                "author": "Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, et al. 2022.",
                "venue": "arXiv preprint arXiv:2208.03188.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Conceptnet 5.5: An open multilingual graph of general knowledge.",
                "author": "Robyn Speer, Joshua Chin, and Catherine Havasi. 2017.",
                "venue": "In Thirty-first AAAI conference on artificial intelligence.",
                "url": null
            }
        },
        {
            "22": {
                "title": "Llama: Open and efficient foundation language models.",
                "author": "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023.",
                "venue": "arXiv preprint arXiv:2302.13971.",
                "url": null
            }
        },
        {
            "23": {
                "title": "Commonsense and named entity aware knowledge grounded dialogue generation.",
                "author": "Deeksha Varshney, Akshara Prabhakar, and Asif Ekbal. 2022.",
                "venue": "In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1322\u20131335, Seattle, United States. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "24": {
                "title": "Naturalconv: A chinese dialogue dataset towards multi-turn topic-driven conversation.",
                "author": "Xiaoyang Wang, Chen Li, Jianqiao Zhao, and Dong Yu. 2021.",
                "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 14006\u201314014.",
                "url": null
            }
        },
        {
            "25": {
                "title": "Scalable zero-shot entity linking with dense entity retrieval.",
                "author": "Ledell Wu, Fabio Petroni, Martin Josifoski, Sebastian Riedel, and Luke Zettlemoyer. 2020.",
                "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6397\u20136407, Online. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "26": {
                "title": "More is better: Enhancing open-domain dialogue generation via multi-source heterogeneous knowledge.",
                "author": "Sixing Wu, Ying Li, Minghui Wang, Dawei Zhang, Yang Zhou, and Zhonghai Wu. 2021.",
                "venue": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 2286\u20132300.",
                "url": null
            }
        },
        {
            "27": {
                "title": "Proactive human-machine conversation with explicit conversation goal.",
                "author": "Wenquan Wu, Zhen Guo, Xiangyang Zhou, Hua Wu, Xiyuan Zhang, Rongzhong Lian, and Haifeng Wang. 2019.",
                "venue": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3794\u20133804, Florence, Italy. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "28": {
                "title": "K-PLUG: Knowledge-injected pre-trained language model for natural language understanding and generation in E-commerce.",
                "author": "Song Xu, Haoran Li, Peng Yuan, Yujia Wang, Youzheng Wu, Xiaodong He, Ying Liu, and Bowen Zhou. 2021.",
                "venue": "In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 1\u201317, Punta Cana, Dominican Republic. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "29": {
                "title": "Grounded conversation generation as guided traverses in commonsense knowledge graphs.",
                "author": "Houyu Zhang, Zhenghao Liu, Chenyan Xiong, and Zhiyuan Liu. 2020.",
                "venue": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2031\u20132043, Online. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "30": {
                "title": "Personalizing dialogue agents: I have a dog, do you have pets too?",
                "author": "Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. 2018.",
                "venue": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2204\u20132213, Melbourne, Australia. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "31": {
                "title": "Commonsense knowledge aware conversation generation with graph attention.",
                "author": "Hao Zhou, Tom Young, Minlie Huang, Haizhou Zhao, Jingfang Xu, and Xiaoyan Zhu. 2018.",
                "venue": "In IJCAI, pages 4623\u20134629.",
                "url": null
            }
        },
        {
            "32": {
                "title": "KdConv: A Chinese multi-domain dialogue dataset towards multi-turn knowledge-driven conversation.",
                "author": "Hao Zhou, Chujie Zheng, Kaili Huang, Minlie Huang, and Xiaoyan Zhu. 2020.",
                "venue": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7098\u20137108, Online. Association for Computational Linguistics.",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.03496v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.1",
            "2.2"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.1.1",
            "3.1.2",
            "3.1.3",
            "3.2",
            "3.2.1",
            "3.2.2",
            "3.3",
            "3.4"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.2",
            "4.2.1",
            "4.2.2",
            "4.3",
            "5",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4.1",
            "5",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
        ]
    },
    "research_context": {
        "paper_id": "2403.03496v1",
        "paper_title": "A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation",
        "research_background": "### Introduction\n\n***Motivation***\n\nThe primary motivation of this paper is to enhance the capabilities of knowledge-based open-domain dialogue systems, which aim to interact with humans across various domains using diverse support knowledge. While large language models (LLMs) like GPT-3 have revolutionized dialogue generation, they rely heavily on pre-trained, static knowledge, which can become outdated. Therefore, grounding response generation with dynamically retrieved and up-to-date knowledge remains a crucial approach to maintaining the relevance and accuracy of these systems.\n\n***Research Problem***\n\nThe paper addresses key challenges hindering the development and evaluation of multi-source knowledge-based dialogue systems. First, there is a lack of existing multi-source datasets for evaluating knowledge retrieval and response generation. Prior attempts have relied on silver-standard approaches or non-knowledge-based dialogues, which fail to clearly demonstrate the relationship between the effectiveness of knowledge selection and the final response quality. Second, existing models often assume that the knowledge sources available during training are the same as those available at inference time, which is unrealistic. New and useful knowledge sources continue to emerge, and models must be adaptable to take advantage of these without retraining.\n\n***Proposed Solution***\n\nTo overcome these challenges, the paper introduces a benchmark named Multi-source Wizard of Wikipedia (Ms.WoW). This dataset partitions pre-annotated, utterance-level grounded knowledge into multiple sources, simulating a real-world multi-source environment. Drawing on the Wizard of Wikipedia dataset, the authors create a controlled setup for evaluating both the knowledge selection and response generation capabilities. Furthermore, the paper proposes a novel \"dialogue knowledge plug-and-play\" task, wherein models are tested on their ability to incorporate and leverage new, previously unseen knowledge sources during inference in a zero-shot manner.\n\n### Related Work\n\n**Prior Contributions**\n\n1. **Single-Source Knowledge:**\n   - Encyclopedias (Dinan et al., 2019) have been useful in providing static domain-specific knowledge.\n   - Knowledge Graphs (Wu et al., 2019; Zhou et al., 2020; Liu et al., 2021) offer structured and relational data supporting richer dialogues.\n   - Personas (Zhang et al., 2018) enrich dialogues with user-specific profiles, fostering personalized interactions.\n   - Commonsense Knowledge (Zhou et al., 2018; Zhang et al., 2020; Wu et al., 2021; Varshney et al., 2022) infuses contextual understanding into conversations.\n\n2. **Multi-Source Knowledge:**\n   - Shuster et al. (2022) demonstrated that integrating multiple knowledge sources benefits the performance of pre-trained language models.\n\n3. **Challenges with Static Knowledge Models:**\n   - Li et al. (2022) and Dinan et al. (2019) identified the positive correlation between knowledge selection and response generation, emphasizing the need for dynamic knowledge integration.\n\n**Dataset Limitations:**\n   - Previous studies often employed non-knowledge-based dialogues with silver-labeled support knowledge (Liu et al., 2019b; Wu et al., 2021), lacking interpretability and ignoring the dynamic nature of real-world knowledge sources.\n\nBy creating Ms.WoW and proposing the plug-and-play task, this paper aims to fill these gaps and provide a robust and adaptable solution for knowledge-based dialogue systems.",
        "methodology": "### Methodology: Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation\n\nThe proposed method revolves around transforming the input WoW (Wizard of Wikipedia) knowledge sentences into modular and refined knowledge tuples to aid in open-domain dialogue generation. Below is a detailed description of the key components and innovative steps of the method:\n\n1. **Entity and Noun Phrase Extraction**:\n   - The system uses the spaCy library to extract entities and noun phrases from each sentence.\n   - These extractions are filtered using NLTK stop words to eliminate irrelevant terms.\n\n2. **Entity Linking**:\n   - Each extracted entity or noun phrase, along with its context (the original sentence), is passed to a dense retrieval-based entity linker based on the method introduced by Wu et al. (2020).\n   - The top-1 Wikidata entity candidate is chosen for each extracted entity or noun phrase.\n\n3. **Wikidata Triplet Retrieval**:\n   - All Wikidata triplets containing at least one linked entity are retrieved.\n   - Only the triplets where both the subject and object match the entities in the corresponding WoW knowledge sentence are kept, requiring one of the following conditions:\n     a. Both subject and object entities in the triplet appear in the set of linked Wikidata entities extracted from the WoW sentence.\n     b. Both subject and object match the WoW sentence using a fuzzy matcher with a score higher than a specified threshold.\n\n4. **Coverage Filtering**:\n   - For each WoW knowledge sentence, only triplets whose entities cover more than 75% of the extracted entity set of the sentence are retained.\n   - Sentences whose retrieved tuples cannot adequately cover their semantics are filtered out to minimize information loss.\n\n5. **Bag of Words Creation**:\n   - Each WoW knowledge sentence is tokenized and lemmatized, with punctuation and stop words removed, to create a \"bag of words\" for each sentence.\n   - All retrieved tuple elements are concatenated to create a pseudo-sentence and its corresponding bag of words.\n   - Only those sets of tuples whose bag of words cover more than 60% of the sentence's bag of words are preserved.\n\n6. **Supplementary Knowledge Source**:\n   - This filtering process leads to the creation of a fourth, supplementary knowledge source comprising Wikipedia sentences from the original WoW that couldn't be adequately captured by tuples from the other three main knowledge sources.\n\n7. **Redundancy Removal and Deduplication**:\n   - Since knowledge tuples are retrieved independently and may contain redundancies, deduplication is conducted to remove redundant tuples.\n   - The goal is to partition the knowledge into complementary sources by selecting the minimum number of tuples that maximally cover the full-coverage bag of words for the original WoW sentence.\n   - This problem is framed as a set-cover problem, acknowledged as NP-Complete, and a 2-approximation algorithm is applied to select the minimum set of tuples that cover the semantics of the original WoW sentence as effectively as the entire set of retrieved tuples.\n\nIn summary, the proposed method is a sophisticated pipeline designed to extract, link, and refine knowledge tuples from existing sentences, ensuring high coverage and minimal semantic loss. By integrating a dense retrieval-based entity linker, advanced fuzzy matching, and efficient set-cover algorithms, the method aims to enhance the precision and utility of knowledge used in dialogue generation.",
        "main_experiment_and_results": "### Main Experiment Setup\n\n#### Datasets\n- **Ms.WoW**: The primary dataset used for evaluating dialogue knowledge plug-and-play mechanisms.\n\n#### Approach\n1. **Input Preparation**:\n   - Input sequences are created by concatenating up to the last five utterances in the conversation history, the speaker roles, and the support knowledge sentences and tuples for each Wizard dialogue turn.\n   - Each support knowledge subsequence is prepended with a special token `<kg>`.\n\n2. **Model Components**:\n   - **Knowledge Selection**:\n     - Utilizes a Roberta-base model followed by a 2-layer feed-forward network.\n     - Takes each support knowledge tuple\u2019s corresponding `<kg>` token representation as its knowledge representation.\n     - Utterances without any candidate knowledge are skipped.\n\n   - **Response Generation**:\n     - Employs a BART-base model for standard response generation using the input sequences from the knowledge selection stage.\n\n#### Baselines\n- **Roberta-base (125M parameters)**: For knowledge selection.\n- **BART-base (139M parameters)**: For response generation.\n  \n  Both models are sourced from Huggingface and mostly use default hyper-parameters.\n\n#### Hardware\n- **Training and Inference**:\n  - Models are trained and tested using a single Nvidia Tesla V100S GPU, requiring approximately 3 hours for training and a few minutes for inference.\n  \n- **LLM Inference**:\n  - Utilizes Vicuna-13B-v1.1 LLM from Huggingface.\n  - Generation temperature is set to 0.7, with inference taking approximately 30 hours on a test set using 4 Nvidia Tesla V100S GPUs.\n\n### Evaluation Metrics\n- The paper does not specify the exact evaluation metrics in this section; however, typical metrics for such tasks may include:\n  - **Perplexity**\n  - **BLEU score**\n  - **ROUGE score**\n  - **Human evaluation metrics** (e.g., fluency, coherence, informativeness)\n\n### Main Experimental Results\n- The results of this exact study are not detailed in the provided excerpt."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To examine the ability of a pretrained dialogue model to adapt to support knowledge from new sources in a zero-shot fashion, focusing on reducing test performance difference when a previously unseen knowledge source becomes available.",
            "experiment_process": "Using the Ms.WoW dataset, the study simulates scenarios where a new knowledge source becomes available after the dialogue model has been trained. They ablate one of the Ms.WoW sources during training and test the ablated model with the full-knowledge test set, where the missing knowledge source becomes available at test time. For response generation, the knowledge-ablated models are compared to two upper bounds: (1) a model retrained with the full set of available knowledge (Ms.WoW full knowledge) and (2) a model using only gold (utterance-grounded) knowledge tuples (Ms.WoW gold knowledge). The conversation between the ",
            "result_discussion": "There is a significant performance gap between full-knowledge models and zero-shot adapted models, with this gap increasing if the ablated knowledge source constitutes a larger proportion of the overall knowledge. Ablated models show dramatically lower recall scores on newly available knowledge sources. However, the introduction of new knowledge sources can also enhance knowledge selection performance for some pre-existing sources, indicating synergy among different sources. For instance, Wikipedia sentence sources are trivially adapted by the pre-trained language model (Roberta) due to its extensive training on Wikipedia content.",
            "ablation_id": "2403.03496v1.No1"
        },
        {
            "research_objective": "To assess the performance differences among various knowledge sources during support knowledge selection and response generation.",
            "experiment_process": "Comparative evaluations of response generation metrics such as ROUGE scores, unigram F1, along with precision, recall, and F1 scores of the generated responses concerning different non-ablated candidate knowledge sources. Different types of knowledge sources are considered, including semantic frame tuples and Wikidata knowledge triplets.",
            "result_discussion": "Models perform significantly better on semantic frame tuples due to their high-precision extraction via human-engineered templates. Wikidata knowledge triplets are found to be less helpful in response generation, likely due to their generally shorter length and lower informativeness compared to other knowledge sources.",
            "ablation_id": "2403.03496v1.No2"
        },
        {
            "research_objective": "To determine the effect of the number of knowledge sources on knowledge selection and response generation performance, especially in zero-shot settings.",
            "experiment_process": "Evaluation of models under conditions where one knowledge source is ablated from both training and testing, emulating a scenario of permanent unavailability. Performance of these models is then compared to models where all knowledge sources are available during both training and testing.",
            "result_discussion": "Introducing additional knowledge sources benefits both knowledge selection and response generation, even in zero-shot settings. This supports the claim that more knowledge sources are beneficial for the dialogue knowledge plug-and-play challenge and performance in few-shot in-context learning for large language models (LLMs).",
            "ablation_id": "2403.03496v1.No3"
        },
        {
            "research_objective": "To analyze the performance of LLM-based response generation in zero-shot settings, comparing it to fine-tuned models and examining the behavior with varying knowledge source availability.",
            "experiment_process": "Comparison of response generated by Vicuna-based LLM with fine-tuned BART-based model on the Ms.WoW dataset under full-knowledge and gold knowledge conditions. The evaluation considers metrics such as mean token length, unigram overlap with gold responses and input knowledge.",
            "result_discussion": "LLM zero-shot responses are significantly longer and demonstrate higher unigram overlap with input knowledge than with gold responses, given sufficient knowledge. Unlike the BART model, LLM performance decreases with gold knowledge only instead of improving. However, similar to the BART model, the LLM's response generation performance improves significantly with more knowledge sources provided at test time.",
            "ablation_id": "2403.03496v1.No4"
        }
    ]
}