{
    "title": "Investigating Neural Machine Translation for Low-Resource Languages: Using Bavarian as a Case StudyPreprint accepted at SIGUL 2024",
    "abstract": "Machine Translation has made impressive progress in recent years offering close to human-level performance on many languages, but studies have primarily focused on high-resource languages with broad online presence and resources. With the help of growing Large Language Models, more and more low-resource languages achieve better results through the presence of other languages. However, studies have shown that not all low-resource languages can benefit from multilingual systems, especially those with insufficient training and evaluation data. In this paper, we revisit state-of-the-art Neural Machine Translation techniques to develop automatic translation systems between German and Bavarian. We investigate conditions of low-resource languages such as data scarcity and parameter sensitivity and focus on refined solutions that combat low-resource difficulties and creative solutions such as harnessing language similarity. Our experiment entails applying Back-translation and Transfer Learning to automatically generate more training data and achieve higher translation performance. We demonstrate noisiness in the data and present our approach to carry out text preprocessing extensively. Evaluation was conducted using combined metrics: BLEU, chrF and TER. Statistical significance results with Bonferroni correction show surprisingly high baseline systems, and that Back-translation leads to significant improvement. Furthermore, we present a qualitative analysis of translation errors and system limitations.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Neural Machine Translation (NMT) has progressed so far to reach human-level performance on some languages [1  ###reference_b1###] and has become one of the most prominent approaches within the research area of Machine Translation (MT). Its easy-to-adapt architecture has achieved impressive performance and high accuracy. Promising methods that fall under NMT include Transfer Learning [2  ###reference_b2###, 3  ###reference_b3###], pre-trained language models [4  ###reference_b4###, 5  ###reference_b5###], and multilingual models [6  ###reference_b6###, 7  ###reference_b7###, 8  ###reference_b8###, 9  ###reference_b9###] etc.\nHowever, existing NMT resources focus overwhelmingly on high-resource languages, which dominate a great portion of contents on the Internet and Social Media. Low-resource languages are often spoken by minorities with minimal online presence and insufficient amount of resources to achieve comparable NMT results [10  ###reference_b10###, 11  ###reference_b11###], but they might even have a very large population of speakers and still be under-resourced (such as Hindi, Bengali and Urdu). Growing interest in low-resource MT is evident through the annually held Conference on Machine Translation (WMT). In 2021, WMT featured tasks to promote MT in low-resource scenarios by exploring similarity and multilinguality [12  ###reference_b12###]. Among all tasks, the objective of the Very Low Resource Supervised Machine Translation task [13  ###reference_b13###] focused on Transfer Learning between German and Upper Sorbian. The task examined effects of utilizing similar languages and results show that combining Transfer Learning and data augmentation can successfully exploit language similarity during training.\nWe introduce our experiment to develop bidirectional state-of-the-art NMT systems for German and Bavarian, a classic high-resource to/from low-resource language pair. Inspired by WMT21, our experiment explores the generalizability of Back-translation and Transfer Learning from the highest-ranking approach from [14  ###reference_b14###]. Our approach covers the following: First, a simple Transformer [15  ###reference_b15###] is trained as the baseline. Secondly, we use the base model for Back-translation and take the extended corpus to train our second model. Lastly, we experiment with Transfer Learning [3  ###reference_b3###] by introducing German-French as the parent model. For evaluation we opt for a combination of three metrics: BLEU [16  ###reference_b16###], chrF [17  ###reference_b17###] and TER [18  ###reference_b18###]. Recent studies have argued that using BLEU as a single metric neglects the complexity of different linguistic characteristics. Using combined metrics and having various penalization standards may be able to capture translation errors more diversely [19  ###reference_b19###, 20  ###reference_b20###].\nBy choosing the language pair Bavarian / German we offer one exemplar for a low-resource language (combined with a high-resource one) that can serve as a reference point for further experimental work applied to other low-resource MT. This will ultimately help addressing the imbalance that still prevails between a handful of well-resourced languages and the many others that are not.\nThis paper makes the following contributions:\nWe offer a systematic evaluation of state-of-the-art NMT approaches for a language pair involving a low-resource language that has attracted little attention so far. This investigation explores both translation from as well as into the low-resource language. We focus on a Transformer baseline against Back-translation and a Transfer Learning approach.\nTo foster reproducibility and replicabilty (which is in the very spirit of SIGUL, LREC and COLING) we make all code available via a GitHub project repository111https://github.com/whher/nmt-de-bar  ###reference_###."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": "Non- and semi-parametric methods have been successfully applied to MT tasks in recent years. [33  ###reference_b33###] demonstrate a powerful combination of neural networks and non-parametric retrieval mechanisms to improve translation. kNN-MT follows the retrieval principle and proposes a more efficient non-parametric translation method, which augments the decoder of a pre-trained NMT model with a nearest neighbor retrieval mechanism, allowing direct access to data store of cached examples [34  ###reference_b34###]. This approach scales the decoder to an arbitrary amount of examples at test time, particularly strengthening decoder\u2019s translation capability. However, the big drawback is high computational cost and low decoding speed due to word-by-word generation. Chunk-based kNN-MT [35  ###reference_b35###] solves this problem by processing translation in chunks of words instead of passing single tokens through the data store.\nin MT is often done by training a high-resource language pair and using this parent model to initialize parameters in a child model with low-resource languages. For example, [3  ###reference_b3###] achieved translation improvements for Hansa, Turkish and Uzbek into English by using French-English as a parent model. Experiments from [36  ###reference_b36###] showed improvements using Transformers [15  ###reference_b15###] to train low-resource languages such as Estonian and Slovak. Their results pointed out key factors for a successful transfer include the size of the parent corpus and sharing the target or source language. For instance, Estonian-English as a child gained up to 2.44 BLEU with Finnish-English as a parent.\nIn Dual Transfer [2  ###reference_b2###], two parent models are used to initialize one child. Monolingual and parallel parent data were trained separately so that inner layers and embeddings can be transferred separately. Another recent study extends conventional transfer learning by additionally transferring probability distributions from parent to child. The Consistency-based Transfer Learning [37  ###reference_b37###] argues that parent prediction distribution is highly informative and can be useful to guide child translation. Their experiment showed that using German-English as a parent can achieve BLEU improvement up to 6.2 for Indonesian-English. Furthermore, the study from [6  ###reference_b6###] investigated a technique to incrementally add new language pairs to a multilingual MT model based on knowledge transfer, without posing the original model at risk for catastrophic forgetting.\n(PLMs) can be fine-tuned on low-resource languages. For instance, MT quality between Spanish and Quecha was shown to improve by leveraging Spanish-English and Spanish-Finnish PLMs [4  ###reference_b4###], with the latter yielding better results. Furthermore, [38  ###reference_b38###] combined a BERT [39  ###reference_b39###] encoder with a vanilla NMT decoder. Evaluation on low-resource languages like English-Vietnamese show that their two-stage training improves performance significantly compared to simple fine-tuning. XLM extends the features of BERT by using Cross-Lingual Masked Language Modeling [40  ###reference_b40###]. It has not only been reported to be beneficial for general unsupervised learning, but also for low-resource supervised MT such as English-Romanian. [41  ###reference_b41###] acknowledged the success of PLMs and presented their granulated study of fine-tuning, which showed that cross-attention layers are crucial to continue training downstream tasks and that they are powerful when adapting to new languages.\nTranslation data for low-resource languages are very difficult to come by and the primary source are often from the Web, making the data noisy and of poor quality [42  ###reference_b42###]. Extra analysis and text normalization are often required to prevent overfitting. For instance, inaccurate translations, noisy data and a large amount of text-overlap was found in the parallel data for African languages collected from large crowd-sourced platforms [22  ###reference_b22###]. Comparative results showed that an English-Zulu model trained with noisy data leads to unreliable results and a reduction of 7 BLEU. Research from [28  ###reference_b28###] corroborated this and provided guidelines for removing low-quality translations. They presented translation filtering by way of n-gram models trained on monolingual data and sentence-level char-BLEU score [43  ###reference_b43###] below 15 or over 90. Another novel filtering approach was proposed by [42  ###reference_b42###], where cosine similarity is determined based on available parallel (good quality) data, which is then used as the threshold to filter out pseudo-parallel (noisy) sentences.\nPrevious findings have pointed out that one-to-many models with middle-sized parallel corpora have achieved better results than one-to-one models [44  ###reference_b44###]. The multilingual model consisting of seven Asian languages developed by [9  ###reference_b9###] using the Asian Language Treebank [45  ###reference_b45###] is a great example. The presence of multiple in-domain aligned languages was argued to have contributed to better learn joint representations, hence leading to intra-language improvements. However, low-resource languages often face the risk of being overfitted in multilingual setups [46  ###reference_b46###].\n[7  ###reference_b7###] investigated the extent of multilinguality for low-resource languages. Their corpus consists of Bible texts in 1,108 languages, all aligned by verse. Results show that BLEU increase/decrease with respect to the number of training languages is not uniform across languages. Although the 5-language models outperform bilingual baseline models for Turkish and Xhosa, accuracy decrease can be found in Tagalog. The negative correlation between number of languages and translation quality is found to start at 10 languages, and maximal degeneration is observed at 100 languages, where addition of languages does not affect translation fluency anymore. This complication and pattern of degeneration can be explained by [47  ###reference_b47###], where text repetition harms the likelihood function during decoding. Furthermore, the errors in sequence modeling are more obvious for multilingual corpora, indicating that increased number of languages leads to increased destructive interference.\nLeveraging similarities between low-resource languages has been a growing interest in the MT community and is evident through the Similar Language Translation task (SLT) and Very Low Resource Supervised Machine Translation task at WMT21 [48  ###reference_b48###]. Regardless of level of closeness and degree of mutual structures, similarity between languages has shown to have positive interactions with MT quality [49  ###reference_b49###]. The goal of using language relatedness is similar to leveraging multilinguality. The major difference is they often do not use English as the pivot language, but translate between closely-related languages.\nIn the Very Low Resource Supervised Machine Translation task at WMT21 [13  ###reference_b13###] between German and Upper Sorbian, the participants were encouraged to make use of Czech and Polish datasets (languages closely related to Sorbian). Results pointed out the importance of including related languages, and that carefully applying tricks can compensate for using smaller datasets substantially. For example, NoahNMT\u2019s [50  ###reference_b50###] approach entails a Dual Transfer [2  ###reference_b2###] model that was initialized using German and Czech monolingual data as a parent model. The NRC-CNRC team\u2019s [14  ###reference_b14###] high-performance was attributed to the combination of minor tricks such as Back-translation [51  ###reference_b51###], monolingual data selection by way of consine similarity, Moore-Lewis filtering [52  ###reference_b52###] and BPE dropout [32  ###reference_b32###].\nThe technique Back-translation is further backed up by the study from [30  ###reference_b30###]. They investigated the effect on Alemannic dialect translation and experienced significant improvement, suggesting that Back-translation is a highly promising method for low-resource languages."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Machine Translation",
            "text": "Non- and semi-parametric methods have been successfully applied to MT tasks in recent years. [33  ###reference_b33###  ###reference_b33###] demonstrate a powerful combination of neural networks and non-parametric retrieval mechanisms to improve translation. kNN-MT follows the retrieval principle and proposes a more efficient non-parametric translation method, which augments the decoder of a pre-trained NMT model with a nearest neighbor retrieval mechanism, allowing direct access to data store of cached examples [34  ###reference_b34###  ###reference_b34###]. This approach scales the decoder to an arbitrary amount of examples at test time, particularly strengthening decoder\u2019s translation capability. However, the big drawback is high computational cost and low decoding speed due to word-by-word generation. Chunk-based kNN-MT [35  ###reference_b35###  ###reference_b35###] solves this problem by processing translation in chunks of words instead of passing single tokens through the data store.\nin MT is often done by training a high-resource language pair and using this parent model to initialize parameters in a child model with low-resource languages. For example, [3  ###reference_b3###  ###reference_b3###] achieved translation improvements for Hansa, Turkish and Uzbek into English by using French-English as a parent model. Experiments from [36  ###reference_b36###  ###reference_b36###] showed improvements using Transformers [15  ###reference_b15###  ###reference_b15###] to train low-resource languages such as Estonian and Slovak. Their results pointed out key factors for a successful transfer include the size of the parent corpus and sharing the target or source language. For instance, Estonian-English as a child gained up to 2.44 BLEU with Finnish-English as a parent.\nIn Dual Transfer [2  ###reference_b2###  ###reference_b2###], two parent models are used to initialize one child. Monolingual and parallel parent data were trained separately so that inner layers and embeddings can be transferred separately. Another recent study extends conventional transfer learning by additionally transferring probability distributions from parent to child. The Consistency-based Transfer Learning [37  ###reference_b37###  ###reference_b37###] argues that parent prediction distribution is highly informative and can be useful to guide child translation. Their experiment showed that using German-English as a parent can achieve BLEU improvement up to 6.2 for Indonesian-English. Furthermore, the study from [6  ###reference_b6###  ###reference_b6###] investigated a technique to incrementally add new language pairs to a multilingual MT model based on knowledge transfer, without posing the original model at risk for catastrophic forgetting.\n(PLMs) can be fine-tuned on low-resource languages. For instance, MT quality between Spanish and Quecha was shown to improve by leveraging Spanish-English and Spanish-Finnish PLMs [4  ###reference_b4###  ###reference_b4###], with the latter yielding better results. Furthermore, [38  ###reference_b38###  ###reference_b38###] combined a BERT [39  ###reference_b39###  ###reference_b39###] encoder with a vanilla NMT decoder. Evaluation on low-resource languages like English-Vietnamese show that their two-stage training improves performance significantly compared to simple fine-tuning. XLM extends the features of BERT by using Cross-Lingual Masked Language Modeling [40  ###reference_b40###  ###reference_b40###]. It has not only been reported to be beneficial for general unsupervised learning, but also for low-resource supervised MT such as English-Romanian. [41  ###reference_b41###  ###reference_b41###] acknowledged the success of PLMs and presented their granulated study of fine-tuning, which showed that cross-attention layers are crucial to continue training downstream tasks and that they are powerful when adapting to new languages."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "Refined Solutions",
            "text": "Translation data for low-resource languages are very difficult to come by and the primary source are often from the Web, making the data noisy and of poor quality [42  ###reference_b42###  ###reference_b42###]. Extra analysis and text normalization are often required to prevent overfitting. For instance, inaccurate translations, noisy data and a large amount of text-overlap was found in the parallel data for African languages collected from large crowd-sourced platforms [22  ###reference_b22###  ###reference_b22###]. Comparative results showed that an English-Zulu model trained with noisy data leads to unreliable results and a reduction of 7 BLEU. Research from [28  ###reference_b28###  ###reference_b28###] corroborated this and provided guidelines for removing low-quality translations. They presented translation filtering by way of n-gram models trained on monolingual data and sentence-level char-BLEU score [43  ###reference_b43###  ###reference_b43###] below 15 or over 90. Another novel filtering approach was proposed by [42  ###reference_b42###  ###reference_b42###], where cosine similarity is determined based on available parallel (good quality) data, which is then used as the threshold to filter out pseudo-parallel (noisy) sentences.\nPrevious findings have pointed out that one-to-many models with middle-sized parallel corpora have achieved better results than one-to-one models [44  ###reference_b44###  ###reference_b44###]. The multilingual model consisting of seven Asian languages developed by [9  ###reference_b9###  ###reference_b9###] using the Asian Language Treebank [45  ###reference_b45###  ###reference_b45###] is a great example. The presence of multiple in-domain aligned languages was argued to have contributed to better learn joint representations, hence leading to intra-language improvements. However, low-resource languages often face the risk of being overfitted in multilingual setups [46  ###reference_b46###  ###reference_b46###].\n[7  ###reference_b7###  ###reference_b7###] investigated the extent of multilinguality for low-resource languages. Their corpus consists of Bible texts in 1,108 languages, all aligned by verse. Results show that BLEU increase/decrease with respect to the number of training languages is not uniform across languages. Although the 5-language models outperform bilingual baseline models for Turkish and Xhosa, accuracy decrease can be found in Tagalog. The negative correlation between number of languages and translation quality is found to start at 10 languages, and maximal degeneration is observed at 100 languages, where addition of languages does not affect translation fluency anymore. This complication and pattern of degeneration can be explained by [47  ###reference_b47###  ###reference_b47###], where text repetition harms the likelihood function during decoding. Furthermore, the errors in sequence modeling are more obvious for multilingual corpora, indicating that increased number of languages leads to increased destructive interference.\nLeveraging similarities between low-resource languages has been a growing interest in the MT community and is evident through the Similar Language Translation task (SLT) and Very Low Resource Supervised Machine Translation task at WMT21 [48  ###reference_b48###  ###reference_b48###]. Regardless of level of closeness and degree of mutual structures, similarity between languages has shown to have positive interactions with MT quality [49  ###reference_b49###  ###reference_b49###]. The goal of using language relatedness is similar to leveraging multilinguality. The major difference is they often do not use English as the pivot language, but translate between closely-related languages.\nIn the Very Low Resource Supervised Machine Translation task at WMT21 [13  ###reference_b13###  ###reference_b13###] between German and Upper Sorbian, the participants were encouraged to make use of Czech and Polish datasets (languages closely related to Sorbian). Results pointed out the importance of including related languages, and that carefully applying tricks can compensate for using smaller datasets substantially. For example, NoahNMT\u2019s [50  ###reference_b50###  ###reference_b50###] approach entails a Dual Transfer [2  ###reference_b2###  ###reference_b2###] model that was initialized using German and Czech monolingual data as a parent model. The NRC-CNRC team\u2019s [14  ###reference_b14###  ###reference_b14###] high-performance was attributed to the combination of minor tricks such as Back-translation [51  ###reference_b51###  ###reference_b51###], monolingual data selection by way of consine similarity, Moore-Lewis filtering [52  ###reference_b52###  ###reference_b52###] and BPE dropout [32  ###reference_b32###  ###reference_b32###].\nThe technique Back-translation is further backed up by the study from [30  ###reference_b30###  ###reference_b30###]. They investigated the effect on Alemannic dialect translation and experienced significant improvement, suggesting that Back-translation is a highly promising method for low-resource languages."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Methodology",
            "text": "Motivated by the current findings, we present our experiment to develop bidirectional state-of-the-art NMT systems between German and Bavarian (ISO codes are de and bar respectively) - a language pair consisting of high- and low-resource languages.\nWhile Bavarian and Upper Sorbian are very different languages, they are both spoken by communities which are geographically located within or near Germany. We expect that applying the NMT methods that were found to be effective as part of WMT21 might result in similar findings for our setting.\nWe formulate the following three research questions (applied to the exemplar language pair Bavarian / German):\nRQ1: Does translating between similar languages achieve generally higher BLEU scores?\nRQ2: How well does Back-translation perform for (bidirectional) German-Bavarian?\nRQ3: Does cross-lingual transfer lead to improved results for German-Bavarian? More specifically, does the child model profit from related parent languages (i.e. German-French)?"
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Data Acquisition",
            "text": "The Tatoeba Challenge222https://github.com/Helsinki-nlp/tatoeba-challenge  ###reference_allenge### [53  ###reference_b53###] is one of the most active projects advocating low-resource MT. It maintains a leader board to compare submitted MT system performance from the community. To our knowledge, we are the first to conduct MT for German-Bavarian systems. We discovered parallel and monolingual sources on OPUS333https://opus.nlpl.eu/  ###reference_opus.nlpl.eu/### [21  ###reference_b21###], which we used for our experiments. More information about data sources can be found in our repository."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Framework",
            "text": "Inspired by the WMT21 Very Low Resource Supervised Machine Translation task [13  ###reference_b13###], our experiment revisits solutions that have been proven to work effectively with low-resource languages.\nFirst, a simple Transformer [15  ###reference_b15###] model using preprocessed parallel data is trained as the baseline model.\nSecondly, Back-translation is used to generate silver-paired parallel data to increase corpus size.\nLastly, we experiment with Transfer Learning [3  ###reference_b3###] by introducing German-French as the parent model.\nFor evaluation, we opt for an ensemble of automated MT metrics consisting of BLEU, chrF and TER for our systems. This is backed up by recent argumentation from [19  ###reference_b19###] and [20  ###reference_b20###], which states that multiple metrics instead of a single metric can diversify the evaluation based on different linguistic characteristics. This approach is a growing trend and has also been adopted by WMT21. Moreover, the study from [30  ###reference_b30###] pointed out BLEU is insufficient in word matching due to ununified orthography."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Implementation",
            "text": "In total we found 99.7K parallel sentences between Bavarian and German on OPUS (details can be found in our repository). After extensive preprocessing, the corpus size was reduced to 42K. To conduct data augmentation for the second system, we downloaded an extra 258K of German and 295K Bavarian monolingual text, mainly from Wikipedia and Wikinews. For German-French, we collected a total size of 184K of parallel data from Tatoeba and WikiMedia, which was reduced to 165K after preprocessing. We argue that the amount of in-domain data could contribute positively to Transfer Learning. Text preprocessing removes special symbols and noisy annotation, as proposed in previous studies [14  ###reference_b14###, 23  ###reference_b23###].\nIn addition to conventional text preprocessing, we took two further measures to de-noise the data. The additional measures entail check and remove misaligned texts by way of cosine similarity between source and target languages and smart sentence truncation. Based on the knowledge that Bavarian and German share common script and that many morphemes are alike, cosine similarity is a great way to support misalignment removal. We assume that a low cosine correlation indicates a low relevance in context between source and target. Following exploratory experiments, we set the correlation threshold at 0.48 and treat anything that falls below 0.48 as misalignment and remove this. We leave a systematic investigation into this aspect as future work.\nOur consideration for smart truncation comes from the long-tailed distribution of sentence lengths (outliers span up to 8000). Having long sentences in the corpus therefore poses potential threat that could damage MT performance [54  ###reference_b54###]. However, if all longer sequences were simply removed, we might lose a significant amount of precious parallel data. Therefore, we implemented smart truncation to deal with longer sequences in the parallel corpus. The truncation is set at the sequence length of 90.\nIn low-resource MT training, it is important to implement Cross Validation (CV) to ensure robust predictive performance and address problems like overfitting. In this case, where the training corpus is small, CV can provide insights on the variability. We opt for 5-fold CV to compare training results. After text preprocessing, the cleaned text are randomly shuffled and split into 5 chunks. The subsets are then concatenated respectively before training. For our baseline systems, 4 of 5 iterations have the subset size of 33813 for training and 8453 for test. The last iteration has the size of 33812 and 8454 respectively.\nof all three systems is carried out as explained in Section 3.2  ###reference_###. We utilized the MT development toolkit Sockeye [55  ###reference_b55###] for BPE encoding, model training and evaluation.\nFor statistical significance analysis, our experimental setup needs to take the multiple comparison problem into account. When testing multiple hypotheses simultaneously, the increased number of statistical inferences leads to increased probability of inexact inferences and Type I errors, making the conventional p threshold of 0.05 less reliable. This is a well-known problem, e.g. in the Genome- and Public Health-related research [56  ###reference_b56###, 57  ###reference_b57###].\nMethods that counteract multiple testing generally adjust  so that the chance of observing inaccurate significant result is reduced. The Bonferroni correction is the simplest (and fairly conservative) approach to cut off the  value. Bonferroni corrects the  by considering the set of n comparisons, causing the  threshold to become . With the Bonferroni correction, the p-value is set to 0.017 as opposed to 0.05."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Evaluation",
            "text": ""
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "Metrics",
            "text": "Despite the popularity of BLEU, recent studies from [19  ###reference_b19###] and [58  ###reference_b58###] questioned the phenomenon of using BLEU as a single metric, especially in low-resource scenarios, where language structures and scripts are complex and different from many high-resource languages. For example, the meta evaluation on Indian languages by [59  ###reference_b59###] reported higher human judgement correlation using COMET [60  ###reference_b60###] as opposed to BLEU. The limitation of BLEU also lies in the strong dependence on reference translation, whose quality can be highly unstable, especially when data is noisy. Issues such as translationese and poor reference diversity [20  ###reference_b20###] might also jeopardize the entire evaluation. We therefore include chrF and TER for a more diverse evaluation. ChrF is language-independent and has been reported to better capture complex morpho-syntactic structures in MT evaluation [17  ###reference_b17###]. TER (Translation Error Rate) quantifies the amount of edit operations it takes to change the system output to match the reference translation [18  ###reference_b18###]. This intuitive technique avoids knowledge-intensive calculations and focuses on matching hypothesis with reference. The main advantage of TER as opposed to BLEU is the lower penalty for phrasal shifts. TER has also been reported to correlate highly with human judgement and has been implemented in recent WMT tasks [12  ###reference_b12###, 61  ###reference_b61###]."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "System 1: Baseline",
            "text": "Despite the lack of sufficient amount of parallel data, baseline models in both translation directions exceed 60 BLEU (see Table 1  ###reference_###). For bar-de baseline, BLEU scores have an average of 66, chrF has an average of 78 and TER 33. We want to point out little variation between the folds - indicating that the results are robust. However, we observe relatively lower scores on the opposite direction, namely an average of 61 BLEU, 74 chrF and 36 TER. Variation are also small for the de-bar base systems."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "System 2: Back-translation",
            "text": "Back-translation (BT) was applied to the best performing baseline folds with monolingual data. Significant improvements can be observed in all three metrics for bar-de, whereas de-bar systems show subtle increase. In contrast to baseline systems, we observe a systematic increase of standard deviation. Where SD was between 0.3 and 0.6 for base systems, 0.7 to 2.2 SD was found in back-translated systems."
        },
        {
            "section_id": "5.4",
            "parent_section_id": "5",
            "section_name": "System 3: Transfer Learning",
            "text": "In contrast to surprisingly high baselines, both parent models perform similarly moderate, the fr-de model scored 29 BLEU, 52 chrF and 65 TER, whereas the de-fr parent reached 30 BLEU, 53 chrF and 65 TER. Given the fact that the German-French corpus size is significantly bigger than the German-Bavarian corpus, we had expected better performance of the parent models. However, our results are comparable with available German-French models on Hugging Face, for instance the one from Helsinki-NLP444https://huggingface.co/Helsinki-NLP/opus-mt-fr-de  ###reference_t-fr-de###.\nDespite the parents\u2019 BLEU scores are only a half of our baseline models, Transfer Learning improves children\u2019s performance considerably. For bar-de, the best system has 54 BLEU, 71 chrF and 42 TER, which is an increase of 25 BLEU and 19 chrF and decrease of 23 TER. For de-bar, the best model scored 51 BLEU, 65 chrF and 43 TER, which has a performance leap of 21 BLEU, 12 chrF and 22 TER from parent. We note that Transfer Learning improved translation capacity from parent to child with an enhancement of more than 20 BLEU. This corroborates with the recent studies on the use of Transfer Learning for low-resource languages. However, these improvement cannot compare with the very high baseline systems and their back-translated extensions."
        },
        {
            "section_id": "5.5",
            "parent_section_id": "5",
            "section_name": "Statistical Analysis",
            "text": "Two-tailed pairwise t-tests were conducted on all pairs with Bonferroni correction (p threshold is 0.017). Test statistics are shown in Tables 2  ###reference_### and 3  ###reference_###. For bar-de models, the BLEU results from baseline (M = 65.7, SD = 0.2) and BT (M = 70.5, SD = 2) indicate that Back-translation leads to significant improvement, t = -4.89, p = 0.0036. BT also performs significantly better than transferred systems (M = 52.8, SD = 0.7), t = 17.25, p < 0.0. Further statistics from the metrics chrF and TER corroborate these findings.\nFor de-bar models, the tendency is similar. ChrF results show a positive enhancement from baseline (M = 74.1, SD = 0.4) to BT (M = 75.5, SD = 0.7), t = -3.84, p = 0.149. The improvement of BT over transferred systems (M = 64.2, SD = 0.6) is significant as well. TER statistics also verify these findings. Interestingly, while chrF and TER successfully rejects the null hypothesis between baseline and BT performance, BLEU does the opposite. We argue that the results are nevertheless significant based on chrF and TER, and consider this disagreement between metrics as an occurrence derived from linguistically-different perspectives and computations."
        },
        {
            "section_id": "5.6",
            "parent_section_id": "5",
            "section_name": "Qualitative Analysis",
            "text": "We argue that the surprisingly high baseline results come from the similarity of the source and target languages. This corresponds to findings from [49  ###reference_b49###] that language relatedness contributes positively to MT quality. The analysis of [23  ###reference_b23###]\u2019s multilingual NMT on Indo-Aryan languages lists linguistic characteristics such as word-order construction, degree of inflection, amount of similar word root, meaning and conjunct verbs as the key drivers for improving training. Our experiments corroborate these argumentation, thus answering RQ1.\nThe significant improvement from Back-translation, which can be seen with all metrics, aligns well with previous findings. Especially in the submitted systems for WMT21 Very Low Resource Supervised MT between Upper Sorbian and German by [14  ###reference_b14###], Back-translation boosted the training corpus size and contributed to performance increase. However, we are aware of its limits. For instance, the augmented text includes many errors, which were inherited from the baseline systems. This issue of Translationese [62  ###reference_b62###] is widely discussed, especially in the context of using silver-paired data for MT. In our case, we have opted for a smaller amount of augmented data, with the aim to reduce Translationese as much as possible while still allowing model improvement. We therefore answer RQ2 that Back-translation contributes positively.\nRegarding RQ3, we point out that while Transfer Learning did improve performance from parent to child, its final performance was not sufficient to exceed the other two systems.\nWe note that our results are similar to the ones from the German - Upper Sorbian translation task from WMT21. Our baseline and back-translated models have an accuracy range between 60 to 73 BLEU and 74 to 82 chrF, comparable with the final scores from the German - Upper Sorbian task. However, it is interesting to note that their chrF scores are substantially higher than ours (by 10), while our BLEU scores are similar. This brings us back to the notion that all metrics work linguistically different and these variations reflect through different languages.\nFurthermore, a common finding can be observed between our experimental results and the WMT21 experiments we comapre against, namely the result discrepancy between high-to-low and low-to-high directions. In our study, de-bar is ca. 10 BLEU and 10 chrF behind bar-de. Similarly but not as extreme, Upper Sorbian - German also performs better than its high-to-low counter direction. This performance gap on the same corpus but different translation directions raises attention, with possible reasons due to the multiple orthographic standards and sub-dialects in our case.\nTable 4  ###reference_### depicts two translation examples. We translate the German phrase \u201cSie hat heute Abend im Restaurant Fisch bestellt\" (English meaning \u201cshe ordered fish in the restaurant tonight.\") into Bavarian using all of our systems. We observe that while Base and BT outputs look similar, their differences could come from various sub-dialects in the corpus. For instance, the term \u201cheute\" was translated into \u201cheit\" and \u201cheid\", with only the last consonant different. However, in the Germanic linguistics, these consonants \u201ct\" and \u201cd\" differ themselves in voice. The linguistic notion of Fortis and Lenis555https://en.wikipedia.org/wiki/Fortis_and_lenis  ###reference_enis### differentiates oral pressure that is given to these consonants. Thus, we suspect these differences come from various dialects."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we presented experimental work in Neural Machine Translation with the aim to push forward our understanding of how to best address the gap between a handful of well-resourced languages and the long tail of languages for which no sufficient resources are available.\nMore specifically, we focused on methods and case studies that have shown promising results for languages with limited resources. We conceptualized the problems of noisy data and data shortage by way of recent studies. We revisited creative solutions designed to combat these challenges such as Back-translation, multilingual training and language relatedness.\nOur own low-resource implementation utilized data augmentation and cross-lingual transfer on German and Bavarian. We report our steps to preprocess the corpus and carry out training for three bidirectional systems. 5-fold cross validation was carried out on each system to compare robustness. We opted for a combined metric system using BLEU, chrF and TER to evaluate translation from different perspectives. For multiple hypothesis testing, pairwise t-tests with Bonferroni correction were conducted to test for statistical significance.\nResults show that translation between similar languages performs generally better and that augmented data contribute positively. However, even though cross-lingual transfer showed huge improvement from parent to child, it was not able to exceed baseline and back-translated models. We recognize that Transfer Learning is an effective approach for low-resource languages, but note that in our study language similarity played a more important role.\nTo support reproducibility and replicability all code is made available via GitHub."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Limitations",
            "text": "The Bavarian orthography has been a known problem for decades, as it is mostly a spoken language and has not been properly standardized. For example, the word \u2019Bavarian\u2019 alone can be written in two ways: Boarisch or Bairisch. The investigation by [63  ###reference_b63###] illustrates that there are multiple Bavarian orthographic conventions. From a computational perspective, the issue is \u201cdeciding which representation should be given precedence\", as stated in the Bribri case study by [11  ###reference_b11###]. Overcoming dialectal variations is also a problem of politics that can carry on for years. In light of the findings by [64  ###reference_b64###], we would add that the automated translation of Bavarian should - like other under-sourced languages - be carefully planned with ethical considerations, and that purely using web-scraped data to deploy translation systems might neglect the concerns of speakers.\nAnother challenge lies in multiple sub-dialects. This phenomenon can be observed in our corpus, which is mined from the Bavarian Wikipedia, where articles are written in different regional dialects. We argue that these sub-dialects in the parallel corpus lead to translation confusion, resulting in translation outputs which consist of mixed accents. Nevertheless, should there be a more refined and organized corpus of a particular sub-dialect, our systems can serve as baselines for fine-tuning.\nAnother, more general limitation is the fact that throughout our work we conducted purely technical evaluations. The strength of such an experimental setup is that it can be reproduced and offers objective results. However, it is clearly necessary to involve native speakers to gain more insights into the quality of any translation process. We mitigated against the problem by choosing not just a single evaluation metric (such as BLEU), but no matter how many different metrics are chosen they are no substitute for user studies."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "Future Work",
            "text": "Following our findings and the limitations stated above, we propose further research directions to inspire future work: First, the curation of a more refined and organized parallel corpus for modern German-Bavarian to help establish a high quality benchmark for training and evaluation. An example to achieve this is through recruiting native speakers in both Bavarian and German who have an adequate amount of linguistic knowledge. This annotation could include not only translation of parallel sentences, but also the sub-dialects or Bavarian regional variations the speakers associate themselves with. This human-annotated dataset could furthermore be split into two parts, one for training and another for evaluation.\nAdditionally, identification of dialects would be an approach to counter translation confusion and mixed accents. This could help unify and isolate non-standardized languages or dialects. As mentioned in the previous section, a great way to start modelling sub-dialect detection is to automatically analyze the Wikipedia articles with their corresponding sub-dialects. This would greatly reduce the training corpus size, but additional measures to increase the corpus size could be taken, such as acquiring diverse datasets (i.e. open-source subtitles of Bavarian TV-programs or historical documents). More generally, we see our work as a reference benchmark for future work \u2013 be it to explore the same language pair further or other work into the general problem of low-resource language translation efforts."
        },
        {
            "section_id": "9",
            "parent_section_id": null,
            "section_name": "Ethical Considerations",
            "text": "Ethical concerns arise whenever natural language is being sampled and used to train machine learning systems. For this experimental work we used existing test collections and other freely accessible data. All the experiments are conducted within the ethical framework imposed on us by our institution. In this context we did not identify a specific ethical issue.\nHowever, it is clear that once any automated translation system is on its way to be deployed that care must be taken to (a) train it on representative samples, (b) mitigate against common biases, and (c) make sure no personal information is included in the training data. If trained on social media data there is also a risk that toxic content might surface. Care must be taken to take these issues seriously (rather than treating this as a box-ticking exercise), but we would argue that there are no ethical concerns arising from this work that have not already been identified previously."
        }
    ],
    "url": "http://arxiv.org/html/2404.08259v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.1"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "5",
            "5.1",
            "5.2",
            "5.3",
            "5.4",
            "5.5",
            "5.6"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "1",
            "3",
            "3.2",
            "4",
            "5",
            "5.1",
            "5.2",
            "5.3",
            "5.4",
            "5.5",
            "5.6"
        ]
    },
    "research_context": {
        "paper_id": "2404.08259v1",
        "paper_title": "Investigating Neural Machine Translation for Low-Resource Languages: Using Bavarian as a Case StudyPreprint accepted at SIGUL 2024",
        "research_background": "### Motivation\n\nThe motivation behind the paper is to address the imbalance in Neural Machine Translation (NMT) research that overwhelmingly focuses on high-resource languages. The authors identify a significant gap in the application of NMT to low-resource languages, which often have insufficient online presence and resources. They aim to address this gap and contribute to the burgeoning interest in low-resource Machine Translation (MT), as highlighted by the inclusion of low-resource tasks in forums like the Conference on Machine Translation (WMT). By investigating methods that can improve NMT for low-resource languages, the paper aims to facilitate more inclusive and equitable advancements in MT technology.\n\n### Research Problem\n\nThe research problem tackled by this paper is the lack of effective NMT systems for low-resource languages. Specifically, the authors aim to develop and evaluate bidirectional NMT systems for German and Bavarian, using methods like Back-translation and Transfer Learning. The core question is whether these methods can be generalized to produce state-of-the-art translation performance for other low-resource languages, thereby helping to mitigate the existing imbalance between well-resourced and under-resourced languages in the field of MT.\n\n### Relevant Prior Work\n\nThe paper builds on several prior works:\n\n1. **NMT Achievements**:\n    - Neural Machine Translation has reached human-level performance on high-resource languages [1 ###reference_b1###].\n    - Architectural designs and methods in NMT such as Transfer Learning [2 ###reference_b2###, 3 ###reference_b3###], pre-trained language models [4 ###reference_b4###, 5 ###reference_b5###], and multilingual models [6 ###reference_b6###, 7 ###reference_b7###, 8 ###reference_b8###, 9 ###reference_b9###] have shown impressive results.\n\n2. **Limitations on Low-Resource Languages**:\n    - Existing NMT resources are predominantly focused on high-resource languages, leaving low-resource languages under-studied [10 ###reference_b10###, 11 ###reference_b11###].\n\n3. **Interest in Low-Resource MT**:\n    - The Conference on Machine Translation (WMT) has shown growing interest in low-resource MT scenarios [12 ###reference_b12###].\n    - The Very Low Resource Supervised Machine Translation task in WMT 2021 demonstrated the effectiveness of Transfer Learning and data augmentation between German and Upper Sorbian [13 ###reference_b13###].\n\n4. **State-of-the-Art Approaches**:\n    - The highest-ranking approach in WMT21 [14 ###reference_b14###] was utilized as a basis for exploring the generalizability of Back-translation and Transfer Learning.\n    - Frameworks such as Transformers [15 ###reference_b15###] are used for establishing baselines.\n\n5. **Evaluation Metrics**:\n    - The study uses a combination of BLEU, chrF, and TER for evaluation as recent studies suggest that using multiple metrics provides a more comprehensive assessment of NMT performance [16 ###reference_b16###, 17 ###reference_b17###, 18 ###reference_b18###, 19 ###reference_b19###, 20 ###reference_b20###].\n\nBy grounding their research in these prior works, the authors seek to validate and extend current techniques to improve translation quality for low-resource languages like Bavarian.",
        "methodology": "The methodology section outlines the proposed method to develop bidirectional state-of-the-art Neural Machine Translation (NMT) systems for a language pair consisting of a high-resource language (German) and a low-resource language (Bavarian). The key components and innovations of the proposed method include:\n\n1. **Language Pair Selection**: The experiment focuses on the language pair of German (de) and Bavarian (bar), leveraging the high-resource nature of German to address the low-resource challenges of Bavarian.\n\n2. **Motivation and Background**:\n   - The researchers draw inspiration from the effectiveness of NMT methods used in the WMT21 competition.\n   - They take into account the geographical and linguistic context, comparing Bavarian with Upper Sorbian to understand the regional language dynamics within and near Germany.\n\n3. **Research Questions**:\n   - **RQ1: Higher BLEU Scores for Similar Languages**: The study investigates whether translating between linguistically similar languages (German and Bavarian in this case) leads to generally higher BLEU scores, a common metric for evaluating the quality of machine-translated text.\n   - **RQ2: Back-translation Performance**: The researchers explore the efficacy of back-translation, a technique where synthetic bilingual data is generated by translating monolingual data from the target language into the source language and vice versa, for improving bidirectional translation between German and Bavarian.\n   - **RQ3: Cross-lingual Transfer**: The study examines the impact of cross-lingual transfer learning, specifically whether a child model (e.g., German-Bavarian) benefits from being trained using related parent languages (e.g., German-French), enhancing the translation quality.\n\nThe proposed innovations lie in the application of these NMT strategies to a low-resource language and investigating the nuances of translating between linguistically and geographically related languages. The outcomes of this research aim to extend the findings of NMT applications to new language pairs, potentially offering broader insights into low-resource machine translation.",
        "main_experiment_and_results": "### Main Experiment Setup\n\n**Datasets:**\n\n1. **Bavarian-German Parallel Data:**\n   - Initial dataset: 99.7K parallel sentences from OPUS.\n   - Post-processing dataset: Reduced to 42K parallel sentences.\n\n2. **Monolingual Data for Data Augmentation:**\n   - Extra German text: 258K sentences.\n   - Extra Bavarian text: 295K sentences.\n   - Sources: Mainly Wikipedia and Wikinews.\n\n3. **German-French Parallel Data:**\n   - Initial dataset: 184K sentences from Tatoeba and WikiMedia.\n   - Post-processing dataset: Reduced to 165K parallel sentences.\n\n**Baselines:**\n- **Cross Validation (CV):** A 5-fold CV approach to ensure robust predictive performance and avoid overfitting given the small dataset size. The cleaned dataset was shuffled and split into 5 folds, with each iteration using 4 folds for training and 1 for testing.\n\n**Model Training and Evaluation:**\n- **MT Toolkit:** Utilized Sockeye for BPE encoding, model training, and evaluation.\n- **Preprocessing Measures:**\n  - Removal of special symbols and noisy annotations.\n  - De-noising measures:\n    - Misalignment removal using cosine similarity with a threshold set at 0.48.\n    - Smart truncation for long sentences exceeding a length of 90 to handle outliers without losing significant data.\n\n**Evaluation Metrics:**\n- **Statistical Significance Analysis:**\n  - To address the multiple comparison problem and avoid Type I errors, the Bonferroni correction was applied.\n  - Adjusted p-value threshold: Set to 0.017 (from the conventional 0.05).\n\n### Main Experimental Results\n\n- The experimental setup was detailed, ensuring a robust process through multiple preprocessing and data handling techniques.\n- The main experiment included comprehensive measures to clean and prepare the data, which involved removing misaligned texts and truncating long sentences.\n- Cross validation was employed to ensure the robustness of the results, mitigating the risk of overfitting.\n- The use of Sockeye for model training and evaluation facilitated standardized and replicable outcomes.\n- Statistical significance in the results was assured by applying the Bonferroni correction, setting a stringent p-value threshold of 0.017 to account for multiple comparisons.\n\nOverall, significant effort was placed on ensuring data quality and robustness of the experiment to provide reliable translation performance analysis for Bavarian, considered a low-resource language in the context of Neural Machine Translation."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To evaluate the translation performance of a Transformer baseline model between the low-resource language Bavarian and the high-resource language German.",
            "experiment_process": "A simple Transformer model using preprocessed parallel data of Bavarian and German was trained as the baseline model. The corpus was preprocessed to remove special symbols and noisy annotations.",
            "result_discussion": "Baseline models in both translation directions exceed 60 BLEU, with average scores of 66 BLEU, 78 chrF, and 33 TER for bar-de; and 61 BLEU, 74 chrF, and 36 TER for de-bar. Results exhibit little variation between the folds, indicating robust scores.",
            "ablation_id": "2404.08259v1.No1"
        },
        {
            "research_objective": "To assess the impact of Back-translation (BT) on translation performance between German and Bavarian.",
            "experiment_process": "Back-translation was applied to the best performing baseline folds with additional monolingual data. Silver-paired parallel data was generated to increase the training corpus size. The translation results were evaluated using BLEU, chrF, and TER metrics.",
            "result_discussion": "Significant improvements were observed in all three metrics for bar-de translations, whereas de-bar systems showed subtle increases. Notably, standard deviation increased systematically, ranging from 0.7 to 2.2 in back-translated systems compared to 0.3 to 0.6 in baseline systems.",
            "ablation_id": "2404.08259v1.No2"
        },
        {
            "research_objective": "To evaluate the effectiveness of Transfer Learning using the parent model German-French on improving the translation performance between German and Bavarian.",
            "experiment_process": "A Transfer Learning approach was trialed by introducing German-French as the parent model. Evaluation metrics included BLEU, chrF, and TER. Text preprocessing was performed to remove special symbols and noisy annotations.",
            "result_discussion": "The parent models (fr-de and de-fr) performed moderately with BLEU scores of 29 and 30 respectively. Transfer Learning significantly improved the child models\u2019 performance, achieving 54 BLEU, 71 chrF, and 42 TER for bar-de and 51 BLEU, 65 chrF, and 43 TER for de-bar. However, the Transfer Learning models did not surpass the baseline and Back-translation systems.",
            "ablation_id": "2404.08259v1.No3"
        },
        {
            "research_objective": "To qualitatively analyze translation errors and system limitations to understand performance variations.",
            "experiment_process": "Two translation examples from German to Bavarian were analyzed using all systems: baseline, Back-translation, and Transfer Learning. Differences were noted at the lexical and sub-dialectal level, focusing on orthographic variations.",
            "result_discussion": "Baseline and BT outputs showed variations likely due to different sub-dialects in the corpus. For instance, 'heute' was translated as both 'heit' and 'heid'. This variation highlights different sub-dialect conventions between Bavarian and German. The high baseline results are attributed to linguistic similarity, supporting the idea that language relatedness can positively impact MT quality.",
            "ablation_id": "2404.08259v1.No4"
        }
    ]
}