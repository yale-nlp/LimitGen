{
    "title": "Language Models for Text Classification: Is In-Context Learning Enough?",
    "abstract": "Recent foundational language models have shown state-of-the-art performance in many NLP tasks in zero- and few-shot settings. An advantage of these models over more standard approaches based on fine-tuning is the ability to understand instructions written in natural language (prompts), which helps them generalise better to different tasks and domains without the need for specific training data. This makes them suitable for addressing text classification problems for domains with limited amounts of annotated instances. However, existing research is limited in scale and lacks understanding of how text generation models combined with prompting techniques compare to more established methods for text classification such as fine-tuning masked language models. In this paper, we address this research gap by performing a large-scale evaluation study for 16 text classification datasets covering binary, multiclass, and multilabel problems. In particular, we compare zero- and few-shot approaches of large language models to fine-tuning smaller language models. We also analyse the results by prompt, classification type, domain, and number of labels. In general, the results show how fine-tuning smaller and more efficient language models can still outperform few-shot approaches of larger language models, which have room for improvement when it comes to text classification.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "A standard approach for supervised text classification is fine-tuning language models such as BERT using an additional classifier head Radford et al. (2018  ###reference_b42###); Dong et al. (2019  ###reference_b12###); Devlin et al. (2018  ###reference_b11###); Yin et al. (2019  ###reference_b67###); Viswanathan et al. (2023  ###reference_b58###); Mosbach et al. (2023  ###reference_b34###). However, these approaches require large amounts of data to achieve state-of-the-art results Edwards et al. (2022  ###reference_b14###) which makes them unsuitable for classification tasks associated with class imbalances and data sparsity Giridhara et al. (2019  ###reference_b19###); Zhang and Wu (2015  ###reference_b71###); T\u00fcrker et al. (2019  ###reference_b56###); Yin et al. (2019  ###reference_b67###). These problems often occur in real world applications where annotation of data can be performed only by scarce domain experts such as medical and legal domains or applications with highly imbalanced classes such as crime data and fraud detection Giridhara et al. (2019  ###reference_b19###); Zhang and Wu (2015  ###reference_b71###); T\u00fcrker et al. (2019  ###reference_b56###).\nRecent advances in Natural Language Processing (NLP) lead to the emerge of an alternative approach based on using autoregressive text generation models Radford et al. (2019  ###reference_b43###) that have zero- and few- shot capabilities and perform unseen tasks through the use of\nprompting Schick and Sch\u00fctze (2021a  ###reference_b47###); Radford et al. (2019  ###reference_b43###); Le Scao and Rush (2021  ###reference_b27###); Viswanathan et al. (2023  ###reference_b58###); Plaza-del Arco et al. (2023  ###reference_b41###). The ability of these models to understand natural language instructions let them generalise to different domains and tasks without the need of large training corpora Plaza-del Arco et al. (2023  ###reference_b41###). There have been even further improvements in the performance of these models in zero-shot settings by fine-tuning them on sets of instructions (task descriptions) Raffel et al. (2020  ###reference_b44###).\nThe promising results of these models against various benchmark datasets Wang et al. (2022b  ###reference_b63###); Liu et al. (2023  ###reference_b29###); Bang et al. (2023  ###reference_b2###) led to increased research into developing methods, mainly based on prompt engineering techniques Viswanathan et al. (2023  ###reference_b58###); Le Scao and Rush (2021  ###reference_b27###) for improving their generalisation capabilities. Further, there has been an increased attention into evaluating the suitability of these models for more specialised domains such as the legal, medical, and financial domain Sarkar et al. (2021  ###reference_b46###); Chalkidis et al. (2020  ###reference_b8###); Yin et al. (2019  ###reference_b67###); Labrak et al. (2023  ###reference_b25###). However, most of the proposed approaches are domain- and task-specific. There is lack of understanding of how these models perform in comparison to more established approaches for text classification. In general, analyses are performed for a small range of model types, domains, and tasks.\nOur work is the first attempt to systematically compare how text generation models using zero-shot and one-shot learning compare to more established but data-consuming approaches for classification based on fine-tuning language models. Our goal is to identify how well current large language models (LLMs) can adapt to different text classification tasks and domains given limited information, and outline the potential strengths and weaknesses of these models. For these purposes, we evaluate five heterogeneous models of different sizes, including traditional masked language models and more recent autoregressive LLMs. Our analyses span over 16 datasets from 7 domains representing binary, multiclass, and multilabel classification.\nOur main contributions are as follows. First, we explore an important but understudied problem of how suitable the newly developed text generation models such as LLaMA, Flan-T5, T5, and ChatGPT are for text classification in few-shot settings compared to lighter models that require training data such as RoBERTa or FastText. In addition to the performance, our analysis helps identify specific strengths and weaknesses of each type of model. Second, in contrast to the majority of existing research focusing on optimisation techniques for prompt creation, we analyse trends in the model\u2019s performance that are non-prompt sensitive as well as look at how the amount of specificity provided in the prompt regarding the task and the domain affect the performance of the models. Third, we evaluate generalisation abilities of models for 7 domains, including real-world specialised domains, such as legal, medical, and crime data. We also analyse how the models\u2019 behaviour changes for datasets used in the pre-training stage versus when testing on unseen datasets."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": "We first introduce the different types of methods and models used for text classification along with their strengths and weaknesses (see Section 2.1  ###reference_###). Then, we discuss relevant work on comparing prompting and fine-tuning approaches for text classification as well as outline challenges and research gaps within existing work (see Section 2.2  ###reference_###)."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Prompting versus Fine-Tuning",
            "text": "Prompting in zero- and few- shot settings, also known as in-context learning (ICL), is the process of providing natural language instructions that describe a task as an input to a language model, including the expected output Labrak et al. (2023  ###reference_b25###). In few-shot prompting, the model is presented with some training examples along with the task instructions. In contrast to fine-tuning techniques, prompting does not involve changing the weights of the model which makes the approach less resource consuming. Additionally, previous research has suggested that prompting can lead to comparable or even better performance than standard fine-tuning techniques Gao et al. (2021  ###reference_b16###); Mosbach et al. (2023  ###reference_b34###). A drawback of this approach is the models\u2019 sensitivity to the prompts where slight changes of the instruction can lead to big differences in the performance Schick and Sch\u00fctze (2021b  ###reference_b48###); Le Scao and Rush (2021  ###reference_b27###); Sun et al. (2023  ###reference_b53###). Thus, much of the work on text generation models is focused on prompt optimisation techniques based on automatic generation for prompts Wang et al. (2022a  ###reference_b61###); Shin et al. (2020  ###reference_b50###), quantifying the benefits of prompting Schick and Sch\u00fctze (2021b  ###reference_b48###); Le Scao and Rush (2021  ###reference_b27###), and improving the generalisation abilities of prompts Zhang et al. (2022  ###reference_b72###); Sch\u00f6nfeld et al. (2019  ###reference_b49###); Song et al. (2021  ###reference_b51###); Wang et al. (2022a  ###reference_b61###); Oniani et al. (2023  ###reference_b36###); Sun et al. (2023  ###reference_b53###)\nThere has been an increased research into evaluating and improving the performance of text generation models for zero and few shot classification in more specialised domains such as the legal, medical, and financial domains Ge et al. (2022  ###reference_b17###); Sarkar et al. (2021  ###reference_b46###); Chalkidis et al. (2020  ###reference_b8###). Labrak et al. (2023  ###reference_b25###) evaluate four state-of-the-art instruction-tuned large language models (ChatGPT, Flan-T5 UL2, Tk-Instruct, and Alpaca) on a set of 13 real-world clinical and biomedical natural NLP tasks, including text classification. The results show that instruction-tuned models tend to be outperformed by a specialised model trained for the medical field such as PubMedBERT Gu et al. (2021  ###reference_b20###). This rises questions into the suitability of text generation models and prompting techniques for more specialised domains which require domain experts for annotation. Another research by Mosbach et al. (2023  ###reference_b34###) conducts a comparison between fine-tuning and prompting techniques for two text classification datasets showing that both approaches have similar performance, although with a large variation in results depending on properties such as model size and number of examples. These works show that adapting these models to tasks, especially text classification for more specialised domains, remains a challenge.\nThe variance in performance between tasks and models depending on the prompt design makes the generalisation of text generation models a challenging problem. The small scale on which analyses are performed does not give enough knowledge on how well prompting techniques compare to the more established models for classification across different text classification types and more challenging unfamiliar domains. In this paper, we address these challenges by performing a large-scale comparison between different model types across a wider range of classification tasks and domains."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Experimental Setting",
            "text": ""
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Datasets",
            "text": "For our experiments we selected a suite of datasets representing all three classification types, i.e., binary, multiclass, and multilabel.\nThe datasets span across 7 domains and 13 classification tasks. Specifically, we selected the Twitter datasets from the SemEval 18 on emoji prediction Barbieri et al. (2018  ###reference_b3###), SemEval 18 on irony Detection Van Hee et al. (2018  ###reference_b57###), SemEval 19 on hate detection Basile et al. (2019  ###reference_b4###), SemEval 19 on offense detection Zampieri et al. (2019  ###reference_b68###), and SemEval 19 on sentiment analysis Nakov et al. (2019  ###reference_b35###). Further, we include datasets for topic categorisation such as BBC news111http://mlg.ucd.ie/datasets/bbc.html, AG News (Zhang et al., 2015  ###reference_b70###), Reuters (Lewis et al., 2004  ###reference_b28###), and 20 Newsgroups (Lang, 1995  ###reference_b26###) , as well as IMDB reviews dataset for polarity detection (Maas et al., 2011  ###reference_b32###), PCL dataset for patronising language detection (Perez Almendros et al., 2020  ###reference_b39###), and Toxic comments (Hosseini et al., 2017  ###reference_b22###). Additionally, we evaluate models for more specialised domains representing real world applications such as EU legislation documents (Chalkidis et al., 2019  ###reference_b7###) for legal legislation concepts detection, Hallmarks of cancer (Baker et al., 2015  ###reference_b1###) for detecting cancer hallmarks, Ohsumed (Joachims, 1998  ###reference_b23###) for cardiovascular diseases detection, and Safeguarding reports (Edwards et al., 2022  ###reference_b14###) for theme detection. Additionally, we perform prediction for the top classes as well as the sub-classes of the 20 Newsgroups and Safeguarding datasets. In this way, we can analyse how the models performance is affected by the number of classes. The main features and statistics of each dataset are summarized in Table 1  ###reference_###. For the EU legislation documents we have performed experiments with the 10 most frequent labels, similarly to Chalkidis et al. (2019  ###reference_b7###). For the Ohsumed dataset, we have selected the top 23 most frequent classes, similar to prior work Pilehvar et al. (2017  ###reference_b40###)."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Comparison Models",
            "text": "We compare three main types of models: generative language models, masked language models, and linear models, all described below.\nGenerative Language Models.\nWe include LLaMA 1 Touvron et al. (2023a  ###reference_b54###) and 2 Touvron et al. (2023b  ###reference_b55###) into the analysis as representatives of large auto-regressive generation models, both with 7 billion parameters. As a representative of smaller but instruction-tuned model, we use Flan-T5 Chung et al. (2022  ###reference_b9###). The model is fine-tuned using the Flan instruction tuning tasks collection (Chung et al., 2022  ###reference_b9###). We use the large Flan-T5 model with 780M parameters. We have also included T5 model Raffel et al. (2020  ###reference_b44###) into our analysis which we fine-tune, similarly to RoBERTa. In particular, we use T5 base model. We have downloaded the models from Hugging Face Wolf et al. (2019  ###reference_b65###).\nAs a representative of the GPT family of autoregressive models Brown et al. (2020  ###reference_b6###), we use OpenAI GPT 3.5-Turbo for our analysis. We added this model for completeness. However, given budget constraints and its closed nature for which few conclusions can be drawn, we only provide results for a sample of all datasets.\nMasked Language Models. As a representative of masked language model, we use RoBERTa Liu et al. (2019  ###reference_b30###), pre-trained on English language. It is known to achieve state-of-the-art results for many text classification tasks. We perform experiments with RobERTa base (125 million parameters) and RoBERTa large (354 million parameters) models to allow analysis into the effect of model size over the classification performance. We have downloaded the models from Hugging Face Wolf et al. (2019  ###reference_b65###).\nLinear Models. Finally, we use FastText Joulin et al. (2017  ###reference_b24###) (see Section 2.1.1  ###reference_.SSS1###) as a representative of a linear text classification model. Despite its simplicity the model provides a strong baseline for many text classification tasks and it is known to give comparable results to state-of-the-art methods, including language models such as BERT for some classification problems Zhou (2020  ###reference_b73###); Edwards et al. (2020  ###reference_b13###)."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Prompting, Training and Evaluation",
            "text": "As mentioned in Section 1  ###reference_###, our aim is to estimate how well the text generation models perform for text classification when\ncompared to the more data consuming models such as RoBERTa and FastText. Therefore, we perform experiments for Flan-T5 and LLaMA in zero- and one- shot ICL settings. For zero shot, we provide information about the task to the model through prompting. For one shot, we randomly select a single training instance per label and we provide these examples along with the instruction to the model. To ensure robustness, the random selection of training samples is performed for three iterations and the results are averaged. For generating labels for the test sequences, we use default model settings. We judge the outputs as expected class labels or not by simply checking whether the output of the model matches one of the labels for the given classification task. We experiment with three different prompts which we describe further in Section 3.4  ###reference_###.\nAs for RoBERTa, we fine-tune it for the classification task on the training data of each dataset using a sequence classifier, a learning rate of 2e-5 and 4 epochs. In particular, we made use of RoBERTa\u2019s Hugging Face default transformers implementation for classifying sentences Wolf et al. (2019  ###reference_b65###). As for T5, we fine-tune it using conditional generation, 2 epochs, and learning rate of 5e-5. Finally, we use FastText classifier with 25 epochs and softmax as the loss function.\nFinally, we report results based on standard micro and macro averaged F1 (Yang, 1999  ###reference_b66###)."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Prompt Design",
            "text": "Our paper does not focus on identifying and describing most efficient prompt engineering practices (as majority of work described in Section 2  ###reference_###) but instead we focus on highlighting prompt-independent trends in the models performance in order to help outline advantages and disadvantages of out-of-the-box approaches for few shot text classification. We selected instructions that led to satisfactory results in previous research or have been used in the training set for the instruction-tuned models Flan-T5 Sun et al. (2023  ###reference_b53###); Wei et al. (2021  ###reference_b64###). These prompts vary in the detail they provide about the given task and domain. We want to analyse trends across models behaviour that are non-prompt sensitive as well as look at how the amount of specificity provided in the prompt affect the performance of the models. For these purposes, we use the following three prompts: (1) generic: a prompt which does not give information about the task or domain, used in Sun et al. (2023  ###reference_b53###); (2) task: describes the given task, i.e., classification; (3) domain: a prompt which gives more information about the domain, for instance, it specifies the type of test data, such as an article or tweet. We have created the domain-based prompts following examples provided in Wei et al. (2021  ###reference_b64###). Table 2  ###reference_### presents examples of the prompts per classification type222A list of all prompts is given in the Appendix.."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Results and Analysis",
            "text": "The aim of our analysis is (1) identify if and how the use of prompts affect the performance of text generation models (see Section 4.1  ###reference_###); (2) compare performance of prompting and fine-tuning techniques in order to identify strengths and weaknesses of the different models \u2013 we focus on a comparison between the three types of classification, i.e., binary, multiclass, and multilabel (see Section 4.2  ###reference_###); and (3) perform a fine-grained analysis comparing models\u2019 performance at the domain and dataset level (see Section  4.3  ###reference_###). In addition to this general comparison, we analyse separately the performance of closed-source GPT3.5 and models for the \u2018IMDB reviews\u2019 and \u2018AG News\u2019 datasets as they are used in the fine-tuning of the Flan-T5 model."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Model and Prompt Analysis",
            "text": "A comparison between the two LLaMA models shows an advantage of LLaMA 2 over LLaMA 1 for both zero- and one-shot settings across all prompt types (see Figure 1  ###reference_### and Table 3  ###reference_###). The two models have similar performance in the zero-shot setting in terms of F1 score. However, the number of wrong labels for LLaMA 1 is much larger with 0.470 wrong labels compared to the 0.100 wrong labels from LLaMA2. Results in Figure 1  ###reference_### also show a clear advantage of Flan-T5 over the other models for all three prompts in terms of micro- and macro- F1 for both zero- and one- shot settings. The Flan-T5 model also leads to smaller number of wrong labels in zero-shot prompting. This suggests that smaller but instruction-tuned models can be more beneficial in zero- and few- shot classification in comparison to larger text generation models. Specifically, Flan-T5 has on average 0.110 improvement in micro- and macro-F1 for both zero- and one- shot settings over LLaMA 2.\n###figure_1### Further analysis into the prompts reveal that prompt choice does not lead to significant changes in the models behaviour where the deviation for the three prompts across all models is relatively small. For instance, for LLaMA 1 and LLaMA 2 is less than 0.02 difference in micro-F1 for both zero- and one- shot settings while for Flan-T5 it gradually decreases from 0.07 in zero-shot to 0.01 for one-shot. This suggests that smaller models such as Flan-T5 are more sensitive to the prompt in zero settings versus few shot learning. The benefits from one-shot prompting are evident across all three models where the F1 measure tends to increase and the number of wrong labels decreases. Flan-T5 improves its performance on a higher rate compared to to the other two models with around 0.047 increase in the micro-F1 score versus 0.027 increase for LLaMA 2. This illustrates the strong abilities of these models to learn tasks with minimal amount of training data."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Prompting versus Fine-tuning",
            "text": "Results in Figure 2  ###reference_### show the same trends for prompting methods where Flan-T5 outperforms LLaMA 1 and LLaMA 2 for all text classification types in terms of micro- and macro-F1. All three models improve their performance for one-shot prompting regarding the number of wrong labels. In one shot setting, Flan-T5 and LLaMA 2 tend to have close to 0 wrong labels with LLaMA 2 returning slightly lower number of irrelevant results, while Flan-T5 has a better F1 score (see Figures 2  ###reference_### and  3  ###reference_###333Macro-F1 results are available in the Appendix.). The advantage of LLaMA 2 over LLaMA 1 is clearly shown for all classification tasks, especially binary and multilabel where LLaMA 2 has a smaller number of irrelevant results and higher F1 score (see Figure 2  ###reference_###).\n###figure_2### ###figure_3### Regarding fine-tuning approaches, results in Figure 2  ###reference_### show a clear dominance of RoBERTa-large in one-shot setting for all classification types.\nWhen fine-tuning is performed using the entire dataset, T5 outperforms the rest of the models for binary classification with micro-F1 = 0.672 versus RoBERTa-large with micro-F1 = 0.607. However, for multiclass and multilabeling tasks, the performance of T5 decreases and the model is outperformed by both RoBERTa-base and RoBERTa-large. For instance, for multiclass problems RoBERTa-large achieves micro-F1 of 0.726 versus micro-F1 for T5 = 0.700. For multilabeling problems the performance gap between the models increases and RoBERTa-large has a micro-F1 = 0.788 versus T5 with micro-F1 = 0.718. These results suggest that fine-tuned masked language models are more suitable for complex classification tasks such as multiclass and multilabeling problems when the number of labels is higher versus fine-tuning text-to-text models such as T5.\nA comparison between prompting and fine-tuning techniques for low resource settings suggests a better performance of prompting for binary and multiclass problems (see Figure 2  ###reference_###) where Flan-T5 and LLaMA 2 outperform fine-tuning models by a significant margin. For instance, Flan-T5 has micro-F1 = 0.553 versus micro-F1 for RoBERTa-large with micro-F1 = 0.485 for binary classification in one shot settings. The advantage of prompting in one shot settings becomes even more evident for multiclass problems where Flan-T5 achieves micro-F1 = 0.489 versus RoBERTa-large with micro-F1 = 0.162. However, for multilabeling problems, fine-tuning approaches outperform prompting methods with a difference in micro-F1 of 0.082 between the best fine-tuned model, RoBERTa-large, and the best prompting model, i.e. Flan-T5. It is worth noting that during one-shot training, all models have been provided the same training examples. However, further analyses are needed to identify most efficient ways for representing multi-labeling problems as part of prompting techniques.\nDespite the better overall performance of prompting techniques in zero- and one- shot settings, these approaches lead to unsatisfactory performance when compared to fine-tuned masked language models on a larger training set. Further, the difference in the performance between the two techniques grows larger for more complex text classification tasks such as multiclass and multilabeling problems. For instance, for binary classification, the difference in performance in terms of micro-F1 between best performing prompting and fine-tuning technique is 0.119 while for multiclass the difference in performance is 0.240. This shows that large autoregressive text generation models coupled with few shot learning techniques still have room for improvement when it comes to text classification. Fine-tuned masked language models, despite being smaller, lead to better performance for text classification versus LLMs in ICL settings."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Trends across datasets and models",
            "text": "Results presented in Table 4  ###reference_### confirm findings from Section 4.2  ###reference_### showing a clear dominance of Flan-T5 over LLaMA for zero- and one-shot prompting for the majority of datasets. Exceptions are the \u2019irony\u2019, \u2019sentiment\u2019, and \u2019PCL\u2019 datasets where LLaMA performs better for either zero or one shot setting, or both. For some datasets such as \u2018hate\u2019, prompting models give better performance in zero- shot than one-shot setting. However, models still improve performance for these datasets in terms of number of wrong labels. Further, the choice of one shot training instances can influence the performance of models in few-shot learning. For the purposes of this analysis we have selected the one shot examples randomly. Analysing the impact of the training examples in few-shot learning can be a future research direction which we leave for future work.\nIn contrast to the prompting approaches, results for the fine-tuned models do not show a clear dominance of either RoBERTa or T5. T5 shows a better performance for the majority of the binary classification tasks (those associated with Twitter datasets) as well as the datasets \u2018AG news\u2019, \u201820 News\u2019 (top 6 classes)\u2019, and the \u2018legal\u2019 domain. The two models attain a similar macro-F1 for the emoji prediction and safeguarding reports datasets.\nImpact of the number of labels.\nAnalysis into the effect of the number of classification labels in the performance shows an interesting trend with the fine-tuned models (RoBERTa and T5) performing slightly better for classification tasks with 6 to 9 labels than classification with less labels (see Figure 4  ###reference_###). For RoBERTa this trend occurs for both micro-F1 and macro-F1 while for T5 it appears only for micro-F1. This can be attributed to the nature of the binary classification tasks (\u2019irony\u2019, \u2019offense\u2019, \u2019hate\u2019) which express human emotions and represent the Twitter domain. This suggests that the models find it more challenging to categorise such texts versus more categorical-based datasets such as news and articles which are part of the datasets with 6 to 9 labels. In contrast, the performance of both prompting approaches decreases as the number of labels for the classification task increases.\n###figure_4### Datasets used for pre-training. As mentioned earlier in the section, we analyse the performance of models for the \u2018IMDB reviews\u2019 and \u2018AG News\u2019 datasets separately as they are used in the fine-tuning of the Flan-T5 model. For these datasets (see Table 5  ###reference_###) Flan-T5 performance significantly improves achieving micro- and macro-F1 results comparable to fine-tuning models on the entire dataset. For instance, for the IMDB dataset, the difference in macro-F1 between Flan-T5 and RoBERTa is 0.007 while for the AG news the difference in macro-F1 is 0.027. In contrast, the performance gap for the rest of the datasets between Flan-T5 and the best performing fine-tuning model is on average around 0.250 in micro-F1. This shows the significant impact that data contamination may have in the final results. However, a careful data contamination analysis becomes harder on large models for which training data is not available, and especially for closed models.\nGPT Analysis. Table 4  ###reference_### presents zero-shot prompting results for the GPT 3.5-Turbo model for the following datasets: \u2018irony\u2019, \u2018offense\u2019, \u2018bbc\u2019, \u2018reuters\u2019, \u2018pcl\u2019, and \u2018safeguard\u2019. We have used the class-based prompt for prompting with GPT 3.5 because it has shown to lead to the higher overall performance for Flan-T5 and LLaMA. Results show a clear advantage of the GPT-based model over Flan-T5 and LLaMA achieving on average 0.350 higher micro- and macro-F1 across the majority of the datasets, except for the \u2018PCL\u2019 dataset. Additionally, results achieved with zero-shot learning with GPT 3.5-Turbo outperform fine-tuned models on the entire dataset for the \u2018irony\u2019 dataset. However, for the rest of the datasets the model is still outperformed by fine-tuning approaches confirming the lack of generalisation abilities of few-shot learning techniques and text generation models for text classification."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusions",
            "text": "This paper presents a large-scale study on how prompt-based LLMs in zero- and one- shot settings compare to smaller but fine-tuned language models for text classification. The evaluation spans across 16 datasets covering binary, multiclass, and multilabel problems. In particular, we compared three different types of models, i.e., linear models such as FastText, masked language models (RoBERTa), and text generation models tested in ICL settings (T5, Flan-T5, and LLaMA, as well as GPT 3.5-Turbo). Analyses on prompting techniques showed a clear advantage of the Flan-T5 model over LLaMA 1 and LLaMA 2 regardless of the prompt used for both zero- and one-shot settings. This shows that smaller but instruction-tuned models have better generalisation abilities for text classification than larger text generation models. Further, our analysis showed that results from zero- and few-shot learning LLMs are considerably lower in comparison to smaller models fine-tuned on the entire training set. This highlights the need for training data, even in the age of LLMs, and that fine-tuning smaller and more efficient language models can still outperform in-context learning methods of larger text generation models."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Acknowledgements",
            "text": "Aleksandra Edwards and Jose Camacho-Collados are supported by a UKRI Future Leaders Fellowship.\nThe safeguarding documents used for performing analysis in the paper have been collected in collaboration with the Wales Safeguarding Repository (WSR) project, funded by the National Independent Safeguarding Board (NISB), the Crime and Security Research Institute at Cardiff University (CSRI), and the School of Social Sciences at Cardiff University (SOCSI). We would like to thank the WSR team for their support."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Limitations",
            "text": "The main limitation of this research is the lack of experiments on fine-tuning Flan-T5 and LLaMA models as well as the lack of further analysis with larger text generation models such as LLaMA with 13 and 17 billion parameters. Moreover, the paper presents a study for zero- and one-shot prompting. As future work, we plan to extend analysis to understand how the number of training instances affect the performance of in-context learning approaches. Further, considering the sensitivity of in-context learning approaches to the given instructions, it would be beneficial to perform further analysis on a larger more diverse set of prompts. Finally, the paper presents results for a single high resource language (English). Experiments for other languages (especially low-resource) could show a different tendency."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Appendix",
            "text": "In Section A.1  ###reference_### we present a comparison between prompting and fine-tuning techniques based on Macro-F1.\nIn Section A.2  ###reference_###, we present the prompts we used for performing analysis with zero- and one- shot in-context learning with Flan-T5 and LLaMA 1 and LLaMA 2."
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T1\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S3.T1.1\" style=\"width:433.6pt;height:216.4pt;vertical-align:-0.6pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-126.8pt,63.1pt) scale(0.630973931336491,0.630973931336491) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T1.1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.1.1\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.2.1\">Domain</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.3.1\">Task</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.4.1\">Type</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.5.1\">Class Type</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.6.1\">Avg tokens</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.1.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.7.1\">Labels</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.8.1\"># Train</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.9.1\"># Dev</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.10.1\"># Test</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.2.1\">SemEval 18 (Emoji)</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.2.2\">Twitter</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.2.3\">Emoji Prediction</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.2.4\">Sentence</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.2.5\">multiclass</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.2.6\">12</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.2.2.7\">20</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.2.8\">45,000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.2.9\">5,000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.2.10\">50,000</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.3.1\">SemEval 18 (Irony)</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.3.2\">Twitter</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.3.3\">Irony Detection</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.3.4\">Sentence</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.3.5\">binary</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.3.6\">13</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.3.3.7\">2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.3.8\">2,862</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.3.9\">955</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.3.10\">784</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.4.1\">SemEval 19 (Hateval)</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.4.2\">Twitter</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.4.3\">Hateval</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.4.4\">Sentence</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.4.5\">binary</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.4.6\">18</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.4.4.7\">2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.4.8\">9,000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.4.9\">1,000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.4.10\">2,970</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.5.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.5.1\">SemEval 19 (OffensEval)</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.5.2\">Twitter</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.5.3\">OffensEval</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.5.4\">Sentence</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.5.5\">binary</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.5.6\">19</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.5.5.7\">2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.5.8\">11,916</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.5.9\">1,324</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.5.10\">860</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.6.1\">SemEval 17 (Sentiment)</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.6.2\">Twitter</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.6.3\">Sentiment Analysis</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.6.4\">Sentence</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.6.5\">multiclass</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.6.6\">20</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.6.6.7\">3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.6.8\">45,389</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.6.9\">2,000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.6.6.10\">11,906</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.7.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.7.7.1\">BBC news</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.7.7.2\">News</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.7.7.3\">Topic categorisation</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.7.7.4\">Document</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.7.7.5\">multiclass</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.7.7.6\">220</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.7.7.7\">5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.7.7.8\">1602</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.7.7.9\">178</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.7.7.10\">445</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.8.1\">Reuters</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.8.2\">News</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.8.3\">Topic categorisation</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.8.4\">Document</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.8.5\">multiclass</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.8.6\">83</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.8.8.7\">8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.8.8\">6120</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.8.9\">680</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.8.8.10\">2659</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.9.9.1\">AG News</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.9.9.2\">News</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.9.9.3\">Topic categorisation</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.9.9.4\">Document</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.9.9.5\">multiclass</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.9.9.6\">31</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.9.9.7\">4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.9.9.8\">103,346</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.9.9.9\">11,482</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.9.9.10\">5,928</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.10.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.10.10.1\">20 Newsgroups</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.10.10.2\">News</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.10.10.3\">Topic categorisation</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.10.10.4\">Document</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.10.10.5\">multiclass</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.10.10.6\">285</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.10.10.7\">6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.10.10.8\">9,857</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.10.10.9\">1,095</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.10.10.10\">7,290</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.11.11\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.11.11.1\">20 Newsgroups</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.11.11.2\">News</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.11.11.3\">Topic categorisation</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.11.11.4\">Document</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.11.11.5\">multiclass</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.11.11.6\">285</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.11.11.7\">20</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.11.11.8\">9,857</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.11.11.9\">1,095</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.11.11.10\">7,290</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.12.12\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.12.12.1\">IMDB reviews</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.12.12.2\">Reviews</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.12.12.3\">Polarity Detection</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.12.12.4\">Document</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.12.12.5\">binary</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.12.12.6\">231</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.12.12.7\">2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.12.12.8\">25200</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.12.12.9\">2,800</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.12.12.10\">25,601</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.13.13\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.13.13.1\">Ohsumed</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.13.13.2\">Medical</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.13.13.3\">Cardiovascular diesese det.</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.13.13.4\">Document</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.13.13.5\">multiclass</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.13.13.6\">104</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.13.13.7\">23</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.13.13.8\">9,390</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.13.13.9\">1,043</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.13.13.10\">12733</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.14.14\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.14.14.1\">Toxic Comments</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.14.14.2\">Wikipedia</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.14.14.3\">Toxic prediction</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.14.14.4\">Document</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.14.14.5\">multilabel</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.14.14.6\">46</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.14.14.7\">7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.14.14.8\">143,614</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.14.14.9\">15,957</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.14.14.10\">63,978</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.15.15\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.15.15.1\">PCL dataset</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.15.15.2\">News</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.15.15.3\">Patronising language det.</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.15.15.4\">Document</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.15.15.5\">multilabel</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.15.15.6\">37</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.15.15.7\">7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.15.15.8\">517</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.15.15.9\">57</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.15.15.10\">419</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.16.16\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.16.16.1\">EU legislation documents</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.16.16.2\">Legislation</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.16.16.3\">Legal legislation concept det.</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.16.16.4\">Document</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.16.16.5\">multilabel</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.16.16.6\">27</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.16.16.7\">10</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.16.16.8\">45,000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.16.16.9\">6,000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.16.16.10\">6,000</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.17.17\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.17.17.1\">Hallmarks of cancer</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.17.17.2\">Medical</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.17.17.3\">Hallmarks of cancer detection</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.17.17.4\">Sentence</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.17.17.5\">multilabel</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.17.17.6\">22</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.17.17.7\">10</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.17.17.8\">12,456</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.17.17.9\">1,384</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.17.17.10\">3624</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.18.18\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.18.18.1\">Safeguarding reports</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.18.18.2\">Safeguarding</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.18.18.3\">Theme detection</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.18.18.4\">Sentence</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.18.18.5\">multilabel</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.18.18.6\">18</td>\n<td class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.18.18.7\">5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.18.18.8\">5,719</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.18.18.9\">635</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.18.18.10\">3496</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.19.19\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.19.19.1\">Safeguarding reports</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.19.19.2\">Safeguarding</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.19.19.3\">Theme detection</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.19.19.4\">Sentence</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.19.19.5\">multilabel</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.19.19.6\">18</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t\" id=\"S3.T1.1.1.19.19.7\">10</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.19.19.8\">5,719</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.19.19.9\">635</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.19.19.10\">3496</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Overview of the classification datasets used in our experiments.</figcaption>\n</figure>",
            "capture": "Table 1: Overview of the classification datasets used in our experiments."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T2\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S3.T2.1\" style=\"width:433.6pt;height:97.1pt;vertical-align:-0.8pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-52.6pt,11.7pt) scale(0.804788838127554,0.804788838127554) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S3.T2.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T2.1.1.1.1.2.1\">\n<span class=\"ltx_p\" id=\"S3.T2.1.1.1.1.2.1.1\" style=\"width:133.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.2.1.1.1\">Binary</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1.1.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T2.1.1.1.1.3.1\">\n<span class=\"ltx_p\" id=\"S3.T2.1.1.1.1.3.1.1\" style=\"width:150.8pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.3.1.1.1\">Multiclass</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1.1.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T2.1.1.1.1.4.1\">\n<span class=\"ltx_p\" id=\"S3.T2.1.1.1.1.4.1.1\" style=\"width:170.7pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.4.1.1.1\">Multilabel</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.2.1.1.1\">generic</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.2.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T2.1.1.2.1.2.1\">\n<span class=\"ltx_p\" id=\"S3.T2.1.1.2.1.2.1.1\" style=\"width:133.7pt;\">Choose your answer: According to the above paragraph, the question <span class=\"ltx_text ltx_font_italic\" id=\"S3.T2.1.1.2.1.2.1.1.1\">\u2019Is the text ironic?\u2019</span>:</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.2.1.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T2.1.1.2.1.3.1\">\n<span class=\"ltx_p\" id=\"S3.T2.1.1.2.1.3.1.1\" style=\"width:150.8pt;\">Pick one category for the following text. The options are:</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.2.1.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T2.1.1.2.1.4.1\">\n<span class=\"ltx_p\" id=\"S3.T2.1.1.2.1.4.1.1\" style=\"width:170.7pt;\">Pick one or more from the categories for the following text.The options are:</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.3.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.3.2.1.1\">task</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.3.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T2.1.1.3.2.2.1\">\n<span class=\"ltx_p\" id=\"S3.T2.1.1.3.2.2.1.1\" style=\"width:133.7pt;\">Classify the input text into one of the following categories:</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.3.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T2.1.1.3.2.3.1\">\n<span class=\"ltx_p\" id=\"S3.T2.1.1.3.2.3.1.1\" style=\"width:150.8pt;\">Classify the input text into one of the following categories:</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.3.2.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T2.1.1.3.2.4.1\">\n<span class=\"ltx_p\" id=\"S3.T2.1.1.3.2.4.1.1\" style=\"width:170.7pt;\">Classify the input text using one or more from the following categories:</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.4.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.4.3.1.1\">domain</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.4.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T2.1.1.4.3.2.1\">\n<span class=\"ltx_p\" id=\"S3.T2.1.1.4.3.2.1.1\" style=\"width:133.7pt;\">Is the Tweet classified as irony or non-irony?</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.4.3.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T2.1.1.4.3.3.1\">\n<span class=\"ltx_p\" id=\"S3.T2.1.1.4.3.3.1.1\" style=\"width:150.8pt;\">Select the topic that the given news is about. The topics are -</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.4.3.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.T2.1.1.4.3.4.1\">\n<span class=\"ltx_p\" id=\"S3.T2.1.1.4.3.4.1.1\" style=\"width:170.7pt;\">Which of the given toxic topics best describe the given comment? Choose one or more from the following topics:</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Examples of prompts used for zero- and one-shot learning for Flan-T5 and LLaMA.</figcaption>\n</figure>",
            "capture": "Table 2: Examples of prompts used for zero- and one-shot learning for Flan-T5 and LLaMA."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T3\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T3.1\" style=\"width:395.6pt;height:221pt;vertical-align:-0.7pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-93.1pt,51.8pt) scale(0.68,0.68) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.1.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.1.1\">Model</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T3.1.1.1.1.2\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.2.1\">Prompt</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"3\" id=\"S4.T3.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.3.1\">zero shot</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"3\" id=\"S4.T3.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.4.1\">one shot</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\" id=\"S4.T3.1.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.5.1\">all</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.2.2.1.1\">micro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.2.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.2.2.2.1\">macro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.2.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.2.2.3.1\">missing labs</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.2.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.2.2.4.1\">micro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.2.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.2.2.5.1\">macro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.2.2.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.2.2.6.1\">missing labs</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.2.2.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.2.2.7.1\">micro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.2.2.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.2.2.8.1\">macro F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.3.3.1\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T3.1.1.3.3.1.1\">Flan-T5</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T3.1.1.3.3.2\">generic</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.3.3.3\">.510</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.3.3.4\">.459</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.3.3.5\">.076</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.3.3.6\">.446</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.3.3.7\">.401</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.3.3.8\">.020</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.3.3.9\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.3.3.10\">\u2014</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T3.1.1.4.4.1\">task</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.4.4.2\">.368</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.4.4.3\">.373</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.4.4.4\">.055</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.4.4.5\">.462</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.4.4.6\">.415</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.4.4.7\">.012</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.4.4.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.4.4.9\">\u2014</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T3.1.1.5.5.1\">domain</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.5.5.2\">.369</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.5.5.3\">.302</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.5.5.4\">.092</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.5.5.5\">.480</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.5.5.6\">.432</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.5.5.7\">.072</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.5.5.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.5.5.9\">\u2014</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T3.1.1.6.6.1\">AVG</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.6.6.2\">.416</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.6.6.3\">.378</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.6.6.4\">.074</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.6.6.5\">.463</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.6.6.6\">.416</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.6.6.7\">.035</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.6.6.8\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.6.6.9\">\u2014</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.7.7.1\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T3.1.1.7.7.1.1\">LLaMA 1</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T3.1.1.7.7.2\">generic</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.7.7.3\">.309</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.7.7.4\">.213</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.7.7.5\">.484</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.7.7.6\">.274</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.7.7.7\">.274</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.7.7.8\">.043</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.7.7.9\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.7.7.10\">\u2014</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T3.1.1.8.8.1\">task</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.8.8.2\">.319</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.8.8.3\">.230</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.8.8.4\">.471</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.8.8.5\">.339</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.8.8.6\">.303</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.8.8.7\">.414</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.8.8.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.8.8.9\">\u2014</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T3.1.1.9.9.1\">domain</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.9.9.2\">.284</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.9.9.3\">.235</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.9.9.4\">.463</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.9.9.5\">.318</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.9.9.6\">.270</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.9.9.7\">.066</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.9.9.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.9.9.9\">\u2014</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T3.1.1.10.10.1\">AVG</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.10.10.2\">.304</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.10.10.3\">.279</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.10.10.4\">.469</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.10.10.5\">.311</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.10.10.6\">.267</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.10.10.7\">.038</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.10.10.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.10.10.9\">\u2014</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.11.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.11.11.1\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T3.1.1.11.11.1.1\">LLaMA 2</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T3.1.1.11.11.2\">generic</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.11.11.3\">.332</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.11.11.4\">.282</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.11.11.5\">.086</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.11.11.6\">.305</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.11.11.7\">.253</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.11.11.8\">.436</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.11.11.9\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.11.11.10\">\u2014</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T3.1.1.12.12.1\">task</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.12.12.2\">.286</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.12.12.3\">.238</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.12.12.4\">.061</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.12.12.5\">.333</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.12.12.6\">.282</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.12.12.7\">.679</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.12.12.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.12.12.9\">\u2014</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.13.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T3.1.1.13.13.1\">domain</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.13.13.2\">.309</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.13.13.3\">.269</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.13.13.4\">.153</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.13.13.5\">.360</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.13.13.6\">.322</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.13.13.7\">.007</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.13.13.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.13.13.9\">\u2014</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.14.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T3.1.1.14.14.1\">AVG</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.14.14.2\">.309</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.14.14.3\">.263</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.14.14.4\">.100</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.14.14.5\">.336</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.14.14.6\">.288</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.14.14.7\">.006</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.14.14.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.14.14.9\">\u2014</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.15.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.15.15.1\">T5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T3.1.1.15.15.2\">\u2014</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.15.15.3\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.15.15.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.15.15.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.15.15.6\">.134</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.15.15.7\">.109</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.15.15.8\">.851</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.15.15.9\">.702</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.15.15.10\">.625</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.16.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.16.16.1\">RoBERTa (base)</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T3.1.1.16.16.2\">\u2014</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.16.16.3\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.16.16.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.16.16.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.16.16.6\">.273</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.16.16.7\">.207</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.16.16.8\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.16.16.9\">.707</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.16.16.10\">.625</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.17.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.17.17.1\">RoBERTa (large)</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T3.1.1.17.17.2\">\u2014</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.17.17.3\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.17.17.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.17.17.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.17.17.6\">.338</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.17.17.7\">.278</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.17.17.8\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.17.17.9\">.727</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.17.17.10\">.657</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.18.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.18.18.1\">fastText</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr ltx_border_tt\" id=\"S4.T3.1.1.18.18.2\">\u2014</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.18.18.3\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.18.18.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.18.18.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.18.18.6\">.254</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.18.18.7\">.164</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.18.18.8\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.18.18.9\">.505</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.18.18.10\">.419</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Prompt Analysis where Micro-F1 and Macro-F1 results averaged across all datasets, comparing the performance of Flan-T5, LLaMA 1, and LLaMA 2 models for all three types of prompts, i.e., <span class=\"ltx_text ltx_font_italic\" id=\"S4.T3.5.1\">\u2018generic\u2019</span>, <span class=\"ltx_text ltx_font_italic\" id=\"S4.T3.6.2\">\u2018task\u2019</span>, and <span class=\"ltx_text ltx_font_italic\" id=\"S4.T3.7.3\">\u2018domain\u2019</span> as well as the average (\u2018AVG\u2019) between them. \u2018Missing labs\u2019 shows the fraction of results returned by the three models that are different from the classification labels. Results are displayed for zero-shot (\u2018zero\u2019) and one-shot setting (\u2018one\u2019).</figcaption>\n</figure>",
            "capture": "Table 3: Prompt Analysis where Micro-F1 and Macro-F1 results averaged across all datasets, comparing the performance of Flan-T5, LLaMA 1, and LLaMA 2 models for all three types of prompts, i.e., \u2018generic\u2019, \u2018task\u2019, and \u2018domain\u2019 as well as the average (\u2018AVG\u2019) between them. \u2018Missing labs\u2019 shows the fraction of results returned by the three models that are different from the classification labels. Results are displayed for zero-shot (\u2018zero\u2019) and one-shot setting (\u2018one\u2019)."
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T4\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T4.128\" style=\"width:412.2pt;height:894.2pt;vertical-align:-0.7pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-97.0pt,210.2pt) scale(0.68,0.68) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.128.128\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.128.128.129.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.129.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.128.128.129.1.1.1\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.128.128.129.1.2\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.128.128.129.1.2.1\">Model</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"3\" id=\"S4.T4.128.128.129.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.128.128.129.1.3.1\">zero shot</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"3\" id=\"S4.T4.128.128.129.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.128.128.129.1.4.1\">one shot</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\" id=\"S4.T4.128.128.129.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.128.128.129.1.5.1\">all</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.128.128.130.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.130.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.128.128.130.2.1.1\">micro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.130.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.128.128.130.2.2.1\">macro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.130.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.128.128.130.2.3.1\">wrong labs</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.130.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.128.128.130.2.4.1\">micro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.130.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.128.128.130.2.5.1\">macro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.130.2.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.128.128.130.2.6.1\">wrong labs</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.130.2.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.128.128.130.2.7.1\">micro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.130.2.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.128.128.130.2.8.1\">macro F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.2.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.2.2.2.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.2.2.2.3.1\">irony</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.2.2.2.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.2.2.2.5\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.2.2.2.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.2.2.2.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.1.1.1.1\">.459 (.005)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.2.2.2.2\">.459 (.005)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.2.2.2.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.2.2.2.9\">.508</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.2.2.2.10\">.508</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.4.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.4.4.4.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.4.4.4.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.4.4.4.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.4.4.4.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.3.3.3.1\">.455( .021)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.4.4.4.2\">.455( .021)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.4.4.4.7\">.589</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.4.4.4.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.4.4.4.8.1\">.688</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.4.4.4.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.4.4.4.9.1\">.688</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.6.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.6.6.6.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.6.6.6.4\">.428</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.6.6.6.5\">.428</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.6.6.6.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.6.6.6.6.1\">.049</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.5.5.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.5.5.5.1.1\">.491( .034)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.6.6.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.6.6.6.2.1\">.491(.034)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.6.6.6.7\">.009</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.6.6.6.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.6.6.6.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.8.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.8.8.8.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.8.8.8.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.8.8.8.4.1\">.499</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.8.8.8.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.8.8.8.5.1\">.499</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.8.8.8.6\">.214</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.7.7.7.1\">.443 (.003)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.8.8.8.2\">.443 (.003)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.8.8.8.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.8.8.8.7.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.8.8.8.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.8.8.8.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.128.128.131.3\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\" id=\"S4.T4.128.128.131.3.1\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.128.128.131.3.2\">GPT 3.5*</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.131.3.3\">.727</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.131.3.4\">.727</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.131.3.5\">.000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.131.3.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.131.3.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.131.3.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.131.3.9\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.131.3.10\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.10.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.10.10.10.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.10.10.10.3.1\">offense</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.10.10.10.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.10.10.10.5\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.10.10.10.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.10.10.10.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.9.9.9.1\">.550 (.143)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.10.10.10.2\">.550 (.143)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.10.10.10.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.10.10.10.9\">.705</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.10.10.10.10\">.705</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.12.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.12.12.12.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.12.12.12.4\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.12.12.12.5\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.12.12.12.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.11.11.11.1\">.462 (.001)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.12.12.12.2\">.462 (.001)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.12.12.12.7\">.864</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.12.12.12.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.12.12.12.8.1\">.709</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.12.12.12.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.12.12.12.9.1\">.709</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.14.14.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.14.14.14.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.14.14.14.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.14.14.14.4.1\">.429</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.14.14.14.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.14.14.14.5.1\">.429</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.14.14.14.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.14.14.14.6.1\">.269</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.13.13.13.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.13.13.13.1.1\">.558(.019)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.14.14.14.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.14.14.14.2.1\">.558(.019)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.14.14.14.7\">.003</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.14.14.14.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.14.14.14.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.16.16.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.16.16.16.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.16.16.16.4\">.419</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.16.16.16.5\">.419</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.16.16.16.6\">.227</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.15.15.15.1\">.347 (.026)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.16.16.16.2\">.347 (.026)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.16.16.16.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.16.16.16.7.1\">.001</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.16.16.16.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.16.16.16.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.128.128.132.4\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\" id=\"S4.T4.128.128.132.4.1\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.128.128.132.4.2\">GPT 3.5*</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.132.4.3\">.635</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.132.4.4\">.635</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.132.4.5\">.000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.132.4.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.132.4.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.132.4.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.132.4.9\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.132.4.10\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.18.18.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.18.18.18.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.18.18.18.3.1\">hate</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.18.18.18.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.18.18.18.5\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.18.18.18.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.18.18.18.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.17.17.17.1\">.445 (.118)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.18.18.18.2\">.445 (.118)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.18.18.18.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.18.18.18.9\">.607</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.18.18.18.10\">.607</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.20.20.20\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.20.20.20.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.20.20.20.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.20.20.20.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.20.20.20.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.19.19.19.1\">.386 (.312)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.20.20.20.2\">.386 (.312)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.20.20.20.7\">.732</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.20.20.20.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.20.20.20.8.1\">.619</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.20.20.20.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.20.20.20.9.1\">.619</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.22.22.22\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.22.22.22.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.22.22.22.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.22.22.22.4.1\">.634</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.22.22.22.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.22.22.22.5.1\">.634</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.22.22.22.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.22.22.22.6.1\">.004</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.21.21.21.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.21.21.21.1.1\">.611 (.006)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.22.22.22.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.22.22.22.2.1\">.611 (.006)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.22.22.22.7\">.005</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.22.22.22.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.22.22.22.9\">-</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.24.24.24\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.24.24.24.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.24.24.24.4\">.539</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.24.24.24.5\">.539</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.24.24.24.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.24.24.24.6.1\">.004</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.23.23.23.1\">.514 (.111)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.24.24.24.2\">.514 (.111)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.24.24.24.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.24.24.24.7.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.24.24.24.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.24.24.24.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.26.26.26\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.26.26.26.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.26.26.26.3.1\">emoji</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.26.26.26.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.26.26.26.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.26.26.26.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.26.26.26.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.25.25.25.1\">.047 (.009)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.26.26.26.2\">.005 (.001)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.26.26.26.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.26.26.26.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.26.26.26.9.1\">.366</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.26.26.26.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.26.26.26.10.1\">.317</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.28.28.28\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.28.28.28.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.28.28.28.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.28.28.28.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.28.28.28.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.27.27.27.1\">.000 (.000)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.28.28.28.2\">.000 (.000)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.28.28.28.7\">.100</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.28.28.28.8\">.259</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.28.28.28.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.28.28.28.9.1\">.317</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.30.30.30\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.30.30.30.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.30.30.30.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.30.30.30.4.1\">.059</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.30.30.30.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.30.30.30.5.1\">.042</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.30.30.30.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.30.30.30.6.1\">.036</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.29.29.29.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.29.29.29.1.1\">.114(.021)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.30.30.30.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.30.30.30.2.1\">.082(.007)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.30.30.30.7\">.006</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.30.30.30.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.30.30.30.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.32.32.32\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.32.32.32.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.32.32.32.4\">.060</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.32.32.32.5\">.041</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.32.32.32.6\">.091</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.31.31.31.1\">.033(.036)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.32.32.32.2\">.020(.017)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.32.32.32.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.32.32.32.7.1\">.001</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.32.32.32.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.32.32.32.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.34.34.34\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.34.34.34.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.34.34.34.3.1\">sentiment</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.34.34.34.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.34.34.34.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.34.34.34.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.34.34.34.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.33.33.33.1\">.449 (.108)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.34.34.34.2\">.271 (.008)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.34.34.34.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.34.34.34.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.34.34.34.9.1\">.714</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.34.34.34.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.34.34.34.10.1\">.714</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.36.36.36\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.36.36.36.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.36.36.36.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.36.36.36.5\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.36.36.36.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.35.35.35.1\">.312 (.121)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.36.36.36.2\">.272 (.078)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.36.36.36.7\">.563</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.36.36.36.8\">.708</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.36.36.36.9\">.709</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.38.38.38\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.38.38.38.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.38.38.38.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.38.38.38.4.1\">.459</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.38.38.38.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.38.38.38.5.1\">.402</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.38.38.38.6\">.109</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.37.37.37.1\">.417 (.004)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.38.38.38.2\">.381 (.007)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.38.38.38.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.38.38.38.7.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.38.38.38.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.38.38.38.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.40.40.40\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.40.40.40.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.40.40.40.4\">.369</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.40.40.40.5\">.334</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.40.40.40.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.40.40.40.6.1\">.027</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.39.39.39.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.39.39.39.1.1\">.482 (.037)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.40.40.40.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.40.40.40.2.1\">.402 (.143)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.40.40.40.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.40.40.40.7.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.40.40.40.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.40.40.40.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.42.42.42\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.42.42.42.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.42.42.42.3.1\">BBC</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.42.42.42.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.42.42.42.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.42.42.42.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.42.42.42.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.41.41.41.1\">.217 (.027)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.42.42.42.2\">.112 (.029)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.42.42.42.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.42.42.42.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.42.42.42.9.1\">.989</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.42.42.42.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.42.42.42.10.1\">.989</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.44.44.44\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.44.44.44.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.44.44.44.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.44.44.44.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.44.44.44.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.43.43.43.1\">.001 (.001)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.44.44.44.2\">.001 (.001)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.44.44.44.7\">.999</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.44.44.44.8\">.977</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.44.44.44.9\">.977</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.46.46.46\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.46.46.46.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.46.46.46.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.46.46.46.4.1\">.922</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.46.46.46.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.46.46.46.5.1\">.867</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.46.46.46.6\">.096</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.45.45.45.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.45.45.45.1.1\">.939(.008)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.46.46.46.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.46.46.46.2.1\">.936(.009)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.46.46.46.7\">.038</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.46.46.46.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.46.46.46.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.48.48.48\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.48.48.48.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.48.48.48.4\">.498</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.48.48.48.5\">.439</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.48.48.48.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.48.48.48.6.1\">.021</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.47.47.47.1\">.849 (.098)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.48.48.48.2\">.843 (.081)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.48.48.48.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.48.48.48.7.1\">.004</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.48.48.48.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.48.48.48.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.128.128.133.5\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\" id=\"S4.T4.128.128.133.5.1\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.128.128.133.5.2\">GPT 3.5*</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.133.5.3\">.912</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.133.5.4\">.913</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.133.5.5\">.000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.133.5.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.133.5.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.133.5.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.133.5.9\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.133.5.10\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.50.50.50\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.50.50.50.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.50.50.50.3.1\">Reuters</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.50.50.50.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.50.50.50.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.50.50.50.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.50.50.50.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.49.49.49.1\">.154 (.111)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.50.50.50.2\">.054 (.021)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.50.50.50.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.50.50.50.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.50.50.50.9.1\">.939</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.50.50.50.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.50.50.50.10.1\">.869</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.52.52.52\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.52.52.52.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.52.52.52.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.52.52.52.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.52.52.52.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.51.51.51.1\">.010 (.034)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.52.52.52.2\">.010 (.067)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.52.52.52.7\">.990</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.52.52.52.8\">.929</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.52.52.52.9\">.833</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.54.54.54\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.54.54.54.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.54.54.54.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.54.54.54.4.1\">.321</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.54.54.54.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.54.54.54.5.1\">.334</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.54.54.54.6\">.334</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.53.53.53.1\">.467 (.023)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.54.54.54.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.54.54.54.2.1\">.504 (.032)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.54.54.54.7\">.017</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.54.54.54.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.54.54.54.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.56.56.56\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.56.56.56.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.56.56.56.4\">.212</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.56.56.56.5\">.168</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.56.56.56.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.56.56.56.6.1\">.006</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.55.55.55.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.55.55.55.1.1\">.528 (.076)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.56.56.56.2\">.304 (.145)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.56.56.56.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.56.56.56.7.1\">.006</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.56.56.56.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.56.56.56.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.128.128.134.6\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\" id=\"S4.T4.128.128.134.6.1\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.128.128.134.6.2\">GPT 3.5*</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.134.6.3\">.852</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.134.6.4\">.718</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.134.6.5\">.000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.134.6.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.134.6.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.134.6.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.134.6.9\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.134.6.10\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.58.58.58\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.58.58.58.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.58.58.58.3.1\">20 News(all)</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.58.58.58.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.58.58.58.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.58.58.58.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.58.58.58.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.57.57.57.1\">.190 (.028)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.58.58.58.2\">.101 (.019)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.58.58.58.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.58.58.58.9\">.859</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.58.58.58.10\">.853</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.60.60.60\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.60.60.60.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.60.60.60.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.60.60.60.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.60.60.60.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.59.59.59.1\">.000 (.000)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.60.60.60.2\">.000 (.000)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.60.60.60.7\">.999</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.60.60.60.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.60.60.60.8.1\">.861</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.60.60.60.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.60.60.60.9.1\">.854</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.62.62.62\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.62.62.62.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.62.62.62.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.62.62.62.4.1\">.564</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.62.62.62.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.62.62.62.5.1\">.520</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.62.62.62.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.62.62.62.6.1\">.001</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.61.61.61.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.61.61.61.1.1\">.684 (.008)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.62.62.62.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.62.62.62.2.1\">.654 (.007)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.62.62.62.7\">.057</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.62.62.62.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.62.62.62.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.64.64.64\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.64.64.64.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.64.64.64.4\">.324</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.64.64.64.5\">.272</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.64.64.64.6\">.094</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.63.63.63.1\">.368 (.034)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.64.64.64.2\">.300(.079)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.64.64.64.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.64.64.64.7.1\">.001</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.64.64.64.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.64.64.64.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.66.66.66\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.66.66.66.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.66.66.66.3.1\">20 News(subcl)</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.66.66.66.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.66.66.66.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.66.66.66.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.66.66.66.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.65.65.65.1\">.055 (.013)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.66.66.66.2\">.015 (.003)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.66.66.66.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.66.66.66.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.66.66.66.9.1\">.741</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.66.66.66.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.66.66.66.10.1\">.728</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.68.68.68\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.68.68.68.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.68.68.68.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.68.68.68.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.68.68.68.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.67.67.67.1\">.000 (.000)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.68.68.68.2\">.000 (.000)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.68.68.68.7\">.990</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.68.68.68.8\">.717</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.68.68.68.9\">.693</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.70.70.70\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.70.70.70.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.70.70.70.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.70.70.70.4.1\">.510</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.70.70.70.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.70.70.70.5.1\">.507</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.70.70.70.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.70.70.70.6.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.69.69.69.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.69.69.69.1.1\">.512 (.013)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.70.70.70.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.70.70.70.2.1\">.501 (.013)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.70.70.70.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.70.70.70.7.1\">.011</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.70.70.70.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.70.70.70.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.72.72.72\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.72.72.72.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.72.72.72.4\">.185</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.72.72.72.5\">.194</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.72.72.72.6\">.167</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.71.71.71.1\">.376 (.015)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.72.72.72.2\">.342 (.014)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.72.72.72.7\">.020</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.72.72.72.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.72.72.72.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.74.74.74\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.74.74.74.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.74.74.74.3.1\">Ohsumed</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.74.74.74.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.74.74.74.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.74.74.74.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.74.74.74.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.73.73.73.1\">.025 (.019)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.74.74.74.2\">.002 (.004)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.74.74.74.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.74.74.74.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.74.74.74.9.1\">.476</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.74.74.74.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.74.74.74.10.1\">.415</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.76.76.76\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.76.76.76.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.76.76.76.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.76.76.76.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.76.76.76.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.75.75.75.1\">.002 (.001)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.76.76.76.2\">.002 (.001)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.76.76.76.7\">.958</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.76.76.76.8\">.452</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.76.76.76.9\">.362</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.78.78.78\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.78.78.78.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.78.78.78.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.78.78.78.4.1\">.306</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.78.78.78.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.78.78.78.5.1\">.283</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.78.78.78.6\">.194</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.77.77.77.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.77.77.77.1.1\">.288 (.003)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.78.78.78.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.78.78.78.2.1\">.241 (.001)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.78.78.78.7\">.375</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.78.78.78.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.78.78.78.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.80.80.80\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.80.80.80.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.80.80.80.4\">.151</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.80.80.80.5\">.099</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.80.80.80.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.80.80.80.6.1\">.154</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.79.79.79.1\">.180 (.110)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.80.80.80.2\">.162 (.110)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.80.80.80.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.80.80.80.7.1\">.036</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.80.80.80.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.80.80.80.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.82.82.82\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.82.82.82.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.82.82.82.3.1\">Toxic</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.82.82.82.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.82.82.82.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.82.82.82.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.82.82.82.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.81.81.81.1\">.671 (.005)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.82.82.82.2\">.550 (.003)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.82.82.82.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.82.82.82.9\">.899</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.82.82.82.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.82.82.82.10.1\">.782</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.84.84.84\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.84.84.84.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.84.84.84.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.84.84.84.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.84.84.84.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.83.83.83.1\">.020 (.001)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.84.84.84.2\">.010 (.011)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.84.84.84.7\">.989</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.84.84.84.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.84.84.84.8.1\">.913</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.84.84.84.9\">.661</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.86.86.86\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.86.86.86.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.86.86.86.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.86.86.86.4.1\">.629</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.86.86.86.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.86.86.86.5.1\">.380</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.86.86.86.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.86.86.86.6.1\">.140</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.85.85.85.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.85.85.85.1.1\">.710 (.066)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.86.86.86.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.86.86.86.2.1\">.262 (.014)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.86.86.86.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.86.86.86.7.1\">.003</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.86.86.86.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.86.86.86.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.88.88.88\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.88.88.88.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.88.88.88.4\">.331</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.88.88.88.5\">.142</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.88.88.88.6\">.211</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.87.87.87.1\">.005 (.079)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.88.88.88.2\">.002 (.077)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.88.88.88.7\">.004</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.88.88.88.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.88.88.88.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.90.90.90\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.90.90.90.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.90.90.90.3.1\">Legal</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.90.90.90.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.90.90.90.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.90.90.90.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.90.90.90.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.89.89.89.1\">.429 (.030)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.90.90.90.2\">.285 (.030)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.90.90.90.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.90.90.90.9\">.965</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.90.90.90.10\">.601</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.92.92.92\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.92.92.92.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.92.92.92.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.92.92.92.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.92.92.92.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.91.91.91.1\">.500 (.037)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.92.92.92.2\">.125 (.042)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.92.92.92.7\">.970</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.92.92.92.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.92.92.92.8.1\">.982</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.92.92.92.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.92.92.92.9.1\">.612</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.94.94.94\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.94.94.94.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.94.94.94.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.94.94.94.4.1\">.251</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.94.94.94.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.94.94.94.5.1\">.233</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.94.94.94.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.94.94.94.6.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.93.93.93.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.93.93.93.1.1\">.351 (.047)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.94.94.94.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.94.94.94.2.1\">.352 (.028)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.94.94.94.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.94.94.94.7.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.94.94.94.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.94.94.94.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.96.96.96\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.96.96.96.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.96.96.96.4\">.224</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.96.96.96.5\">.167</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.96.96.96.6\">.069</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.95.95.95.1\">.269 (.091)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.96.96.96.2\">.232 (.175)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.96.96.96.7\">.005</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.96.96.96.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.96.96.96.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.98.98.98\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.98.98.98.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.98.98.98.3.1\">Cancer</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.98.98.98.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.98.98.98.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.98.98.98.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.98.98.98.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.97.97.97.1\">.309 (.003)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.98.98.98.2\">.290 (.002)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.98.98.98.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.98.98.98.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.98.98.98.9.1\">.524</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.98.98.98.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.98.98.98.10.1\">.414</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.100.100.100\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.100.100.100.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.100.100.100.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.100.100.100.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.100.100.100.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.99.99.99.1\">.000 (.000)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.100.100.100.2\">.000 (.000)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.100.100.100.7\">.000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.100.100.100.8\">.344</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.100.100.100.9\">.157</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.102.102.102\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.102.102.102.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.102.102.102.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.102.102.102.4.1\">.296</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.102.102.102.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.102.102.102.5.1\">.286</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.102.102.102.6\">.246</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.101.101.101.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.101.101.101.1.1\">.361 (.027)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.102.102.102.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.102.102.102.2.1\">.319 (.017)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.102.102.102.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.102.102.102.7.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.102.102.102.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.102.102.102.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.104.104.104\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.104.104.104.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.104.104.104.4\">.249</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.104.104.104.5\">.178</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.104.104.104.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.104.104.104.6.1\">.141</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.103.103.103.1\">.168 (.131)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.104.104.104.2\">.104 (.098)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.104.104.104.7\">.004</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.104.104.104.8\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.104.104.104.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.106.106.106\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.106.106.106.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.106.106.106.3.1\">PCL</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.106.106.106.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.106.106.106.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.106.106.106.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.106.106.106.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.105.105.105.1\">.555 (.004)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.106.106.106.2\">.518 (.006)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.106.106.106.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.106.106.106.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.106.106.106.9.1\">.719</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.106.106.106.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.106.106.106.10.1\">.592</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.108.108.108\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.108.108.108.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.108.108.108.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.108.108.108.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.108.108.108.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.107.107.107.1\">.001 (.001)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.108.108.108.2\">.001 (.001)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.108.108.108.7\">.999</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.108.108.108.8\">.654</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.108.108.108.9\">.525</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.110.110.110\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.110.110.110.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.110.110.110.4\">.224</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.110.110.110.5\">.124</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.110.110.110.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.110.110.110.6.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.109.109.109.1\">.224 (.008)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.110.110.110.2\">.141 (.112)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.110.110.110.7\">.001</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.110.110.110.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.110.110.110.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.112.112.112\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.112.112.112.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.112.112.112.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.112.112.112.4.1\">.392</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.112.112.112.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.112.112.112.5.1\">.303</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.112.112.112.6\">.050</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.111.111.111.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.111.111.111.1.1\">.287 (.095)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.112.112.112.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.112.112.112.2.1\">.159 (.114)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.112.112.112.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.112.112.112.7.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.112.112.112.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.112.112.112.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.128.128.135.7\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\" id=\"S4.T4.128.128.135.7.1\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.128.128.135.7.2\">GPT 3.5*</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.135.7.3\">.207</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.135.7.4\">.117</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.135.7.5\">.000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.135.7.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.135.7.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.135.7.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.135.7.9\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.135.7.10\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.114.114.114\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.114.114.114.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.114.114.114.3.1\">Safeguard(all)</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.114.114.114.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.114.114.114.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.114.114.114.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.114.114.114.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.113.113.113.1\">.601 (.011)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.114.114.114.2\">.589 (.011)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.114.114.114.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.114.114.114.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.114.114.114.9.1\">.905</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.114.114.114.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.114.114.114.10.1\">.895</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.116.116.116\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.116.116.116.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.116.116.116.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.116.116.116.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.116.116.116.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.115.115.115.1\">.000 (.000)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.116.116.116.2\">.000 (.000)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.116.116.116.7\">.000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.116.116.116.8\">.756</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.116.116.116.9\">.725</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.118.118.118\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.118.118.118.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.118.118.118.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.118.118.118.4.1\">.347</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.118.118.118.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.118.118.118.5.1\">.326</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.118.118.118.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.118.118.118.6.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.117.117.117.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.117.117.117.1.1\">.392 (.007)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.118.118.118.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.118.118.118.2.1\">.360 (.003)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.118.118.118.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.118.118.118.7.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.118.118.118.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.118.118.118.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.120.120.120\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.120.120.120.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.120.120.120.4\">.291</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.120.120.120.5\">.233</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.120.120.120.6\">.041</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.119.119.119.1\">.286 (.007)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.120.120.120.2\">.197 (.003)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.120.120.120.7\">.001</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.120.120.120.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.120.120.120.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.128.128.136.8\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\" id=\"S4.T4.128.128.136.8.1\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.128.128.136.8.2\">GPT 3.5*</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.136.8.3\">.369</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.136.8.4\">.340</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.136.8.5\">.000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.136.8.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.136.8.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.136.8.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.136.8.9\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.136.8.10\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.122.122.122\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T4.122.122.122.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T4.122.122.122.3.1\">Safeguard(subcl)</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T4.122.122.122.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.122.122.122.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.122.122.122.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.122.122.122.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.121.121.121.1\">.247 (.105)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.122.122.122.2\">.201 (.102)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.122.122.122.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.122.122.122.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.122.122.122.9.1\">.718</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T4.122.122.122.10\">.515</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.124.124.124\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.124.124.124.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.124.124.124.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.124.124.124.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.124.124.124.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.123.123.123.1\">.010 (.002)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.124.124.124.2\">.020 (.002)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.124.124.124.7\">.969</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.124.124.124.8\">.657</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.124.124.124.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.124.124.124.9.1\">.516</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.126.126.126\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.126.126.126.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.126.126.126.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.126.126.126.4.1\">.275</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.126.126.126.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.126.126.126.5.1\">.253</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.126.126.126.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.126.126.126.6.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.125.125.125.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.125.125.125.1.1\">.281 (.012)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.126.126.126.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.126.126.126.2.1\">.265 (.009)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.126.126.126.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T4.126.126.126.7.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.126.126.126.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.126.126.126.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.128.128.128\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T4.128.128.128.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.128.4\">.195</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.128.5\">.176</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.128.6\">.051</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.127.127.127.1\">.237 (.049)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.128.2\">.231 (.089)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.128.7\">.006</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.128.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.128.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.128.128.137.9\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_r\" id=\"S4.T4.128.128.137.9.1\"></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr ltx_border_t\" id=\"S4.T4.128.128.137.9.2\">GPT 3.5*</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.137.9.3\">.359</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.137.9.4\">.366</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.137.9.5\">.012</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.137.9.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.137.9.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.137.9.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.137.9.9\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T4.128.128.137.9.10\">\u2013</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Micro-F1 and Macro-F1 results per dataset for RoBERTa (large), fine-tuned T5, Flan-T5, LLaMA 2, and GPT 3.5-Turbo. The ratio of wrongly-formatted outputs is included in the wrong labels (labs) column.The results for Flan-T5 and LLaMA 2 are based on averaged results across all prompts.</figcaption>\n</figure>",
            "capture": "Table 4: Micro-F1 and Macro-F1 results per dataset for RoBERTa (large), fine-tuned T5, Flan-T5, LLaMA 2, and GPT 3.5-Turbo. The ratio of wrongly-formatted outputs is included in the wrong labels (labs) column.The results for Flan-T5 and LLaMA 2 are based on averaged results across all prompts."
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T5\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"S4.T5.16\" style=\"width:393.9pt;height:123.1pt;vertical-align:-0.7pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-92.7pt,28.8pt) scale(0.68,0.68) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T5.16.16\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T5.16.16.17.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.17.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.16.16.17.1.1.1\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T5.16.16.17.1.2\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.16.16.17.1.2.1\">Model</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"3\" id=\"S4.T5.16.16.17.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.16.16.17.1.3.1\">zero shot</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"3\" id=\"S4.T5.16.16.17.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.16.16.17.1.4.1\">one shot</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\" id=\"S4.T5.16.16.17.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.16.16.17.1.5.1\">all</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.16.16.18.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.18.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.16.16.18.2.1.1\">micro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.18.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.16.16.18.2.2.1\">macro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.18.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.16.16.18.2.3.1\">wrong labs</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.18.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.16.16.18.2.4.1\">micro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.18.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.16.16.18.2.5.1\">macro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.18.2.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.16.16.18.2.6.1\">wrong labs</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.18.2.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.16.16.18.2.7.1\">micro F1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.18.2.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.16.16.18.2.8.1\">macro F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.2.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T5.2.2.2.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T5.2.2.2.3.1\">IMDB</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T5.2.2.2.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.2.2.2.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.2.2.2.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.2.2.2.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.1.1.1.1\">.436 (.311)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.2.2.2.2\">.436 (0.311)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.2.2.2.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.2.2.2.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.2.2.2.9.1\">.955</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.2.2.2.10\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.2.2.2.10.1\">.955</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.4.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T5.4.4.4.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.4.4.4.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.4.4.4.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.4.4.4.6\">\u2014-</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.3.3.3.1\">.751 (.065)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.4.4.4.2\">.751 (.065)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.4.4.4.7\">.711</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.4.4.4.8\">.952</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.4.4.4.9\">.952</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.6.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T5.6.6.6.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.6.6.6.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.6.6.6.4.1\">.948</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.6.6.6.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.6.6.6.5.1\">.948</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.6.6.6.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T5.6.6.6.6.1\">.097</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.5.5.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.5.5.5.1.1\">.900 (.007)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.6.6.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.6.6.6.2.1\">.900 (.007)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.6.6.6.7\">.017</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.6.6.6.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.6.6.6.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.8.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T5.8.8.8.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.8.8.8.4\">.628</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.8.8.8.5\">.628</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.8.8.8.6\">.219</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.7.7.7.1\">.803 (.012)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.8.8.8.2\">.803 (.012)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.8.8.8.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T5.8.8.8.7.1\">.005</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.8.8.8.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.8.8.8.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.10.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_r ltx_border_tt\" id=\"S4.T5.10.10.10.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T5.10.10.10.3.1\">AG News</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" id=\"S4.T5.10.10.10.4\">RoBERTa</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.10.10.10.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.10.10.10.6\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.10.10.10.7\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.9.9.9.1\">.280 (.022)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.10.10.10.2\">.111 (.024)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.10.10.10.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.10.10.10.9\">.906</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"S4.T5.10.10.10.10\">.884</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.12.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T5.12.12.12.3\">T5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.12.12.12.4\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.12.12.12.5\">\u2014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.12.12.12.6\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.11.11.11.1\">.010 (.003)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.12.12.12.2\">.010 (.003)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.12.12.12.7\">.990</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.12.12.12.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.12.12.12.8.1\">.907</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.12.12.12.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.12.12.12.9.1\">.886</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.14.14.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\" id=\"S4.T5.14.14.14.3\">FlanT5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.14.14.14.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.14.14.14.4.1\">.819</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.14.14.14.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.14.14.14.5.1\">.789</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.14.14.14.6\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T5.14.14.14.6.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.13.13.13.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.13.13.13.1.1\">.813 (.008)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.14.14.14.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.14.14.14.2.1\">.782(.009)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.14.14.14.7\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" id=\"S4.T5.14.14.14.7.1\">.000</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.14.14.14.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.14.14.14.9\">\u2013</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.16.16.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr ltx_border_t\" id=\"S4.T5.16.16.16.3\">LLaMA</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.16.4\">.479</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.16.5\">.463</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.16.6\">.011</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T5.15.15.15.1\">.787 (.006)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.16.2\">.753 (.005)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.16.7\">.003</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.16.8\">\u2013</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T5.16.16.16.9\">\u2013</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>Micro- and Macro-F1 results for \u2018AG News\u2019 and \u2018IMDB\u2019 datasets for RoBERTa-large, fine-tuned T5 model, Flan-T5, LLaMA 2. The ratio of wrongly-formatted outputs is included in the wrong labels (labs) column. The results for Flan-T5 and LLaMA 2 are based on averaged results across all prompts.</figcaption>\n</figure>",
            "capture": "Table 5: Micro- and Macro-F1 results for \u2018AG News\u2019 and \u2018IMDB\u2019 datasets for RoBERTa-large, fine-tuned T5 model, Flan-T5, LLaMA 2. The ratio of wrongly-formatted outputs is included in the wrong labels (labs) column. The results for Flan-T5 and LLaMA 2 are based on averaged results across all prompts."
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"A1.T6\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" id=\"A1.T6.1\" style=\"width:180.8pt;height:249.5pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-60.3pt,83.2pt) scale(0.6,0.6) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A1.T6.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T6.1.1.1.1.1.1\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t\" id=\"A1.T6.1.1.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.1.1.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.1.1.2.1.1\" style=\"width:227.6pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T6.1.1.1.1.2.1.1.1\">Domain Prompt</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.2.1.1\">irony</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.2.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.2.1.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.2.1.2.1.1\" style=\"width:227.6pt;\">Is the Tweet classified as irony or non-irony?</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.3.2.1\">offense</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.3.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.3.2.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.3.2.2.1.1\" style=\"width:227.6pt;\">Is the Tweet classified as offensive or non-offensive?</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.4.3.1\">hate</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.4.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.4.3.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.4.3.2.1.1\" style=\"width:227.6pt;\">Is the Tweet classified as hate or non-hate?</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.5.4.1\">emoji</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.5.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.5.4.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.5.4.2.1.1\" style=\"width:227.6pt;\">Which of the given emojis best describe the given Tweet?The emojis are:</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.6.5.1\">sentiment</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.6.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.6.5.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.6.5.2.1.1\" style=\"width:227.6pt;\">Is the Tweet positive, negative, or neutral?</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.7.6.1\">BBC</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.7.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.7.6.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.7.6.2.1.1\" style=\"width:227.6pt;\">Classify the news into one of the following topics:</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.8.7.1\">Reuters</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.8.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.8.7.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.8.7.2.1.1\" style=\"width:227.6pt;\">Classify the news into one of the following topics:</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.9.8.1\">20 News</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.9.8.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.9.8.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.9.8.2.1.1\" style=\"width:227.6pt;\">Classify the newsgroup into one of the following topics:</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.10.9.1\">Ohsumed</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.10.9.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.10.9.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.10.9.2.1.1\" style=\"width:227.6pt;\">Select the medical conditions that this article is about. The options are:</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.11.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.11.10.1\">Toxic</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.11.10.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.11.10.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.11.10.2.1.1\" style=\"width:227.6pt;\">Which of the given toxic topics best describe the given comment? Choose one or more from the following topics:</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.12.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.12.11.1\">Legal</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.12.11.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.12.11.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.12.11.2.1.1\" style=\"width:227.6pt;\">Which of the given legal topics best describe the given legislation document?Choose one or more from the following topics:</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.13.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.13.12.1\">Cancer</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.13.12.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.13.12.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.13.12.2.1.1\" style=\"width:227.6pt;\">Which hallmarks of cancer are present in the text? Choose one or more from the following options</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.14.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.14.13.1\">PCL</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.14.13.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.14.13.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.14.13.2.1.1\" style=\"width:227.6pt;\">Which of the given topics best describe the patronising comment. Choose one or more from the following topics:</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.15.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.15.14.1\">Safeguard</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.15.14.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.15.14.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.15.14.2.1.1\" style=\"width:227.6pt;\">Which of the given themes best describe the sentence? Choose one or more from the following themes:</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.16.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.16.15.1\">IMDB</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T6.1.1.16.15.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.16.15.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.16.15.2.1.1\" style=\"width:227.6pt;\">Is the movie review positive or negative?</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T6.1.1.17.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\" id=\"A1.T6.1.1.17.16.1\">AG News</th>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t\" id=\"A1.T6.1.1.17.16.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T6.1.1.17.16.2.1\">\n<span class=\"ltx_p\" id=\"A1.T6.1.1.17.16.2.1.1\" style=\"width:227.6pt;\">Select the topic that the given article is about.The topics are:</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 6: </span>A list of all domain-based prompts used per dataset.</figcaption>\n</figure>",
            "capture": "Table 6: A list of all domain-based prompts used per dataset."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.17661v2_figure_1.png",
            "caption": "Figure 1: Micro-F1 (left) and Macro-F1 (middle) results averaged across all datasets, comparing the performance of Flan-T5, LLaMA 1, and LLaMA 2 models for all three types of prompts, i.e., \u2019generic\u2019, \u2019task\u2019, and \u2019domain\u2019 as well as the average (\u2019AVG\u2019) between them. \u2019Missing label\u2019 (right) shows the fraction of results returned by the three models that are different from the classification labels. Results are displayed for zero-shot (\u2019zero\u2019) and one-shot setting (\u2019one\u2019)."
        },
        "2": {
            "figure_path": "2403.17661v2_figure_2.png",
            "caption": "Figure 2: Comparison between prompting (left) and fine-tuning (right) approaches per text classification type where \u2019AVG\u2019 refers to averaged results across all prompt types per model. In \u2019Prompting\u2019, \u2019zero\u2019 and \u2019one\u2019 refer to zero- and one- shot prompt-based learning techniques, in \u2019Fine Tuning\u2019, \u2019one\u2019 refers to fine-tuning the models with one training instance per label and \u2019all\u2019 refers to fine-tuning using the entire dataset."
        },
        "3": {
            "figure_path": "2403.17661v2_figure_3.png",
            "caption": "Figure 3: Wrong labels for prompting approaches per binary (left), multiclass (middle), and multilabel (right) classification where \u2019zero\u2019 refers to zero-shot learning and \u2019one\u2019 refers to one-shot learning."
        },
        "4": {
            "figure_path": "2403.17661v2_figure_4.png",
            "caption": "Figure 4: Averaged Micro-F1 and Macro-F1 results based on number of classification labels: \u2018RoBERTa (all)\u2019 and \u2018T5 (all)\u2019 refer to models fine-tuned on the entire training set, \u2018Flan-T5 (one)\u2019 and \u2018LLaMA (one)\u2019 refer to one-shot prompting."
        },
        "5": {
            "figure_path": "2403.17661v2_figure_5.png",
            "caption": "Figure 5: Comparison between prompting (left) and fine-tuning (right) approaches per text classification type where \u2019AVG\u2019 refers to averaged results across all prompt types per model. In \u2019Prompting\u2019, \u2019zero\u2019 and \u2019one\u2019 refer to zero- and one- shot prompt-based learning techniques, in \u2019Fine Tuning\u2019, \u2019one\u2019 refers to fine-tuning the models with one training instance per label and \u2019all\u2019 refers to fine-tuning using the entire dataset."
        }
    },
    "references": [
        {
            "1": {
                "title": "Automatic semantic classification of scientific literature according to the hallmarks of cancer.",
                "author": "Simon Baker, Ilona Silins, Yufan Guo, Imran Ali, Johan H\u00f6gberg, Ulla Stenius, and Anna Korhonen. 2015.",
                "venue": "Bioinformatics, 32(3):432\u2013440.",
                "url": null
            }
        },
        {
            "2": {
                "title": "A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity.",
                "author": "Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al. 2023.",
                "venue": "arXiv preprint arXiv:2302.04023.",
                "url": null
            }
        },
        {
            "3": {
                "title": "Semeval 2018 task 2: Multilingual emoji prediction.",
                "author": "Francesco Barbieri, Jose Camacho-Collados, Francesco Ronzano, Luis Espinosa Anke, Miguel Ballesteros, Valerio Basile, Viviana Patti, and Horacio Saggion. 2018.",
                "venue": "In Proceedings of the 12th international workshop on semantic evaluation, pages 24\u201333.",
                "url": null
            }
        },
        {
            "4": {
                "title": "Semeval-2019 task 5: Multilingual detection of hate speech against immigrants and women in twitter.",
                "author": "Valerio Basile, Cristina Bosco, Elisabetta Fersini, Debora Nozza, Viviana Patti, Francisco Manuel Rangel Pardo, Paolo Rosso, and Manuela Sanguinetti. 2019.",
                "venue": "In Proceedings of the 13th international workshop on semantic evaluation, pages 54\u201363.",
                "url": null
            }
        },
        {
            "5": {
                "title": "Gpt-neox-20b: An open-source autoregressive language model.",
                "author": "Sidney Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, et al. 2022.",
                "venue": "In Proceedings of BigScience Episode# 5\u2013Workshop on Challenges & Perspectives in Creating Large Language Models, pages 95\u2013136.",
                "url": null
            }
        },
        {
            "6": {
                "title": "Language models are few-shot learners.",
                "author": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020.",
                "venue": "Advances in neural information processing systems, 33:1877\u20131901.",
                "url": null
            }
        },
        {
            "7": {
                "title": "Large-scale multi-label text classification on eu legislation.",
                "author": "Ilias Chalkidis, Emmanouil Fergadiotis, Prodromos Malakasiotis, and Ion Androutsopoulos. 2019.",
                "venue": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 6314\u20136322.",
                "url": null
            }
        },
        {
            "8": {
                "title": "An empirical study on large-scale multi-label text classification including few and zero-shot labels.",
                "author": "Ilias Chalkidis, Manos Fergadiotis, Sotiris Kotitsas, Prodromos Malakasiotis, Nikolaos Aletras, and Ion Androutsopoulos. 2020.",
                "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 7503\u20137515.",
                "url": null
            }
        },
        {
            "9": {
                "title": "Scaling instruction-finetuned language models.",
                "author": "Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022.",
                "venue": "arXiv preprint arXiv:2210.11416.",
                "url": null
            }
        },
        {
            "10": {
                "title": "Rlprompt: Optimizing discrete text prompts with reinforcement learning.",
                "author": "Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song, Eric Xing, and Zhiting Hu. 2022.",
                "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 3369\u20133391.",
                "url": null
            }
        },
        {
            "11": {
                "title": "Bert: Pre-training of deep bidirectional transformers for language understanding.",
                "author": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.",
                "venue": "arXiv preprint arXiv:1810.04805.",
                "url": null
            }
        },
        {
            "12": {
                "title": "Unified language model pre-training for natural language understanding and generation.",
                "author": "Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, and Hsiao-Wuen Hon. 2019.",
                "venue": "Advances in neural information processing systems, 32.",
                "url": null
            }
        },
        {
            "13": {
                "title": "Go simple and pre-train on domain-specific corpora: On the role of training data for text classification.",
                "author": "Aleksandra Edwards, Jose Camacho-Collados, H\u00e9l\u00e8ne De Ribaupierre, and Alun Preece. 2020.",
                "venue": "In Proceedings of the 28th international conference on computational linguistics, pages 5522\u20135529.",
                "url": null
            }
        },
        {
            "14": {
                "title": "Guiding generative language models for data augmentation in few-shot text classification.",
                "author": "Aleksandra Edwards, Asahi Ushio, Jose Camacho-Collados, Helene Ribaupierre, and Alun Preece. 2022.",
                "venue": "In Proceedings of the Fourth Workshop on Data Science with Human-in-the-Loop (Language Advances), pages 51\u201363.",
                "url": null
            }
        },
        {
            "15": {
                "title": "The turking test: Can language models understand instructions?",
                "author": "Avia Efrat and Omer Levy. 2020.",
                "venue": "arXiv preprint arXiv:2010.11982.",
                "url": null
            }
        },
        {
            "16": {
                "title": "Making pre-trained language models better few-shot learners.",
                "author": "Tianyu Gao, Adam Fisch, and Danqi Chen. 2021.",
                "venue": "In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 3816\u20133830.",
                "url": null
            }
        },
        {
            "17": {
                "title": "Few-shot learning for medical text: A systematic review.",
                "author": "Yao Ge, Yuting Guo, Yuan-Chi Yang, Mohammed Ali Al-Garadi, and Abeed Sarker. 2022.",
                "venue": "arXiv preprint arXiv:2204.14081.",
                "url": null
            }
        },
        {
            "18": {
                "title": "Zero-shot text classification with self-training.",
                "author": "Ariel Gera, Alon Halfon, Eyal Shnarch, Yotam Perlitz, Liat Ein-Dor, and Noam Slonim. 2022.",
                "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 1107\u20131119, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2022.emnlp-main.73"
            }
        },
        {
            "19": {
                "title": "A study of various text augmentation techniques for relation classification in free text.",
                "author": "Praveen Kumar Badimala Giridhara, Chinmaya Mishra, Reddy Kumar Modam Venkataramana, Syed Saqib Bukhari, and Andreas Dengel. 2019.",
                "venue": "ICPRAM, 3:5.",
                "url": null
            }
        },
        {
            "20": {
                "title": "Domain-specific language model pretraining for biomedical natural language processing.",
                "author": "Yu Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto Usuyama, Xiaodong Liu, Tristan Naumann, Jianfeng Gao, and Hoifung Poon. 2021.",
                "venue": "ACM Transactions on Computing for Healthcare (HEALTH), 3(1):1\u201323.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Effective few-shot classification with transfer learning.",
                "author": "Aakriti Gupta, Kapil Thadani, and Neil O\u2019Hare. 2020.",
                "venue": "In Proceedings of the 28th International Conference on Computational Linguistics, pages 1061\u20131066.",
                "url": null
            }
        },
        {
            "22": {
                "title": "Deceiving google\u2019s perspective api built for detecting toxic comments. arxiv 2017.",
                "author": "Hossein Hosseini, Sreeram Kannan, Baosen Zhang, and Radha Poovendran. 2017.",
                "venue": "arXiv preprint arXiv:1702.08138.",
                "url": null
            }
        },
        {
            "23": {
                "title": "Text categorization with support vector machines: Learning with many relevant features.",
                "author": "Thorsten Joachims. 1998.",
                "venue": "In European conference on machine learning, pages 137\u2013142. Springer.",
                "url": null
            }
        },
        {
            "24": {
                "title": "Bag of tricks for efficient text classification.",
                "author": "Armand Joulin, \u00c9douard Grave, Piotr Bojanowski, and Tom\u00e1\u0161 Mikolov. 2017.",
                "venue": "In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 427\u2013431.",
                "url": null
            }
        },
        {
            "25": {
                "title": "A zero-shot and few-shot study of instruction-finetuned large language models applied to clinical and biomedical tasks.",
                "author": "Yanis Labrak, Mickael Rouvier, and Richard Dufour. 2023.",
                "venue": "arXiv preprint arXiv:2307.12114.",
                "url": null
            }
        },
        {
            "26": {
                "title": "Newsweeder: Learning to filter netnews.",
                "author": "Ken Lang. 1995.",
                "venue": "In Proceedings of the 12th International Conference on Machine Learning, pages 331\u2013339, Tahoe City, California.",
                "url": null
            }
        },
        {
            "27": {
                "title": "How many data points is a prompt worth?",
                "author": "Teven Le Scao and Alexander M Rush. 2021.",
                "venue": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2627\u20132636.",
                "url": null
            }
        },
        {
            "28": {
                "title": "Rcv1: A new benchmark collection for text categorization research.",
                "author": "David D Lewis, Yiming Yang, Tony Russell-Rose, and Fan Li. 2004.",
                "venue": "Journal of machine learning research, 5(Apr):361\u2013397.",
                "url": null
            }
        },
        {
            "29": {
                "title": "Gpteval: Nlg evaluation using gpt-4 with better human alignment.",
                "author": "Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. 2023.",
                "venue": "arXiv preprint arXiv:2303.16634.",
                "url": null
            }
        },
        {
            "30": {
                "title": "Roberta: A robustly optimized bert pretraining approach.",
                "author": "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.",
                "venue": "arXiv preprint arXiv:1907.11692.",
                "url": null
            }
        },
        {
            "31": {
                "title": "A sentence-level hierarchical bert model for document classification with limited labelled data.",
                "author": "Jinghui Lu, Maeve Henchion, Ivan Bacher, and Brian Mac Namee. 2021.",
                "venue": "In Discovery Science: 24th International Conference, DS 2021, Halifax, NS, Canada, October 11\u201313, 2021, Proceedings 24, pages 231\u2013241. Springer.",
                "url": null
            }
        },
        {
            "32": {
                "title": "Learning word vectors for sentiment analysis.",
                "author": "Andrew L Maas, Raymond E Daly, Peter T Pham, Dan Huang, Andrew Y Ng, and Christopher Potts. 2011.",
                "venue": "In Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies-volume 1, pages 142\u2013150. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "33": {
                "title": "Cross-task generalization via natural language crowdsourcing instructions.",
                "author": "Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2022.",
                "venue": "In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3470\u20133487.",
                "url": null
            }
        },
        {
            "34": {
                "title": "Few-shot fine-tuning vs. in-context learning: A fair comparison and evaluation.",
                "author": "Marius Mosbach, Tiago Pimentel, Shauli Ravfogel, Dietrich Klakow, and Yanai Elazar. 2023.",
                "venue": "arXiv preprint arXiv:2305.16938.",
                "url": null
            }
        },
        {
            "35": {
                "title": "Semeval-2016 task 4: Sentiment analysis in twitter.",
                "author": "Preslav Nakov, Alan Ritter, Sara Rosenthal, Fabrizio Sebastiani, and Veselin Stoyanov. 2019.",
                "venue": "arXiv preprint arXiv:1912.01973.",
                "url": null
            }
        },
        {
            "36": {
                "title": "Large language models vote: Prompting for rare disease identification.",
                "author": "David Oniani, Jordan Hilsman, Hang Dong, Fengyi Gao, Shiven Verma, and Yanshan Wang. 2023.",
                "venue": "arXiv preprint arXiv:2308.12890.",
                "url": null
            }
        },
        {
            "37": {
                "title": "Training language models to follow instructions with human feedback.",
                "author": "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022.",
                "venue": "Advances in Neural Information Processing Systems, 35:27730\u201327744.",
                "url": null
            }
        },
        {
            "38": {
                "title": "Is domain adaptation worth your investment? comparing bert and finbert on financial tasks.",
                "author": "Bo Peng, Emmanuele Chersoni, Yu-Yin Hsu, and Chu-Ren Huang. 2021.",
                "venue": "In Proceedings of the Third Workshop on Economics and Natural Language Processing, pages 37\u201344.",
                "url": null
            }
        },
        {
            "39": {
                "title": "Don\u2019t patronize me! an annotated dataset with patronizing and condescending language towards vulnerable communities.",
                "author": "Carla Perez Almendros, Espinosa Anke, Luis, and Steven Schockaert. 2020.",
                "venue": "In Proceedings of the 28th International Conference on Computational Linguistics, pages 5891\u20135902, Barcelona, Spain (Online). International Committee on Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2020.coling-main.518"
            }
        },
        {
            "40": {
                "title": "Towards a seamless integration of word senses into downstream nlp applications.",
                "author": "Mohammad Taher Pilehvar, Jose Camacho-Collados, Roberto Navigli, and Nigel Collier. 2017.",
                "venue": "In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1857\u20131869.",
                "url": null
            }
        },
        {
            "41": {
                "title": "Leveraging label variation in large language models for zero-shot text classification.",
                "author": "Flor Miriam Plaza-del Arco, Debora Nozza, and Dirk Hovy. 2023.",
                "venue": "arXiv preprint arXiv:2307.12973.",
                "url": null
            }
        },
        {
            "42": {
                "title": "Improving language understanding by generative pre-training.",
                "author": "Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. 2018.",
                "venue": "OpenAI.",
                "url": null
            }
        },
        {
            "43": {
                "title": "Language models are unsupervised multitask learners.",
                "author": "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019.",
                "venue": "OpenAI blog, 1(8):9.",
                "url": null
            }
        },
        {
            "44": {
                "title": "Exploring the limits of transfer learning with a unified text-to-text transformer.",
                "author": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020.",
                "venue": "The Journal of Machine Learning Research, 21(1):5485\u20135551.",
                "url": null
            }
        },
        {
            "45": {
                "title": "Multitask prompted training enables zero-shot task generalization.",
                "author": "Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2022.",
                "venue": "In ICLR 2022-Tenth International Conference on Learning Representations.",
                "url": null
            }
        },
        {
            "46": {
                "title": "Few-shot and zero-shot approaches to legal text classification: A case study in the financial sector.",
                "author": "Rajdeep Sarkar, Atul Kr. Ojha, Jay Megaro, John Mariano, Vall Herard, and John P. McCrae. 2021.",
                "venue": "In Proceedings of the Natural Legal Language Processing Workshop 2021, pages 102\u2013106, Punta Cana, Dominican Republic. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2021.nllp-1.10"
            }
        },
        {
            "47": {
                "title": "Exploiting cloze-questions for few-shot text classification and natural language inference.",
                "author": "Timo Schick and Hinrich Sch\u00fctze. 2021a.",
                "venue": "In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 255\u2013269.",
                "url": null
            }
        },
        {
            "48": {
                "title": "It\u2019s not just size that matters: Small language models are also few-shot learners.",
                "author": "Timo Schick and Hinrich Sch\u00fctze. 2021b.",
                "venue": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2339\u20132352.",
                "url": null
            }
        },
        {
            "49": {
                "title": "Generalized zero-and few-shot learning via aligned variational autoencoders.",
                "author": "Edgar Sch\u00f6nfeld, Sayna Ebrahimi, Samarth Sinha, Trevor Darrell, and Zeynep Akata. 2019.",
                "venue": "In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 8239\u20138247. IEEE.",
                "url": null
            }
        },
        {
            "50": {
                "title": "Autoprompt: Eliciting knowledge from language models with automatically generated prompts.",
                "author": "Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace, and Sameer Singh. 2020.",
                "venue": "arXiv preprint arXiv:2010.15980.",
                "url": null
            }
        },
        {
            "51": {
                "title": "Generalized zero-shot text classification for icd coding.",
                "author": "Congzheng Song, Shanghang Zhang, Najmeh Sadoughi, Pengtao Xie, and Eric Xing. 2021.",
                "venue": "In Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence, pages 4018\u20134024.",
                "url": null
            }
        },
        {
            "52": {
                "title": "Energy and policy considerations for deep learning in nlp.",
                "author": "Emma Strubell, Ananya Ganesh, and Andrew McCallum. 2019.",
                "venue": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3645\u20133650.",
                "url": null
            }
        },
        {
            "53": {
                "title": "Evaluating the zero-shot robustness of instruction-tuned language models.",
                "author": "Jiuding Sun, Chantal Shaib, and Byron C Wallace. 2023.",
                "venue": "arXiv preprint arXiv:2306.11270.",
                "url": null
            }
        },
        {
            "54": {
                "title": "Llama: Open and efficient foundation language models.",
                "author": "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023a.",
                "venue": "arXiv preprint arXiv:2302.13971.",
                "url": null
            }
        },
        {
            "55": {
                "title": "Llama 2: Open foundation and fine-tuned chat models.",
                "author": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023b.",
                "venue": "arXiv preprint arXiv:2307.09288.",
                "url": null
            }
        },
        {
            "56": {
                "title": "Knowledge-based short text categorization using entity and category embedding.",
                "author": "Rima T\u00fcrker, Lei Zhang, Maria Koutraki, and Harald Sack. 2019.",
                "venue": "In The Semantic Web: 16th International Conference, ESWC 2019, Portoro\u017e, Slovenia, June 2\u20136, 2019, Proceedings 16, pages 346\u2013362. Springer.",
                "url": null
            }
        },
        {
            "57": {
                "title": "Semeval-2018 task 3: Irony detection in english tweets.",
                "author": "Cynthia Van Hee, Els Lefever, and V\u00e9ronique Hoste. 2018.",
                "venue": "In Proceedings of The 12th International Workshop on Semantic Evaluation, pages 39\u201350.",
                "url": null
            }
        },
        {
            "58": {
                "title": "Prompt2model: Generating deployable models from natural language instructions.",
                "author": "Vijay Viswanathan, Chenyang Zhao, Amanda Bertsch, Tongshuang Wu, and Graham Neubig. 2023.",
                "venue": "arXiv preprint arXiv:2308.12261.",
                "url": null
            }
        },
        {
            "59": {
                "title": "Superglue: A stickier benchmark for general-purpose language understanding systems.",
                "author": "Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. 2019.",
                "venue": "Advances in neural information processing systems, 32.",
                "url": null
            }
        },
        {
            "60": {
                "title": "Glue: A multi-task benchmark and analysis platform for natural language understanding.",
                "author": "Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. 2018.",
                "venue": "In International Conference on Learning Representations.",
                "url": null
            }
        },
        {
            "61": {
                "title": "Automatic multi-label prompting: Simple and interpretable few-shot classification.",
                "author": "Han Wang, Canwen Xu, and Julian McAuley. 2022a.",
                "venue": "arXiv preprint arXiv:2204.06305.",
                "url": null
            }
        },
        {
            "62": {
                "title": "Generalizing from a few examples: A survey on few-shot learning.",
                "author": "Yaqing Wang, Quanming Yao, James T Kwok, and Lionel M Ni. 2020.",
                "venue": "ACM computing surveys (csur), 53(3):1\u201334.",
                "url": null
            }
        },
        {
            "63": {
                "title": "Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks.",
                "author": "Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva Naik, Arjun Ashok, Arut Selvan Dhanasekaran, Anjana Arunkumar, David Stap, et al. 2022b.",
                "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 5085\u20135109.",
                "url": null
            }
        },
        {
            "64": {
                "title": "Finetuned language models are zero-shot learners.",
                "author": "Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2021.",
                "venue": "In International Conference on Learning Representations.",
                "url": null
            }
        },
        {
            "65": {
                "title": "Huggingface\u2019s transformers: State-of-the-art natural language processing.",
                "author": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, et al. 2019.",
                "venue": "arXiv preprint arXiv:1910.03771.",
                "url": null
            }
        },
        {
            "66": {
                "title": "An evaluation of statistical approaches to text categorization.",
                "author": "Yiming Yang. 1999.",
                "venue": "Information retrieval, 1(1-2):69\u201390.",
                "url": null
            }
        },
        {
            "67": {
                "title": "Benchmarking zero-shot text classification: Datasets, evaluation and entailment approach.",
                "author": "Wenpeng Yin, Jamaal Hay, and Dan Roth. 2019.",
                "venue": "In 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, pages 3914\u20133923. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "68": {
                "title": "Semeval-2019 task 6: Identifying and categorizing offensive language in social media (offenseval).",
                "author": "Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, and Ritesh Kumar. 2019.",
                "venue": "In Proceedings of the 13th International Workshop on Semantic Evaluation, pages 75\u201386.",
                "url": null
            }
        },
        {
            "69": {
                "title": "Bertscore: Evaluating text generation with bert.",
                "author": "Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi. 2019.",
                "venue": "In International Conference on Learning Representations.",
                "url": null
            }
        },
        {
            "70": {
                "title": "Character-level convolutional networks for text classification.",
                "author": "Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015.",
                "venue": "In Advances in neural information processing systems, pages 649\u2013657.",
                "url": null
            }
        },
        {
            "71": {
                "title": "Short text classification based on feature extension using the n-gram model.",
                "author": "Xinwei Zhang and Bin Wu. 2015.",
                "venue": "In 2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD), pages 710\u2013716. IEEE.",
                "url": null
            }
        },
        {
            "72": {
                "title": "Learn to adapt for generalized zero-shot text classification.",
                "author": "Yiwen Zhang, Caixia Yuan, Xiaojie Wang, Ziwei Bai, and Yongbin Liu. 2022.",
                "venue": "In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 517\u2013527, Dublin, Ireland. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2022.acl-long.39"
            }
        },
        {
            "73": {
                "title": "A review of text classification based on deep learning.",
                "author": "Yifan Zhou. 2020.",
                "venue": "In Association for Computing Machinery, ICGDA \u201920, page 132\u2013136, New York, NY, USA.",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.17661v2",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.2"
        ],
        "methodology_sections": [
            "3.2",
            "3.3",
            "3.4"
        ],
        "main_experiment_and_results_sections": [
            "3.1",
            "4",
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4",
            "3.3",
            "3.4",
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "research_context": {
        "paper_id": "2403.17661v2",
        "paper_title": "Language Models for Text Classification: Is In-Context Learning Enough?",
        "research_background": "### Paper's Motivation and Research Problem:\n\nThe paper is motivated by the need to address challenges in text classification, particularly in domains with class imbalances and data sparsity where traditional supervised approaches requiring large datasets are not suitable. Specifically, the paper seeks to investigate whether recent advancements in autoregressive text generation models with zero- and few-shot capabilities can effectively perform text classification tasks without the need for extensive training data. This study aims to systematically compare these newer models against more established, data-intensive methods like fine-tuning language models to identify their strengths, weaknesses, and generalisation capabilities across different tasks and domains.\n\n### Relevant Prior Work:\n\n- **Traditional Supervised Text Classification**:\n  - Fine-tuning language models such as BERT with an additional classifier head has been a standard approach. Studies by Radford et al. (2018), Dong et al. (2019), Devlin et al. (2018), Yin et al. (2019), Viswanathan et al. (2023), and Mosbach et al. (2023) have established this method, although it requires large amounts of data, making it unsuitable for tasks with class imbalances and data sparsity (Edwards et al. 2022; Giridhara et al. 2019; Zhang and Wu 2015; T\u00fcrker et al. 2019).\n\n- **Emergence of Autoregressive Text Generation Models**:\n  - Alternative approaches using autoregressive models with zero- and few-shot capabilities have emerged (Radford et al. 2019). These models can understand natural language instructions and generalise to various domains and tasks without requiring large training corpora (Schick and Sch\u00fctze 2021a; Radford et al. 2019; Le Scao and Rush 2021; Viswanathan et al. 2023; Plaza-del Arco et al. 2023).\n  - Fine-tuning these models on sets of instructions has further improved their zero-shot performance (Raffel et al. 2020).\n\n- **Advances and Evaluations**:\n  - Promising results of these models on benchmark datasets (Wang et al. 2022b; Liu et al. 2023; Bang et al. 2023) have led to intense research into improving their generalisation capabilities using prompt engineering techniques (Viswanathan et al. 2023; Le Scao and Rush 2021).\n  - There has been an increased focus on evaluating these models in specialised domains such as legal, medical, and financial domains (Sarkar et al. 2021; Chalkidis et al. 2020; Yin et al. 2019; Labrak et al. 2023). However, most studies have been domain- and task-specific, lacking a comprehensive comparison against established approaches for text classification.\n\n### Original Wording and Phrases:\n- \"A standard approach for supervised text classification is fine-tuning language models such as BERT using an additional classifier head.\"\n- \"However, these approaches require large amounts of data to achieve state-of-the-art results... making them unsuitable for classification tasks associated with class imbalances and data sparsity.\"\n- \"Recent advances in Natural Language Processing (NLP) lead to the emerge of an alternative approach based on using autoregressive text generation models... that have zero- and few- shot capabilities and perform unseen tasks through the use of prompting.\"\n- \"The ability of these models to understand natural language instructions let them generalise to different domains and tasks without the need of large training corpora.\"\n- \"Our work is the first attempt to systematically compare how text generation models using zero-shot and one-shot learning compare to more established but data-consuming approaches for classification based on fine-tuning language models.\"\n\nBy focusing on recent innovations in text classification, this paper addresses an important gap in the literature by comparing newer, less data-dependent models to traditional, data-intensive ones, and evaluating their performance comprehensively across multiple domains and tasks.",
        "methodology": "In this study, we compare three primary types of models for text classification: generative language models, masked language models, and linear models. Here, we detail each model category and their specific representatives as used in our analysis.\n\n#### Generative Language Models\n\n**LLaMA Models:**\n- **LLaMA 1** and **LLaMA 2** (Touvron et al., 2023a, 2023b):\n  - These are large auto-regressive generation models, both encompassing 7 billion parameters.\n\n**Flan-T5 Model:**\n- **Flan-T5 (Chung et al., 2022)**:\n  - An instruction-tuned model fine-tuned with the Flan instruction tuning tasks collection, featuring 780 million parameters.\n\n**T5 Model:**\n- **T5 (Raffel et al., 2020)**:\n  - For our experiments, we use the T5 base model, which is also fine-tuned similarly to RoBERTa.\n\n**GPT Family:**\n- **GPT 3.5-Turbo (Brown et al., 2020)**:\n  - OpenAI's GPT 3.5-Turbo is incorporated to conclude our selection of generative language models. Due to budget constraints and its proprietary nature, results are provided for only a sample dataset set.\n\n#### Masked Language Models\n\n**RoBERTa Models:**\n- **RoBERTa (Liu et al., 2019)**:\n  - Pre-trained on the English language, RoBERTa is recognized for achieving state-of-the-art results in various text classification tasks.\n  - Models used:\n    - **RoBERTa base**: 125 million parameters.\n    - **RoBERTa large**: 354 million parameters.\n\n#### Linear Models\n\n**FastText:**\n- **FastText (Joulin et al., 2017)**:\n  - Serving as a representative of linear text classification models, FastText is simple yet effective, providing a strong baseline for numerous text classification tasks. It often yields results comparable to state-of-the-art models like BERT in certain scenarios.\n\nAll models are sourced from Hugging Face's model repository (Wolf et al., 2019) to ensure consistency and reliability in our comparative study.",
        "main_experiment_and_results": "### Main Experiment Setup\n\n1. **Datasets**:\n   - The study utilizes datasets from various domains and classification tasks, encompassing binary, multiclass, and multilabel classification problems.\n   - **Dataset Sources**:\n     - **Twitter**:\n       - SemEval 18: Emoji prediction, irony detection.\n       - SemEval 19: Hate detection, offense detection, sentiment analysis.\n     - **Topic Categorization**:\n       - BBC News, AG News, Reuters, 20 Newsgroups.\n     - **Reviews**:\n       - IMDB Reviews.\n     - **Specialized Domains**:\n       - PCL (patronising language detection), Toxic comments, EU legislation documents, Hallmarks of cancer, Ohsumed (cardiovascular diseases detection), Safeguarding reports (theme detection).\n   - The number of classes varies across datasets, ranging from general to more specialized classifications.\n\n2. **Evaluation Metrics**:\n   - The metrics employed for evaluation have not been explicitly detailed in the provided text. Common metrics for such tasks typically include accuracy, precision, recall, F1-score, and possibly area under the ROC curve (AUC) for binary and multilabel tasks. For multiclass tasks, micro and macro averages of these metrics may be relevant.\n   \n3. **Baselines**:\n   - The text does not specify the baselines used for comparison. Normally, baselines might include traditional machine learning classifiers (e.g., SVMs, Random Forests), earlier neural network models, and simpler versions of language models without in-context learning capabilities.\n\n### Main Experimental Results\n\n- The results section is not provided in the original text, so it is necessary to infer that the outcomes measured the performance of language models in these diverse settings.\n- The study's results would demonstrate whether in-context learning is sufficient across varied datasets and classification types, reflecting the performance metrics mentioned previously.\n- It can be assumed that results would be presented in terms of whether the model achieves state-of-the-art performance on these tasks or how it compares against the baselines and traditional models. \n\nGiven the information, specific quantitative or qualitative results are not available to be detailed."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "Estimate the performance of text generation models for text classification compared to data-consuming models such as RoBERTa and FastText, specifically in zero- and one-shot in-context learning (ICL) settings.",
            "experiment_process": "Text generation models Flan-T5 and LLaMA were tested in zero- and one-shot ICL settings. For zero-shot, information about the task was provided via prompting. In one-shot, a single training instance per label was randomly selected and provided to the models with instructions. The random selection was performed in three iterations and results averaged. Default model settings were used to generate labels for the test sequences, and the outputs were verified by matching them against expected class labels. Three different prompts were used, descriptions in section 3.4. RoBERTa was fine-tuned using a sequence classifier with a learning rate of 2e-5 for 4 epochs, utilizing the Hugging Face transformers implementation. T5 was fine-tuned using conditional generation for 2 epochs with a learning rate of 5e-5. FastText classifier was used with 25 epochs and softmax as the loss function. Results were reported based on standard micro and macro averaged F1 scores.",
            "result_discussion": "Flan-T5 outperformed other models for all prompts in both zero- and one-shot settings in terms of micro- and macro-F1 score, with fewer wrong labels in zero-shot prompting. LLaMA 2 showed improved performance over LLaMA 1 across all prompt types. Prompt sensitivity was low, with minimal differences in F1 scores for different prompts. Models showed performance improvement with one-shot prompting, with Flan-T5 showing a higher rate of improvement. This indicates the strong capability of these models to learn with minimal training data.",
            "ablation_id": "2403.17661v2.No1"
        },
        {
            "research_objective": "Compare the performance of prompting and fine-tuning techniques to identify strengths and weaknesses of different text classification models.",
            "experiment_process": "The study compared prompting methods using Flan-T5 and LLaMA models against fine-tuning approaches using RoBERTa and T5 for binary, multiclass, and multilabel text classification tasks. The performance was measured using micro- and macro-F1 scores and the number of wrong labels. Models were tested in zero- and one-shot settings for prompting and with the entire dataset for fine-tuning. Specific focus was given to analyzing results by binary, multiclass, and multilabel classification types.",
            "result_discussion": "Flan-T5 outperformed LLaMA models in all text classification types for micro- and macro-F1 scores across zero- and one-shot settings. Fine-tuned RoBERTa-large showed dominance in one-shot settings, especially for complex multiclass and multilabel tasks. The performance gap was more pronounced in these complex tasks, indicating that fine-tuned masked language models are more suitable for such problems. Prompting methods showed better performance for binary and multiclass problems in low-resource settings, whereas fine-tuning was more effective for multilabel problems. Overall, fine-tuned models outperformed prompting methods for larger training sets and complex classification tasks.",
            "ablation_id": "2403.17661v2.No2"
        },
        {
            "research_objective": "Analyze trends across datasets and model performance, with a focus on the impact of the number of classification labels and datasets used for pre-training.",
            "experiment_process": "Performance of Flan-T5 and LLaMA models was compared for zero- and one-shot prompting across various datasets. The study also analyzed fine-tuning models RoBERTa and T5, with a particular focus on the number of labels and dataset types. Separate analysis was conducted for models on the 'IMDB reviews' and 'AG News' datasets, which were used in the fine-tuning of the Flan-T5 model. Additionally, zero-shot prompting results for the GPT 3.5-Turbo model were compared for specific datasets.",
            "result_discussion": "Flan-T5 generally outperformed LLaMA across most datasets in zero- and one-shot settings, except for 'irony', 'sentiment', and 'PCL' datasets where LLaMA performed better. Fine-tuning models showed no clear dominance between RoBERTa and T5. T5 performed better for binary classification tasks and certain datasets like 'AG news' and '20 News'. Fine-tuned models performed better for classification tasks with more labels, while prompting approaches' performance decreased as label numbers increased. GPT 3.5-Turbo showed better zero-shot prompting performance than Flan-T5 and LLaMA, but was still outperformed by fine-tuning approaches in most datasets, highlighting the generalization limitations of few-shot learning techniques and text generation models for text classification.",
            "ablation_id": "2403.17661v2.No3"
        }
    ]
}