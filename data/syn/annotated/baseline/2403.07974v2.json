{
    "title": "LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code",
    "abstract": "Large Language Models (LLMs) applied to code-related applications have emerged as a prominent field, attracting significant interest from both academia and industry. However, as new and improved LLMs are developed, existing evaluation benchmarks (e.g., MBPP) are no longer sufficient for assessing their capabilities. In this work, we propose LiveCodeBench, a comprehensive and contamination-free evaluation of LLMs for code, which collects new problems over time from contests across three competition platforms, namely LeetCode, AtCoder, and CodeForces. Notably, our benchmark also focuses on a broader range of code-related capabilities, such as self-repair, code execution, and test output prediction, beyond just code generation. Currently, LiveCodeBench hosts over five hundred coding problems that were published between May 2023 and May 2024. We have evaluated base LLMs and instruction-tuned LLMs on LiveCodeBench. We present empirical findings on contamination, holistic performance comparisons, potential overfitting in existing benchmarks as well as individual model comparisons. We will release all prompts and model completions for further community analysis, along with a general toolkit for adding new scenarios and models.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Code has emerged as an important application area for LLMs, with a proliferation of code-specific models and their applications across various domains and tasks such as program repair, optimization, test generation, documentation generation, tool usage, SQL, and more. In contrast with these rapid advancements, evaluations have remained relatively stagnant, and current benchmarks like MBPP and APPS may paint a skewed or misleading picture. Firstly, while coding is a multi-faceted skill, these benchmarks only focus on natural language-to-code tasks, thus overlooking broader code-related capabilities. Moreover, these benchmarks may be subject to potential contamination or overfitting, as benchmark samples are present in the training datasets.\n\nMotivated by these shortcomings, we introduce LiveCodeBench, a holistic and contamination-free benchmark for evaluating code capabilities. LiveCodeBench is built on the following principles:\n\nLive updates to prevent contamination. LLMs are trained on massive inscrutable corpora, and current benchmarks suffer from the risk of data contamination as they could be included in those training datasets. While previous works have attempted decontamination using both exact and fuzzy matches, it can be a non-trivial task and can be evaded using simple strategies like rephrasing. Here, to prevent the risk of problem contamination, we use live updates, that is, evaluate models on new problems. Particularly, we collect problems from weekly contests on competition platforms and tag them with a release date. Next, for newer models, we only consider problems released after the model\u2019s cutoff date to ensure that the model has not encountered the exact problem in the training dataset. In Figure 1, we find that the performance of the DeepSeek model starkly drops when evaluated on the LeetCode problems released after August. Similarly, GPT-4-O observes a drop in performance on LeetCode problems released since November 2023, its specified cutoff date. This indicates that these models are likely trained on the older LeetCode problems and time-segmented evaluations allow fair comparisons.\n\nHolistic Evaluation. Current code evaluations primarily focus on natural language to code generation. However, programming is a multi-faceted task that requires a variety of capabilities beyond those measured by code generation. In LiveCodeBench, we evaluate code LLMs on three additional scenarios, listed below:\n\n- Self-Repair: Fix an incorrect program from execution information, evaluating the ability to debug code from feedback. The model is given the natural language problem description, the incorrect program, the test case it fails on, and the execution feedback from that failure. The output should be a correct repaired program.\n- Code Execution: \u201cExecute\u201d a program on an input, evaluating code comprehension ability. The model is given a program and an input, and the output should be the result.\n- Test Output Prediction: Solve the natural language task on a specified input, evaluating the ability to generate testing outputs. The model is given the natural language problem description and an input, and the output should be the output for the problem.\n\nFigure 2 (left) depicts performance on the different scenarios considered in LiveCodeBench.\n\nHigh-quality problems and tests. High-quality problems and tests are crucial for reliable evaluation of LLMs. However, prior works have revealed deficiencies in existing benchmarks. In LiveCodeBench, we source the problems from reputable competition websites whose quality is already validated by the platform users. In addition, for every problem, we provide a good number of tests for meaningful and robust evaluations while still finishing quickly.\n\nBalanced problem difficulty. Competition programming is challenging for even the best-performing LLMs, and most of the current SoTA models achieve close to zero performance on a majority of problems. As a result, they can be unsuitable for meaningful comparing today\u2019s LLMs because the variance in performances is low. Furthermore, the averaging of evaluation scores across problems with different difficulty levels artificially minimizes the differences between models. Therefore, we use problem difficulty ratings (sourced from the competition websites) for filtering the harder problems and classifying problem difficulties to ensure balanced problem difficulty distribution and allow granular model comparisons.\n\nWith these principles in mind, we build LiveCodeBench, a continuously updated benchmark that avoids data contamination. Particularly, we have collected problems from contests across three competition platforms \u2013 LeetCode, AtCoder, and CodeForces occurring from May to the present (May) and use them to construct the different LiveCodeBench scenarios.\n\nEmpirical Findings. We have evaluated base models and instruction-tuned models across different LiveCodeBench scenarios. Below, we present the empirical findings from our evaluations, which have not been revealed in prior benchmarks.\n\nContamination. We observe a stark drop in the performance of DeepSeek, GPT-4-O, and Codestral on LeetCode problems released after Aug, Oct, and Jan. These results highlight likely contamination in older problems and time-segmented evaluations prove effective for performing fair comparisons.\n\nHolistic Evaluation. Our evaluations reveal that model performances are correlated across tasks, but the relative differences do"
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Holistic Evaluation",
            "text": "Code capabilities of LLMs are evaluated and compared using natural language to code generation tasks. However, this only captures one dimension of code-related capabilities. Real-world software engineering requires expertise in tasks beyond just generation, such as synthesizing informative test cases, debugging incorrect code, understanding existing code, and writing documentation. These tasks are crucial parts of the software development process and contribute to improving the quality, maintainability, and reliability of the code (Boehm, 2006). This also applies to LLMs, and adopting similar workflows can enable the models to perform better code generation. For example, AlphaCodium (Ridnik et al., 2024) is an intricate LLM pipeline for solving competition coding problems. By combining natural language reasoning, test case generation, code generation, and self-repair, they achieve significant improvements over a naive direct code generation baseline, showcasing the importance of these broader capabilities. Motivated by this, we propose a more holistic evaluation of LLMs in this work using a suite of evaluation setups that capture a broader range of code-related capabilities. Specifically, we evaluate code LLMs in four scenarios, namely code generation, self-repair, code execution, and test output prediction. Our selection criterion was to pick settings that are useful components in code LLM workflows and, in addition, have clear and automated evaluation metrics. Following we describe each of these scenarios in detail.\n\n### Code Generation\nThe code generation scenario follows the standard setup for generating code from natural language. The model is given a problem statement, which includes a natural language description and example tests (input-output pairs), and is tasked with generating a correct solution. The evaluation is performed based on functional correctness, using a set of unseen test cases. We use the Pass@1 metric measured as the fraction of the problems for which the model was able to generate a program passing all tests.\n\n### Self Repair\nThe self-repair scenario is based on previous works that tested the self-repair capabilities of LLMs (Olausson et al., 2023; Shinn et al., 2023; Chen et al., 2023). Here, the model is given a problem statement from which it generates a candidate program (similar to the single-step code generation scenario above). However, in case of a mistake, the model is additionally provided with error feedback (either the exception message or a failing test case in case of incorrect code generation) and is tasked with generating the fixed solution. Similar to the code generation scenario, the evaluation is performed via functional correctness on the final program, i.e. either the single-step correct generation or the attempted repair. We use the Pass@1 metric to measure the combined performance after the repair step.\n\n### Code Execution\nThe code execution scenario involves providing the model with a program snippet consisting of a function along with a test input to the program and tasking it with predicting the output of the program on the input test case. The evaluation is performed via an execution-based correctness metric where the model generation is considered correct if assert f(input) == generated_output passes.\n\n### Test Case Output Prediction\nFinally, we introduce a new task that is designed to study natural language reasoning and test generation. In this task, the model is given the problem statement along with a test case input and is tasked with generating the expected output for that input. This task follows a setup similar to the one used in CodeT (Chen et al., 2022), where tests are generated solely from problem statements, without the need for the function\u2019s implementation. A key difference is that we provide a fixed set of test inputs for each problem in our dataset, and the models are then prompted to only predict the expected output for those specific inputs. This approach allows for a straightforward evaluation of the test generation capabilities by avoiding test input prediction, a hard-to-evaluate task.\n\nFinally, we would like to point out that LiveCodeBench also offers an extensible framework to add new scenarios in the future. Other relevant settings like input generation, program summarization, optimization, etc., can be integrated with our setup."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Benchmark Curation",
            "text": "We curate our problems from three coding competition websites: LeetCode, AtCoder, and CodeForces.\nThese websites periodically host contests containing problems that assess the coding and problem-solving skills of participants.\nThe problems consist of a natural language problem statement along with example input-output examples, and the goal is to write a program that passes a set of hidden tests.\nFurther, thousands of participants participate, solving these problems thus ensuring that the problems are vetted for clarity and correctness."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Data Collection",
            "text": "We have written HTML scrapers for each of the above websites to collect problems and the corresponding metadata.\nTo ensure quality and consistency, we parse mathematical formulas and exclude problems with images.\nWe also exclude problems that are not suitable for grading by input-output examples, such as those that accept multiple correct answers or require the construction of data structures.\nBesides parsing the problem descriptions, we also collect associated ground truth solutions and test cases whenever directly available.\nThus for each problem, we collect tuples of natural language problem statement ,\ntest cases , and ground truth solution .\nFinally, we associate the contest date  to mark the release date of each problem and\nuse the collected attributes to construct problems for our four scenarios (detailed in Section 3.3  ###reference_### ahead).\nScrolling through time.\nAs noted, we associate the contest date  for each problem.\nThe release date allows us the measure the performance of LLMs over different time windows by filtering problems\nbased on whether the problem release date falls within a time window (referred to as \u201cscrolling\u201d through time).\nThis is crucial for evaluating and comparing models trained at different times.\nSpecifically, for a new model and the corresponding cutoff date (normalized to the release date if the\ntraining cutoff date is not published),\nwe can measure the performance of the model on benchmark problems released after the cutoff date.\nWe have developed a UI that allows comparing models on problems released during different time windows (shown in Figure 9  ###reference_###).\nTest collection.\nTests are crucial for assessing the correctness of the generated outputs and are used in all four scenarios.\nWe collect tests available on platform websites whenever possible and use them for the benchmark.\nOtherwise, following Liu et al. (2023b  ###reference_b39###), we use a LLM (here GPT-4-Turbo) to generate tests for the problems.\nA key difference between our test generation approach is that instead of generating inputs directly using the LLM, we construct generators that sample inputs based on the problem specifications using in context learning.\nDetails and examples of such input generators can be found in Section A.2  ###reference_###.\nFinally, we collect a small fraction of failing tests from the platform for the more recent problems allowing more directed adversarial test collection.\nProblem difficulty.\nCompetition programming has remained a challenge for LLMs, with GPT-4 achieving an average CodeForces rating (ELO) of 392, placing it in the bottom 5 percentile  (OpenAI, 2023  ###reference_b52###).\nThis makes it difficult to compare LLMs, as the variation in performance across models is low.\nIn LiveCodeBench, we collect problems of diverse difficulties as labeled in competition platforms, excluding problems that are rated above a certain threshold that are likely too difficult for even the best models111From our early explorations, we find CodeForces problems being considerably more difficult than AtCoder and LeetCode problems and thus focus primarily on the latter platforms..\nFurther, we use these ratings to classify problems as Easy, Medium, and Hard for more granular model comparisons."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Platform Specific Curation",
            "text": "We describe the curation process for each platform.\nLeetCode.\nWe collect problems from all weekly and biweekly contests on LeetCode that have taken place after April\u201923.\nFor each problem, we collect the problems, public tests, and user solutions.\nThe platform also provides a difficulty label for each problem which we use to tag the problems as Easy, Medium, and Hard.\nSince LeetCode provides a starter code for each problem, we also collect it and provide it to the LLM in the STDIN format.\nSince the hidden tests are not directly available, we use our generator-based test input generation approach (Section A.2  ###reference_###) and also collect the auto grader failing tests for some of the recent problems.\nAtCoder.\nWe collect problems from the abc (beginner round) contests on AtCoder that have taken place after April\u201923.\nWe deliberately avoid the more challenging arc and agc contests which are designed for more advanced Olympiad participants.\nThe problems are assigned numeric difficulty ratings, and we exclude abc problems with a rating of more than .\nWe also use these numeric ratings to tag the problems as Easy, Medium, and Hard.\nSpecifically, we use the rating brackets , , and  to perform the classification.\nAtCoder provides public and hidden tests for each problem which we directly use in the benchmark.\nCodeForces.\nWe have collected problems from the Division 3 and Division 4 contests on CodeForces.\nNotably, we find that even with this filter, the problems are harder than the other two platforms.\nCodeForces also provides difficulty ratings for the problems which we use to tag the problems as Easy, Medium, and Hard using the rating brackets , , and  respectively.\nDue to the higher difficulty, we only consider a small fraction of problems from CodeForces and semi-automatically construct test case generators, as they do not provide complete tests on the platform (long tests are truncated).\nTable 1 provides various statistics about the problems that we have collected for LiveCodeBench."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Scenario-specific benchmark construction",
            "text": "Code Generation and Self-Repair.\nWe use the natural language problem statement as the problem statement for these scenarios.\nFor LeetCode, as noted above, an additional starter code is provided for the functional input format.\nFor AtCoder and CodeForces problems, we use the standard input format (similar to  Hendrycks et al. (2021  ###reference_b20###)).\nThe collected or generated tests are then used to evaluate the correctness of the generated programs.\nOur final dataset consists of  problem instances across the three platforms.\nCode Execution.\nWe draw inspiration from the benchmark creation procedure used in  Gu et al. (2024  ###reference_b17###).\nFirst, we collect a large pool of  correct, human-submitted solutions from the LeetCode subset.\nHowever, many of these programs have multiple nested loops, complex numerical computations, and a large number of execution steps.\nTherefore, we apply compile-time and run-time filters to ensure samples are reasonable, and we double-check this with a manual inspection.\nMore details on the filtering criteria and statistics of the dataset can be found in Appendix A.3  ###reference_###.\nOur final dataset consists of  samples from  problems.\nTest Case Output Prediction.\nWe use the natural language problem statement from the LeetCode platform and the example test inputs to construct our test case output prediction dataset.\nSince the example test inputs in the problems are reasonable test cases for humans to reason about and understand the problems, they also serve as ideal test inputs for LLMs to process.\nOur final dataset consists of  problem instances from a total of  LeetCode problems."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiment Setup",
            "text": "We describe the experimental setup in this section.\nFirst, we provide the common setup across the scenarios, followed by the scenario-specific setups in Section 4.1  ###reference_###.\nModels.\nWe evaluate  models across various sizes, ranging from B to B, including base models, instruction models, and both open and closed models.\nOur experiments include models from different classes, such as GPTs (GPT-3.5-turbo, GPT-4, GPT-4-Turbo,GPT-4-O), Claudes (Claude-Ins-1, Claude-2, Claude-3s), Geminis(Gemini-Pro, Gemini-Flash), Mistral among closed-access and LLaMa-3s(L3-Base-{7, 70}B, L3-Ins-{7, 70}B), DeepSeeks (DS-Base-{1.3, 6.7, 33}B, DS-Ins-{1.3, 6.7, 33}B), CodeLLaMas (CL-Ins-{7, 13, 34}B, CL-Base-{7, 13, 34}B), StarCoder2 (SC2-Base-{3,7,15}B), CodeQwen among open.\nAdditionally, we also include fine-tuned models Phind-34B from CL-Base-34B, and MagiCoders (MC-{6.7, 7}B) from CL-Base-7B and DS-Base-6.7B.\nSee Appendix C.1  ###reference_### for a complete list of models and estimated cutoff dates.\nEvaluation Metrics.\nWe use the Pass@1 (Kulal et al., 2019  ###reference_b27###; Chen et al., 2021  ###reference_b11###) metric for our evaluations.\nSpecifically, we generate  candidate answers for each problem either using API or using vLLM (Kwon et al., 2023  ###reference_b28###).\nWe use nucleus sampling with temperature  and top_p  and calculate the fraction of programs or answers that are correct.\nFor the code generation and self-repair scenarios, we use tests to verify the correctness of the programs. For these scenarios, programs must pass all tests to be considered correct.\nFor the code execution scenario, we use an execution-based correctness metric between the generated output and the ground truth output. For the test output prediction scenario, we parse the generated response to extract the answer and use equivalence checks for grading as specified in Section 2  ###reference_###."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Scenario-specific setup",
            "text": "The setup for each scenario is presented below.\nNote that the base models are only used in the code generation scenario since they do not easily follow the format for the other scenarios.\nCode Generation.\nFor the instruction-tuned models, we use a zero-shot prompt and follow the approach of Hendrycks et al. (2021  ###reference_b20###) by adding appropriate instructions to generate solutions in either functional or stdin format.\nFor the base models, we use a constant one-shot example, with a separate example provided for problems that accept stdin input and for problems that accept functional output.\nSection C.2  ###reference_### shows the high-level zero-shot prompt used.\nSelf Repair.\nSimilar to prior work Olausson et al. (2023  ###reference_b51###), we use the programs generated during the code generation scenario\nalong with the corresponding error feedback to build the zero-shot prompt for the self-repair scenario.\nThe type of error feedback includes syntax errors, runtime errors, wrong answers, and time-limit errors, as applicable.\nSection C.3  ###reference_### provides the pseudo-code for computing the error feedback and the corresponding prompt.\nCode Execution.\nWe use few-shot prompts for the code execution scenario, both with and without chain-of-thought prompting (COT).\nParticularly, we use a 2-shot prompt without COT and a 1-shot prompt with COT with manually detailed steps.\nThe prompts are detailed in Section C.4  ###reference_###.\nTest Output Prediction.\nWe use a zero-shot prompt that queries the model to complete assertions, given the problem, function signature, and test input.\nWe provide the prompt in Section C.5  ###reference_###."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Results",
            "text": "We first describe how LiveCodeBench helps detect and avoid benchmark contamination in Section 5.1 ###reference_###.\nNext, we present the findings from our evaluations on LiveCodeBench in Section 5.2 ###reference_###."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "Avoiding Contamination",
            "text": "A distinguishing aspect of our benchmark is the ability to evaluate models on problems released over different time windows. This allows us to measure the model performance on problems released after the cutoff date, thereby giving a performance estimate on unseen problems. Contamination in DeepSeek and GPT-4-O. LiveCodeBench comprises problems released since May. However, DeepSeek models were released in September and might have already been trained on some of the problems in our benchmark. Similarly, OpenAI notes GPT-4-O cutoff date in November. We can measure the performance of the models on the benchmark using problems released after the cutoff date, thereby estimating the performance of the model on previously unseen problems. Figure 1 shows the performance of these models on LiveCodeBench code generation and test output prediction scenario on LeetCode problems released in different months from May to February. We notice a stark drop in the performance of DS-Ins-33B model after August (right before its release date), which suggests that the earlier problems might indeed be contaminated. This trend is consistent across other LiveCodeBench scenarios like repair and code execution, as depicted in Figure 10. Concurrently, Guo et al. (2024) (Section 4.1, last paragraph) also acknowledge the possibility of LeetCode contamination, noting that \u201cmodels achieved higher scores in the LeetCode Contest held in July and August. Similarly, performance of the GPT-4-O model drops on problems released since November (its official cutoff date). Interestingly, we find that this drop in performance primarily occurs for the LeetCode problems only and that the model performance is relatively smooth across the months for problems from other platforms. Figure 11 shows a relatively stable performance for all models on AtCoder problems released over different periods, with the possible exception of May and June.\n\nWe study performance variations in other models released recently. Particularly, GPT-4-Turbo, Gemini-Pro, Mistral-L, and Claude-3s models were released in November, December, February, and March respectively. Note that GPT-4-Turbo (-preview variant) and Claude-3s have cutoff dates April and August respectively. Irrespective of the release or cutoff dates, we do not find any drastic performance variations across the months, as shown in Figure 12, particularly compared to the DeepSeek models. Interestingly, we find that even the DS-Base-33B model also suffers from contamination dropping from Pass@1 in May problems to Pass@1 in September LeetCode problems. This also suggests the likely inclusion of competition problems in the pretraining of the DeepSeek models, thereby affecting all instruction models trained from it. Finally, Codestral achieves Pass@1 on problems released between May\u201923 and January\u201924 and Pass@1 on problems since February\u201924."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "Performance and Model Comparisons",
            "text": "We evaluate instruction-tuned models (and base models used in the code generation scenario) on LiveCodeBench. These models range from closed access to open access with their various fine-tuned variants. To overcome contamination issues in DeepSeek models, we only consider problems released since September for all evaluations below. Figure 4 shows the performance of a subset of models across the four scenarios. We highlight our key findings below.\n\nHolistic Evaluations.\nWe have evaluated the models across the four scenarios currently available in LiveCodeBench. Figure 2 displays the performance of models on all scenarios along the axes of the polar chart. First, we observe that the relative order of models remains mostly consistent across the scenarios. This is also supported by high correlations between Pass@1 metric across the scenarios \u2013 over across all pairs as shown in Figure 13. Interestingly, the correlations are larger for related tasks, for generation and self-repair, and for test output prediction and code execution. This correlation drops to for generation and execution scenarios. However, despite the strong correlation, the relative differences in performance do vary across the scenarios. For example, GPT-4-Turbo further gains performance gap over GPT-4 in the self-repair scenario after already leading in the code generation scenario. Similarly, Claude-3-Opus and Mistral-L perform well in tasks involving COT, particularly in the code execution and test output prediction scenarios. For instance, Claude-3-Opus even outperforms GPT-4-Turbo in the test output prediction scenario. Similarly, Mistral-L outperforms Claude-3-Sonnet in both scenarios after trailing behind in code generation and repair scenarios. These differences highlight the need for holistic evaluations beyond measuring code generation capabilities.\n\nHighlighting the gap between SoTA and open models.\nOne distinct observation from our evaluations is the large gap between SoTA models and open models across all scenarios. Particularly, GPT-4-Turbo, GPT-4, Gemini-Pro-1.5 and Claude-3-Opus lead across the benchmarks with wide performance margins over other models. This distinguishes LiveCodeBench from prior benchmarks where various open models have achieved similar or better performance. For example, DS-Ins-33B is merely point behind GPT-4-Turbo on HumanEval+ but points (%) on LCB code generation scenario. This gap either holds or sometimes even amplifies across other scenarios. For instance, consider test output prediction and code execution (with COT) where GPT-4-Turbo leads the DS-Ins-33B model by and respectively! We qualitatively analyze code samples generated by the leading model, GPT-4-Turbo, and find that it generates more readable code. Specifically, the code consists of more inline natural language comments that reason or plan before producing the code. We verify this quantitatively and find GPT-4-Turbo generated uses more comment tokens compared to GPT-4.\n\nComparing Base Models.\nWe use four families of base models \u2013 L3-Base, DeepSeek, CodeLLaMa, and StarCoder2 and compare them on the code generation scenario. A one-shot prompt is used for all models to avoid any formatting and answer extraction issues. We find L3-Base and DS models are significantly better than both CodeLLaMa and StarCoder2 base models with a DS-Base-6.7B model even outperforming both CL-Base-34B and SC2-Base-15B models. Next, we observe that SC2-Base-15B also outperforms the CL-Base-34B model. Note that some LiveCodeBench specific differences can potentially be attributed to data curation approaches. For instance, StarCoder2 models use competition problems in the pre-training corpus.\n\nRole of Post Training.\nWe find that post-training improves performance on both HumanEval+ and LiveCodeBench for the code generation scenario. Particularly, L3-Ins-70B, DS-Ins-33B and Phind-34B achieve Pass@1 on LCB improving over their base models by points respectively. This highlights the importance of good post-training datasets for building strong LLMs. At the same time, we note that the base models have aligned performances on LCB code generation and HumanEval+ benchmarks and lie within or close to the green shaded region in Figure 5. However, the fine-tuned open models exhibit a larger performance gap, with much better performances on HumanEval+. On the other hand, the closed-access models are still aligned across both benchmarks. This suggests that the fine-tuning data for open models might not be as diverse as that for closed models, leading to a lack of generalization to different kinds of problems.\n\nComparing open-access instruction-tuned models.\nHere, we compare various fine-tuned variants of the L3-Base, DeepSeek and CodeLLaMa base models across different model sizes. We find that fine-tuned L3-"
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": ""
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "Code Generation",
            "text": "Language Models for Code Generation.\nStarting with Codex (Chen et al., 2021), there are over a dozen code LLMs. These include CodeT5 (Wang et al., 2021, 2023), CodeGen (Nijkamp et al., 2022), SantaCoder (Allal et al., 2023), StarCoder (Li et al., 2023b), AlphaCode (Li et al., 2022), InCoder (Fried et al., 2022), and CodeGeeX (Zheng et al., 2023).\nAs of May 2024, L3-Base and DeepSeek (Bi et al., 2024), StarCoder Lozhkov et al. (2024); Li et al. (2023b) and CodeLLaMa (Roziere et al., 2023) are the most popular open models.\nMany downstream models resulted from fine-tuning them on synthetically generated data, such as WizardCoder (Luo et al., 2023), MagiCoders (Wei et al., 2023b), and Phind-34B.\nCode Generation Benchmarks.\nMany benchmarks have been proposed to compare and evaluate these models.\nThese primarily focus on natural language to Python code generation:\nAPPS (Hendrycks et al., 2021),\nCode-Contests (Li et al., 2022),\nMBPP (Austin et al., 2021),\nL2CEval (Ni et al., 2023).\nTheir variants have been proposed to cover more languages, (Wang et al., 2022a; Zheng et al., 2023; Cassano et al., 2022; Athiwaratkun et al., 2022).\nMany benchmarks have focused on code generation in APIs. Benchmarks like DS-1000 (Lai et al., 2023), ARCADE (Yin et al., 2022), NumpyEval (Zhang et al., 2023b), and PandasEval (Jain et al., 2022) focus on data science APIs.\nOther benchmarks measure using broader APIs or general software engineering tasks, such as JuICe (Agashe et al., 2019), APIBench (Patil et al., 2023), RepoBench (Liu et al., 2023c), ODEX (Wang et al., 2022b), SWE-Bench (Jimenez et al., 2023), GoogleCodeRepo (Shrivastava et al., 2023), RepoEval (Zhang et al., 2023a), and Cocomic-Data (Ding et al., 2022).\nA few benchmarks specifically measure competitive programming, such as APPS (Hendrycks et al., 2021), CodeContests (Li et al., 2022), CodeScope (Yan et al., 2023), xCodeEval (Khan et al., 2023), and LeetCode-Hard (Shinn et al., 2023), and TACO (Li et al., 2023c).\nMethods such as AlphaCode (Li et al., 2022), AlphaCode 2 (Gemini Team et al., 2023), ALGO (Zhang et al., 2023d), Parsel (Zelikman et al., 2022), code cleaning (Jain et al., 2023), code explanations (Li et al., 2023a), analogical reasoning (Yasunaga et al., 2023), and AlphaCodium (Ridnik et al., 2024) have been pushing the boundaries of what is possible with LLMs in this domain. The biggest differentiating factor between LiveCodeBench and these benchmarks is that our benchmark is continuously updated, problem curation with balanced difficulty, higher tests and problem quality, and contains more scenarios such as code repair, code execution, and test output prediction capturing more facets for building agentic coding systems."
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "Holistic Tasks",
            "text": "LiveCodeBench considers self-repair, test output prediction, and code execution as additional scenarios. Below we note pertinent related work for these domains.\n\nCode Repair.\n(Chen et al., 2023; Olausson et al., 2023; Madaan et al., 2023b; Peng et al., 2023; Zhang et al., 2023c) have investigated self-repair for existing code LLM benchmarks. Particularly, these methods use error feedback for models to improve inspiring our code repair scenario.\n\nCode Execution.\nCode execution was first studied in Austin et al. (2021); Nye et al. (2021).\n\nTest Generation.\nTest generation using LLMs has been explored in (Yuan et al., 2023; Sch\u00e4fer et al., 2024; Tufano et al., 2022; Watson et al., 2020). Furthermore, Chen et al. (2022) demonstrated that LLMs can assist in generating test case inputs/outputs for competitive programming problems, thereby improving the accuracy of the generated code, thus inspiring our test generation scenario. However, LiveCodeBench\u2019s test generation scenario is unique in that it decouples the test inputs and outputs allowing more proper evaluations.\n\nFinally, some works have additionally studied other tasks and scenarios like type prediction (Mir et al., 2022; Wei et al., 2023a; Malik et al., 2019), code summarization (LeClair et al., 2019; Iyer et al., 2016; Barone and Sennrich, 2017; Hasan et al., 2021; Alon et al., 2018), code security (Liguori et al., 2022; Pearce et al., 2022; Tony et al., 2023), etc."
        },
        {
            "section_id": "6.3",
            "parent_section_id": "6",
            "section_name": "Contamination",
            "text": "Data contamination and test-case leakage have received considerable attention as LLMs might be getting trained on benchmarks. Some researchers have demonstrated contamination by prompting the model to reveal its own contamination. To address these issues, various detection methods have been developed to avoid these cases. For code, some use approaches like edit distance and AST-based semantic similarity to detect contamination."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Limitations",
            "text": "Benchmark Size.\nLiveCodeBench code generation scenario currently hosts over  instances from problems released between May and February.\nTo account for contamination in DeepSeek, we only perform evaluations on problems released after the model cutoff date.\nThis leads to only  problems used in our final evaluations which might add noise due to problem set samples.\nWe currently estimate  performance variations in LiveCodeBench code generation due to this issue (measured by bootstrapping  sized problem sets from the  sized dataset).\nOther scenarios, i.e. self-repair, code execution, and test output prediction comprise , , and  problems would have similar performance variations.\nWe thus recommend exercising proper judgement when comparing models with small performance differences.\nNote that HumanEval has  problems and would also struggle with similar issues.\nThis issue is also exacerbated for newer models, with more recent cutoff dates, as they might only have access to a smaller evaluation set.\nWe propose two solutions addressing this issue as we evolve LiveCodeBench.\nFirst, we will use other competition platforms for problem collection, allowing larger number of recent problems to be added to the benchmark.\nIn addition, we also hope supplement this with an unreleased private test set constructed specifically for model evaluation.\nThese problems will use a similar flavor to current problems and will be used when models are submitted for evaluation to the LiveCodeBench platform.\nThis would reduce the reliance on public accessible problems and provide a more robust evaluation of the models while providing community public access to similar problems, similar to strategies employed by popular platforms like Kaggle.\nFocus on Python.\nLiveCodeBench currently only focuses on Python which might not provide enough signal about model capabilities in other languages.\nHowever, since we collected problem statements and serialized tests, adding new programming languages would be straightforward once appropriate evaluation engines are used.\nRobustness to Prompts.\nRecent works have identified huge performance variances that can be caused due to insufficient prompt.\nHere, we either do not tune prompts across models or make minor adjustments based on the system prompts and delimiter tokens.\nThis can lead to performance variance in our results.\nOur findings and model comparison orders generalize across LiveCodeBench scenarios\nand mostly match the performance trends observed on HumanEval making this a less prominient issue.\nThis issue can be particularly observed open models on the code execution scenario with COT prompting.\nInterestingly, often the open models perform even worse in comparsion to the direct code execution baseline.\nNote that we used same prompts for the closed models all of which show noticable improvement from COT.\nWhile the used prompts might be sub-optimal, this highlights how open-models perform worse against the closed models at performing chain-of-thought.\nProblem Domain.\nProgramming is a vast domain and occurs in various forms such as programming puzzles, competition programming, and real-world software development.\nDifferent domains might have individual requirements, constraints, challenges, and difficulty levels.\nLiveCodeBench currently focuses on competition problems sourced from three platforms.\nThis might not be representative of the \u201cmost general\u201d notion of LLM programming capabilities.\nParticularly, real-world usage of LLMs is drawn upon open-ended and unconstrained problems rasied by users.\nWe therefore recommend using LiveCodeBench as a starting point for evaluating LLMs and\nfurther using domain-specific evaluations to measure and compare LLMs in specific settings as required."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this work, we propose LiveCodeBench, a new benchmark for evaluating LLMs for code. Our benchmark mitigates contamination issues in existing benchmarks by introducing live evaluations and emphasizing scenarios beyond code generation to account for the broader coding abilities of LLMs. LiveCodeBench is an extensible framework that will continue updating with new problems, scenarios, and models. Our evaluations reveal novel findings such as contamination detection and potential overfitting. We hope LiveCodeBench will serve to advance understanding of current code LLMs and also guide future research in this area through our findings."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Dataset",
            "text": ""
        },
        {
            "section_id": "Appendix 2",
            "parent_section_id": null,
            "section_name": "Appendix B UI",
            "text": "###figure_11### ###figure_12###"
        },
        {
            "section_id": "Appendix 3",
            "parent_section_id": null,
            "section_name": "Appendix C Experimental Setup",
            "text": ""
        },
        {
            "section_id": "Appendix 4",
            "parent_section_id": null,
            "section_name": "Appendix D Results",
            "text": ""
        },
        {
            "section_id": "Appendix 5",
            "parent_section_id": null,
            "section_name": "Appendix E Qualitative Examples",
            "text": ""
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S3.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T1.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T1.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S3.T1.2.1.1.1\">Platform</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S3.T1.2.1.1.2\">Total Count</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S3.T1.2.1.1.3\">#Easy</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S3.T1.2.1.1.4\">#Medium</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S3.T1.2.1.1.5\">#Hard</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S3.T1.2.1.1.6\">Average Tests</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T1.2.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T1.2.2.1.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.2.2.1.1.1\" style=\"font-size:90%;\">LCB</span> (May-end)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.2.2.1.2\">511</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.2.2.1.3\">182</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.2.2.1.4\">206</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.2.2.1.5\">123</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.2.2.1.6\">17.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.2.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.2.3.2.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.2.3.2.1.1\" style=\"font-size:90%;\">LCB</span> (Sep-end)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.3.2.2\">349</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.3.2.3\">125</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.3.2.4\">136</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.3.2.5\">88</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.3.2.6\">18.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.2.4.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.2.4.3.1\">\n<span class=\"ltx_ERROR undefined\" id=\"S3.T1.2.4.3.1.1\">\\hdashline</span><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.2.4.3.1.2\" style=\"font-size:90%;\">AtCoder</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.4.3.2\">267</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.4.3.3\">99</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.4.3.4\">91</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.4.3.5\">77</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.4.3.6\">15.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.2.5.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.2.5.4.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.2.5.4.1.1\" style=\"font-size:90%;\">LeetCode</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.5.4.2\">235</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.5.4.3\">79</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.5.4.4\">113</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.5.4.5\">43</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.5.4.6\">19.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.2.6.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.2.6.5.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.2.6.5.1.1\" style=\"font-size:90%;\">CodeForces</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.6.5.2\">9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.6.5.3\">4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.6.5.4\">2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.6.5.5\">3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.6.5.6\">11.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.2.7.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.2.7.6.1\">\n<span class=\"ltx_ERROR undefined\" id=\"S3.T1.2.7.6.1.1\">\\hdashline</span><span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.2.7.6.1.2\" style=\"font-size:90%;\">LCB</span>-Easy</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.7.6.2\">182</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.7.6.3\">182</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.7.6.4\">0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.7.6.5\">0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.7.6.6\">16.1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.2.8.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.2.8.7.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.2.8.7.1.1\" style=\"font-size:90%;\">LCB</span>-Medium</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.8.7.2\">206</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.8.7.3\">0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.8.7.4\">206</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.8.7.5\">0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.2.8.7.6\">17.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.2.9.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S3.T1.2.9.8.1\">\n<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.2.9.8.1.1\" style=\"font-size:90%;\">LCB</span>-Hard</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S3.T1.2.9.8.2\">123</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S3.T1.2.9.8.3\">0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S3.T1.2.9.8.4\">0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S3.T1.2.9.8.5\">123</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S3.T1.2.9.8.6\">18.0</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"S3.T1.9.1.1\" style=\"font-size:90%;\">Table 1</span>: </span><span class=\"ltx_text\" id=\"S3.T1.10.2\" style=\"font-size:90%;\">\nThe statistics of problems collected in <span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.10.2.1\">LiveCodeBench</span> (<span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.10.2.2\">LCB</span>).\nWe present the number of problems, their difficulty distributions and the average number of tests per problem.\nWe present the results on the following subsets of <span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.10.2.3\">LiveCodeBench</span> (used throughout this manuscript) - (a) problems in the May\u201923-May\u201924 and Sep\u201923-May\u201924 time windows, (b) problems sourced from the three platforms, and (c) problems in the <span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.10.2.4\">LCB</span>-Easy, <span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.10.2.5\">LCB</span>-Medium, and <span class=\"ltx_text ltx_font_smallcaps\" id=\"S3.T1.10.2.6\">LCB</span>-Hard subsets.</span></figcaption>\n</figure>",
            "capture": "Table 1: \nThe statistics of problems collected in LiveCodeBench (LCB).\nWe present the number of problems, their difficulty distributions and the average number of tests per problem.\nWe present the results on the following subsets of LiveCodeBench (used throughout this manuscript) - (a) problems in the May\u201923-May\u201924 and Sep\u201923-May\u201924 time windows, (b) problems sourced from the three platforms, and (c) problems in the LCB-Easy, LCB-Medium, and LCB-Hard subsets."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T2\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"A3.T2.2.1.1\" style=\"font-size:90%;\">Table 2</span>: </span><span class=\"ltx_text\" id=\"A3.T2.3.2\" style=\"font-size:90%;\">Language Models Overview</span></figcaption>\n<table class=\"ltx_tabular\" id=\"A3.T2.4\">\n<tr class=\"ltx_tr\" id=\"A3.T2.4.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.1.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.1.1.1.1\" style=\"width:130.1pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T2.4.1.1.1.1.1\">Model ID</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.1.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.1.2.1.1\" style=\"width:95.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T2.4.1.2.1.1.1\">Short Name</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.1.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.1.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.1.3.1.1\" style=\"width:65.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T2.4.1.3.1.1.1\">Approximate Cutoff Date</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.1.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.1.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.1.4.1.1\" style=\"width:121.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T2.4.1.4.1.1.1\">Link</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.2.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.2.1.1.1\" style=\"width:130.1pt;\">deepseek-ai/deepseek-coder-33b-instruct</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.2.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.2.2.1.1\" style=\"width:95.4pt;\">DSCoder-33b-Ins</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.2.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.2.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.2.3.1.1\" style=\"width:65.0pt;\">08/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.2.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.2.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.2.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct\" title=\"\">deepseek-coder-33b-instruct</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.3.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.3.1.1.1\" style=\"width:130.1pt;\">deepseek-ai/deepseek-coder-6.7b-instruct</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.3.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.3.2.1.1\" style=\"width:95.4pt;\">DSCoder-6.7b-Ins</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.3.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.3.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.3.3.1.1\" style=\"width:65.0pt;\">08/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.3.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.3.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.3.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct\" title=\"\">deepseek-coder-6.7b-instruct</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.4.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.4.1.1.1\" style=\"width:130.1pt;\">deepseek-ai/deepseek-coder-1.3b-instruct</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.4.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.4.2.1.1\" style=\"width:95.4pt;\">DSCoder-1.3b-Ins</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.4.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.4.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.4.3.1.1\" style=\"width:65.0pt;\">08/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.4.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.4.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.4.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-instruct\" title=\"\">deepseek-coder-1.3b-instruct</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.5.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.5.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.5.1.1.1\" style=\"width:130.1pt;\">codellama/CodeLlama-70b-Instruct-hf</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.5.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.5.2.1.1\" style=\"width:95.4pt;\">CodeLlama-70b-Ins</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.5.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.5.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.5.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.5.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.5.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.5.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/codellama/CodeLlama-70b-Instruct-hf\" title=\"\">CodeLlama-70b-Instruct-hf</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.6.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.6.1.1.1\" style=\"width:130.1pt;\">openbmb/Eurus-70b-sft</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.6.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.6.2.1.1\" style=\"width:95.4pt;\">Eurus-70B-SFT (n=1)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.6.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.6.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.6.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.6.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.6.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.6.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/openbmb/Eurus-70b-sft\" title=\"\">Eurus-70b-sft</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.7\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.7.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.7.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.7.1.1.1\" style=\"width:130.1pt;\">openbmb/Eurux-8x22b-nca</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.7.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.7.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.7.2.1.1\" style=\"width:95.4pt;\">Eurux-8x22b-NCA (n=1)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.7.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.7.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.7.3.1.1\" style=\"width:65.0pt;\">04/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.7.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.7.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.7.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/openbmb/Eurux-8x22b-nca\" title=\"\">Eurux-8x22b-nca</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.8\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.8.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.8.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.8.1.1.1\" style=\"width:130.1pt;\">codellama/CodeLlama-34b-Instruct-hf</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.8.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.8.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.8.2.1.1\" style=\"width:95.4pt;\">CodeLlama-34b-Ins</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.8.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.8.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.8.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.8.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.8.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.8.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/codellama/CodeLlama-34b-Instruct-hf\" title=\"\">CodeLlama-34b-Instruct-hf</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.9\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.9.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.9.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.9.1.1.1\" style=\"width:130.1pt;\">codellama/CodeLlama-13b-Instruct-hf</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.9.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.9.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.9.2.1.1\" style=\"width:95.4pt;\">CodeLlama-13b-Ins</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.9.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.9.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.9.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.9.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.9.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.9.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/codellama/CodeLlama-13b-Instruct-hf\" title=\"\">CodeLlama-13b-Instruct-hf</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.10\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.10.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.10.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.10.1.1.1\" style=\"width:130.1pt;\">codellama/CodeLlama-7b-Instruct-hf</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.10.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.10.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.10.2.1.1\" style=\"width:95.4pt;\">CodeLlama-7b-Ins</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.10.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.10.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.10.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.10.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.10.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.10.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/codellama/CodeLlama-7b-Instruct-hf\" title=\"\">CodeLlama-7b-Instruct-hf</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.11\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.11.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.11.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.11.1.1.1\" style=\"width:130.1pt;\">meta-llama/Meta-Llama-3-8B-Instruct</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.11.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.11.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.11.2.1.1\" style=\"width:95.4pt;\">LLama3-8b-Ins</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.11.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.11.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.11.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.11.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.11.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.11.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\" title=\"\">Meta-Llama-3-8B-Instruct</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.12\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.12.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.12.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.12.1.1.1\" style=\"width:130.1pt;\">meta-llama/Meta-Llama-3-70B-Instruct</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.12.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.12.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.12.2.1.1\" style=\"width:95.4pt;\">LLama3-70b-Ins</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.12.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.12.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.12.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.12.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.12.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.12.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct\" title=\"\">Meta-Llama-3-70B-Instruct</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.13\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.13.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.13.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.13.1.1.1\" style=\"width:130.1pt;\">Phind/Phind-CodeLlama-34B-v2</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.13.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.13.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.13.2.1.1\" style=\"width:95.4pt;\">Phind-34B-V2</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.13.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.13.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.13.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.13.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.13.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.13.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/Phind/Phind-CodeLlama-34B-v2\" title=\"\">Phind-CodeLlama-34B-v2</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.14\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.14.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.14.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.14.1.1.1\" style=\"width:130.1pt;\">Smaug-2-72B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.14.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.14.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.14.2.1.1\" style=\"width:95.4pt;\">Smaug-2-72B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.14.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.14.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.14.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.14.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.14.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.14.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/abacusai/Smaug-2-72B\" title=\"\">Smaug-2-72B</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.15\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.15.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.15.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.15.1.1.1\" style=\"width:130.1pt;\">Qwen-1.5-72B-Chat</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.15.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.15.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.15.2.1.1\" style=\"width:95.4pt;\">Qwen-1.5-72B-Chat</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.15.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.15.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.15.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.15.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.15.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.15.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/qwen/Qwen1.5-72B-Chat\" title=\"\">Qwen-1.5-72B-Chat</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.16\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.16.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.16.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.16.1.1.1\" style=\"width:130.1pt;\">Qwen/CodeQwen1.5-7B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.16.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.16.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.16.2.1.1\" style=\"width:95.4pt;\">CodeQwen15-7B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.16.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.16.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.16.3.1.1\" style=\"width:65.0pt;\">08/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.16.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.16.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.16.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/Qwen/CodeQwen1.5-7B\" title=\"\">CodeQwen1.5-7B</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.17\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.17.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.17.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.17.1.1.1\" style=\"width:130.1pt;\">Qwen/CodeQwen1.5-7B-Chat</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.17.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.17.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.17.2.1.1\" style=\"width:95.4pt;\">CodeQwen15-7B-Chat</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.17.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.17.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.17.3.1.1\" style=\"width:65.0pt;\">08/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.17.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.17.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.17.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/Qwen/CodeQwen1.5-7B-Chat\" title=\"\">CodeQwen1.5-7B-Chat</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.18\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.18.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.18.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.18.1.1.1\" style=\"width:130.1pt;\">gpt-3.5-turbo-0301</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.18.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.18.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.18.2.1.1\" style=\"width:95.4pt;\">GPT-3.5-Turbo-0301</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.18.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.18.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.18.3.1.1\" style=\"width:65.0pt;\">10/01/2021</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.18.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.18.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.18.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://openai.com/blog/new-models-and-developer-products-announced-at-devday\" title=\"\">gpt-3.5-turbo-0301</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.19\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.19.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.19.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.19.1.1.1\" style=\"width:130.1pt;\">gpt-3.5-turbo-0125</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.19.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.19.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.19.2.1.1\" style=\"width:95.4pt;\">GPT-3.5-Turbo-0125</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.19.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.19.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.19.3.1.1\" style=\"width:65.0pt;\">10/01/2021</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.19.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.19.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.19.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://openai.com/blog/new-embedding-models-and-api-updates#:~:text=Other%20new%20models%20and%20lower%20pricing\" title=\"\">gpt-3.5-turbo-0125</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.20\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.20.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.20.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.20.1.1.1\" style=\"width:130.1pt;\">gpt-4-0613</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.20.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.20.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.20.2.1.1\" style=\"width:95.4pt;\">GPT-4-0613</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.20.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.20.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.20.3.1.1\" style=\"width:65.0pt;\">10/01/2021</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.20.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.20.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.20.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://openai.com/blog/new-models-and-developer-products-announced-at-devday\" title=\"\">gpt-4-0613</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.21\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.21.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.21.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.21.1.1.1\" style=\"width:130.1pt;\">gpt-4-1106-preview</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.21.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.21.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.21.2.1.1\" style=\"width:95.4pt;\">GPT-4-Turbo-1106</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.21.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.21.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.21.3.1.1\" style=\"width:65.0pt;\">04/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.21.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.21.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.21.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://openai.com/blog/new-models-and-developer-products-announced-at-devday\" title=\"\">gpt-4-1106-preview</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.22\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.22.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.22.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.22.1.1.1\" style=\"width:130.1pt;\">gpt-4-turbo-2024-04-09</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.22.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.22.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.22.2.1.1\" style=\"width:95.4pt;\">GPT-4-Turbo-2024-04-09</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.22.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.22.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.22.3.1.1\" style=\"width:65.0pt;\">04/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.22.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.22.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.22.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://openai.com/blog/new-models-and-developer-products-announced-at-devday\" title=\"\">gpt-4-turbo-2024-04-09</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.23\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.23.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.23.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.23.1.1.1\" style=\"width:130.1pt;\">gpt-4o-2024-05-13</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.23.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.23.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.23.2.1.1\" style=\"width:95.4pt;\">GPT-4O-2024-05-13</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.23.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.23.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.23.3.1.1\" style=\"width:65.0pt;\">10/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.23.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.23.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.23.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://openai.com/index/spring-update\" title=\"\">gpt-4o-2024-05-13</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.24\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.24.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.24.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.24.1.1.1\" style=\"width:130.1pt;\">claude-2</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.24.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.24.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.24.2.1.1\" style=\"width:95.4pt;\">Claude-2</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.24.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.24.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.24.3.1.1\" style=\"width:65.0pt;\">12/31/2022</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.24.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.24.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.24.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://www.anthropic.com/index/claude-2\" title=\"\">claude-2</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.25\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.25.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.25.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.25.1.1.1\" style=\"width:130.1pt;\">claude-instant-1</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.25.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.25.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.25.2.1.1\" style=\"width:95.4pt;\">Claude-Instant-1</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.25.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.25.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.25.3.1.1\" style=\"width:65.0pt;\">12/31/2022</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.25.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.25.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.25.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://www.anthropic.com/index/introducing-claude\" title=\"\">claude-instant-1</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.26\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.26.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.26.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.26.1.1.1\" style=\"width:130.1pt;\">claude-3-opus-20240229</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.26.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.26.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.26.2.1.1\" style=\"width:95.4pt;\">Claude-3-Opus</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.26.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.26.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.26.3.1.1\" style=\"width:65.0pt;\">04/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.26.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.26.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.26.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://www.anthropic.com/claude\" title=\"\">claude-3-opus-20240229</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.27\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.27.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.27.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.27.1.1.1\" style=\"width:130.1pt;\">claude-3-sonnet-20240229</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.27.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.27.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.27.2.1.1\" style=\"width:95.4pt;\">Claude-3-Sonnet</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.27.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.27.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.27.3.1.1\" style=\"width:65.0pt;\">04/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.27.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.27.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.27.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://www.anthropic.com/claude\" title=\"\">claude-3-sonnet-20240229</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.28\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.28.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.28.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.28.1.1.1\" style=\"width:130.1pt;\">claude-3-haiku-20240307</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.28.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.28.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.28.2.1.1\" style=\"width:95.4pt;\">Claude-3-Haiku</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.28.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.28.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.28.3.1.1\" style=\"width:65.0pt;\">04/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.28.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.28.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.28.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://www.anthropic.com/claude\" title=\"\">claude-3-haiku-20240307</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.29\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.29.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.29.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.29.1.1.1\" style=\"width:130.1pt;\">codestral-latest</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.29.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.29.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.29.2.1.1\" style=\"width:95.4pt;\">Codestral-Latest</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.29.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.29.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.29.3.1.1\" style=\"width:65.0pt;\">01/31/2024</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.29.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.29.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.29.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://mistral.ai/news/codestral/\" title=\"\">codestral-latest</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.30\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.30.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.30.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.30.1.1.1\" style=\"width:130.1pt;\">gemini-pro</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.30.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.30.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.30.2.1.1\" style=\"width:95.4pt;\">Gemini-Pro</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.30.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.30.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.30.3.1.1\" style=\"width:65.0pt;\">04/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.30.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.30.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.30.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://blog.google/technology/ai/gemini-api-developers-cloud\" title=\"\">gemini-pro</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.31\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.31.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.31.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.31.1.1.1\" style=\"width:130.1pt;\">gemini-1.5-pro-latest</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.31.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.31.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.31.2.1.1\" style=\"width:95.4pt;\">Gemini-Pro-1.5-May</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.31.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.31.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.31.3.1.1\" style=\"width:65.0pt;\">04/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.31.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.31.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.31.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://blog.google/technology/ai/gemini-api-developers-cloud\" title=\"\">gemini-1.5-pro-latest</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.32\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.32.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.32.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.32.1.1.1\" style=\"width:130.1pt;\">gemini-1.5-flash-latest</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.32.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.32.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.32.2.1.1\" style=\"width:95.4pt;\">Gemini-Flash-1.5-May</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.32.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.32.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.32.3.1.1\" style=\"width:65.0pt;\">04/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.32.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.32.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.32.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://blog.google/technology/ai/gemini-api-developers-cloud\" title=\"\">gemini-1.5-flash-latest</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.33\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.33.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.33.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.33.1.1.1\" style=\"width:130.1pt;\">ise-uiuc/Magicoder-S-DS-6.7B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.33.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.33.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.33.2.1.1\" style=\"width:95.4pt;\">MagiCoderS-DS-6.7B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.33.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.33.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.33.3.1.1\" style=\"width:65.0pt;\">08/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.33.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.33.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.33.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/ise-uiuc/Magicoder-S-DS-6.7B\" title=\"\">Magicoder-S-DS-6.7B</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.34\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.34.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.34.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.34.1.1.1\" style=\"width:130.1pt;\">ise-uiuc/Magicoder-S-CL-7B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.34.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.34.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.34.2.1.1\" style=\"width:95.4pt;\">MagiCoderS-CL-7B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.34.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.34.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.34.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.34.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.34.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.34.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/ise-uiuc/Magicoder-S-CL-7B\" title=\"\">Magicoder-S-CL-7B</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.35\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.35.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.35.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.35.1.1.1\" style=\"width:130.1pt;\">bigcode/starcoder2-3b</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.35.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.35.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.35.2.1.1\" style=\"width:95.4pt;\">StarCoder2-3b</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.35.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.35.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.35.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.35.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.35.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.35.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/bigcode/starcoder2-3b\" title=\"\">starcoder2-3b</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.36\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.36.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.36.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.36.1.1.1\" style=\"width:130.1pt;\">bigcode/starcoder2-7b</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.36.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.36.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.36.2.1.1\" style=\"width:95.4pt;\">StarCoder2-7b</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.36.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.36.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.36.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.36.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.36.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.36.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/bigcode/starcoder2-7b\" title=\"\">starcoder2-7b</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.37\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.37.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.37.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.37.1.1.1\" style=\"width:130.1pt;\">bigcode/starcoder2-15b</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.37.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.37.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.37.2.1.1\" style=\"width:95.4pt;\">StarCoder2-15b</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.37.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.37.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.37.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.37.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.37.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.37.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/bigcode/starcoder2-15b\" title=\"\">starcoder2-15b</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.38\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.38.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.38.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.38.1.1.1\" style=\"width:130.1pt;\">codellama/CodeLlama-70b-hf</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.38.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.38.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.38.2.1.1\" style=\"width:95.4pt;\">CodeLlama-70b-Base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.38.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.38.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.38.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.38.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.38.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.38.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/codellama/CodeLlama-70b-hf\" title=\"\">CodeLlama-70b-hf</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.39\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.39.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.39.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.39.1.1.1\" style=\"width:130.1pt;\">codellama/CodeLlama-34b-hf</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.39.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.39.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.39.2.1.1\" style=\"width:95.4pt;\">CodeLlama-34b-Base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.39.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.39.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.39.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.39.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.39.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.39.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/codellama/CodeLlama-34b-hf\" title=\"\">CodeLlama-34b-hf</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.40\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.40.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.40.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.40.1.1.1\" style=\"width:130.1pt;\">codellama/CodeLlama-13b-hf</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.40.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.40.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.40.2.1.1\" style=\"width:95.4pt;\">CodeLlama-13b-Base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.40.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.40.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.40.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.40.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.40.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.40.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/codellama/CodeLlama-13b-hf\" title=\"\">CodeLlama-13b-hf</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.41\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.41.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.41.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.41.1.1.1\" style=\"width:130.1pt;\">codellama/CodeLlama-7b-hf</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.41.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.41.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.41.2.1.1\" style=\"width:95.4pt;\">CodeLlama-7b-Base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.41.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.41.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.41.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.41.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.41.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.41.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/codellama/CodeLlama-7b-hf\" title=\"\">CodeLlama-7b-hf</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.42\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.42.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.42.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.42.1.1.1\" style=\"width:130.1pt;\">deepseek-ai/deepseek-coder-33b-base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.42.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.42.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.42.2.1.1\" style=\"width:95.4pt;\">DSCoder-33b-Base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.42.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.42.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.42.3.1.1\" style=\"width:65.0pt;\">08/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.42.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.42.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.42.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/deepseek-ai/deepseek-coder-33b-base\" title=\"\">deepseek-coder-33b-base</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.43\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.43.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.43.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.43.1.1.1\" style=\"width:130.1pt;\">deepseek-ai/deepseek-coder-6.7b-base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.43.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.43.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.43.2.1.1\" style=\"width:95.4pt;\">DSCoder-6.7b-Base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.43.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.43.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.43.3.1.1\" style=\"width:65.0pt;\">08/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.43.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.43.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.43.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-base\" title=\"\">deepseek-coder-6.7b-base</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.44\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.44.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.44.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.44.1.1.1\" style=\"width:130.1pt;\">deepseek-ai/deepseek-coder-1.3b-base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.44.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.44.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.44.2.1.1\" style=\"width:95.4pt;\">DSCoder-1.3b-Base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.44.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.44.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.44.3.1.1\" style=\"width:65.0pt;\">08/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.44.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.44.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.44.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-base\" title=\"\">deepseek-coder-1.3b-base</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.45\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.45.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.45.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.45.1.1.1\" style=\"width:130.1pt;\">google/codegemma-7b</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.45.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.45.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.45.2.1.1\" style=\"width:95.4pt;\">CodeGemma-7b-Base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.45.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.45.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.45.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.45.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.45.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.45.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/google/codegemma-7b\" title=\"\">codegemma-7b</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.46\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.46.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.46.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.46.1.1.1\" style=\"width:130.1pt;\">google/codegemma-2b</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.46.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.46.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.46.2.1.1\" style=\"width:95.4pt;\">CodeGemma-2b-Base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.46.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.46.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.46.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.46.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.46.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.46.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/google/codegemma-2b\" title=\"\">codegemma-2b</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.47\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.47.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.47.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.47.1.1.1\" style=\"width:130.1pt;\">google/gemma-7b</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.47.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.47.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.47.2.1.1\" style=\"width:95.4pt;\">Gemma-7b-Base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.47.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.47.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.47.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.47.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.47.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.47.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/google/gemma-7b\" title=\"\">gemma-7b</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.48\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.48.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.48.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.48.1.1.1\" style=\"width:130.1pt;\">google/gemma-2b</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.48.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.48.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.48.2.1.1\" style=\"width:95.4pt;\">Gemma-2b-Base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.48.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.48.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.48.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.48.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.48.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.48.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/google/gemma-2b\" title=\"\">gemma-2b</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.49\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.49.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.49.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.49.1.1.1\" style=\"width:130.1pt;\">meta-llama/Meta-Llama-3-70B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.49.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.49.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.49.2.1.1\" style=\"width:95.4pt;\">LLama3-70b-Base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.49.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.49.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.49.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.49.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.49.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.49.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/meta-llama/Meta-Llama-3-70B\" title=\"\">Meta-Llama-3-70B</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.50\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.50.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.50.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.50.1.1.1\" style=\"width:130.1pt;\">meta-llama/Meta-Llama-3-8B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.50.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.50.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.50.2.1.1\" style=\"width:95.4pt;\">LLama3-8b-Base</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.50.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.50.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.50.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.50.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.50.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.50.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/meta-llama/Meta-Llama-3-8B\" title=\"\">Meta-Llama-3-8B</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.51\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.51.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.51.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.51.1.1.1\" style=\"width:130.1pt;\">mistral-large-latest</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.51.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.51.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.51.2.1.1\" style=\"width:95.4pt;\">Mistral-Large</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.51.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.51.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.51.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.51.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.51.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.51.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://mistral.ai/news/mistral-large/\" title=\"\">mistral-large-latest</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.52\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.52.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.52.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.52.1.1.1\" style=\"width:130.1pt;\">open-mixtral-8x22b</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.52.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.52.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.52.2.1.1\" style=\"width:95.4pt;\">Mixtral-8x22B-Ins</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.52.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.52.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.52.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.52.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.52.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.52.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://mistral.ai/news/mixtral-8x22b/\" title=\"\">open-mixtral-8x22b</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.53\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.53.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.53.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.53.1.1.1\" style=\"width:130.1pt;\">open-mixtral-8x7b</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.53.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.53.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.53.2.1.1\" style=\"width:95.4pt;\">Mixtral-8x7B-Ins</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.53.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.53.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.53.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.53.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.53.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.53.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://mistral.ai/news/mixtral-8x7b/\" title=\"\">open-mixtral-8x7b</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.54\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.54.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.54.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.54.1.1.1\" style=\"width:130.1pt;\">m-a-p/OpenCodeInterpreter-DS-33B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.54.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.54.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.54.2.1.1\" style=\"width:95.4pt;\">OC-DS-33B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.54.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.54.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.54.3.1.1\" style=\"width:65.0pt;\">08/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.54.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.54.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.54.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/m-a-p/OpenCodeInterpreter-DS-33B/\" title=\"\">OpenCodeInterpreter-DS-33B</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.55\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.55.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.55.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.55.1.1.1\" style=\"width:130.1pt;\">m-a-p/OpenCodeInterpreter-DS-6.7B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.55.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.55.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.55.2.1.1\" style=\"width:95.4pt;\">OC-DS-6.7B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.55.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.55.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.55.3.1.1\" style=\"width:65.0pt;\">08/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.55.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.55.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.55.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/m-a-p/OpenCodeInterpreter-DS-6.7B/\" title=\"\">OpenCodeInterpreter-DS-6.7B</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.56\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.56.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.56.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.56.1.1.1\" style=\"width:130.1pt;\">m-a-p/OpenCodeInterpreter-DS-1.3B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.56.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.56.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.56.2.1.1\" style=\"width:95.4pt;\">OC-DS-1.3B</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.56.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.56.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.56.3.1.1\" style=\"width:65.0pt;\">08/30/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.56.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.56.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.56.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://huggingface.co/m-a-p/OpenCodeInterpreter-DS-1.3B/\" title=\"\">OpenCodeInterpreter-DS-1.3B</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.57\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.57.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.57.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.57.1.1.1\" style=\"width:130.1pt;\">command-r</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.57.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.57.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.57.2.1.1\" style=\"width:95.4pt;\">Command-R</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.57.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.57.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.57.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.57.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.57.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.57.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://docs.cohere.com/docs/models\" title=\"\">command-r</a></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.4.58\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\" id=\"A3.T2.4.58.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.58.1.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.58.1.1.1\" style=\"width:130.1pt;\">command-r+</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.58.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.58.2.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.58.2.1.1\" style=\"width:95.4pt;\">Command-R+</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.58.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.58.3.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.58.3.1.1\" style=\"width:65.0pt;\">01/01/2023</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" id=\"A3.T2.4.58.4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A3.T2.4.58.4.1\">\n<span class=\"ltx_p\" id=\"A3.T2.4.58.4.1.1\" style=\"width:121.4pt;\"><a class=\"ltx_ref ltx_href\" href=\"https://docs.cohere.com/docs/models\" title=\"\">command-r+</a></span>\n</span>\n</td>\n</tr>\n</table>\n</figure>",
            "capture": "Table 2: Language Models Overview"
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"A4.T3\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A4.T3.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A4.T3.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"A4.T3.2.1.1.1\">Model Name</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"A4.T3.2.1.1.2\">Easy</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"A4.T3.2.1.1.3\">Medium</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"A4.T3.2.1.1.4\">Hard</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"A4.T3.2.1.1.5\">Total</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A4.T3.2.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A4.T3.2.2.1.1\">Claude-2</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A4.T3.2.2.1.2\">61.80</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A4.T3.2.2.1.3\">4.90</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A4.T3.2.2.1.4\">0.20</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A4.T3.2.2.1.5\">22.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.3.2.1\">Claude-3-Haiku</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.3.2.2\">63.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.3.2.3\">4.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.3.2.4\">1.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.3.2.5\">22.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.4.3.1\">Claude-3-Opus</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.4.3.2\">78.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.4.3.3\">16.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.4.3.4\">3.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.4.3.5\">32.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.5.4.1\">Claude-3-Sonnet</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.5.4.2\">67.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.5.4.3\">6.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.5.4.4\">1.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.5.4.5\">25.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.6.5.1\">Claude-Instant-1</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.6.5.2\">60.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.6.5.3\">4.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.6.5.4\">1.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.6.5.5\">22.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.7.6.1\">CodeGemma-2b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.7.6.2\">18.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.7.6.3\">0.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.7.6.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.7.6.5\">6.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.8.7.1\">CodeGemma-7b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.8.7.2\">35.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.8.7.3\">2.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.8.7.4\">0.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.8.7.5\">12.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.9.8.1\">CodeLlama-13b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.9.8.2\">24.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.9.8.3\">0.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.9.8.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.9.8.5\">8.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.10.9.1\">CodeLlama-13b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.10.9.2\">36.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.10.9.3\">2.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.10.9.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.10.9.5\">13.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.11.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.11.10.1\">CodeLlama-34b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.11.10.2\">32.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.11.10.3\">1.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.11.10.4\">0.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.11.10.5\">11.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.12.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.12.11.1\">CodeLlama-34b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.12.11.2\">33.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.12.11.3\">2.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.12.11.4\">1.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.12.11.5\">12.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.13.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.13.12.1\">CodeLlama-70b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.13.12.2\">15.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.13.12.3\">1.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.13.12.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.13.12.5\">5.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.14.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.14.13.1\">CodeLlama-70b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.14.13.2\">7.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.14.13.3\">0.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.14.13.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.14.13.5\">2.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.15.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.15.14.1\">CodeLlama-7b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.15.14.2\">19.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.15.14.3\">0.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.15.14.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.15.14.5\">6.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.16.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.16.15.1\">CodeLlama-7b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.16.15.2\">28.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.16.15.3\">2.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.16.15.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.16.15.5\">10.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.17.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.17.16.1\">CodeQwen15-7B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.17.16.2\">40.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.17.16.3\">4.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.17.16.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.17.16.5\">15.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.18.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.18.17.1\">CodeQwen15-7B-Chat</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.18.17.2\">39.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.18.17.3\">13.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.18.17.4\">0.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.18.17.5\">17.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.19.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.19.18.1\">Codestral-Latest</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.19.18.2\">69.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.19.18.3\">18.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.19.18.4\">0.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.19.18.5\">29.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.20.19\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.20.19.1\">Command-R</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.20.19.2\">39.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.20.19.3\">3.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.20.19.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.20.19.5\">14.20</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.21.20\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.21.20.1\">Command-R+</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.21.20.2\">56.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.21.20.3\">6.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.21.20.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.21.20.5\">21.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.22.21\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.22.21.1\">DSCoder-1.3b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.22.21.2\">17.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.22.21.3\">0.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.22.21.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.22.21.5\">6.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.23.22\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.23.22.1\">DSCoder-1.3b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.23.22.2\">22.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.23.22.3\">1.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.23.22.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.23.22.5\">8.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.24.23\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.24.23.1\">DSCoder-33b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.24.23.2\">39.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.24.23.3\">2.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.24.23.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.24.23.5\">13.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.25.24\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.25.24.1\">DSCoder-33b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.25.24.2\">55.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.25.24.3\">9.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.25.24.4\">0.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.25.24.5\">21.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.26.25\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.26.25.1\">DSCoder-6.7b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.26.25.2\">34.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.26.25.3\">1.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.26.25.4\">0.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.26.25.5\">11.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.27.26\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.27.26.1\">DSCoder-6.7b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.27.26.2\">46.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.27.26.3\">5.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.27.26.4\">0.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.27.26.5\">17.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.28.27\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.28.27.1\">GPT-3.5-Turbo-0125</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.28.27.2\">56.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.28.27.3\">10.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.28.27.4\">0.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.28.27.5\">22.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.29.28\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.29.28.1\">GPT-3.5-Turbo-0301</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.29.28.2\">53.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.29.28.3\">8.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.29.28.4\">0.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.29.28.5\">20.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.30.29\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.30.29.1\">GPT-4-0613</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.30.29.2\">78.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.30.29.3\">21.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.30.29.4\">2.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.30.29.5\">33.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.31.30\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.31.30.1\">GPT-4-Turbo-1106</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.31.30.2\">84.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.31.30.3\">24.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.31.30.4\">0.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.31.30.5\">36.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.32.31\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.32.31.1\">GPT-4-Turbo-2024-04-09</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.32.31.2\">85.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.32.31.3\">33.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.32.31.4\">5.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.32.31.5\">41.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.33.32\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.33.32.1\">GPT-4O-2024-05-13</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.33.32.2\">88.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.33.32.3\">33.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.33.32.4\">4.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.33.32.5\">41.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.34.33\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.34.33.1\">Gemini-Flash-1.5-May</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.34.33.2\">68.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.34.33.3\">12.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.34.33.4\">2.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.34.33.5\">27.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.35.34\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.35.34.1\">Gemini-Pro-1.5-May</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.35.34.2\">76.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.35.34.3\">19.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.35.34.4\">3.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.35.34.5\">33.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.36.35\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.36.35.1\">Gemma-7b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.36.35.2\">27.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.36.35.3\">0.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.36.35.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.36.35.5\">9.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.37.36\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.37.36.1\">LLama3-70b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.37.36.2\">52.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.37.36.3\">3.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.37.36.4\">0.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.37.36.5\">18.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.38.37\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.38.37.1\">LLama3-70b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.38.37.2\">60.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.38.37.3\">15.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.38.37.4\">1.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.38.37.5\">26.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.39.38\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.39.38.1\">LLama3-8b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.39.38.2\">32.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.39.38.3\">1.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.39.38.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.39.38.5\">11.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.40.39\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.40.39.1\">LLama3-8b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.40.39.2\">38.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.40.39.3\">3.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.40.39.4\">0.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.40.39.5\">14.20</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.41.40\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.41.40.1\">MagiCoderS-DS-6.7B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.41.40.2\">49.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.41.40.3\">7.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.41.40.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.41.40.5\">18.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.42.41\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.42.41.1\">Mistral-Large</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.42.41.2\">60.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.42.41.3\">10.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.42.41.4\">0.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.42.41.5\">24.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.43.42\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.43.42.1\">Mixtral-8x22B-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.43.42.2\">59.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.43.42.3\">12.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.43.42.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.43.42.5\">24.20</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.44.43\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.44.43.1\">Mixtral-8x7B-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.44.43.2\">31.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.44.43.3\">2.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.44.43.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.44.43.5\">11.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.45.44\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.45.44.1\">OC-DS-1.3B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.45.44.2\">11.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.45.44.3\">0.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.45.44.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.45.44.5\">3.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.46.45\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.46.45.1\">OC-DS-33B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.46.45.2\">53.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.46.45.3\">5.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.46.45.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.46.45.5\">19.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.47.46\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.47.46.1\">OC-DS-6.7B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.47.46.2\">46.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.47.46.3\">4.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.47.46.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.47.46.5\">16.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.48.47\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.48.47.1\">Phind-34B-V2</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.48.47.2\">53.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.48.47.3\">4.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.48.47.4\">0.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.48.47.5\">19.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.49.48\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.49.48.1\">StarCoder2-15b</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.49.48.2\">37.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.49.48.3\">2.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.49.48.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.49.48.5\">13.20</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.50.49\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T3.2.50.49.1\">StarCoder2-3b</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.50.49.2\">28.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.50.49.3\">0.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.50.49.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T3.2.50.49.5\">9.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T3.2.51.50\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\" id=\"A4.T3.2.51.50.1\">StarCoder2-7b</th>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"A4.T3.2.51.50.2\">29.90</td>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"A4.T3.2.51.50.3\">1.20</td>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"A4.T3.2.51.50.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"A4.T3.2.51.50.5\">10.40</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"A4.T3.3.1.1\" style=\"font-size:90%;\">Table 3</span>: </span><span class=\"ltx_text\" id=\"A4.T3.4.2\" style=\"font-size:90%;\">Code Generation Performances</span></figcaption>\n</figure>",
            "capture": "Table 3: Code Generation Performances"
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"A4.T4\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A4.T4.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A4.T4.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"A4.T4.2.1.1.1\">Model Name</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"A4.T4.2.1.1.2\">Easy</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"A4.T4.2.1.1.3\">Medium</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"A4.T4.2.1.1.4\">Hard</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"A4.T4.2.1.1.5\">Total</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A4.T4.2.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A4.T4.2.2.1.1\">Claude-2</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A4.T4.2.2.1.2\">66.20</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A4.T4.2.2.1.3\">10.30</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A4.T4.2.2.1.4\">0.40</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A4.T4.2.2.1.5\">25.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.3.2.1\">Claude-3-Haiku</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.3.2.2\">66.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.3.2.3\">8.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.3.2.4\">2.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.3.2.5\">25.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.4.3.1\">Claude-3-Opus</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.4.3.2\">83.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.4.3.3\">23.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.4.3.4\">6.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.4.3.5\">37.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.5.4.1\">Claude-3-Sonnet</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.5.4.2\">72.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.5.4.3\">11.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.5.4.4\">2.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.5.4.5\">28.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.6.5.1\">Claude-Instant-1</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.6.5.2\">64.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.6.5.3\">7.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.6.5.4\">2.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.6.5.5\">24.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.7.6.1\">CodeLlama-13b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.7.6.2\">43.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.7.6.3\">3.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.7.6.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.7.6.5\">15.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.8.7.1\">CodeLlama-34b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.8.7.2\">31.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.8.7.3\">3.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.8.7.4\">1.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.8.7.5\">12.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.9.8.1\">CodeLlama-7b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.9.8.2\">31.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.9.8.3\">3.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.9.8.4\">1.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.9.8.5\">12.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.10.9.1\">Codestral-Latest</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.10.9.2\">72.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.10.9.3\">25.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.10.9.4\">3.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.10.9.5\">33.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.11.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.11.10.1\">DSCoder-1.3b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.11.10.2\">29.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.11.10.3\">2.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.11.10.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.11.10.5\">10.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.12.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.12.11.1\">DSCoder-33b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.12.11.2\">60.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.12.11.3\">8.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.12.11.4\">1.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.12.11.5\">23.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.13.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.13.12.1\">DSCoder-6.7b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.13.12.2\">49.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.13.12.3\">5.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.13.12.4\">1.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.13.12.5\">18.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.14.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.14.13.1\">GPT-3.5-Turbo-0125</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.14.13.2\">59.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.14.13.3\">11.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.14.13.4\">0.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.14.13.5\">23.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.15.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.15.14.1\">GPT-3.5-Turbo-0301</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.15.14.2\">58.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.15.14.3\">11.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.15.14.4\">0.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.15.14.5\">23.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.16.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.16.15.1\">GPT-4-0613</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.16.15.2\">79.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.16.15.3\">25.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.16.15.4\">2.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.16.15.5\">35.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.17.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.17.16.1\">GPT-4-Turbo-1106</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.17.16.2\">86.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.17.16.3\">36.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.17.16.4\">4.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.17.16.5\">42.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.18.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.18.17.1\">GPT-4-Turbo-2024-04-09</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.18.17.2\">88.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.18.17.3\">39.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.18.17.4\">8.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.18.17.5\">45.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.19.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.19.18.1\">GPT-4O-2024-05-13</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.19.18.2\">92.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.19.18.3\">46.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.19.18.4\">8.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.19.18.5\">49.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.20.19\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.20.19.1\">Gemini-Flash-1.5-May</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.20.19.2\">73.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.20.19.3\">16.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.20.19.4\">4.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.20.19.5\">31.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.21.20\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.21.20.1\">Gemini-Pro</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.21.20.2\">53.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.21.20.3\">9.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.21.20.4\">0.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.21.20.5\">21.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.22.21\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.22.21.1\">Gemini-Pro-1.5-April (n=1)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.22.21.2\">71.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.22.21.3\">19.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.22.21.4\">5.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.22.21.5\">32.20</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.23.22\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.23.22.1\">Gemini-Pro-1.5-May</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.23.22.2\">84.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.23.22.3\">30.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.23.22.4\">7.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.23.22.5\">40.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.24.23\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.24.23.1\">LLama3-70b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.24.23.2\">69.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.24.23.3\">19.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.24.23.4\">1.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.24.23.5\">30.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.25.24\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.25.24.1\">LLama3-8b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.25.24.2\">47.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.25.24.3\">6.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.25.24.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.25.24.5\">17.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.26.25\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.26.25.1\">MagiCoderS-CL-7B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.26.25.2\">36.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.26.25.3\">3.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.26.25.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.26.25.5\">13.20</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.27.26\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.27.26.1\">MagiCoderS-DS-6.7B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.27.26.2\">50.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.27.26.3\">8.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.27.26.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.27.26.5\">19.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.28.27\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.28.27.1\">Mistral-Large</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.28.27.2\">71.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.28.27.3\">15.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.28.27.4\">3.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.28.27.5\">30.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.29.28\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.29.28.1\">OC-DS-1.3B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.29.28.2\">20.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.29.28.3\">0.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.29.28.4\">0.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.29.28.5\">6.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.30.29\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.30.29.1\">OC-DS-33B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.30.29.2\">58.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.30.29.3\">7.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.30.29.4\">1.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.30.29.5\">22.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.31.30\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T4.2.31.30.1\">OC-DS-6.7B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.31.30.2\">50.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.31.30.3\">6.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.31.30.4\">0.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T4.2.31.30.5\">19.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T4.2.32.31\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\" id=\"A4.T4.2.32.31.1\">Phind-34B-V2</th>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"A4.T4.2.32.31.2\">62.00</td>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"A4.T4.2.32.31.3\">6.50</td>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"A4.T4.2.32.31.4\">0.90</td>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"A4.T4.2.32.31.5\">23.10</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"A4.T4.3.1.1\" style=\"font-size:90%;\">Table 4</span>: </span><span class=\"ltx_text\" id=\"A4.T4.4.2\" style=\"font-size:90%;\">Self Repair Performances</span></figcaption>\n</figure>",
            "capture": "Table 4: Self Repair Performances"
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"A4.T5\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A4.T5.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A4.T5.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"A4.T5.2.1.1.1\">Model Name</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"A4.T5.2.1.1.2\">Pass@1</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A4.T5.2.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A4.T5.2.2.1.1\">Claude-2</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A4.T5.2.2.1.2\">32.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.3.2.1\">Claude-3-Haiku</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.3.2.2\">32.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.4.3.1\">Claude-3-Opus</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.4.3.2\">58.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.5.4.1\">Claude-3-Sonnet</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.5.4.2\">34.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.6.5.1\">Claude-Instant-1</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.6.5.2\">25.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.7.6.1\">CodeLlama-13b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.7.6.2\">24.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.8.7.1\">CodeLlama-34b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.8.7.2\">23.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.9.8.1\">CodeLlama-70b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.9.8.2\">16.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.10.9.1\">CodeLlama-7b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.10.9.2\">15.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.11.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.11.10.1\">Codestral-Latest</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.11.10.2\">41.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.12.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.12.11.1\">DSCoder-1.3b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.12.11.2\">12.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.13.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.13.12.1\">DSCoder-33b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.13.12.2\">28.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.14.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.14.13.1\">DSCoder-6.7b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.14.13.2\">26.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.15.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.15.14.1\">GPT-3.5-Turbo-0125</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.15.14.2\">35.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.16.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.16.15.1\">GPT-3.5-Turbo-0301</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.16.15.2\">32.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.17.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.17.16.1\">GPT-4-0613</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.17.16.2\">52.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.18.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.18.17.1\">GPT-4-Turbo-1106</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.18.17.2\">55.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.19.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.19.18.1\">GPT-4-Turbo-2024-04-09</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.19.18.2\">66.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.20.19\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.20.19.1\">GPT-4O-2024-05-13</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.20.19.2\">68.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.21.20\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.21.20.1\">Gemini-Flash-1.5-May</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.21.20.2\">38.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.22.21\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.22.21.1\">Gemini-Pro</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.22.21.2\">29.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.23.22\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.23.22.1\">Gemini-Pro-1.5-April (n=1)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.23.22.2\">49.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.24.23\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.24.23.1\">Gemini-Pro-1.5-May</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.24.23.2\">44.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.25.24\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.25.24.1\">LLama3-70b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.25.24.2\">41.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.26.25\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.26.25.1\">LLama3-8b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.26.25.2\">24.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.27.26\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.27.26.1\">MagiCoderS-CL-7B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.27.26.2\">21.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.28.27\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.28.27.1\">MagiCoderS-DS-6.7B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.28.27.2\">27.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.29.28\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.29.28.1\">Mistral-Large</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.29.28.2\">46.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.30.29\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.30.29.1\">Mixtral-8x22B-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.30.29.2\">44.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.31.30\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.31.30.1\">Mixtral-8x7B-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.31.30.2\">31.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.32.31\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.32.31.1\">OC-DS-1.3B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.32.31.2\">7.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.33.32\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.33.32.1\">OC-DS-33B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.33.32.2\">11.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.34.33\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T5.2.34.33.1\">OC-DS-6.7B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T5.2.34.33.2\">18.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T5.2.35.34\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\" id=\"A4.T5.2.35.34.1\">Phind-34B-V2</th>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"A4.T5.2.35.34.2\">27.20</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"A4.T5.3.1.1\" style=\"font-size:90%;\">Table 5</span>: </span><span class=\"ltx_text\" id=\"A4.T5.4.2\" style=\"font-size:90%;\">Test Output Prediction Performances</span></figcaption>\n</figure>",
            "capture": "Table 5: Test Output Prediction Performances"
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"A4.T6\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A4.T6.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A4.T6.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"A4.T6.2.1.1.1\">Model Name</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"A4.T6.2.1.1.2\">Pass@1</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"A4.T6.2.1.1.3\">Pass@1 (COT)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A4.T6.2.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A4.T6.2.2.1.1\">Claude-2</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A4.T6.2.2.1.2\">31.50</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"A4.T6.2.2.1.3\">43.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.3.2.1\">Claude-3-Haiku</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.3.2.2\">0.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.3.2.3\">28.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.4.3.1\">Claude-3-Opus</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.4.3.2\">36.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.4.3.3\">80.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.5.4.1\">Claude-3-Sonnet</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.5.4.2\">29.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.5.4.3\">39.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.6.5.1\">Claude-Instant-1</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.6.5.2\">20.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.6.5.3\">34.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.7.6.1\">Cllama-13b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.7.6.2\">23.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.7.6.3\">14.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.8.7.1\">Cllama-34b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.8.7.2\">28.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.8.7.3\">24.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.9.8.1\">Cllama-7b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.9.8.2\">20.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.9.8.3\">14.20</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.10.9.1\">CodeLlama-70b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.10.9.2\">31.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.10.9.3\">-1.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.11.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.11.10.1\">Codestral-Latest</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.11.10.2\">37.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.11.10.3\">41.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.12.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.12.11.1\">DSCoder-1.3b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.12.11.2\">19.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.12.11.3\">13.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.13.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.13.12.1\">DSCoder-1.3b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.13.12.2\">18.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.13.12.3\">17.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.14.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.14.13.1\">DSCoder-33b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.14.13.2\">29.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.14.13.3\">29.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.15.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.15.14.1\">DSCoder-33b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.15.14.2\">26.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.15.14.3\">31.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.16.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.16.15.1\">DSCoder-6.7b-Base</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.16.15.2\">23.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.16.15.3\">25.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.17.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.17.16.1\">DSCoder-6.7b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.17.16.2\">23.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.17.16.3\">23.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.18.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.18.17.1\">GPT-3.5-Turbo-0301</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.18.17.2\">33.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.18.17.3\">34.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.19.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.19.18.1\">GPT-4-0613</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.19.18.2\">44.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.19.18.3\">64.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.20.19\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.20.19.1\">GPT-4-Turbo-1106</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.20.19.2\">40.50</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.20.19.3\">83.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.21.20\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.21.20.1\">GPT-4-Turbo-2024-04-09</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.21.20.2\">45.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.21.20.3\">83.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.22.21\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.22.21.1\">GPT-4O-2024-05-13</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.22.21.2\">39.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.22.21.3\">91.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.23.22\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.23.22.1\">Gemini-Flash-1.5-May</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.23.22.2\">21.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.23.22.3\">57.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.24.23\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.24.23.1\">Gemini-Pro</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.24.23.2\">27.70</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.24.23.3\">37.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.25.24\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.25.24.1\">Gemini-Pro-1.5 (April) (n=1)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.25.24.2\">30.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.25.24.3\">64.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.26.25\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.26.25.1\">Gemini-Pro-1.5-May</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.26.25.2\">42.10</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.26.25.3\">72.10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.27.26\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.27.26.1\">LLama3-70b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.27.26.2\">29.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.27.26.3\">55.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.28.27\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.28.27.1\">LLama3-8b-Ins</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.28.27.2\">18.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.28.27.3\">29.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.29.28\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.29.28.1\">MagiCoderS-CL-7B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.29.28.2\">21.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.29.28.3\">-1.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.30.29\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.30.29.1\">MagiCoderS-DS-6.7B</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.30.29.2\">27.20</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.30.29.3\">-1.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.31.30\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.31.30.1\">Mistral-Large</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.31.30.2\">36.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.31.30.3\">54.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.32.31\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.32.31.1\">Phind-34B-V2</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.32.31.2\">26.90</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.32.31.3\">-1.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.33.32\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A4.T6.2.33.32.1\">StarCoder</th>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.33.32.2\">20.30</td>\n<td class=\"ltx_td ltx_align_right\" id=\"A4.T6.2.33.32.3\">-1.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A4.T6.2.34.33\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\" id=\"A4.T6.2.34.33.1\">WCoder-34B-V1</th>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"A4.T6.2.34.33.2\">28.40</td>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"A4.T6.2.34.33.3\">-1.00</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" id=\"A4.T6.3.1.1\" style=\"font-size:90%;\">Table 6</span>: </span><span class=\"ltx_text\" id=\"A4.T6.4.2\" style=\"font-size:90%;\">Code Execution Performances</span></figcaption>\n</figure>",
            "capture": "Table 6: Code Execution Performances"
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.07974v2_figure_1.png",
            "caption": "Figure 1: \nLiveCodeBench comprises problems marked with release dates, allowing evaluations over different time windows.\nFor newer models, we can detect and avoid contamination by only evaluating on time-windows after the model\u2019s cutoff date.\nThe figures demonstrate the performance of models on code generation and test output prediction LiveCodeBench scenarios with LeetCode problems released across the months between May 2023202320232023 and February 2024202420242024.\nNotice that DeepSeek-Instruct and GPT-4-O perform considerably worse on problems released since September and November 2023202320232023 (their release and cutoff dates respectively!) \u2013 indicating potential contamination for the earlier problems.\nThus, while performing evaluations, we use the post-September/post-November time window (green) for fairly comparing these models."
        },
        "2": {
            "figure_path": "2403.07974v2_figure_2.png",
            "caption": "Figure 1: \nLiveCodeBench comprises problems marked with release dates, allowing evaluations over different time windows.\nFor newer models, we can detect and avoid contamination by only evaluating on time-windows after the model\u2019s cutoff date.\nThe figures demonstrate the performance of models on code generation and test output prediction LiveCodeBench scenarios with LeetCode problems released across the months between May 2023202320232023 and February 2024202420242024.\nNotice that DeepSeek-Instruct and GPT-4-O perform considerably worse on problems released since September and November 2023202320232023 (their release and cutoff dates respectively!) \u2013 indicating potential contamination for the earlier problems.\nThus, while performing evaluations, we use the post-September/post-November time window (green) for fairly comparing these models."
        },
        "3": {
            "figure_path": "2403.07974v2_figure_3.png",
            "caption": "Figure 2: \nLeft.\nWe propose evaluating LLMs across\nscenarios capturing various coding-related capabilities.\nSpecifically, we host four different scenarios, namely code generation,\nself-repair, code execution, and test output prediction.\nThe figure depicts various model performances across the four scenarios available in LiveCodeBench in a radial plot \u2013\nhighlighting how relative differences across models change across the scenarios.\nRight.\nComparison of open access and (closed) API access models on LiveCodeBench-Easy\ncode generation scenario. We find that closed-access models consistently\noutperform the open models with only strong instruction-tuned variants of >30absent30>30> 30B\nmodels (specifically L3-Ins-70B, Mixtral and DS-Ins-33B models) crossing the performance gap."
        },
        "4": {
            "figure_path": "2403.07974v2_figure_4.png",
            "caption": "Figure 2: \nLeft.\nWe propose evaluating LLMs across\nscenarios capturing various coding-related capabilities.\nSpecifically, we host four different scenarios, namely code generation,\nself-repair, code execution, and test output prediction.\nThe figure depicts various model performances across the four scenarios available in LiveCodeBench in a radial plot \u2013\nhighlighting how relative differences across models change across the scenarios.\nRight.\nComparison of open access and (closed) API access models on LiveCodeBench-Easy\ncode generation scenario. We find that closed-access models consistently\noutperform the open models with only strong instruction-tuned variants of >30absent30>30> 30B\nmodels (specifically L3-Ins-70B, Mixtral and DS-Ins-33B models) crossing the performance gap."
        },
        "5": {
            "figure_path": "2403.07974v2_figure_5.png",
            "caption": "Figure 3: \nOverview of the different scenarios present in LiveCodeBench.\nCoding is multi-faceted and we propose evaluating LLMs on a suite of evaluation setups that capture various coding-related capabilities.\nSpecifically, beyond the standard code generation setting, we consider three additional scenarios, namely self-repair, code execution, and a newly introduced test output prediction task."
        },
        "6": {
            "figure_path": "2403.07974v2_figure_6.png",
            "caption": "((a))"
        },
        "7": {
            "figure_path": "2403.07974v2_figure_7.png",
            "caption": "((b))"
        },
        "8": {
            "figure_path": "2403.07974v2_figure_8.png",
            "caption": "((c))"
        },
        "9": {
            "figure_path": "2403.07974v2_figure_9.png",
            "caption": "((d))"
        },
        "10": {
            "figure_path": "2403.07974v2_figure_10.png",
            "caption": "Figure 5: \nScatter plot comparing Pass@1 of models on HumanEval+ versus Pass@1 on the easy subset of LiveCodeBench code generation scenario.\nStar markers denote the closed-access models while other markers denote different open model families.\nWe find that the models are separated into two groups \u2013 the green-shaded region where performances on the two datasets are aligned and the red-shaded region where models perform well on HumanEval+ but perform poorly on LiveCodeBench.\nThis indicates potential overfitting on HumanEval+ and primarily occurs in the fine-tuned variants of open-access models.\nFor example, DS-Ins-1.3B which achieves Pass@1 of 60606060 and 26262626 on HumanEval+ and LCB-Easy subset.\nThus, while it ranks above CMD-R+ on HumanEval+, it performs significantly worse on the LCB.\nSimilarly, DS-Ins-6.7B and CodeQwen outperform Claude-3-Sonnet on HumanEval+ but are >20absent20>20> 20 points behind on LCB-Easy."
        },
        "11": {
            "figure_path": "2403.07974v2_figure_11.png",
            "caption": "Figure 8: Distribution of code lengths and number of execution steps"
        },
        "12": {
            "figure_path": "2403.07974v2_figure_12.png",
            "caption": "Figure 8: Distribution of code lengths and number of execution steps"
        },
        "13": {
            "figure_path": "2403.07974v2_figure_13.png",
            "caption": "Figure 9: UI of LiveCodeBench showing two views \u2013 May-Jan and Sep-Jan. The contaminated models are blurred and the performance difference is visible across the two views. The scroller on the top allows selecting different periods of time highlighting the live nature of the benchmark."
        },
        "14": {
            "figure_path": "2403.07974v2_figure_14.png",
            "caption": "Figure 9: UI of LiveCodeBench showing two views \u2013 May-Jan and Sep-Jan. The contaminated models are blurred and the performance difference is visible across the two views. The scroller on the top allows selecting different periods of time highlighting the live nature of the benchmark."
        },
        "15": {
            "figure_path": "2403.07974v2_figure_15.png",
            "caption": "Figure 10: Contamination in DS models across self-repair and code execution (without COT) scenarios over time. Note that code execution currently runs between May and November"
        },
        "16": {
            "figure_path": "2403.07974v2_figure_16.png",
            "caption": "Figure 10: Contamination in DS models across self-repair and code execution (without COT) scenarios over time. Note that code execution currently runs between May and November"
        },
        "17": {
            "figure_path": "2403.07974v2_figure_17.png",
            "caption": "Figure 11: Performance on problems released over different months for AtCoder"
        },
        "18": {
            "figure_path": "2403.07974v2_figure_18.png",
            "caption": "Figure 12: Live evaluation over time for various models on code generation scenario in LiveCodeBench. We consider many recently released models and do not find significant performance variations across months except for DS models."
        },
        "19": {
            "figure_path": "2403.07974v2_figure_19.png",
            "caption": "Figure 12: Live evaluation over time for various models on code generation scenario in LiveCodeBench. We consider many recently released models and do not find significant performance variations across months except for DS models."
        },
        "20": {
            "figure_path": "2403.07974v2_figure_20.png",
            "caption": "Figure 13: Correlations across different scenarios studied in LiveCodeBench"
        }
    },
    "references": [
        {
            "1": {
                "title": "Juice: A large scale distantly supervised dataset for open domain context-based code generation.",
                "author": "Rajas Agashe, Srinivasan Iyer, and Luke Zettlemoyer. 2019.",
                "venue": "arXiv preprint arXiv:1910.02216.",
                "url": null
            }
        },
        {
            "2": {
                "title": "Santacoder: don\u2019t reach for the stars!",
                "author": "Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, et al. 2023.",
                "venue": "arXiv preprint arXiv:2301.03988.",
                "url": null
            }
        },
        {
            "3": {
                "title": "code2seq: Generating sequences from structured representations of code.",
                "author": "Uri Alon, Shaked Brody, Omer Levy, and Eran Yahav. 2018.",
                "venue": "arXiv preprint arXiv:1808.01400.",
                "url": null
            }
        },
        {
            "4": {
                "title": "Multi-lingual evaluation of code generation models.",
                "author": "Ben Athiwaratkun, Sanjay Krishna Gouda, Zijian Wang, Xiaopeng Li, Yuchen Tian, Ming Tan, Wasi Uddin Ahmad, Shiqi Wang, Qing Sun, Mingyue Shang, et al. 2022.",
                "venue": "arXiv preprint arXiv:2210.14868.",
                "url": null
            }
        },
        {
            "5": {
                "title": "Program synthesis with large language models.",
                "author": "Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. 2021.",
                "venue": "arXiv preprint arXiv:2108.07732.",
                "url": null
            }
        },
        {
            "6": {
                "title": "A parallel corpus of python functions and documentation strings for automated code documentation and code generation.",
                "author": "Antonio Valerio Miceli Barone and Rico Sennrich. 2017.",
                "venue": "arXiv preprint arXiv:1707.02275.",
                "url": null
            }
        },
        {
            "7": {
                "title": "Deepseek llm: Scaling open-source language models with longtermism.",
                "author": "Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu, et al. 2024.",
                "venue": "arXiv preprint arXiv:2401.02954.",
                "url": null
            }
        },
        {
            "8": {
                "title": "A view of 20th and 21st century software engineering.",
                "author": "Barry Boehm. 2006.",
                "venue": "In Proceedings of the 28th International Conference on Software Engineering, ICSE \u201906, page 12\u201329, New York, NY, USA. Association for Computing Machinery.",
                "url": "https://doi.org/10.1145/1134285.1134288"
            }
        },
        {
            "9": {
                "title": "Multipl-e: A scalable and extensible approach to benchmarking neural code generation.",
                "author": "Federico Cassano, John Gouwar, Daniel Nguyen, Sydney Nguyen, Luna Phipps-Costin, Donald Pinckney, Ming-Ho Yee, Yangtian Zi, Carolyn Jane Anderson, Molly Q Feldman, et al. 2022.",
                "venue": "arXiv preprint arXiv:2208.08227.",
                "url": null
            }
        },
        {
            "10": {
                "title": "Codet: Code generation with generated tests.",
                "author": "Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu Chen. 2022.",
                "venue": "arXiv preprint arXiv:2207.10397.",
                "url": null
            }
        },
        {
            "11": {
                "title": "Evaluating large language models trained on code.",
                "author": "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021.",
                "venue": "arXiv preprint arXiv:2107.03374.",
                "url": null
            }
        },
        {
            "12": {
                "title": "Teaching large language models to self-debug.",
                "author": "Xinyun Chen, Maxwell Lin, Nathanael Sch\u00e4rli, and Denny Zhou. 2023.",
                "venue": "arXiv preprint arXiv:2304.05128.",
                "url": null
            }
        },
        {
            "13": {
                "title": "Cocomic: Code completion by jointly modeling in-file and cross-file context.",
                "author": "Yangruibo Ding, Zijian Wang, Wasi Uddin Ahmad, Murali Krishna Ramanathan, Ramesh Nallapati, Parminder Bhatia, Dan Roth, and Bing Xiang. 2022.",
                "venue": "arXiv preprint arXiv:2212.10007.",
                "url": null
            }
        },
        {
            "14": {
                "title": "Incoder: A generative model for code infilling and synthesis.",
                "author": "Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong, Wen tau Yih, Luke Zettlemoyer, and Mike Lewis. 2022.",
                "venue": "preprint arXiv:2204.05999.",
                "url": null
            }
        },
        {
            "15": {
                "title": "Gemini: a family of highly capable multimodal models.",
                "author": "A Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. 2023.",
                "venue": "arXiv preprint arXiv:2312.11805.",
                "url": null
            }
        },
        {
            "16": {
                "title": "Time travel in llms: Tracing data contamination in large language models.",
                "author": "Shahriar Golchin and Mihai Surdeanu. 2023.",
                "venue": "arXiv preprint arXiv:2308.08493.",
                "url": null
            }
        },
        {
            "17": {
                "title": "Cruxeval: A benchmark for code reasoning, understanding and execution.",
                "author": "Alex Gu, Baptiste Rozi\u00e8re, Hugh Leather, Armando Solar-Lezama, Gabriel Synnaeve, and Sida I Wang. 2024.",
                "venue": "arXiv preprint arXiv:2401.03065.",
                "url": null
            }
        },
        {
            "18": {
                "title": "Deepseek-coder: When the large language model meets programming\u2013the rise of code intelligence.",
                "author": "Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao Zhang, Guanting Chen, Xiao Bi, Y Wu, YK Li, et al. 2024.",
                "venue": "arXiv preprint arXiv:2401.14196.",
                "url": null
            }
        },
        {
            "19": {
                "title": "Codesc: A large code-description parallel dataset.",
                "author": "Masum Hasan, Tanveer Muttaqueen, Abdullah Al Ishtiaq, Kazi Sajeed Mehrab, Md Mahim Anjum Haque, Tahmid Hasan, Wasi Uddin Ahmad, Anindya Iqbal, and Rifat Shahriyar. 2021.",
                "venue": "arXiv preprint arXiv:2105.14220.",
                "url": null
            }
        },
        {
            "20": {
                "title": "Measuring mathematical problem solving with the math dataset.",
                "author": "Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021.",
                "venue": "arXiv preprint arXiv:2103.03874.",
                "url": null
            }
        },
        {
            "21": {
                "title": "Competition-level problems are effective llm evaluators.",
                "author": "Yiming Huang, Zhenghao Lin, Xiao Liu, Yeyun Gong, Shuai Lu, Fangyu Lei, Yaobo Liang, Yelong Shen, Chen Lin, Nan Duan, et al. 2023.",
                "venue": "arXiv preprint arXiv:2312.02143.",
                "url": null
            }
        },
        {
            "22": {
                "title": "Summarizing source code using a neural attention model.",
                "author": "Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. 2016.",
                "venue": "In 54th Annual Meeting of the Association for Computational Linguistics 2016, pages 2073\u20132083. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "23": {
                "title": "Jigsaw: Large language models meet program synthesis.",
                "author": "Naman Jain, Skanda Vaidyanath, Arun Iyer, Nagarajan Natarajan, Suresh Parthasarathy, Sriram Rajamani, and Rahul Sharma. 2022.",
                "venue": "In Proceedings of the 44th International Conference on Software Engineering, pages 1219\u20131231.",
                "url": null
            }
        },
        {
            "24": {
                "title": "Llm-assisted code cleaning for training accurate code generators.",
                "author": "Naman Jain, Tianjun Zhang, Wei-Lin Chiang, Joseph E Gonzalez, Koushik Sen, and Ion Stoica. 2023.",
                "venue": "arXiv preprint arXiv:2311.14904.",
                "url": null
            }
        },
        {
            "25": {
                "title": "Swe-bench: Can language models resolve real-world github issues?",
                "author": "Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik Narasimhan. 2023.",
                "venue": "arXiv preprint arXiv:2310.06770.",
                "url": null
            }
        },
        {
            "26": {
                "title": "xcodeeval: A large scale multilingual multitask benchmark for code understanding, generation, translation and retrieval.",
                "author": "Mohammad Abdullah Matin Khan, M Saiful Bari, Xuan Long Do, Weishi Wang, Md Rizwan Parvez, and Shafiq Joty. 2023.",
                "venue": "arXiv preprint arXiv:2303.03004.",
                "url": null
            }
        },
        {
            "27": {
                "title": "Spoc: Search-based pseudocode to code.",
                "author": "Sumith Kulal, Panupong Pasupat, Kartik Chandra, Mina Lee, Oded Padon, Alex Aiken, and Percy S Liang. 2019.",
                "venue": "Advances in Neural Information Processing Systems, 32.",
                "url": null
            }
        },
        {
            "28": {
                "title": "Efficient memory management for large language model serving with pagedattention.",
                "author": "Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. 2023.",
                "venue": "In Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles.",
                "url": null
            }
        },
        {
            "29": {
                "title": "Ds-1000: A natural and reliable benchmark for data science code generation.",
                "author": "Yuhang Lai, Chengxi Li, Yiming Wang, Tianyi Zhang, Ruiqi Zhong, Luke Zettlemoyer, Wen-tau Yih, Daniel Fried, Sida Wang, and Tao Yu. 2023.",
                "venue": "In International Conference on Machine Learning, pages 18319\u201318345. PMLR.",
                "url": null
            }
        },
        {
            "30": {
                "title": "A neural model for generating natural language summaries of program subroutines.",
                "author": "Alexander LeClair, Siyuan Jiang, and Collin McMillan. 2019.",
                "venue": "In 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pages 795\u2013806. IEEE.",
                "url": null
            }
        },
        {
            "31": {
                "title": "Explaining competitive-level programming solutions using llms.",
                "author": "Jierui Li, Szymon Tworkowski, Yingying Wu, and Raymond Mooney. 2023a.",
                "venue": "arXiv preprint arXiv:2307.05337.",
                "url": null
            }
        },
        {
            "32": {
                "title": "Starcoder: may the source be with you!",
                "author": "Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, et al. 2023b.",
                "venue": "arXiv preprint arXiv:2305.06161.",
                "url": null
            }
        },
        {
            "33": {
                "title": "Taco: Topics in algorithmic code generation dataset.",
                "author": "Rongao Li, Jie Fu, Bo-Wen Zhang, Tao Huang, Zhihong Sun, Chen Lyu, Guang Liu, Zhi Jin, and Ge Li. 2023c.",
                "venue": "arXiv preprint arXiv:2312.14852.",
                "url": null
            }
        },
        {
            "34": {
                "title": "Textbooks are all you need ii: phi-1.5 technical report.",
                "author": "Yuanzhi Li, S\u00e9bastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya Gunasekar, and Yin Tat Lee. 2023d.",
                "venue": "arXiv preprint arXiv:2309.05463.",
                "url": null
            }
        },
        {
            "35": {
                "title": "Competition-level code generation with alphacode.",
                "author": "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R\u00e9mi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. 2022.",
                "venue": "Science, 378(6624):1092\u20131097.",
                "url": null
            }
        },
        {
            "36": {
                "title": "Can we generate shellcodes via natural language? an empirical study.",
                "author": "Pietro Liguori, Erfan Al-Hossami, Domenico Cotroneo, Roberto Natella, Bojan Cukic, and Samira Shaikh. 2022.",
                "venue": "Automated Software Engineering, 29(1):30.",
                "url": null
            }
        },
        {
            "37": {
                "title": "Codemind: A framework to challenge large language models for code reasoning.",
                "author": "Changshu Liu, Shizhuo Dylan Zhang, and Reyhaneh Jabbarvand. 2024.",
                "venue": "arXiv preprint arXiv:2402.09664.",
                "url": null
            }
        },
        {
            "38": {
                "title": "Evaluating the logical reasoning ability of chatgpt and gpt-4.",
                "author": "Hanmeng Liu, Ruoxi Ning, Zhiyang Teng, Jian Liu, Qiji Zhou, and Yue Zhang. 2023a.",
                "venue": "arXiv preprint arXiv:2304.03439.",
                "url": null
            }
        },
        {
            "39": {
                "title": "Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation.",
                "author": "Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. 2023b.",
                "venue": "arXiv preprint arXiv:2305.01210.",
                "url": null
            }
        },
        {
            "40": {
                "title": "Repobench: Benchmarking repository-level code auto-completion systems.",
                "author": "Tianyang Liu, Canwen Xu, and Julian McAuley. 2023c.",
                "venue": "arXiv preprint arXiv:2306.03091.",
                "url": null
            }
        },
        {
            "41": {
                "title": "Starcoder 2 and the stack v2: The next generation.",
                "author": "Anton Lozhkov, Raymond Li, Loubna Ben Allal, Federico Cassano, Joel Lamy-Poirier, Nouamane Tazi, Ao Tang, Dmytro Pykhtar, Jiawei Liu, Yuxiang Wei, Tianyang Liu, Max Tian, Denis Kocetkov, Arthur Zucker, Younes Belkada, Zijian Wang, Qian Liu, Dmitry Abulkhanov, Indraneil Paul, Zhuang Li, Wen-Ding Li, Megan Risdal, Jia Li, Jian Zhu, Terry Yue Zhuo, Evgenii Zheltonozhskii, Nii Osae Osae Dade, Wenhao Yu, Lucas Krau\u00df, Naman Jain, Yixuan Su, Xuanli He, Manan Dey, Eduardo Abati, Yekun Chai, Niklas Muennighoff, Xiangru Tang, Muhtasham Oblokulov, Christopher Akiki, Marc Marone, Chenghao Mou, Mayank Mishra, Alex Gu, Binyuan Hui, Tri Dao, Armel Zebaze, Olivier Dehaene, Nicolas Patry, Canwen Xu, Julian McAuley, Torsten Scholak, Sebastien Paquet, Jennifer Robinson, Carolyn Jane Anderson, Nicolas Chapados, Mostofa Patwary, Nima Tajbakhsh, Yacine Jernite, Carlos Mu\u00f1oz Ferrandis, Lingming Zhang, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, and Harm de Vries. 2024.",
                "venue": null,
                "url": null
            }
        },
        {
            "42": {
                "title": "Repoagent: An llm-powered open-source framework for repository-level code documentation generation.",
                "author": "Qinyu Luo, Yining Ye, Shihao Liang, Zhong Zhang, Yujia Qin, Yaxi Lu, Yesai Wu, Xin Cong, Yankai Lin, Yingli Zhang, et al. 2024.",
                "venue": "arXiv preprint arXiv:2402.16667.",
                "url": null
            }
        },
        {
            "43": {
                "title": "Wizardcoder: Empowering code large language models with evol-instruct.",
                "author": "Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang. 2023.",
                "venue": "arXiv preprint arXiv:2306.08568.",
                "url": null
            }
        },
        {
            "44": {
                "title": "Learning performance-improving code edits.",
                "author": "Aman Madaan, Alexander Shypula, Uri Alon, Milad Hashemi, Parthasarathy Ranganathan, Yiming Yang, Graham Neubig, and Amir Yazdanbakhsh. 2023a.",
                "venue": "arXiv preprint arXiv:2302.07867.",
                "url": null
            }
        },
        {
            "45": {
                "title": "Self-refine: Iterative refinement with self-feedback.",
                "author": "Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. 2023b.",
                "venue": "arXiv preprint arXiv:2303.17651.",
                "url": null
            }
        },
        {
            "46": {
                "title": "Nl2type: inferring javascript function types from natural language information.",
                "author": "Rabee Sohail Malik, Jibesh Patra, and Michael Pradel. 2019.",
                "venue": "In 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pages 304\u2013315. IEEE.",
                "url": null
            }
        },
        {
            "47": {
                "title": "Type4py: Practical deep similarity learning-based type inference for python.",
                "author": "Amir M Mir, Evaldas Lato\u0161kinas, Sebastian Proksch, and Georgios Gousios. 2022.",
                "venue": "In Proceedings of the 44th International Conference on Software Engineering, pages 2241\u20132252.",
                "url": null
            }
        },
        {
            "48": {
                "title": "L2ceval: Evaluating language-to-code generation capabilities of large language models.",
                "author": "Ansong Ni, Pengcheng Yin, Yilun Zhao, Martin Riddell, Troy Feng, Rui Shen, Stephen Yin, Ye Liu, Semih Yavuz, Caiming Xiong, et al. 2023.",
                "venue": "arXiv preprint arXiv:2309.17446.",
                "url": null
            }
        },
        {
            "49": {
                "title": "Codegen: An open large language model for code with multi-turn program synthesis.",
                "author": "Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong. 2022.",
                "venue": "In The Eleventh International Conference on Learning Representations.",
                "url": null
            }
        },
        {
            "50": {
                "title": "Show your work: Scratchpads for intermediate computation with language models.",
                "author": "Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021.",
                "venue": "arXiv preprint arXiv:2112.00114.",
                "url": null
            }
        },
        {
            "51": {
                "title": "Demystifying gpt self-repair for code generation.",
                "author": "Theo X Olausson, Jeevana Priya Inala, Chenglong Wang, Jianfeng Gao, and Armando Solar-Lezama. 2023.",
                "venue": "arXiv preprint arXiv:2306.09896.",
                "url": null
            }
        },
        {
            "52": {
                "title": "Gpt-4 technical report. arxiv 2303.08774.",
                "author": "R OpenAI. 2023.",
                "venue": "View in Article.",
                "url": null
            }
        },
        {
            "53": {
                "title": "Proving test set contamination for black-box language models.",
                "author": "Yonatan Oren, Nicole Meister, Niladri Chatterji, Faisal Ladhak, and Tatsunori B Hashimoto. 2024.",
                "venue": "In The Twelfth International Conference on Learning Representations.",
                "url": "https://openreview.net/forum?id=KS8mIvetg2"
            }
        },
        {
            "54": {
                "title": "Gorilla: Large language model connected with massive apis.",
                "author": "Shishir G Patil, Tianjun Zhang, Xin Wang, and Joseph E Gonzalez. 2023.",
                "venue": "arXiv preprint arXiv:2305.15334.",
                "url": null
            }
        },
        {
            "55": {
                "title": "Asleep at the keyboard? assessing the security of github copilot\u2019s code contributions.",
                "author": "Hammond Pearce, Baleegh Ahmad, Benjamin Tan, Brendan Dolan-Gavitt, and Ramesh Karri. 2022.",
                "venue": "In 2022 IEEE Symposium on Security and Privacy (SP), pages 754\u2013768. IEEE.",
                "url": null
            }
        },
        {
            "56": {
                "title": "Check your facts and try again: Improving large language models with external knowledge and automated feedback.",
                "author": "Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, and Jianfeng Gao. 2023.",
                "venue": "arXiv preprint arXiv:2302.12813.",
                "url": null
            }
        },
        {
            "57": {
                "title": "ToolLLM: Facilitating large language models to master 16000+ real-world APIs.",
                "author": "Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, dahai li, Zhiyuan Liu, and Maosong Sun. 2024.",
                "venue": "In The Twelfth International Conference on Learning Representations.",
                "url": "https://openreview.net/forum?id=dHng2O0Jjr"
            }
        },
        {
            "58": {
                "title": "Quantifying contamination in evaluating code generation capabilities of language models.",
                "author": "Martin Riddell, Ansong Ni, and Arman Cohan. 2024.",
                "venue": null,
                "url": "http://arxiv.org/abs/2403.04811"
            }
        },
        {
            "59": {
                "title": "Code generation with alphacodium: From prompt engineering to flow engineering.",
                "author": "Tal Ridnik, Dedy Kredo, and Itamar Friedman. 2024.",
                "venue": "arXiv preprint arXiv:2401.08500.",
                "url": null
            }
        },
        {
            "60": {
                "title": "To the cutoff\u2026 and beyond? a longitudinal perspective on LLM data contamination.",
                "author": "Manley Roberts, Himanshu Thakur, Christine Herlihy, Colin White, and Samuel Dooley. 2024.",
                "venue": "In The Twelfth International Conference on Learning Representations.",
                "url": "https://openreview.net/forum?id=m2NVG4Htxs"
            }
        },
        {
            "61": {
                "title": "Phind.",
                "author": "Michael Royzen, Justin Wei, and Russell Coleman. 2023.",
                "venue": null,
                "url": "https://www.phind.com"
            }
        },
        {
            "62": {
                "title": "Code llama: Open foundation models for code.",
                "author": "Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, J\u00e9r\u00e9my Rapin, et al. 2023.",
                "venue": "arXiv preprint arXiv:2308.12950.",
                "url": null
            }
        },
        {
            "63": {
                "title": "Did chatgpt cheat on your test?",
                "author": "Oscar Sainz, Jon Ander Campos, Iker Garc\u00eda-Ferrero, Julen Etxaniz, and Eneko Agirre. 2023.",
                "venue": null,
                "url": "https://hitz-zentroa.github.io/lm-contamination/blog/"
            }
        },
        {
            "64": {
                "title": "An empirical evaluation of using large language models for automated unit test generation.",
                "author": "Max Sch\u00e4fer, Sarah Nadi, Aryaz Eghbali, and Frank Tip. 2024.",
                "venue": "IEEE Transactions on Software Engineering, 50(1):85\u2013105.",
                "url": "https://doi.org/10.1109/TSE.2023.3334955"
            }
        },
        {
            "65": {
                "title": "Detecting pretraining data from large language models.",
                "author": "Weijia Shi, Anirudh Ajith, Mengzhou Xia, Yangsibo Huang, Daogao Liu, Terra Blevins, Danqi Chen, and Luke Zettlemoyer. 2023.",
                "venue": "arXiv preprint arXiv:2310.16789.",
                "url": null
            }
        },
        {
            "66": {
                "title": "Reflexion: Language agents with verbal reinforcement learning.",
                "author": "Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik R Narasimhan, and Shunyu Yao. 2023.",
                "venue": "In Thirty-seventh Conference on Neural Information Processing Systems.",
                "url": null
            }
        },
        {
            "67": {
                "title": "Repository-level prompt generation for large language models of code.",
                "author": "Disha Shrivastava, Hugo Larochelle, and Daniel Tarlow. 2023.",
                "venue": "In International Conference on Machine Learning, pages 31693\u201331715. PMLR.",
                "url": null
            }
        },
        {
            "68": {
                "title": "Nofuneval: Funny how code lms falter on requirements beyond functional correctness.",
                "author": "Manav Singhal, Tushar Aggarwal, Abhijeet Awasthi, Nagarajan Natarajan, and Aditya Kanade. 2024.",
                "venue": "arXiv preprint arXiv:2401.15963.",
                "url": null
            }
        },
        {
            "69": {
                "title": "Reinforcement learning from automatic feedback for high-quality unit test generation.",
                "author": "Benjamin Steenhoek, Michele Tufano, Neel Sundaresan, and Alexey Svyatkovskiy. 2023.",
                "venue": "arXiv preprint arXiv:2310.02368.",
                "url": null
            }
        },
        {
            "70": {
                "title": "Sql-palm: Improved large language modeladaptation for text-to-sql.",
                "author": "Ruoxi Sun, Sercan O Arik, Hootan Nakhost, Hanjun Dai, Rajarishi Sinha, Pengcheng Yin, and Tomas Pfister. 2023.",
                "venue": "arXiv preprint arXiv:2306.00739.",
                "url": null
            }
        },
        {
            "71": {
                "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context.",
                "author": "Gemini Team. 2024.",
                "venue": null,
                "url": "https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf"
            }
        },
        {
            "72": {
                "title": "Llmseceval: A dataset of natural language prompts for security evaluations.",
                "author": "Catherine Tony, Markus Mutas, Nicol\u00e1s E D\u00edaz Ferreyra, and Riccardo Scandariato. 2023.",
                "venue": "arXiv preprint arXiv:2303.09384.",
                "url": null
            }
        },
        {
            "73": {
                "title": "Methods2test: A dataset of focal methods mapped to test cases.",
                "author": "Michele Tufano, Shao Kun Deng, Neel Sundaresan, and Alexey Svyatkovskiy. 2022.",
                "venue": "In Proceedings of the 19th International Conference on Mining Software Repositories, pages 299\u2013303.",
                "url": null
            }
        },
        {
            "74": {
                "title": "Recode: Robustness evaluation of code generation models.",
                "author": "Shiqi Wang, Zheng Li, Haifeng Qian, Chenghao Yang, Zijian Wang, Mingyue Shang, Varun Kumar, Samson Tan, Baishakhi Ray, Parminder Bhatia, et al. 2022a.",
                "venue": "arXiv preprint arXiv:2212.10264.",
                "url": null
            }
        },
        {
            "75": {
                "title": "Codet5+: Open code large language models for code understanding and generation.",
                "author": "Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi DQ Bui, Junnan Li, and Steven CH Hoi. 2023.",
                "venue": "arXiv preprint arXiv:2305.07922.",
                "url": null
            }
        },
        {
            "76": {
                "title": "Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation.",
                "author": "Yue Wang, Weishi Wang, Shafiq Joty, and Steven CH Hoi. 2021.",
                "venue": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 8696\u20138708.",
                "url": null
            }
        },
        {
            "77": {
                "title": "Execution-based evaluation for open-domain code generation.",
                "author": "Zhiruo Wang, Shuyan Zhou, Daniel Fried, and Graham Neubig. 2022b.",
                "venue": "arXiv preprint arXiv:2212.10481.",
                "url": null
            }
        },
        {
            "78": {
                "title": "On learning meaningful assert statements for unit test cases.",
                "author": "Cody Watson, Michele Tufano, Kevin Moran, Gabriele Bavota, and Denys Poshyvanyk. 2020.",
                "venue": "In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pages 1398\u20131409.",
                "url": null
            }
        },
        {
            "79": {
                "title": "Typet5: Seq2seq type inference using static analysis.",
                "author": "Jiayi Wei, Greg Durrett, and Isil Dillig. 2023a.",
                "venue": "arXiv preprint arXiv:2303.09564.",
                "url": null
            }
        },
        {
            "80": {
                "title": "Magicoder: Source code is all you need.",
                "author": "Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming Zhang. 2023b.",
                "venue": "arXiv preprint arXiv:2312.02120.",
                "url": null
            }
        },
        {
            "81": {
                "title": "\u201d according to\u2026\u201d prompting language models improves quoting from pre-training data.",
                "author": "Orion Weller, Marc Marone, Nathaniel Weir, Dawn Lawrie, Daniel Khashabi, and Benjamin Van Durme. 2023.",
                "venue": "arXiv preprint arXiv:2305.13252.",
                "url": null
            }
        },
        {
            "82": {
                "title": "Codescope: An execution-based multilingual multitask multidimensional benchmark for evaluating llms on code understanding and generation.",
                "author": "Weixiang Yan, Haitian Liu, Yunkun Wang, Yunzhe Li, Qian Chen, Wen Wang, Tingyu Lin, Weishan Zhao, Li Zhu, Shuiguang Deng, et al. 2023.",
                "venue": "arXiv preprint arXiv:2311.08588.",
                "url": null
            }
        },
        {
            "83": {
                "title": "Rethinking benchmark and contamination for language models with rephrased samples.",
                "author": "Shuo Yang, Wei-Lin Chiang, Lianmin Zheng, Joseph E. Gonzalez, and Ion Stoica. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2311.04850"
            }
        },
        {
            "84": {
                "title": "Large language models as analogical reasoners.",
                "author": "Michihiro Yasunaga, Xinyun Chen, Yujia Li, Panupong Pasupat, Jure Leskovec, Percy Liang, Ed H Chi, and Denny Zhou. 2023.",
                "venue": "arXiv preprint arXiv:2310.01714.",
                "url": null
            }
        },
        {
            "85": {
                "title": "Natural language to code generation in interactive data science notebooks.",
                "author": "Pengcheng Yin, Wen-Ding Li, Kefan Xiao, Abhishek Rao, Yeming Wen, Kensen Shi, Joshua Howland, Paige Bailey, Michele Catasta, Henryk Michalewski, et al. 2022.",
                "venue": "arXiv preprint arXiv:2212.09248.",
                "url": null
            }
        },
        {
            "86": {
                "title": "No more manual tests? evaluating and improving chatgpt for unit test generation.",
                "author": "Zhiqiang Yuan, Yiling Lou, Mingwei Liu, Shiji Ding, Kaixin Wang, Yixuan Chen, and Xin Peng. 2023.",
                "venue": "arXiv preprint arXiv:2305.04207.",
                "url": null
            }
        },
        {
            "87": {
                "title": "Parsel: A unified natural language framework for algorithmic reasoning.",
                "author": "Eric Zelikman, Qian Huang, Gabriel Poesia, Noah D Goodman, and Nick Haber. 2022.",
                "venue": "arXiv preprint arXiv:2212.10561.",
                "url": null
            }
        },
        {
            "88": {
                "title": "Repocoder: Repository-level code completion through iterative retrieval and generation.",
                "author": "Fengji Zhang, Bei Chen, Yue Zhang, Jin Liu, Daoguang Zan, Yi Mao, Jian-Guang Lou, and Weizhu Chen. 2023a.",
                "venue": "arXiv preprint arXiv:2303.12570.",
                "url": null
            }
        },
        {
            "89": {
                "title": "Toolcoder: Teach code generation models to use apis with search tools.",
                "author": "Kechi Zhang, Ge Li, Jia Li, Zhuo Li, and Zhi Jin. 2023b.",
                "venue": "arXiv preprint arXiv:2305.04032.",
                "url": null
            }
        },
        {
            "90": {
                "title": "Self-edit: Fault-aware code editor for code generation.",
                "author": "Kechi Zhang, Zhuo Li, Jia Li, Ge Li, and Zhi Jin. 2023c.",
                "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 769\u2013787, Toronto, Canada. Association for Computational Linguistics.",
                "url": null
            }
        },
        {
            "91": {
                "title": "Algo: Synthesizing algorithmic programs with generated oracle verifiers.",
                "author": "Kexun Zhang, Danqing Wang, Jingtao Xia, William Yang Wang, and Lei Li. 2023d.",
                "venue": "arXiv preprint arXiv:2305.14591.",
                "url": null
            }
        },
        {
            "92": {
                "title": "Codegeex: A pre-trained model for code generation with multilingual evaluations on humaneval-x.",
                "author": "Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen, Andi Wang, Yang Li, et al. 2023.",
                "venue": "arXiv preprint arXiv:2303.17568.",
                "url": null
            }
        },
        {
            "93": {
                "title": "Opencodeinterpreter: Integrating code generation with execution and refinement.",
                "author": "Tianyu Zheng, Ge Zhang, Tianhao Shen, Xueling Liu, Bill Yuchen Lin, Jie Fu, Wenhu Chen, and Xiang Yue. 2024.",
                "venue": "https://arxiv.org/abs/2402.14658.",
                "url": null
            }
        },
        {
            "94": {
                "title": "Codegen-test: An automatic code generation model integrating program test information.",
                "author": "Maosheng Zhong, Gen Liu, Hongwei Li, Jiangling Kuang, Jinshan Zeng, and Mingwen Wang. 2022.",
                "venue": "arXiv preprint arXiv:2202.07612.",
                "url": null
            }
        },
        {
            "95": {
                "title": "Don\u2019t make your llm an evaluation benchmark cheater.",
                "author": "Kun Zhou, Yutao Zhu, Zhipeng Chen, Wentong Chen, Wayne Xin Zhao, Xu Chen, Yankai Lin, Ji-Rong Wen, and Jiawei Han. 2023.",
                "venue": "arXiv preprint arXiv:2311.01964.",
                "url": null
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.07974v2",
    "segmentation": {
        "research_background_sections": [
            "1"
        ],
        "methodology_sections": [
            "2",
            "3",
            "3.1",
            "3.2",
            "3.3"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "5",
            "5.1",
            "5.2"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "5.1",
            "5.2"
        ]
    },
    "research_context": {
        "paper_id": "2403.07974v2",
        "paper_title": "LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code",
        "research_background": "**Motivation:** The rapid proliferation of large language models (LLMs) for code generation and related tasks has highlighted the need for robust evaluation benchmarks. Current benchmarks such as HumanEval, MBPP, and APPS, while useful, have limitations. Specifically, they largely focus on natural language-to-code tasks and are susceptible to contamination or overfitting, as benchmark samples could exist within training datasets. This potentially skews evaluation results and offers a misleading picture of model capabilities.\n\n**Research Problem:** The primary issue addressed by this paper is the inadequacy of existing benchmarks to holistically and contamination-free evaluate the code-related capabilities of LLMs. This research aims to introduce a new benchmark, LiveCodeBench, that addresses these shortcomings by preventing contamination through live updates and offering a more holistic evaluation that spans multiple code-related tasks beyond simple code generation.\n\n**Relevant Prior Work:**\n1. **Code-specific models:** Numerous code-specific models have been developed recently (Chen et al., 2021; Austin et al., 2021; Li et al., 2022; Zhong et al., 2022; etc.), focusing on applications like program repair, optimization, test generation, and documentation generation.\n2. **Decontamination attempts:** Efforts to decontaminate model training data using exact and fuzzy matches have been made (Li et al., 2023b, d), but these methods can often be circumvented by simple rephrasing strategies (Yang et al., 2023).\n3. **Benchmark deficiencies:** Previous benchmarks such as HumanEval and MBPP have been found lacking. HumanEval suffers from insufficient tests and ambiguous descriptions (Liu et al., 2023a), prompting the creation of HumanEval+. MBPP required sanitization to remove ambiguities (Austin et al., 2021).\n4. **Other holistic evaluations:** Other works have also aimed to enrich LLM evaluation but often lack the holistic method proposed here. For instance, Huang et al. (2023) evaluated LLMs in a time-segmented manner but only on CodeForces problems. Li et al. (2023c) proposed a dataset of competitive programming problems but did not study contamination or tasks beyond code generation. Liu et al. (2024) focused on code comprehension, while Singhal et al. (2024) evaluated tasks beyond generation, considering non-functional correctness.\n5. **Risk of contamination in older problems:** Guo et al. (2024) also note the possibility of contamination when evaluating models on existing benchmarks.\n\nBy considering these factors, LiveCodeBench presents a contamination-free, dynamically updated, and holistic benchmark that aims to offer a more accurate and comprehensive evaluation of LLMs for code.",
        "methodology": "### Methodology: LiveCodeBench\n\nThe proposed method, **LiveCodeBench**, aims to offer a more holistic and contamination-free evaluation of Large Language Models (LLMs) for code-related capabilities. Unlike traditional methods that predominantly focus on natural language to code generation tasks, LiveCodeBench encompasses a broader spectrum of real-world software engineering tasks. \n\n#### Key Components and Innovations:\n\n1. **Holistic Evaluation Setups**:\n   The methodology evaluates LLMs across four crucial scenarios: code generation, self-repair, code execution, and test output prediction. This comprehensive approach aims to capture the multifaceted nature of software engineering tasks.\n\n2. **Scenarios Detailed**:\n\n   - **Code Generation**: \n     - **Task**: Generating correct code from a problem statement and example tests (input-output pairs).\n     - **Evaluation**: Functional correctness using a set of unseen test cases.\n     - **Metric**: Pass@1, which measures the fraction of problems for which the model generates a program passing all tests.\n\n   - **Self-Repair**:\n     - **Task**: Generating a candidate program and then provided with error feedback to generate a fixed solution, if there was a mistake in the initial attempt.\n     - **Evaluation**: Functional correctness on the final program, whether it\u2019s the single-step generation or the repaired code.\n     - **Metric**: Pass@1, similar to code generation but includes the repair step.\n\n   - **Code Execution**:\n     - **Task**: Predicting the output of a program given a function and test input.\n     - **Evaluation**: Execution-based correctness, where the model generation is correct if `assert f(input) == generated_output` passes.\n   \n   - **Test Case Output Prediction**:\n     - **Task**: Generating the expected output for given test case inputs based on a problem statement.\n     - **Evaluation**: Straightforward assessment of test generation capabilities, avoiding the complexities associated with predicting test inputs.\n\n3. **Motivation and Comparisons**:\n   - **Importance of Broader Capabilities**: Inspired by pipelines like AlphaCodium, which combines various tasks such as natural language reasoning, test case generation, code generation, and self-repair to improve performance.\n   - **Effective Workflows**: Leveraging similar workflows in LLMs can enhance their code generation capabilities.\n\n4. **Extensible Framework**:\n   - **Future Scenarios**: LiveCodeBench offers an extensible framework to integrate additional tasks like input generation, program summarization, and optimization, making it adaptable for future advancements.\n\nBy adopting these evaluation setups, LiveCodeBench ensures a more thorough assessment of LLMs' capabilities, emphasizing tasks that are not only useful but also have clear and automated evaluation metrics. This methodology aims to drive improvements in the quality, maintainability, and reliability of code produced by LLMs.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n#### Common Setup\nWe evaluate various models across different sizes and categories. The models range in size from B to B and include base, instruction, open, and closed models. The models evaluated are from different classes, such as:\n\n- **Closed-access Models**: GPTs (GPT-3.5-turbo, GPT-4, GPT-4-Turbo, GPT-4-O), Claudes (Claude-Ins-1, Claude-2, Claude-3s), Geminis (Gemini-Pro, Gemini-Flash), Mistral.\n- **Open Models**: LLaMa-3s (L3-Base-{7, 70}B, L3-Ins-{7, 70}B), DeepSeeks (DS-Base-{1.3, 6.7, 33}B, DS-Ins-{1.3, 6.7, 33}B), CodeLLaMas (CL-Ins-{7, 13, 34}B, CL-Base-{7, 13, 34}B), StarCoder2 (SC2-Base-{3,7,15}B), CodeQwen.\n- **Fine-tuned Models**: Phind-34B from CL-Base-34B, and MagiCoders (MC-{6.7, 7}B) from CL-Base-7B and DS-Base-6.7B.\n\nA more detailed list of models and their estimated cutoff dates can be found in Appendix C.1.\n\n#### Evaluation Metrics\nWe utilize the Pass@1 metric to evaluate the performance of these models. This metric checks if the generated code or answer is correct on the first attempt. Specifically, we:\n\n- Generate  candidate answers for each problem using API or vLLM.\n- Use nucleus sampling with a temperature and top_p settings.\n- Evaluate the correctness fraction of the programs or answers.\n\nFor different scenarios (code generation, self-repair, code execution, test output prediction):\n\n- **Code Generation and Self-Repair**: Correctness is verified by running tests on the generated programs. A program is considered correct if it passes all tests.\n- **Code Execution**: An execution-based correctness metric is used to compare the generated output against the ground truth output.\n- **Test Output Prediction**: The generated response is parsed to extract the answer, and equivalence checks as specified in Section 2 are conducted for grading.\n\n#### Main Experimental Results\nThe results of the main experiments highlight the performance of the evaluated models under the defined metrics and scenarios. The overall effectiveness and correctness of each model size and type are reflected by their respective Pass@1 scores across different tasks, offering insights into their comparative performance in code-related challenges. The full results and detailed comparisons among the models are documented to show how each model variant performs under the various scenarios of code generation, self-repair, execution-based correctness, and test output prediction. These results establish a benchmark for evaluating and understanding the strengths and weaknesses of different large language models in coding tasks."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To evaluate the extent of model contamination in LiveCodeBench by comparing the performance of various models on coding problems released over different time periods.",
            "experiment_process": "The models' performance was measured on problems released after their respective cutoff dates. Specifically, the performances of DS-Ins-33B and GPT-4-O were evaluated on LeetCode problems released from May 2023 to February 2024. The study also analyzed other models such as GPT-4-Turbo, Gemini-Pro, Mistral-L, and Claude-3s, comparing their performances across various time windows. The metrics used included Pass@1, which measures the percentage of problems a model solves correctly on the first attempt.",
            "result_discussion": "The results showed a significant drop in the performance of DS-Ins-33B after its August 2023 cutoff, indicating possible contamination. This trend was consistent across other scenarios in LiveCodeBench, such as code execution and self-repair. GPT-4-O also exhibited a performance drop on problems released after its November 2023 cutoff, particularly on LeetCode problems. In contrast, other models like GPT-4-Turbo and Claude-3s showed relatively stable performance across different months, pointing to less contamination. The study highlighted the potential inclusion of competition problems in pretraining data, especially for DeepSeek models.",
            "ablation_id": "2403.07974v2.No1"
        },
        {
            "research_objective": "To conduct holistic evaluations and model comparisons on various scenarios within LiveCodeBench, comparing these results with the traditional HumanEval benchmark.",
            "experiment_process": "Instruction-tuned models and base models were evaluated across four LiveCodeBench scenarios. For contamination control, only problems released after September 2023 were considered. The scenarios included code generation, self-repair, test output prediction, and code execution. The performance metrics used were Pass@1 on HumanEval+, LCB-Easy, and other specific LiveCodeBench scenarios. Comparative evaluations were also performed between open- and closed-access models, as well as between fine-tuned and base models.",
            "result_discussion": "Models generally displayed consistent performance across various scenarios, with high correlations in Pass@1 metrics. GPT-4-Turbo outperformed GPT-4 in self-repair tasks, and Claude-3-Opus excelled in test output prediction and code execution. The study found a moderate correlation between performances on LiveCodeBench and HumanEval+, with some models overfitting on HumanEval but underperforming on LiveCodeBench. Particularly, DS-Ins-1.3B, despite high performance on HumanEval+, showed a significant drop on LCB-Easy, indicating overfitting. There was a noticeable gap between state-of-the-art (SoTA) and open models, with closed-access models consistently outperforming open-access ones. Post-training significantly improved model performance across benchmarks, emphasizing the importance of high-quality post-training datasets.",
            "ablation_id": "2403.07974v2.No2"
        }
    ]
}