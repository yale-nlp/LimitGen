{
    "title": "SilverSight: A Multi-Task Chinese Financial Large Language Model Based on Adaptive Semantic Space Learning",
    "abstract": "Large language models (LLMs) are increasingly being applied across various specialized fields, leveraging their extensive knowledge to empower a multitude of scenarios within these domains. However, each field encompasses a variety of specific tasks that require learning, and the diverse, heterogeneous data across these domains can lead to conflicts during model task transfer. In response to this challenge, our study introduces an Adaptive Semantic Space Learning (ASSL) framework, which utilizes the adaptive reorganization of data distributions within the semantic space to enhance the performance and selection efficacy of multi-expert models. Utilizing this framework, we trained a financial multi-task LLM named \"SilverSight\". Our research findings demonstrate that our framework can achieve results close to those obtained with full data training using only 10% of the data, while also exhibiting strong generalization capabilities.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Recently, large language models such as GPT-4 OpenAI (2023 ###reference_b13###) and LLaMA Touvron et al. (2023 ###reference_b17###) have demonstrated remarkable capabilities across various tasks in the field of natural language processing (NLP). These models, with their formidable knowledge storage and context comprehension abilities, have extensively infiltrated professional domains such as finance Zhou et al. (2024 ###reference_b21###); Chen et al. (2023 ###reference_b3###) and law Cui et al. (2023 ###reference_b4###), showcasing their exceptional performance. Instruction fine-tuning, leveraging supervised datasets to refine the models, plays an important role in the construction of LLMs, facilitating their transition from simple text continuation to solving complex tasks Qiu et al. (2020 ###reference_b15###). However, the process is often constrained by the data availability in specific domains and computational resource limitations, necessitating the use of parameter-efficient fine-tuning (PEFT) strategies Houlsby et al. (2019 ###reference_b6###). These strategies, requiring minimal updates or additions to the base model\u2019s parameters, significantly enhance the model\u2019s responsiveness to instructions.\n\nCurrently, one of the research hotspots in the field of NLP is the use of Mixture of Experts (MoE) models Jordan and Jacobs (1994 ###reference_b8###) to address the challenges of multitasking. MoE models, an ensemble learning strategy, integrate multiple expert models to leverage each model\u2019s expertise on specific sub-problems, thereby enhancing overall performance in complex tasks Dou et al. (2023 ###reference_b5###). These multi-expert strategies face challenges related to their token-level processing and the fixed nature of post-training experts and routing strategies, limiting the models\u2019 ability to rapidly adapt to new instructions or scenarios. \n\nTo address this gap, we propose an Adaptive Semantic Space Learning (ASSL) framework and have trained a financial multitask large language model named \"SilverSight\" using a Chinese financial multitask dataset. The ASSL framework clusters multitask training data based on similarities in the semantic space, thereby eliminating the need for predefined task types. Our experiments show that our method has clear advantages over traditional predefined classification methods, ensuring that each expert model is allocated to the most relevant downstream tasks. We also observed that training tasks from different sources and formats could lead to unavoidable task conflicts, affecting the model\u2019s ability to follow instructions. Moreover, by leveraging similarities in the semantic space, our method can aggregate diverse data from complementary tasks, improving model performance on related tasks.\n\nWithin the ASSL framework, we adopt a model self-evolution-based data redistribution strategy in each cluster for adaptive data selection. Through a two-step adaptive data filtering process, we ensure that the limited data used to train each expert is of high quality, coverage, and necessity. In scenarios where original data quality and quantity distributions are uneven, the ASSL framework adapts the selection of training data for each expert by considering semantic space distribution density and model self-feedback mechanisms. This approach allows the model to more evenly fit top similarity data and tail small-sample data in the long-tail distribution, thereby improving the model\u2019s generalization ability and performance across diverse tasks.\n\nWe collected 220k Chinese financial fine-tuning data points from 23 different sources in the financial domain, classifying them into various task types such as sentiment analysis, financial Q&A, text generation, and financial multiple-choice questions. Based on these experimental data, we made the following key findings: \n\n1. By clustering based on similarities in the semantic space, we could identify mutually enhancing and conflicting training tasks. Using multiple expert models to learn specific domain tasks allows each model to focus on its area of expertise, achieving a division of labor.\n\n2. By combining the density distribution of data in the semantic space with the model\u2019s own training data needs, we could effectively perform semantic smoothing and redistribution of data. This method enables the entire system to achieve similar effects with only 10% of the data used for fine-tuning compared to using the full dataset.\n\n3. By smoothing the data distribution within clusters, we optimize the allocation and performance of experts.\n\nThese findings not only validate the effectiveness of the ASSL framework in financial multitask learning but also provide new perspectives and methods for efficiently using limited data resources to improve model performance. These achievements are significant for advancing natural language processing technology in the domain.\n\nOur main contributions are as follows:\n\n1. We innovatively propose the ASSL framework, which analyzes the distribution of data in the semantic space to achieve an adaptive selection mechanism for experts and data in multitask scenarios. This effectively adjusts the distribution balance between experts and training data, using semantic space information for smooth data processing, thereby avoiding expert overfitting or conflicts during training.\n\n2. We empirically validate the effectiveness of the ASSL framework in the financial domain and successfully trained a Chinese financial multitask large"
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Preliminaries",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "LoRA",
            "text": "Fine-tuning LLMs with all parameters requires substantial data and computational resources and may lead to issues of catastrophic forgetting Luo et al. (2023  ###reference_b11###). To address this, recent studies have developed various efficient fine-tuning methods, among which LoRA Hu et al. (2021  ###reference_b7###) has been widely applied due to its effectiveness. The LoRA method employs the concept of low-rank matrix decomposition to reduce the number of parameters that need to be adjusted during fine-tuning. This is achieved by introducing an additional bypass structure  in the network. Specifically, LoRA modifies the weights in the network by adding  to the original weight matrix , as follows:\nHere,  and  are two matrices obtained from  through low-rank decomposition, with r representing the rank of the matrices. When the input to the model is the token representation , the output of the model  can be expressed as:\nIn this case,  represents the token representation input to the model, while  denotes the model output.\n\n###figure_2###"
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Task Definition",
            "text": "Within the ASSL framework, we harness the distribution of data in the semantic space to design a multi-expert system, focusing primarily on two core tasks: adaptive expert selection and adaptive data selection. These tasks aim to enhance the system\u2019s flexibility and efficiency in a multi-task environment.\nThe task of adaptive expert selection concentrates on how to adaptively choose the most suitable LoRA expert for a specific task given an input. Considering that our multi-task system comprises a set of  different tasks  and a set of  different LoRA experts , where each expert  is trained on several specific tasks to optimize its performance. For any input , our goal is to find a mapping function  such that  selects the expert  most suited for the current input . This can be achieved by maximizing the relevance between input  and expert , as follows:\nHere, the function  measures the relevance between the input  and the expert .\nOn the other hand, the task of adaptive data selection focuses on handling heterogeneous data from multiple sources and addressing the long-tail distribution present within the data. We have a dataset , with each  representing data from different sources. In practice, these data often follow a long-tail distribution, meaning a large amount of data is concentrated in a few categories, while most categories contain only a small amount of data. Our goal is to process the original dataset  through a transformation function , converting it into a smoother, more evenly distributed dataset  to mitigate the effects of the long-tail distribution."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Adaptive Semantic Space Learning",
            "text": "We introduce a framework named Adaptive Semantic Space Learning (ASSL), designed to facilitate the adaptive selection of LoRA experts and their corresponding data. The framework is illustrated in 2  ###reference_###, ensuring that each expert operates at peak performance and that the system excels across a variety of multitask environments. In this chapter, we will delve into the framework\u2019s two pivotal components, detailing how adaptive selection between experts and data is achieved through the redistribution of data within the semantic space."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Adaptive Selection of LoRA Experts",
            "text": "In addressing the adaptive selection of LoRA experts, our aim is to optimize data segmentation to avert potential conflicts between tasks and ensure that for each input, the expert most proficient in handling the given problem is matched. This objective is twofold: (1) how to more effectively train multitask instructions; and (2) how to choose the most appropriate LoRA expert based on user input.\nFirst, to enhance the system\u2019s generalization capability across diverse instructions, we expanded the instructions for each subtask within the task set. Specifically, we manually crafted 30 semantically similar but differently phrased instructions for each task. Then, using a sentence encoder , we encoded each instruction and its concatenated input data , obtaining embedding vectors for all data within the same semantic space. We employed the K-means clustering method MacQueen et al. (1967  ###reference_b12###) to group semantically similar sentences in the semantic space into  clusters, thereby optimizing task data segmentation. The clustering process is represented by the following equation:\nwhere  denotes the set of all data points,  is the set of data points in cluster , and  is the centroid of cluster .\nAs proven by experiments in Section 4.5  ###reference_###, compared to mixed task segmentation and predefined label-based segmentation, this semantic clustering approach significantly enhances system performance. For each LoRA expert, we selected the centroid of its cluster as the expert\u2019s semantic embedding. The centroid  for each cluster is the average position of all semantic embeddings in the cluster, calculated as follows:\nwhere  is the set of data points in cluster  and  represents the number of elements in set .  signifies the mean of all points in cluster , i.e., the centroid. Whenever there is a user input, the system finds the expert whose semantic embedding is closest to the semantic embedding of the user input using the following formula:\nHere,  is the embedding vector of the user input,  is the semantic embedding vector of the expert, and  is the selected expert. Through this matching method, the system can find the expert that best matches the training task in the semantic space.\n\n###figure_3###"
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Adaptive Selection of Heterogeneous Multi-source Data",
            "text": "In this section, we discuss clustering multi-task supervised data to isolate conflicting tasks and gather those that enhance each other. While this approach effectively resolves conflicts between tasks, it introduces new challenges such as imbalanced data ratios and varying quality, especially concerning long-tail data distributions. To address these issues, we designed a two-stage data redistribution operation for each cluster, aiming to achieve effective fine-tuning on a limited dataset while emulating the effects of full dataset fine-tuning, as shown in Figure 3  ###reference_###.\nIn the first stage, addressing the issue of data imbalance within clusters, we devised an adaptively adjusted A-DBSCAN algorithm based on the DBSCAN algorithm Schubert et al. (2017  ###reference_b16###), performing nested clustering within each cluster. The detailed algorithmic process is provided in Appendix A.4  ###reference_###. This algorithm dynamically adjusts the requirements for connectivity count based on data density in different areas. The specific steps are as follows: initially, the algorithm evaluates the local density of data points in the semantic space using the K-Nearest Neighbor (KNN) Peterson (2009  ###reference_b14###) distance calculation framework. The local density for each data point is the reciprocal of the average distance to its  nearest neighbors, mathematically expressed as:\nwhere  represents the distance between data point  and its th nearest neighbor .\nSubsequently, the algorithm sorts data points based on the calculated local density values, forming a priority queue and prioritizing data points with higher local density. In each iteration, the point with the highest local density in the queue is selected as the starting point for cluster formation.\nDuring the adaptive process, the algorithm defines the neighborhood radius  using the median of KNN distances for all data points in the queue. The initial value of neighborhood node count  is heuristically set as:\nwhere  denotes the global maximum local density, i.e., the local density of the first data point in the initial priority queue. After forming each cluster,  is updated according to the following formula to adapt to the current local density environment:\nHere,  refers to the local density of the first point in the current priority queue. This dynamic adjustment strategy allows the algorithm to adapt more flexibly to different density data distributions, enhancing clustering accuracy and efficiency. Simultaneously, this strategy enables averaging data selection in each sub-cluster while filtering out disconnected noise points, effectively downsampling high-density data and upsampling low-density data to avoid overfitting and underfitting.\nIn the second stage, we use the small dataset filtered from the first stage to conduct preliminary fine-tuning on the model. According to previous studies, large language models primarily learn new language style distributions during the fine-tuning phase and struggle to acquire new domain knowledge. Therefore, considering the score differences before and after training the large model on unselected data, we designed two scoring mechanisms to evaluate each data point\u2019s value to the current model. The differential score and proportional score are defined as follows:\nModel scores are calculated using the Rouge method Lin (2004  ###reference_b9###). Moreover, to ensure the quality of newly selected data and coverage over the\nentire cluster, we introduce and modify the MMR formula Carbonell and Goldstein (1998  ###reference_b2###) as the utility function for data:\nwhere  represents the cluster centroid,  is the new data point to be added,  denotes the set of already selected data points, and , , and  are three adjustable weight parameters used to balance the contributions of similarity, diversity, and model score to the final utility value of data points.\nThrough two stages of data filtering, data within each cluster will be redistributed in the semantic space, encouraging the model to learn rare but beneficial data and avoid overfitting on common datasets."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "In this chapter, we will train a Chinese financial multitask large model named \"SilverSight\" using publicly available datasets from the financial domain. We will validate the effectiveness of the Adaptive Semantic Space Learning (ASSL) algorithm proposed in this study using two Chinese financial evaluation benchmarks."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Data Introduction",
            "text": "We collected 220,000 Chinese financial fine-tuning data points from 23 different sources within the financial domain, classifying these data into 7 task categories such as sentiment analysis and financial Q&A. Detailed information can be found in Appendix A.1. For evaluation, we used the CFLEB and FinEval benchmarks, aiming to assess the large language model\u2019s knowledge reserve, instruction following, and task execution capabilities in the financial domain.\n\nThe CFLEB benchmark, constructed using publicly available research reports and news items, is a high-quality and practical evaluation standard containing six natural language processing tasks. It measures the comprehensive understanding and generation capabilities of models in the financial domain across sentiment analysis, Q&A, summary generation, information extraction, semantic matching, and more.\n\nThe FinEval benchmark is a comprehensive dataset designed for knowledge assessment in the financial domain, consisting of 4661 multiple-choice questions covering 34 different academic fields such as finance, insurance, macroeconomics, and tax law. The questions are mainly divided into four categories: finance, economics, accounting, and qualification exams, to thoroughly test large models\u2019 general knowledge in the financial domain and evaluate their advanced knowledge and practical application capabilities in financial specialties."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Experimental Setup",
            "text": "We used the representative Chinese model Qwen1.5-7B-Chat Bai et al. (2023) as our base model and conducted our experiments on 2 A800 GPUs. In the K-Means clustering algorithm, after multiple trials, we finally set , and in the adaptive A-DBSCAN algorithm, we chose  as the initial KNN calculation parameter. For the modified MMR formula, we set , , and  to 0.2, 0.2, and 0.6, respectively, to balance the contributions of similarity to the cluster center, diversity, and model score to the final utility function of the data points."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "SilverSight: Financial Multitask Large Model",
            "text": "In this study, we processed data using the designed ASSL framework and trained a multitask large language model for the Chinese financial domain named \"SilverSight\". First, we employed the K-Means algorithm to cluster publicly available financial domain data in the semantic space, ultimately forming six categories. The data distribution for various category numbers can be found in Appendix A.3. Next, we smoothed the data distribution within each cluster through two stages: In the first stage, we selected data using the adaptive density clustering algorithm A-DBSCAN, downsampling high-density areas and upsampling low-density areas within each cluster, selecting approximately 2000 fine-tuning data points per cluster and treating data in extremely low-density areas as noise. The second stage aimed to adaptively supplement necessary data points not selected in the first stage, using the original model before training and the model after training with the first-stage data. This made the fine-tuning data distribution smoother and enhanced data selection diversity. In total, about 4000 data points were selected from each cluster, amounting to approximately 10% of the total data volume."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "Main Results",
            "text": "The evaluation results of the \"SilverSight\" large model on CFLEB and FinEval benchmarks are shown in Tables 1  ###reference_### and 2  ###reference_###, respectively. In the CFLEB experiments, our approach achieved similar test scores to the fully fine-tuned model (Newest_all) using only 10."
        },
        {
            "section_id": "4.5",
            "parent_section_id": "4",
            "section_name": "Ablation Studies",
            "text": "To demonstrate the effectiveness of the algorithms within the ASSL framework, we explored the following three questions:  \nQuestion 1: Does clustering in the semantic space have advantages over manual task categorization?  \nQuestion 2: Is the first stage of data redistribution meaningful?  \nQuestion 3: Is the second stage of data selection and supplementation meaningful?  \n  \nTo answer Question 1, we designed a set of control experiments with both model systems using the expert adaptive selection method. For the first model system, data was manually divided into seven categories based on the definitions of natural language processing tasks during the data preprocessing stage, forming a multi-expert system. For the second model system, data was re-clustered into six categories in the semantic space to verify whether distances in the semantic space could reflect the complementarity between tasks, offering advantages over manually predefined categories. We conducted a thorough comparative analysis of the six categories obtained from clustering algorithms and the original seven categories. As shown in Figure 5, the predefined manual categorization method performed worse on average on the CFLEB dataset compared to the semantic space clustering method, especially on the FinQA and FinNSP1 tasks. This proves the superiority of the semantic space clustering learning method over the predefined task type method, demonstrating that leveraging semantic space similarities can aggregate diverse data from complementary tasks, enhancing model performance on these tasks.\n  \nTo answer Question 3 and further confirm the importance of enhancing data smooth distribution, we compared the results of the second-stage improved MMR algorithm experiment. To ensure fairness, both experiment types selected 4000 data points from each cluster for training. As shown in Figure 7, the comprehensive performance of the model significantly improved after the second-stage data expansion compared to just the first-stage filtering. This further validates the necessity and effectiveness of data expansion in the second stage, enhancing the smoothness of the original data\u2019s long-tail distribution."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Discussion",
            "text": "Our research trained a Chinese financial multitask large model based on the ASSL framework and achieved outstanding performance on multiple evaluation sets. The ASSL framework allows researchers to understand the advantages of adaptive learning based on semantic space, utilizing the characteristics of semantic space to infuse the benefits of a multi-expert system into the semantic space, achieving expert adaptive selection and data adaptive selection for better model performance. Based on this, we can further discuss the complementary characteristics of adaptive learning based on semantic space.\n\nEach domain possesses numerous natural language processing or domain-specific tasks, requiring domain large models to have comprehensive and integrated capabilities. However, current heterogeneous multi-source data can easily trigger conflicts during task style transitions in models. When conducting multitask learning, training a large model with all corpora can easily affect the model\u2019s ability to follow instructions, leading to performance degradation and hallucination phenomena. Therefore, developing a multi-expert system and formulating adaptive task categorization and data selection strategies based on the distribution of all data in the same semantic space becomes particularly important. According to  Figure 4, utilizing the similarity of data points in the semantic space can effectively cluster task data that promote model capability enhancement and separate conflicting task data, improving the balance of fine-tuning data. This method ensures the coherence and consistency of data, tasks, and models in the semantic space, ultimately enhancing the model\u2019s overall capabilities. Experimental results further validate the effectiveness and robustness of this method."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this study, we investigated the impact of adaptive learning based on semantic space on the performance of multi-expert large language model systems. The goal was to divide complementary and conflicting task data based on semantic space, adaptively select multiple experts using their embedding positions, and adjust the training data distribution in two stages using both the model itself and the density distribution of the semantic space. This framework enabled the model to have better performance and generalization when conducting multitask learning. Based on the Adaptive Semantic Space Learning framework, we trained the \"SilverSight\" large language model using publicly available datasets from the financial domain and evaluated the \"SilverSight\" model system on benchmarks, demonstrating its outstanding performance. These results not only prove the feasibility and effectiveness of our method but also open new perspectives for the development of multi-expert system large language models in the future."
        }
    ],
    "url": "http://arxiv.org/html/2404.04949v1",
    "segmentation": {
        "research_background_sections": [
            "1"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2"
        ],
        "main_experiment_and_results_sections": [
            "4.1",
            "4.2",
            "4.3",
            "4.4"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4.5"
        ]
    },
    "research_context": {
        "paper_id": "2404.04949v1",
        "paper_title": "SilverSight: A Multi-Task Chinese Financial Large Language Model Based on Adaptive Semantic Space Learning",
        "research_background": "**Motivation:**\n\nThe paper is motivated by the recent advancements in large language models (LLMs) such as GPT-4 and LLaMA, which have shown exceptional performance in various professional domains, including finance and law. However, the existing strategies for fine-tuning these models, such as parameter-efficient fine-tuning (PEFT) and Low-Rank Adaptation (LoRA), face limitations in adaptability and data usage efficiency. Specifically, these approaches struggle with the need for predefined task types, manual data segmentation, and uneven data quality from different sources. Thus, there's a critical need for a more sophisticated method that optimizes data selection and maintains semantic continuity in the data used for training, to enhance the performance of multitask LLMs in the financial domain.\n\n**Research Problem:**\n\nThe paper aims to address the following research problem: How to develop an effective fine-tuning strategy for large language models in the financial domain that:\n1. Adapts seamlessly to diverse and complex instructions and scenarios.\n2. Efficiently utilizes limited data resources while maintaining high quality and coverage.\n3. Avoids biases and task conflicts commonly encountered in traditional fine-tuning methods.\n4. Enhances the generalization ability and multitask performance of the model.\n\n**Relevant Prior Work:**\n\n1. **Large Language Models:** GPT-4 (OpenAI, 2023) and LLaMA (Touvron et al., 2023) have demonstrated significant capabilities in NLP across various domains.\n2. **Instruction Fine-Tuning:** Plays a crucial role in refining LLMs for complex tasks (Qiu et al., 2020), but is constrained by data availability and computational resources.\n3. **Parameter-Efficient Fine-Tuning (PEFT):** Introduced to reduce the parameter updates needed, with methods like LoRA (Hu et al., 2021), which facilitate modular modifications.\n4. **Mixture of Experts (MoE):** Enhances overall model performance by integrating multiple expert models for complex tasks (Jordan and Jacobs, 1994; Dou et al., 2023).\n5. **LoRAMoE:** Combines LoRA with MoE strategies to divide expert models into those handling general knowledge and those for new tasks (Dou et al., 2023), but has limitations in adaptability.\n6. **LoraRetriever:** Uses embeddings to retrieve matching LoRA configurations to improve performance and generalization (Zhao et al., 2024), though it relies on manual task segmentation.\n7. **Challenges with Existing Methods:** Current methods do not fully consider intrinsic data connections within the semantic space, leading to biased embeddings and inefficient handling of diverse data sources. Managing data volume and quality remains a key challenge (Touvron et al., 2023).\n\nBy proposing the Adaptive Semantic Space Learning (ASSL) framework, the paper builds on these prior works but addresses their limitations by clustering data based on semantic similarities and adopting an adaptive data redistribution strategy to enhance multitask learning for financial applications.",
        "methodology": "SilverSight: A Multi-Task Chinese Financial Large Language Model Based on Adaptive Semantic Space Learning\n\nMethodology: We introduce a framework named **Adaptive Semantic Space Learning (ASSL)**, designed to facilitate the adaptive selection of **LoRA experts** and their corresponding data. The framework ensures that each expert operates at peak performance and that the system excels across a variety of multitask environments. In this chapter, we will delve into the framework\u2019s two pivotal components, detailing how adaptive selection between experts and data is achieved through the **redistribution of data within the semantic space**.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n**Datasets:**\n- **Fine-Tuning Data:** A collection of 220,000 Chinese financial data points sourced from 23 different financial domain sources, classified into 7 task categories including sentiment analysis and financial Q&A.\n- **Evaluation Benchmarks:** \n  - **CFLEB (Chinese Financial Language Education Benchmark):** This benchmark includes six natural language processing tasks such as sentiment analysis, Q&A, summary generation, information extraction, and semantic matching. It leverages publicly accessible research reports and news items.\n  - **FinEval:** A dataset made up of 4661 multiple-choice questions spanning across 34 academic fields such as finance, insurance, macroeconomics, and tax law, divided into four main categories: finance, economics, accounting, and qualification exams.\n\n**Baselines:**\nThe baselines for the evaluation are not explicitly stated in the description, but typically, they would include state-of-the-art models and possibly previous iterations of the model being evaluated.\n\n**Evaluation Metrics:**\n- **CFLEB:** Measures comprehensive understanding and generation capabilities in the financial domain.\n- **FinEval:** Assesses general knowledge in financial specialties, advanced knowledge, and practical application abilities via multiple-choice questions.\n\n**Main Experimental Results:**\nThe specific results of the main experiments are not detailed in the provided text, so they can't be included here. Usually, such results would be available in the main body or results section of the paper, showing how the SilverSight model compares to baselines in terms of various evaluation metrics for each task category.\n\nFor detailed information, readers would be referred to the respective sections of the original paper and benchmark descriptions (Appendix A.1 for fine-tuning data detail).\n\n---\n\nNote: Since the actual results are not provided, one might typically look for comparative performance metrics such as accuracy, F1-score, precision, recall for each task on both CFLEB and FinEval benchmarks in the referenced paper sections."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To determine whether clustering in the semantic space has advantages over manual task categorization.",
            "experiment_process": "We designed a set of control experiments with both model systems using the LoRA expert adaptive selection method. For the first model system, data was manually divided into seven categories based on the definitions of natural language processing tasks during the data preprocessing stage, with each category training a LoRA expert to form a multi-expert system. For the second model system, data was re-clustered into six categories in the semantic space. A comparative analysis was conducted between the six categories obtained from clustering algorithms and the original seven categories.",
            "result_discussion": "The predefined manual categorization method performed worse on average on the CFLEB dataset compared to the semantic space clustering method, especially on the FinQA and FinNSP1 tasks. This proves the superiority of the semantic space clustering learning method over the predefined task type method, demonstrating that leveraging semantic space similarities can aggregate diverse data from complementary tasks, enhancing model performance on these tasks.",
            "ablation_id": "2404.04949v1.No1"
        },
        {
            "research_objective": "To evaluate whether the first stage of data redistribution is meaningful.",
            "experiment_process": "We compared the first part of the ASSL framework\u2019s data redistribution A-DBSCAN algorithm with two baseline data selection algorithms: Random selection and K-Center Greedy algorithm. These three data selection algorithms have different focuses: the Random algorithm aims to uniformly extract data from each cluster according to the original data distribution, the K-Center Greedy algorithm focuses on the diversity of selected data, and the A-DBSCAN redistributes the original data based on density sparsity, also filtering a large amount of outlier noise data. Performance was evaluated on the CFLEB and FinEval datasets.",
            "result_discussion": "On the CFLEB dataset, the A-DBSCAN and Random algorithms showed prominent performance; whereas, on the FinEval dataset, the K-Center Greedy and A-DBSCAN algorithms demonstrated better performance. The robustness of the A-DBSCAN algorithm on both datasets confirms the superiority of this method, which smoothens the distribution of data in the semantic space, but due to its extensive noise filtering, further data supplementation is required.",
            "ablation_id": "2404.04949v1.No2"
        },
        {
            "research_objective": "To assess the significance of the second stage of data selection and supplementation.",
            "experiment_process": "We compared the results of the second-stage improved MMR algorithm experiment with the Random algorithm. Both experiment types selected 4000 data points from each cluster for training. The comparison focused on the comprehensive performance of the models.",
            "result_discussion": "The comprehensive performance of the model significantly improved after the second-stage data expansion compared to just the first-stage filtering, and also outperformed the Random algorithm. This further validates the necessity and effectiveness of data expansion in the second stage, enhancing the smoothness of the original data\u2019s long-tail distribution.",
            "ablation_id": "2404.04949v1.No3"
        }
    ]
}