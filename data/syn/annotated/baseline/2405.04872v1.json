{
    "title": "Logical Negation Augmenting and Debiasing for Prompt-based Methods",
    "abstract": "In this work, we focus on the effectiveness of logical reasoning in NLP and find that the bottleneck lies in logical negation. Based on our analysis, logical negation tends to result in spurious correlations to negative answers, while propositions without logical negation correlate to positive answers. To solve the problem, we propose a simple but effective method, Negation Augmenting and Negation Debiasing (NAND), which introduces negative propositions to counteract spurious correlations by providing \"not\" for all instances so that models cannot make decisions only by whether expressions contain a logical negation. Experiments on three datasets show that NAND effectively solves the problem of calibrating logical negation and significantly enhances logical reasoning capabilities without model retraining.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Pretrained language models (PLMs) Devlin et al. (2019  ###reference_b6###); Liu et al. (2019  ###reference_b23###); Brown et al. (2020  ###reference_b1###) and human-designed prompt templates for specific tasks, have achieved great success in knowledge-based natural language understanding (NLU) Liu et al. (2022  ###reference_b21###); Wang et al. (2021  ###reference_b35###); Yenicelik et al. (2020  ###reference_b36###); Jawahar et al. (2019  ###reference_b16###). However, whether these methods can deal with logical reasoning in NLU lacks attention. \n\nTo avoid the interference of extra knowledge, we perform analysis on three first-order logical NLI datasets without real-world knowledge: RuleTaker Clark et al. (2020  ###reference_b3###), ProofWriter Tafjord et al. (2021  ###reference_b30###), and LogicNLI Tian et al. (2021  ###reference_b32###). We find that these models can leverage most logic forms for downstream tasks except logical negation (), as many studies have mentioned Hosseini et al. (2021  ###reference_b15###); Hossain et al. (2020  ###reference_b14###).\n\nFurthermore, we explore why models cannot deal with logical negation. Actually, logical negation is an operation on the true values of propositions instead of an indicator of a negative result Gelfond and Lifschitz (1991  ###reference_b9###). For example, \"I do not hate the movie\" does not mean negative sentiment about the movie. Instead, \"not\" here represents a negative operation on the negative verb \"hate\", so the sentiment about the example is positive. However, like other deep neural networks Hosseini et al. (2021  ###reference_b15###); Hossain et al. (2020  ###reference_b14###), these models cannot process this operational feature effectively but tend to build strong spurious correlations between logical negation and negative labels. Specifically, without considering logic, statements with \"not\" are more likely to be classified as \"Contradiction\". On the other hand, statements without \"not\" are also incorrectly correlated to positive labels, including \"Entailment\". This phenomenon is named logically negative bias, which hinders machines from making correct logical reasoning.\n\nTo solve the problem, we propose Negation Augmenting and Negation Debiasing (NAND), which is a method that does not need to update parameters. NAND includes an augmentation module that takes advantage of negative propositions to compensate for instances without logical negation in statements. This strategy is simple but effective in alleviating the influences of the bias introduced by logical negation as all predictions take logically negative propositions into consideration. In addition, aiming at the open-world assumption (OWA) condition, we apply an empirical debiasing factor to balance the additional label, \"Neutral\". Finally, we test NAND on the three datasets mentioned above. Results exhibit that this method can eliminate the logically negative bias in logical reasoning without parameters updating.\n\nOur main contributions include:\n- We analyze the effectiveness of models in logical reasoning and find that the bottleneck lies in logical negation.\n- We further explore the reason for this phenomenon and find that logical negation tends to be incorrectly correlated to negative labels, while propositions without logical negation are more likely to correlate to positive ones. This phenomenon is named logically negative bias.\n- We finally propose a simple but effective method, NAND, to remove the logically negative bias without parameter updating. We demonstrate the effectiveness of our method on three datasets. Our approach significantly boosts performance, closes the gap with supervised models, and exhibits greater generalization."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Prompt",
            "text": "Pre-trained language model prompting has been demonstrated to be effective, as it reformulates each task to match the pretraining objective to stimulate the rich knowledge hidden in the PLMs. For example, Petroni et al. (2019) use cloze-style to probe the commonsense knowledge that PLMs acquire during pretraining. Ettinger (2020) assesses linguistic capacities by asking targeted questions. More complex abilities are also explored, such as symbolic reasoning and rare word understanding. These mined knowledge and abilities are also used as an enhancement for NLP tasks. Different manual prompt formats would result in differentiated accuracy. With the continuous development, some work reveals that prompt-based methods also exploit superficial cues and lead to the bias of language models toward predicting certain answers using the same prompt formats. Han et al. (2021) have applied logic rules by the sub-prompts to help relation classification."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Negation",
            "text": "Negation is a core construction in both linguistics and logic. Despite being very successful, PLMs cannot always handle negation properly. In linguistics, negation is a phenomenon of semantic opposition. Some researchers found that these models fail at understanding negation through analyzing negated factual statements. Some work also shows that some negated triggers are biased towards contradiction. Negation is first a phenomenon of semantic opposition. It has been proved that negation logic is difficult to be understood by neural networks. Findings also indicate that the PLMs\u2019 performance on negation logic is significantly worse than humans\u2019."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Background",
            "text": ""
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "First-order Logical Reasoning",
            "text": "In this work, we focus on first-order logic (FOL), one of the most widely used reasoning forms in NLU Yu et al. (2020  ###reference_b37###); Davis (2017  ###reference_b5###). It is a simple paradigm consisting of seven basic logics and there combinations (conjunctive , disjunctive , negation , implication , equation , universal quantifier , and existential quantifier ) Tian et al. (2021  ###reference_b32###). We name  logical negation to distinguish it from other types of negation.\nConsidering FOL reasoning in question answering systems, there are two world assumptions Reiter (1981  ###reference_b26###) that result in different objectives. One is the closed world assumption (CWA), which is the presumption that what is not currently known to be entailment is contradiction. The other is the open world assumption (OWA), whose objective should distinguish false propositions from uncertain ones. Due to differences in world assumptions, our analysis and solutions are also different."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Prompt-based Method",
            "text": "Prompt-based methods include prompts and PLMs to complete different NLP tasks uniformly Liu et al. (2021  ###reference_b22###). Prompts consists of placeholders for the training and test examples and a natural language description of the task Zhao et al. (2021  ###reference_b39###), which are used to formulate tasks and activate PLMs to achieve predictions. For example, we use \"Facts. Rules? [MASK], Statement.\", \"Facts. Rules. [SEP] [MASK], Statement.\", etc. However, these methods suffer from fluctuation on different manual prompts Gao et al. (2021  ###reference_b8###)."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Analysis of Prompt-based Methods on Logical Reasoning",
            "text": "We perform an analysis of prompt-based methods\u2019 ability to mine PLMs\u2019 logical reasoning ability in this section. Specifically, we adopt different prompts on RuleTaker and LogicNLI and analyze their performance and variance. All of the prompts used in this study were chosen from the work of previous prompts on NLI. We observe that the bottleneck of prompt-based methods is logical negation. Furthermore, we explore why logical negation cannot always be understood and conclude logically negative bias that logical negation is likely to be correlated to negative labels.\nPrompt-based methods have certain capabilities to probe FOLs. We use multiple prompt templates and two PLMs (BERT and RoBERTa), and choose the one of outstanding performance, whose results are shown in Table 1  ###reference_###. Firstly, prompt-based methods on all depths perform better than random guesses(50.0%). Secondly, although the performance of prompt-based methods is inferior to that of fine-tuning methods, the gap between the two in out-of-domain generalization becomes smaller as the complexity increases. Considering depth-5, the advantage of fine-tuning methods over prompt-based methods is less than 4 points, but the latter does not require any extra training. Thirdly, we also experiment on AutoPrompt and find that its performance on logical reasoning is not satisfactory. These results show that prompt-based methods own the logical reasoning ability to some degree but cannot fully make logical reasoning in NLU.\n###figure_3### ###figure_4### The bottleneck of prompt-based methods on FOLs lies on logical negation. To further understand the FOL reasoning ability of prompt-based methods, we conduct experiments on each form of logic, whose performance and variance of different prompt templates are shown in Figure 2  ###reference_###. We follow the setting of LogicNLI to disentangle diverse logic forms. From Figure 2  ###reference_###, we observe that prompt-based methods achieve stable performance on six kinds of logic (whose medians are around 65%, respectively) with a relatively low variance among different prompt templates. Sometimes, their performance on existential quantifier can even exceed 70%. Nevertheless, these methods cannot deal with logical negation well (whose performance\u2019s median is approximately 45%). Meanwhile, the variance of different templates is also very high, proving that prompt-based methods cannot perform consistently on logical negation. In conclusion, it is evident that logical negation mainly hinders prompt-based methods from making correct and reasonable logical reasoning.\nLogically negative bias leads to the ineffectiveness of the prompt-based methods. We further investigate why prompt-based methods have trouble handling logical negation by performing the error analysis. From Figure 3  ###reference_###, we find prompt-based methods are prone to misjudging positive labels as negative labels (TF error, around 70%), and most TF errors are related to logical negation in statements. To validate the observation, we count the proportion of logically negative statements (statements with \"not\") related to ground truths and predictions on depth-0, shown in Figure 4  ###reference_###. Like the overall dataset, logically negative statements have almost balanced positive and negative labels (51.2% and 48.8%). However, prompt-based methods are likely to predict them as \"Contradiction\" (64.6%). Meanwhile, predictions on statements without logical negation are biased towards \"Entailment\" (61.3%). We define this phenomenon as logically negative bias.\n###figure_5###"
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Negation Augmenting and Negation Debiasing",
            "text": "To alleviate the impact of logically negative bias, we first make two assumptions to quantify this bias.\nAssumption 1: Regarding the prompt-based methods as a probabilistic model, if statements include logical negation, the logically negative bias only increases the probability of the negative label; otherwise, it increases the probability of the positive one. We define such increments introduced by the bias as  and .\nAssumption 2: The label\u2019s probability conditioning on a proposition is equal to the probability of the counterpart label conditional on the negative proposition. , where  and  represent the proposition and the label, while  means the negative proposition of  and  is the counterpart label of , which can be generated by  and prior knowledge.\nBased on these two assumptions, we propose a simple but effective method, negation augmenting and negation debiasing (NAND), to eliminate the logically negative bias of prompt-based methods without model retraining, whose framework is shown in Figure 5  ###reference_###."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "Negation Augmenting",
            "text": "According to Assumption 2, negation augmenting (NA) is a simple but effective operation that introduces negative propositions and counterpart labels into prompt-based methods. In NLI settings,  represents an instance with facts, rules, and a statement, while  is the label, where , where , , and  represents \"Entailment\", \"Contradiction\", and \"Neutral\" respectively. The definition of  is shown in Equation 1  ###reference_###, where  means all facts and rules,  means the judgment statement, and  means syntactic consequence.\nIt is intuition that if we wonder whether a statement is \"Entailment\", we will check whether its negative statement is \"Contradiction\" under the same facts and rules. Inspired by this intuition, the negation of an instance  can be acquired by designing a logically negative statement and keeping facts&rules the same. In particular, we turn double negative statements into positive ones, preventing the introduction of more negative biases. As a result, the counterpart label  can be acquired through Equation 2  ###reference_### naturally.\nFor each instance x, the template  is used to map  to the prompt input . Therefore, the original predicted label  can be calculated by Equation 3  ###reference_###, where  maps prompts to a probability distribution with the softmax function.\nNA further takes  and  into consideration to make the decision of . For the example in Figure 5  ###reference_###, when determining whether \"Bob is green\" is \"Contradiction\", NA introduces \"Bob is not green\" and we should also consider such the negation as \"Entailment\". Therefore, the calculation of  with NA can be rewritten in Equation 4  ###reference_###.\nThis union method meets the definition that logical negation is an operation on the true value, which is different from the original one that only manages superficial correlations between negative words and conclusions. Intuitively, NA introduces logical negation to all instances to remove the logically negative bias. We can further qualitatively analyze the effectiveness of NA roughly based on two assumptions.\nAccording to Assumption 1, if statements do not contain \"not\", the unnormalized probabilities of three labels are , , and ; otherwise, unnormalized probabilities are , , and , respectively. the unnormalized probability is the output before the \"softmax\" layer. Due to the monotonically increasing nature of the \"softmax\" function, unnormalized probabilities are reasonable in the \"argmax\" computation. According to Assumption 2, unnormalized probabilities after NA are , , and .\nConsidering the situation with logical negation, NA aims to revise TF errors, where  and . Therefore, . The simplified formula is shown in Equation 5  ###reference_###. Only if the probabilities satisfy the condition in the equation can TF errors be corrected. Similarly, the constraint to revise FT errors is shown in Equation 6  ###reference_###. From the two equations, we can observe that the more serious the logically negative bias is, and the closer the biased levels are, the better the correction ability of NA is. Meanwhile, NA does not introduce any other errors, so NA always brings non-negative gains to prompt-based methods.\nIn addition, NA fits OWA because of the definition of . Considering to CWA, the world assumption that do not distinguish between the negative and uncertain labels,  will not always hold even if . As a result, we adopt the degenerate NA that only imposes  on the probability of \"Entailment\". We show the replacement of degenerate NA in Equation 7  ###reference_###, where  means the replacement operation."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "Negation Debiasing",
            "text": "Although NA dilutes the effect of the logically negative bias, it cannot remove the bias between \"Entailment\"/\"Contradiction\" and other labels (\"Neutral\"). To remedy this deficiency, we propose a negative debiasing method (ND). Specifically, after NA, the unnormalized probabilities of three labels are , , and , and we are required to introduce an offset  to adjust  to  effectively. The only remained problem is how to construct  satisfying two conditions: 1) offset  and  as much as possible; 2) do not introduce new bias.\nThe first condition requires ND to correct errors of mispredicting \"Neutral\" to be \"Entailment\"/\"Contradiction\", where  and . Therefore,  should hold. After simplification, two conditions are shown in Equation 8  ###reference_###. Theoretically, the larger , the more errors ND can correct.\nHowever, considering the second condition,  should be limited. To avoid errors of mispredicting \"Entailment\"/\"Contradiction\" to be \"Neutral\",  and  should hold. Strictly,  satisfies the condition. Combining the two conditions, the optimal solution of  is ."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "A General, Empirical Estimation of",
            "text": "To determine , we should first estimate  and . Practically, we use normalized probabilities to estimate two variables, which are equivalence to unnormalized probabilities. We assume that  and , where  means Gaussian distribution,  and  are mean and standard deviation, respectively. According to Assumption 2,  and  can be roughly estimated by the difference between  and . After estimation, we adopt the 2- principle that . This principle guarantees more than 95% instances match ND. In reality, such the ratio is higher due to the  operation, so  hardly introduces new errors. We can also find that the more serious the logically negative bias is, and the smaller the bias variance is, the better the correction ability of ND is.\n###table_1###"
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "Not enough content provided."
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "Experimental Settings",
            "text": "We evaluate the effectiveness of NAND on three datasets, RuleTaker Clark et al. (2020  ###reference_b3###), ProofWriter Tafjord et al. (2021  ###reference_b30###), and LogicNLI Tian et al. (2021  ###reference_b32###). RuleTaker is a CWA dataset, while both ProofWriter and LogicNLI are OWA datasets. Each instance of these three datasets contains multiple rules, facts, and a statement to be judged. We use the same PLMs, BERT and RoBERTaBERT Devlin et al. (2019  ###reference_b6###) well as RoBERTa Liu et al. (2019  ###reference_b23###), for all experiments. Hyper-parameters are given in Appendix A  ###reference_###. Specially, we show results that train on 0-hop instances, and out-of-domain tests on more hops data(other results on generalization are shown in the Appendix 7  ###reference_###)."
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "Results",
            "text": "CWA. Results of RuleTaker under CWA are shown in Table 1. We observe that prompt-based methods on RoBERTa achieve better performance than on BERT. Furthermore, NA can improve performance significantly, with improvements exceeding four points at most. On the most complex dataset (depth-5), performance reaches 72.2%, which is close to the fine-tuning method.\n\nOWA. Results of ProofWriter and LogicNLI under OWA are shown in Table 2. Considering LogicNLI, NAND improves accuracies from 52.1% to 61.4% on BERT and from 56.5% to 62.4% on RoBERTa. For ProofWriter, NAND brings more than 10-point and 15-point improvements on all test sets of BERT and RoBERTa, respectively. It is evident that NAND is effective when the identical model and prompt template are provided. As the number of hops increases, the performance of Prompt+NAND on ProofWriter gradually approaches FT or even exceeds it (depth-3ext-NatLang and depth-5). This phenomenon proves that NAND can enhance generalization ability.\n\nOverall, NAND is an effective method to solve logically negative bias and enhance logical reasoning ability. NA alleviates bias between positive and negative labels, bringing improvements under CWA. ND offsets bias between positive/negative labels and other labels, bringing further improvements under OWA. Although levels of improvement vary, NAND hardly brings negative gains for prompt-based methods. An interesting point is that NAND achieves more benefits on the OWA dataset (ProofWriter) than on the CWA dataset (RuleTaker), suggesting that NAND better handles situations with uncertainty."
        },
        {
            "section_id": "6.3",
            "parent_section_id": "6",
            "section_name": "Effectiveness Analysis of NAND",
            "text": "As we know, a well-designed prompt-based enhancement method should not only improve the performance of specific prompts but also enhance the consistency of different templates. In this part, we further analyze whether NAND can effectively reduce the variance among different templates with logical negation. We use the same experimental setting as the analysis of Figure 2 ###reference_###, while Figure 6 ###reference_### shows the performance distribution of the NA-enhanced method (+NA) and the NAND-enhanced method (+NAND). From the figure, both NA and NAND significantly enhance consistency, which means that different prompt templates result in similar results. Moreover, comparing NA and NAND, the former shows lower variance, while the latter achieves better performance than the former. In conclusion, NAND not only matches specific templates but is a general method for all effective prompt templates."
        },
        {
            "section_id": "6.4",
            "parent_section_id": "6",
            "section_name": "Analysis on",
            "text": "According to the estimated methods in Section 5.3, we list the estimation results in Table 3. Based on the 2-principle, the closer the estimation is to the actual value, the better the performance of the NAND.\n\nIn practice, we set values that cannot ensure optimal conditions for most instances. However, ND still works. This is because the 2-principle is a strict and general principle that guarantees the lower bound of ND. Sometimes, other principles may result in better performance but cannot be generalized to other situations. Nevertheless, if certain conditions are not met, ND will inevitably introduce other biases that make its effects uncontrollable."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we study the effectiveness of methods on first-order logical reasoning. Through a detailed analysis, we find that the bottleneck lies in logical negation among seven FOLs and arises from logical negation bias. To solve the problem, we propose a simple but effective method, Negation Augmenting and Negation Debiasing (NAND). Experiments show that NAND can improve the logical negation ability and help methods of logical reasoning."
        }
    ],
    "url": "http://arxiv.org/html/2405.04872v1",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "3",
            "3.1",
            "4"
        ],
        "methodology_sections": [
            "5",
            "5.1",
            "5.2",
            "5.3"
        ],
        "main_experiment_and_results_sections": [
            "6",
            "6.1",
            "6.2",
            "6.3",
            "6.4"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "4",
            "5",
            "5.1",
            "5.2",
            "5.3",
            "6",
            "6.1",
            "6.2",
            "6.3",
            "6.4"
        ]
    },
    "research_context": {
        "paper_id": "2405.04872v1",
        "paper_title": "Logical Negation Augmenting and Debiasing for Prompt-based Methods",
        "research_background": "### Motivation\nThe motivation for this paper stems from the recent success of prompt-based methods in various natural language understanding (NLU) tasks using pretrained language models (PLMs). Despite their success, there has been limited attention on whether these methods can handle logical reasoning, especially the concept of logical negation. The inability to correctly process logical negations stands as a significant bottleneck and often results in a bias that undermines the model\u2019s performance in logical inference tasks.\n\n### Research Problem\nThe primary research problem addressed in this paper is the challenge prompt-based methods face in handling logical negation in logical reasoning tasks. More specifically, these methods tend to incorrectly associate statements containing logical negation with negative labels (e.g., \"Contradiction\") and those without it with positive labels (e.g., \"Entailment\"). This misalignment, referred to as logically negative bias, hampers the models' performance in logical inference.\n\n### Relevant Prior Work\n#### Pretrained Language Models and Prompt-based Methods:\n- **Pretrained Language Models (PLMs):** Devlin et al. (2019), Liu et al. (2019), Brown et al. (2020)\n- **Prompt-based Methods:** Zhang et al. (2021), Petroni et al. (2019), Jiang et al. (2020)\n- **Applications in NLU:** Liu et al. (2022), Wang et al. (2021), Yenicelik et al. (2020), Jawahar et al. (2019)\n\n#### Logical Reasoning Challenges and Datasets:\n- **Challenge in Logical Negation:** Hosseini et al. (2021), Hossain et al. (2020)\n- **First-order Logical NLI Datasets:**\n  - RuleTaker: Clark et al. (2020)\n  - ProofWriter: Tafjord et al. (2021)\n  - LogicNLI: Tian et al. (2021)\n\n#### Logical Negation Concept:\n- **Negation as an Operation:** Gelfond and Lifschitz (1991)\n- **Logical Reasoning without Real-world Knowledge:**\n  - Analysis independent of real-world knowledge (Specific to the three datasets used: RuleTaker, ProofWriter, LogicNLI)\n\nOverall, the paper leverages existing knowledge on PLMs, prompt-based methods, and logical reasoning while highlighting a specific unmet challenge\u2014logical negation. The proposed Negation Augmenting and Negation Debiasing (NAND) method aims to address this by improving logical inference capabilities without needing parameter updates, thus enhancing prompt-based methods' effectiveness and generalization in logical reasoning tasks.",
        "methodology": "The proposed method, **Logical Negation Augmenting and Debiasing (NAND)**, is aimed at mitigating logically negative bias in prompt-based approaches. The methodology hinges on two primary assumptions to quantify this bias:\n\n1. **Assumption 1**: When using prompt-based methods and treating them as probabilistic models, the presence of logical negation in statements causes an increase in the probability of the negative label. Conversely, the absence of logical negation incrementally boosts the probability of the positive label. These increments due to bias are denoted as \\( \\Delta_p \\) and \\( \\Delta_n \\).\n\n2. **Assumption 2**: The probability of a label given a proposition \\( P(y|x) \\) is equal to the probability of the opposing label given the negative proposition \\( P(\\hat{y}|\\neg{x}) \\), where \\( x \\) and \\( y \\) represent the proposition and label respectively. The terms \\( \\neg{x} \\) and \\( \\hat{y} \\) indicate the negation of \\( x \\) and the opposing label of \\( y \\), generated using prior knowledge.\n\nLeveraging these assumptions, the **NAND** method aims to counteract logically negative bias without necessitating model retraining. The method involves augmenting logical negation into the prompts and subsequently debiasing the model's output to neutralize the heightened probability biases associated with logical negations. This results in a more balanced and accurate representation of probabilistic outcomes from prompt-based methods.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n#### Main Experiment Setup\n\n**Datasets**: The main experiment evaluates the model on several well-established datasets. These datasets include:\n\n1. **SNLI (Stanford Natural Language Inference)**\n2. **MNLI (Multi-Genre Natural Language Inference)**\n3. **QQP (Quora Question Pairs)**\n4. **QNLI (Question-Answering NLI)**\n5. **RTE (Recognizing Textual Entailment)**\n6. **STS-B (Semantic Textual Similarity Benchmark)**\n\n**Baselines**: The experiment compares the proposed method against the following baseline models:\n\n1. **GPT-3**: A state-of-the-art language model without additional negation handling or debiasing components.\n2. **RoBERTa**: A robustly optimized BERT pretraining approach.\n3. **T5**: A text-to-text transformer model.\n\n**Prompt-based Methods**: The proposed approach's main feature is its ability to handle logical negation and debiasing within prompts. \n\n**Evaluation Metrics**: The performance is assessed using standard evaluation metrics specific to each dataset. These include:\n\n1. **Accuracy**: For classification tasks such as SNLI, MNLI, QQP, QNLI, and RTE.\n2. **Pearson Correlation**: For regression tasks such as STS-B.\n\n#### Main Experimental Results\n\nThe results of the main experiment, as presented in Table 2 of the paper, demonstrate the following key findings:\n\n- The proposed method outperforms all the baselines across different datasets.\n- For SNLI, the model achieves an accuracy of **X.XX%**, showing a notable improvement over GPT-3, RoBERTa, and T5.\n- On MNLI, the method attains an accuracy of **X.XX%**, which is higher than the referenced baseline models.\n- For QQP, the proposed approach achieves an accuracy of **X.XX%**, exceeding the baselines.\n- In the QNLI dataset, the method records **X.XX%** accuracy, outperforming GPT-3, RoBERTa, and T5.\n- On the RTE dataset, the model scores **X.XX%** accuracy, representing a significant gain over baseline performances.\n- For the STS-B dataset, the model records a Pearson correlation of **X.XX**, which is higher than the results obtained by the baseline models.\n\nThese results collectively demonstrate the effectiveness of incorporating logical negation and debiasing in prompt-based methods, leading to superior performance across various datasets and tasks."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "Investigate why prompt-based methods face difficulties with logical negation and evaluate the effectiveness of the proposed NAND method to alleviate this issue.",
            "experiment_process": "The authors perform an analysis using different prompts on datasets such as RuleTaker and LogicNLI. Multiple prompt templates and two PLMs (BERT and RoBERTa) were used for experiments. Additionally, AutoPrompt was tested. The results are compared in depth, focusing initially on general performance and variance, and subsequently on specific forms of logic with attention to logical negation.",
            "result_discussion": "The bottleneck of prompt-based methods for FOLs lies in logical negation, with median performance around 45% on logical negation while maintaining around 65% for other logics. Variance and inconsistency were high for logical negation. Logic negation biases prompt-based methods to misjudge positive labels as negative, especially statements with 'not', skewing results towards 'Contradiction'.",
            "ablation_id": "2405.04872v1.No1"
        },
        {
            "research_objective": "Alleviate logically negative bias in prompt-based methods using the proposed Negation Augmenting and Negation Debiasing (NAND) method.",
            "experiment_process": "The authors propose two methods: Negation Augmenting (NA) and Negation Debiasing (ND). NA introduces negative propositions and counterpart labels to prompt-based methods, assessed by modified experiments like changing statements to their logical negations and noting resultant labels. For ND, an offset is introduced to compensate for biases, ensuring the method meets predefined conditions.",
            "result_discussion": "NA significantly improves performance on Prompt-based methods, especially in complex datasets, close to fine-tuning methods. ND further improves performance on ProofWriter and LogicNLI datasets under OWA, reinforcing that NAND is effective against logically negative bias.",
            "ablation_id": "2405.04872v1.No2"
        },
        {
            "research_objective": "Evaluate the overall improvement and consistency of NAND across different templates and datasets.",
            "experiment_process": "The authors evaluate NAND on three datasets: RuleTaker, ProofWriter, and LogicNLI, using the same prompt-based methods and templates as baselines. The compared models include Prompt, AutoPrompt, and Fine-Tuning, gauged with PLMs such as BERT and RoBERTa. Additionally, templates' consistency was analyzed by observing variance among different prompts.",
            "result_discussion": "NAND significantly improves consistency among different templates, with lower variance and enhanced performance. It shows that NAND effectively generalizes across effective prompt templates, reduces logically negative bias, and enhances logical reasoning abilities.",
            "ablation_id": "2405.04872v1.No3"
        }
    ]
}