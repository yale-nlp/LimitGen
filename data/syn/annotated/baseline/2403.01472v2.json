{
    "title": "WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection",
    "abstract": "Embedding as a Service (EaaS) has become a widely adopted solution, which offers feature extraction capabilities for addressing various downstream tasks in Natural Language Processing (NLP). Prior studies have shown that EaaS can be prone to model extraction attacks; nevertheless, this concern could be mitigated by adding backdoor watermarks to the text embeddings and subsequently verifying the attack models post-publication.\n\nOur defense approach, WARDEN, notably increases the stealthiness of watermarks and has been empirically shown to be effective against adversarial attacks. The code is available at https://github.com/anudeex/WARDEN.git.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Nowadays, Large Language Models (LLMs), due to their vast capacity, have showcased exceptional proficiency in comprehending and generating natural language and proven effective in many real-world applications. Using them as EaaS in a black-box API manner has become one of the most successful commercialization paradigms. Consequently, the owners of these models, such as OpenAI, Google, and Mistral AI, have initiated the provision of EaaS to aid users in various NLP tasks. For instance, one notable provider, OpenAI, with over 150 million users, recently released more performant, cheaper EaaS models.\n\nGiven the recent success of EaaS, the associated vulnerabilities have started to attract attention in security and NLP communities. As a primary example, model extraction attack, a.k.a. imitation attack, has been proven to be effective in stealing the capability of LLMs. To conduct such attacks, the attackers query the victim model and then train their own model based on the collected data. Attackers usually invest far less cost and resources than victims to provide competitive services. Therefore, it is imperative to defend against them, and the most popular tactic is to implant statistical signals (or watermarks) via backdoor techniques.\n\nBeyond intellectual property (IP) infringement, further vulnerabilities have been exposed, such as privacy breaches, more performant surrogate models, and transferable adversarial attacks. As a result, backdoor watermarks are added to EaaS embeddings enabling post-attack lawsuits because the attack models inherit the stealthy watermarks, which could be utilized by EaaS providers to identify them. The first work of this kind uses a pre-determined embedding (vector) as the watermark, which is then incorporated into text embeddings in proportion to trigger words. The primary requirements for watermarking methods include: (i) they should not lower the quality of the original application, and (ii) it should be difficult for malicious users to identify or deduce the secret watermark vector.\n\nOur first work, CSE attack, challenges the aforementioned second point. It involves creating a framework CSE (Clustering, Selection, Elimination) that selects the suspected embeddings with watermarks by comparing the distortion between embedding pairs of the victim model and a benchmark model, then neutralizes the impact of the watermark on the embeddings. Empirical evidence demonstrates that CSE successfully compromises the watermark while preserving high embedding utility. To mitigate the effects of CSE, our second work introduces WARDEN, a multi-directional Watermark Augmentation for Robust DEfeNse mechanism, which uses multiple watermark embeddings to reduce the chance of attackers breaching all of them. We notice that WARDEN, even with a limited number of watermarks, is successful in countering CSE. Moreover, we design a corresponding verification protocol to allow every watermark the authority to verify copyright violations.\n\nOur main contributions are as follows:\n- We propose CSE (Clustering, Selection, Elimination) framework that breaches the recent state-of-the-art watermarking technique for EaaS, and we conduct extensive experiments to evaluate its effectiveness.\n- We design WARDEN to enhance the backdoor watermarks by considering various watermark vectors and conditions. Our studies suggest that the proposed defense method is more robust against CSE on various datasets."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Imitation Attacks",
            "text": "Imitation attacks (Krishna et al., 2020; Orekondy et al., 2019; Yue et al., 2021; Wallace et al., 2020) can replicate cloud models without needing access to their internal parameters, architecture, or training data. This attack strategy involves querying the victim model and then training a surrogate model that mimics the victim based on the API's responses (Chandrasekaran et al., 2020; Tram\u00e8r et al., 2016). Liu et al. (2022) highlighted that publicly available cloud EaaS APIs are susceptible to these imitation attacks. This vulnerability presents a significant threat to EaaS providers, as attackers can quickly duplicate the deployed model with little time and financial resources. Alarmingly, such surrogate models can outperform the original victim models (Xu et al., 2022), especially when factors such as victim model ensemble and domain adaptation come into play. These surrogate models can be used to launch a similar API at a lower price, infringing on intellectual property rights and negatively impacting the market."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Backdoor Attacks and Watermarks",
            "text": "Backdoor attacks involve inserting textual triggers into a target model such that the victim model behaves normally until the backdoor is activated. Recent works have shown that pre-trained LLMs are susceptible to backdoor attacks and transferable to downstream tasks.\n\nRecent research has utilized backdoor as the essential technology to integrate verifiable watermark information in deep learning models, especially LLMs. The reason is that other techniques, such as altering model parameters, need white-box access and are non-transferable in model extraction attacks. Similarly, lexical watermarks do not work on embeddings in the EaaS use case. Drawing inspiration from backdoor attacks, one can correspond EaaS embeddings to a pre-defined watermark when trigger conditions are satisfied."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Methodology",
            "text": "In this section, we present an overview of the conventional backdoor watermark framework to counter model extraction attacks and then proceed to a detailed design of our CSE attack. Next, we explain WARDEN, the multi-directional watermark extension to the previous watermarking technique.\n\nWe employ clustering algorithms to organize the embeddings in the dataset (retrieved by attackers) into groups. This enhances the subsequent selection step by: (i) improving the efficiency of calculating pair-wise distance within smaller sets of embeddings, and (ii) providing distinct groups of poisoned data entries, which facilitates the identification of more anomalous pairs. The K-Means algorithm is used as the primary clustering approach, and the effectiveness of other clustering methods is discussed in Appendix C.1. However, clustering alone is not sufficient for filtering out the watermarked embeddings. For instance, it can be observed from the contour lines in Figure 3 that watermarked samples are spread across clusters and inconspicuous. Furthermore, the centroids of the watermarked samples and overall clusters do not coincide. To counteract this, we propose the selection module to identify the most suspicious embeddings with the watermark.\n\nWe introduce a hold-out standard model (or benchmark model). Within each cluster, we conduct pairwise evaluations on the corresponding embeddings (provided embedding) and (standard embedding). Those with distinctive distance changes are considered suspected samples.\n\nGiven the suspicious embeddings that are potentially watermarked from the previous step, we hypothesize that the watermark can be identified and recovered in suspicious embeddings\u2019 top principal components because the target embedding would be common among them. Following this idea, we propose an elimination algorithm, composed of two steps. First, we apply singular value decomposition (SVD) to analyze and identify the top principal components. Then, the contribution of these components is iteratively eliminated using the Gram-Schmidt (GS) process. The elimination step for each principal component vector is demonstrated as follows: \n\nIn the projection function, is projected onto the -th principal component, denoted as. Here, is initialized with . After each iteration, is acquired by normalizing such that .\n\nTo diversify the possibility of watermark directions (or target embeddings), we introduce multiple watermarks. This strategy increases the difficulty of inferring all of them via the elimination module in the CSE attack. These watermarks remain confidential on servers and can be subject to regular updates. We randomly split the trigger words set into independent subsets for watermarks. The trigger counting function is the frequency of trigger words in the set with a maximum threshold.\n\nWe add watermarks to the original embedding for text to generate the corresponding embedding as follows:\n\nBecause we split for multiple watermarks, the proportion of watermarked samples is independent and is the same as in the single watermark case. Due to weight values being implicitly normalized, where is watermark weight used on a single trigger set.\n\nWe adopt a conservative approach to copyright verification with multiple watermarks, i.e., if any watermark confidently flags IP infringement, we consider it positive. Hence, we build verification datasets, backdoor texts, and benign text as follows:\n\nThe premise is that embeddings for these backdoor texts will be closer to their corresponding target embedding in contrast to benign texts in the case of watermarks. We leverage this behavior of embedding backdoors to verify copyright infringement at each watermark level. We quantify the closeness by computing cosine similarity and squared distance between target embeddings and embeddings of the backdoor and benign texts.\n\nThe copyright detection performance is evaluated by taking the difference of averaged cosine similarity and averaged squared distance. Furthermore, we compute using the Kolmogorov-Smirnov (KS) test, which compares these test value distributions. We aim to reject the null hypothesis: The two cosine similarity value sets are consistent.\n\nWe evaluate these three metrics independently for all the watermarks and then combine them.\n\nThe core idea is that overall infringement can be certified by the infringement of any one of the target watermarking embeddings."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Preliminary",
            "text": "Malicious attackers target the EaaS victim service by sending texts as queries to receive corresponding original embeddings. Considering the threat of model extraction attacks, the victim backdoors original embedding using a watermarking function to inject an additional pre-defined embedding to return provided embedding. Then, the attack model is trained on the embeddings received by querying, and the attacker provides a competitive service based on the model. Copyright protection is feasible when the system adheres to these criteria: (i) the original EaaS provider should be able to query the attack model to verify if it has imitated the original model; (ii) the utility of provided embeddings is comparable to that of the original model for downstream tasks."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "CSE Attack Framework",
            "text": "This section outlines our Clustering, Selection, and Elimination (CSE) attack, as the framework shown in Figure 2. This approach aims at (i) identifying the embedding vectors most likely to contain the watermark and (ii) eliminating the influence of the watermark while preserving the essential semantics within the embeddings.\n\nWe first employ clustering algorithms to organize the embeddings in the dataset (which attackers have retrieved) into groups. This action enhances the subsequent selection step by: (i) improving the efficiency of calculating pair-wise distance within smaller sets of embeddings, and (ii) providing distinct groups of poisoned data entries, which facilitates the identification of more anomalous pairs. K-Means algorithm is used as the primary clustering approach, while we discuss the effectiveness of other clustering methods in Appendix C.1. Nevertheless, clustering solely is not sufficient for filtering out the watermarked embeddings. For instance, we can observe from the contour lines in Figure 3 that watermarked samples are spread across clusters and inconspicuous. Furthermore, the centroids of the watermarked samples and overall clusters do not coincide. To counteract this, we thus propose the selection module to identify the most suspicious embeddings with the watermark.\n\nWe denote the victim model as  and introduce another hold-out standard model (or benchmark model) as . Within each cluster , we conduct pairwise evaluations on the corresponding embeddings  (provided embedding) and  (standard embedding). Those with distinctive distance changes are considered suspected samples.\n\nGiven the suspicious embeddings that are potentially watermarked from the previous step, we hypothesize that the watermark can be identified and recovered in suspicious embeddings\u2019 top principal components because the target embedding would be common among them. Following this idea, we propose an elimination algorithm, composed of two steps. First, we apply singular value decomposition (SVD) to analyze and identify the top principal components. Then, the contribution of these components are iteratively eliminated using the Gram-Schmidt (GS) process. The elimination step for each principal component vector is demonstrated as follows:\n\nIn the projection function, is projected onto the -th principal component, denoted as\n\nHere,  is initialized with . After each iteration,  is acquired by normalizing  such that ."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "WARDEN Defense Framework",
            "text": "In response to the successful CSE attack, we propose Watermark Augmentation for Robust DEfeNse (WARDEN) as a counter measurement, which incorporates multiple directions as watermarking embeddings. To diversify the possibility of watermark directions (or target embeddings), we introduce multiple watermarks. This strategy increases the difficulty of inferring all of them via the elimination module in CSE attack. These watermarks remain confidential on servers and can be subject to regular updates. We randomly split the trigger words set into independent subsets for watermarks. Then, the trigger counting function is the frequency of trigger words in a set with a maximum threshold of a level of watermark.\n\nFinally, we add watermarks to the original embedding for text to generate the corresponding embedding. Because we split the trigger words set for multiple watermarks, the proportion of watermarked samples is independent and is the same as in the single watermark case. Weight values are implicitly normalized, where the watermark weight is used on a single trigger set.\n\nWe adopt a conservative approach to copyright verification with multiple watermarks, i.e., if any watermark confidently flags IP infringement, we consider it positive. Hence, we build verification datasets, backdoor texts, and benign text as follows: The premise is that embeddings for these backdoor texts will be closer to their corresponding target embedding in contrast to benign texts in the case of watermarks. We leverage this behavior of embedding backdoors to verify copyright infringement at each watermark level. We quantify the closeness by computing cosine similarity and squared distance between target embeddings and embeddings of backdoor and benign texts.\n\nThe copyright detection performance is evaluated by taking the difference of averaged cosine similarity and averaged squared distance. Furthermore, we compute the statistic using the Kolmogorov-Smirnov (KS) test as the third metric, which compares these test value distributions. We aim to reject the null hypothesis that the two cosine similarity value sets are consistent. We evaluate these three metrics independently for all the watermarks and then combine them. The core idea is that overall infringement can be certified by the infringement of any one of the target watermarking embeddings."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "To benchmark our attack and defense, we employ standard NLP datasets: Enron Metsis et al. (2006), SST2 Socher et al. (2013), AG News Zhang et al. (2015), and MIND Wu et al. (2020). We use Enron dataset for email spam classification. AG News and MIND are news-based and used for recommendation and classification tasks. We use SST2 for sentiment classification. The statistics of these datasets are reported in Table 1.\n\nTo evaluate different aspects of our techniques, we adopt the following metrics:\n\n(Downstream) Task Performance: We construct a multi-layer perceptron (MLP) classifier with the EaaS embeddings as inputs. The quality of the embeddings is measured by the accuracy and -score of the classifiers on the downstream tasks.\n\n(Reconstruction) Attack Performance: We measure the closeness of reconstructed target embedding(s) with original target embedding(s) by reporting their cosine similarity.\n\n(Infringement) Detection Performance: Following previous work (Peng et al., 2023), we employ three metrics: p-value, difference of cosine similarity, and difference of squared distance. Their customized variations for WARDEN are defined in Section 3.3. Our findings largely rely on this evaluation as it reflects the performance in real-world applications. Additional details are provided in Appendix A.\n\nIn a successful attack, the principal components removed from the embeddings erase the watermark by recovering the target embedding. To validate this conjecture, we model and solve an optimization problem as defined in Equation 9 where a linear combination results in the recovered target embedding. We then calculate cosine similarity to the target embedding. A high cosine similarity demonstrates the technique\u2019s effectiveness.\n\nAn attacker will not be aware whether the model they are trying to imitate is watermarked. Table 4 shows that our attack leads to only minor quality degradation in such scenarios, demonstrating the suitability of our approach. We perform further extensive quantitative and qualitative sensitivity study to investigate how other factors (such as algorithms, parameters, and models) affect the efficacy of our suggested attack in Appendix C.\n\nFigure 5 illustrates the efficiency of employing multiple watermarks, which demonstrates the outstanding performance (yellow and green line upward trend) of WARDEN with increasing use and marginal degradation (blue line) in the downstream utility. Similar patterns are observed in the results on other datasets as detailed in Appendix D.1.\n\nNow, we investigate the effectiveness of WARDEN against attacks as shown in Figure 6. As observed in the previous section, WARDEN is stealthier with increasing watermarks. As expected, the performance of the attack diminishes, correlating with decreasing attack performance (red line). Due to the usage of more watermarks, there is a natural increase in the likelihood that one of them will detect an infringement. Moreover, in extreme scenarios, a mixture of multiple target embeddings will substitute the watermarked samples, reducing the impact of the attack\u2019s exploitation of the semantic distortion in the embeddings.\n\nTo further strengthen WARDEN, we explore the application of the Gram-Schmidt (GS) process on target embeddings, assuming the orthogonal set of watermark embeddings is more distinguishable. In our experiments, as reported in Figure 7, detection performance is stronger after GS selection. In addition, due to orthogonality, the reconstructed target embedding cosine similarities will be significantly lower, indicating potential ineffectiveness of the attack. The corresponding ablation study in Appendix D.1 supports this observation.\n\nSimilar to the experiments for removal of watermarks, we perform WARDEN on non-watermarked models. With strict verification, at high values of , the p-value could be noisy. This may occur as the verification process might find closeness due to genuine semantics instead of backdoors because of a high pool of watermark directions. This could lead to false positives, i.e., incorrectly classifying models as copied. However, other detection metrics remain reliable, aiding entities in making appropriate decisions. This is further discussed in Figure 18. We conduct a further detailed ablation study dissecting the WARDEN components and demonstrating its stealthiness in Appendix D."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Experimental Settings",
            "text": "To benchmark our attack and defense, we employ standard NLP datasets: Enron Metsis et al. (2006), SST2 Socher et al. (2013), AG News Zhang et al. (2015), and MIND Wu et al. (2020). We use Enron dataset for email spam classification. AG News and MIND are news-based and used for recommendation and classification tasks. We use SST2 for sentiment classification. The statistics of these datasets are reported in Table 1.\n\nTo evaluate different aspects of our techniques, we adopt the following metrics:\n\n(Downstream) Task Performance: We construct a multi-layer perceptron (MLP) classifier with the EaaS embeddings as inputs. The quality of the embeddings is measured by the accuracy and -score of the classifiers on the downstream tasks.\n\n(Reconstruction) Attack Performance: We measure the closeness of reconstructed target embedding(s) with original target embedding(s) by reporting their cosine similarity.\n\n(Infringement) Detection Performance: Following previous work (Peng et al., 2023), we employ three metrics, i.e., p-value, difference of cosine similarity, and difference of squared distance. Their customized variations for WARDEN are defined in Section 3.3. Our findings largely rely on this evaluation as it reflects the performance in real-world applications.\n\nis detailed in the Appendix A."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "CSE Experiments",
            "text": "CSE is designed to assist model extraction attack bypassing post-publish copyright verification. Hence, we evaluate whether we are able to bypass the copyright verification using the same watermark detection metrics with an opposite objective, i.e., lower p-value and the absolute values of metrics close to zero.\n\nIn a successful attack, the principal components removed from the embeddings erase the watermark. To validate this conjecture, we model and solve an optimization problem as defined in Equation 9  ###reference_###  ###reference_### where a linear combination of results in the recovered target embedding . We then calculate cosine similarity to the target embedding. A high cosine similarity demonstrates the CSE technique\u2019s effectiveness. For CSE, the reconstructed target embedding is extremely (99+% cosine similarity) close to the original target embedding (more in following Section 4.2  ###reference_.SSS0.Px3###  ###reference_.SSS0.Px3###).\n\nAn attacker will not be aware whether the model they are trying to imitate is watermarked. Table 4  ###reference_###  ###reference_### shows that our attack leads to only minor quality degradation for such scenarios, demonstrating the suitability of CSE. We perform further extensive quantitative and qualitative sensitivity study to investigate how other factors (such as algorithms, parameters, and models) affect the efficacy of our suggested CSE attack in Appendix C  ###reference_###  ###reference_###."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "WARDEN Experiments",
            "text": "We illustrate the efficiency of employing multiple watermarks in Figure 5, which demonstrates the outstanding performance (yellow and green line upward trend) of WARDEN with increasing and marginal degradation (blue line) in the downstream utility. The results on other datasets also show similar patterns which can be found in Appendix D.1.\n\nNow, we investigate the effectiveness of WARDEN against CSE (shown in Figure 6). As observed in the previous section, WARDEN is stealthier with increasing watermarks. As expected, the performance of CSE diminishes, correlating with decreasing attack performance (red line). Due to the usage of more watermarks, there is a natural increase in the likelihood that one of them will detect an infringement. Moreover, in extreme scenarios, a mixture of multiple target embeddings will substitute the watermarked samples, reducing the impact of the CSE attack\u2019s exploitation of the semantic distortion in the embeddings.\n\nTo further strengthen WARDEN, we investigate the application of the Gram-Schmidt (GS) process on target embeddings, as we assume the orthogonal set of watermark embeddings are more distinguishable to each other. In our experiments, as reported in Figure 7, the detection performance is stronger after GS selection. In addition, due to orthogonality, the reconstructed target embedding cosine similarities will be significantly lower, indicating CSE might also be ineffective. We observe the same from the corresponding ablation study in Appendix D.1.\n\nSimilar to the experiments for CSE, we perform WARDEN on non-watermarked models. Due to our strict verification, for the high value, the p-value could be noisy. It is because the verification process might find closeness due to genuine semantics instead of backdoors as a result of a high pool of watermark directions. This could lead to false positives, i.e., incorrectly classifying models as copied. However, in such cases, we observe that other detection metrics are reliable, which should aid the entity in making appropriate decisions (refer Figure 18). We conduct a further detailed ablation study dissecting the WARDEN components and showing its stealthiness in Appendix D."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we demonstrate that our new CSE attack can bypass the recent EaaS watermarking technique. CSE cleanses the watermarked dataset by clustering them first, then selecting embedding pairs with disparity, and finally eliminating their top principal components, while maintaining the service utility. To remedy this shortcoming, we propose a simple yet effective watermarking method, WARDEN, which augments the previous approach by introducing multiple watermarks to embeddings. Our intensive experiments show that WARDEN is superior in verifying the copyright of EaaS from prior works. Furthermore, WARDEN is also effective against potent CSE, which shows its resilience to different attacks. We also conduct detailed ablation studies to verify the importance of every component of CSE and WARDEN. Future studies may consider exploring watermark ownership under multi-owner service settings."
        }
    ],
    "appendix": [
        {
            "section_id": "Appendix x1",
            "parent_section_id": null,
            "section_name": "Appendix",
            "text": ""
        },
        {
            "section_id": "Appendix 1",
            "parent_section_id": null,
            "section_name": "Appendix A Experimental Settings",
            "text": "We leverage the standard codebase of the Transformers (Wolf et al., 2020  ###reference_b41###) library and AdamW (Loshchilov and Hutter, 2019  ###reference_b23###) algorithm for model training and development. Likewise, we use scikit-learn (Pedregosa et al., 2011  ###reference_b28###) for clustering algorithms and other utility calculations. We use GPT-3 text-embedding-002 API as original benign embeddings and the BERT (Devlin et al., 2019  ###reference_b8###) model as the victim model.\nWe perform all the experiments on a single A100 GPU with CUDA 11.7 and pytorch 2.1.2. We assume that both the victim model and imitators use the same datasets to separate the effects of the watermarking technique from other factors. Furthermore, we assume that the extracted model is trained only using the watermarked outputs from the victim model.\nFinally, we implement the EmbMarker and other experiments following their default configurations and settings, i.e., . The only exception is the  case in WARDEN, where we use  to have enough trigger words. A standard dataset, WikiText Merity et al. (2016  ###reference_b24###) consisting of  entries, serves as a hold-out dataset for selecting moderate-frequency words as watermark triggers ()."
        },
        {
            "section_id": "Appendix 2",
            "parent_section_id": null,
            "section_name": "Appendix B Similarity Distribution Plots",
            "text": "###figure_13### ###figure_14### ###figure_15### ###figure_16### The observations (captured in  Figure 8  ###reference_###) for other datasets are similar to SST2 as seen in Figure 4  ###reference_###, i.e., watermarked embeddings are closer to target embedding, and there is a clear difference in similarities for watermarked and non-watermarked embeddings. Due to skewness between the number of suspected and unsuspected embeddings, we employ sampling for unsuspected entries in these plots."
        },
        {
            "section_id": "Appendix 3",
            "parent_section_id": null,
            "section_name": "Appendix C CSE Attack Analyses",
            "text": "In this section, we perform detailed ablation studies for CSE attack."
        },
        {
            "section_id": "Appendix 4",
            "parent_section_id": null,
            "section_name": "Appendix D WARDEN Defense Analyses",
            "text": ""
        }
    ],
    "tables": {
        "1": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.1\">Dataset</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.2\"># Train</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.3\"># Test</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.4\"># Class</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.2.1.1\"><span class=\"ltx_text\" id=\"S4.T1.1.2.1.1.1\">SST2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.2.1.2\">67,349</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.2.1.3\">872</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.2.1.4\">2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.3.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.3.2.1\"><span class=\"ltx_text\" id=\"S4.T1.1.3.2.1.1\">MIND</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.3.2.2\">97,791</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.3.2.3\">32,592</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.3.2.4\">18</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.4.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.3.1\"><span class=\"ltx_text\" id=\"S4.T1.1.4.3.1.1\">AG News</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.3.2\">120,000</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.3.3\">7,600</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.3.4\">4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.5.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.5.4.1\"><span class=\"ltx_text\" id=\"S4.T1.1.5.4.1.1\">Enron</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.5.4.2\">31,716</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.5.4.3\">2,000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.5.4.4\">2</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Statistics for classification datasets.</figcaption>\n</figure>",
            "capture": "Table 1: Statistics for classification datasets."
        },
        "2": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T2\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.6\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.6.7.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T2.6.7.1.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T2.6.7.1.1.1\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" colspan=\"3\" id=\"S4.T2.6.7.1.2\">Detection Performance</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S4.T2.2.2.3\">p-value</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.2.2.2\"></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.3.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.3.3.2\"><span class=\"ltx_text\" id=\"S4.T2.3.3.2.1\">SST2</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.3.3.1\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.3.3\">0.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.3.4\">0.01</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.4.4\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T2.4.4.2\"><span class=\"ltx_text\" id=\"S4.T2.4.4.2.1\">MIND</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T2.4.4.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.4.3\">0.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.4.4\">0.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.5.5\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T2.5.5.2\"><span class=\"ltx_text\" id=\"S4.T2.5.5.2.1\">AG News</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T2.5.5.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.5.5.3\">0.09</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.5.5.4\">-0.18</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.6\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T2.6.6.2\"><span class=\"ltx_text\" id=\"S4.T2.6.6.2.1\">Enron</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T2.6.6.1\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.6.6.3\">0.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.6.6.4\">0.01</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Copyright verification can be bypassed when the target direction is known and eliminated\nfrom the provided embeddings.</figcaption>\n</figure>",
            "capture": "Table 2: Copyright verification can be bypassed when the target direction is known and eliminated\nfrom the provided embeddings."
        },
        "3": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T3\">\n<figure class=\"ltx_figure ltx_minipage ltx_align_center ltx_align_middle\" id=\"S4.T3.70\" style=\"width:433.6pt;\">\n<div class=\"ltx_inline-block ltx_transformed_outer\" id=\"S4.T3.64.64\" style=\"width:433.6pt;height:242.2pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-8.8pt,4.9pt) scale(0.961195176023095,0.961195176023095) ;\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T3.64.64.64\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.64.64.64.65.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.64.64.64.65.1.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T3.64.64.64.65.1.1.1\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.64.64.64.65.1.2\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T3.64.64.64.65.1.2.1\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" id=\"S4.T3.64.64.64.65.1.3\">Task Performance</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\" id=\"S4.T3.64.64.64.65.1.4\">Detection Performance</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.4.4.4.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.4.4.4.4.5\">ACC.(%)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.1.1.1\">\n-score</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.2.2.2.2.2\">p-value \n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.3.3.3.3.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.4.4.4.4.4\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.9.9.9.9\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.9.9.9.9.6\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T3.9.9.9.9.6.1\">SST2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.9.9.9.9.7\">Original</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.5.5.5.1\">93.420.13</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.6.6.6.6.2\">93.420.13</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.7.7.7.7.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.8.8.8.8.4\">-0.180.22</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.9.9.9.9.5\">0.370.43</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.14.14.14.14\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.14.14.14.14.6\"><span class=\"ltx_text\" id=\"S4.T3.14.14.14.14.6.1\">EmbMarker</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.10.10.10.10.1\">93.120.12</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.11.11.11.11.2\">93.120.12</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.12.12.12.12.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.13.13.13.13.4\">3.560.50</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.14.14.14.14.5\">-7.111.01</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.19.19.19.19\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.19.19.19.19.6\">\n<span class=\"ltx_text\" id=\"S4.T3.19.19.19.19.6.1\">EmbMarker</span> + <span class=\"ltx_text ltx_font_italic\" id=\"S4.T3.19.19.19.19.6.2\">CSE</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.15.15.15.15.1\">90.460.98</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.16.16.16.16.2\">90.460.98</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.17.17.17.17.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.18.18.18.18.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.18.18.18.18.4.1\">0.99</span>0.40</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.19.19.19.19.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.19.19.19.19.5.1\">-1.97</span>0.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.24.24.24.24\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.24.24.24.24.6\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T3.24.24.24.24.6.1\">MIND</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.24.24.24.24.7\">Original</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.20.20.20.20.1\">77.220.13</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.21.21.21.21.2\">51.370.31</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.22.22.22.22.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.23.23.23.23.4\">-0.690.17</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.24.24.24.24.5\">1.370.35</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.29.29.29.29\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.29.29.29.29.6\"><span class=\"ltx_text\" id=\"S4.T3.29.29.29.29.6.1\">EmbMarker</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.25.25.25.25.1\">77.190.09</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.26.26.26.26.2\">51.400.16</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.27.27.27.27.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.28.28.28.28.4\">4.690.17</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.29.29.29.29.5\">-9.370.33</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.34.34.34.34\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.34.34.34.34.6\">\n<span class=\"ltx_text\" id=\"S4.T3.34.34.34.34.6.1\">EmbMarker</span> + <span class=\"ltx_text ltx_font_italic\" id=\"S4.T3.34.34.34.34.6.2\">CSE</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.30.30.30.30.1\">75.510.16</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.31.31.31.31.2\">50.350.46</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.32.32.32.32.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.33.33.33.33.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.33.33.33.33.4.1\">0.55</span>0.18</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.34.34.34.34.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.34.34.34.34.5.1\">-1.10</span>0.37</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.39.39.39.39\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.39.39.39.39.6\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T3.39.39.39.39.6.1\">AG News</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.39.39.39.39.7\">Original</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.35.35.35.35.1\">93.640.11</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.36.36.36.36.2\">93.640.11</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.37.37.37.37.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.38.38.38.38.4\">0.560.24</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.39.39.39.39.5\">-1.130.48</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.44.44.44.44\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.44.44.44.44.6\"><span class=\"ltx_text\" id=\"S4.T3.44.44.44.44.6.1\">EmbMarker</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.40.40.40.40.1\">93.520.11</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.41.41.41.41.2\">93.52 0.11</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.42.42.42.42.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.43.43.43.43.4\">12.760.43</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.44.44.44.44.5\">-25.520.87</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.49.49.49.49\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.49.49.49.49.6\">\n<span class=\"ltx_text\" id=\"S4.T3.49.49.49.49.6.1\">EmbMarker</span> + <span class=\"ltx_text ltx_font_italic\" id=\"S4.T3.49.49.49.49.6.2\">CSE</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.45.45.45.45.1\">92.870.32</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.46.46.46.46.2\">92.870.32</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.47.47.47.47.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.48.48.48.48.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.48.48.48.48.4.1\">0.27</span>0.30</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.49.49.49.49.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.49.49.49.49.5.1\">-0.55</span>0.60</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.54.54.54.54\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T3.54.54.54.54.6\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T3.54.54.54.54.6.1\">Enron</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.54.54.54.54.7\">Original</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.50.50.50.50.1\">94.730.14</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.51.51.51.51.2\">94.730.14</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.52.52.52.52.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.53.53.53.53.4\">-0.380.38</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.54.54.54.54.5\">0.760.75</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.59.59.59.59\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.59.59.59.59.6\"><span class=\"ltx_text\" id=\"S4.T3.59.59.59.59.6.1\">EmbMarker</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.55.55.55.55.1\">94.610.28</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.56.56.56.56.2\">94.610.28</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.57.57.57.57.3\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.58.58.58.58.4\">5.930.28</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.59.59.59.59.5\">-11.860.56</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.64.64.64.64\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.64.64.64.64.6\">\n<span class=\"ltx_text\" id=\"S4.T3.64.64.64.64.6.1\">EmbMarker</span> + <span class=\"ltx_text ltx_font_italic\" id=\"S4.T3.64.64.64.64.6.2\">CSE</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.60.60.60.60.1\">95.560.21</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.61.61.61.61.2\">95.560.21</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.62.62.62.62.3\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.63.63.63.63.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.63.63.63.63.4.1\">0.59</span>0.33</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.64.64.64.64.5\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.64.64.64.64.5.1\">\n-1.17</span>0.65</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_figure\">Table 3: </span>The performance of <span class=\"ltx_text ltx_font_italic\" id=\"S4.T3.70.79.1\">CSE</span> for different scenarios on <span class=\"ltx_text\" id=\"S4.T3.70.80.2\">SST2</span>, <span class=\"ltx_text\" id=\"S4.T3.70.81.3\">MIND</span>, <span class=\"ltx_text\" id=\"S4.T3.70.82.4\">AG News</span>, and <span class=\"ltx_text\" id=\"S4.T3.70.83.5\">Enron</span> datasets. \u2018Original\u2019 represents a benign victim model, \u2018<span class=\"ltx_text\" id=\"S4.T3.70.84.6\">EmbMarker</span>\u2019 stands for the existing watermarking technique, and \u2018\u2019 is the case where <span class=\"ltx_text ltx_font_italic\" id=\"S4.T3.70.85.7\">CSE</span> is performed on provided embeddings by <span class=\"ltx_text\" id=\"S4.T3.70.86.8\">EmbMarker</span> before doing model extraction (as shown in \u00a0Figure\u00a0<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.01472v2#S1.F1\" title=\"Figure 1 \u2023 1 Introduction \u2023 WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>.c).  denotes higher metrics are better and  denotes lower metrics are better from the attacker\u2019s objective. </figcaption>\n</figure>\n</figure>",
            "capture": "Table 3: The performance of CSE for different scenarios on SST2, MIND, AG News, and Enron datasets. \u2018Original\u2019 represents a benign victim model, \u2018EmbMarker\u2019 stands for the existing watermarking technique, and \u2018\u2019 is the case where CSE is performed on provided embeddings by EmbMarker before doing model extraction (as shown in \u00a0Figure\u00a01.c).  denotes higher metrics are better and  denotes lower metrics are better from the attacker\u2019s objective. "
        },
        "4": {
            "table_html": "<figure class=\"ltx_table\" id=\"S4.T4\">\n<figure class=\"ltx_figure ltx_minipage ltx_align_middle\" id=\"S4.T4.7\" style=\"width:411.9pt;\">\n<div class=\"ltx_inline-block ltx_transformed_outer\" id=\"S4.T4.7.7\" style=\"width:433.6pt;height:165.8pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(75.6pt,-28.9pt) scale(1.53551238329075,1.53551238329075) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.7.7.7\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T4.7.7.7.8.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.7.7.7.8.1.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T4.7.7.7.8.1.1.1\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T4.7.7.7.8.1.2\">Task Performance</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S4.T4.7.7.7.8.1.3\">Detection Performance</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.3.3.3.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.3.3.3.3.4\">ACC.(%)</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.1.1.1.1.1\">\n-score</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.3.3.3.3.5\">p-value</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.2.2.2.2.2\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.3.3.3.3.3\"></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.4.4.4.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.4.4.4.4.2\"><span class=\"ltx_text\" id=\"S4.T4.4.4.4.4.2.1\">SST2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.4.4.4.4.3\">87.04</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.4.4.4.4.4\">87.01</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.4.4.4.4.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.4.4.4.4.5\">0.19</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.4.4.4.4.6\">-0.39</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.5.5.5.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.5.5.5.5.2\"><span class=\"ltx_text\" id=\"S4.T4.5.5.5.5.2.1\">MIND</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.5.5.5.5.3\">74.80</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.5.5.5.5.4\">50.57</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.5.5.5.5.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.5.5.5.5.5\">1.09</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.5.5.5.5.6\">-2.19</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.6.6.6.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.6.6.6.6.2\"><span class=\"ltx_text\" id=\"S4.T4.6.6.6.6.2.1\">AG News</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.6.6.6.6.3\">93.04</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.6.6.6.6.4\">93.04</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.6.6.6.6.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.6.6.6.6.5\">-2.14</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.6.6.6.6.6\">4.29</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.7.7.7.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.7.7.7.7.2\"><span class=\"ltx_text\" id=\"S4.T4.7.7.7.7.2.1\">Enron</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.7.7.7.7.3\">95.45</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.7.7.7.7.4\">95.45</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.7.7.7.7.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.7.7.7.7.5\">-1.28</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.7.7.7.7.6\">2.57</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_figure\">Table 4: </span><span class=\"ltx_text ltx_font_italic\" id=\"S4.T4.7.9.1\">CSE</span> on a non-watermarked victim model, with minimal degradation in downstream utility and copyright detection metrics of an innocent model.</figcaption>\n</figure>\n</figure>",
            "capture": "Table 4: CSE on a non-watermarked victim model, with minimal degradation in downstream utility and copyright detection metrics of an innocent model."
        },
        "5": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T5\">\n<figure class=\"ltx_figure ltx_minipage ltx_align_middle\" id=\"A3.T5.14\" style=\"width:433.6pt;\">\n<div class=\"ltx_inline-block ltx_transformed_outer\" id=\"A3.T5.14.14\" style=\"width:433.6pt;height:222pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(111.4pt,-57.0pt) scale(2.05601491215149,2.05601491215149) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A3.T5.14.14.14\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A3.T5.14.14.14.15.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A3.T5.14.14.14.15.1.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"A3.T5.14.14.14.15.1.1.1\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" colspan=\"3\" id=\"A3.T5.14.14.14.15.1.2\">Detection Performance</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T5.2.2.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"A3.T5.2.2.2.2.3\">p-value</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A3.T5.1.1.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A3.T5.2.2.2.2.2\"></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A3.T5.5.5.5.5\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" id=\"A3.T5.5.5.5.5.4\"><span class=\"ltx_text\" id=\"A3.T5.5.5.5.5.4.1\">SST2</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" id=\"A3.T5.3.3.3.3.1\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T5.4.4.4.4.2\">1.000.40</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T5.5.5.5.5.3\">-2.000.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T5.8.8.8.8\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"A3.T5.8.8.8.8.4\"><span class=\"ltx_text\" id=\"A3.T5.8.8.8.8.4.1\">MIND</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"A3.T5.6.6.6.6.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.7.7.7.7.2\">0.280.31</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.8.8.8.8.3\">-0.550.63</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T5.11.11.11.11\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"A3.T5.11.11.11.11.4\"><span class=\"ltx_text\" id=\"A3.T5.11.11.11.11.4.1\">AG News</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"A3.T5.9.9.9.9.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.10.10.10.10.2\">0.450.42</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T5.11.11.11.11.3\">-0.900.84</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T5.14.14.14.14\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"A3.T5.14.14.14.14.4\"><span class=\"ltx_text\" id=\"A3.T5.14.14.14.14.4.1\">Enron</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"A3.T5.12.12.12.12.1\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T5.13.13.13.13.2\">0.230.52</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T5.14.14.14.14.3\">-0.471.04</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_figure\">Table 5: </span><span class=\"ltx_text ltx_font_italic\" id=\"A3.T5.14.17.1\">CSE</span> performance using GMM clustering algorithm, similar to <span class=\"ltx_text\" id=\"A3.T5.14.18.2\">K-Means</span> algorithm (tabulated in Table\u00a0<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2403.01472v2#S4.T3\" title=\"Table 3 \u2023 Effectiveness Evaluation \u2023 4.2 CSE Experiments \u2023 4 Experiments \u2023 WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>).</figcaption>\n</figure>\n</figure>",
            "capture": "Table 5: CSE performance using GMM clustering algorithm, similar to K-Means algorithm (tabulated in Table\u00a03)."
        },
        "6": {
            "table_html": "<figure class=\"ltx_table\" id=\"A3.T6\">\n<figure class=\"ltx_figure ltx_minipage ltx_align_middle\" id=\"A3.T6.14\" style=\"width:411.9pt;\">\n<div class=\"ltx_inline-block ltx_transformed_outer\" id=\"A3.T6.14.14\" style=\"width:433.6pt;height:499.5pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(107.4pt,-123.8pt) scale(1.98228952161535,1.98228952161535) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A3.T6.14.14.14\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A3.T6.14.14.14.15.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A3.T6.14.14.14.15.1.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"A3.T6.14.14.14.15.1.1.1\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A3.T6.14.14.14.15.1.2\" rowspan=\"2\"><span class=\"ltx_text\" id=\"A3.T6.14.14.14.15.1.2.1\">Size</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"A3.T6.14.14.14.15.1.3\">Detection Performance</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.2.2.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A3.T6.2.2.2.2.3\">p-value</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A3.T6.1.1.1.1.1\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A3.T6.2.2.2.2.2\"></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A3.T6.3.3.3.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T6.3.3.3.3.2\"><span class=\"ltx_text\" id=\"A3.T6.3.3.3.3.2.1\">SST2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T6.3.3.3.3.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"A3.T6.3.3.3.3.3.1\">Small</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T6.3.3.3.3.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T6.3.3.3.3.4\">0.41</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A3.T6.3.3.3.3.5\">-0.81</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.4.4.4.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.4.4.4.4.2\"><span class=\"ltx_text\" id=\"A3.T6.4.4.4.4.2.1\">MIND</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.4.4.4.4.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.4.4.4.4.3\">1.38</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.4.4.4.4.4\">-2.76</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.5.5.5.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.5.5.5.5.2\"><span class=\"ltx_text\" id=\"A3.T6.5.5.5.5.2.1\">AG News</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.5.5.5.5.1\">\n7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.5.5.5.5.3\">-0.08</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.5.5.5.5.4\">0.17</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.6.6.6.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.6.6.6.6.2\"><span class=\"ltx_text\" id=\"A3.T6.6.6.6.6.2.1\">Enron</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.6.6.6.6.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.6.6.6.6.3\">0.63</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.6.6.6.6.4\">-1.27</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.7.7.7.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.7.7.7.7.2\"><span class=\"ltx_text\" id=\"A3.T6.7.7.7.7.2.1\">SST2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.7.7.7.7.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"A3.T6.7.7.7.7.3.1\">Base</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.7.7.7.7.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.7.7.7.7.4\">0.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.7.7.7.7.5\">-0.01</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.8.8.8.8\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.8.8.8.8.2\"><span class=\"ltx_text\" id=\"A3.T6.8.8.8.8.2.1\">MIND</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.8.8.8.8.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.8.8.8.8.3\">-0.01</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.8.8.8.8.4\">0.03</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.9.9.9.9\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.9.9.9.9.2\"><span class=\"ltx_text\" id=\"A3.T6.9.9.9.9.2.1\">AG News</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.9.9.9.9.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.9.9.9.9.3\">0.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.9.9.9.9.4\">-0.01</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.10.10.10.10\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.10.10.10.10.2\"><span class=\"ltx_text\" id=\"A3.T6.10.10.10.10.2.1\">Enron</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.10.10.10.10.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.10.10.10.10.3\">0.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.10.10.10.10.4\">-0.01</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.11.11.11.11\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.11.11.11.11.2\"><span class=\"ltx_text\" id=\"A3.T6.11.11.11.11.2.1\">SST2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"A3.T6.11.11.11.11.3\" rowspan=\"4\"><span class=\"ltx_text\" id=\"A3.T6.11.11.11.11.3.1\">Large</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.11.11.11.11.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.11.11.11.11.4\">0.89</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T6.11.11.11.11.5\">-1.79</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.12.12.12.12\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.12.12.12.12.2\"><span class=\"ltx_text\" id=\"A3.T6.12.12.12.12.2.1\">MIND</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.12.12.12.12.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.12.12.12.12.3\">0.37</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.12.12.12.12.4\">-0.74</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.13.13.13.13\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.13.13.13.13.2\"><span class=\"ltx_text\" id=\"A3.T6.13.13.13.13.2.1\">AG News</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.13.13.13.13.1\"></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.13.13.13.13.3\">0.04</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T6.13.13.13.13.4\">-0.09</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T6.14.14.14.14\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T6.14.14.14.14.2\"><span class=\"ltx_text\" id=\"A3.T6.14.14.14.14.2.1\">Enron</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T6.14.14.14.14.1\"></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T6.14.14.14.14.3\">0.28</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A3.T6.14.14.14.14.4\">-0.56</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_figure\">Table 6: </span>The impact of extracted model size on <span class=\"ltx_text ltx_font_italic\" id=\"A3.T6.14.16.1\">CSE</span> performance.</figcaption>\n</figure>\n</figure>",
            "capture": "Table 6: The impact of extracted model size on CSE performance."
        }
    },
    "image_paths": {
        "1": {
            "figure_path": "2403.01472v2_figure_1.png",
            "caption": "Figure 1: An overview of recent developments: (a) model extraction attack on EaaS, (b) EmbMarker watermarking approach, and contributions from this work: (c) CSE attack and (d) WARDEN defense. CSE attack effectively eliminates the watermark (in Red) injected by EmbMarker, as shown in part (c). Whereas, WARDEN adds multiple watermarks (in Red, Blue, and Purple), where some of them (Blue and Purple in verification embedding) are missed by CSE attack, as illustrated in part (d)."
        },
        "2": {
            "figure_path": "2403.01472v2_figure_2.png",
            "caption": "Figure 2: The outline of our proposed CSE, consisting of three incremental steps: (i) clustering, (ii) selection, and (iii) elimination. More details are elaborated in Section 3.2."
        },
        "3": {
            "figure_path": "2403.01472v2_figure_3.png",
            "caption": "Figure 3: t-SNE (Van der Maaten and Hinton, 2008) visualisation for K-Means clustering (n=3\ud835\udc5b3n=3italic_n = 3) of MIND dataset, discussed in Section 3.2. Please refer to Appendix C.2 for plots of other datasets."
        },
        "4": {
            "figure_path": "2403.01472v2_figure_4.png",
            "caption": "Figure 4: Similarity distribution plot between the target embedding and various embedding types. As we can see, the suspected embeddings returned by the selection module in CSE are distinctly different from unsuspected embeddings and more akin to the target embedding. The results for other datasets are reported in Appendix B."
        },
        "5": {
            "figure_path": "2403.01472v2_figure_5.png",
            "caption": "Figure 5: The impact of the number of watermarks (R\ud835\udc45Ritalic_R) in WARDEN for SST2 dataset."
        },
        "6": {
            "figure_path": "2403.01472v2_figure_6.png",
            "caption": "Figure 6: The impact of the number of watermarks (R\ud835\udc45Ritalic_R) in WARDEN against CSE on SST2 dataset.\nNote: \u2018Recon. Cos. Sim.\u2019 (the Red line) represents the minimum reconstructed cosine similarity among all possible watermarks in \ud835\udc7e\ud835\udc7e{\\bm{W}}bold_italic_W."
        },
        "7": {
            "figure_path": "2403.01472v2_figure_7.png",
            "caption": "Figure 7: The impact of GS extension on WARDEN for SST2 dataset. The observations are in line with normal WARDEN (Figure 6) results with the only difference being stronger metrics."
        },
        "8": {
            "figure_path": "2403.01472v2_figure_8.png",
            "caption": "(a) SST2"
        },
        "9": {
            "figure_path": "2403.01472v2_figure_9.png",
            "caption": "(b) MIND"
        },
        "10": {
            "figure_path": "2403.01472v2_figure_10.png",
            "caption": "(c) AG News"
        },
        "11": {
            "figure_path": "2403.01472v2_figure_11.png",
            "caption": "(d) Enron"
        },
        "12": {
            "figure_path": "2403.01472v2_figure_12.png",
            "caption": "(a) SST2"
        },
        "13": {
            "figure_path": "2403.01472v2_figure_13.png",
            "caption": "(b) MIND"
        },
        "14": {
            "figure_path": "2403.01472v2_figure_14.png",
            "caption": "(c) AG News"
        },
        "15": {
            "figure_path": "2403.01472v2_figure_15.png",
            "caption": "(d) Enron"
        },
        "16": {
            "figure_path": "2403.01472v2_figure_16.png",
            "caption": "(a) SST2"
        },
        "17": {
            "figure_path": "2403.01472v2_figure_17.png",
            "caption": "(a) SST2"
        },
        "18": {
            "figure_path": "2403.01472v2_figure_18.png",
            "caption": "(b) MIND"
        },
        "19": {
            "figure_path": "2403.01472v2_figure_19.png",
            "caption": "(c) AG News"
        },
        "20": {
            "figure_path": "2403.01472v2_figure_20.png",
            "caption": "(d) Enron"
        },
        "21": {
            "figure_path": "2403.01472v2_figure_21.png",
            "caption": "(a) SST2"
        },
        "22": {
            "figure_path": "2403.01472v2_figure_22.png",
            "caption": "(b) MIND"
        },
        "23": {
            "figure_path": "2403.01472v2_figure_23.png",
            "caption": "(c) AG News"
        },
        "24": {
            "figure_path": "2403.01472v2_figure_24.png",
            "caption": "(d) Enron"
        },
        "25": {
            "figure_path": "2403.01472v2_figure_25.png",
            "caption": "(a) SST2"
        },
        "26": {
            "figure_path": "2403.01472v2_figure_26.png",
            "caption": "(b) MIND"
        },
        "27": {
            "figure_path": "2403.01472v2_figure_27.png",
            "caption": "(c) AG News"
        },
        "28": {
            "figure_path": "2403.01472v2_figure_28.png",
            "caption": "(d) Enron"
        },
        "29": {
            "figure_path": "2403.01472v2_figure_29.png",
            "caption": "(a) SST2"
        },
        "30": {
            "figure_path": "2403.01472v2_figure_30.png",
            "caption": "(b) MIND"
        },
        "31": {
            "figure_path": "2403.01472v2_figure_31.png",
            "caption": "(c) AG News"
        },
        "32": {
            "figure_path": "2403.01472v2_figure_32.png",
            "caption": "(d) Enron"
        },
        "33": {
            "figure_path": "2403.01472v2_figure_33.png",
            "caption": "(a) SST2"
        },
        "34": {
            "figure_path": "2403.01472v2_figure_34.png",
            "caption": "(b) MIND"
        },
        "35": {
            "figure_path": "2403.01472v2_figure_35.png",
            "caption": "(c) AG News"
        },
        "36": {
            "figure_path": "2403.01472v2_figure_36.png",
            "caption": "(d) Enron"
        },
        "37": {
            "figure_path": "2403.01472v2_figure_37.png",
            "caption": "(a) SST2"
        },
        "38": {
            "figure_path": "2403.01472v2_figure_38.png",
            "caption": "(b) MIND"
        },
        "39": {
            "figure_path": "2403.01472v2_figure_39.png",
            "caption": "(c) AG News"
        },
        "40": {
            "figure_path": "2403.01472v2_figure_40.png",
            "caption": "(d) Enron"
        },
        "41": {
            "figure_path": "2403.01472v2_figure_41.png",
            "caption": "(a) SST2"
        },
        "42": {
            "figure_path": "2403.01472v2_figure_42.png",
            "caption": "(b) MIND"
        },
        "43": {
            "figure_path": "2403.01472v2_figure_43.png",
            "caption": "(c) AG News"
        },
        "44": {
            "figure_path": "2403.01472v2_figure_44.png",
            "caption": "(d) Enron"
        },
        "45": {
            "figure_path": "2403.01472v2_figure_45.png",
            "caption": "(a) SST2"
        },
        "46": {
            "figure_path": "2403.01472v2_figure_46.png",
            "caption": "(b) MIND"
        },
        "47": {
            "figure_path": "2403.01472v2_figure_47.png",
            "caption": "(c) AG News"
        },
        "48": {
            "figure_path": "2403.01472v2_figure_48.png",
            "caption": "(d) Enron"
        },
        "49": {
            "figure_path": "2403.01472v2_figure_49.png",
            "caption": "(a) SST2"
        },
        "50": {
            "figure_path": "2403.01472v2_figure_50.png",
            "caption": "(b) MIND"
        },
        "51": {
            "figure_path": "2403.01472v2_figure_51.png",
            "caption": "(c) AG News"
        },
        "52": {
            "figure_path": "2403.01472v2_figure_52.png",
            "caption": "(d) Enron"
        }
    },
    "references": [
        {
            "1": {
                "title": "Generating natural language adversarial examples.",
                "author": "Moustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani Srivastava, and Kai-Wei Chang. 2018.",
                "venue": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2890\u20132896, Brussels, Belgium. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/D18-1316"
            }
        },
        {
            "2": {
                "title": "k-means++: The advantages of careful seeding.",
                "author": "David Arthur, Sergei Vassilvitskii, et al. 2007.",
                "venue": "In Soda, volume 7, pages 1027\u20131035.",
                "url": null
            }
        },
        {
            "3": {
                "title": "Kolmogorov\u2013Smirnov Test: Overview. John Wiley & Sons, Ltd.",
                "author": "Vance W. Berger and YanYan Zhou. 2014.",
                "venue": null,
                "url": "https://doi.org/https://doi.org/10.1002/9781118445112.stat06558"
            }
        },
        {
            "4": {
                "title": "Language models are few-shot learners.",
                "author": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020.",
                "venue": "In Advances in Neural Information Processing Systems, volume 33, pages 1877\u20131901. Curran Associates, Inc.",
                "url": "https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf"
            }
        },
        {
            "5": {
                "title": "Exploring connections between active learning and model extraction.",
                "author": "Varun Chandrasekaran, Kamalika Chaudhuri, Irene Giacomelli, Somesh Jha, and Songbai Yan. 2020.",
                "venue": "In Proceedings of the 29th USENIX Conference on Security Symposium, SEC\u201920, USA. USENIX Association.",
                "url": null
            }
        },
        {
            "6": {
                "title": "Badpre: Task-agnostic backdoor attacks to pre-trained NLP foundation models.",
                "author": "Kangjie Chen, Yuxian Meng, Xiaofei Sun, Shangwei Guo, Tianwei Zhang, Jiwei Li, and Chun Fan. 2022.",
                "venue": "In International Conference on Learning Representations.",
                "url": "https://openreview.net/forum?id=Mng8CQ9eBW"
            }
        },
        {
            "7": {
                "title": "A backdoor attack against lstm-based text classification systems.",
                "author": "Jiazhu Dai, Chuanshuai Chen, and Yufeng Li. 2019.",
                "venue": "IEEE Access, 7:138872\u2013138878.",
                "url": "https://doi.org/10.1109/ACCESS.2019.2941376"
            }
        },
        {
            "8": {
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding.",
                "author": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.",
                "venue": "In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171\u20134186, Minneapolis, Minnesota. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/N19-1423"
            }
        },
        {
            "9": {
                "title": "HotFlip: White-box adversarial examples for text classification.",
                "author": "Javid Ebrahimi, Anyi Rao, Daniel Lowd, and Dejing Dou. 2018.",
                "venue": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 31\u201336, Melbourne, Australia. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/P18-2006"
            }
        },
        {
            "10": {
                "title": "Singular value decomposition and least squares solutions.",
                "author": "G. H. Golub and C. Reinsch. 1970.",
                "venue": "Numer. Math., 14(5):403\u2013420.",
                "url": "https://doi.org/10.1007/BF02163027"
            }
        },
        {
            "11": {
                "title": "Extracted BERT model leaks more information than you think!",
                "author": "Xuanli He, Lingjuan Lyu, Chen Chen, and Qiongkai Xu. 2022a.",
                "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 1530\u20131537, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2022.emnlp-main.99"
            }
        },
        {
            "12": {
                "title": "Model extraction and adversarial transferability, your BERT is vulnerable!",
                "author": "Xuanli He, Lingjuan Lyu, Lichao Sun, and Qiongkai Xu. 2021a.",
                "venue": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2006\u20132012, Online. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2021.naacl-main.161"
            }
        },
        {
            "13": {
                "title": "Model extraction and adversarial transferability, your BERT is vulnerable!",
                "author": "Xuanli He, Lingjuan Lyu, Lichao Sun, and Qiongkai Xu. 2021b.",
                "venue": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2006\u20132012, Online. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2021.naacl-main.161"
            }
        },
        {
            "14": {
                "title": "Protecting intellectual property of language generation apis with lexical watermark.",
                "author": "Xuanli He, Qiongkai Xu, Lingjuan Lyu, Fangzhao Wu, and Chenguang Wang. 2022b.",
                "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, 36(10):10758\u201310766.",
                "url": "https://doi.org/10.1609/aaai.v36i10.21321"
            }
        },
        {
            "15": {
                "title": "CATER: Intellectual property protection on text generation APIs via conditional watermarks.",
                "author": "Xuanli He, Qiongkai Xu, Yi Zeng, Lingjuan Lyu, Fangzhao Wu, Jiwei Li, and Ruoxi Jia. 2022c.",
                "venue": "In Advances in Neural Information Processing Systems.",
                "url": "https://openreview.net/forum?id=L7P3IvsoUXY"
            }
        },
        {
            "16": {
                "title": "Training-free lexical backdoor attacks on language models.",
                "author": "Yujin Huang, Terry Yue Zhuo, Qiongkai Xu, Han Hu, Xingliang Yuan, and Chunyang Chen. 2023.",
                "venue": "In Proceedings of the ACM Web Conference 2023, pages 2198\u20132208.",
                "url": null
            }
        },
        {
            "17": {
                "title": "Prada: protecting against dnn model stealing attacks.",
                "author": "Mika Juuti, Sebastian Szyller, Samuel Marchal, and N Asokan. 2019.",
                "venue": "In 2019 IEEE European Symposium on Security and Privacy (EuroS&P), pages 512\u2013527. IEEE.",
                "url": null
            }
        },
        {
            "18": {
                "title": "A watermark for large language models.",
                "author": "John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein. 2023.",
                "venue": "In International Conference on Machine Learning, pages 17061\u201317084. PMLR.",
                "url": null
            }
        },
        {
            "19": {
                "title": "Thieves on sesame street! model extraction of bert-based apis.",
                "author": "Kalpesh Krishna, Gaurav Singh Tomar, Ankur P. Parikh, Nicolas Papernot, and Mohit Iyyer. 2020.",
                "venue": "In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.",
                "url": "https://openreview.net/forum?id=Byl5NREFDr"
            }
        },
        {
            "20": {
                "title": "Untargeted backdoor watermark: Towards harmless and stealthy dataset copyright protection.",
                "author": "Yiming Li, Yang Bai, Yong Jiang, Yong Yang, Shu-Tao Xia, and Bo Li. 2022.",
                "venue": "In Advances in Neural Information Processing Systems.",
                "url": "https://openreview.net/forum?id=kcQiIrvA_nz"
            }
        },
        {
            "21": {
                "title": "Protect, show, attend and tell: Empowering image captioning models with ownership protection.",
                "author": "Jian Han Lim, Chee Seng Chan, Kam Woh Ng, Lixin Fan, and Qiang Yang. 2022.",
                "venue": "Pattern Recognition, 122:108285.",
                "url": "https://doi.org/https://doi.org/10.1016/j.patcog.2021.108285"
            }
        },
        {
            "22": {
                "title": "Stolenencoder: Stealing pre-trained encoders in self-supervised learning.",
                "author": "Yupei Liu, Jinyuan Jia, Hongbin Liu, and Neil Zhenqiang Gong. 2022.",
                "venue": "In CCS 2022 - Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, Proceedings of the ACM Conference on Computer and Communications Security, pages 2115\u20132128. Association for Computing Machinery.",
                "url": "https://doi.org/10.1145/3548606.3560586"
            }
        },
        {
            "23": {
                "title": "Decoupled weight decay regularization.",
                "author": "Ilya Loshchilov and Frank Hutter. 2019.",
                "venue": "In International Conference on Learning Representations.",
                "url": "https://openreview.net/forum?id=Bkg6RiCqY7"
            }
        },
        {
            "24": {
                "title": "Pointer sentinel mixture models.",
                "author": "Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. 2016.",
                "venue": "In ICLR.",
                "url": null
            }
        },
        {
            "25": {
                "title": "Spam filtering with naive bayes-which naive bayes?",
                "author": "Vangelis Metsis, Ion Androutsopoulos, and Georgios Paliouras. 2006.",
                "venue": "In CEAS, volume 17, pages 28\u201369. Mountain View, CA.",
                "url": null
            }
        },
        {
            "26": {
                "title": "New embedding models and API updates \u2014 openai.com.",
                "author": "OpenAI. 2024.",
                "venue": "https://openai.com/blog/new-embedding-models-and-api-updates.",
                "url": null
            }
        },
        {
            "27": {
                "title": "Knockoff nets: Stealing functionality of black-box models.",
                "author": "Tribhuvanesh Orekondy, Bernt Schiele, and Mario Fritz. 2019.",
                "venue": "In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 4949\u20134958.",
                "url": "https://doi.org/10.1109/CVPR.2019.00509"
            }
        },
        {
            "28": {
                "title": "Scikit-learn: Machine learning in Python.",
                "author": "F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011.",
                "venue": "Journal of Machine Learning Research, 12:2825\u20132830.",
                "url": null
            }
        },
        {
            "29": {
                "title": "Are you copying my model? protecting the copyright of large language models for EaaS via backdoor watermark.",
                "author": "Wenjun Peng, Jingwei Yi, Fangzhao Wu, Shangxi Wu, Bin Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu, Guangzhong Sun, and Xing Xie. 2023.",
                "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 7653\u20137668, Toronto, Canada. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2023.acl-long.423"
            }
        },
        {
            "30": {
                "title": "Geometric algebra with applications in engineering, volume 4.",
                "author": "Christian Perwass, Herbert Edelsbrunner, Leif Kobbelt, and Konrad Polthier. 2009.",
                "venue": "Springer.",
                "url": null
            }
        },
        {
            "31": {
                "title": "Language models are unsupervised multitask learners.",
                "author": "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019.",
                "venue": "OpenAI blog, 1(8):9.",
                "url": null
            }
        },
        {
            "32": {
                "title": "Sentence-BERT: Sentence embeddings using Siamese BERT-networks.",
                "author": "Nils Reimers and Iryna Gurevych. 2019.",
                "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3982\u20133992, Hong Kong, China. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/D19-1410"
            }
        },
        {
            "33": {
                "title": "Gaussian mixture models.",
                "author": "Douglas A Reynolds et al. 2009.",
                "venue": "Encyclopedia of biometrics, 741(659-663).",
                "url": null
            }
        },
        {
            "34": {
                "title": "Recursive deep models for semantic compositionality over a sentiment treebank.",
                "author": "Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013.",
                "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1631\u20131642, Seattle, Washington, USA. Association for Computational Linguistics.",
                "url": "https://aclanthology.org/D13-1170"
            }
        },
        {
            "35": {
                "title": "Watermarking vision-language pre-trained models for multi-modal embedding as a service.",
                "author": "Yuanmin Tang, Jing Yu, Keke Gai, Xiangyan Qu, Yue Hu, Gang Xiong, and Qi Wu. 2023.",
                "venue": null,
                "url": "http://arxiv.org/abs/2311.05863"
            }
        },
        {
            "36": {
                "title": "Stealing machine learning models via prediction apis.",
                "author": "Florian Tram\u00e8r, Fan Zhang, Ari Juels, Michael K. Reiter, and Thomas Ristenpart. 2016.",
                "venue": "In Proceedings of the 25th USENIX Conference on Security Symposium, SEC\u201916, page 601\u2013618, USA. USENIX Association.",
                "url": null
            }
        },
        {
            "37": {
                "title": "Numerical Linear Algebra.",
                "author": "Lloyd N. Trefethen and David Bau. 1997.",
                "venue": "SIAM.",
                "url": null
            }
        },
        {
            "38": {
                "title": "Embedding watermarks into deep neural networks.",
                "author": "Yusuke Uchida, Yuki Nagai, Shigeyuki Sakazawa, and Shin\u2019ichi Satoh. 2017.",
                "venue": "In Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval, ICMR \u201917, page 269\u2013277, New York, NY, USA. Association for Computing Machinery.",
                "url": "https://doi.org/10.1145/3078971.3078974"
            }
        },
        {
            "39": {
                "title": "Visualizing data using t-sne.",
                "author": "Laurens Van der Maaten and Geoffrey Hinton. 2008.",
                "venue": "Journal of machine learning research, 9(11).",
                "url": null
            }
        },
        {
            "40": {
                "title": "Imitation attacks and defenses for black-box machine translation systems.",
                "author": "Eric Wallace, Mitchell Stern, and Dawn Xiaodong Song. 2020.",
                "venue": "In Conference on Empirical Methods in Natural Language Processing.",
                "url": "https://api.semanticscholar.org/CorpusID:216868525"
            }
        },
        {
            "41": {
                "title": "Transformers: State-of-the-art natural language processing.",
                "author": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020.",
                "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38\u201345, Online. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2020.emnlp-demos.6"
            }
        },
        {
            "42": {
                "title": "MIND: A large-scale dataset for news recommendation.",
                "author": "Fangzhao Wu, Ying Qiao, Jiun-Hung Chen, Chuhan Wu, Tao Qi, Jianxun Lian, Danyang Liu, Xing Xie, Jianfeng Gao, Winnie Wu, and Ming Zhou. 2020.",
                "venue": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3597\u20133606, Online. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2020.acl-main.331"
            }
        },
        {
            "43": {
                "title": "Security challenges in natural language processing models.",
                "author": "Qiongkai Xu and Xuanli He. 2023.",
                "venue": "In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts, pages 7\u201312, Singapore. Association for Computational Linguistics.",
                "url": "https://doi.org/10.18653/v1/2023.emnlp-tutorial.2"
            }
        },
        {
            "44": {
                "title": "Student surpasses teacher: Imitation attack for black-box NLP APIs.",
                "author": "Qiongkai Xu, Xuanli He, Lingjuan Lyu, Lizhen Qu, and Gholamreza Haffari. 2022.",
                "venue": "In Proceedings of the 29th International Conference on Computational Linguistics, pages 2849\u20132860, Gyeongju, Republic of Korea. International Committee on Computational Linguistics.",
                "url": "https://aclanthology.org/2022.coling-1.251"
            }
        },
        {
            "45": {
                "title": "Black-box attacks on sequential recommenders via data-free model extraction.",
                "author": "Zhenrui Yue, Zhankui He, Huimin Zeng, and Julian McAuley. 2021.",
                "venue": "In Proceedings of the 15th ACM Conference on Recommender Systems, RecSys \u201921, page 44\u201354, New York, NY, USA. Association for Computing Machinery.",
                "url": "https://doi.org/10.1145/3460231.3474275"
            }
        },
        {
            "46": {
                "title": "Character-level convolutional networks for text classification.",
                "author": "Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015.",
                "venue": "In Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1, NIPS\u201915, page 649\u2013657, Cambridge, MA, USA. MIT Press.",
                "url": null
            }
        },
        {
            "47": {
                "title": "Red alarm for pre-trained models: Universal vulnerability to neuron-level backdoor attacks.",
                "author": "Zhengyan Zhang, Guangxuan Xiao, Yongwei Li, Tian Lv, Fanchao Qi, Zhiyuan Liu, Yasheng Wang, Xin Jiang, and Maosong Sun. 2023.",
                "venue": "Machine Intelligence Research, 20(2):180\u2013193.",
                "url": "https://doi.org/10.1007/s11633-022-1377-5"
            }
        }
    ],
    "url": "http://arxiv.org/html/2403.01472v2",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2",
            "2.1",
            "2.2"
        ],
        "methodology_sections": [
            "3",
            "3.1",
            "3.2",
            "3.3"
        ],
        "main_experiment_and_results_sections": [
            "4",
            "4.1",
            "4.2",
            "4.3"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "3",
            "4.2",
            "4.3"
        ]
    },
    "research_context": {
        "paper_id": "2403.01472v2",
        "paper_title": "WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection",
        "research_background": "### Motivation\nThe paper is motivated by the increasing use of Large Language Models (LLMs) as Embedding-as-a-Service (EaaS) provided by commercial entities such as OpenAI, Google, and Mistral AI. These models are highly effective in various NLP tasks, making them valuable in commercial applications. However, the success of EaaS has also led to vulnerabilities, particularly model extraction attacks, where attackers imitate the capabilities of these models by querying them and training their own competitive models with far less cost and resources. This presents a significant threat to the intellectual property (IP) of EaaS providers.\n\n### Research Problem\nThe primary research problem addressed in the paper is the defense against model extraction attacks on EaaS models. The current defense mechanisms involve embedding backdoor watermarks in the model's output, which can later be used to recognize stolen models. However, existing watermarking methods come with limitations:\n1. **Quality Preservation**: The watermark should not degrade the quality of the original application.\n2. **Stealth**: The watermark should be difficult for malicious users to identify or deduce.\n\nThe paper identifies that despite these methods, skilled attackers can use techniques such as Clustering, Selection, and Elimination (CSE) to neutralize these watermarks while maintaining high utility of the model. Therefore, there is a need for a more robust watermarking mechanism.\n\n### Relevant Prior Work\n1. **EaaS Vulnerabilities**: Studies have highlighted vulnerabilities like model extraction attacks (Krishna et al., 2020; Tram\u00e8r et al., 2016; He et al., 2021a) and privacy breaches (He et al., 2022a). Other challenges include more performant surrogate models (Xu et al., 2022) and transferable adversarial attacks (He et al., 2021b).\n2. **Existing Watermarking Techniques**: The first methods for embedding watermarks in EaaS involve incorporating a pre-determined embedding vector in text embeddings linked to specific trigger words (Peng et al., 2023). These methods focus on ensuring that watermarks do not degrade model quality and are difficult to detect (Juuti et al., 2019).\n3. **CSE Attack**: This is a novel framework that challenges traditional watermarking techniques by selecting and neutralizing watermarked embeddings via a process of Clustering, Selection, and Elimination. Empirical evidence shows this method can effectively remove watermarks without compromising model utility.\n\nGiven the limitations of current watermarking techniques against sophisticated attacks like CSE, the paper proposes WARDEN, a multi-directional watermarking augmentation mechanism designed to be more robust and stealthy against CSE attacks. The paper makes two main contributions:\n1. **CSE Framework**: Demonstrates a method to effectively breach state-of-the-art watermarking techniques.\n2. **WARDEN Defense Mechanism**: Shows that using multiple watermark embeddings can counteract CSE, thereby enhancing the robustness and stealthiness of watermark-based defenses in EaaS models.",
        "methodology": "This section outlines the methodology of the proposed method, \"WARDEN,\" including the overall framework, detailed attack design, and extensions to backdoor watermarking techniques.\n\n1. **Overview of Conventional Backdoor Watermark Framework:**\n   - The basic framework is used to counter model extraction attacks by embedding watermarks into models.\n\n2. **Clustering to Enhance Selection:**\n   - **Clustering Algorithms:** Employed to organize retrieved embeddings into groups.\n     - Improves pair-wise distance calculation efficiency.\n     - Provides distinct groups facilitating anomalous pair identification.\n   - **K-Means Algorithm:** Primary clustering approach.\n   - **Challenges:** Watermarked samples spread and inconspicuous; centroids of watermarked samples and overall clusters do not coincide.\n\n3. **Selection Module:**\n   - **Holding Standard Model:** Introduce a standard model for comparison.\n   - **Pairwise Distance Evaluations:** Conduct evaluations on embeddings within each cluster.\n   - **Watermarked Samples Identification:** Search for distinctive distance changes indicative of suspected watermark samples.\n\n4. **Embedding Watermark (EmbMarker):**\n   - **Embedding Poisoning:** Incorporate predetermined target embedding into texts containing trigger words.\n   - **Anomalous Embedding Behavior:** Distance between embeddings with watermark exhibits anomaly behavior.\n   - **Evaluation Metric:** Use cosine similarity disparities to reflect the significance of anomalous pairs.\n\n5. **Watermark Extraction and Elimination:**\n   - **Suspicious Embeddings:** Identify watermark from suspicious embeddings\u2019 top principal components.\n   - **Singular Value Decomposition (SVD):** Identify top principal components.\n   - **Gram-Schmidt (GS) Process:** Iteratively eliminate principal components\u2019 contributions.\n\n6. **Embedding Modification and Verification:**\n   - **Trigger Words Set Split:** Multiple independent subsets for different watermarks.\n   - **Watermark Proportion:** Consistent with single watermark case and randomly split among triggers.\n   - **Copyright Verification:** Conservative approach\u2014flagging IP infringement if any watermark indicates so.\n   - **Verification Datasets:** Create backdoor texts and benign texts for comparison.\n   - **Closeness Metric:** Compute cosine similarity and squared distance between target and modified embeddings.\n\n7. **Performance Evaluation:**\n   - **Comparison Metrics:**\n     - Difference in averaged cosine similarity.\n     - Averaged squared distance.\n     - Kolmogorov-Smirnov (KS) test.\n   - **Infringement Certification:** Infringement certified if any watermark is detected confidently.\n\nThis comprehensive methodology combines advanced clustering, selection techniques, embedding manipulation, and rigorous verification to protect the copyright of embeddings used in Embedding-as-a-Service.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n#### Datasets\n- **Enron**: Used for email spam classification.\n- **SST2**: Employed for sentiment classification.\n- **AG News**: Utilized for news classification tasks.\n- **MIND**: Applied for news recommendation tasks.\n\n#### Evaluation Metrics\n1. **Downstream Task Performance**: Evaluated using a multi-layer perceptron (MLP) classifier with the embeddings from Embedding-as-a-Service (EaaS) as inputs. The performance is measured by accuracy and F1-score of the classifiers on the downstream tasks.\n2. **Reconstruction Attack Performance**: Assessed by measuring the cosine similarity between the reconstructed target embedding(s) and the original target embedding(s).\n3. **Infringement Detection Performance**: Measured using customized variations of p-value, difference of cosine similarity, and difference of squared distance metrics.\n\n#### Main Experimental Results\n1. **CSE Effectiveness**:\n    - Reconstruction of the target embedding using CSE demonstrates a high cosine similarity (99+%), indicating successful recovery and watermark removal.\n\n2. **WARDEN Effectiveness Against CSE**:\n    - Utilizing multiple watermarks improves detection performance with only marginal degradation in downstream utility.\n    - Increased number of watermarks correlates with reduced CSE attack effectiveness, as it becomes stealthier.\n    - Application of the Gram-Schmidt (GS) process on target embeddings shows stronger detection performance and significantly lower cosine similarities for reconstructed embeddings post-CSE, indicating heightened resistance to attacks.\n\nOverall, the main experiment results corroborate the robustness of the proposed methods in both attacking (CSE) and defending (WARDEN) scenarios, validating the effectiveness of the techniques and metrics employed."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To evaluate the effectiveness of the CSE attack in bypassing watermark detection while maintaining high utility of embeddings.",
            "experiment_process": "The CSE attack was tested by attempting to bypass the watermark detection using the same metrics but with the goal of lower p-value and metrics close to zero. The EmbMarker's secret target embedding () was removed, and the impact on copyright verification and downstream utility was measured. Cosine similarity was calculated to validate the recovery and elimination of the target embedding. The experiment used datasets such as SST2, MIND, AG News to gauge the effect on downstream performance.",
            "result_discussion": "The experiments showed that CSE could effectively remove watermarks with minimal impact on downstream utility, maintaining 99%+ cosine similarity to the original target embedding. The copyright detection performance dropped significantly, and for specific datasets, downstream performance only dropped by 1-2%, demonstrating the efficacy of the CSE attack.",
            "ablation_id": "2403.01472v2.No1"
        },
        {
            "research_objective": "To assess the effectiveness of WARDEN in resisting the CSE attack by employing multiple watermarks.",
            "experiment_process": "WARDEN's performance was evaluated by measuring the detection of multiple watermarks under CSE attacks. Different datasets were used, and key metrics like cosine similarity, squared distance, and KS test p-values were recorded. Additional experiments included applying the Gram-Schmidt (GS) process to target embeddings to see if orthogonality of watermark embeddings improved resistance to CSE.",
            "result_discussion": "Results indicated that WARDEN's multiple watermarks enhanced the stealthiness against CSE, showing a decrease in CSE's effectiveness with more watermarks. Orthogonality through the GS process further improved detection performance and reduced target embedding similarity, contributing to more effective watermarking defense. False positives were noted at higher values, but other metrics helped in minimizing misclassification.",
            "ablation_id": "2403.01472v2.No2"
        }
    ]
}