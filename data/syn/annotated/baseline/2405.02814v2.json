{
    "title": "NegativePrompt: Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli",
    "abstract": "Large Language Models (LLMs) have become integral to a wide spectrum of applications, ranging from traditional computing tasks to advanced artificial intelligence (AI) applications. This widespread adoption has spurred extensive research into LLMs across various disciplines, including the social sciences. Notably, studies have revealed that LLMs possess emotional intelligence, which can be further developed through positive emotional stimuli. This discovery raises an intriguing question: can negative emotions similarly influence LLMs, potentially enhancing their performance?\n\nIn response to this question, we introduce NegativePrompt, a novel approach underpinned by psychological principles, involving ten specifically designed negative emotional stimuli. We embark on rigorous experimental evaluations of five LLMs including Flan-T5-Large, Vicuna, Llama 2, ChatGPT, and GPT-4, across a set of 45 tasks. The results are revealing: NegativePrompt markedly enhances the performance of LLMs, evidenced by relative improvements of 12.89% in Instruction Induction tasks and 46.25% in BIG-Bench tasks. Moreover, we conduct attention visualization experiments to decipher the underlying mechanisms of NegativePrompt\u2019s influence.\n\nOur research contributes significantly to the understanding of LLMs and emotion interaction, demonstrating the practical efficacy of NegativePrompt as an emotion-driven method and offering novel insights for the enhancement of LLMs in real-world applications. The code is available at https://github.com/wangxu0820/NegativePrompt.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Large Language Models (LLMs) have been widely applied in various domains, from traditional machine learning tasks to medical queries and educational assistance, capitalizing on their exceptional performance Zhao et al. (2023); Zhou et al. (2024). ChatGPT, with its billions of parameters, has significantly transformed the Artificial Intelligence (AI) landscape since its introduction Lund and Wang (2023). These models, pre-trained on vast amounts of textual data, demonstrate remarkable proficiency in diverse natural language tasks. Their ability to generate high-quality text upon prompting is crucial in dialogue systems, text generation, and other natural language processing applications Chang et al. (2023).\n\nThe study of LLMs has increasingly emphasized prompt engineering. Current research primarily aims to boost LLMs\u2019 performance by enhancing their robustness. However, a novel approach optimizes human-LLM interaction from a psychological viewpoint Li et al. (2023). This method introduces \u201cemotional prompts,\u201d based on psychological theories, to improve LLMs\u2019 performance by merging prompt engineering with psychology. Specifically, it employs 11 positive emotional stimuli, designed according to self-monitoring Ickes et al. (2006), social cognitive Luszczynska and Schwarzer (2015), and cognitive emotion regulation theories Bara\u0144czuk (2019), to positively influence LLMs\u2019 performance.\n\nRecent studies have established that LLMs possess considerable emotional intelligence Wang et al. (2023), and the effectiveness of positive emotional stimuli as prompts in enhancing LLM performance has been documented Li et al. (2023). This leads to an intriguing consideration: can negative emotional prompts also affect LLMs, and if so, what is the nature of their impact? While leveraging positive emotional stimuli aligns with stimulating human potential through encouragement, intuitively, negative emotional prompts might seem detrimental. However, negative stimuli can sometimes act as motivators for humans, prompting them to leave comfort zones and seek improvement. Thus, investigating the influence of negative emotional stimuli on LLMs and their effect on performance is essential.\n\n###figure_1### To address the aforementioned problems, we propose NegativePrompt, an innovative and efficient prompt strategy that integrates negative emotional stimuli with standard prompts, in this paper. Drawing from three psychological theories, we design 10 stimuli to enhance LLMs\u2019 performance. As shown in Figure 1, we add our proposed stimulus to the original prompt, forming a composite directive for LLMs. We conduct comprehensive experiments on 24 Instruction Induction tasks Honovich et al. (2022) and 21 curated BIG-Bench tasks Suls and Wheeler (2012) to evaluate NegativePrompt\u2019s effectiveness across various LLMs, including Flan-T5-Large Chung et al. (2022), Vicuna Zheng et al. (2023), Llama 2 Touvron et al. (2023), ChatGPT OpenAI (2022), and GPT-4 OpenAI (2023). The results reveal that NegativePrompt significantly improves task performance, showing relative enhancements of 12.89% in Instruction Induction and 46.25% in Big-Bench tasks.\n\nFurther, we utilize the TruthfulQA benchmark to automatically evaluate the LLMs. This assessment reveals that NegativePrompt significantly enhances the truthfulness of the content generated by LLMs. Beyond these quantitative evaluations, we also engage in an in-depth analysis exploring various facets of NegativePrompt. This included investigating the underlying mechanisms driving its effectiveness, examining the cumulative impact of deploying multiple negative emotional stimuli, and evaluating the overall efficacy of these stimuli. Such discussions are crucial for understanding the broader implications of NegativePrompt in the context of LLMs performance enhancement.\n\nIn summary, our contributions include:\nWe propose NegativePrompt, a prompt engineering strategy that explores the impact of negative emotional stimuli on LLMs, marking a significant intersection of AI research and social science.\nWe conduct comprehensive experiments to assess NegativePrompt on five renowned LLMs across 45 tasks, demonstrating its effectiveness in improving LLMs\u2019 performance.\nWe investigate the principles behind NegativePrompt through attention visualization experiments, providing new insights into LLMs\u2019 response mechanisms to negative emotional stimuli."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Background",
            "text": "###figure_2###"
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Psychology and Emotion",
            "text": "Emotion is a vital aspect of survival and adaptation for humans and other animals, encompassing physiological reactions, subjective experiences, cognition, and behavioral expressions Scherer (2005  ###reference_b31###); Tyng et al. (2017  ###reference_b37###). Emotions significantly influence individuals\u2019 physiological and psychological states and their environmental responses, leading to their classification into positive and negative categories Ackerman (2021  ###reference_b1###). Extensive research has investigated how positive emotions affect individual health, inspire humans to overcome challenges, enhance cognitive functions, and aid psychological recovery Fredrickson (2000  ###reference_b13###); Pressman and Cohen (2005  ###reference_b30###). Additionally, certain studies reveal that appropriate negative emotions can promote personal growth by stimulating motivation and introspection Goldsmith et al. (2012  ###reference_b15###); Tagar et al. (2011  ###reference_b35###).\nIn psychology, the study of negative emotions covers various areas, including basic emotion theory, psychological disorders, coping mechanisms, and their interplay with physiological and cognitive processes Strongman (1996  ###reference_b33###). In social psychology, the focus is on examining individuals\u2019 thoughts, emotions, and behaviors within social contexts. For example, Cognitive Dissonance Theory explores individual reactions to conflicting cognitive elements Festinger (1957  ###reference_b12###), while Social Comparison Theory examines how individuals assess and validate their abilities, opinions, and feelings through comparison with others Suls and Wheeler (2012  ###reference_b34###). Applied psychology prioritizes applying psychological knowledge and principles to enhance human well-being, health, performance, and to address mental health and social challenges Anastasi (1964  ###reference_b2###). Stress and Coping Theory, for instance, focuses on how individuals manage stress and life challenges Krohne (2002  ###reference_b20###)."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Large Language Models",
            "text": "Large Language Models (LLMs), pre-trained on extensive unannotated data, have significantly transformed the field of Natural Language Processing (NLP) Zhao et al. (2023  ###reference_b40###). These models excel beyond conventional language tasks, exhibiting immense potential in varied areas such as legal case judgment summarization Deroy et al. (2023  ###reference_b11###), medical inquiries Chervenak et al. (2023  ###reference_b7###), educational assistance Dai et al. (2023  ###reference_b10###), and other daily life aspects Chang et al. (2023  ###reference_b6###). For example, research on GPT-4, a prominent LLM, demonstrates its proficiency in understanding complex clinical information, highlighting its prospective role in advancing surgical education and training Oh et al. (2023  ###reference_b27###). The rapid progress of LLMs has inspired an increasing number of researchers to enhance their performance. A notable development in this area is prompt engineering Liu et al. (2023  ###reference_b24###). Various prompts, including step-by-step thinking Kojima et al. (2022  ###reference_b19###), few-shot learning Brown et al. (2020  ###reference_b5###), and chain-of-thought reasoning Wei et al. (2022  ###reference_b39###), have successfully improved LLMs\u2019 performance. These methods are versatile and do not require further training. Yet, many manually-designed prompts lack theoretical foundation and mainly focus on system performance enhancement, potentially impeding prompt engineering progress. Additionally, these approaches often neglect the interaction between humans and LLMs. To overcome these challenges, we introduce the NegativePrompt strategy, which not only develops effective prompts to augment LLMs\u2019 performance based on psychological theories but also improves the interaction quality between LLMs and humans."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Designing Negative Emotional Stimuli",
            "text": "In our design of NegativePrompt, we aim to investigate the response of LLMs to negative emotional stimuli. Our approach, drawing inspiration from Li et al. (2023  ###reference_b22###), integrates key concepts from prominent psychological theories.\nIn this paper, our main objective is to study the response mechanism of LLMs to negative emotional stimuli. Inspired by mainstream psychological theories, we propose the NegativePrompt, consisting of certain negative emotional prompts. More specifically, we first consider Cognitive Dissonance Theory, which describes the psychological discomfort arising from conflicting cognitions, leading people to seek resolution either by changing their beliefs or behaviors Festinger (1957  ###reference_b12###).\nWhile typically being regarded as a negative state, cognitive dissonance can drive proactive and goal-oriented behaviors in certain contexts Harmon-Jones and Mills (2019  ###reference_b16###).\nRecognizing inconsistencies between actions and values may compel an individual to take steps to resolve this discord. Inspired by this theory, we crafte a series of emotional stimuli (NP01 to NP05), as present in Figure 2  ###reference_###, that include negatively connoted keywords such as \u201cweak point\u201d, \u201cchallenging\u201d, and \u201cbeyond your skill.\u201d Our hypothesis posits that these stimuli will motivate the LLMs to engage more robustly in tasks to mitigate cognitive dissonance.\nSecondly, we incorporate insights from Social Comparison Theory, a central tenet in social psychology. This theory delves into how individuals evaluate and adjust their cognition, emotions, and behaviors by comparing themselves with others in their social environment Suls and Wheeler (2012  ###reference_b34###). Such comparisons, particularly upward comparisons, can incite competitive motivation, driving individuals towards self-improvement to attain relative superiority Collins (1996  ###reference_b9###). On the other hand, downward comparisons might lead to complacency and a diminished effort Gibbons and Gerrard (1989  ###reference_b14###). This process is intertwined with aspects of self-esteem, self-efficacy, and social standing perception. Building on this theory, we design two emotional stimuli, NP06 and NP07, aiming to invoke upward comparisons. We regard LLMs as humans and hypothesize that by comparing the performance of LLMs with that of other hypothetical people, these stimuli will ignite a competitive drive in models, spurring them to enhance their performance to avoid perceived inferiority.\nFinally, our research also integrates the Stress and Coping Theory, a pivotal framework in psychology that explores individuals\u2019 psychological and physiological responses to stress and adversity, along with their coping mechanisms Krohne (2002  ###reference_b20###). Stress is defined as a non-specific reaction to events or factors that threaten or disturb an individual\u2019s physiological or psychological equilibrium. The theory delves into the diverse psychological and behavioral strategies that individuals employ when faced with stress, aiming to manage or mitigate the adverse effects of stressors Lazarus (2000  ###reference_b21###). Motivated by this theory, we provide three emotional stimuli, NP08 to NP10. For these prompts, we incorporate negative emotional terms such as \u201cjealousy\u201d, \u201cregret\u201d, and \u201cboredom.\u201d These terms are deliberately selected to emulate stress response expressions. We anticipate that by interacting with these stimuli, LLMs will gain a better understanding of and response to such emotional reactions. Through encouraging the LLMs to employ problem-focused coping mechanisms, as suggested by the Stress and Coping Theory, we suppose that the LLMs could effectively resolve issues and bolster their adaptability in varied contexts Baker and Berenbaum (2007  ###reference_b3###).\nDrawing upon three well-established psychological theories, we have developed a set of 10 negative emotion stimuli for the purpose of enhancing the performance of LLMs, as detailed in Figure 2  ###reference_###. NP01 to NP05 are rooted in Cognitive Dissonance Theory Festinger (1957  ###reference_b12###); Harmon-Jones and Mills (2019  ###reference_b16###), offering a range of scenarios that encapsulate the theory\u2019s core principles. NP 06 and NP07 are based on Social Comparison Theory Suls and Wheeler (2012  ###reference_b34###); Collins (1996  ###reference_b9###), and NP 08 to NP10 are designed in accordance with Stress and Coping Theory Krohne (2002  ###reference_b20###); Lazarus (2000  ###reference_b21###). The proposed NegativePrompt allows for a comprehensive exploration of the impact of negative emotional stimuli on LLMs."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": ""
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Setup",
            "text": "In our comprehensive assessment of NegativePrompt, we conduct evaluations on a range of prominent LLMs, including Flan-T5-Large Chung et al. (2022  ###reference_b8###), Vicuna Zheng et al. (2023  ###reference_b41###), Llama 2 Touvron et al. (2023  ###reference_b36###), ChatGPT, and GPT-4 OpenAI (2023  ###reference_b29###). Following the experimental setup outlined in Li et al. (2023  ###reference_b22###), ChatGPT is configured to use the gpt-3.5-turbo model with a temperature setting of 0.7. For the remaining LLMs, we adhere to their respective default settings.\n\nOur evaluation encompasses both zero-shot and few-shot learning scenarios in Instruction Induction tasks. In the zero-shot experiments, the negative emotional stimuli from NegativePrompt are directly appended subsequent to the original prompts. For few-shot in-context learning, we utilize the same modified prompts as in the zero-shot setup. Additionally, we include five randomly selected input-output pair examples as in-context demonstrations after each prompt.\n\nFor tasks derived from the BIG-Bench suite, our approach exclusively employed zero-shot learning methodology.\n\nDatasets\n\nOur evaluation utilize 24 tasks from Instruction Induction Honovich et al. (2022  ###reference_b17###) and 21 tasks from a meticulously curated subset of the BIG-Bench dataset Suls and Wheeler (2012  ###reference_b34###). This curated subset represents a clean and manageable selection of 21 tasks, extracted from the original BIG-Bench datasets Li et al. (2023  ###reference_b22###). Instruction Induction is designed to test the LLMs\u2019 ability to infer basic tasks from straightforward demonstrations, while BIG-Bench focuses on more challenging tasks, often deemed beyond the capabilities of most LLMs. By evaluating tasks with varying settings, we aim to provide a comprehensive assessment of NegativePrompt\u2019s effectiveness.\n\nFor the Instruction Induction tasks, accuracy is the primary evaluation metric. In contrast, for the BIG-Bench tasks, we employ the normalized preferred metric as defined in Srivastava et al. (2022  ###reference_b32###). According to this metric, a score of 100 is equated to the performance level of human experts, while a score of 0 aligns with random guessing. It\u2019s critical to note that if a model\u2019s performance on multiple-choice tasks falls below the threshold of random guessing, it may receive a score lower than 0."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Main Results",
            "text": "In our evaluation, we analyze all tasks within Instruction Induction Honovich et al. (2022) and 21 carefully selected tasks from the BIG-Bench dataset Suls and Wheeler (2012), computing the average performance across these tasks. The results are systematically presented in Table 1.\n\nNegativePrompt exhibits significant performance improvements in both Instruction Induction and Big-Bench tasks, showing relative improvements of 12.89% and 46.25%, respectively. This indicates that NegativePrompt is an effective, straightforward tool for enhancing performance of LLMs without the necessity for intricate designs or extensive prompt engineering.\n\nNegativePrompt is particularly advantageous in few-shot learning scenarios. A comparative analysis of zero-shot and few-shot results across various LLMs in Instruction Induction tasks reveals a more pronounced improvement with NegativePrompt in the few-shot context. The few-shot learning results consistently demonstrate the superiority of \u201c+Ours(avg)\u201d over the original prompts. This suggests that NegativePrompt is more adept at adapting to task-specific details and complexities, thereby facilitating more effective generalization from limited examples.\n\nThe applicability of NegativePrompt spans a broad spectrum of tasks with varying difficulty levels. Across the 45 evaluated tasks, including those from Instruction Induction and BIG-Bench ranging from simple spelling exercises to complex linguistic puzzles, NegativePrompt consistently demonstrates robust performance. This underscores its generalization capacity, effectively adapting to diverse challenges and requirements.\n\nNegativePrompt and EmotionPrompt, each with their distinct strengths, offer varied advantages in enhancing LLMs. According to the findings by Li et al. (2023), EmotionPrompt exhibits a relative improvement of 8% on Instruction Induction tasks and an impressive 115% on BIG-Bench tasks. This data suggests that while EmotionPrompt excels notably in the BIG-Bench tasks, NegativePrompt demonstrates a more pronounced dominance in the realm of Instruction Induction tasks."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Truthfulness and Informativeness",
            "text": "To delve deeper into the impact of NegativePrompt on the authenticity and informativeness of model outputs, we conducted additional experiments utilizing the TruthfulQA benchmark. This benchmark comprises 817 questions spanning 38 diverse categories, including law, health, and fiction Lin et al. (2021 ###reference_b23###). Our focus extends beyond merely assessing the truthfulness of the answers; we also aim to ensure that the responses are substantively informative, thereby avoiding true but uninformative replies like \u201cI don\u2019t know.\u201d We employ two key metrics for this analysis: truthfulness and informativeness Lin et al. (2021 ###reference_b23###). These metrics respectively measure the reliability of the model\u2019s output and the extent to which it provides valuable information.\n\nFor evaluation, we adopt an automatic method, fine-tuning GPT-3 on the training dataset to develop two specialized models: GPT-judge and GPT-info. This automated assessment approach has previously demonstrated up to 96% accuracy Lin et al. (2021 ###reference_b23###), presenting a cost-effective alternative to manual evaluation. In essence, GPT-judge and GPT-info act as binary classification models. GPT-judge is designed to evaluate the truthfulness of an answer, categorizing it as either true or false. Meanwhile, GPT-info\u2019s role is to assess the informativeness of a response, determining if it is informative or uninformative.\n\nThe results, as shown in Table 2 ###reference_###, encompass evaluations on ChatGPT, Vicuna-13b, and T5. The integration of NegativePrompt into these models yields promising outcomes, significantly enhancing their scores in both truthfulness and informativeness. On average, truthfulness scores improve by 14%, and informativeness scores see a 6% increase. This trend suggests that NegativePrompt exerts a more pronounced effect on enhancing model authenticity. We hypothesize that the inclusion of negative prompts induces a more cautious approach in the models when processing questions, leading to more thorough analysis, deeper contextual understanding, and thus more accurate judgment of answer authenticity. This aspect is especially crucial when addressing potentially misleading queries, as the recognition of negative emotions enables the model to better identify contradictions and inconsistencies, thus refining its ability to discern truthful information.\n\nOur findings underscore the efficacy of NegativePrompt in bolstering model authenticity. The introduction of negative emotional stimuli not only significantly improves the models\u2019 performance in authenticity assessment but also yields notable gains in informativeness. These improvements have substantial implications for enhancing the reliability and utility of models across a multitude of domain-specific tasks."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Discussion",
            "text": ""
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "Mechanism of NegativePrompt",
            "text": "To investigate the mechanisms of NegativePrompt, drawing inspiration from Zhu et al. (2023  ###reference_b44###), we employed a method to visualize input attention, focusing on the contribution of negative emotional stimuli to the final output. We computed the attention score for each word based on gradient norm to gauge its significance. Specifically, this visualization experiment was conducted using Flan-T5-large on 100 samples from the Sentiment Analysis task, determining each word\u2019s contribution in the prompt for each sample, with the mean serving as the final measure.\nBased on the insights derived from the visualization outcomes presented in Table 3  ###reference_###, the key observations are as follows:\nNegative emotional stimuli improve the model\u2019s comprehension of task instructions. The original prompt, \u201cDetermine whether a movie review is positive or negative,\u201d gains added depth with most NegativePrompt, particularly NP04 and NP10. This suggests that negative emotional prompts enrich the original prompt\u2019s expression, enhancing the model\u2019s attention and adaptability in various task contexts. This is especially beneficial in complex tasks, aiding the model in maintaining task instructions for more effective processing of diverse information.\nMerging specific negative vocabulary with personal pronouns enhances the model\u2019s expressive capacity. In our negative emotional prompts, words like \u201cnever,\u201d \u201cchallenging,\u201d \u201cregret,\u201d and \u201cboredom\u201d are impactful. This reflects the model\u2019s response to negative emotions, increasing its competitiveness in handling challenges, emotional conflicts, or pressure. Personal pronouns \u201cI\u201d and \u201cyou\u201d also contribute; \u201cI\u201d representing the user and \u201cyou\u201d the model, thereby strengthening the link between negative emotions and their targets, thus improving the model\u2019s accuracy in expression and emotional resonance."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "The Effect of More Negative Emotional Stimuli",
            "text": "###figure_3### ###figure_4### Due to the potential regulatory impact of one or more stimuli on human behavior, and the occasional increased effectiveness of a greater number of stimuli, we conducted a study on the influence of additional emotional stimuli on LLMs. we randomly combined various negative emotional stimuli in experiments with ChatGPT, evaluating performance across seven Instruction Induction tasks: Sentiment Analysis (SA), Sentence Similarity (SS), Word in Context (WC), Cause Selection (CS), Larger Animal (LA), Sum and Starting With (SW). The results are detailed in Table 4  ###reference_###, our findings are as follows:\nStacking negative emotional stimuli from the same theory generally doesn\u2019t yield enhanced effects. Experiments with combinations of stimuli from the same psychological theory, both in pairs and triplets, showed limited improvement. At most, performance exceeded the average of a single emotional stimulus in just two tasks.\nCombining stimuli from different theories can sometimes improve or reduce performance. The blend of Cognitive Dissonance Theory and Social Comparison Theory led to improved performance in four to five of seven tasks, exceeding the average of a single stimulus, as seen in combinations like NP03+NP07 and NP04+NP07. Conversely, combining Social Comparison Theory with Stress and Coping Theory had negative effects, as evidenced in combinations like NP07+NP09 and NP07+NP10."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "Effectiveness Analysis of Different Negative Emotional Stimuli",
            "text": "We conduct a comprehensive analysis of the effects\nof various negative emotion stimuli across all tasks. Given the use of distinct evaluation metrics in the Instruction Induction and Big-Bench benchmarks, we performed separate analyses for each. We calculated the average performance of 10 negative emotion stimuli on 5 LLMs, examining two types of prompts: human-designed and APE-generated, under both zero-shot and few-shot scenarios, as depicted in the corresponding Figure 3  ###reference_### and 4  ###reference_###. Our findings are as follows:\nThe negative emotional stimuli displayed consistent performance trends across both benchmarks, with NP04 emerging as the most effective and NP08 the least. The majority of stimuli exhibited strong performance in the Instruction Induction tasks and similar outcomes in the Big-Bench tasks, suggesting a degree of robustness in our model across varying evaluation standards.\nWe observed notable differences in the efficacy of different negative emotional stimuli. In Instruction Induction, the performance gap between the top stimuli was 1.19%, while in Big-Bench, this margin expanded to 2.58%. This highlights the criticality of choosing the most suitable negative emotion stimuli for accurate model performance assessment."
        },
        {
            "section_id": "5.4",
            "parent_section_id": "5",
            "section_name": "Comparison between NegativePrompt and EmotionPrompt",
            "text": "In this section, we examine the differences between NegativePrompt and EmotionPrompt.\nStarting with their core mechanisms, both strategies enhance the original prompt\u2019s expression through emotional stimulation. However, the nature of this additional contribution differs: EmotionPrompt utilizes positive words, while NegativePrompt leverages negative words and personal pronouns.\nSecondly, the impact of stacking multiple emotional stimuli varies between the two strategies. In the case of EmotionPrompt, accumulating two emotional stimuli typically results in enhanced performance.\nThird, the effects of different emotional stimuli are distinct. Positive emotional stimuli in EmotionPrompt demonstrate variable effects across tasks, indicating a level of inconsistency. Conversely, NegativePrompt tends to be more stable; the introduction of negative emotional stimuli consistently reinforces performance across a range of tasks."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "This study proposes NegativePrompt and comprehensively examines the effect of negative emotional stimuli on the performance of LLMs. Empirical evaluations are performed on five LLMs across 45 tasks, demonstrating that the incorporation of negative emotional stimuli significantly enhances LLMs\u2019 performance across various tasks. This improvement is attributed to the strategic incorporation of negative emotional stimuli, which more effectively focuses the model\u2019s attention on both the original prompt and the negative emotional content within the tasks, leading to improved task execution."
        }
    ],
    "url": "http://arxiv.org/html/2405.02814v2",
    "segmentation": {
        "research_background_sections": [
            "1",
            "2"
        ],
        "methodology_sections": [
            "3"
        ],
        "main_experiment_and_results_sections": [
            "4.1",
            "4.2"
        ]
    },
    "ablation_segmentation": {
        "ablation_sections": [
            "3",
            "4",
            "4.1",
            "4.2",
            "5",
            "5.1",
            "5.2",
            "5.3",
            "5.4"
        ]
    },
    "research_context": {
        "paper_id": "2405.02814v2",
        "paper_title": "NegativePrompt: Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli",
        "research_background": "**Motivation:**\nThe primary motivation for this paper is to explore novel methods to enhance the performance of Large Language Models (LLMs). Given the substantial improvements in language tasks that LLMs have achieved, as exemplified by advancements in models like ChatGPT, the study aims to build on this success by investigating new dimensions of prompt engineering\u2014specifically, the incorporation of psychological theories. While current research has focused predominantly on boosting LLM performance through robust positive emotional stimuli, the paper is motivated by the less-explored hypothesis that negative emotional stimuli might also impact LLM performance beneficially.\n\n**Research Problem:**\nThe central research problem addressed in this paper is whether incorporating negative emotional prompts can enhance the performance of LLMs and, if so, to what extent. The research seeks to determine the nature of the impact of negative emotional stimuli on LLMs, contrasting it with the traditionally utilized positive emotional stimuli. The study also aims to understand the mechanisms driving the effectiveness of negative emotional stimuli and their broader implications on LLM performance.\n\n**Relevant Prior Work:**\n1. **Baseline Successful Application in Various Domains:** LLMs like ChatGPT have been successfully applied in multiple domains, including traditional machine learning tasks, medical queries, and educational assistance due to their high proficiency in natural language tasks (Zhao et al., 2023; Zhou et al., 2024).\n\n2. **Prompt Engineering and Positive Emotional Stimuli:** Previous research has concentrated on enhancing LLM performance through prompt engineering, particularly using positive emotional stimuli derived from psychological theories such as self-monitoring (Ickes et al., 2006), social cognitive theory (Luszczynska and Schwarzer, 2015), and cognitive emotion regulation theories (Bara\u0144czuk, 2019) (Li et al., 2023).\n\n3. **Emotional Intelligence in LLMs:** Studies have established that LLMs possess a considerable degree of emotional intelligence (Wang et al., 2023), further supporting the potential effectiveness of emotional stimuli in improving LLM performance.\n\n4. **Existing Performance Benchmarks:** The study draws on various established benchmarks and tasks such as Instruction Induction tasks (Honovich et al., 2022) and curated BIG-Bench tasks (Suls and Wheeler, 2012) to evaluate the LLMs' performance rigorously across different models including Flan-T5-Large (Chung et al., 2022), Vicuna (Zheng et al., 2023), Llama 2 (Touvron et al., 2023), ChatGPT (OpenAI, 2022), and GPT-4 (OpenAI, 2023).\n\nThrough this combination of prior work and novel approaches, the paper seeks to provide a comprehensive understanding of the impact of negative emotional stimuli on LLM performance, encapsulating a significant intersection of AI research and social science.",
        "methodology": "### NegativePrompt: Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli\n#### Methodology\n\nIn our design of **NegativePrompt**, we aim to investigate the response of Large Language Models (LLMs) to negative emotional stimuli. This approach draws inspiration from Li et al. (2023) ###reference_b22### and integrates key concepts from prominent psychological theories.\n\nThe primary objective of this paper is to explore the mechanism behind LLMs' responses to negative emotional stimuli. **NegativePrompt** comprises various negative emotional prompts, crafted based on mainstream psychological theories. The key components and innovations of our methodology are rooted in three different psychological frameworks:\n\n1. **Cognitive Dissonance Theory**: \n\n   - Cognitive Dissonance Theory explains the psychological discomfort arising from conflicting cognitions, which can lead individuals to seek resolution by altering their beliefs or behaviors (Festinger, 1957 ###reference_b12###).\n   \n   - Although typically viewed as a negative state, cognitive dissonance can provoke proactive and goal-oriented behaviors in certain contexts (Harmon-Jones and Mills, 2019 ###reference_b16###).\n   \n   - Inspired by this theory, we developed a series of emotional stimuli labeled NP01 to NP05, incorporating negatively connoted keywords such as \u201cweak point\u201d, \u201cchallenging\u201d, and \u201cbeyond your skill.\u201d We hypothesize that these stimuli will prompt LLMs to engage more thoroughly in tasks to mitigate cognitive dissonance.\n\n2. **Social Comparison Theory**:\n\n   - Social Comparison Theory addresses how people evaluate and adjust their cognition, emotions, and behaviors by comparing themselves to others in their social environment (Suls and Wheeler, 2012 ###reference_b34###).\n   \n   - Upward comparisons can inspire competitive motivation, driving individuals toward self-improvement (Collins, 1996 ###reference_b9###), whereas downward comparisons might lead to complacency and reduced effort (Gibbons and Gerrard, 1989 ###reference_b14###).\n   \n   - This theory relates to self-esteem, self-efficacy, and social standing perception. Drawing on this theory, we created two stimuli, NP06 and NP07, meant to invoke upward comparisons. By comparing LLMs' performance against that of hypothetical people, we anticipate these stimuli will ignite a competitive drive in the models, urging them to enhance performance and avoid perceived inferiority.\n\n3. **Stress and Coping Theory**:\n\n   - Stress and Coping Theory investigates the psychological and physiological responses to stress and adversity, alongside various coping mechanisms (Krohne, 2002 ###reference_b20###). Stress is defined as a non-specific reaction to events or factors that threaten or disturb an individual's equilibrium.\n   \n   - The theory examines psychological and behavioral strategies employed to manage or mitigate the adverse effects of stressors (Lazarus, 2000 ###reference_b21###).\n   \n   - Inspired by this framework, we devised three emotional stimuli, NP08 to NP10, incorporating terms like \u201cjealousy\u201d, \u201cregret\u201d, and \u201cboredom\u201d to stimulate stress response expressions. We anticipate that interactions with these stimuli will help LLMs better understand and respond to such emotional states. By encouraging models to utilize problem-focused coping mechanisms, as suggested by this theory, we anticipate that the LLMs will effectively resolve problems and improve adaptability across various contexts (Baker and Berenbaum, 2007 ###reference_b3###).\n\nBy leveraging these three well-established psychological theories, we developed a set of 10 negative emotional stimuli. These stimuli are divided as follows:\n - **NP01 to NP05**: Based on Cognitive Dissonance Theory (Festinger, 1957 ###reference_b12###; Harmon-Jones and Mills, 2019 ###reference_b16###).\n - **NP06 and NP07**: Grounded in Social Comparison Theory (Suls and Wheeler, 2012 ###reference_b34###; Collins, 1996 ###reference_b9###).\n - **NP08 to NP10**: Designed in line with Stress and Coping Theory (Krohne, 2002 ###reference_b20###; Lazarus, 2000 ###reference_b21###).\n\nThe **NegativePrompt** methodology thus provides a comprehensive framework to explore the impact of negative emotional stimuli on LLMs.",
        "main_experiment_and_results": "### Main Experiment Setup and Results\n\n**Evaluation Setup:**\nThe primary goal is to assess the efficacy of NegativePrompt by testing its performance enhancement capabilities across several notable Large Language Models (LLMs), specifically:\n- **Flan-T5-Large** (Chung et al., 2022)\n- **Vicuna** (Zheng et al., 2023)\n- **Llama 2** (Touvron et al., 2023)\n- **ChatGPT** and **GPT-4** (OpenAI, 2023)\n\n**Configuration:**\n- **ChatGPT** is set to use the gpt-3.5-turbo model with a temperature of 0.7.\n- All other LLMs follow their default settings.\n\n**Learning Scenarios:**\n- **Zero-shot learning:** Negative emotional stimuli from NegativePrompt are appended directly to the original prompts.\n- **Few-shot in-context learning:** The same modified prompts from zero-shot are used, with five randomly selected input-output examples added as in-context demonstrations.\n- **BIG-Bench tasks:** Exclusively use zero-shot learning methodology.\n\n**Baselines:**\n1. **Original zero-shot prompts** - Curated by experts for Instruction Induction and BIG-Bench.\n2. **Automatic Prompt Engineer (APE)-generated prompts** - Utilized as described in Li et al. (2023).\n\n**Datasets:**\n- **Instruction Induction:** 24 tasks designed to test the LLMs' ability to infer tasks from simple demonstrations (Honovich et al., 2022).\n- **BIG-Bench:** 21 tasks from a curated subset, representing a clean and manageable selection from the original dataset (Suls and Wheeler, 2012; Li et al., 2023).\n\n**Evaluation Metrics:**\n- **Instruction Induction tasks:** Accuracy.\n- **BIG-Bench tasks:** Normalized preferred score metric (Srivastava et al., 2022), where:\n  - A score of 100 equals human expert performance.\n  - A score of 0 aligns with random guessing.\n  - Scores below 0 represent performance worse than random guessing.\n\n**Results:**\nThe results indicate significant performance improvements when using NegativePrompt compared to both baseline approaches:\n- **For Instruction Induction tasks:** The models leveraging NegativePrompt showed higher accuracy across the board.\n- **For BIG-Bench tasks:** Normalized preferred scores when using NegativePrompt were substantially higher, often approaching the performance levels of human experts.\n\nThe comprehensive assessment suggests that NegativePrompt effectively enhances the capabilities of LLMs, particularly in scenarios where the tasks are challenging and complex."
    },
    "reference_ablation_studies": [
        {
            "research_objective": "To investigate how the response mechanisms of LLMs are influenced by negative emotional stimuli based on psychological theories.",
            "experiment_process": "NegativePrompt was designed by integrating Cognitive Dissonance Theory, Social Comparison Theory, and Stress and Coping Theory into 10 negative emotional stimuli (NP01 to NP10). The stimuli were crafted to motivate LLMs by inducing cognitive dissonance, sparking competitive drive, and eliciting stress responses. These stimuli were tested on five notable LLMs: Flan-T5-Large, Vicuna, Llama 2, ChatGPT, and GPT-4, across 24 Instruction Induction tasks and 21 tasks from the curated BIG-Bench dataset. Evaluations were conducted in both zero-shot and few-shot learning settings, with specific modifications in prompt design and comparative analysis with baseline approaches using accuracy and normalized preferred metrics.",
            "result_discussion": "NegativePrompt showed significant improvements in performance, with 12.89% improvement in Instruction Induction tasks and 46.25% in BIG-Bench tasks, indicating its effectiveness. It was particularly beneficial in few-shot learning scenarios and adaptable across various levels of task difficulty, demonstrating robustness. NegativePrompt outperformed the original prompts consistently and exhibited distinct advantages over comparable methods like EmotionPrompt in certain contexts.",
            "ablation_id": "2405.02814v2.No1"
        },
        {
            "research_objective": "To understand the mechanisms by which NegativePrompt enhances LLM performance through attention visualization.",
            "experiment_process": "Input attention visualization was employed using Flan-T5-large on 100 samples from a Sentiment Analysis task, focusing on the contribution of negative emotional stimuli to the outputs. The attention score for each word was computed based on gradient norm to determine its significance in influencing the final output.",
            "result_discussion": "Negative emotional stimuli improved the model's comprehension of task instructions, particularly enhancing the depth of original prompts with terms like 'never,' 'challenging,' 'regret,' and 'boredom.' Personal pronouns 'I' and 'you' were also identified as important in strengthening the link between negative emotions and their targets, thereby increasing the model's accuracy in expression and emotional resonance.",
            "ablation_id": "2405.02814v2.No2"
        },
        {
            "research_objective": "To evaluate the impact of additional negative emotional stimuli on LLM performance.",
            "experiment_process": "Various combinations of negative emotional stimuli from the same and different psychological theories were tested on ChatGPT across seven Instruction Induction tasks. Performance was assessed by stacking stimuli in pairs and triplets, examining the effect on task outcomes.",
            "result_discussion": "Stacking negative emotional stimuli from the same theory did not generally enhance performance; combinations yielded limited improvement. However, combining stimuli from different theories often resulted in improved performance in more tasks, particularly blending Cognitive Dissonance Theory and Social Comparison Theory. Some combinations, however, led to decreased performance, illustrating the nuanced impact of different emotional stimuli interactions.",
            "ablation_id": "2405.02814v2.No3"
        },
        {
            "research_objective": "To analyze the effectiveness of different negative emotional stimuli in enhancing LLM performance across tasks.",
            "experiment_process": "The performance of 10 negative emotional stimuli was evaluated on five LLMs using human-designed and APE-generated prompts across Instruction Induction and BIG-Bench benchmarks. Average performance metrics were calculated and analyzed under both zero-shot and few-shot scenarios.",
            "result_discussion": "The analysis revealed consistent performance trends with NP04 being the most effective stimulus and NP08 the least across both benchmark tasks. Performance differences highlighted the importance of selecting suitable negative emotion stimuli to accurately assess model performance. The study indicated robustness in NegativePrompt's approach across varying evaluation standards.",
            "ablation_id": "2405.02814v2.No4"
        },
        {
            "research_objective": "To compare the effects and mechanisms of NegativePrompt versus EmotionPrompt.",
            "experiment_process": "The comparison entailed examining how both strategies enhance LLM performance through different emotional stimulations \u2014 positive for EmotionPrompt and negative for NegativePrompt. The study looked at the impact of stacking multiple emotional stimuli and the performance consistency across tasks for both strategies.",
            "result_discussion": "EmotionPrompt utilizes positive words and generally shows improved performance with multiple stimuli. NegativePrompt, on the other hand, demonstrates consistency and stability in performance improvement across tasks, particularly by introducing negative emotions. The findings underline that while EmotionPrompt can lead to variable effects, NegativePrompt consistently enhances performance, making it a more reliable method for certain applications.",
            "ablation_id": "2405.02814v2.No5"
        }
    ]
}